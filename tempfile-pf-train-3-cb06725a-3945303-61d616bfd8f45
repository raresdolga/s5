//
// Generated by LLVM NVPTX Back-End
//

.version 8.3
.target sm_80
.address_size 64

	// .globl	loop_maximum_select_fusion_6
.visible .global .align 128 .b8 buffer_for_constant_1607_0[64];
// shared_cache has been demoted
// shared_cache1 has been demoted
// shared_cache2 has been demoted
// shared_cache3 has been demoted
// shared_cache4 has been demoted
// shared_cache5 has been demoted
// shared_cache6 has been demoted
// shared_cache7_$_0 has been demoted
// shared_cache8 has been demoted
// shared_cache9 has been demoted
// shared_cache10 has been demoted
// shared_cache11 has been demoted
// shared_cache12 has been demoted
// shared_cache13 has been demoted
// shared_cache14 has been demoted
// shared_cache15 has been demoted
// shared_cache16 has been demoted
// shared_cache17 has been demoted
// shared_cache18 has been demoted
// shared_cache19 has been demoted
// shared_cache20 has been demoted
// shared_cache21 has been demoted
// shared_cache22 has been demoted
// shared_cache23 has been demoted
// shared_cache24 has been demoted
// shared_cache25 has been demoted
// shared_cache26 has been demoted
// shared_cache27 has been demoted
// shared_cache28 has been demoted
// shared_cache29 has been demoted
// shared_cache30 has been demoted
// shared_cache31 has been demoted
// shared_cache32 has been demoted
// shared_cache33 has been demoted
// shared_cache34 has been demoted
// shared_cache35 has been demoted
// shared_cache36 has been demoted
// shared_cache37 has been demoted
// shared_cache38 has been demoted
// shared_cache39 has been demoted
// shared_cache40 has been demoted
// shared_cache41 has been demoted
// shared_cache42 has been demoted
// shared_cache43 has been demoted
// shared_cache44 has been demoted
// shared_cache45 has been demoted
// shared_cache46 has been demoted
// shared_cache47 has been demoted
// shared_cache48 has been demoted
// shared_cache49 has been demoted
// shared_cache50 has been demoted
// shared_cache51 has been demoted
// shared_cache52 has been demoted
// shared_cache53 has been demoted
// shared_cache54 has been demoted
// shared_cache55 has been demoted
// shared_cache56 has been demoted
// shared_cache57 has been demoted
// shared_cache58 has been demoted
// shared_cache59 has been demoted
// shared_cache60 has been demoted
// shared_cache61 has been demoted
// shared_cache62 has been demoted
// sort_$_35_$_1_tile_param_0 has been demoted
// sort_$_35_$_1_tile_param_1 has been demoted
// sort_$_35_$_1_tile_param_2 has been demoted
// sort_$_34_$_1_tile_param_0 has been demoted
// sort_$_34_$_1_tile_param_1 has been demoted
// sort_$_34_$_1_tile_param_2 has been demoted
// sort_$_33_$_1_tile_param_0 has been demoted
// sort_$_33_$_1_tile_param_1 has been demoted
// sort_$_33_$_1_tile_param_2 has been demoted
// sort_$_32_$_1_tile_param_0 has been demoted
// sort_$_32_$_1_tile_param_1 has been demoted
// sort_$_32_$_1_tile_param_2 has been demoted
// sort_$_31_$_0_tile_param_0 has been demoted
// sort_$_31_$_0_tile_param_1 has been demoted
// sort_$_31_$_0_tile_param_2 has been demoted
// sort_$_30_$_1_tile_param_0 has been demoted
// sort_$_30_$_1_tile_param_1 has been demoted
// sort_$_30_$_1_tile_param_2 has been demoted
// shared_cache63 has been demoted
// shared_cache64 has been demoted
// shared_cache65 has been demoted
// shared_cache66 has been demoted
// shared_cache67 has been demoted
.extern .shared .align 16 .b8 global_smem[];
.global .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry loop_maximum_select_fusion_6(
	.param .u64 loop_maximum_select_fusion_6_param_0,
	.param .u64 loop_maximum_select_fusion_6_param_1,
	.param .u64 loop_maximum_select_fusion_6_param_2
)
.reqntid 64, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<7>;
	.reg .f32 	%f<171>;
	.reg .b64 	%rd<12>;

	ld.param.u64 	%rd1, [loop_maximum_select_fusion_6_param_0];
	ld.param.u64 	%rd2, [loop_maximum_select_fusion_6_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_maximum_select_fusion_6_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %tid.x;
	mul.lo.s32 	%r2, %r1, 6;
	mul.wide.u32 	%rd7, %r2, 24;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd8];
	sub.rn.f32 	%f5, %f1, %f1;
	abs.f32 	%f6, %f5;
	ld.global.nc.v4.f32 	{%f7, %f8, %f9, %f10}, [%rd8+16];
	sub.rn.f32 	%f11, %f9, %f2;
	abs.f32 	%f12, %f11;
	add.rn.f32 	%f13, %f6, %f12;
	ld.global.nc.v4.f32 	{%f14, %f15, %f16, %f17}, [%rd8+48];
	sub.rn.f32 	%f18, %f14, %f3;
	abs.f32 	%f19, %f18;
	add.rn.f32 	%f20, %f13, %f19;
	ld.global.nc.v4.f32 	{%f21, %f22, %f23, %f24}, [%rd8+64];
	sub.rn.f32 	%f25, %f23, %f4;
	abs.f32 	%f26, %f25;
	add.rn.f32 	%f27, %f20, %f26;
	ld.global.nc.v4.f32 	{%f28, %f29, %f30, %f31}, [%rd8+96];
	sub.rn.f32 	%f32, %f28, %f7;
	abs.f32 	%f33, %f32;
	add.rn.f32 	%f34, %f27, %f33;
	ld.global.nc.v4.f32 	{%f35, %f36, %f37, %f38}, [%rd8+112];
	sub.rn.f32 	%f39, %f37, %f8;
	abs.f32 	%f40, %f39;
	add.rn.f32 	%f41, %f34, %f40;
	sub.rn.f32 	%f42, %f2, %f9;
	abs.f32 	%f43, %f42;
	sub.rn.f32 	%f44, %f10, %f10;
	abs.f32 	%f45, %f44;
	add.rn.f32 	%f46, %f43, %f45;
	ld.global.nc.v4.f32 	{%f47, %f48, %f49, %f50}, [%rd8+32];
	sub.rn.f32 	%f51, %f15, %f47;
	abs.f32 	%f52, %f51;
	add.rn.f32 	%f53, %f46, %f52;
	sub.rn.f32 	%f54, %f24, %f48;
	abs.f32 	%f55, %f54;
	add.rn.f32 	%f56, %f53, %f55;
	sub.rn.f32 	%f57, %f29, %f49;
	abs.f32 	%f58, %f57;
	add.rn.f32 	%f59, %f56, %f58;
	sub.rn.f32 	%f60, %f38, %f50;
	abs.f32 	%f61, %f60;
	add.rn.f32 	%f62, %f59, %f61;
	max.NaN.f32 	%f63, %f41, %f62;
	sub.rn.f32 	%f64, %f3, %f14;
	abs.f32 	%f65, %f64;
	sub.rn.f32 	%f66, %f47, %f15;
	abs.f32 	%f67, %f66;
	add.rn.f32 	%f68, %f65, %f67;
	sub.rn.f32 	%f69, %f16, %f16;
	abs.f32 	%f70, %f69;
	add.rn.f32 	%f71, %f68, %f70;
	ld.global.nc.v4.f32 	{%f72, %f73, %f74, %f75}, [%rd8+80];
	sub.rn.f32 	%f76, %f72, %f17;
	abs.f32 	%f77, %f76;
	add.rn.f32 	%f78, %f71, %f77;
	sub.rn.f32 	%f79, %f30, %f21;
	abs.f32 	%f80, %f79;
	add.rn.f32 	%f81, %f78, %f80;
	ld.global.nc.v4.f32 	{%f82, %f83, %f84, %f85}, [%rd8+128];
	sub.rn.f32 	%f86, %f82, %f22;
	abs.f32 	%f87, %f86;
	add.rn.f32 	%f88, %f81, %f87;
	max.NaN.f32 	%f89, %f63, %f88;
	sub.rn.f32 	%f90, %f4, %f23;
	abs.f32 	%f91, %f90;
	sub.rn.f32 	%f92, %f48, %f24;
	abs.f32 	%f93, %f92;
	add.rn.f32 	%f94, %f91, %f93;
	sub.rn.f32 	%f95, %f17, %f72;
	abs.f32 	%f96, %f95;
	add.rn.f32 	%f97, %f94, %f96;
	sub.rn.f32 	%f98, %f73, %f73;
	abs.f32 	%f99, %f98;
	add.rn.f32 	%f100, %f97, %f99;
	sub.rn.f32 	%f101, %f31, %f74;
	abs.f32 	%f102, %f101;
	add.rn.f32 	%f103, %f100, %f102;
	sub.rn.f32 	%f104, %f83, %f75;
	abs.f32 	%f105, %f104;
	add.rn.f32 	%f106, %f103, %f105;
	max.NaN.f32 	%f107, %f89, %f106;
	sub.rn.f32 	%f108, %f7, %f28;
	abs.f32 	%f109, %f108;
	sub.rn.f32 	%f110, %f49, %f29;
	abs.f32 	%f111, %f110;
	add.rn.f32 	%f112, %f109, %f111;
	sub.rn.f32 	%f113, %f21, %f30;
	abs.f32 	%f114, %f113;
	add.rn.f32 	%f115, %f112, %f114;
	sub.rn.f32 	%f116, %f74, %f31;
	abs.f32 	%f117, %f116;
	add.rn.f32 	%f118, %f115, %f117;
	sub.rn.f32 	%f119, %f35, %f35;
	abs.f32 	%f120, %f119;
	add.rn.f32 	%f121, %f118, %f120;
	sub.rn.f32 	%f122, %f84, %f36;
	abs.f32 	%f123, %f122;
	add.rn.f32 	%f124, %f121, %f123;
	max.NaN.f32 	%f125, %f107, %f124;
	sub.rn.f32 	%f126, %f8, %f37;
	abs.f32 	%f127, %f126;
	sub.rn.f32 	%f128, %f50, %f38;
	abs.f32 	%f129, %f128;
	add.rn.f32 	%f130, %f127, %f129;
	sub.rn.f32 	%f131, %f22, %f82;
	abs.f32 	%f132, %f131;
	add.rn.f32 	%f133, %f130, %f132;
	sub.rn.f32 	%f134, %f75, %f83;
	abs.f32 	%f135, %f134;
	add.rn.f32 	%f136, %f133, %f135;
	sub.rn.f32 	%f137, %f36, %f84;
	abs.f32 	%f138, %f137;
	add.rn.f32 	%f139, %f136, %f138;
	sub.rn.f32 	%f140, %f85, %f85;
	abs.f32 	%f141, %f140;
	add.rn.f32 	%f142, %f139, %f141;
	max.NaN.f32 	%f143, %f125, %f142;
	mul.rn.f32 	%f144, %f143, 0f3E826BFA;
	setp.lt.f32 	%p1, %f144, 0f00800000;
	mul.rn.f32 	%f145, %f144, 0f4B000000;
	selp.f32 	%f146, %f145, %f144, %p1;
	selp.f32 	%f147, 0fC1B80000, 0f00000000, %p1;
	mov.b32 	%r3, %f146;
	add.s32 	%r4, %r3, -1059760811;
	and.b32  	%r5, %r4, -8388608;
	sub.s32 	%r6, %r3, %r5;
	mov.b32 	%f148, %r6;
	cvt.rn.f32.s32 	%f149, %r5;
	fma.rn.f32 	%f150, %f149, 0f34000000, %f147;
	add.rn.f32 	%f151, %f148, 0fBF800000;
	fma.rn.f32 	%f152, %f151, 0fBE055027, 0f3E1039F6;
	fma.rn.f32 	%f153, %f152, %f151, 0fBDF8CDCC;
	fma.rn.f32 	%f154, %f153, %f151, 0f3E0F2955;
	fma.rn.f32 	%f155, %f154, %f151, 0fBE2AD8B9;
	fma.rn.f32 	%f156, %f155, %f151, 0f3E4CED0B;
	fma.rn.f32 	%f157, %f156, %f151, 0fBE7FFF22;
	fma.rn.f32 	%f158, %f157, %f151, 0f3EAAAA78;
	fma.rn.f32 	%f159, %f158, %f151, 0fBF000000;
	mul.rn.f32 	%f160, %f151, %f159;
	fma.rn.f32 	%f161, %f160, %f151, %f151;
	fma.rn.f32 	%f162, %f150, 0f3F317218, %f161;
	setp.gt.u32 	%p2, %r3, 2139095039;
	fma.rn.f32 	%f163, %f146, 0f7F800000, 0f7F800000;
	selp.f32 	%f164, %f163, %f162, %p2;
	setp.eq.f32 	%p3, %f146, 0f00000000;
	mul.rn.f32 	%f165, %f164, 0f3FB8AA3B;
	selp.f32 	%f166, 0fFF800000, %f165, %p3;
	cvt.rmi.f32.f32 	%f167, %f166;
	max.NaN.f32 	%f168, %f167, 0f00000000;
	setp.nan.f32 	%p4, %f143, %f143;
	setp.eq.f32 	%p5, %f143, 0f00000000;
	selp.f32 	%f169, 0f00000000, %f143, %p5;
	selp.f32 	%f170, 0f7FC00000, %f169, %p4;
	mul.wide.u32 	%rd9, %r1, 4;
	add.s64 	%rd10, %rd5, %rd9;
	st.global.f32 	[%rd10], %f168;
	add.s64 	%rd11, %rd3, %rd9;
	st.global.f32 	[%rd11], %f170;
	ret;

}
	// .globl	loop_power_fusion_4
.visible .entry loop_power_fusion_4(
	.param .u64 loop_power_fusion_4_param_0,
	.param .u64 loop_power_fusion_4_param_1
)
.reqntid 64, 1, 1
{
	.reg .pred 	%p<11>;
	.reg .b32 	%r<11>;
	.reg .f32 	%f<66>;
	.reg .b64 	%rd<10>;

	ld.param.u64 	%rd3, [loop_power_fusion_4_param_0];
	ld.param.u64 	%rd4, [loop_power_fusion_4_param_1];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd5, %rd3;
	mov.u32 	%r1, %tid.x;
	cvt.u64.u32 	%rd2, %r1;
	mul.wide.u32 	%rd6, %r1, 4;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.nc.f32 	%f1, [%rd7];
	setp.eq.f32 	%p5, %f1, 0f00000000;
	mov.f32 	%f65, 0f3F800000;
	@%p5 bra 	$L__BB1_4;
	mov.f32 	%f10, 0f40000000;
	abs.f32 	%f2, %f10;
	setp.nan.f32 	%p6, %f2, %f2;
	abs.f32 	%f62, %f1;
	setp.nan.f32 	%p7, %f62, %f62;
	or.pred  	%p8, %p6, %p7;
	@!%p8 bra 	$L__BB1_3;
	bra.uni 	$L__BB1_2;
$L__BB1_2:
	add.rn.f32 	%f65, %f10, %f1;
	bra.uni 	$L__BB1_4;
$L__BB1_3:
	setp.lt.f32 	%p1, %f2, 0f00800000;
	mul.rn.f32 	%f11, %f2, 0f4B800000;
	selp.f32 	%f12, %f11, %f2, %p1;
	selp.f32 	%f13, 0fC1C00000, 0f00000000, %p1;
	mov.b32 	%r2, %f12;
	add.s32 	%r3, %r2, -1060439283;
	and.b32  	%r4, %r3, -8388608;
	sub.s32 	%r5, %r2, %r4;
	mov.b32 	%f14, %r5;
	cvt.rn.f32.s32 	%f15, %r4;
	fma.rn.f32 	%f16, %f15, 0f34000000, %f13;
	add.rn.f32 	%f17, %f14, 0fBF800000;
	add.rn.f32 	%f8, %f14, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f7,%f8;
	// end inline asm
	add.rn.f32 	%f18, %f17, %f17;
	mul.rn.f32 	%f19, %f18, %f7;
	mul.rn.f32 	%f20, %f19, %f19;
	sub.rn.f32 	%f21, %f17, %f19;
	add.rn.f32 	%f22, %f21, %f21;
	neg.f32 	%f23, %f19;
	fma.rn.f32 	%f24, %f23, %f17, %f22;
	mul.rn.f32 	%f25, %f7, %f24;
	fma.rn.f32 	%f26, %f20, 0f3A2C32E4, 0f3B52E7DB;
	fma.rn.f32 	%f27, %f26, %f20, 0f3C93BB73;
	fma.rn.f32 	%f28, %f27, %f20, 0f3DF6384F;
	mul.rn.f32 	%f29, %f28, %f20;
	fma.rn.f32 	%f30, %f19, 0f3FB8AA3B, %f16;
	sub.rn.f32 	%f31, %f16, %f30;
	fma.rn.f32 	%f32, %f19, 0f3FB8AA3B, %f31;
	fma.rn.f32 	%f33, %f25, 0f3FB8AA3B, %f32;
	fma.rn.f32 	%f34, %f19, 0f32A55E34, %f33;
	mul.rn.f32 	%f35, %f29, 0f40400000;
	fma.rn.f32 	%f36, %f35, %f25, %f34;
	fma.rn.f32 	%f37, %f29, %f19, %f36;
	add.rn.f32 	%f38, %f30, %f37;
	neg.f32 	%f39, %f30;
	add.rn.f32 	%f40, %f38, %f39;
	neg.f32 	%f41, %f40;
	add.rn.f32 	%f42, %f37, %f41;
	mul.rn.f32 	%f43, %f38, %f1;
	neg.f32 	%f44, %f43;
	fma.rn.f32 	%f45, %f38, %f1, %f44;
	fma.rn.f32 	%f46, %f42, %f1, %f45;
	cvt.rni.f32.f32 	%f47, %f43;
	sub.rn.f32 	%f48, %f43, %f47;
	add.rn.f32 	%f49, %f48, %f46;
	fma.rn.f32 	%f50, %f49, 0f391FCB8E, 0f3AAF85ED;
	fma.rn.f32 	%f51, %f50, %f49, 0f3C1D9856;
	fma.rn.f32 	%f52, %f51, %f49, 0f3D6357BB;
	fma.rn.f32 	%f53, %f52, %f49, 0f3E75FDEC;
	fma.rn.f32 	%f54, %f53, %f49, 0f3F317218;
	fma.rn.f32 	%f55, %f54, %f49, 0f3F800000;
	cvt.rzi.s32.f32 	%r6, %f47;
	setp.gt.f32 	%p2, %f47, 0f00000000;
	selp.b32 	%r7, 0, -2097152000, %p2;
	add.s32 	%r8, %r7, 2130706432;
	mov.b32 	%f56, %r8;
	mul.rn.f32 	%f57, %f55, %f56;
	shl.b32 	%r9, %r6, 23;
	sub.s32 	%r10, %r9, %r7;
	mov.b32 	%f58, %r10;
	mul.rn.f32 	%f59, %f57, %f58;
	abs.f32 	%f60, %f43;
	setp.gt.f32 	%p3, %f60, 0f43180000;
	setp.lt.f32 	%p4, %f43, 0f00000000;
	selp.f32 	%f61, 0f00000000, 0f7F800000, %p4;
	selp.f32 	%f3, %f61, %f59, %p3;
	setp.eq.f32 	%p9, %f2, 0f7F800000;
	setp.lt.f32 	%p10, %f1, 0f00000000;
	selp.f32 	%f63, 0f3F000000, 0f40800000, %p10;
	selp.f32 	%f65, %f63, %f3, %p9;
$L__BB1_4:
	shl.b64 	%rd8, %rd2, 2;
	add.s64 	%rd9, %rd1, %rd8;
	st.global.f32 	[%rd9], %f65;
	ret;

}
	// .globl	loop_divide_fusion_6
.visible .entry loop_divide_fusion_6(
	.param .u64 loop_divide_fusion_6_param_0,
	.param .u64 loop_divide_fusion_6_param_1,
	.param .u64 loop_divide_fusion_6_param_2
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<6>;
	.reg .b64 	%rd<16>;

	ld.param.u64 	%rd1, [loop_divide_fusion_6_param_0];
	ld.param.u64 	%rd2, [loop_divide_fusion_6_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_divide_fusion_6_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	mul.lo.s16 	%rs11, %rs3, 6;
	add.s16 	%rs12, %rs11, %rs10;
	cvt.u32.u16 	%r5, %rs12;
	mul.wide.u32 	%rd7, %r5, 24;
	add.s64 	%rd8, %rd5, %rd7;
	cvt.u32.u16 	%r6, %rs8;
	mul.wide.u32 	%rd9, %r6, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd5, %rd11;
	ld.global.nc.f32 	%f2, [%rd12];
	sub.rn.f32 	%f3, %f1, %f2;
	cvt.u32.u16 	%r7, %rs3;
	mul.wide.u32 	%rd13, %r7, 4;
	add.s64 	%rd14, %rd6, %rd13;
	ld.global.nc.f32 	%f4, [%rd14];
	div.full.f32 	%f5, %f3, %f4;
	add.s64 	%rd15, %rd3, %rd11;
	st.global.f32 	[%rd15], %f5;
	ret;

}
	// .globl	wrapped_concatenate_18
.visible .entry wrapped_concatenate_18(
	.param .u64 wrapped_concatenate_18_param_0,
	.param .u64 wrapped_concatenate_18_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd1, [wrapped_concatenate_18_param_0];
	ld.param.u64 	%rd2, [wrapped_concatenate_18_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	mul.wide.u32 	%rd5, %r4, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.f32 	%f1, [%rd6];
	cvt.u32.u16 	%r5, %rs8;
	mul.wide.u32 	%rd7, %r5, 24;
	cvt.u32.u16 	%r6, %rs10;
	mul.wide.u32 	%rd8, %r6, 432;
	add.s64 	%rd9, %rd3, %rd8;
	add.s64 	%rd10, %rd9, %rd7;
	cvt.u32.u16 	%r7, %rs5;
	mul.wide.u32 	%rd11, %r7, 4;
	add.s64 	%rd12, %rd10, %rd11;
	st.global.f32 	[%rd12], %f1;
	st.global.f32 	[%rd12+144], %f1;
	st.global.f32 	[%rd12+288], %f1;
	ret;

}
	// .globl	wrapped_slice_12
.visible .entry wrapped_slice_12(
	.param .u64 wrapped_slice_12_param_0,
	.param .u64 wrapped_slice_12_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd1, [wrapped_slice_12_param_0];
	ld.param.u64 	%rd2, [wrapped_slice_12_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r5, %rs8;
	mul.wide.u32 	%rd5, %r5, 72;
	cvt.u32.u16 	%r6, %rs3;
	mul.wide.u32 	%rd6, %r6, 432;
	add.s64 	%rd7, %rd4, %rd6;
	add.s64 	%rd8, %rd7, %rd5;
	cvt.u32.u16 	%r7, %rs10;
	mul.wide.u32 	%rd9, %r7, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10+48];
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd3, %rd11;
	st.global.f32 	[%rd12], %f1;
	ret;

}
	// .globl	wrapped_dot_96
.visible .entry wrapped_dot_96(
	.param .u64 wrapped_dot_96_param_0,
	.param .u64 wrapped_dot_96_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<25>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd1, [wrapped_dot_96_param_0];
	ld.param.u64 	%rd2, [wrapped_dot_96_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs8;
	mul.wide.u32 	%rd5, %r5, 24;
	cvt.u32.u16 	%r6, %rs10;
	mul.wide.u32 	%rd6, %r6, 144;
	add.s64 	%rd7, %rd4, %rd6;
	add.s64 	%rd8, %rd7, %rd5;
	ld.global.nc.v2.f32 	{%f1, %f2}, [%rd8];
	cvt.u32.u16 	%r7, %rs5;
	mul.wide.u32 	%rd9, %r7, 4;
	add.s64 	%rd10, %rd7, %rd9;
	ld.global.nc.f32 	%f3, [%rd10];
	mul.rn.f32 	%f4, %f1, %f3;
	add.rn.f32 	%f5, %f4, 0f00000000;
	ld.global.nc.f32 	%f6, [%rd10+24];
	mul.rn.f32 	%f7, %f2, %f6;
	add.rn.f32 	%f8, %f5, %f7;
	ld.global.nc.v2.f32 	{%f9, %f10}, [%rd8+8];
	ld.global.nc.f32 	%f11, [%rd10+48];
	mul.rn.f32 	%f12, %f9, %f11;
	add.rn.f32 	%f13, %f8, %f12;
	ld.global.nc.f32 	%f14, [%rd10+72];
	mul.rn.f32 	%f15, %f10, %f14;
	add.rn.f32 	%f16, %f13, %f15;
	ld.global.nc.v2.f32 	{%f17, %f18}, [%rd8+16];
	ld.global.nc.f32 	%f19, [%rd10+96];
	mul.rn.f32 	%f20, %f17, %f19;
	add.rn.f32 	%f21, %f16, %f20;
	ld.global.nc.f32 	%f22, [%rd10+120];
	mul.rn.f32 	%f23, %f18, %f22;
	add.rn.f32 	%f24, %f21, %f23;
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd3, %rd11;
	st.global.f32 	[%rd12], %f24;
	ret;

}
	// .globl	wrapped_dot_97
.visible .entry wrapped_dot_97(
	.param .u64 wrapped_dot_97_param_0,
	.param .u64 wrapped_dot_97_param_1,
	.param .u64 wrapped_dot_97_param_2
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<25>;
	.reg .b64 	%rd<16>;

	ld.param.u64 	%rd1, [wrapped_dot_97_param_0];
	ld.param.u64 	%rd2, [wrapped_dot_97_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [wrapped_dot_97_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs8;
	mul.wide.u32 	%rd7, %r5, 24;
	cvt.u32.u16 	%r6, %rs10;
	mul.wide.u32 	%rd8, %r6, 144;
	add.s64 	%rd9, %rd6, %rd8;
	add.s64 	%rd10, %rd9, %rd7;
	ld.global.nc.v2.f32 	{%f1, %f2}, [%rd10];
	cvt.u32.u16 	%r7, %rs5;
	mul.wide.u32 	%rd11, %r7, 4;
	add.s64 	%rd12, %rd5, %rd8;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.nc.f32 	%f3, [%rd13];
	mul.rn.f32 	%f4, %f1, %f3;
	add.rn.f32 	%f5, %f4, 0f00000000;
	ld.global.nc.f32 	%f6, [%rd13+24];
	mul.rn.f32 	%f7, %f2, %f6;
	add.rn.f32 	%f8, %f5, %f7;
	ld.global.nc.v2.f32 	{%f9, %f10}, [%rd10+8];
	ld.global.nc.f32 	%f11, [%rd13+48];
	mul.rn.f32 	%f12, %f9, %f11;
	add.rn.f32 	%f13, %f8, %f12;
	ld.global.nc.f32 	%f14, [%rd13+72];
	mul.rn.f32 	%f15, %f10, %f14;
	add.rn.f32 	%f16, %f13, %f15;
	ld.global.nc.v2.f32 	{%f17, %f18}, [%rd10+16];
	ld.global.nc.f32 	%f19, [%rd13+96];
	mul.rn.f32 	%f20, %f17, %f19;
	add.rn.f32 	%f21, %f16, %f20;
	ld.global.nc.f32 	%f22, [%rd13+120];
	mul.rn.f32 	%f23, %f18, %f22;
	add.rn.f32 	%f24, %f21, %f23;
	mul.wide.u32 	%rd14, %r4, 4;
	add.s64 	%rd15, %rd3, %rd14;
	st.global.f32 	[%rd15], %f24;
	ret;

}
	// .globl	loop_add_fusion_276
.visible .entry loop_add_fusion_276(
	.param .u64 loop_add_fusion_276_param_0,
	.param .u64 loop_add_fusion_276_param_1,
	.param .u64 loop_add_fusion_276_param_2,
	.param .u64 loop_add_fusion_276_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<10>;
	.reg .b64 	%rd<23>;

	ld.param.u64 	%rd1, [loop_add_fusion_276_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_276_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_276_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_276_param_2];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd9, %r5, 24;
	cvt.u32.u16 	%r6, %rs3;
	mul.wide.u32 	%rd10, %r6, 144;
	add.s64 	%rd11, %rd7, %rd10;
	add.s64 	%rd12, %rd11, %rd9;
	cvt.u32.u16 	%r7, %rs8;
	mul.wide.u32 	%rd13, %r7, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	add.s64 	%rd15, %rd6, %rd10;
	add.s64 	%rd16, %rd15, %rd9;
	add.s64 	%rd17, %rd16, %rd13;
	ld.global.nc.f32 	%f2, [%rd17];
	mul.rn.f32 	%f3, %f2, 0f44BD0000;
	add.rn.f32 	%f4, %f1, %f3;
	add.s64 	%rd18, %rd8, %rd10;
	add.s64 	%rd19, %rd18, %rd9;
	add.s64 	%rd20, %rd19, %rd13;
	ld.global.nc.f32 	%f5, [%rd20];
	mul.rn.f32 	%f6, %f5, 0f48875A00;
	add.rn.f32 	%f7, %f4, %f6;
	setp.eq.s16 	%p1, %rs10, %rs8;
	selp.f32 	%f8, 0f4B03F7C0, 0f00000000, %p1;
	add.rn.f32 	%f9, %f8, %f7;
	mul.wide.u32 	%rd21, %r4, 4;
	add.s64 	%rd22, %rd3, %rd21;
	st.global.f32 	[%rd22], %f9;
	ret;

}
	// .globl	wrapped_slice_13
.visible .entry wrapped_slice_13(
	.param .u64 wrapped_slice_13_param_0,
	.param .u64 wrapped_slice_13_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd1, [wrapped_slice_13_param_0];
	ld.param.u64 	%rd2, [wrapped_slice_13_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r5, %rs8;
	mul.wide.u32 	%rd5, %r5, 72;
	cvt.u32.u16 	%r6, %rs3;
	mul.wide.u32 	%rd6, %r6, 432;
	add.s64 	%rd7, %rd4, %rd6;
	add.s64 	%rd8, %rd7, %rd5;
	cvt.u32.u16 	%r7, %rs10;
	mul.wide.u32 	%rd9, %r7, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10+24];
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd3, %rd11;
	st.global.f32 	[%rd12], %f1;
	ret;

}
	// .globl	loop_add_fusion_277
.visible .entry loop_add_fusion_277(
	.param .u64 loop_add_fusion_277_param_0,
	.param .u64 loop_add_fusion_277_param_1,
	.param .u64 loop_add_fusion_277_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<7>;
	.reg .b64 	%rd<18>;

	ld.param.u64 	%rd1, [loop_add_fusion_277_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_277_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_277_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd7, %r5, 24;
	cvt.u32.u16 	%r6, %rs3;
	mul.wide.u32 	%rd8, %r6, 144;
	add.s64 	%rd9, %rd6, %rd8;
	add.s64 	%rd10, %rd9, %rd7;
	cvt.u32.u16 	%r7, %rs8;
	mul.wide.u32 	%rd11, %r7, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	add.s64 	%rd13, %rd5, %rd8;
	add.s64 	%rd14, %rd13, %rd7;
	add.s64 	%rd15, %rd14, %rd11;
	ld.global.nc.f32 	%f2, [%rd15];
	mul.rn.f32 	%f3, %f2, 0f43D20000;
	add.rn.f32 	%f4, %f1, %f3;
	setp.eq.s16 	%p1, %rs10, %rs8;
	selp.f32 	%f5, 0f466C4000, 0f00000000, %p1;
	add.rn.f32 	%f6, %f5, %f4;
	mul.wide.u32 	%rd16, %r4, 4;
	add.s64 	%rd17, %rd3, %rd16;
	st.global.f32 	[%rd17], %f6;
	ret;

}
	// .globl	loop_add_fusion_278
.visible .entry loop_add_fusion_278(
	.param .u64 loop_add_fusion_278_param_0,
	.param .u64 loop_add_fusion_278_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd1, [loop_add_fusion_278_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_278_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd5, %r5, 72;
	cvt.u32.u16 	%r6, %rs3;
	mul.wide.u32 	%rd6, %r6, 432;
	add.s64 	%rd7, %rd4, %rd6;
	add.s64 	%rd8, %rd7, %rd5;
	cvt.u32.u16 	%r7, %rs8;
	mul.wide.u32 	%rd9, %r7, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	setp.eq.s16 	%p1, %rs10, %rs8;
	selp.f32 	%f2, 0f42700000, 0f00000000, %p1;
	add.rn.f32 	%f3, %f2, %f1;
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd3, %rd11;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	wrapped_concatenate_19
.visible .entry wrapped_concatenate_19(
	.param .u64 wrapped_concatenate_19_param_0,
	.param .u64 wrapped_concatenate_19_param_1,
	.param .u64 wrapped_concatenate_19_param_2,
	.param .u64 wrapped_concatenate_19_param_3
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<19>;

	ld.param.u64 	%rd1, [wrapped_concatenate_19_param_0];
	ld.param.u64 	%rd2, [wrapped_concatenate_19_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [wrapped_concatenate_19_param_1];
	ld.param.u64 	%rd5, [wrapped_concatenate_19_param_2];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	mul.wide.u32 	%rd9, %r4, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	cvt.u32.u16 	%r5, %rs8;
	mul.wide.u32 	%rd11, %r5, 24;
	cvt.u32.u16 	%r6, %rs10;
	mul.wide.u32 	%rd12, %r6, 432;
	add.s64 	%rd13, %rd3, %rd12;
	add.s64 	%rd14, %rd13, %rd11;
	cvt.u32.u16 	%r7, %rs5;
	mul.wide.u32 	%rd15, %r7, 4;
	add.s64 	%rd16, %rd14, %rd15;
	st.global.f32 	[%rd16], %f1;
	add.s64 	%rd17, %rd7, %rd9;
	ld.global.nc.f32 	%f2, [%rd17];
	st.global.f32 	[%rd16+144], %f2;
	add.s64 	%rd18, %rd6, %rd9;
	ld.global.nc.f32 	%f3, [%rd18];
	st.global.f32 	[%rd16+288], %f3;
	ret;

}
	// .globl	loop_maximum_select_fusion_9
.visible .entry loop_maximum_select_fusion_9(
	.param .u64 loop_maximum_select_fusion_9_param_0,
	.param .u64 loop_maximum_select_fusion_9_param_1,
	.param .u64 loop_maximum_select_fusion_9_param_2
)
.reqntid 64, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<7>;
	.reg .f32 	%f<171>;
	.reg .b64 	%rd<12>;

	ld.param.u64 	%rd1, [loop_maximum_select_fusion_9_param_0];
	ld.param.u64 	%rd2, [loop_maximum_select_fusion_9_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_maximum_select_fusion_9_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %tid.x;
	mul.lo.s32 	%r2, %r1, 6;
	mul.wide.u32 	%rd7, %r2, 24;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd8];
	sub.rn.f32 	%f5, %f1, %f1;
	abs.f32 	%f6, %f5;
	ld.global.nc.v4.f32 	{%f7, %f8, %f9, %f10}, [%rd8+16];
	sub.rn.f32 	%f11, %f9, %f2;
	abs.f32 	%f12, %f11;
	add.rn.f32 	%f13, %f6, %f12;
	ld.global.nc.v4.f32 	{%f14, %f15, %f16, %f17}, [%rd8+48];
	sub.rn.f32 	%f18, %f14, %f3;
	abs.f32 	%f19, %f18;
	add.rn.f32 	%f20, %f13, %f19;
	ld.global.nc.v4.f32 	{%f21, %f22, %f23, %f24}, [%rd8+64];
	sub.rn.f32 	%f25, %f23, %f4;
	abs.f32 	%f26, %f25;
	add.rn.f32 	%f27, %f20, %f26;
	ld.global.nc.v4.f32 	{%f28, %f29, %f30, %f31}, [%rd8+96];
	sub.rn.f32 	%f32, %f28, %f7;
	abs.f32 	%f33, %f32;
	add.rn.f32 	%f34, %f27, %f33;
	ld.global.nc.v4.f32 	{%f35, %f36, %f37, %f38}, [%rd8+112];
	sub.rn.f32 	%f39, %f37, %f8;
	abs.f32 	%f40, %f39;
	add.rn.f32 	%f41, %f34, %f40;
	sub.rn.f32 	%f42, %f2, %f9;
	abs.f32 	%f43, %f42;
	sub.rn.f32 	%f44, %f10, %f10;
	abs.f32 	%f45, %f44;
	add.rn.f32 	%f46, %f43, %f45;
	ld.global.nc.v4.f32 	{%f47, %f48, %f49, %f50}, [%rd8+32];
	sub.rn.f32 	%f51, %f15, %f47;
	abs.f32 	%f52, %f51;
	add.rn.f32 	%f53, %f46, %f52;
	sub.rn.f32 	%f54, %f24, %f48;
	abs.f32 	%f55, %f54;
	add.rn.f32 	%f56, %f53, %f55;
	sub.rn.f32 	%f57, %f29, %f49;
	abs.f32 	%f58, %f57;
	add.rn.f32 	%f59, %f56, %f58;
	sub.rn.f32 	%f60, %f38, %f50;
	abs.f32 	%f61, %f60;
	add.rn.f32 	%f62, %f59, %f61;
	max.NaN.f32 	%f63, %f41, %f62;
	sub.rn.f32 	%f64, %f3, %f14;
	abs.f32 	%f65, %f64;
	sub.rn.f32 	%f66, %f47, %f15;
	abs.f32 	%f67, %f66;
	add.rn.f32 	%f68, %f65, %f67;
	sub.rn.f32 	%f69, %f16, %f16;
	abs.f32 	%f70, %f69;
	add.rn.f32 	%f71, %f68, %f70;
	ld.global.nc.v4.f32 	{%f72, %f73, %f74, %f75}, [%rd8+80];
	sub.rn.f32 	%f76, %f72, %f17;
	abs.f32 	%f77, %f76;
	add.rn.f32 	%f78, %f71, %f77;
	sub.rn.f32 	%f79, %f30, %f21;
	abs.f32 	%f80, %f79;
	add.rn.f32 	%f81, %f78, %f80;
	ld.global.nc.v4.f32 	{%f82, %f83, %f84, %f85}, [%rd8+128];
	sub.rn.f32 	%f86, %f82, %f22;
	abs.f32 	%f87, %f86;
	add.rn.f32 	%f88, %f81, %f87;
	max.NaN.f32 	%f89, %f63, %f88;
	sub.rn.f32 	%f90, %f4, %f23;
	abs.f32 	%f91, %f90;
	sub.rn.f32 	%f92, %f48, %f24;
	abs.f32 	%f93, %f92;
	add.rn.f32 	%f94, %f91, %f93;
	sub.rn.f32 	%f95, %f17, %f72;
	abs.f32 	%f96, %f95;
	add.rn.f32 	%f97, %f94, %f96;
	sub.rn.f32 	%f98, %f73, %f73;
	abs.f32 	%f99, %f98;
	add.rn.f32 	%f100, %f97, %f99;
	sub.rn.f32 	%f101, %f31, %f74;
	abs.f32 	%f102, %f101;
	add.rn.f32 	%f103, %f100, %f102;
	sub.rn.f32 	%f104, %f83, %f75;
	abs.f32 	%f105, %f104;
	add.rn.f32 	%f106, %f103, %f105;
	max.NaN.f32 	%f107, %f89, %f106;
	sub.rn.f32 	%f108, %f7, %f28;
	abs.f32 	%f109, %f108;
	sub.rn.f32 	%f110, %f49, %f29;
	abs.f32 	%f111, %f110;
	add.rn.f32 	%f112, %f109, %f111;
	sub.rn.f32 	%f113, %f21, %f30;
	abs.f32 	%f114, %f113;
	add.rn.f32 	%f115, %f112, %f114;
	sub.rn.f32 	%f116, %f74, %f31;
	abs.f32 	%f117, %f116;
	add.rn.f32 	%f118, %f115, %f117;
	sub.rn.f32 	%f119, %f35, %f35;
	abs.f32 	%f120, %f119;
	add.rn.f32 	%f121, %f118, %f120;
	sub.rn.f32 	%f122, %f84, %f36;
	abs.f32 	%f123, %f122;
	add.rn.f32 	%f124, %f121, %f123;
	max.NaN.f32 	%f125, %f107, %f124;
	sub.rn.f32 	%f126, %f8, %f37;
	abs.f32 	%f127, %f126;
	sub.rn.f32 	%f128, %f50, %f38;
	abs.f32 	%f129, %f128;
	add.rn.f32 	%f130, %f127, %f129;
	sub.rn.f32 	%f131, %f22, %f82;
	abs.f32 	%f132, %f131;
	add.rn.f32 	%f133, %f130, %f132;
	sub.rn.f32 	%f134, %f75, %f83;
	abs.f32 	%f135, %f134;
	add.rn.f32 	%f136, %f133, %f135;
	sub.rn.f32 	%f137, %f36, %f84;
	abs.f32 	%f138, %f137;
	add.rn.f32 	%f139, %f136, %f138;
	sub.rn.f32 	%f140, %f85, %f85;
	abs.f32 	%f141, %f140;
	add.rn.f32 	%f142, %f139, %f141;
	max.NaN.f32 	%f143, %f125, %f142;
	mul.rn.f32 	%f144, %f143, 0f3E826BFA;
	setp.lt.f32 	%p1, %f144, 0f00800000;
	mul.rn.f32 	%f145, %f144, 0f4B000000;
	selp.f32 	%f146, %f145, %f144, %p1;
	selp.f32 	%f147, 0fC1B80000, 0f00000000, %p1;
	mov.b32 	%r3, %f146;
	add.s32 	%r4, %r3, -1059760811;
	and.b32  	%r5, %r4, -8388608;
	sub.s32 	%r6, %r3, %r5;
	mov.b32 	%f148, %r6;
	cvt.rn.f32.s32 	%f149, %r5;
	fma.rn.f32 	%f150, %f149, 0f34000000, %f147;
	add.rn.f32 	%f151, %f148, 0fBF800000;
	fma.rn.f32 	%f152, %f151, 0fBE055027, 0f3E1039F6;
	fma.rn.f32 	%f153, %f152, %f151, 0fBDF8CDCC;
	fma.rn.f32 	%f154, %f153, %f151, 0f3E0F2955;
	fma.rn.f32 	%f155, %f154, %f151, 0fBE2AD8B9;
	fma.rn.f32 	%f156, %f155, %f151, 0f3E4CED0B;
	fma.rn.f32 	%f157, %f156, %f151, 0fBE7FFF22;
	fma.rn.f32 	%f158, %f157, %f151, 0f3EAAAA78;
	fma.rn.f32 	%f159, %f158, %f151, 0fBF000000;
	mul.rn.f32 	%f160, %f151, %f159;
	fma.rn.f32 	%f161, %f160, %f151, %f151;
	fma.rn.f32 	%f162, %f150, 0f3F317218, %f161;
	setp.gt.u32 	%p2, %r3, 2139095039;
	fma.rn.f32 	%f163, %f146, 0f7F800000, 0f7F800000;
	selp.f32 	%f164, %f163, %f162, %p2;
	setp.eq.f32 	%p3, %f146, 0f00000000;
	mul.rn.f32 	%f165, %f164, 0f3FB8AA3B;
	selp.f32 	%f166, 0fFF800000, %f165, %p3;
	cvt.rmi.f32.f32 	%f167, %f166;
	max.NaN.f32 	%f168, %f167, 0f00000000;
	setp.nan.f32 	%p4, %f143, %f143;
	setp.eq.f32 	%p5, %f143, 0f00000000;
	selp.f32 	%f169, 0f00000000, %f143, %p5;
	selp.f32 	%f170, 0f7FC00000, %f169, %p4;
	mul.wide.u32 	%rd9, %r1, 4;
	add.s64 	%rd10, %rd5, %rd9;
	st.global.f32 	[%rd10], %f168;
	add.s64 	%rd11, %rd3, %rd9;
	st.global.f32 	[%rd11], %f170;
	ret;

}
	// .globl	loop_divide_fusion_9
.visible .entry loop_divide_fusion_9(
	.param .u64 loop_divide_fusion_9_param_0,
	.param .u64 loop_divide_fusion_9_param_1,
	.param .u64 loop_divide_fusion_9_param_2
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<6>;
	.reg .b64 	%rd<16>;

	ld.param.u64 	%rd1, [loop_divide_fusion_9_param_0];
	ld.param.u64 	%rd2, [loop_divide_fusion_9_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_divide_fusion_9_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	mul.lo.s16 	%rs11, %rs3, 6;
	mul.wide.u32 	%rd7, %r4, 4;
	add.s64 	%rd8, %rd5, %rd7;
	ld.global.nc.f32 	%f1, [%rd8];
	add.s16 	%rs12, %rs11, %rs10;
	cvt.u32.u16 	%r5, %rs12;
	mul.wide.u32 	%rd9, %r5, 24;
	add.s64 	%rd10, %rd5, %rd9;
	cvt.u32.u16 	%r6, %rs8;
	mul.wide.u32 	%rd11, %r6, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f2, [%rd12];
	sub.rn.f32 	%f3, %f1, %f2;
	cvt.u32.u16 	%r7, %rs3;
	mul.wide.u32 	%rd13, %r7, 4;
	add.s64 	%rd14, %rd6, %rd13;
	ld.global.nc.f32 	%f4, [%rd14];
	div.full.f32 	%f5, %f3, %f4;
	add.s64 	%rd15, %rd3, %rd7;
	st.global.f32 	[%rd15], %f5;
	ret;

}
	// .globl	wrapped_concatenate_24
.visible .entry wrapped_concatenate_24(
	.param .u64 wrapped_concatenate_24_param_0,
	.param .u64 wrapped_concatenate_24_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd1, [wrapped_concatenate_24_param_0];
	ld.param.u64 	%rd2, [wrapped_concatenate_24_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	mul.wide.u32 	%rd5, %r4, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.f32 	%f1, [%rd6];
	cvt.u32.u16 	%r5, %rs8;
	mul.wide.u32 	%rd7, %r5, 72;
	cvt.u32.u16 	%r6, %rs10;
	mul.wide.u32 	%rd8, %r6, 432;
	add.s64 	%rd9, %rd3, %rd8;
	add.s64 	%rd10, %rd9, %rd7;
	cvt.u32.u16 	%r7, %rs5;
	mul.wide.u32 	%rd11, %r7, 4;
	add.s64 	%rd12, %rd10, %rd11;
	st.global.f32 	[%rd12], %f1;
	st.global.f32 	[%rd12+24], %f1;
	st.global.f32 	[%rd12+48], %f1;
	ret;

}
	// .globl	loop_divide_fusion_10
.visible .entry loop_divide_fusion_10(
	.param .u64 loop_divide_fusion_10_param_0,
	.param .u64 loop_divide_fusion_10_param_1,
	.param .u64 loop_divide_fusion_10_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<11>;
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<70>;
	.reg .b64 	%rd<18>;

	ld.param.u64 	%rd3, [loop_divide_fusion_10_param_0];
	ld.param.u64 	%rd4, [loop_divide_fusion_10_param_2];
	cvta.to.global.u64 	%rd1, %rd4;
	ld.param.u64 	%rd5, [loop_divide_fusion_10_param_1];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd3;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	mul.lo.s16 	%rs11, %rs3, 6;
	add.s16 	%rs12, %rs11, %rs10;
	cvt.u32.u16 	%r5, %rs12;
	mul.wide.u32 	%rd8, %r5, 24;
	add.s64 	%rd9, %rd7, %rd8;
	cvt.u32.u16 	%r6, %rs8;
	mul.wide.u32 	%rd10, %r6, 4;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.nc.f32 	%f1, [%rd11];
	cvt.u64.u32 	%rd2, %r4;
	mul.wide.u32 	%rd12, %r4, 4;
	add.s64 	%rd13, %rd7, %rd12;
	ld.global.nc.f32 	%f2, [%rd13];
	cvt.u32.u16 	%r7, %rs3;
	mul.wide.u32 	%rd14, %r7, 4;
	add.s64 	%rd15, %rd6, %rd14;
	ld.global.nc.f32 	%f3, [%rd15];
	setp.eq.f32 	%p5, %f3, 0f00000000;
	mov.f32 	%f69, 0f3F800000;
	@%p5 bra 	$L__BB15_4;
	mov.f32 	%f12, 0f40000000;
	abs.f32 	%f4, %f12;
	setp.nan.f32 	%p6, %f4, %f4;
	abs.f32 	%f64, %f3;
	setp.nan.f32 	%p7, %f64, %f64;
	or.pred  	%p8, %p6, %p7;
	@!%p8 bra 	$L__BB15_3;
	bra.uni 	$L__BB15_2;
$L__BB15_2:
	add.rn.f32 	%f69, %f12, %f3;
	bra.uni 	$L__BB15_4;
$L__BB15_3:
	setp.lt.f32 	%p1, %f4, 0f00800000;
	mul.rn.f32 	%f13, %f4, 0f4B800000;
	selp.f32 	%f14, %f13, %f4, %p1;
	selp.f32 	%f15, 0fC1C00000, 0f00000000, %p1;
	mov.b32 	%r8, %f14;
	add.s32 	%r9, %r8, -1060439283;
	and.b32  	%r10, %r9, -8388608;
	sub.s32 	%r11, %r8, %r10;
	mov.b32 	%f16, %r11;
	cvt.rn.f32.s32 	%f17, %r10;
	fma.rn.f32 	%f18, %f17, 0f34000000, %f15;
	add.rn.f32 	%f19, %f16, 0fBF800000;
	add.rn.f32 	%f10, %f16, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f9,%f10;
	// end inline asm
	add.rn.f32 	%f20, %f19, %f19;
	mul.rn.f32 	%f21, %f20, %f9;
	mul.rn.f32 	%f22, %f21, %f21;
	sub.rn.f32 	%f23, %f19, %f21;
	add.rn.f32 	%f24, %f23, %f23;
	neg.f32 	%f25, %f21;
	fma.rn.f32 	%f26, %f25, %f19, %f24;
	mul.rn.f32 	%f27, %f9, %f26;
	fma.rn.f32 	%f28, %f22, 0f3A2C32E4, 0f3B52E7DB;
	fma.rn.f32 	%f29, %f28, %f22, 0f3C93BB73;
	fma.rn.f32 	%f30, %f29, %f22, 0f3DF6384F;
	mul.rn.f32 	%f31, %f30, %f22;
	fma.rn.f32 	%f32, %f21, 0f3FB8AA3B, %f18;
	sub.rn.f32 	%f33, %f18, %f32;
	fma.rn.f32 	%f34, %f21, 0f3FB8AA3B, %f33;
	fma.rn.f32 	%f35, %f27, 0f3FB8AA3B, %f34;
	fma.rn.f32 	%f36, %f21, 0f32A55E34, %f35;
	mul.rn.f32 	%f37, %f31, 0f40400000;
	fma.rn.f32 	%f38, %f37, %f27, %f36;
	fma.rn.f32 	%f39, %f31, %f21, %f38;
	add.rn.f32 	%f40, %f32, %f39;
	neg.f32 	%f41, %f32;
	add.rn.f32 	%f42, %f40, %f41;
	neg.f32 	%f43, %f42;
	add.rn.f32 	%f44, %f39, %f43;
	mul.rn.f32 	%f45, %f40, %f3;
	neg.f32 	%f46, %f45;
	fma.rn.f32 	%f47, %f40, %f3, %f46;
	fma.rn.f32 	%f48, %f44, %f3, %f47;
	cvt.rni.f32.f32 	%f49, %f45;
	sub.rn.f32 	%f50, %f45, %f49;
	add.rn.f32 	%f51, %f50, %f48;
	fma.rn.f32 	%f52, %f51, 0f391FCB8E, 0f3AAF85ED;
	fma.rn.f32 	%f53, %f52, %f51, 0f3C1D9856;
	fma.rn.f32 	%f54, %f53, %f51, 0f3D6357BB;
	fma.rn.f32 	%f55, %f54, %f51, 0f3E75FDEC;
	fma.rn.f32 	%f56, %f55, %f51, 0f3F317218;
	fma.rn.f32 	%f57, %f56, %f51, 0f3F800000;
	cvt.rzi.s32.f32 	%r12, %f49;
	setp.gt.f32 	%p2, %f49, 0f00000000;
	selp.b32 	%r13, 0, -2097152000, %p2;
	add.s32 	%r14, %r13, 2130706432;
	mov.b32 	%f58, %r14;
	mul.rn.f32 	%f59, %f57, %f58;
	shl.b32 	%r15, %r12, 23;
	sub.s32 	%r16, %r15, %r13;
	mov.b32 	%f60, %r16;
	mul.rn.f32 	%f61, %f59, %f60;
	abs.f32 	%f62, %f45;
	setp.gt.f32 	%p3, %f62, 0f43180000;
	setp.lt.f32 	%p4, %f45, 0f00000000;
	selp.f32 	%f63, 0f00000000, 0f7F800000, %p4;
	selp.f32 	%f5, %f63, %f61, %p3;
	setp.eq.f32 	%p9, %f4, 0f7F800000;
	setp.lt.f32 	%p10, %f3, 0f00000000;
	selp.f32 	%f65, 0f3F000000, 0f40800000, %p10;
	selp.f32 	%f69, %f65, %f5, %p9;
$L__BB15_4:
	sub.rn.f32 	%f67, %f1, %f2;
	div.full.f32 	%f68, %f67, %f69;
	shl.b64 	%rd16, %rd2, 2;
	add.s64 	%rd17, %rd1, %rd16;
	st.global.f32 	[%rd17], %f68;
	ret;

}
	// .globl	loop_broadcast_fusion_23
.visible .entry loop_broadcast_fusion_23(
	.param .u64 loop_broadcast_fusion_23_param_0,
	.param .u64 loop_broadcast_fusion_23_param_1,
	.param .u64 loop_broadcast_fusion_23_param_2,
	.param .u64 loop_broadcast_fusion_23_param_3,
	.param .u64 loop_broadcast_fusion_23_param_4,
	.param .u64 loop_broadcast_fusion_23_param_5,
	.param .u64 loop_broadcast_fusion_23_param_6
)
.reqntid 64, 1, 1
{
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<23>;

	ld.param.u64 	%rd1, [loop_broadcast_fusion_23_param_0];
	ld.param.u64 	%rd2, [loop_broadcast_fusion_23_param_6];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_broadcast_fusion_23_param_1];
	ld.param.u64 	%rd5, [loop_broadcast_fusion_23_param_5];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_broadcast_fusion_23_param_2];
	ld.param.u64 	%rd8, [loop_broadcast_fusion_23_param_4];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_broadcast_fusion_23_param_3];
	cvta.to.global.u64 	%rd11, %rd10;
	cvta.to.global.u64 	%rd12, %rd7;
	cvta.to.global.u64 	%rd13, %rd4;
	cvta.to.global.u64 	%rd14, %rd1;
	mov.u32 	%r1, %tid.x;
	mul.wide.u32 	%rd15, %r1, 4;
	add.s64 	%rd16, %rd14, %rd15;
	mov.b32 	%r2, 0;
	st.global.u32 	[%rd16], %r2;
	add.s64 	%rd17, %rd13, %rd15;
	st.global.u32 	[%rd17], %r2;
	add.s64 	%rd18, %rd12, %rd15;
	st.global.u32 	[%rd18], %r2;
	add.s64 	%rd19, %rd11, %rd15;
	st.global.u32 	[%rd19], %r2;
	add.s64 	%rd20, %rd9, %rd15;
	st.global.u32 	[%rd20], %r2;
	add.s64 	%rd21, %rd6, %rd15;
	st.global.u32 	[%rd21], %r2;
	add.s64 	%rd22, %rd3, %rd15;
	st.global.u32 	[%rd22], %r2;
	ret;

}
	// .globl	loop_broadcast_fusion_24
.visible .entry loop_broadcast_fusion_24(
	.param .u64 loop_broadcast_fusion_24_param_0,
	.param .u64 loop_broadcast_fusion_24_param_1,
	.param .u64 loop_broadcast_fusion_24_param_2,
	.param .u64 loop_broadcast_fusion_24_param_3,
	.param .u64 loop_broadcast_fusion_24_param_4,
	.param .u64 loop_broadcast_fusion_24_param_5,
	.param .u64 loop_broadcast_fusion_24_param_6
)
.reqntid 64, 1, 1
{
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<23>;

	ld.param.u64 	%rd1, [loop_broadcast_fusion_24_param_0];
	ld.param.u64 	%rd2, [loop_broadcast_fusion_24_param_6];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_broadcast_fusion_24_param_1];
	ld.param.u64 	%rd5, [loop_broadcast_fusion_24_param_5];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_broadcast_fusion_24_param_2];
	ld.param.u64 	%rd8, [loop_broadcast_fusion_24_param_4];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_broadcast_fusion_24_param_3];
	cvta.to.global.u64 	%rd11, %rd10;
	cvta.to.global.u64 	%rd12, %rd7;
	cvta.to.global.u64 	%rd13, %rd4;
	cvta.to.global.u64 	%rd14, %rd1;
	mov.u32 	%r1, %tid.x;
	mul.wide.u32 	%rd15, %r1, 4;
	add.s64 	%rd16, %rd14, %rd15;
	mov.b32 	%r2, 2;
	st.global.u32 	[%rd16], %r2;
	add.s64 	%rd17, %rd13, %rd15;
	st.global.u32 	[%rd17], %r2;
	add.s64 	%rd18, %rd12, %rd15;
	st.global.u32 	[%rd18], %r2;
	add.s64 	%rd19, %rd11, %rd15;
	st.global.u32 	[%rd19], %r2;
	add.s64 	%rd20, %rd9, %rd15;
	st.global.u32 	[%rd20], %r2;
	add.s64 	%rd21, %rd6, %rd15;
	st.global.u32 	[%rd21], %r2;
	add.s64 	%rd22, %rd3, %rd15;
	st.global.u32 	[%rd22], %r2;
	ret;

}
	// .globl	loop_compare_fusion_13
.visible .entry loop_compare_fusion_13(
	.param .u64 loop_compare_fusion_13_param_0,
	.param .u64 loop_compare_fusion_13_param_1
)
.reqntid 1, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [loop_compare_fusion_13_param_0];
	ld.param.u64 	%rd2, [loop_compare_fusion_13_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	ld.global.nc.u32 	%r1, [%rd4];
	setp.lt.s32 	%p1, %r1, 2;
	selp.u16 	%rs1, 1, 0, %p1;
	st.global.u8 	[%rd3], %rs1;
	ret;

}
	// .globl	loop_add_fusion_19
.visible .entry loop_add_fusion_19(
	.param .u64 loop_add_fusion_19_param_0
)
.reqntid 1, 1, 1
{
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<3>;

	ld.param.u64 	%rd1, [loop_add_fusion_19_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	ld.global.u32 	%r1, [%rd2];
	add.s32 	%r2, %r1, 1;
	st.global.u32 	[%rd2], %r2;
	ret;

}
	// .globl	loop_select_fusion_13
.visible .entry loop_select_fusion_13(
	.param .u64 loop_select_fusion_13_param_0,
	.param .u64 loop_select_fusion_13_param_1,
	.param .u64 loop_select_fusion_13_param_2,
	.param .u64 loop_select_fusion_13_param_3,
	.param .u64 loop_select_fusion_13_param_4,
	.param .u64 loop_select_fusion_13_param_5
)
.reqntid 64, 1, 1
{
	.reg .pred 	%p<11>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<21>;

	ld.param.u64 	%rd1, [loop_select_fusion_13_param_0];
	ld.param.u64 	%rd2, [loop_select_fusion_13_param_5];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_select_fusion_13_param_1];
	ld.param.u64 	%rd5, [loop_select_fusion_13_param_4];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_select_fusion_13_param_2];
	ld.param.u64 	%rd8, [loop_select_fusion_13_param_3];
	cvta.to.global.u64 	%rd9, %rd8;
	cvta.to.global.u64 	%rd10, %rd7;
	cvta.to.global.u64 	%rd11, %rd4;
	cvta.to.global.u64 	%rd12, %rd1;
	mov.u32 	%r1, %tid.x;
	mul.wide.u32 	%rd13, %r1, 4;
	add.s64 	%rd14, %rd10, %rd13;
	ld.global.nc.u32 	%r2, [%rd14];
	setp.lt.s32 	%p1, %r2, 0;
	xor.b32  	%r3, %r2, 2147483647;
	selp.b32 	%r4, %r3, %r2, %p1;
	add.s64 	%rd15, %rd12, %rd13;
	ld.global.nc.u32 	%r5, [%rd15];
	add.s64 	%rd16, %rd9, %rd13;
	ld.global.nc.u32 	%r6, [%rd16];
	add.s32 	%r7, %r6, %r5;
	setp.lt.s32 	%p2, %r7, 1;
	setp.lt.s32 	%p3, %r7, 0;
	abs.s32 	%r8, %r7;
	and.b32  	%r9, %r8, 1;
	setp.eq.b32 	%p4, %r9, 1;
	shr.u32 	%r10, %r8, 1;
	neg.s32 	%r11, %r10;
	selp.b32 	%r12, %r11, %r10, %p3;
	and.pred  	%p5, %p2, %p4;
	selp.s32 	%r13, -1, 0, %p5;
	add.s32 	%r14, %r12, %r13;
	shr.u32 	%r15, %r14, 30;
	and.b32  	%r16, %r15, 2;
	add.s32 	%r17, %r16, %r14;
	setp.gt.s32 	%p6, %r17, 0;
	selp.u32 	%r18, 1, 0, %p6;
	mul.wide.u32 	%rd17, %r18, 4;
	add.s64 	%rd18, %rd11, %rd17;
	ld.global.nc.f32 	%f1, [%rd18];
	setp.nan.f32 	%p7, %f1, %f1;
	setp.eq.f32 	%p8, %f1, 0f00000000;
	selp.f32 	%f2, 0f00000000, %f1, %p8;
	selp.f32 	%f3, 0f7FC00000, %f2, %p7;
	mov.b32 	%r19, %f3;
	setp.lt.s32 	%p9, %r19, 0;
	xor.b32  	%r20, %r19, 2147483647;
	selp.b32 	%r21, %r20, %r19, %p9;
	setp.lt.s32 	%p10, %r4, %r21;
	selp.b32 	%r22, %r5, %r14, %p10;
	selp.b32 	%r23, %r14, %r6, %p10;
	add.s64 	%rd19, %rd6, %rd13;
	st.global.u32 	[%rd19], %r22;
	add.s64 	%rd20, %rd3, %rd13;
	st.global.u32 	[%rd20], %r23;
	ret;

}
	// .globl	loop_add_fusion_160
.visible .entry loop_add_fusion_160(
	.param .u64 loop_add_fusion_160_param_0,
	.param .u64 loop_add_fusion_160_param_1,
	.param .u64 loop_add_fusion_160_param_2,
	.param .u64 loop_add_fusion_160_param_3,
	.param .u64 loop_add_fusion_160_param_4,
	.param .u64 loop_add_fusion_160_param_5,
	.param .u64 loop_add_fusion_160_param_6,
	.param .u64 loop_add_fusion_160_param_7,
	.param .u64 loop_add_fusion_160_param_8,
	.param .u64 loop_add_fusion_160_param_9,
	.param .u64 loop_add_fusion_160_param_10,
	.param .u64 loop_add_fusion_160_param_11,
	.param .u64 loop_add_fusion_160_param_12,
	.param .u64 loop_add_fusion_160_param_13,
	.param .u64 loop_add_fusion_160_param_14,
	.param .u64 loop_add_fusion_160_param_15,
	.param .u64 loop_add_fusion_160_param_16,
	.param .u64 loop_add_fusion_160_param_17,
	.param .u64 loop_add_fusion_160_param_18,
	.param .u64 loop_add_fusion_160_param_19,
	.param .u64 loop_add_fusion_160_param_20,
	.param .u64 loop_add_fusion_160_param_21,
	.param .u64 loop_add_fusion_160_param_22,
	.param .u64 loop_add_fusion_160_param_23,
	.param .u64 loop_add_fusion_160_param_24,
	.param .u64 loop_add_fusion_160_param_25,
	.param .u64 loop_add_fusion_160_param_26,
	.param .u64 loop_add_fusion_160_param_27,
	.param .u64 loop_add_fusion_160_param_28,
	.param .u64 loop_add_fusion_160_param_29,
	.param .u64 loop_add_fusion_160_param_30,
	.param .u64 loop_add_fusion_160_param_31,
	.param .u64 loop_add_fusion_160_param_32,
	.param .u64 loop_add_fusion_160_param_33,
	.param .u64 loop_add_fusion_160_param_34,
	.param .u64 loop_add_fusion_160_param_35,
	.param .u64 loop_add_fusion_160_param_36,
	.param .u64 loop_add_fusion_160_param_37,
	.param .u64 loop_add_fusion_160_param_38,
	.param .u64 loop_add_fusion_160_param_39,
	.param .u64 loop_add_fusion_160_param_40,
	.param .u64 loop_add_fusion_160_param_41,
	.param .u64 loop_add_fusion_160_param_42,
	.param .u64 loop_add_fusion_160_param_43,
	.param .u64 loop_add_fusion_160_param_44,
	.param .u64 loop_add_fusion_160_param_45,
	.param .u64 loop_add_fusion_160_param_46,
	.param .u64 loop_add_fusion_160_param_47,
	.param .u64 loop_add_fusion_160_param_48,
	.param .u64 loop_add_fusion_160_param_49,
	.param .u64 loop_add_fusion_160_param_50,
	.param .u64 loop_add_fusion_160_param_51,
	.param .u64 loop_add_fusion_160_param_52,
	.param .u64 loop_add_fusion_160_param_53,
	.param .u64 loop_add_fusion_160_param_54,
	.param .u64 loop_add_fusion_160_param_55
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<14>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<28>;
	.reg .f32 	%f<160>;
	.reg .b64 	%rd<260>;

	ld.param.u64 	%rd1, [loop_add_fusion_160_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_160_param_55];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_160_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_160_param_54];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_160_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_160_param_53];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_160_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_160_param_52];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_160_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_160_param_51];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_160_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_160_param_50];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_160_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_160_param_49];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_160_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_160_param_48];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_add_fusion_160_param_8];
	ld.param.u64 	%rd26, [loop_add_fusion_160_param_47];
	cvta.to.global.u64 	%rd27, %rd26;
	ld.param.u64 	%rd28, [loop_add_fusion_160_param_9];
	ld.param.u64 	%rd29, [loop_add_fusion_160_param_46];
	cvta.to.global.u64 	%rd30, %rd29;
	ld.param.u64 	%rd31, [loop_add_fusion_160_param_10];
	ld.param.u64 	%rd32, [loop_add_fusion_160_param_45];
	cvta.to.global.u64 	%rd33, %rd32;
	ld.param.u64 	%rd34, [loop_add_fusion_160_param_11];
	ld.param.u64 	%rd35, [loop_add_fusion_160_param_44];
	cvta.to.global.u64 	%rd36, %rd35;
	ld.param.u64 	%rd37, [loop_add_fusion_160_param_12];
	ld.param.u64 	%rd38, [loop_add_fusion_160_param_43];
	cvta.to.global.u64 	%rd39, %rd38;
	ld.param.u64 	%rd40, [loop_add_fusion_160_param_13];
	ld.param.u64 	%rd41, [loop_add_fusion_160_param_42];
	cvta.to.global.u64 	%rd42, %rd41;
	ld.param.u64 	%rd43, [loop_add_fusion_160_param_14];
	ld.param.u64 	%rd44, [loop_add_fusion_160_param_41];
	cvta.to.global.u64 	%rd45, %rd44;
	ld.param.u64 	%rd46, [loop_add_fusion_160_param_15];
	ld.param.u64 	%rd47, [loop_add_fusion_160_param_40];
	cvta.to.global.u64 	%rd48, %rd47;
	ld.param.u64 	%rd49, [loop_add_fusion_160_param_16];
	ld.param.u64 	%rd50, [loop_add_fusion_160_param_39];
	cvta.to.global.u64 	%rd51, %rd50;
	ld.param.u64 	%rd52, [loop_add_fusion_160_param_17];
	ld.param.u64 	%rd53, [loop_add_fusion_160_param_38];
	cvta.to.global.u64 	%rd54, %rd53;
	ld.param.u64 	%rd55, [loop_add_fusion_160_param_18];
	ld.param.u64 	%rd56, [loop_add_fusion_160_param_37];
	cvta.to.global.u64 	%rd57, %rd56;
	ld.param.u64 	%rd58, [loop_add_fusion_160_param_19];
	ld.param.u64 	%rd59, [loop_add_fusion_160_param_36];
	cvta.to.global.u64 	%rd60, %rd59;
	ld.param.u64 	%rd61, [loop_add_fusion_160_param_20];
	ld.param.u64 	%rd62, [loop_add_fusion_160_param_35];
	cvta.to.global.u64 	%rd63, %rd62;
	ld.param.u64 	%rd64, [loop_add_fusion_160_param_21];
	ld.param.u64 	%rd65, [loop_add_fusion_160_param_34];
	cvta.to.global.u64 	%rd66, %rd65;
	ld.param.u64 	%rd67, [loop_add_fusion_160_param_22];
	ld.param.u64 	%rd68, [loop_add_fusion_160_param_33];
	cvta.to.global.u64 	%rd69, %rd68;
	ld.param.u64 	%rd70, [loop_add_fusion_160_param_23];
	ld.param.u64 	%rd71, [loop_add_fusion_160_param_32];
	cvta.to.global.u64 	%rd72, %rd71;
	ld.param.u64 	%rd73, [loop_add_fusion_160_param_24];
	ld.param.u64 	%rd74, [loop_add_fusion_160_param_31];
	cvta.to.global.u64 	%rd75, %rd74;
	ld.param.u64 	%rd76, [loop_add_fusion_160_param_25];
	ld.param.u64 	%rd77, [loop_add_fusion_160_param_30];
	cvta.to.global.u64 	%rd78, %rd77;
	ld.param.u64 	%rd79, [loop_add_fusion_160_param_26];
	ld.param.u64 	%rd80, [loop_add_fusion_160_param_29];
	cvta.to.global.u64 	%rd81, %rd80;
	ld.param.u64 	%rd82, [loop_add_fusion_160_param_27];
	ld.param.u64 	%rd83, [loop_add_fusion_160_param_28];
	cvta.to.global.u64 	%rd84, %rd83;
	cvta.to.global.u64 	%rd85, %rd82;
	cvta.to.global.u64 	%rd86, %rd79;
	cvta.to.global.u64 	%rd87, %rd76;
	cvta.to.global.u64 	%rd88, %rd73;
	cvta.to.global.u64 	%rd89, %rd70;
	cvta.to.global.u64 	%rd90, %rd67;
	cvta.to.global.u64 	%rd91, %rd64;
	cvta.to.global.u64 	%rd92, %rd61;
	cvta.to.global.u64 	%rd93, %rd58;
	cvta.to.global.u64 	%rd94, %rd55;
	cvta.to.global.u64 	%rd95, %rd52;
	cvta.to.global.u64 	%rd96, %rd49;
	cvta.to.global.u64 	%rd97, %rd46;
	cvta.to.global.u64 	%rd98, %rd43;
	cvta.to.global.u64 	%rd99, %rd40;
	cvta.to.global.u64 	%rd100, %rd37;
	cvta.to.global.u64 	%rd101, %rd34;
	cvta.to.global.u64 	%rd102, %rd31;
	cvta.to.global.u64 	%rd103, %rd28;
	cvta.to.global.u64 	%rd104, %rd25;
	cvta.to.global.u64 	%rd105, %rd22;
	cvta.to.global.u64 	%rd106, %rd19;
	cvta.to.global.u64 	%rd107, %rd16;
	cvta.to.global.u64 	%rd108, %rd13;
	cvta.to.global.u64 	%rd109, %rd10;
	cvta.to.global.u64 	%rd110, %rd7;
	cvta.to.global.u64 	%rd111, %rd4;
	cvta.to.global.u64 	%rd112, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd113, %r5, 4;
	add.s64 	%rd114, %rd111, %rd113;
	ld.global.nc.u32 	%r6, [%rd114];
	add.s64 	%rd115, %rd110, %rd113;
	ld.global.nc.u32 	%r7, [%rd115];
	add.s64 	%rd116, %rd112, %rd113;
	ld.global.nc.u32 	%r8, [%rd116];
	max.s32 	%r9, %r6, %r7;
	min.s32 	%r10, %r8, %r9;
	setp.lt.s32 	%p1, %r10, 1;
	cvt.u32.u16 	%r11, %rs5;
	mul.wide.u32 	%rd117, %r11, 72;
	mul.wide.u32 	%rd118, %r5, 432;
	add.s64 	%rd119, %rd109, %rd118;
	add.s64 	%rd120, %rd119, %rd117;
	cvt.u32.u16 	%r12, %rs8;
	mul.wide.u32 	%rd121, %r12, 4;
	add.s64 	%rd122, %rd120, %rd121;
	ld.global.nc.f32 	%f1, [%rd122];
	setp.lt.s32 	%p2, %r9, %r8;
	ld.global.nc.f32 	%f2, [%rd122+24];
	ld.global.nc.f32 	%f3, [%rd122+48];
	selp.f32 	%f4, %f2, %f3, %p2;
	selp.f32 	%f5, %f1, %f4, %p1;
	add.s64 	%rd123, %rd107, %rd118;
	add.s64 	%rd124, %rd123, %rd117;
	add.s64 	%rd125, %rd124, %rd121;
	ld.global.nc.f32 	%f6, [%rd125];
	mul.rn.f32 	%f7, %f6, 0f41400000;
	setp.eq.s16 	%p3, %rs5, %rs8;
	selp.f32 	%f8, 0f42F00000, 0f00000000, %p3;
	add.rn.f32 	%f9, %f8, %f7;
	mul.wide.u32 	%rd126, %r11, 24;
	mul.wide.u32 	%rd127, %r5, 144;
	add.s64 	%rd128, %rd103, %rd127;
	add.s64 	%rd129, %rd128, %rd126;
	add.s64 	%rd130, %rd129, %rd121;
	ld.global.nc.f32 	%f10, [%rd130];
	mul.rn.f32 	%f11, %f10, 0f41F00000;
	add.s64 	%rd131, %rd104, %rd127;
	add.s64 	%rd132, %rd131, %rd126;
	add.s64 	%rd133, %rd132, %rd121;
	ld.global.nc.f32 	%f12, [%rd133];
	mul.rn.f32 	%f13, %f12, 0f45520000;
	add.rn.f32 	%f14, %f11, %f13;
	selp.f32 	%f15, 0f46EC4000, 0f00000000, %p3;
	add.rn.f32 	%f16, %f15, %f14;
	add.s64 	%rd134, %rd105, %rd127;
	add.s64 	%rd135, %rd134, %rd126;
	add.s64 	%rd136, %rd135, %rd121;
	ld.global.nc.f32 	%f17, [%rd136];
	mul.rn.f32 	%f18, %f17, 0f42600000;
	add.s64 	%rd137, %rd106, %rd127;
	add.s64 	%rd138, %rd137, %rd126;
	add.s64 	%rd139, %rd138, %rd121;
	ld.global.nc.f32 	%f19, [%rd139];
	mul.rn.f32 	%f20, %f19, 0f46C4E000;
	add.rn.f32 	%f21, %f18, %f20;
	add.s64 	%rd140, %rd108, %rd127;
	add.s64 	%rd141, %rd140, %rd126;
	add.s64 	%rd142, %rd141, %rd121;
	ld.global.nc.f32 	%f22, [%rd142];
	mul.rn.f32 	%f23, %f22, 0f49F3A200;
	add.rn.f32 	%f24, %f21, %f23;
	selp.f32 	%f25, 0f4B83F7C0, 0f00000000, %p3;
	add.rn.f32 	%f26, %f25, %f24;
	selp.f32 	%f27, %f16, %f26, %p2;
	selp.f32 	%f28, %f9, %f27, %p1;
	sub.rn.f32 	%f29, %f28, %f5;
	add.s64 	%rd143, %rd95, %rd113;
	ld.global.nc.u32 	%r13, [%rd143];
	max.s32 	%r14, %r6, %r13;
	min.s32 	%r15, %r8, %r14;
	setp.lt.s32 	%p4, %r15, 1;
	add.s64 	%rd144, %rd96, %rd118;
	add.s64 	%rd145, %rd144, %rd117;
	add.s64 	%rd146, %rd145, %rd121;
	ld.global.nc.f32 	%f30, [%rd146];
	setp.lt.s32 	%p5, %r14, %r8;
	ld.global.nc.f32 	%f31, [%rd146+24];
	ld.global.nc.f32 	%f32, [%rd146+48];
	selp.f32 	%f33, %f31, %f32, %p5;
	selp.f32 	%f34, %f30, %f33, %p4;
	add.s64 	%rd147, %rd97, %rd118;
	add.s64 	%rd148, %rd147, %rd117;
	add.s64 	%rd149, %rd148, %rd121;
	ld.global.nc.f32 	%f35, [%rd149];
	mul.rn.f32 	%f36, %f35, 0f41400000;
	add.rn.f32 	%f37, %f8, %f36;
	add.s64 	%rd150, %rd98, %rd127;
	add.s64 	%rd151, %rd150, %rd126;
	add.s64 	%rd152, %rd151, %rd121;
	ld.global.nc.f32 	%f38, [%rd152];
	mul.rn.f32 	%f39, %f38, 0f41F00000;
	add.s64 	%rd153, %rd99, %rd127;
	add.s64 	%rd154, %rd153, %rd126;
	add.s64 	%rd155, %rd154, %rd121;
	ld.global.nc.f32 	%f40, [%rd155];
	mul.rn.f32 	%f41, %f40, 0f45520000;
	add.rn.f32 	%f42, %f39, %f41;
	add.rn.f32 	%f43, %f15, %f42;
	add.s64 	%rd156, %rd100, %rd127;
	add.s64 	%rd157, %rd156, %rd126;
	add.s64 	%rd158, %rd157, %rd121;
	ld.global.nc.f32 	%f44, [%rd158];
	mul.rn.f32 	%f45, %f44, 0f42600000;
	add.s64 	%rd159, %rd101, %rd127;
	add.s64 	%rd160, %rd159, %rd126;
	add.s64 	%rd161, %rd160, %rd121;
	ld.global.nc.f32 	%f46, [%rd161];
	mul.rn.f32 	%f47, %f46, 0f46C4E000;
	add.rn.f32 	%f48, %f45, %f47;
	add.s64 	%rd162, %rd102, %rd127;
	add.s64 	%rd163, %rd162, %rd126;
	add.s64 	%rd164, %rd163, %rd121;
	ld.global.nc.f32 	%f49, [%rd164];
	mul.rn.f32 	%f50, %f49, 0f49F3A200;
	add.rn.f32 	%f51, %f48, %f50;
	add.rn.f32 	%f52, %f25, %f51;
	selp.f32 	%f53, %f43, %f52, %p5;
	selp.f32 	%f54, %f37, %f53, %p4;
	sub.rn.f32 	%f55, %f54, %f34;
	add.s64 	%rd165, %rd87, %rd113;
	ld.global.nc.u32 	%r16, [%rd165];
	max.s32 	%r17, %r6, %r16;
	min.s32 	%r18, %r8, %r17;
	setp.lt.s32 	%p6, %r18, 1;
	add.s64 	%rd166, %rd88, %rd118;
	add.s64 	%rd167, %rd166, %rd117;
	add.s64 	%rd168, %rd167, %rd121;
	ld.global.nc.f32 	%f56, [%rd168];
	setp.lt.s32 	%p7, %r17, %r8;
	ld.global.nc.f32 	%f57, [%rd168+24];
	ld.global.nc.f32 	%f58, [%rd168+48];
	selp.f32 	%f59, %f57, %f58, %p7;
	selp.f32 	%f60, %f56, %f59, %p6;
	add.s64 	%rd169, %rd89, %rd118;
	add.s64 	%rd170, %rd169, %rd117;
	add.s64 	%rd171, %rd170, %rd121;
	ld.global.nc.f32 	%f61, [%rd171];
	mul.rn.f32 	%f62, %f61, 0f41400000;
	add.rn.f32 	%f63, %f8, %f62;
	add.s64 	%rd172, %rd90, %rd127;
	add.s64 	%rd173, %rd172, %rd126;
	add.s64 	%rd174, %rd173, %rd121;
	ld.global.nc.f32 	%f64, [%rd174];
	mul.rn.f32 	%f65, %f64, 0f41F00000;
	add.s64 	%rd175, %rd91, %rd127;
	add.s64 	%rd176, %rd175, %rd126;
	add.s64 	%rd177, %rd176, %rd121;
	ld.global.nc.f32 	%f66, [%rd177];
	mul.rn.f32 	%f67, %f66, 0f45520000;
	add.rn.f32 	%f68, %f65, %f67;
	add.rn.f32 	%f69, %f15, %f68;
	add.s64 	%rd178, %rd92, %rd127;
	add.s64 	%rd179, %rd178, %rd126;
	add.s64 	%rd180, %rd179, %rd121;
	ld.global.nc.f32 	%f70, [%rd180];
	mul.rn.f32 	%f71, %f70, 0f42600000;
	add.s64 	%rd181, %rd93, %rd127;
	add.s64 	%rd182, %rd181, %rd126;
	add.s64 	%rd183, %rd182, %rd121;
	ld.global.nc.f32 	%f72, [%rd183];
	mul.rn.f32 	%f73, %f72, 0f46C4E000;
	add.rn.f32 	%f74, %f71, %f73;
	add.s64 	%rd184, %rd94, %rd127;
	add.s64 	%rd185, %rd184, %rd126;
	add.s64 	%rd186, %rd185, %rd121;
	ld.global.nc.f32 	%f75, [%rd186];
	mul.rn.f32 	%f76, %f75, 0f49F3A200;
	add.rn.f32 	%f77, %f74, %f76;
	add.rn.f32 	%f78, %f25, %f77;
	selp.f32 	%f79, %f69, %f78, %p7;
	selp.f32 	%f80, %f63, %f79, %p6;
	sub.rn.f32 	%f81, %f80, %f60;
	add.s64 	%rd187, %rd69, %rd113;
	ld.global.nc.u32 	%r19, [%rd187];
	max.s32 	%r20, %r6, %r19;
	min.s32 	%r21, %r8, %r20;
	setp.lt.s32 	%p8, %r21, 1;
	add.s64 	%rd188, %rd72, %rd118;
	add.s64 	%rd189, %rd188, %rd117;
	add.s64 	%rd190, %rd189, %rd121;
	ld.global.nc.f32 	%f82, [%rd190];
	setp.lt.s32 	%p9, %r20, %r8;
	ld.global.nc.f32 	%f83, [%rd190+24];
	ld.global.nc.f32 	%f84, [%rd190+48];
	selp.f32 	%f85, %f83, %f84, %p9;
	selp.f32 	%f86, %f82, %f85, %p8;
	add.s64 	%rd191, %rd75, %rd118;
	add.s64 	%rd192, %rd191, %rd117;
	add.s64 	%rd193, %rd192, %rd121;
	ld.global.nc.f32 	%f87, [%rd193];
	mul.rn.f32 	%f88, %f87, 0f41400000;
	add.rn.f32 	%f89, %f8, %f88;
	add.s64 	%rd194, %rd78, %rd127;
	add.s64 	%rd195, %rd194, %rd126;
	add.s64 	%rd196, %rd195, %rd121;
	ld.global.nc.f32 	%f90, [%rd196];
	mul.rn.f32 	%f91, %f90, 0f41F00000;
	add.s64 	%rd197, %rd81, %rd127;
	add.s64 	%rd198, %rd197, %rd126;
	add.s64 	%rd199, %rd198, %rd121;
	ld.global.nc.f32 	%f92, [%rd199];
	mul.rn.f32 	%f93, %f92, 0f45520000;
	add.rn.f32 	%f94, %f91, %f93;
	add.rn.f32 	%f95, %f15, %f94;
	add.s64 	%rd200, %rd84, %rd127;
	add.s64 	%rd201, %rd200, %rd126;
	add.s64 	%rd202, %rd201, %rd121;
	ld.global.nc.f32 	%f96, [%rd202];
	mul.rn.f32 	%f97, %f96, 0f42600000;
	add.s64 	%rd203, %rd85, %rd127;
	add.s64 	%rd204, %rd203, %rd126;
	add.s64 	%rd205, %rd204, %rd121;
	ld.global.nc.f32 	%f98, [%rd205];
	mul.rn.f32 	%f99, %f98, 0f46C4E000;
	add.rn.f32 	%f100, %f97, %f99;
	add.s64 	%rd206, %rd86, %rd127;
	add.s64 	%rd207, %rd206, %rd126;
	add.s64 	%rd208, %rd207, %rd121;
	ld.global.nc.f32 	%f101, [%rd208];
	mul.rn.f32 	%f102, %f101, 0f49F3A200;
	add.rn.f32 	%f103, %f100, %f102;
	add.rn.f32 	%f104, %f25, %f103;
	selp.f32 	%f105, %f95, %f104, %p9;
	selp.f32 	%f106, %f89, %f105, %p8;
	sub.rn.f32 	%f107, %f106, %f86;
	add.s64 	%rd209, %rd45, %rd113;
	ld.global.nc.u32 	%r22, [%rd209];
	max.s32 	%r23, %r6, %r22;
	min.s32 	%r24, %r8, %r23;
	setp.lt.s32 	%p10, %r24, 1;
	add.s64 	%rd210, %rd48, %rd118;
	add.s64 	%rd211, %rd210, %rd117;
	add.s64 	%rd212, %rd211, %rd121;
	ld.global.nc.f32 	%f108, [%rd212];
	setp.lt.s32 	%p11, %r23, %r8;
	ld.global.nc.f32 	%f109, [%rd212+24];
	ld.global.nc.f32 	%f110, [%rd212+48];
	selp.f32 	%f111, %f109, %f110, %p11;
	selp.f32 	%f112, %f108, %f111, %p10;
	add.s64 	%rd213, %rd51, %rd118;
	add.s64 	%rd214, %rd213, %rd117;
	add.s64 	%rd215, %rd214, %rd121;
	ld.global.nc.f32 	%f113, [%rd215];
	mul.rn.f32 	%f114, %f113, 0f41400000;
	add.rn.f32 	%f115, %f8, %f114;
	add.s64 	%rd216, %rd54, %rd127;
	add.s64 	%rd217, %rd216, %rd126;
	add.s64 	%rd218, %rd217, %rd121;
	ld.global.nc.f32 	%f116, [%rd218];
	mul.rn.f32 	%f117, %f116, 0f41F00000;
	add.s64 	%rd219, %rd57, %rd127;
	add.s64 	%rd220, %rd219, %rd126;
	add.s64 	%rd221, %rd220, %rd121;
	ld.global.nc.f32 	%f118, [%rd221];
	mul.rn.f32 	%f119, %f118, 0f45520000;
	add.rn.f32 	%f120, %f117, %f119;
	add.rn.f32 	%f121, %f15, %f120;
	add.s64 	%rd222, %rd60, %rd127;
	add.s64 	%rd223, %rd222, %rd126;
	add.s64 	%rd224, %rd223, %rd121;
	ld.global.nc.f32 	%f122, [%rd224];
	mul.rn.f32 	%f123, %f122, 0f42600000;
	add.s64 	%rd225, %rd63, %rd127;
	add.s64 	%rd226, %rd225, %rd126;
	add.s64 	%rd227, %rd226, %rd121;
	ld.global.nc.f32 	%f124, [%rd227];
	mul.rn.f32 	%f125, %f124, 0f46C4E000;
	add.rn.f32 	%f126, %f123, %f125;
	add.s64 	%rd228, %rd66, %rd127;
	add.s64 	%rd229, %rd228, %rd126;
	add.s64 	%rd230, %rd229, %rd121;
	ld.global.nc.f32 	%f127, [%rd230];
	mul.rn.f32 	%f128, %f127, 0f49F3A200;
	add.rn.f32 	%f129, %f126, %f128;
	add.rn.f32 	%f130, %f25, %f129;
	selp.f32 	%f131, %f121, %f130, %p11;
	selp.f32 	%f132, %f115, %f131, %p10;
	sub.rn.f32 	%f133, %f132, %f112;
	add.s64 	%rd231, %rd21, %rd113;
	ld.global.nc.u32 	%r25, [%rd231];
	max.s32 	%r26, %r6, %r25;
	min.s32 	%r27, %r8, %r26;
	setp.lt.s32 	%p12, %r27, 1;
	add.s64 	%rd232, %rd24, %rd118;
	add.s64 	%rd233, %rd232, %rd117;
	add.s64 	%rd234, %rd233, %rd121;
	ld.global.nc.f32 	%f134, [%rd234];
	setp.lt.s32 	%p13, %r26, %r8;
	ld.global.nc.f32 	%f135, [%rd234+24];
	ld.global.nc.f32 	%f136, [%rd234+48];
	selp.f32 	%f137, %f135, %f136, %p13;
	selp.f32 	%f138, %f134, %f137, %p12;
	add.s64 	%rd235, %rd27, %rd118;
	add.s64 	%rd236, %rd235, %rd117;
	add.s64 	%rd237, %rd236, %rd121;
	ld.global.nc.f32 	%f139, [%rd237];
	mul.rn.f32 	%f140, %f139, 0f41400000;
	add.rn.f32 	%f141, %f8, %f140;
	add.s64 	%rd238, %rd30, %rd127;
	add.s64 	%rd239, %rd238, %rd126;
	add.s64 	%rd240, %rd239, %rd121;
	ld.global.nc.f32 	%f142, [%rd240];
	mul.rn.f32 	%f143, %f142, 0f41F00000;
	add.s64 	%rd241, %rd33, %rd127;
	add.s64 	%rd242, %rd241, %rd126;
	add.s64 	%rd243, %rd242, %rd121;
	ld.global.nc.f32 	%f144, [%rd243];
	mul.rn.f32 	%f145, %f144, 0f45520000;
	add.rn.f32 	%f146, %f143, %f145;
	add.rn.f32 	%f147, %f15, %f146;
	add.s64 	%rd244, %rd36, %rd127;
	add.s64 	%rd245, %rd244, %rd126;
	add.s64 	%rd246, %rd245, %rd121;
	ld.global.nc.f32 	%f148, [%rd246];
	mul.rn.f32 	%f149, %f148, 0f42600000;
	add.s64 	%rd247, %rd39, %rd127;
	add.s64 	%rd248, %rd247, %rd126;
	add.s64 	%rd249, %rd248, %rd121;
	ld.global.nc.f32 	%f150, [%rd249];
	mul.rn.f32 	%f151, %f150, 0f46C4E000;
	add.rn.f32 	%f152, %f149, %f151;
	add.s64 	%rd250, %rd42, %rd127;
	add.s64 	%rd251, %rd250, %rd126;
	add.s64 	%rd252, %rd251, %rd121;
	ld.global.nc.f32 	%f153, [%rd252];
	mul.rn.f32 	%f154, %f153, 0f49F3A200;
	add.rn.f32 	%f155, %f152, %f154;
	add.rn.f32 	%f156, %f25, %f155;
	selp.f32 	%f157, %f147, %f156, %p13;
	selp.f32 	%f158, %f141, %f157, %p12;
	sub.rn.f32 	%f159, %f158, %f138;
	mul.wide.u32 	%rd253, %r4, 4;
	add.s64 	%rd254, %rd18, %rd253;
	st.global.f32 	[%rd254], %f29;
	add.s64 	%rd255, %rd15, %rd253;
	st.global.f32 	[%rd255], %f55;
	add.s64 	%rd256, %rd12, %rd253;
	st.global.f32 	[%rd256], %f81;
	add.s64 	%rd257, %rd9, %rd253;
	st.global.f32 	[%rd257], %f107;
	add.s64 	%rd258, %rd6, %rd253;
	st.global.f32 	[%rd258], %f133;
	add.s64 	%rd259, %rd3, %rd253;
	st.global.f32 	[%rd259], %f159;
	ret;

}
	// .globl	loop_add_fusion_256
.visible .entry loop_add_fusion_256(
	.param .u64 loop_add_fusion_256_param_0
)
.reqntid 384, 1, 1
{
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [loop_add_fusion_256_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %tid.x;
	mul.wide.u32 	%rd3, %r1, 4;
	add.s64 	%rd4, %rd2, %rd3;
	ld.global.u32 	%r2, [%rd4];
	add.s32 	%r3, %r2, -1;
	st.global.u32 	[%rd4], %r3;
	ret;

}
	// .globl	loop_select_transpose_fusion
.visible .entry loop_select_transpose_fusion(
	.param .u64 loop_select_transpose_fusion_param_0,
	.param .u64 loop_select_transpose_fusion_param_1,
	.param .u64 loop_select_transpose_fusion_param_2,
	.param .u64 loop_select_transpose_fusion_param_3,
	.param .u64 loop_select_transpose_fusion_param_4,
	.param .u64 loop_select_transpose_fusion_param_5,
	.param .u64 loop_select_transpose_fusion_param_6,
	.param .u64 loop_select_transpose_fusion_param_7,
	.param .u64 loop_select_transpose_fusion_param_8,
	.param .u64 loop_select_transpose_fusion_param_9,
	.param .u64 loop_select_transpose_fusion_param_10,
	.param .u64 loop_select_transpose_fusion_param_11,
	.param .u64 loop_select_transpose_fusion_param_12,
	.param .u64 loop_select_transpose_fusion_param_13,
	.param .u64 loop_select_transpose_fusion_param_14,
	.param .u64 loop_select_transpose_fusion_param_15,
	.param .u64 loop_select_transpose_fusion_param_16,
	.param .u64 loop_select_transpose_fusion_param_17,
	.param .u64 loop_select_transpose_fusion_param_18,
	.param .u64 loop_select_transpose_fusion_param_19,
	.param .u64 loop_select_transpose_fusion_param_20,
	.param .u64 loop_select_transpose_fusion_param_21,
	.param .u64 loop_select_transpose_fusion_param_22,
	.param .u64 loop_select_transpose_fusion_param_23,
	.param .u64 loop_select_transpose_fusion_param_24,
	.param .u64 loop_select_transpose_fusion_param_25,
	.param .u64 loop_select_transpose_fusion_param_26,
	.param .u64 loop_select_transpose_fusion_param_27,
	.param .u64 loop_select_transpose_fusion_param_28,
	.param .u64 loop_select_transpose_fusion_param_29,
	.param .u64 loop_select_transpose_fusion_param_30,
	.param .u64 loop_select_transpose_fusion_param_31,
	.param .u64 loop_select_transpose_fusion_param_32,
	.param .u64 loop_select_transpose_fusion_param_33,
	.param .u64 loop_select_transpose_fusion_param_34,
	.param .u64 loop_select_transpose_fusion_param_35,
	.param .u64 loop_select_transpose_fusion_param_36,
	.param .u64 loop_select_transpose_fusion_param_37,
	.param .u64 loop_select_transpose_fusion_param_38,
	.param .u64 loop_select_transpose_fusion_param_39,
	.param .u64 loop_select_transpose_fusion_param_40,
	.param .u64 loop_select_transpose_fusion_param_41,
	.param .u64 loop_select_transpose_fusion_param_42,
	.param .u64 loop_select_transpose_fusion_param_43,
	.param .u64 loop_select_transpose_fusion_param_44,
	.param .u64 loop_select_transpose_fusion_param_45,
	.param .u64 loop_select_transpose_fusion_param_46,
	.param .u64 loop_select_transpose_fusion_param_47,
	.param .u64 loop_select_transpose_fusion_param_48,
	.param .u64 loop_select_transpose_fusion_param_49,
	.param .u64 loop_select_transpose_fusion_param_50,
	.param .u64 loop_select_transpose_fusion_param_51,
	.param .u64 loop_select_transpose_fusion_param_52,
	.param .u64 loop_select_transpose_fusion_param_53,
	.param .u64 loop_select_transpose_fusion_param_54,
	.param .u64 loop_select_transpose_fusion_param_55,
	.param .u64 loop_select_transpose_fusion_param_56,
	.param .u64 loop_select_transpose_fusion_param_57,
	.param .u64 loop_select_transpose_fusion_param_58,
	.param .u64 loop_select_transpose_fusion_param_59,
	.param .u64 loop_select_transpose_fusion_param_60,
	.param .u64 loop_select_transpose_fusion_param_61,
	.param .u64 loop_select_transpose_fusion_param_62,
	.param .u64 loop_select_transpose_fusion_param_63,
	.param .u64 loop_select_transpose_fusion_param_64,
	.param .u64 loop_select_transpose_fusion_param_65,
	.param .u64 loop_select_transpose_fusion_param_66,
	.param .u64 loop_select_transpose_fusion_param_67,
	.param .u64 loop_select_transpose_fusion_param_68,
	.param .u64 loop_select_transpose_fusion_param_69,
	.param .u64 loop_select_transpose_fusion_param_70,
	.param .u64 loop_select_transpose_fusion_param_71,
	.param .u64 loop_select_transpose_fusion_param_72,
	.param .u64 loop_select_transpose_fusion_param_73
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<32>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<67>;
	.reg .f32 	%f<187>;
	.reg .b64 	%rd<334>;

	ld.param.u64 	%rd1, [loop_select_transpose_fusion_param_0];
	ld.param.u64 	%rd2, [loop_select_transpose_fusion_param_73];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_select_transpose_fusion_param_1];
	ld.param.u64 	%rd5, [loop_select_transpose_fusion_param_72];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_select_transpose_fusion_param_2];
	ld.param.u64 	%rd8, [loop_select_transpose_fusion_param_71];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_select_transpose_fusion_param_3];
	ld.param.u64 	%rd11, [loop_select_transpose_fusion_param_70];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_select_transpose_fusion_param_4];
	ld.param.u64 	%rd14, [loop_select_transpose_fusion_param_69];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_select_transpose_fusion_param_5];
	ld.param.u64 	%rd17, [loop_select_transpose_fusion_param_68];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_select_transpose_fusion_param_6];
	ld.param.u64 	%rd20, [loop_select_transpose_fusion_param_67];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_select_transpose_fusion_param_7];
	ld.param.u64 	%rd23, [loop_select_transpose_fusion_param_66];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_select_transpose_fusion_param_8];
	ld.param.u64 	%rd26, [loop_select_transpose_fusion_param_65];
	cvta.to.global.u64 	%rd27, %rd26;
	ld.param.u64 	%rd28, [loop_select_transpose_fusion_param_9];
	ld.param.u64 	%rd29, [loop_select_transpose_fusion_param_64];
	cvta.to.global.u64 	%rd30, %rd29;
	ld.param.u64 	%rd31, [loop_select_transpose_fusion_param_10];
	ld.param.u64 	%rd32, [loop_select_transpose_fusion_param_63];
	cvta.to.global.u64 	%rd33, %rd32;
	ld.param.u64 	%rd34, [loop_select_transpose_fusion_param_11];
	ld.param.u64 	%rd35, [loop_select_transpose_fusion_param_62];
	cvta.to.global.u64 	%rd36, %rd35;
	ld.param.u64 	%rd37, [loop_select_transpose_fusion_param_12];
	ld.param.u64 	%rd38, [loop_select_transpose_fusion_param_61];
	cvta.to.global.u64 	%rd39, %rd38;
	ld.param.u64 	%rd40, [loop_select_transpose_fusion_param_13];
	ld.param.u64 	%rd41, [loop_select_transpose_fusion_param_60];
	cvta.to.global.u64 	%rd42, %rd41;
	ld.param.u64 	%rd43, [loop_select_transpose_fusion_param_14];
	ld.param.u64 	%rd44, [loop_select_transpose_fusion_param_59];
	cvta.to.global.u64 	%rd45, %rd44;
	ld.param.u64 	%rd46, [loop_select_transpose_fusion_param_15];
	ld.param.u64 	%rd47, [loop_select_transpose_fusion_param_58];
	cvta.to.global.u64 	%rd48, %rd47;
	ld.param.u64 	%rd49, [loop_select_transpose_fusion_param_16];
	ld.param.u64 	%rd50, [loop_select_transpose_fusion_param_57];
	cvta.to.global.u64 	%rd51, %rd50;
	ld.param.u64 	%rd52, [loop_select_transpose_fusion_param_17];
	ld.param.u64 	%rd53, [loop_select_transpose_fusion_param_56];
	cvta.to.global.u64 	%rd54, %rd53;
	ld.param.u64 	%rd55, [loop_select_transpose_fusion_param_18];
	ld.param.u64 	%rd56, [loop_select_transpose_fusion_param_55];
	cvta.to.global.u64 	%rd57, %rd56;
	ld.param.u64 	%rd58, [loop_select_transpose_fusion_param_19];
	ld.param.u64 	%rd59, [loop_select_transpose_fusion_param_54];
	cvta.to.global.u64 	%rd60, %rd59;
	ld.param.u64 	%rd61, [loop_select_transpose_fusion_param_20];
	ld.param.u64 	%rd62, [loop_select_transpose_fusion_param_53];
	cvta.to.global.u64 	%rd63, %rd62;
	ld.param.u64 	%rd64, [loop_select_transpose_fusion_param_21];
	ld.param.u64 	%rd65, [loop_select_transpose_fusion_param_52];
	cvta.to.global.u64 	%rd66, %rd65;
	ld.param.u64 	%rd67, [loop_select_transpose_fusion_param_22];
	ld.param.u64 	%rd68, [loop_select_transpose_fusion_param_51];
	cvta.to.global.u64 	%rd69, %rd68;
	ld.param.u64 	%rd70, [loop_select_transpose_fusion_param_23];
	ld.param.u64 	%rd71, [loop_select_transpose_fusion_param_50];
	cvta.to.global.u64 	%rd72, %rd71;
	ld.param.u64 	%rd73, [loop_select_transpose_fusion_param_24];
	ld.param.u64 	%rd74, [loop_select_transpose_fusion_param_49];
	cvta.to.global.u64 	%rd75, %rd74;
	ld.param.u64 	%rd76, [loop_select_transpose_fusion_param_25];
	ld.param.u64 	%rd77, [loop_select_transpose_fusion_param_48];
	cvta.to.global.u64 	%rd78, %rd77;
	ld.param.u64 	%rd79, [loop_select_transpose_fusion_param_26];
	ld.param.u64 	%rd80, [loop_select_transpose_fusion_param_47];
	cvta.to.global.u64 	%rd81, %rd80;
	ld.param.u64 	%rd82, [loop_select_transpose_fusion_param_27];
	ld.param.u64 	%rd83, [loop_select_transpose_fusion_param_46];
	cvta.to.global.u64 	%rd84, %rd83;
	ld.param.u64 	%rd85, [loop_select_transpose_fusion_param_28];
	ld.param.u64 	%rd86, [loop_select_transpose_fusion_param_45];
	cvta.to.global.u64 	%rd87, %rd86;
	ld.param.u64 	%rd88, [loop_select_transpose_fusion_param_29];
	ld.param.u64 	%rd89, [loop_select_transpose_fusion_param_44];
	cvta.to.global.u64 	%rd90, %rd89;
	ld.param.u64 	%rd91, [loop_select_transpose_fusion_param_30];
	ld.param.u64 	%rd92, [loop_select_transpose_fusion_param_43];
	cvta.to.global.u64 	%rd93, %rd92;
	ld.param.u64 	%rd94, [loop_select_transpose_fusion_param_31];
	ld.param.u64 	%rd95, [loop_select_transpose_fusion_param_42];
	cvta.to.global.u64 	%rd96, %rd95;
	ld.param.u64 	%rd97, [loop_select_transpose_fusion_param_32];
	ld.param.u64 	%rd98, [loop_select_transpose_fusion_param_41];
	cvta.to.global.u64 	%rd99, %rd98;
	ld.param.u64 	%rd100, [loop_select_transpose_fusion_param_33];
	ld.param.u64 	%rd101, [loop_select_transpose_fusion_param_40];
	cvta.to.global.u64 	%rd102, %rd101;
	ld.param.u64 	%rd103, [loop_select_transpose_fusion_param_34];
	ld.param.u64 	%rd104, [loop_select_transpose_fusion_param_39];
	cvta.to.global.u64 	%rd105, %rd104;
	ld.param.u64 	%rd106, [loop_select_transpose_fusion_param_35];
	ld.param.u64 	%rd107, [loop_select_transpose_fusion_param_38];
	cvta.to.global.u64 	%rd108, %rd107;
	ld.param.u64 	%rd109, [loop_select_transpose_fusion_param_36];
	ld.param.u64 	%rd110, [loop_select_transpose_fusion_param_37];
	cvta.to.global.u64 	%rd111, %rd110;
	cvta.to.global.u64 	%rd112, %rd109;
	cvta.to.global.u64 	%rd113, %rd106;
	cvta.to.global.u64 	%rd114, %rd103;
	cvta.to.global.u64 	%rd115, %rd100;
	cvta.to.global.u64 	%rd116, %rd97;
	cvta.to.global.u64 	%rd117, %rd94;
	cvta.to.global.u64 	%rd118, %rd91;
	cvta.to.global.u64 	%rd119, %rd88;
	cvta.to.global.u64 	%rd120, %rd85;
	cvta.to.global.u64 	%rd121, %rd82;
	cvta.to.global.u64 	%rd122, %rd79;
	cvta.to.global.u64 	%rd123, %rd76;
	cvta.to.global.u64 	%rd124, %rd73;
	cvta.to.global.u64 	%rd125, %rd70;
	cvta.to.global.u64 	%rd126, %rd67;
	cvta.to.global.u64 	%rd127, %rd64;
	cvta.to.global.u64 	%rd128, %rd61;
	cvta.to.global.u64 	%rd129, %rd58;
	cvta.to.global.u64 	%rd130, %rd55;
	cvta.to.global.u64 	%rd131, %rd52;
	cvta.to.global.u64 	%rd132, %rd49;
	cvta.to.global.u64 	%rd133, %rd46;
	cvta.to.global.u64 	%rd134, %rd43;
	cvta.to.global.u64 	%rd135, %rd40;
	cvta.to.global.u64 	%rd136, %rd37;
	cvta.to.global.u64 	%rd137, %rd34;
	cvta.to.global.u64 	%rd138, %rd31;
	cvta.to.global.u64 	%rd139, %rd28;
	cvta.to.global.u64 	%rd140, %rd25;
	cvta.to.global.u64 	%rd141, %rd22;
	cvta.to.global.u64 	%rd142, %rd19;
	cvta.to.global.u64 	%rd143, %rd16;
	cvta.to.global.u64 	%rd144, %rd13;
	cvta.to.global.u64 	%rd145, %rd10;
	cvta.to.global.u64 	%rd146, %rd7;
	cvta.to.global.u64 	%rd147, %rd4;
	cvta.to.global.u64 	%rd148, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.hi.u16 	%rs4, %rs3, 10923;
	mul.lo.s16 	%rs5, %rs4, 6;
	sub.s16 	%rs6, %rs3, %rs5;
	cvt.u32.u16 	%r5, %rs6;
	mul.hi.u16 	%rs7, %rs1, -7281;
	shr.u16 	%rs8, %rs7, 5;
	mul.lo.s16 	%rs9, %rs3, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r6, %rs8;
	mul.wide.u32 	%rd149, %r6, 4;
	add.s64 	%rd150, %rd147, %rd149;
	ld.global.nc.u32 	%r7, [%rd150];
	add.s64 	%rd151, %rd146, %rd149;
	ld.global.nc.u32 	%r8, [%rd151];
	setp.lt.s32 	%p1, %r7, %r8;
	mul.wide.u32 	%rd152, %r4, 4;
	add.s64 	%rd153, %rd148, %rd152;
	ld.global.f32 	%f1, [%rd153];
	selp.f32 	%f2, 0f7FC00000, %f1, %p1;
	mul.lo.s16 	%rs11, %rs8, 6;
	add.s16 	%rs12, %rs11, %rs10;
	mul.hi.u16 	%rs14, %rs12, -21845;
	shr.u16 	%rs15, %rs14, 2;
	setp.gt.u16 	%p2, %rs12, 377;
	selp.b16 	%rs16, 63, %rs15, %p2;
	mul.lo.s16 	%rs17, %rs15, 6;
	sub.s16 	%rs18, %rs12, %rs17;
	cvt.u32.u16 	%r9, %rs18;
	mul.wide.u32 	%rd154, %r9, 4;
	cvt.u32.u16 	%r10, %rs15;
	mul.wide.u32 	%rd155, %r10, 24;
	add.s64 	%rd156, %rd145, %rd155;
	add.s64 	%rd157, %rd156, %rd154;
	ld.global.nc.u32 	%r11, [%rd157];
	setp.lt.s32 	%p3, %r11, 0;
	add.s32 	%r12, %r11, 6;
	selp.b32 	%r13, %r12, %r11, %p3;
	max.s32 	%r14, %r13, 0;
	min.s32 	%r15, %r14, 5;
	cvt.u32.u16 	%r16, %rs16;
	mul.wide.u32 	%rd158, %r16, 4;
	add.s64 	%rd159, %rd146, %rd158;
	ld.global.nc.u32 	%r17, [%rd159];
	add.s64 	%rd160, %rd136, %rd158;
	ld.global.nc.u32 	%r18, [%rd160];
	add.s64 	%rd161, %rd137, %rd158;
	ld.global.nc.u32 	%r19, [%rd161];
	max.s32 	%r20, %r17, %r18;
	min.s32 	%r21, %r19, %r20;
	setp.lt.s32 	%p4, %r21, 1;
	mul.wide.u32 	%rd162, %r15, 72;
	mul.wide.u32 	%rd163, %r16, 432;
	add.s64 	%rd164, %rd138, %rd163;
	add.s64 	%rd165, %rd164, %rd162;
	mul.wide.u32 	%rd166, %r5, 4;
	add.s64 	%rd167, %rd165, %rd166;
	ld.global.nc.f32 	%f3, [%rd167];
	setp.lt.s32 	%p5, %r20, %r19;
	ld.global.nc.f32 	%f4, [%rd167+24];
	ld.global.nc.f32 	%f5, [%rd167+48];
	selp.f32 	%f6, %f4, %f5, %p5;
	selp.f32 	%f7, %f3, %f6, %p4;
	add.s64 	%rd168, %rd139, %rd163;
	add.s64 	%rd169, %rd168, %rd162;
	add.s64 	%rd170, %rd169, %rd166;
	ld.global.nc.f32 	%f8, [%rd170];
	mul.rn.f32 	%f9, %f8, 0f41400000;
	setp.eq.s32 	%p6, %r15, %r5;
	selp.f32 	%f10, 0f42F00000, 0f00000000, %p6;
	add.rn.f32 	%f11, %f10, %f9;
	mul.wide.u32 	%rd171, %r15, 24;
	mul.wide.u32 	%rd172, %r16, 144;
	add.s64 	%rd173, %rd140, %rd172;
	add.s64 	%rd174, %rd173, %rd171;
	add.s64 	%rd175, %rd174, %rd166;
	ld.global.nc.f32 	%f12, [%rd175];
	mul.rn.f32 	%f13, %f12, 0f41F00000;
	add.s64 	%rd176, %rd141, %rd172;
	add.s64 	%rd177, %rd176, %rd171;
	add.s64 	%rd178, %rd177, %rd166;
	ld.global.nc.f32 	%f14, [%rd178];
	mul.rn.f32 	%f15, %f14, 0f45520000;
	add.rn.f32 	%f16, %f13, %f15;
	selp.f32 	%f17, 0f46EC4000, 0f00000000, %p6;
	add.rn.f32 	%f18, %f17, %f16;
	add.s64 	%rd179, %rd142, %rd172;
	add.s64 	%rd180, %rd179, %rd171;
	add.s64 	%rd181, %rd180, %rd166;
	ld.global.nc.f32 	%f19, [%rd181];
	mul.rn.f32 	%f20, %f19, 0f42600000;
	add.s64 	%rd182, %rd143, %rd172;
	add.s64 	%rd183, %rd182, %rd171;
	add.s64 	%rd184, %rd183, %rd166;
	ld.global.nc.f32 	%f21, [%rd184];
	mul.rn.f32 	%f22, %f21, 0f46C4E000;
	add.rn.f32 	%f23, %f20, %f22;
	add.s64 	%rd185, %rd144, %rd172;
	add.s64 	%rd186, %rd185, %rd171;
	add.s64 	%rd187, %rd186, %rd166;
	ld.global.nc.f32 	%f24, [%rd187];
	mul.rn.f32 	%f25, %f24, 0f49F3A200;
	add.rn.f32 	%f26, %f23, %f25;
	selp.f32 	%f27, 0f4B83F7C0, 0f00000000, %p6;
	add.rn.f32 	%f28, %f27, %f26;
	selp.f32 	%f29, %f18, %f28, %p5;
	selp.f32 	%f30, %f11, %f29, %p4;
	add.rn.f32 	%f31, %f7, %f30;
	add.s64 	%rd188, %rd134, %rd149;
	ld.global.nc.u32 	%r22, [%rd188];
	setp.lt.s32 	%p7, %r22, %r8;
	add.s64 	%rd189, %rd135, %rd152;
	ld.global.f32 	%f32, [%rd189];
	selp.f32 	%f33, 0f7FC00000, %f32, %p7;
	add.s64 	%rd190, %rd133, %rd155;
	add.s64 	%rd191, %rd190, %rd154;
	ld.global.nc.u32 	%r23, [%rd191];
	setp.lt.s32 	%p8, %r23, 0;
	add.s32 	%r24, %r23, 6;
	selp.b32 	%r25, %r24, %r23, %p8;
	max.s32 	%r26, %r25, 0;
	min.s32 	%r27, %r26, 5;
	add.s64 	%rd192, %rd125, %rd158;
	ld.global.nc.u32 	%r28, [%rd192];
	max.s32 	%r29, %r17, %r28;
	min.s32 	%r30, %r19, %r29;
	setp.lt.s32 	%p9, %r30, 1;
	mul.wide.u32 	%rd193, %r27, 72;
	add.s64 	%rd194, %rd126, %rd163;
	add.s64 	%rd195, %rd194, %rd193;
	add.s64 	%rd196, %rd195, %rd166;
	ld.global.nc.f32 	%f34, [%rd196];
	setp.lt.s32 	%p10, %r29, %r19;
	ld.global.nc.f32 	%f35, [%rd196+24];
	ld.global.nc.f32 	%f36, [%rd196+48];
	selp.f32 	%f37, %f35, %f36, %p10;
	selp.f32 	%f38, %f34, %f37, %p9;
	add.s64 	%rd197, %rd127, %rd163;
	add.s64 	%rd198, %rd197, %rd193;
	add.s64 	%rd199, %rd198, %rd166;
	ld.global.nc.f32 	%f39, [%rd199];
	mul.rn.f32 	%f40, %f39, 0f41400000;
	setp.eq.s32 	%p11, %r27, %r5;
	selp.f32 	%f41, 0f42F00000, 0f00000000, %p11;
	add.rn.f32 	%f42, %f40, %f41;
	mul.wide.u32 	%rd200, %r27, 24;
	add.s64 	%rd201, %rd128, %rd172;
	add.s64 	%rd202, %rd201, %rd200;
	add.s64 	%rd203, %rd202, %rd166;
	ld.global.nc.f32 	%f43, [%rd203];
	mul.rn.f32 	%f44, %f43, 0f41F00000;
	add.s64 	%rd204, %rd129, %rd172;
	add.s64 	%rd205, %rd204, %rd200;
	add.s64 	%rd206, %rd205, %rd166;
	ld.global.nc.f32 	%f45, [%rd206];
	mul.rn.f32 	%f46, %f45, 0f45520000;
	add.rn.f32 	%f47, %f44, %f46;
	selp.f32 	%f48, 0f46EC4000, 0f00000000, %p11;
	add.rn.f32 	%f49, %f48, %f47;
	add.s64 	%rd207, %rd130, %rd172;
	add.s64 	%rd208, %rd207, %rd200;
	add.s64 	%rd209, %rd208, %rd166;
	ld.global.nc.f32 	%f50, [%rd209];
	mul.rn.f32 	%f51, %f50, 0f42600000;
	add.s64 	%rd210, %rd131, %rd172;
	add.s64 	%rd211, %rd210, %rd200;
	add.s64 	%rd212, %rd211, %rd166;
	ld.global.nc.f32 	%f52, [%rd212];
	mul.rn.f32 	%f53, %f52, 0f46C4E000;
	add.rn.f32 	%f54, %f51, %f53;
	add.s64 	%rd213, %rd132, %rd172;
	add.s64 	%rd214, %rd213, %rd200;
	add.s64 	%rd215, %rd214, %rd166;
	ld.global.nc.f32 	%f55, [%rd215];
	mul.rn.f32 	%f56, %f55, 0f49F3A200;
	add.rn.f32 	%f57, %f54, %f56;
	selp.f32 	%f58, 0f4B83F7C0, 0f00000000, %p11;
	add.rn.f32 	%f59, %f58, %f57;
	selp.f32 	%f60, %f49, %f59, %p10;
	selp.f32 	%f61, %f42, %f60, %p9;
	add.rn.f32 	%f62, %f38, %f61;
	add.s64 	%rd216, %rd123, %rd149;
	ld.global.nc.u32 	%r31, [%rd216];
	setp.lt.s32 	%p12, %r31, %r8;
	add.s64 	%rd217, %rd124, %rd152;
	ld.global.f32 	%f63, [%rd217];
	selp.f32 	%f64, 0f7FC00000, %f63, %p12;
	add.s64 	%rd218, %rd121, %rd149;
	ld.global.nc.u32 	%r32, [%rd218];
	setp.lt.s32 	%p13, %r32, %r8;
	add.s64 	%rd219, %rd122, %rd152;
	ld.global.f32 	%f65, [%rd219];
	selp.f32 	%f66, 0f7FC00000, %f65, %p13;
	add.s64 	%rd220, %rd119, %rd149;
	ld.global.nc.u32 	%r33, [%rd220];
	setp.lt.s32 	%p14, %r33, %r8;
	add.s64 	%rd221, %rd120, %rd152;
	ld.global.f32 	%f67, [%rd221];
	selp.f32 	%f68, 0f7FC00000, %f67, %p14;
	add.s64 	%rd222, %rd117, %rd149;
	ld.global.nc.u32 	%r34, [%rd222];
	setp.lt.s32 	%p15, %r34, %r8;
	add.s64 	%rd223, %rd118, %rd152;
	ld.global.f32 	%f69, [%rd223];
	selp.f32 	%f70, 0f7FC00000, %f69, %p15;
	add.s64 	%rd224, %rd116, %rd155;
	add.s64 	%rd225, %rd224, %rd154;
	ld.global.nc.u32 	%r35, [%rd225];
	setp.lt.s32 	%p16, %r35, 0;
	add.s32 	%r36, %r35, 6;
	selp.b32 	%r37, %r36, %r35, %p16;
	max.s32 	%r38, %r37, 0;
	min.s32 	%r39, %r38, 5;
	add.s64 	%rd226, %rd102, %rd158;
	ld.global.nc.u32 	%r40, [%rd226];
	max.s32 	%r41, %r17, %r40;
	min.s32 	%r42, %r19, %r41;
	setp.lt.s32 	%p17, %r42, 1;
	mul.wide.u32 	%rd227, %r39, 72;
	add.s64 	%rd228, %rd105, %rd163;
	add.s64 	%rd229, %rd228, %rd227;
	add.s64 	%rd230, %rd229, %rd166;
	ld.global.nc.f32 	%f71, [%rd230];
	setp.lt.s32 	%p18, %r41, %r19;
	ld.global.nc.f32 	%f72, [%rd230+24];
	ld.global.nc.f32 	%f73, [%rd230+48];
	selp.f32 	%f74, %f72, %f73, %p18;
	selp.f32 	%f75, %f71, %f74, %p17;
	add.s64 	%rd231, %rd108, %rd163;
	add.s64 	%rd232, %rd231, %rd227;
	add.s64 	%rd233, %rd232, %rd166;
	ld.global.nc.f32 	%f76, [%rd233];
	mul.rn.f32 	%f77, %f76, 0f41400000;
	setp.eq.s32 	%p19, %r39, %r5;
	selp.f32 	%f78, 0f42F00000, 0f00000000, %p19;
	add.rn.f32 	%f79, %f77, %f78;
	mul.wide.u32 	%rd234, %r39, 24;
	add.s64 	%rd235, %rd111, %rd172;
	add.s64 	%rd236, %rd235, %rd234;
	add.s64 	%rd237, %rd236, %rd166;
	ld.global.nc.f32 	%f80, [%rd237];
	mul.rn.f32 	%f81, %f80, 0f41F00000;
	add.s64 	%rd238, %rd112, %rd172;
	add.s64 	%rd239, %rd238, %rd234;
	add.s64 	%rd240, %rd239, %rd166;
	ld.global.nc.f32 	%f82, [%rd240];
	mul.rn.f32 	%f83, %f82, 0f45520000;
	add.rn.f32 	%f84, %f81, %f83;
	selp.f32 	%f85, 0f46EC4000, 0f00000000, %p19;
	add.rn.f32 	%f86, %f85, %f84;
	add.s64 	%rd241, %rd113, %rd172;
	add.s64 	%rd242, %rd241, %rd234;
	add.s64 	%rd243, %rd242, %rd166;
	ld.global.nc.f32 	%f87, [%rd243];
	mul.rn.f32 	%f88, %f87, 0f42600000;
	add.s64 	%rd244, %rd114, %rd172;
	add.s64 	%rd245, %rd244, %rd234;
	add.s64 	%rd246, %rd245, %rd166;
	ld.global.nc.f32 	%f89, [%rd246];
	mul.rn.f32 	%f90, %f89, 0f46C4E000;
	add.rn.f32 	%f91, %f88, %f90;
	add.s64 	%rd247, %rd115, %rd172;
	add.s64 	%rd248, %rd247, %rd234;
	add.s64 	%rd249, %rd248, %rd166;
	ld.global.nc.f32 	%f92, [%rd249];
	mul.rn.f32 	%f93, %f92, 0f49F3A200;
	add.rn.f32 	%f94, %f91, %f93;
	selp.f32 	%f95, 0f4B83F7C0, 0f00000000, %p19;
	add.rn.f32 	%f96, %f95, %f94;
	selp.f32 	%f97, %f86, %f96, %p18;
	selp.f32 	%f98, %f79, %f97, %p17;
	add.rn.f32 	%f99, %f75, %f98;
	add.s64 	%rd250, %rd99, %rd155;
	add.s64 	%rd251, %rd250, %rd154;
	ld.global.nc.u32 	%r43, [%rd251];
	setp.lt.s32 	%p20, %r43, 0;
	add.s32 	%r44, %r43, 6;
	selp.b32 	%r45, %r44, %r43, %p20;
	max.s32 	%r46, %r45, 0;
	min.s32 	%r47, %r46, 5;
	add.s64 	%rd252, %rd75, %rd158;
	ld.global.nc.u32 	%r48, [%rd252];
	max.s32 	%r49, %r17, %r48;
	min.s32 	%r50, %r19, %r49;
	setp.lt.s32 	%p21, %r50, 1;
	mul.wide.u32 	%rd253, %r47, 72;
	add.s64 	%rd254, %rd78, %rd163;
	add.s64 	%rd255, %rd254, %rd253;
	add.s64 	%rd256, %rd255, %rd166;
	ld.global.nc.f32 	%f100, [%rd256];
	setp.lt.s32 	%p22, %r49, %r19;
	ld.global.nc.f32 	%f101, [%rd256+24];
	ld.global.nc.f32 	%f102, [%rd256+48];
	selp.f32 	%f103, %f101, %f102, %p22;
	selp.f32 	%f104, %f100, %f103, %p21;
	add.s64 	%rd257, %rd81, %rd163;
	add.s64 	%rd258, %rd257, %rd253;
	add.s64 	%rd259, %rd258, %rd166;
	ld.global.nc.f32 	%f105, [%rd259];
	mul.rn.f32 	%f106, %f105, 0f41400000;
	setp.eq.s32 	%p23, %r47, %r5;
	selp.f32 	%f107, 0f42F00000, 0f00000000, %p23;
	add.rn.f32 	%f108, %f106, %f107;
	mul.wide.u32 	%rd260, %r47, 24;
	add.s64 	%rd261, %rd84, %rd172;
	add.s64 	%rd262, %rd261, %rd260;
	add.s64 	%rd263, %rd262, %rd166;
	ld.global.nc.f32 	%f109, [%rd263];
	mul.rn.f32 	%f110, %f109, 0f41F00000;
	add.s64 	%rd264, %rd87, %rd172;
	add.s64 	%rd265, %rd264, %rd260;
	add.s64 	%rd266, %rd265, %rd166;
	ld.global.nc.f32 	%f111, [%rd266];
	mul.rn.f32 	%f112, %f111, 0f45520000;
	add.rn.f32 	%f113, %f110, %f112;
	selp.f32 	%f114, 0f46EC4000, 0f00000000, %p23;
	add.rn.f32 	%f115, %f114, %f113;
	add.s64 	%rd267, %rd90, %rd172;
	add.s64 	%rd268, %rd267, %rd260;
	add.s64 	%rd269, %rd268, %rd166;
	ld.global.nc.f32 	%f116, [%rd269];
	mul.rn.f32 	%f117, %f116, 0f42600000;
	add.s64 	%rd270, %rd93, %rd172;
	add.s64 	%rd271, %rd270, %rd260;
	add.s64 	%rd272, %rd271, %rd166;
	ld.global.nc.f32 	%f118, [%rd272];
	mul.rn.f32 	%f119, %f118, 0f46C4E000;
	add.rn.f32 	%f120, %f117, %f119;
	add.s64 	%rd273, %rd96, %rd172;
	add.s64 	%rd274, %rd273, %rd260;
	add.s64 	%rd275, %rd274, %rd166;
	ld.global.nc.f32 	%f121, [%rd275];
	mul.rn.f32 	%f122, %f121, 0f49F3A200;
	add.rn.f32 	%f123, %f120, %f122;
	selp.f32 	%f124, 0f4B83F7C0, 0f00000000, %p23;
	add.rn.f32 	%f125, %f124, %f123;
	selp.f32 	%f126, %f115, %f125, %p22;
	selp.f32 	%f127, %f108, %f126, %p21;
	add.rn.f32 	%f128, %f104, %f127;
	add.s64 	%rd276, %rd72, %rd155;
	add.s64 	%rd277, %rd276, %rd154;
	ld.global.nc.u32 	%r51, [%rd277];
	setp.lt.s32 	%p24, %r51, 0;
	add.s32 	%r52, %r51, 6;
	selp.b32 	%r53, %r52, %r51, %p24;
	max.s32 	%r54, %r53, 0;
	min.s32 	%r55, %r54, 5;
	add.s64 	%rd278, %rd48, %rd158;
	ld.global.nc.u32 	%r56, [%rd278];
	max.s32 	%r57, %r17, %r56;
	min.s32 	%r58, %r19, %r57;
	setp.lt.s32 	%p25, %r58, 1;
	mul.wide.u32 	%rd279, %r55, 72;
	add.s64 	%rd280, %rd51, %rd163;
	add.s64 	%rd281, %rd280, %rd279;
	add.s64 	%rd282, %rd281, %rd166;
	ld.global.nc.f32 	%f129, [%rd282];
	setp.lt.s32 	%p26, %r57, %r19;
	ld.global.nc.f32 	%f130, [%rd282+24];
	ld.global.nc.f32 	%f131, [%rd282+48];
	selp.f32 	%f132, %f130, %f131, %p26;
	selp.f32 	%f133, %f129, %f132, %p25;
	add.s64 	%rd283, %rd54, %rd163;
	add.s64 	%rd284, %rd283, %rd279;
	add.s64 	%rd285, %rd284, %rd166;
	ld.global.nc.f32 	%f134, [%rd285];
	mul.rn.f32 	%f135, %f134, 0f41400000;
	setp.eq.s32 	%p27, %r55, %r5;
	selp.f32 	%f136, 0f42F00000, 0f00000000, %p27;
	add.rn.f32 	%f137, %f135, %f136;
	mul.wide.u32 	%rd286, %r55, 24;
	add.s64 	%rd287, %rd57, %rd172;
	add.s64 	%rd288, %rd287, %rd286;
	add.s64 	%rd289, %rd288, %rd166;
	ld.global.nc.f32 	%f138, [%rd289];
	mul.rn.f32 	%f139, %f138, 0f41F00000;
	add.s64 	%rd290, %rd60, %rd172;
	add.s64 	%rd291, %rd290, %rd286;
	add.s64 	%rd292, %rd291, %rd166;
	ld.global.nc.f32 	%f140, [%rd292];
	mul.rn.f32 	%f141, %f140, 0f45520000;
	add.rn.f32 	%f142, %f139, %f141;
	selp.f32 	%f143, 0f46EC4000, 0f00000000, %p27;
	add.rn.f32 	%f144, %f143, %f142;
	add.s64 	%rd293, %rd63, %rd172;
	add.s64 	%rd294, %rd293, %rd286;
	add.s64 	%rd295, %rd294, %rd166;
	ld.global.nc.f32 	%f145, [%rd295];
	mul.rn.f32 	%f146, %f145, 0f42600000;
	add.s64 	%rd296, %rd66, %rd172;
	add.s64 	%rd297, %rd296, %rd286;
	add.s64 	%rd298, %rd297, %rd166;
	ld.global.nc.f32 	%f147, [%rd298];
	mul.rn.f32 	%f148, %f147, 0f46C4E000;
	add.rn.f32 	%f149, %f146, %f148;
	add.s64 	%rd299, %rd69, %rd172;
	add.s64 	%rd300, %rd299, %rd286;
	add.s64 	%rd301, %rd300, %rd166;
	ld.global.nc.f32 	%f150, [%rd301];
	mul.rn.f32 	%f151, %f150, 0f49F3A200;
	add.rn.f32 	%f152, %f149, %f151;
	selp.f32 	%f153, 0f4B83F7C0, 0f00000000, %p27;
	add.rn.f32 	%f154, %f153, %f152;
	selp.f32 	%f155, %f144, %f154, %p26;
	selp.f32 	%f156, %f137, %f155, %p25;
	add.rn.f32 	%f157, %f133, %f156;
	add.s64 	%rd302, %rd45, %rd155;
	add.s64 	%rd303, %rd302, %rd154;
	ld.global.nc.u32 	%r59, [%rd303];
	setp.lt.s32 	%p28, %r59, 0;
	add.s32 	%r60, %r59, 6;
	selp.b32 	%r61, %r60, %r59, %p28;
	max.s32 	%r62, %r61, 0;
	min.s32 	%r63, %r62, 5;
	add.s64 	%rd304, %rd21, %rd158;
	ld.global.nc.u32 	%r64, [%rd304];
	max.s32 	%r65, %r17, %r64;
	min.s32 	%r66, %r19, %r65;
	setp.lt.s32 	%p29, %r66, 1;
	mul.wide.u32 	%rd305, %r63, 72;
	add.s64 	%rd306, %rd24, %rd163;
	add.s64 	%rd307, %rd306, %rd305;
	add.s64 	%rd308, %rd307, %rd166;
	ld.global.nc.f32 	%f158, [%rd308];
	setp.lt.s32 	%p30, %r65, %r19;
	ld.global.nc.f32 	%f159, [%rd308+24];
	ld.global.nc.f32 	%f160, [%rd308+48];
	selp.f32 	%f161, %f159, %f160, %p30;
	selp.f32 	%f162, %f158, %f161, %p29;
	add.s64 	%rd309, %rd27, %rd163;
	add.s64 	%rd310, %rd309, %rd305;
	add.s64 	%rd311, %rd310, %rd166;
	ld.global.nc.f32 	%f163, [%rd311];
	mul.rn.f32 	%f164, %f163, 0f41400000;
	setp.eq.s32 	%p31, %r63, %r5;
	selp.f32 	%f165, 0f42F00000, 0f00000000, %p31;
	add.rn.f32 	%f166, %f164, %f165;
	mul.wide.u32 	%rd312, %r63, 24;
	add.s64 	%rd313, %rd30, %rd172;
	add.s64 	%rd314, %rd313, %rd312;
	add.s64 	%rd315, %rd314, %rd166;
	ld.global.nc.f32 	%f167, [%rd315];
	mul.rn.f32 	%f168, %f167, 0f41F00000;
	add.s64 	%rd316, %rd33, %rd172;
	add.s64 	%rd317, %rd316, %rd312;
	add.s64 	%rd318, %rd317, %rd166;
	ld.global.nc.f32 	%f169, [%rd318];
	mul.rn.f32 	%f170, %f169, 0f45520000;
	add.rn.f32 	%f171, %f168, %f170;
	selp.f32 	%f172, 0f46EC4000, 0f00000000, %p31;
	add.rn.f32 	%f173, %f172, %f171;
	add.s64 	%rd319, %rd36, %rd172;
	add.s64 	%rd320, %rd319, %rd312;
	add.s64 	%rd321, %rd320, %rd166;
	ld.global.nc.f32 	%f174, [%rd321];
	mul.rn.f32 	%f175, %f174, 0f42600000;
	add.s64 	%rd322, %rd39, %rd172;
	add.s64 	%rd323, %rd322, %rd312;
	add.s64 	%rd324, %rd323, %rd166;
	ld.global.nc.f32 	%f176, [%rd324];
	mul.rn.f32 	%f177, %f176, 0f46C4E000;
	add.rn.f32 	%f178, %f175, %f177;
	add.s64 	%rd325, %rd42, %rd172;
	add.s64 	%rd326, %rd325, %rd312;
	add.s64 	%rd327, %rd326, %rd166;
	ld.global.nc.f32 	%f179, [%rd327];
	mul.rn.f32 	%f180, %f179, 0f49F3A200;
	add.rn.f32 	%f181, %f178, %f180;
	selp.f32 	%f182, 0f4B83F7C0, 0f00000000, %p31;
	add.rn.f32 	%f183, %f182, %f181;
	selp.f32 	%f184, %f173, %f183, %p30;
	selp.f32 	%f185, %f166, %f184, %p29;
	add.rn.f32 	%f186, %f162, %f185;
	st.global.f32 	[%rd153], %f2;
	add.s64 	%rd328, %rd18, %rd152;
	st.global.f32 	[%rd328], %f31;
	st.global.f32 	[%rd189], %f33;
	add.s64 	%rd329, %rd15, %rd152;
	st.global.f32 	[%rd329], %f62;
	st.global.f32 	[%rd217], %f64;
	st.global.f32 	[%rd219], %f66;
	st.global.f32 	[%rd221], %f68;
	st.global.f32 	[%rd223], %f70;
	add.s64 	%rd330, %rd12, %rd152;
	st.global.f32 	[%rd330], %f99;
	add.s64 	%rd331, %rd9, %rd152;
	st.global.f32 	[%rd331], %f128;
	add.s64 	%rd332, %rd6, %rd152;
	st.global.f32 	[%rd332], %f157;
	add.s64 	%rd333, %rd3, %rd152;
	st.global.f32 	[%rd333], %f186;
	ret;

}
	// .globl	loop_transpose_fusion_102
.visible .entry loop_transpose_fusion_102(
	.param .u64 loop_transpose_fusion_102_param_0,
	.param .u64 loop_transpose_fusion_102_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd1, [loop_transpose_fusion_102_param_0];
	ld.param.u64 	%rd2, [loop_transpose_fusion_102_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd5, %r5, 24;
	cvt.u32.u16 	%r6, %rs3;
	mul.wide.u32 	%rd6, %r6, 144;
	add.s64 	%rd7, %rd4, %rd6;
	add.s64 	%rd8, %rd7, %rd5;
	cvt.u32.u16 	%r7, %rs8;
	mul.wide.u32 	%rd9, %r7, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd3, %rd11;
	st.global.f32 	[%rd12], %f1;
	ret;

}
	// .globl	loop_broadcast_fusion_25
.visible .entry loop_broadcast_fusion_25(
	.param .u64 loop_broadcast_fusion_25_param_0,
	.param .u64 loop_broadcast_fusion_25_param_1,
	.param .u64 loop_broadcast_fusion_25_param_2,
	.param .u64 loop_broadcast_fusion_25_param_3,
	.param .u64 loop_broadcast_fusion_25_param_4,
	.param .u64 loop_broadcast_fusion_25_param_5,
	.param .u64 loop_broadcast_fusion_25_param_6,
	.param .u64 loop_broadcast_fusion_25_param_7,
	.param .u64 loop_broadcast_fusion_25_param_8,
	.param .u64 loop_broadcast_fusion_25_param_9,
	.param .u64 loop_broadcast_fusion_25_param_10,
	.param .u64 loop_broadcast_fusion_25_param_11
)
.reqntid 1024, 1, 1
{
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<38>;

	ld.param.u64 	%rd1, [loop_broadcast_fusion_25_param_0];
	ld.param.u64 	%rd2, [loop_broadcast_fusion_25_param_11];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_broadcast_fusion_25_param_1];
	ld.param.u64 	%rd5, [loop_broadcast_fusion_25_param_10];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_broadcast_fusion_25_param_2];
	ld.param.u64 	%rd8, [loop_broadcast_fusion_25_param_9];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_broadcast_fusion_25_param_3];
	ld.param.u64 	%rd11, [loop_broadcast_fusion_25_param_8];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_broadcast_fusion_25_param_4];
	ld.param.u64 	%rd14, [loop_broadcast_fusion_25_param_7];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_broadcast_fusion_25_param_5];
	ld.param.u64 	%rd17, [loop_broadcast_fusion_25_param_6];
	cvta.to.global.u64 	%rd18, %rd17;
	cvta.to.global.u64 	%rd19, %rd16;
	cvta.to.global.u64 	%rd20, %rd13;
	cvta.to.global.u64 	%rd21, %rd10;
	cvta.to.global.u64 	%rd22, %rd7;
	cvta.to.global.u64 	%rd23, %rd4;
	cvta.to.global.u64 	%rd24, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 10;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u64.u32 	%rd25, %r4;
	add.s64 	%rd26, %rd24, %rd25;
	mov.u16 	%rs1, 0;
	st.global.u8 	[%rd26], %rs1;
	add.s64 	%rd27, %rd23, %rd25;
	st.global.u8 	[%rd27], %rs1;
	add.s64 	%rd28, %rd22, %rd25;
	st.global.u8 	[%rd28], %rs1;
	add.s64 	%rd29, %rd21, %rd25;
	st.global.u8 	[%rd29], %rs1;
	add.s64 	%rd30, %rd20, %rd25;
	st.global.u8 	[%rd30], %rs1;
	add.s64 	%rd31, %rd19, %rd25;
	st.global.u8 	[%rd31], %rs1;
	add.s64 	%rd32, %rd18, %rd25;
	st.global.u8 	[%rd32], %rs1;
	add.s64 	%rd33, %rd15, %rd25;
	st.global.u8 	[%rd33], %rs1;
	add.s64 	%rd34, %rd12, %rd25;
	st.global.u8 	[%rd34], %rs1;
	add.s64 	%rd35, %rd9, %rd25;
	st.global.u8 	[%rd35], %rs1;
	add.s64 	%rd36, %rd6, %rd25;
	st.global.u8 	[%rd36], %rs1;
	add.s64 	%rd37, %rd3, %rd25;
	st.global.u8 	[%rd37], %rs1;
	ret;

}
	// .globl	loop_broadcast_fusion_26
.visible .entry loop_broadcast_fusion_26(
	.param .u64 loop_broadcast_fusion_26_param_0,
	.param .u64 loop_broadcast_fusion_26_param_1,
	.param .u64 loop_broadcast_fusion_26_param_2,
	.param .u64 loop_broadcast_fusion_26_param_3,
	.param .u64 loop_broadcast_fusion_26_param_4,
	.param .u64 loop_broadcast_fusion_26_param_5
)
.reqntid 1024, 1, 1
{
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<20>;

	ld.param.u64 	%rd1, [loop_broadcast_fusion_26_param_0];
	ld.param.u64 	%rd2, [loop_broadcast_fusion_26_param_5];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_broadcast_fusion_26_param_1];
	ld.param.u64 	%rd5, [loop_broadcast_fusion_26_param_4];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_broadcast_fusion_26_param_2];
	ld.param.u64 	%rd8, [loop_broadcast_fusion_26_param_3];
	cvta.to.global.u64 	%rd9, %rd8;
	cvta.to.global.u64 	%rd10, %rd7;
	cvta.to.global.u64 	%rd11, %rd4;
	cvta.to.global.u64 	%rd12, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 10;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd12, %rd13;
	mov.b32 	%r5, 0;
	st.global.u32 	[%rd14], %r5;
	add.s64 	%rd15, %rd11, %rd13;
	st.global.u32 	[%rd15], %r5;
	add.s64 	%rd16, %rd10, %rd13;
	st.global.u32 	[%rd16], %r5;
	add.s64 	%rd17, %rd9, %rd13;
	st.global.u32 	[%rd17], %r5;
	add.s64 	%rd18, %rd6, %rd13;
	st.global.u32 	[%rd18], %r5;
	add.s64 	%rd19, %rd3, %rd13;
	st.global.u32 	[%rd19], %r5;
	ret;

}
	// .globl	loop_broadcast_fusion_27
.visible .entry loop_broadcast_fusion_27(
	.param .u64 loop_broadcast_fusion_27_param_0,
	.param .u64 loop_broadcast_fusion_27_param_1,
	.param .u64 loop_broadcast_fusion_27_param_2,
	.param .u64 loop_broadcast_fusion_27_param_3,
	.param .u64 loop_broadcast_fusion_27_param_4,
	.param .u64 loop_broadcast_fusion_27_param_5
)
.reqntid 1024, 1, 1
{
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<20>;

	ld.param.u64 	%rd1, [loop_broadcast_fusion_27_param_0];
	ld.param.u64 	%rd2, [loop_broadcast_fusion_27_param_5];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_broadcast_fusion_27_param_1];
	ld.param.u64 	%rd5, [loop_broadcast_fusion_27_param_4];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_broadcast_fusion_27_param_2];
	ld.param.u64 	%rd8, [loop_broadcast_fusion_27_param_3];
	cvta.to.global.u64 	%rd9, %rd8;
	cvta.to.global.u64 	%rd10, %rd7;
	cvta.to.global.u64 	%rd11, %rd4;
	cvta.to.global.u64 	%rd12, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 10;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd12, %rd13;
	mov.b32 	%r5, 0;
	st.global.u32 	[%rd14], %r5;
	add.s64 	%rd15, %rd11, %rd13;
	st.global.u32 	[%rd15], %r5;
	add.s64 	%rd16, %rd10, %rd13;
	st.global.u32 	[%rd16], %r5;
	add.s64 	%rd17, %rd9, %rd13;
	st.global.u32 	[%rd17], %r5;
	add.s64 	%rd18, %rd6, %rd13;
	st.global.u32 	[%rd18], %r5;
	add.s64 	%rd19, %rd3, %rd13;
	st.global.u32 	[%rd19], %r5;
	ret;

}
	// .globl	wrapped_iota_12
.visible .entry wrapped_iota_12(
	.param .u64 wrapped_iota_12_param_0
)
.reqntid 16, 1, 1
{
	.reg .b32 	%r<2>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [wrapped_iota_12_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %tid.x;
	cvt.rn.f32.u32 	%f1, %r1;
	mul.wide.u32 	%rd3, %r1, 4;
	add.s64 	%rd4, %rd2, %rd3;
	st.global.f32 	[%rd4], %f1;
	ret;

}
	// .globl	loop_compare_fusion
.visible .entry loop_compare_fusion(
	.param .u64 loop_compare_fusion_param_0,
	.param .u64 loop_compare_fusion_param_1
)
.reqntid 1, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [loop_compare_fusion_param_0];
	ld.param.u64 	%rd2, [loop_compare_fusion_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	ld.global.nc.u32 	%r1, [%rd4];
	setp.lt.s32 	%p1, %r1, 16;
	selp.u16 	%rs1, 1, 0, %p1;
	st.global.u8 	[%rd3], %rs1;
	ret;

}
	// .globl	loop_dynamic_update_slice_fusion_44
.visible .entry loop_dynamic_update_slice_fusion_44(
	.param .u64 loop_dynamic_update_slice_fusion_44_param_0,
	.param .u64 loop_dynamic_update_slice_fusion_44_param_1,
	.param .u64 loop_dynamic_update_slice_fusion_44_param_2
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<17>;

	ld.param.u64 	%rd1, [loop_dynamic_update_slice_fusion_44_param_0];
	ld.param.u64 	%rd2, [loop_dynamic_update_slice_fusion_44_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_dynamic_update_slice_fusion_44_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	and.b16  	%rs4, %rs3, 63;
	mul.hi.u16 	%rs5, %rs1, -21845;
	shr.u16 	%rs6, %rs5, 2;
	mul.hi.u16 	%rs7, %rs6, 10923;
	mul.lo.s16 	%rs8, %rs7, 6;
	sub.s16 	%rs9, %rs6, %rs8;
	mul.lo.s16 	%rs10, %rs6, 6;
	sub.s16 	%rs11, %rs1, %rs10;
	ld.global.nc.u32 	%r5, [%rd3];
	shr.u32 	%r6, %r5, 27;
	and.b32  	%r7, %r6, 16;
	add.s32 	%r8, %r7, %r5;
	max.s32 	%r9, %r8, 0;
	min.s32 	%r10, %r9, 15;
	mul.wide.u32 	%rd7, %r4, 4;
	add.s64 	%rd8, %rd5, %rd7;
	ld.global.nc.f32 	%f1, [%rd8];
	mul.wide.u32 	%rd9, %r10, 9216;
	add.s64 	%rd10, %rd6, %rd9;
	cvt.u32.u16 	%r11, %rs4;
	mul.wide.u32 	%rd11, %r11, 144;
	add.s64 	%rd12, %rd10, %rd11;
	cvt.u32.u16 	%r12, %rs9;
	mul.wide.u32 	%rd13, %r12, 24;
	add.s64 	%rd14, %rd12, %rd13;
	cvt.u32.u16 	%r13, %rs11;
	mul.wide.u32 	%rd15, %r13, 4;
	add.s64 	%rd16, %rd14, %rd15;
	st.global.f32 	[%rd16], %f1;
	ret;

}
	// .globl	loop_select_fusion_57
.visible .entry loop_select_fusion_57(
	.param .u64 loop_select_fusion_57_param_0,
	.param .u64 loop_select_fusion_57_param_1,
	.param .u64 loop_select_fusion_57_param_2,
	.param .u64 loop_select_fusion_57_param_3,
	.param .u64 loop_select_fusion_57_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<12>;
	.reg .f32 	%f<6>;
	.reg .b64 	%rd<18>;

	ld.param.u64 	%rd1, [loop_select_fusion_57_param_0];
	ld.param.u64 	%rd2, [loop_select_fusion_57_param_4];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_select_fusion_57_param_1];
	ld.param.u64 	%rd5, [loop_select_fusion_57_param_3];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_select_fusion_57_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	cvta.to.global.u64 	%rd9, %rd4;
	cvta.to.global.u64 	%rd10, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	ld.global.nc.u32 	%r5, [%rd3];
	shr.u32 	%r6, %r5, 27;
	and.b32  	%r7, %r6, 16;
	add.s32 	%r8, %r7, %r5;
	max.s32 	%r9, %r8, 0;
	min.s32 	%r10, %r9, 15;
	mul.wide.u32 	%rd11, %r10, 4;
	add.s64 	%rd12, %rd6, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	cvt.u32.u16 	%r11, %rs3;
	mul.wide.u32 	%rd13, %r11, 4;
	add.s64 	%rd14, %rd8, %rd13;
	ld.global.nc.f32 	%f2, [%rd14];
	setp.lt.f32 	%p1, %f1, %f2;
	mul.wide.u32 	%rd15, %r4, 4;
	add.s64 	%rd16, %rd10, %rd15;
	ld.global.f32 	%f3, [%rd16];
	add.s64 	%rd17, %rd9, %rd15;
	ld.global.nc.f32 	%f4, [%rd17];
	selp.f32 	%f5, %f4, %f3, %p1;
	st.global.f32 	[%rd16], %f5;
	ret;

}
	// .globl	loop_dynamic_update_slice_fusion_45
.visible .entry loop_dynamic_update_slice_fusion_45(
	.param .u64 loop_dynamic_update_slice_fusion_45_param_0,
	.param .u64 loop_dynamic_update_slice_fusion_45_param_1,
	.param .u64 loop_dynamic_update_slice_fusion_45_param_2,
	.param .u64 loop_dynamic_update_slice_fusion_45_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<15>;
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<21>;

	ld.param.u64 	%rd1, [loop_dynamic_update_slice_fusion_45_param_0];
	ld.param.u64 	%rd2, [loop_dynamic_update_slice_fusion_45_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_dynamic_update_slice_fusion_45_param_1];
	ld.param.u64 	%rd5, [loop_dynamic_update_slice_fusion_45_param_2];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	and.b16  	%rs4, %rs3, 63;
	mul.hi.u16 	%rs5, %rs1, -21845;
	shr.u16 	%rs6, %rs5, 2;
	mul.hi.u16 	%rs7, %rs6, 10923;
	mul.lo.s16 	%rs8, %rs7, 6;
	sub.s16 	%rs9, %rs6, %rs8;
	mul.lo.s16 	%rs10, %rs6, 6;
	sub.s16 	%rs11, %rs1, %rs10;
	ld.global.nc.u32 	%r5, [%rd7];
	shr.u32 	%r6, %r5, 27;
	and.b32  	%r7, %r6, 16;
	add.s32 	%r8, %r7, %r5;
	max.s32 	%r9, %r8, 0;
	min.s32 	%r10, %r9, 15;
	mul.wide.u32 	%rd9, %r10, 4;
	add.s64 	%rd10, %rd3, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	cvt.u32.u16 	%r11, %rs4;
	mul.wide.u32 	%rd11, %r11, 4;
	add.s64 	%rd12, %rd6, %rd11;
	ld.global.nc.f32 	%f2, [%rd12];
	setp.lt.f32 	%p1, %f1, %f2;
	selp.u32 	%r12, 1, 0, %p1;
	mul.wide.u32 	%rd13, %r10, 9216;
	add.s64 	%rd14, %rd8, %rd13;
	mul.wide.u32 	%rd15, %r11, 144;
	add.s64 	%rd16, %rd14, %rd15;
	cvt.u32.u16 	%r13, %rs9;
	mul.wide.u32 	%rd17, %r13, 24;
	add.s64 	%rd18, %rd16, %rd17;
	cvt.u32.u16 	%r14, %rs11;
	mul.wide.u32 	%rd19, %r14, 4;
	add.s64 	%rd20, %rd18, %rd19;
	st.global.u32 	[%rd20], %r12;
	ret;

}
	// .globl	loop_dynamic_update_slice_fusion_46
.visible .entry loop_dynamic_update_slice_fusion_46(
	.param .u64 loop_dynamic_update_slice_fusion_46_param_0,
	.param .u64 loop_dynamic_update_slice_fusion_46_param_1,
	.param .u64 loop_dynamic_update_slice_fusion_46_param_2,
	.param .u64 loop_dynamic_update_slice_fusion_46_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<13>;
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<21>;

	ld.param.u64 	%rd1, [loop_dynamic_update_slice_fusion_46_param_0];
	ld.param.u64 	%rd2, [loop_dynamic_update_slice_fusion_46_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_dynamic_update_slice_fusion_46_param_1];
	ld.param.u64 	%rd5, [loop_dynamic_update_slice_fusion_46_param_2];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	and.b16  	%rs4, %rs3, 63;
	mul.hi.u16 	%rs5, %rs1, -21845;
	shr.u16 	%rs6, %rs5, 2;
	mul.hi.u16 	%rs7, %rs6, 10923;
	mul.lo.s16 	%rs8, %rs7, 6;
	sub.s16 	%rs9, %rs6, %rs8;
	mul.lo.s16 	%rs10, %rs6, 6;
	sub.s16 	%rs11, %rs1, %rs10;
	cvt.u64.u16 	%rd9, %rs11;
	ld.global.nc.u32 	%r5, [%rd7];
	shr.u32 	%r6, %r5, 27;
	and.b32  	%r7, %r6, 16;
	add.s32 	%r8, %r7, %r5;
	max.s32 	%r9, %r8, 0;
	min.s32 	%r10, %r9, 15;
	mul.wide.u32 	%rd10, %r10, 4;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.nc.f32 	%f1, [%rd11];
	cvt.u32.u16 	%r11, %rs4;
	mul.wide.u32 	%rd12, %r11, 4;
	add.s64 	%rd13, %rd6, %rd12;
	ld.global.nc.f32 	%f2, [%rd13];
	setp.lt.f32 	%p1, %f1, %f2;
	selp.u16 	%rs12, 1, 0, %p1;
	mul.wide.u32 	%rd14, %r10, 2304;
	add.s64 	%rd15, %rd8, %rd14;
	mul.wide.u32 	%rd16, %r11, 36;
	add.s64 	%rd17, %rd15, %rd16;
	cvt.u32.u16 	%r12, %rs9;
	mul.wide.u32 	%rd18, %r12, 6;
	add.s64 	%rd19, %rd17, %rd18;
	add.s64 	%rd20, %rd19, %rd9;
	st.global.u8 	[%rd20], %rs12;
	ret;

}
	// .globl	loop_dynamic_update_slice_fusion_47
.visible .entry loop_dynamic_update_slice_fusion_47(
	.param .u64 loop_dynamic_update_slice_fusion_47_param_0,
	.param .u64 loop_dynamic_update_slice_fusion_47_param_1,
	.param .u64 loop_dynamic_update_slice_fusion_47_param_2,
	.param .u64 loop_dynamic_update_slice_fusion_47_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<13>;
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<21>;

	ld.param.u64 	%rd1, [loop_dynamic_update_slice_fusion_47_param_0];
	ld.param.u64 	%rd2, [loop_dynamic_update_slice_fusion_47_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_dynamic_update_slice_fusion_47_param_1];
	ld.param.u64 	%rd5, [loop_dynamic_update_slice_fusion_47_param_2];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	and.b16  	%rs4, %rs3, 63;
	mul.hi.u16 	%rs5, %rs1, -21845;
	shr.u16 	%rs6, %rs5, 2;
	mul.hi.u16 	%rs7, %rs6, 10923;
	mul.lo.s16 	%rs8, %rs7, 6;
	sub.s16 	%rs9, %rs6, %rs8;
	mul.lo.s16 	%rs10, %rs6, 6;
	sub.s16 	%rs11, %rs1, %rs10;
	cvt.u64.u16 	%rd9, %rs11;
	ld.global.nc.u32 	%r5, [%rd7];
	shr.u32 	%r6, %r5, 27;
	and.b32  	%r7, %r6, 16;
	add.s32 	%r8, %r7, %r5;
	max.s32 	%r9, %r8, 0;
	min.s32 	%r10, %r9, 15;
	mul.wide.u32 	%rd10, %r10, 4;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.nc.f32 	%f1, [%rd11];
	cvt.u32.u16 	%r11, %rs4;
	mul.wide.u32 	%rd12, %r11, 4;
	add.s64 	%rd13, %rd6, %rd12;
	ld.global.nc.f32 	%f2, [%rd13];
	setp.geu.f32 	%p1, %f1, %f2;
	selp.u16 	%rs12, 1, 0, %p1;
	mul.wide.u32 	%rd14, %r10, 2304;
	add.s64 	%rd15, %rd8, %rd14;
	mul.wide.u32 	%rd16, %r11, 36;
	add.s64 	%rd17, %rd15, %rd16;
	cvt.u32.u16 	%r12, %rs9;
	mul.wide.u32 	%rd18, %r12, 6;
	add.s64 	%rd19, %rd17, %rd18;
	add.s64 	%rd20, %rd19, %rd9;
	st.global.u8 	[%rd20], %rs12;
	ret;

}
	// .globl	loop_select_fusion_32
.visible .entry loop_select_fusion_32(
	.param .u64 loop_select_fusion_32_param_0,
	.param .u64 loop_select_fusion_32_param_1,
	.param .u64 loop_select_fusion_32_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<17>;

	ld.param.u64 	%rd1, [loop_select_fusion_32_param_0];
	ld.param.u64 	%rd2, [loop_select_fusion_32_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_select_fusion_32_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r5, %rs3;
	mul.wide.u32 	%rd7, %r5, 4;
	add.s64 	%rd8, %rd5, %rd7;
	ld.global.nc.f32 	%f1, [%rd8];
	setp.gt.f32 	%p1, %f1, 0f41800000;
	cvt.u32.u16 	%r6, %rs10;
	mul.wide.u32 	%rd9, %r6, 24;
	mul.wide.u32 	%rd10, %r5, 144;
	add.s64 	%rd11, %rd6, %rd10;
	add.s64 	%rd12, %rd11, %rd9;
	cvt.u32.u16 	%r7, %rs8;
	mul.wide.u32 	%rd13, %r7, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.nc.f32 	%f2, [%rd14];
	selp.f32 	%f3, 0f7FC00000, %f2, %p1;
	mul.wide.u32 	%rd15, %r4, 4;
	add.s64 	%rd16, %rd3, %rd15;
	st.global.f32 	[%rd16], %f3;
	ret;

}
	// .globl	loop_exponential_fusion_6
.visible .entry loop_exponential_fusion_6(
	.param .u64 loop_exponential_fusion_6_param_0,
	.param .u64 loop_exponential_fusion_6_param_1,
	.param .u64 loop_exponential_fusion_6_param_2,
	.param .u64 loop_exponential_fusion_6_param_3,
	.param .u64 loop_exponential_fusion_6_param_4,
	.param .u64 loop_exponential_fusion_6_param_5
)
.reqntid 64, 1, 1
{
	.reg .b32 	%r<14>;
	.reg .f32 	%f<69>;
	.reg .b64 	%rd<20>;

	ld.param.u64 	%rd1, [loop_exponential_fusion_6_param_0];
	ld.param.u64 	%rd2, [loop_exponential_fusion_6_param_5];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_exponential_fusion_6_param_1];
	ld.param.u64 	%rd5, [loop_exponential_fusion_6_param_4];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_exponential_fusion_6_param_2];
	ld.param.u64 	%rd8, [loop_exponential_fusion_6_param_3];
	cvta.to.global.u64 	%rd9, %rd8;
	cvta.to.global.u64 	%rd10, %rd7;
	cvta.to.global.u64 	%rd11, %rd4;
	cvta.to.global.u64 	%rd12, %rd1;
	mov.u32 	%r1, %tid.x;
	mul.wide.u32 	%rd13, %r1, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	fma.rn.f32 	%f2, %f1, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f3, %f2;
	mov.f32 	%f4, 0f4B400001;
	mov.f32 	%f5, 0f437C0000;
	fma.rm.f32 	%f6, %f3, %f5, %f4;
	add.rn.f32 	%f7, %f6, 0fCB40007F;
	neg.f32 	%f8, %f7;
	fma.rn.f32 	%f9, %f1, 0f3FB8AA3B, %f8;
	fma.rn.f32 	%f10, %f1, 0f32A57060, %f9;
	mov.b32 	%r2, %f6;
	shl.b32 	%r3, %r2, 23;
	mov.b32 	%f11, %r3;
	ex2.approx.ftz.f32 	%f12, %f10;
	mul.rn.f32 	%f13, %f12, %f11;
	neg.f32 	%f14, %f13;
	sub.rn.f32 	%f15, %f14, %f13;
	add.rn.f32 	%f16, %f15, %f15;
	fma.rn.f32 	%f17, %f16, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f18, %f17;
	fma.rm.f32 	%f19, %f18, %f5, %f4;
	add.rn.f32 	%f20, %f19, 0fCB40007F;
	neg.f32 	%f21, %f20;
	fma.rn.f32 	%f22, %f16, 0f3FB8AA3B, %f21;
	fma.rn.f32 	%f23, %f16, 0f32A57060, %f22;
	mov.b32 	%r4, %f19;
	shl.b32 	%r5, %r4, 23;
	mov.b32 	%f24, %r5;
	ex2.approx.ftz.f32 	%f25, %f23;
	mul.rn.f32 	%f26, %f25, %f24;
	fma.rn.f32 	%f27, %f15, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f28, %f27;
	fma.rm.f32 	%f29, %f28, %f5, %f4;
	add.rn.f32 	%f30, %f29, 0fCB40007F;
	neg.f32 	%f31, %f30;
	fma.rn.f32 	%f32, %f15, 0f3FB8AA3B, %f31;
	fma.rn.f32 	%f33, %f15, 0f32A57060, %f32;
	mov.b32 	%r6, %f29;
	shl.b32 	%r7, %r6, 23;
	mov.b32 	%f34, %r7;
	ex2.approx.ftz.f32 	%f35, %f33;
	mul.rn.f32 	%f36, %f35, %f34;
	fma.rn.f32 	%f37, %f13, 0fBBBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f38, %f37;
	fma.rm.f32 	%f39, %f38, %f5, %f4;
	add.rn.f32 	%f40, %f39, 0fCB40007F;
	neg.f32 	%f41, %f40;
	fma.rn.f32 	%f42, %f13, 0fBFB8AA3B, %f41;
	fma.rn.f32 	%f43, %f13, 0fB2A57060, %f42;
	mov.b32 	%r8, %f39;
	shl.b32 	%r9, %r8, 23;
	mov.b32 	%f44, %r9;
	ex2.approx.ftz.f32 	%f45, %f43;
	mul.rn.f32 	%f46, %f45, %f44;
	add.rn.f32 	%f47, %f16, %f16;
	add.rn.f32 	%f48, %f47, %f47;
	fma.rn.f32 	%f49, %f48, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f50, %f49;
	fma.rm.f32 	%f51, %f50, %f5, %f4;
	add.rn.f32 	%f52, %f51, 0fCB40007F;
	neg.f32 	%f53, %f52;
	fma.rn.f32 	%f54, %f48, 0f3FB8AA3B, %f53;
	fma.rn.f32 	%f55, %f48, 0f32A57060, %f54;
	mov.b32 	%r10, %f51;
	shl.b32 	%r11, %r10, 23;
	mov.b32 	%f56, %r11;
	ex2.approx.ftz.f32 	%f57, %f55;
	mul.rn.f32 	%f58, %f57, %f56;
	fma.rn.f32 	%f59, %f47, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f60, %f59;
	fma.rm.f32 	%f61, %f60, %f5, %f4;
	add.rn.f32 	%f62, %f61, 0fCB40007F;
	neg.f32 	%f63, %f62;
	fma.rn.f32 	%f64, %f47, 0f3FB8AA3B, %f63;
	fma.rn.f32 	%f65, %f47, 0f32A57060, %f64;
	mov.b32 	%r12, %f61;
	shl.b32 	%r13, %r12, 23;
	mov.b32 	%f66, %r13;
	ex2.approx.ftz.f32 	%f67, %f65;
	mul.rn.f32 	%f68, %f67, %f66;
	add.s64 	%rd15, %rd11, %rd13;
	st.global.f32 	[%rd15], %f26;
	add.s64 	%rd16, %rd10, %rd13;
	st.global.f32 	[%rd16], %f36;
	add.s64 	%rd17, %rd9, %rd13;
	st.global.f32 	[%rd17], %f46;
	add.s64 	%rd18, %rd6, %rd13;
	st.global.f32 	[%rd18], %f58;
	add.s64 	%rd19, %rd3, %rd13;
	st.global.f32 	[%rd19], %f68;
	ret;

}
	// .globl	input_reduce_fusion_289
.visible .entry input_reduce_fusion_289(
	.param .u64 input_reduce_fusion_289_param_0,
	.param .u64 input_reduce_fusion_289_param_1
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<20>;
	.reg .b64 	%rd<23>;
	// demoted variable
	.shared .align 4 .b8 shared_cache[32];
	ld.param.u64 	%rd6, [input_reduce_fusion_289_param_0];
	cvta.to.global.u64 	%rd2, %rd6;
	mov.u32 	%r4, %tid.x;
	mov.u32 	%r5, %ctaid.x;
	shr.u32 	%r1, %r4, 5;
	and.b32  	%r2, %r4, 31;
	shl.b32 	%r6, %r5, 3;
	or.b32  	%r7, %r1, %r6;
	cvt.u64.u32 	%rd3, %r7;
	cvt.u16.u32 	%rs1, %r2;
	mul.lo.s16 	%rs2, %rs1, 43;
	shr.u16 	%rs3, %rs2, 8;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs5, 255;
	setp.eq.s16 	%p1, %rs3, %rs6;
	mul.wide.u32 	%rd8, %r7, 144;
	add.s64 	%rd9, %rd2, %rd8;
	cvt.u32.u16 	%r8, %rs3;
	mul.wide.u32 	%rd10, %r8, 24;
	add.s64 	%rd11, %rd9, %rd10;
	cvt.u32.u16 	%r9, %rs5;
	and.b32  	%r10, %r9, 255;
	mul.wide.u32 	%rd12, %r10, 4;
	add.s64 	%rd13, %rd11, %rd12;
	ld.global.nc.f32 	%f5, [%rd13];
	add.rn.f32 	%f6, %f5, 0f00000000;
	selp.f32 	%f19, %f6, 0f00000000, %p1;
	or.b32  	%r3, %r2, 32;
	setp.lt.u32 	%p2, %r3, 36;
	@%p2 bra 	$L__BB37_1;
	bra.uni 	$L__BB37_2;
$L__BB37_1:
	cvt.u16.u32 	%rs7, %r3;
	mul.lo.s16 	%rs8, %rs7, 43;
	shr.u16 	%rs9, %rs8, 8;
	mul.lo.s16 	%rs10, %rs9, 6;
	sub.s16 	%rs11, %rs7, %rs10;
	and.b16  	%rs12, %rs11, 255;
	setp.eq.s16 	%p3, %rs9, %rs12;
	mul.lo.s64 	%rd14, %rd3, 144;
	add.s64 	%rd15, %rd2, %rd14;
	cvt.u32.u16 	%r11, %rs9;
	mul.wide.u32 	%rd16, %r11, 24;
	add.s64 	%rd17, %rd15, %rd16;
	cvt.u32.u16 	%r12, %rs11;
	and.b32  	%r13, %r12, 255;
	mul.wide.u32 	%rd18, %r13, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.nc.f32 	%f7, [%rd19];
	selp.f32 	%f8, %f7, 0f00000000, %p3;
	add.rn.f32 	%f19, %f19, %f8;
$L__BB37_2:
	shfl.sync.down.b32	%f9, %f19, 16, 31, -1;
	add.rn.f32 	%f10, %f19, %f9;
	shfl.sync.down.b32	%f11, %f10, 8, 31, -1;
	add.rn.f32 	%f12, %f10, %f11;
	shfl.sync.down.b32	%f13, %f12, 4, 31, -1;
	add.rn.f32 	%f14, %f12, %f13;
	shfl.sync.down.b32	%f15, %f14, 2, 31, -1;
	add.rn.f32 	%f16, %f14, %f15;
	shfl.sync.down.b32	%f17, %f16, 1, 31, -1;
	setp.eq.s32 	%p4, %r2, 0;
	mul.wide.u32 	%rd20, %r1, 4;
	mov.u64 	%rd21, shared_cache;
	add.s64 	%rd4, %rd21, %rd20;
	@%p4 bra 	$L__BB37_5;
	bra.uni 	$L__BB37_3;
$L__BB37_5:
	add.rn.f32 	%f4, %f16, %f17;
	st.shared.f32 	[%rd4], %f4;
$L__BB37_3:
	bar.sync 	0;
	@%p4 bra 	$L__BB37_6;
	bra.uni 	$L__BB37_4;
$L__BB37_6:
	ld.param.u64 	%rd7, [input_reduce_fusion_289_param_1];
	cvta.to.global.u64 	%rd1, %rd7;
	shl.b64 	%rd22, %rd3, 2;
	add.s64 	%rd5, %rd1, %rd22;
	ld.shared.f32 	%f18, [%rd4];
	st.global.f32 	[%rd5], %f18;
$L__BB37_4:
	ret;

}
	// .globl	loop_multiply_fusion_74
.visible .entry loop_multiply_fusion_74(
	.param .u64 loop_multiply_fusion_74_param_0,
	.param .u64 loop_multiply_fusion_74_param_1,
	.param .u64 loop_multiply_fusion_74_param_2,
	.param .u64 loop_multiply_fusion_74_param_3
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<9>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [loop_multiply_fusion_74_param_0];
	ld.param.u64 	%rd2, [loop_multiply_fusion_74_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_multiply_fusion_74_param_1];
	ld.param.u64 	%rd5, [loop_multiply_fusion_74_param_2];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r1;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 4;
	cvt.u32.u16 	%r5, %rs3;
	mul.wide.u32 	%rd9, %r5, 4;
	add.s64 	%rd10, %rd6, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	mov.f32 	%f2, 0f3F800000;
	sub.rn.f32 	%f3, %f2, %f1;
	add.s64 	%rd11, %rd7, %rd9;
	ld.global.nc.f32 	%f4, [%rd11];
	div.full.f32 	%f5, %f3, %f4;
	sqrt.approx.f32 	%f6, %f5;
	mul.wide.u32 	%rd12, %r4, 4;
	add.s64 	%rd13, %rd8, %rd12;
	ld.global.nc.f32 	%f7, [%rd13];
	mul.rn.f32 	%f8, %f6, %f7;
	add.s64 	%rd14, %rd3, %rd12;
	st.global.f32 	[%rd14], %f8;
	ret;

}
	// .globl	input_reduce_fusion_290
.visible .entry input_reduce_fusion_290(
	.param .u64 input_reduce_fusion_290_param_0,
	.param .u64 input_reduce_fusion_290_param_1,
	.param .u64 input_reduce_fusion_290_param_2,
	.param .u64 input_reduce_fusion_290_param_3,
	.param .u64 input_reduce_fusion_290_param_4
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<15>;
	.reg .f32 	%f<78>;
	.reg .b64 	%rd<53>;
	// demoted variable
	.shared .align 4 .b8 shared_cache1[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache2[4224];
	ld.param.u64 	%rd12, [input_reduce_fusion_290_param_0];
	ld.param.u64 	%rd13, [input_reduce_fusion_290_param_4];
	cvta.to.global.u64 	%rd1, %rd13;
	ld.param.u64 	%rd14, [input_reduce_fusion_290_param_1];
	ld.param.u64 	%rd15, [input_reduce_fusion_290_param_3];
	cvta.to.global.u64 	%rd2, %rd15;
	ld.param.u64 	%rd16, [input_reduce_fusion_290_param_2];
	cvta.to.global.u64 	%rd17, %rd16;
	cvta.to.global.u64 	%rd18, %rd14;
	cvta.to.global.u64 	%rd19, %rd12;
	mov.u32 	%r7, %tid.x;
	mov.u32 	%r8, %ctaid.x;
	shr.u32 	%r1, %r7, 5;
	and.b32  	%r2, %r7, 31;
	shr.u32 	%r9, %r8, 4;
	shl.b32 	%r10, %r8, 5;
	and.b32  	%r3, %r10, 480;
	or.b32  	%r11, %r3, %r2;
	cvt.u64.u32 	%rd3, %r9;
	mul.wide.u32 	%rd20, %r11, 4;
	add.s64 	%rd21, %rd18, %rd20;
	ld.global.nc.f32 	%f1, [%rd21];
	add.s64 	%rd22, %rd19, %rd20;
	ld.global.nc.f32 	%f2, [%rd22];
	add.s32 	%r14, %r1, -256;
	mul.wide.u32 	%rd23, %r9, 4096;
	shr.u32 	%r12, %r7, 3;
	cvt.u64.u32 	%rd24, %r12;
	and.b64  	%rd25, %rd24, 536870908;
	add.s64 	%rd26, %rd23, %rd25;
	add.s64 	%rd27, %rd26, %rd17;
	add.s64 	%rd52, %rd27, 512;
	mov.f32 	%f76, 0f00000000;
	mov.f32 	%f77, %f76;
$L__BB39_1:
	ld.global.nc.f32 	%f10, [%rd52+-512];
	mul.rn.f32 	%f11, %f10, %f1;
	add.rn.f32 	%f12, %f11, %f2;
	add.rn.f32 	%f13, %f77, %f12;
	mul.rn.f32 	%f14, %f12, %f12;
	add.rn.f32 	%f15, %f76, %f14;
	ld.global.nc.f32 	%f16, [%rd52+-384];
	mul.rn.f32 	%f17, %f16, %f1;
	add.rn.f32 	%f18, %f17, %f2;
	add.rn.f32 	%f19, %f13, %f18;
	mul.rn.f32 	%f20, %f18, %f18;
	add.rn.f32 	%f21, %f15, %f20;
	ld.global.nc.f32 	%f22, [%rd52+-256];
	mul.rn.f32 	%f23, %f22, %f1;
	add.rn.f32 	%f24, %f23, %f2;
	add.rn.f32 	%f25, %f19, %f24;
	mul.rn.f32 	%f26, %f24, %f24;
	add.rn.f32 	%f27, %f21, %f26;
	ld.global.nc.f32 	%f28, [%rd52+-128];
	mul.rn.f32 	%f29, %f28, %f1;
	add.rn.f32 	%f30, %f29, %f2;
	add.rn.f32 	%f31, %f25, %f30;
	mul.rn.f32 	%f32, %f30, %f30;
	add.rn.f32 	%f33, %f27, %f32;
	ld.global.nc.f32 	%f34, [%rd52];
	mul.rn.f32 	%f35, %f34, %f1;
	add.rn.f32 	%f36, %f35, %f2;
	add.rn.f32 	%f37, %f31, %f36;
	mul.rn.f32 	%f38, %f36, %f36;
	add.rn.f32 	%f39, %f33, %f38;
	ld.global.nc.f32 	%f40, [%rd52+128];
	mul.rn.f32 	%f41, %f40, %f1;
	add.rn.f32 	%f42, %f41, %f2;
	add.rn.f32 	%f43, %f37, %f42;
	mul.rn.f32 	%f44, %f42, %f42;
	add.rn.f32 	%f45, %f39, %f44;
	ld.global.nc.f32 	%f46, [%rd52+256];
	mul.rn.f32 	%f47, %f46, %f1;
	add.rn.f32 	%f48, %f47, %f2;
	add.rn.f32 	%f49, %f43, %f48;
	mul.rn.f32 	%f50, %f48, %f48;
	add.rn.f32 	%f51, %f45, %f50;
	ld.global.nc.f32 	%f52, [%rd52+384];
	mul.rn.f32 	%f53, %f52, %f1;
	add.rn.f32 	%f54, %f53, %f2;
	add.rn.f32 	%f77, %f49, %f54;
	mul.rn.f32 	%f55, %f54, %f54;
	add.rn.f32 	%f76, %f51, %f55;
	add.s32 	%r14, %r14, 256;
	add.s64 	%rd52, %rd52, 1024;
	setp.lt.u32 	%p1, %r14, 768;
	@%p1 bra 	$L__BB39_1;
	cvt.u64.u32 	%rd7, %r2;
	cvt.u64.u32 	%rd8, %r1;
	mul.wide.u32 	%rd28, %r2, 132;
	mov.u64 	%rd29, shared_cache1;
	add.s64 	%rd30, %rd29, %rd28;
	mul.wide.u32 	%rd31, %r1, 4;
	add.s64 	%rd32, %rd30, %rd31;
	st.shared.f32 	[%rd32], %f77;
	bar.sync 	0;
	mul.wide.u32 	%rd33, %r1, 132;
	add.s64 	%rd34, %rd29, %rd33;
	mul.wide.u32 	%rd35, %r2, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.shared.f32 	%f56, [%rd36];
	shfl.sync.down.b32	%f57, %f56, 16, 31, -1;
	add.rn.f32 	%f58, %f56, %f57;
	shfl.sync.down.b32	%f59, %f58, 8, 31, -1;
	add.rn.f32 	%f60, %f58, %f59;
	shfl.sync.down.b32	%f61, %f60, 4, 31, -1;
	add.rn.f32 	%f62, %f60, %f61;
	shfl.sync.down.b32	%f63, %f62, 2, 31, -1;
	add.rn.f32 	%f64, %f62, %f63;
	shfl.sync.down.b32	%f65, %f64, 1, 31, -1;
	add.rn.f32 	%f7, %f64, %f65;
	st.shared.f32 	[%rd36], %f7;
	setp.eq.s32 	%p2, %r2, 0;
	or.b32  	%r13, %r3, %r1;
	shl.b64 	%rd37, %rd3, 11;
	@%p2 bra 	$L__BB39_5;
	bra.uni 	$L__BB39_3;
$L__BB39_5:
	add.s64 	%rd38, %rd2, %rd37;
	mul.wide.u32 	%rd39, %r13, 4;
	add.s64 	%rd10, %rd38, %rd39;
	st.global.f32 	[%rd10], %f7;
$L__BB39_3:
	mul.lo.s64 	%rd40, %rd7, 132;
	mov.u64 	%rd41, shared_cache2;
	add.s64 	%rd42, %rd41, %rd40;
	shl.b64 	%rd43, %rd8, 2;
	add.s64 	%rd44, %rd42, %rd43;
	st.shared.f32 	[%rd44], %f76;
	bar.sync 	0;
	mul.lo.s64 	%rd45, %rd8, 132;
	add.s64 	%rd46, %rd41, %rd45;
	shl.b64 	%rd47, %rd7, 2;
	add.s64 	%rd48, %rd46, %rd47;
	ld.shared.f32 	%f66, [%rd48];
	shfl.sync.down.b32	%f67, %f66, 16, 31, -1;
	add.rn.f32 	%f68, %f66, %f67;
	shfl.sync.down.b32	%f69, %f68, 8, 31, -1;
	add.rn.f32 	%f70, %f68, %f69;
	shfl.sync.down.b32	%f71, %f70, 4, 31, -1;
	add.rn.f32 	%f72, %f70, %f71;
	shfl.sync.down.b32	%f73, %f72, 2, 31, -1;
	add.rn.f32 	%f74, %f72, %f73;
	shfl.sync.down.b32	%f75, %f74, 1, 31, -1;
	add.rn.f32 	%f8, %f74, %f75;
	st.shared.f32 	[%rd48], %f8;
	@%p2 bra 	$L__BB39_6;
	bra.uni 	$L__BB39_4;
$L__BB39_6:
	cvt.u64.u32 	%rd9, %r13;
	add.s64 	%rd50, %rd1, %rd37;
	shl.b64 	%rd51, %rd9, 2;
	add.s64 	%rd11, %rd50, %rd51;
	st.global.f32 	[%rd11], %f8;
$L__BB39_4:
	ret;

}
	// .globl	input_reduce_fusion_291
.visible .entry input_reduce_fusion_291(
	.param .u64 input_reduce_fusion_291_param_0,
	.param .u64 input_reduce_fusion_291_param_1,
	.param .u64 input_reduce_fusion_291_param_2
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<18>;
	.reg .b64 	%rd<34>;
	// demoted variable
	.shared .align 4 .b8 shared_cache3[4224];
	ld.param.u64 	%rd9, [input_reduce_fusion_291_param_0];
	ld.param.u64 	%rd10, [input_reduce_fusion_291_param_2];
	cvta.to.global.u64 	%rd1, %rd10;
	ld.param.u64 	%rd11, [input_reduce_fusion_291_param_1];
	cvta.to.global.u64 	%rd12, %rd11;
	cvta.to.global.u64 	%rd13, %rd9;
	mov.u32 	%r9, %tid.x;
	mov.u32 	%r1, %ctaid.x;
	shr.u32 	%r2, %r9, 5;
	and.b32  	%r3, %r9, 31;
	shr.u32 	%r4, %r1, 4;
	shl.b32 	%r10, %r1, 5;
	and.b32  	%r5, %r10, 480;
	or.b32  	%r11, %r5, %r3;
	add.s32 	%r13, %r2, -32;
	cvt.u64.u32 	%rd14, %r9;
	shl.b64 	%rd15, %rd14, 6;
	and.b64  	%rd16, %rd15, 274877904896;
	mul.wide.u32 	%rd17, %r11, 4;
	or.b64  	%rd18, %rd16, %rd17;
	add.s64 	%rd33, %rd12, %rd18;
	add.s64 	%rd32, %rd13, %rd18;
	mov.f32 	%f17, 0f00000000;
	setp.lt.u32 	%p1, %r1, 16;
$L__BB40_1:
	selp.b64 	%rd19, %rd33, %rd32, %p1;
	ld.global.nc.f32 	%f5, [%rd19];
	mul.rn.f32 	%f6, %f5, 0f3A800000;
	add.rn.f32 	%f17, %f17, %f6;
	add.s32 	%r13, %r13, 32;
	add.s64 	%rd33, %rd33, 65536;
	add.s64 	%rd32, %rd32, 65536;
	setp.lt.u32 	%p2, %r13, 18;
	@%p2 bra 	$L__BB40_1;
	mul.wide.u32 	%rd20, %r3, 132;
	mov.u64 	%rd21, shared_cache3;
	add.s64 	%rd22, %rd21, %rd20;
	mul.wide.u32 	%rd23, %r2, 4;
	add.s64 	%rd24, %rd22, %rd23;
	st.shared.f32 	[%rd24], %f17;
	bar.sync 	0;
	mul.wide.u32 	%rd25, %r2, 132;
	add.s64 	%rd26, %rd21, %rd25;
	mul.wide.u32 	%rd27, %r3, 4;
	add.s64 	%rd28, %rd26, %rd27;
	ld.shared.f32 	%f7, [%rd28];
	shfl.sync.down.b32	%f8, %f7, 16, 31, -1;
	add.rn.f32 	%f9, %f7, %f8;
	shfl.sync.down.b32	%f10, %f9, 8, 31, -1;
	add.rn.f32 	%f11, %f9, %f10;
	shfl.sync.down.b32	%f12, %f11, 4, 31, -1;
	add.rn.f32 	%f13, %f11, %f12;
	shfl.sync.down.b32	%f14, %f13, 2, 31, -1;
	add.rn.f32 	%f15, %f13, %f14;
	shfl.sync.down.b32	%f16, %f15, 1, 31, -1;
	add.rn.f32 	%f3, %f15, %f16;
	st.shared.f32 	[%rd28], %f3;
	setp.ne.s32 	%p3, %r3, 0;
	@%p3 bra 	$L__BB40_4;
	or.b32  	%r12, %r5, %r2;
	mul.wide.u32 	%rd29, %r4, 2048;
	add.s64 	%rd30, %rd1, %rd29;
	mul.wide.u32 	%rd31, %r12, 4;
	add.s64 	%rd8, %rd30, %rd31;
	st.global.f32 	[%rd8], %f3;
$L__BB40_4:
	ret;

}
	// .globl	loop_multiply_fusion_75
.visible .entry loop_multiply_fusion_75(
	.param .u64 loop_multiply_fusion_75_param_0,
	.param .u64 loop_multiply_fusion_75_param_1
)
.reqntid 1024, 1, 1
{
	.reg .b32 	%r<2>;
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<8>;

	ld.param.u64 	%rd1, [loop_multiply_fusion_75_param_0];
	ld.param.u64 	%rd2, [loop_multiply_fusion_75_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %tid.x;
	mul.wide.u32 	%rd5, %r1, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.f32 	%f1, [%rd6];
	mul.rn.f32 	%f2, %f1, 0f3CA3D70A;
	add.s64 	%rd7, %rd3, %rd5;
	st.global.f32 	[%rd7], %f2;
	ret;

}
	// .globl	loop_multiply_fusion_76
.visible .entry loop_multiply_fusion_76(
	.param .u64 loop_multiply_fusion_76_param_0,
	.param .u64 loop_multiply_fusion_76_param_1,
	.param .u64 loop_multiply_fusion_76_param_2
)
.reqntid 128, 1, 1
{
	.reg .b32 	%r<5>;
	.reg .f32 	%f<10>;
	.reg .b64 	%rd<11>;

	ld.param.u64 	%rd1, [loop_multiply_fusion_76_param_0];
	ld.param.u64 	%rd2, [loop_multiply_fusion_76_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_multiply_fusion_76_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.wide.u32 	%rd7, %r4, 4;
	add.s64 	%rd8, %rd5, %rd7;
	ld.global.nc.f32 	%f1, [%rd8+2048];
	ld.global.nc.f32 	%f2, [%rd8];
	mul.rn.f32 	%f3, %f2, %f2;
	sub.rn.f32 	%f4, %f1, %f3;
	max.NaN.f32 	%f5, %f4, 0f00000000;
	add.rn.f32 	%f6, %f5, 0f3727C5AC;
	rsqrt.approx.f32 	%f7, %f6;
	add.s64 	%rd9, %rd6, %rd7;
	ld.global.nc.f32 	%f8, [%rd9];
	mul.rn.f32 	%f9, %f7, %f8;
	add.s64 	%rd10, %rd3, %rd7;
	st.global.f32 	[%rd10], %f9;
	ret;

}
	// .globl	loop_multiply_fusion_77
.visible .entry loop_multiply_fusion_77(
	.param .u64 loop_multiply_fusion_77_param_0,
	.param .u64 loop_multiply_fusion_77_param_1,
	.param .u64 loop_multiply_fusion_77_param_2,
	.param .u64 loop_multiply_fusion_77_param_3,
	.param .u64 loop_multiply_fusion_77_param_4,
	.param .u64 loop_multiply_fusion_77_param_5,
	.param .u64 loop_multiply_fusion_77_param_6,
	.param .u64 loop_multiply_fusion_77_param_7,
	.param .u64 loop_multiply_fusion_77_param_8
)
.reqntid 128, 1, 1
{
	.reg .b32 	%r<8>;
	.reg .f32 	%f<50>;
	.reg .b64 	%rd<33>;

	ld.param.u64 	%rd1, [loop_multiply_fusion_77_param_0];
	ld.param.u64 	%rd2, [loop_multiply_fusion_77_param_8];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_multiply_fusion_77_param_1];
	ld.param.u64 	%rd5, [loop_multiply_fusion_77_param_7];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_multiply_fusion_77_param_2];
	ld.param.u64 	%rd8, [loop_multiply_fusion_77_param_6];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_multiply_fusion_77_param_3];
	ld.param.u64 	%rd11, [loop_multiply_fusion_77_param_5];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_multiply_fusion_77_param_4];
	cvta.to.global.u64 	%rd14, %rd13;
	cvta.to.global.u64 	%rd15, %rd10;
	cvta.to.global.u64 	%rd16, %rd7;
	cvta.to.global.u64 	%rd17, %rd4;
	cvta.to.global.u64 	%rd18, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	mul.wide.u32 	%rd19, %r4, 4;
	add.s64 	%rd20, %rd18, %rd19;
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd20];
	and.b32  	%r6, %r1, 1023;
	shr.u32 	%r7, %r1, 10;
	mul.wide.u32 	%rd21, %r7, 4096;
	add.s64 	%rd22, %rd9, %rd21;
	mul.wide.u32 	%rd23, %r6, 4;
	add.s64 	%rd24, %rd22, %rd23;
	ld.global.nc.f32 	%f5, [%rd24];
	add.s64 	%rd25, %rd12, %rd19;
	ld.global.nc.v4.f32 	{%f6, %f7, %f8, %f9}, [%rd25];
	mul.rn.f32 	%f10, %f5, %f6;
	add.s64 	%rd26, %rd14, %rd19;
	ld.global.nc.v4.f32 	{%f11, %f12, %f13, %f14}, [%rd26];
	add.rn.f32 	%f15, %f10, %f11;
	add.s64 	%rd27, %rd15, %rd19;
	ld.global.nc.v4.f32 	{%f16, %f17, %f18, %f19}, [%rd27];
	sub.rn.f32 	%f20, %f15, %f16;
	add.s64 	%rd28, %rd16, %rd19;
	ld.global.nc.v4.f32 	{%f21, %f22, %f23, %f24}, [%rd28];
	mul.rn.f32 	%f25, %f20, %f21;
	add.s64 	%rd29, %rd17, %rd19;
	ld.global.nc.v4.f32 	{%f26, %f27, %f28, %f29}, [%rd29];
	add.rn.f32 	%f30, %f25, %f26;
	mul.rn.f32 	%f31, %f1, %f30;
	mul.wide.u32 	%rd30, %r5, 4;
	add.s64 	%rd31, %rd6, %rd30;
	add.s64 	%rd32, %rd3, %rd30;
	mul.rn.f32 	%f32, %f5, %f7;
	add.rn.f32 	%f33, %f32, %f12;
	sub.rn.f32 	%f34, %f33, %f17;
	mul.rn.f32 	%f35, %f34, %f22;
	add.rn.f32 	%f36, %f35, %f27;
	mul.rn.f32 	%f37, %f2, %f36;
	mul.rn.f32 	%f38, %f5, %f8;
	add.rn.f32 	%f39, %f38, %f13;
	sub.rn.f32 	%f40, %f39, %f18;
	mul.rn.f32 	%f41, %f40, %f23;
	add.rn.f32 	%f42, %f41, %f28;
	mul.rn.f32 	%f43, %f3, %f42;
	mul.rn.f32 	%f44, %f5, %f9;
	add.rn.f32 	%f45, %f44, %f14;
	sub.rn.f32 	%f46, %f45, %f19;
	mul.rn.f32 	%f47, %f46, %f24;
	add.rn.f32 	%f48, %f47, %f29;
	mul.rn.f32 	%f49, %f4, %f48;
	st.global.v4.f32 	[%rd31], {%f31, %f37, %f43, %f49};
	st.global.v4.f32 	[%rd32], {%f25, %f35, %f41, %f47};
	ret;

}
	// .globl	gemm_fusion_dot_525_1
.visible .entry gemm_fusion_dot_525_1(
	.param .u64 gemm_fusion_dot_525_1_param_0,
	.param .u64 gemm_fusion_dot_525_1_param_1,
	.param .u64 gemm_fusion_dot_525_1_param_2,
	.param .u64 gemm_fusion_dot_525_1_param_3
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<74>;
	.reg .b32 	%r<1337>;
	.reg .f32 	%f<1733>;
	.reg .b64 	%rd<448>;

	ld.param.u64 	%rd80, [gemm_fusion_dot_525_1_param_0];
	ld.param.u64 	%rd81, [gemm_fusion_dot_525_1_param_3];
	cvta.to.global.u64 	%rd1, %rd81;
	ld.param.u64 	%rd82, [gemm_fusion_dot_525_1_param_1];
	ld.param.u64 	%rd83, [gemm_fusion_dot_525_1_param_2];
	cvta.to.global.u64 	%rd84, %rd83;
	cvta.to.global.u64 	%rd443, %rd82;
	cvta.to.global.u64 	%rd85, %rd80;
	// begin inline asm
	mov.u32 %r36, %ctaid.x;
	// end inline asm
	mul.hi.s32 	%r95, %r36, 715827883;
	shr.u32 	%r96, %r95, 31;
	shr.s32 	%r97, %r95, 2;
	add.s32 	%r98, %r97, %r96;
	shl.b32 	%r99, %r98, 3;
	mov.b32 	%r100, 200;
	sub.s32 	%r101, %r100, %r99;
	min.s32 	%r102, %r101, 8;
	rem.s32 	%r103, %r36, %r102;
	add.s32 	%r104, %r99, %r103;
	mad.lo.s32 	%r105, %r98, -24, %r36;
	div.s32 	%r106, %r105, %r102;
	shl.b32 	%r107, %r104, 8;
	cvt.s64.s32 	%rd3, %r107;
	shl.b32 	%r108, %r106, 7;
	cvt.s64.s32 	%rd4, %r108;
	mov.u32 	%r1, %tid.x;
	and.b32  	%r2, %r1, 31;
	shr.u32 	%r3, %r1, 5;
	shr.u32 	%r4, %r1, 3;
	bfe.u32 	%r5, %r1, 3, 1;
	or.b32  	%r109, %r4, 32;
	or.b32  	%r110, %r4, 64;
	or.b32  	%r111, %r4, 96;
	or.b32  	%r112, %r4, 128;
	or.b32  	%r113, %r4, 160;
	or.b32  	%r114, %r4, 192;
	or.b32  	%r115, %r4, 224;
	cvt.u64.u32 	%rd86, %r4;
	cvt.u64.u32 	%rd87, %r109;
	cvt.u64.u32 	%rd88, %r110;
	cvt.u64.u32 	%rd89, %r111;
	cvt.u64.u32 	%rd90, %r112;
	cvt.u64.u32 	%rd91, %r113;
	cvt.u64.u32 	%rd92, %r114;
	cvt.u64.u32 	%rd93, %r115;
	or.b64  	%rd94, %rd3, %rd86;
	or.b64  	%rd95, %rd3, %rd87;
	or.b64  	%rd96, %rd3, %rd88;
	or.b64  	%rd97, %rd3, %rd89;
	or.b64  	%rd98, %rd3, %rd90;
	or.b64  	%rd99, %rd3, %rd91;
	or.b64  	%rd100, %rd3, %rd92;
	or.b64  	%rd101, %rd3, %rd93;
	shl.b32 	%r6, %r1, 2;
	and.b32  	%r7, %r6, 28;
	or.b64  	%rd102, %rd4, %rd86;
	or.b64  	%rd103, %rd4, %rd87;
	or.b64  	%rd104, %rd4, %rd88;
	or.b64  	%rd105, %rd4, %rd89;
	mul.wide.u32 	%rd106, %r7, 4;
	shl.b64 	%rd107, %rd94, 11;
	or.b64  	%rd108, %rd107, %rd106;
	add.s64 	%rd54, %rd85, %rd108;
	shl.b64 	%rd109, %rd95, 11;
	or.b64  	%rd110, %rd109, %rd106;
	add.s64 	%rd55, %rd85, %rd110;
	shl.b64 	%rd111, %rd96, 11;
	or.b64  	%rd112, %rd111, %rd106;
	add.s64 	%rd56, %rd85, %rd112;
	shl.b64 	%rd113, %rd97, 11;
	or.b64  	%rd114, %rd113, %rd106;
	add.s64 	%rd57, %rd85, %rd114;
	shl.b64 	%rd115, %rd98, 11;
	or.b64  	%rd116, %rd115, %rd106;
	add.s64 	%rd58, %rd85, %rd116;
	shl.b64 	%rd117, %rd99, 11;
	or.b64  	%rd118, %rd117, %rd106;
	add.s64 	%rd59, %rd85, %rd118;
	shl.b64 	%rd119, %rd100, 11;
	or.b64  	%rd120, %rd119, %rd106;
	add.s64 	%rd60, %rd85, %rd120;
	shl.b64 	%rd121, %rd101, 11;
	or.b64  	%rd122, %rd121, %rd106;
	add.s64 	%rd61, %rd85, %rd122;
	shl.b32 	%r116, %r4, 5;
	or.b32  	%r117, %r116, %r7;
	cvt.u64.u32 	%rd5, %r117;
	mul.wide.u32 	%rd123, %r117, 4;
	mov.u64 	%rd79, global_smem;
	add.s64 	%rd124, %rd79, %rd123;
	shl.b32 	%r118, %r109, 5;
	or.b32  	%r119, %r118, %r7;
	cvt.u64.u32 	%rd6, %r119;
	mul.wide.u32 	%rd125, %r119, 4;
	add.s64 	%rd126, %rd79, %rd125;
	shl.b32 	%r120, %r110, 5;
	or.b32  	%r121, %r120, %r7;
	cvt.u64.u32 	%rd7, %r121;
	mul.wide.u32 	%rd127, %r121, 4;
	add.s64 	%rd128, %rd79, %rd127;
	shl.b32 	%r122, %r111, 5;
	or.b32  	%r123, %r122, %r7;
	cvt.u64.u32 	%rd8, %r123;
	mul.wide.u32 	%rd129, %r123, 4;
	add.s64 	%rd130, %rd79, %rd129;
	shl.b32 	%r124, %r112, 5;
	or.b32  	%r125, %r124, %r7;
	cvt.u64.u32 	%rd9, %r125;
	mul.wide.u32 	%rd131, %r125, 4;
	add.s64 	%rd132, %rd79, %rd131;
	shl.b32 	%r126, %r113, 5;
	or.b32  	%r127, %r126, %r7;
	cvt.u64.u32 	%rd10, %r127;
	mul.wide.u32 	%rd133, %r127, 4;
	add.s64 	%rd134, %rd79, %rd133;
	shl.b32 	%r128, %r114, 5;
	or.b32  	%r129, %r128, %r7;
	cvt.u64.u32 	%rd11, %r129;
	mul.wide.u32 	%rd135, %r129, 4;
	add.s64 	%rd136, %rd79, %rd135;
	shl.b32 	%r130, %r115, 5;
	or.b32  	%r131, %r130, %r7;
	cvt.u64.u32 	%rd12, %r131;
	mul.wide.u32 	%rd137, %r131, 4;
	add.s64 	%rd138, %rd79, %rd137;
	cvt.u32.u64 	%r37, %rd124;
	mov.b32 	%r38, 16;
	mov.pred 	%p42, -1;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r37 + 0 ], [ %rd54 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r39, %rd126;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r39 + 0 ], [ %rd55 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r41, %rd128;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r41 + 0 ], [ %rd56 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r43, %rd130;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r43 + 0 ], [ %rd57 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r45, %rd132;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r45 + 0 ], [ %rd58 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r47, %rd134;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r47 + 0 ], [ %rd59 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r49, %rd136;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r49 + 0 ], [ %rd60 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r51, %rd138;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r51 + 0 ], [ %rd61 + 0 ], 0x10, %r38;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	shl.b64 	%rd139, %rd102, 11;
	or.b64  	%rd140, %rd139, %rd106;
	add.s64 	%rd62, %rd84, %rd140;
	shl.b64 	%rd141, %rd103, 11;
	or.b64  	%rd142, %rd141, %rd106;
	add.s64 	%rd63, %rd84, %rd142;
	shl.b64 	%rd143, %rd104, 11;
	or.b64  	%rd144, %rd143, %rd106;
	add.s64 	%rd64, %rd84, %rd144;
	shl.b64 	%rd145, %rd105, 11;
	or.b64  	%rd146, %rd145, %rd106;
	add.s64 	%rd65, %rd84, %rd146;
	shr.u32 	%r132, %r1, 1;
	xor.b32  	%r133, %r132, %r6;
	and.b32  	%r134, %r133, 28;
	or.b32  	%r135, %r134, %r116;
	cvt.u64.u32 	%rd13, %r135;
	mul.wide.u32 	%rd147, %r135, 4;
	add.s64 	%rd78, %rd79, 65536;
	add.s64 	%rd148, %rd78, %rd147;
	or.b32  	%r136, %r118, %r134;
	cvt.u64.u32 	%rd14, %r136;
	mul.wide.u32 	%rd149, %r136, 4;
	add.s64 	%rd150, %rd78, %rd149;
	or.b32  	%r137, %r120, %r134;
	cvt.u64.u32 	%rd15, %r137;
	mul.wide.u32 	%rd151, %r137, 4;
	add.s64 	%rd152, %rd78, %rd151;
	or.b32  	%r138, %r122, %r134;
	cvt.u64.u32 	%rd16, %r138;
	mul.wide.u32 	%rd153, %r138, 4;
	add.s64 	%rd154, %rd78, %rd153;
	cvt.u32.u64 	%r53, %rd148;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r53 + 0 ], [ %rd62 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r55, %rd150;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r55 + 0 ], [ %rd63 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r57, %rd152;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r57 + 0 ], [ %rd64 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r59, %rd154;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r59 + 0 ], [ %rd65 + 0 ], 0x10, %r38;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	add.s64 	%rd66, %rd54, 128;
	add.s64 	%rd67, %rd55, 128;
	add.s64 	%rd68, %rd56, 128;
	add.s64 	%rd69, %rd57, 128;
	add.s64 	%rd70, %rd58, 128;
	add.s64 	%rd71, %rd59, 128;
	add.s64 	%rd72, %rd60, 128;
	add.s64 	%rd73, %rd61, 128;
	bar.sync 	0;
	add.s64 	%rd155, %rd79, 32768;
	add.s64 	%rd156, %rd155, %rd123;
	add.s64 	%rd157, %rd155, %rd125;
	add.s64 	%rd158, %rd155, %rd127;
	add.s64 	%rd159, %rd155, %rd129;
	add.s64 	%rd160, %rd155, %rd131;
	add.s64 	%rd161, %rd155, %rd133;
	add.s64 	%rd162, %rd155, %rd135;
	add.s64 	%rd163, %rd155, %rd137;
	cvt.u32.u64 	%r61, %rd156;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r61 + 0 ], [ %rd66 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r63, %rd157;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r63 + 0 ], [ %rd67 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r65, %rd158;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r65 + 0 ], [ %rd68 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r67, %rd159;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r67 + 0 ], [ %rd69 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r69, %rd160;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r69 + 0 ], [ %rd70 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r71, %rd161;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r71 + 0 ], [ %rd71 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r73, %rd162;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r73 + 0 ], [ %rd72 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r75, %rd163;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r75 + 0 ], [ %rd73 + 0 ], 0x10, %r38;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	add.s64 	%rd74, %rd62, 128;
	add.s64 	%rd75, %rd63, 128;
	add.s64 	%rd76, %rd64, 128;
	add.s64 	%rd77, %rd65, 128;
	add.s64 	%rd164, %rd79, 81920;
	add.s64 	%rd165, %rd164, %rd147;
	add.s64 	%rd166, %rd164, %rd149;
	add.s64 	%rd167, %rd164, %rd151;
	add.s64 	%rd168, %rd164, %rd153;
	cvt.u32.u64 	%r77, %rd165;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r77 + 0 ], [ %rd74 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r79, %rd166;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r79 + 0 ], [ %rd75 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r81, %rd167;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r81 + 0 ], [ %rd76 + 0 ], 0x10, %r38;
	// end inline asm
	cvt.u32.u64 	%r83, %rd168;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r83 + 0 ], [ %rd77 + 0 ], 0x10, %r38;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	// begin inline asm
	cp.async.wait_group 0x2;
	// end inline asm
	bar.sync 	0;
	add.s64 	%rd169, %rd79, 98304;
	add.s64 	%rd17, %rd169, %rd147;
	add.s64 	%rd18, %rd169, %rd149;
	add.s64 	%rd19, %rd169, %rd151;
	add.s64 	%rd20, %rd169, %rd153;
	or.b32  	%r139, %r124, %r134;
	mul.wide.u32 	%rd170, %r139, 4;
	add.s64 	%rd21, %rd169, %rd170;
	or.b32  	%r140, %r126, %r134;
	mul.wide.u32 	%rd171, %r140, 4;
	add.s64 	%rd22, %rd169, %rd171;
	or.b32  	%r141, %r128, %r134;
	mul.wide.u32 	%rd172, %r141, 4;
	add.s64 	%rd23, %rd169, %rd172;
	or.b32  	%r142, %r130, %r134;
	mul.wide.u32 	%rd173, %r142, 4;
	add.s64 	%rd24, %rd169, %rd173;
	and.b32  	%r8, %r1, 7;
	bfe.u32 	%r143, %r1, 4, 1;
	and.b32  	%r144, %r3, 6;
	or.b32  	%r145, %r144, %r5;
	xor.b32  	%r146, %r143, %r8;
	shl.b32 	%r147, %r146, 2;
	shl.b32 	%r148, %r145, 8;
	shl.b32 	%r149, %r8, 5;
	or.b32  	%r150, %r148, %r149;
	or.b32  	%r151, %r150, %r147;
	mul.wide.u32 	%rd174, %r151, 4;
	add.s64 	%rd25, %rd169, %rd174;
	or.b32  	%r152, %r143, 2;
	xor.b32  	%r153, %r152, %r8;
	shl.b32 	%r154, %r153, 2;
	or.b32  	%r155, %r154, %r150;
	mul.wide.u32 	%rd175, %r155, 4;
	add.s64 	%rd26, %rd169, %rd175;
	or.b32  	%r156, %r143, 4;
	xor.b32  	%r157, %r156, %r8;
	shl.b32 	%r158, %r157, 2;
	or.b32  	%r159, %r158, %r150;
	mul.wide.u32 	%rd176, %r159, 4;
	add.s64 	%rd27, %rd169, %rd176;
	or.b32  	%r160, %r143, 6;
	xor.b32  	%r161, %r160, %r8;
	shl.b32 	%r162, %r161, 2;
	or.b32  	%r163, %r162, %r150;
	mul.wide.u32 	%rd177, %r163, 4;
	add.s64 	%rd28, %rd169, %rd177;
	add.s64 	%rd29, %rd25, 8192;
	add.s64 	%rd30, %rd26, 8192;
	add.s64 	%rd31, %rd27, 8192;
	add.s64 	%rd32, %rd28, 8192;
	add.s64 	%rd33, %rd25, 16384;
	add.s64 	%rd34, %rd26, 16384;
	add.s64 	%rd35, %rd27, 16384;
	add.s64 	%rd36, %rd28, 16384;
	add.s64 	%rd37, %rd25, 24576;
	add.s64 	%rd38, %rd26, 24576;
	add.s64 	%rd39, %rd27, 24576;
	add.s64 	%rd40, %rd28, 24576;
	shr.u32 	%r164, %r1, 2;
	and.b32  	%r9, %r164, 8;
	and.b32  	%r165, %r1, 23;
	or.b32  	%r10, %r9, %r165;
	or.b32  	%r11, %r5, 2;
	or.b32  	%r12, %r5, 4;
	or.b32  	%r13, %r5, 6;
	mul.wide.u32 	%rd41, %r8, 16;
	add.s64 	%rd445, %rd85, %rd107;
	add.s64 	%rd444, %rd84, %rd139;
	mov.f32 	%f1605, 0f00000000;
	mov.b32 	%r1330, 0;
	mov.b32 	%r1334, 1;
	mov.b32 	%r1333, 32;
	shl.b64 	%rd236, %rd5, 2;
	shl.b64 	%rd238, %rd6, 2;
	shl.b64 	%rd240, %rd7, 2;
	shl.b64 	%rd242, %rd8, 2;
	shl.b64 	%rd244, %rd9, 2;
	shl.b64 	%rd246, %rd10, 2;
	shl.b64 	%rd248, %rd11, 2;
	shl.b64 	%rd250, %rd12, 2;
	shl.b64 	%rd256, %rd13, 2;
	shl.b64 	%rd258, %rd14, 2;
	shl.b64 	%rd260, %rd15, 2;
	shl.b64 	%rd262, %rd16, 2;
	mov.u64 	%rd446, %rd78;
	mov.u32 	%r1332, %r1330;
	mov.u64 	%rd447, %rd79;
	mov.u32 	%r1335, %r1330;
	mov.u32 	%r1336, %r1334;
	mov.f32 	%f1606, %f1605;
	mov.f32 	%f1607, %f1605;
	mov.f32 	%f1608, %f1605;
	mov.f32 	%f1609, %f1605;
	mov.f32 	%f1610, %f1605;
	mov.f32 	%f1611, %f1605;
	mov.f32 	%f1612, %f1605;
	mov.f32 	%f1613, %f1605;
	mov.f32 	%f1614, %f1605;
	mov.f32 	%f1615, %f1605;
	mov.f32 	%f1616, %f1605;
	mov.f32 	%f1617, %f1605;
	mov.f32 	%f1618, %f1605;
	mov.f32 	%f1619, %f1605;
	mov.f32 	%f1620, %f1605;
	mov.f32 	%f1621, %f1605;
	mov.f32 	%f1622, %f1605;
	mov.f32 	%f1623, %f1605;
	mov.f32 	%f1624, %f1605;
	mov.f32 	%f1625, %f1605;
	mov.f32 	%f1626, %f1605;
	mov.f32 	%f1627, %f1605;
	mov.f32 	%f1628, %f1605;
	mov.f32 	%f1629, %f1605;
	mov.f32 	%f1630, %f1605;
	mov.f32 	%f1631, %f1605;
	mov.f32 	%f1632, %f1605;
	mov.f32 	%f1633, %f1605;
	mov.f32 	%f1634, %f1605;
	mov.f32 	%f1635, %f1605;
	mov.f32 	%f1636, %f1605;
	mov.f32 	%f1637, %f1605;
	mov.f32 	%f1638, %f1605;
	mov.f32 	%f1639, %f1605;
	mov.f32 	%f1640, %f1605;
	mov.f32 	%f1641, %f1605;
	mov.f32 	%f1642, %f1605;
	mov.f32 	%f1643, %f1605;
	mov.f32 	%f1644, %f1605;
	mov.f32 	%f1645, %f1605;
	mov.f32 	%f1646, %f1605;
	mov.f32 	%f1647, %f1605;
	mov.f32 	%f1648, %f1605;
	mov.f32 	%f1649, %f1605;
	mov.f32 	%f1650, %f1605;
	mov.f32 	%f1651, %f1605;
	mov.f32 	%f1652, %f1605;
	mov.f32 	%f1653, %f1605;
	mov.f32 	%f1654, %f1605;
	mov.f32 	%f1655, %f1605;
	mov.f32 	%f1656, %f1605;
	mov.f32 	%f1657, %f1605;
	mov.f32 	%f1658, %f1605;
	mov.f32 	%f1659, %f1605;
	mov.f32 	%f1660, %f1605;
	mov.f32 	%f1661, %f1605;
	mov.f32 	%f1662, %f1605;
	mov.f32 	%f1663, %f1605;
	mov.f32 	%f1664, %f1605;
	mov.f32 	%f1665, %f1605;
	mov.f32 	%f1666, %f1605;
	mov.f32 	%f1667, %f1605;
	mov.f32 	%f1668, %f1605;
	mov.f32 	%f1669, %f1605;
	mov.f32 	%f1670, %f1605;
	mov.f32 	%f1671, %f1605;
	mov.f32 	%f1672, %f1605;
	mov.f32 	%f1673, %f1605;
	mov.f32 	%f1674, %f1605;
	mov.f32 	%f1675, %f1605;
	mov.f32 	%f1676, %f1605;
	mov.f32 	%f1677, %f1605;
	mov.f32 	%f1678, %f1605;
	mov.f32 	%f1679, %f1605;
	mov.f32 	%f1680, %f1605;
	mov.f32 	%f1681, %f1605;
	mov.f32 	%f1682, %f1605;
	mov.f32 	%f1683, %f1605;
	mov.f32 	%f1684, %f1605;
	mov.f32 	%f1685, %f1605;
	mov.f32 	%f1686, %f1605;
	mov.f32 	%f1687, %f1605;
	mov.f32 	%f1688, %f1605;
	mov.f32 	%f1689, %f1605;
	mov.f32 	%f1690, %f1605;
	mov.f32 	%f1691, %f1605;
	mov.f32 	%f1692, %f1605;
	mov.f32 	%f1693, %f1605;
	mov.f32 	%f1694, %f1605;
	mov.f32 	%f1695, %f1605;
	mov.f32 	%f1696, %f1605;
	mov.f32 	%f1697, %f1605;
	mov.f32 	%f1698, %f1605;
	mov.f32 	%f1699, %f1605;
	mov.f32 	%f1700, %f1605;
	mov.f32 	%f1701, %f1605;
	mov.f32 	%f1702, %f1605;
	mov.f32 	%f1703, %f1605;
	mov.f32 	%f1704, %f1605;
	mov.f32 	%f1705, %f1605;
	mov.f32 	%f1706, %f1605;
	mov.f32 	%f1707, %f1605;
	mov.f32 	%f1708, %f1605;
	mov.f32 	%f1709, %f1605;
	mov.f32 	%f1710, %f1605;
	mov.f32 	%f1711, %f1605;
	mov.f32 	%f1712, %f1605;
	mov.f32 	%f1713, %f1605;
	mov.f32 	%f1714, %f1605;
	mov.f32 	%f1715, %f1605;
	mov.f32 	%f1716, %f1605;
	mov.f32 	%f1717, %f1605;
	mov.f32 	%f1718, %f1605;
	mov.f32 	%f1719, %f1605;
	mov.f32 	%f1720, %f1605;
	mov.f32 	%f1721, %f1605;
	mov.f32 	%f1722, %f1605;
	mov.f32 	%f1723, %f1605;
	mov.f32 	%f1724, %f1605;
	mov.f32 	%f1725, %f1605;
	mov.f32 	%f1726, %f1605;
	mov.f32 	%f1727, %f1605;
	mov.f32 	%f1728, %f1605;
	mov.f32 	%f1729, %f1605;
	mov.f32 	%f1730, %f1605;
	mov.f32 	%f1731, %f1605;
	mov.f32 	%f1732, %f1605;
$L__BB44_1:
	setp.lt.u32 	%p38, %r1330, 448;
	mul.lo.s32 	%r1122, %r1333, %r4;
	mad.lo.s32 	%r1123, %r1334, %r7, %r1122;
	mul.wide.s32 	%rd191, %r1123, 4;
	add.s64 	%rd192, %rd447, %rd191;
	shl.b32 	%r1124, %r1333, 5;
	add.s32 	%r1125, %r1123, %r1124;
	mul.wide.s32 	%rd193, %r1125, 4;
	add.s64 	%rd194, %rd447, %rd193;
	add.s32 	%r1126, %r1125, %r1124;
	mul.wide.s32 	%rd195, %r1126, 4;
	add.s64 	%rd196, %rd447, %rd195;
	add.s32 	%r1127, %r1126, %r1124;
	mul.wide.s32 	%rd197, %r1127, 4;
	add.s64 	%rd198, %rd447, %rd197;
	add.s32 	%r1128, %r1127, %r1124;
	mul.wide.s32 	%rd199, %r1128, 4;
	add.s64 	%rd200, %rd447, %rd199;
	add.s32 	%r1129, %r1128, %r1124;
	mul.wide.s32 	%rd201, %r1129, 4;
	add.s64 	%rd202, %rd447, %rd201;
	add.s32 	%r1130, %r1129, %r1124;
	mul.wide.s32 	%rd203, %r1130, 4;
	add.s64 	%rd204, %rd447, %rd203;
	add.s32 	%r1131, %r1130, %r1124;
	mul.wide.s32 	%rd205, %r1131, 4;
	add.s64 	%rd206, %rd447, %rd205;
	add.s64 	%rd178, %rd443, %rd41;
	ld.shared.v4.f32 	{%f1537, %f1538, %f1539, %f1540}, [%rd192];
	ld.shared.v4.f32 	{%f1541, %f1542, %f1543, %f1544}, [%rd194];
	ld.shared.v4.f32 	{%f1545, %f1546, %f1547, %f1548}, [%rd196];
	ld.shared.v4.f32 	{%f1549, %f1550, %f1551, %f1552}, [%rd198];
	ld.shared.v4.f32 	{%f1553, %f1554, %f1555, %f1556}, [%rd200];
	ld.shared.v4.f32 	{%f1557, %f1558, %f1559, %f1560}, [%rd202];
	ld.shared.v4.f32 	{%f1561, %f1562, %f1563, %f1564}, [%rd204];
	ld.shared.v4.f32 	{%f1565, %f1566, %f1567, %f1568}, [%rd206];
	// begin inline asm
	mov.u32 %r166, 0x0;
	mov.u32 %r167, 0x0;
	mov.u32 %r168, 0x0;
	mov.u32 %r169, 0x0;
	@%p42 ld.global.v4.b32 { %r166, %r167, %r168, %r169 }, [ %rd178 + 0 ];
	// end inline asm
	mov.b32 	%f1569, %r166;
	mov.b32 	%f1570, %r167;
	mov.b32 	%f1571, %r168;
	mov.b32 	%f1572, %r169;
	add.rn.f32 	%f1573, %f1540, %f1572;
	add.rn.f32 	%f1574, %f1539, %f1571;
	add.rn.f32 	%f1575, %f1538, %f1570;
	add.rn.f32 	%f1576, %f1537, %f1569;
	add.rn.f32 	%f1577, %f1544, %f1572;
	add.rn.f32 	%f1578, %f1543, %f1571;
	add.rn.f32 	%f1579, %f1542, %f1570;
	add.rn.f32 	%f1580, %f1541, %f1569;
	add.rn.f32 	%f1581, %f1548, %f1572;
	add.rn.f32 	%f1582, %f1547, %f1571;
	add.rn.f32 	%f1583, %f1546, %f1570;
	add.rn.f32 	%f1584, %f1545, %f1569;
	add.rn.f32 	%f1585, %f1552, %f1572;
	add.rn.f32 	%f1586, %f1551, %f1571;
	add.rn.f32 	%f1587, %f1550, %f1570;
	add.rn.f32 	%f1588, %f1549, %f1569;
	add.rn.f32 	%f1589, %f1556, %f1572;
	add.rn.f32 	%f1590, %f1555, %f1571;
	add.rn.f32 	%f1591, %f1554, %f1570;
	add.rn.f32 	%f1592, %f1553, %f1569;
	add.rn.f32 	%f1593, %f1560, %f1572;
	add.rn.f32 	%f1594, %f1559, %f1571;
	add.rn.f32 	%f1595, %f1558, %f1570;
	add.rn.f32 	%f1596, %f1557, %f1569;
	add.rn.f32 	%f1597, %f1564, %f1572;
	add.rn.f32 	%f1598, %f1563, %f1571;
	add.rn.f32 	%f1599, %f1562, %f1570;
	add.rn.f32 	%f1600, %f1561, %f1569;
	add.rn.f32 	%f1601, %f1568, %f1572;
	add.rn.f32 	%f1602, %f1567, %f1571;
	add.rn.f32 	%f1603, %f1566, %f1570;
	add.rn.f32 	%f1604, %f1565, %f1569;
	st.shared.v4.f32 	[%rd17], {%f1576, %f1575, %f1574, %f1573};
	st.shared.v4.f32 	[%rd18], {%f1580, %f1579, %f1578, %f1577};
	st.shared.v4.f32 	[%rd19], {%f1584, %f1583, %f1582, %f1581};
	st.shared.v4.f32 	[%rd20], {%f1588, %f1587, %f1586, %f1585};
	st.shared.v4.f32 	[%rd21], {%f1592, %f1591, %f1590, %f1589};
	st.shared.v4.f32 	[%rd22], {%f1596, %f1595, %f1594, %f1593};
	st.shared.v4.f32 	[%rd23], {%f1600, %f1599, %f1598, %f1597};
	st.shared.v4.f32 	[%rd24], {%f1604, %f1603, %f1602, %f1601};
	bar.sync 	0;
	cvt.u32.u64 	%r174, %rd25;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r330, %r331, %r332, %r333 }, [ %r174 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r179, %rd26;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r522, %r523, %r524, %r525 }, [ %r179 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r184, %rd27;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r714, %r715, %r716, %r717 }, [ %r184 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r189, %rd28;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r906, %r907, %r908, %r909 }, [ %r189 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r194, %rd29;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r378, %r379, %r380, %r381 }, [ %r194 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r199, %rd30;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r570, %r571, %r572, %r573 }, [ %r199 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r204, %rd31;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r762, %r763, %r764, %r765 }, [ %r204 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r209, %rd32;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r954, %r955, %r956, %r957 }, [ %r209 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r214, %rd33;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r426, %r427, %r428, %r429 }, [ %r214 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r219, %rd34;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r618, %r619, %r620, %r621 }, [ %r219 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r224, %rd35;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r810, %r811, %r812, %r813 }, [ %r224 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r229, %rd36;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1002, %r1003, %r1004, %r1005 }, [ %r229 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r234, %rd37;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r474, %r475, %r476, %r477 }, [ %r234 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r239, %rd38;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r666, %r667, %r668, %r669 }, [ %r239 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r244, %rd39;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r858, %r859, %r860, %r861 }, [ %r244 + 0 ];
	// end inline asm
	cvt.u32.u64 	%r249, %rd40;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1050, %r1051, %r1052, %r1053 }, [ %r249 + 0 ];
	// end inline asm
	shr.u32 	%r1132, %r1332, 2;
	add.s32 	%r1133, %r1132, %r5;
	xor.b32  	%r1134, %r1133, %r8;
	shl.b32 	%r1135, %r1134, 2;
	mul.lo.s32 	%r1136, %r1333, %r10;
	add.s32 	%r1137, %r1135, %r1136;
	neg.s32 	%r1138, %r1332;
	mul.wide.s32 	%rd207, %r1138, 4;
	add.s64 	%rd208, %rd446, %rd207;
	mul.wide.s32 	%rd209, %r1137, 4;
	add.s64 	%rd210, %rd208, %rd209;
	cvt.u32.u64 	%r254, %rd210;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r334, %r335, %r340, %r341 }, [ %r254 + 0 ];
	// end inline asm
	add.s32 	%r1139, %r11, %r1132;
	xor.b32  	%r1140, %r1139, %r8;
	shl.b32 	%r1141, %r1140, 2;
	add.s32 	%r1142, %r1141, %r1136;
	mul.wide.s32 	%rd211, %r1142, 4;
	add.s64 	%rd212, %rd208, %rd211;
	cvt.u32.u64 	%r259, %rd212;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r526, %r527, %r532, %r533 }, [ %r259 + 0 ];
	// end inline asm
	add.s32 	%r1143, %r12, %r1132;
	xor.b32  	%r1144, %r1143, %r8;
	shl.b32 	%r1145, %r1144, 2;
	add.s32 	%r1146, %r1145, %r1136;
	mul.wide.s32 	%rd213, %r1146, 4;
	add.s64 	%rd214, %rd208, %rd213;
	cvt.u32.u64 	%r264, %rd214;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r718, %r719, %r724, %r725 }, [ %r264 + 0 ];
	// end inline asm
	add.s32 	%r1147, %r13, %r1132;
	xor.b32  	%r1148, %r1147, %r8;
	shl.b32 	%r1149, %r1148, 2;
	add.s32 	%r1150, %r1149, %r1136;
	mul.wide.s32 	%rd215, %r1150, 4;
	add.s64 	%rd216, %rd208, %rd215;
	cvt.u32.u64 	%r269, %rd216;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r910, %r911, %r916, %r917 }, [ %r269 + 0 ];
	// end inline asm
	shl.b32 	%r1151, %r1333, 5;
	mul.wide.s32 	%rd217, %r1151, 4;
	add.s64 	%rd218, %rd210, %rd217;
	cvt.u32.u64 	%r274, %rd218;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r346, %r347, %r352, %r353 }, [ %r274 + 0 ];
	// end inline asm
	add.s64 	%rd219, %rd212, %rd217;
	cvt.u32.u64 	%r279, %rd219;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r538, %r539, %r544, %r545 }, [ %r279 + 0 ];
	// end inline asm
	add.s64 	%rd220, %rd214, %rd217;
	cvt.u32.u64 	%r284, %rd220;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r730, %r731, %r736, %r737 }, [ %r284 + 0 ];
	// end inline asm
	add.s64 	%rd221, %rd216, %rd217;
	cvt.u32.u64 	%r289, %rd221;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r922, %r923, %r928, %r929 }, [ %r289 + 0 ];
	// end inline asm
	shl.b32 	%r1152, %r1333, 6;
	mul.wide.s32 	%rd222, %r1152, 4;
	add.s64 	%rd223, %rd210, %rd222;
	cvt.u32.u64 	%r294, %rd223;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r358, %r359, %r364, %r365 }, [ %r294 + 0 ];
	// end inline asm
	add.s64 	%rd224, %rd212, %rd222;
	cvt.u32.u64 	%r299, %rd224;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r550, %r551, %r556, %r557 }, [ %r299 + 0 ];
	// end inline asm
	add.s64 	%rd225, %rd214, %rd222;
	cvt.u32.u64 	%r304, %rd225;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r742, %r743, %r748, %r749 }, [ %r304 + 0 ];
	// end inline asm
	add.s64 	%rd226, %rd216, %rd222;
	cvt.u32.u64 	%r309, %rd226;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r934, %r935, %r940, %r941 }, [ %r309 + 0 ];
	// end inline asm
	mul.lo.s32 	%r1153, %r1333, 96;
	mul.wide.s32 	%rd227, %r1153, 4;
	add.s64 	%rd228, %rd210, %rd227;
	cvt.u32.u64 	%r314, %rd228;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r370, %r371, %r376, %r377 }, [ %r314 + 0 ];
	// end inline asm
	add.s64 	%rd229, %rd212, %rd227;
	cvt.u32.u64 	%r319, %rd229;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r562, %r563, %r568, %r569 }, [ %r319 + 0 ];
	// end inline asm
	add.s64 	%rd230, %rd214, %rd227;
	cvt.u32.u64 	%r324, %rd230;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r754, %r755, %r760, %r761 }, [ %r324 + 0 ];
	// end inline asm
	add.s64 	%rd231, %rd216, %rd227;
	cvt.u32.u64 	%r329, %rd231;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r946, %r947, %r952, %r953 }, [ %r329 + 0 ];
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1605, %f1606, %f1607, %f1608 }, { %r330, %r331, %r332, %r333 }, { %r334, %r335 }, { %f1605, %f1606, %f1607, %f1608 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1609, %f1610, %f1611, %f1612 }, { %r330, %r331, %r332, %r333 }, { %r340, %r341 }, { %f1609, %f1610, %f1611, %f1612 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1613, %f1614, %f1615, %f1616 }, { %r330, %r331, %r332, %r333 }, { %r346, %r347 }, { %f1613, %f1614, %f1615, %f1616 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1617, %f1618, %f1619, %f1620 }, { %r330, %r331, %r332, %r333 }, { %r352, %r353 }, { %f1617, %f1618, %f1619, %f1620 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1621, %f1622, %f1623, %f1624 }, { %r330, %r331, %r332, %r333 }, { %r358, %r359 }, { %f1621, %f1622, %f1623, %f1624 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1625, %f1626, %f1627, %f1628 }, { %r330, %r331, %r332, %r333 }, { %r364, %r365 }, { %f1625, %f1626, %f1627, %f1628 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1629, %f1630, %f1631, %f1632 }, { %r330, %r331, %r332, %r333 }, { %r370, %r371 }, { %f1629, %f1630, %f1631, %f1632 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1633, %f1634, %f1635, %f1636 }, { %r330, %r331, %r332, %r333 }, { %r376, %r377 }, { %f1633, %f1634, %f1635, %f1636 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1637, %f1638, %f1639, %f1640 }, { %r378, %r379, %r380, %r381 }, { %r334, %r335 }, { %f1637, %f1638, %f1639, %f1640 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1641, %f1642, %f1643, %f1644 }, { %r378, %r379, %r380, %r381 }, { %r340, %r341 }, { %f1641, %f1642, %f1643, %f1644 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1645, %f1646, %f1647, %f1648 }, { %r378, %r379, %r380, %r381 }, { %r346, %r347 }, { %f1645, %f1646, %f1647, %f1648 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1649, %f1650, %f1651, %f1652 }, { %r378, %r379, %r380, %r381 }, { %r352, %r353 }, { %f1649, %f1650, %f1651, %f1652 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1653, %f1654, %f1655, %f1656 }, { %r378, %r379, %r380, %r381 }, { %r358, %r359 }, { %f1653, %f1654, %f1655, %f1656 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1657, %f1658, %f1659, %f1660 }, { %r378, %r379, %r380, %r381 }, { %r364, %r365 }, { %f1657, %f1658, %f1659, %f1660 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1661, %f1662, %f1663, %f1664 }, { %r378, %r379, %r380, %r381 }, { %r370, %r371 }, { %f1661, %f1662, %f1663, %f1664 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1665, %f1666, %f1667, %f1668 }, { %r378, %r379, %r380, %r381 }, { %r376, %r377 }, { %f1665, %f1666, %f1667, %f1668 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1669, %f1670, %f1671, %f1672 }, { %r426, %r427, %r428, %r429 }, { %r334, %r335 }, { %f1669, %f1670, %f1671, %f1672 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1673, %f1674, %f1675, %f1676 }, { %r426, %r427, %r428, %r429 }, { %r340, %r341 }, { %f1673, %f1674, %f1675, %f1676 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1677, %f1678, %f1679, %f1680 }, { %r426, %r427, %r428, %r429 }, { %r346, %r347 }, { %f1677, %f1678, %f1679, %f1680 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1681, %f1682, %f1683, %f1684 }, { %r426, %r427, %r428, %r429 }, { %r352, %r353 }, { %f1681, %f1682, %f1683, %f1684 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1685, %f1686, %f1687, %f1688 }, { %r426, %r427, %r428, %r429 }, { %r358, %r359 }, { %f1685, %f1686, %f1687, %f1688 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1689, %f1690, %f1691, %f1692 }, { %r426, %r427, %r428, %r429 }, { %r364, %r365 }, { %f1689, %f1690, %f1691, %f1692 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1693, %f1694, %f1695, %f1696 }, { %r426, %r427, %r428, %r429 }, { %r370, %r371 }, { %f1693, %f1694, %f1695, %f1696 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1697, %f1698, %f1699, %f1700 }, { %r426, %r427, %r428, %r429 }, { %r376, %r377 }, { %f1697, %f1698, %f1699, %f1700 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1701, %f1702, %f1703, %f1704 }, { %r474, %r475, %r476, %r477 }, { %r334, %r335 }, { %f1701, %f1702, %f1703, %f1704 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1705, %f1706, %f1707, %f1708 }, { %r474, %r475, %r476, %r477 }, { %r340, %r341 }, { %f1705, %f1706, %f1707, %f1708 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1709, %f1710, %f1711, %f1712 }, { %r474, %r475, %r476, %r477 }, { %r346, %r347 }, { %f1709, %f1710, %f1711, %f1712 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1713, %f1714, %f1715, %f1716 }, { %r474, %r475, %r476, %r477 }, { %r352, %r353 }, { %f1713, %f1714, %f1715, %f1716 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1717, %f1718, %f1719, %f1720 }, { %r474, %r475, %r476, %r477 }, { %r358, %r359 }, { %f1717, %f1718, %f1719, %f1720 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1721, %f1722, %f1723, %f1724 }, { %r474, %r475, %r476, %r477 }, { %r364, %r365 }, { %f1721, %f1722, %f1723, %f1724 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1725, %f1726, %f1727, %f1728 }, { %r474, %r475, %r476, %r477 }, { %r370, %r371 }, { %f1725, %f1726, %f1727, %f1728 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1729, %f1730, %f1731, %f1732 }, { %r474, %r475, %r476, %r477 }, { %r376, %r377 }, { %f1729, %f1730, %f1731, %f1732 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1605, %f1606, %f1607, %f1608 }, { %r522, %r523, %r524, %r525 }, { %r526, %r527 }, { %f1605, %f1606, %f1607, %f1608 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1609, %f1610, %f1611, %f1612 }, { %r522, %r523, %r524, %r525 }, { %r532, %r533 }, { %f1609, %f1610, %f1611, %f1612 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1613, %f1614, %f1615, %f1616 }, { %r522, %r523, %r524, %r525 }, { %r538, %r539 }, { %f1613, %f1614, %f1615, %f1616 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1617, %f1618, %f1619, %f1620 }, { %r522, %r523, %r524, %r525 }, { %r544, %r545 }, { %f1617, %f1618, %f1619, %f1620 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1621, %f1622, %f1623, %f1624 }, { %r522, %r523, %r524, %r525 }, { %r550, %r551 }, { %f1621, %f1622, %f1623, %f1624 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1625, %f1626, %f1627, %f1628 }, { %r522, %r523, %r524, %r525 }, { %r556, %r557 }, { %f1625, %f1626, %f1627, %f1628 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1629, %f1630, %f1631, %f1632 }, { %r522, %r523, %r524, %r525 }, { %r562, %r563 }, { %f1629, %f1630, %f1631, %f1632 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1633, %f1634, %f1635, %f1636 }, { %r522, %r523, %r524, %r525 }, { %r568, %r569 }, { %f1633, %f1634, %f1635, %f1636 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1637, %f1638, %f1639, %f1640 }, { %r570, %r571, %r572, %r573 }, { %r526, %r527 }, { %f1637, %f1638, %f1639, %f1640 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1641, %f1642, %f1643, %f1644 }, { %r570, %r571, %r572, %r573 }, { %r532, %r533 }, { %f1641, %f1642, %f1643, %f1644 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1645, %f1646, %f1647, %f1648 }, { %r570, %r571, %r572, %r573 }, { %r538, %r539 }, { %f1645, %f1646, %f1647, %f1648 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1649, %f1650, %f1651, %f1652 }, { %r570, %r571, %r572, %r573 }, { %r544, %r545 }, { %f1649, %f1650, %f1651, %f1652 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1653, %f1654, %f1655, %f1656 }, { %r570, %r571, %r572, %r573 }, { %r550, %r551 }, { %f1653, %f1654, %f1655, %f1656 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1657, %f1658, %f1659, %f1660 }, { %r570, %r571, %r572, %r573 }, { %r556, %r557 }, { %f1657, %f1658, %f1659, %f1660 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1661, %f1662, %f1663, %f1664 }, { %r570, %r571, %r572, %r573 }, { %r562, %r563 }, { %f1661, %f1662, %f1663, %f1664 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1665, %f1666, %f1667, %f1668 }, { %r570, %r571, %r572, %r573 }, { %r568, %r569 }, { %f1665, %f1666, %f1667, %f1668 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1669, %f1670, %f1671, %f1672 }, { %r618, %r619, %r620, %r621 }, { %r526, %r527 }, { %f1669, %f1670, %f1671, %f1672 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1673, %f1674, %f1675, %f1676 }, { %r618, %r619, %r620, %r621 }, { %r532, %r533 }, { %f1673, %f1674, %f1675, %f1676 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1677, %f1678, %f1679, %f1680 }, { %r618, %r619, %r620, %r621 }, { %r538, %r539 }, { %f1677, %f1678, %f1679, %f1680 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1681, %f1682, %f1683, %f1684 }, { %r618, %r619, %r620, %r621 }, { %r544, %r545 }, { %f1681, %f1682, %f1683, %f1684 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1685, %f1686, %f1687, %f1688 }, { %r618, %r619, %r620, %r621 }, { %r550, %r551 }, { %f1685, %f1686, %f1687, %f1688 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1689, %f1690, %f1691, %f1692 }, { %r618, %r619, %r620, %r621 }, { %r556, %r557 }, { %f1689, %f1690, %f1691, %f1692 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1693, %f1694, %f1695, %f1696 }, { %r618, %r619, %r620, %r621 }, { %r562, %r563 }, { %f1693, %f1694, %f1695, %f1696 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1697, %f1698, %f1699, %f1700 }, { %r618, %r619, %r620, %r621 }, { %r568, %r569 }, { %f1697, %f1698, %f1699, %f1700 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1701, %f1702, %f1703, %f1704 }, { %r666, %r667, %r668, %r669 }, { %r526, %r527 }, { %f1701, %f1702, %f1703, %f1704 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1705, %f1706, %f1707, %f1708 }, { %r666, %r667, %r668, %r669 }, { %r532, %r533 }, { %f1705, %f1706, %f1707, %f1708 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1709, %f1710, %f1711, %f1712 }, { %r666, %r667, %r668, %r669 }, { %r538, %r539 }, { %f1709, %f1710, %f1711, %f1712 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1713, %f1714, %f1715, %f1716 }, { %r666, %r667, %r668, %r669 }, { %r544, %r545 }, { %f1713, %f1714, %f1715, %f1716 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1717, %f1718, %f1719, %f1720 }, { %r666, %r667, %r668, %r669 }, { %r550, %r551 }, { %f1717, %f1718, %f1719, %f1720 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1721, %f1722, %f1723, %f1724 }, { %r666, %r667, %r668, %r669 }, { %r556, %r557 }, { %f1721, %f1722, %f1723, %f1724 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1725, %f1726, %f1727, %f1728 }, { %r666, %r667, %r668, %r669 }, { %r562, %r563 }, { %f1725, %f1726, %f1727, %f1728 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1729, %f1730, %f1731, %f1732 }, { %r666, %r667, %r668, %r669 }, { %r568, %r569 }, { %f1729, %f1730, %f1731, %f1732 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1605, %f1606, %f1607, %f1608 }, { %r714, %r715, %r716, %r717 }, { %r718, %r719 }, { %f1605, %f1606, %f1607, %f1608 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1609, %f1610, %f1611, %f1612 }, { %r714, %r715, %r716, %r717 }, { %r724, %r725 }, { %f1609, %f1610, %f1611, %f1612 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1613, %f1614, %f1615, %f1616 }, { %r714, %r715, %r716, %r717 }, { %r730, %r731 }, { %f1613, %f1614, %f1615, %f1616 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1617, %f1618, %f1619, %f1620 }, { %r714, %r715, %r716, %r717 }, { %r736, %r737 }, { %f1617, %f1618, %f1619, %f1620 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1621, %f1622, %f1623, %f1624 }, { %r714, %r715, %r716, %r717 }, { %r742, %r743 }, { %f1621, %f1622, %f1623, %f1624 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1625, %f1626, %f1627, %f1628 }, { %r714, %r715, %r716, %r717 }, { %r748, %r749 }, { %f1625, %f1626, %f1627, %f1628 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1629, %f1630, %f1631, %f1632 }, { %r714, %r715, %r716, %r717 }, { %r754, %r755 }, { %f1629, %f1630, %f1631, %f1632 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1633, %f1634, %f1635, %f1636 }, { %r714, %r715, %r716, %r717 }, { %r760, %r761 }, { %f1633, %f1634, %f1635, %f1636 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1637, %f1638, %f1639, %f1640 }, { %r762, %r763, %r764, %r765 }, { %r718, %r719 }, { %f1637, %f1638, %f1639, %f1640 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1641, %f1642, %f1643, %f1644 }, { %r762, %r763, %r764, %r765 }, { %r724, %r725 }, { %f1641, %f1642, %f1643, %f1644 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1645, %f1646, %f1647, %f1648 }, { %r762, %r763, %r764, %r765 }, { %r730, %r731 }, { %f1645, %f1646, %f1647, %f1648 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1649, %f1650, %f1651, %f1652 }, { %r762, %r763, %r764, %r765 }, { %r736, %r737 }, { %f1649, %f1650, %f1651, %f1652 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1653, %f1654, %f1655, %f1656 }, { %r762, %r763, %r764, %r765 }, { %r742, %r743 }, { %f1653, %f1654, %f1655, %f1656 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1657, %f1658, %f1659, %f1660 }, { %r762, %r763, %r764, %r765 }, { %r748, %r749 }, { %f1657, %f1658, %f1659, %f1660 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1661, %f1662, %f1663, %f1664 }, { %r762, %r763, %r764, %r765 }, { %r754, %r755 }, { %f1661, %f1662, %f1663, %f1664 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1665, %f1666, %f1667, %f1668 }, { %r762, %r763, %r764, %r765 }, { %r760, %r761 }, { %f1665, %f1666, %f1667, %f1668 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1669, %f1670, %f1671, %f1672 }, { %r810, %r811, %r812, %r813 }, { %r718, %r719 }, { %f1669, %f1670, %f1671, %f1672 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1673, %f1674, %f1675, %f1676 }, { %r810, %r811, %r812, %r813 }, { %r724, %r725 }, { %f1673, %f1674, %f1675, %f1676 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1677, %f1678, %f1679, %f1680 }, { %r810, %r811, %r812, %r813 }, { %r730, %r731 }, { %f1677, %f1678, %f1679, %f1680 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1681, %f1682, %f1683, %f1684 }, { %r810, %r811, %r812, %r813 }, { %r736, %r737 }, { %f1681, %f1682, %f1683, %f1684 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1685, %f1686, %f1687, %f1688 }, { %r810, %r811, %r812, %r813 }, { %r742, %r743 }, { %f1685, %f1686, %f1687, %f1688 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1689, %f1690, %f1691, %f1692 }, { %r810, %r811, %r812, %r813 }, { %r748, %r749 }, { %f1689, %f1690, %f1691, %f1692 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1693, %f1694, %f1695, %f1696 }, { %r810, %r811, %r812, %r813 }, { %r754, %r755 }, { %f1693, %f1694, %f1695, %f1696 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1697, %f1698, %f1699, %f1700 }, { %r810, %r811, %r812, %r813 }, { %r760, %r761 }, { %f1697, %f1698, %f1699, %f1700 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1701, %f1702, %f1703, %f1704 }, { %r858, %r859, %r860, %r861 }, { %r718, %r719 }, { %f1701, %f1702, %f1703, %f1704 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1705, %f1706, %f1707, %f1708 }, { %r858, %r859, %r860, %r861 }, { %r724, %r725 }, { %f1705, %f1706, %f1707, %f1708 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1709, %f1710, %f1711, %f1712 }, { %r858, %r859, %r860, %r861 }, { %r730, %r731 }, { %f1709, %f1710, %f1711, %f1712 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1713, %f1714, %f1715, %f1716 }, { %r858, %r859, %r860, %r861 }, { %r736, %r737 }, { %f1713, %f1714, %f1715, %f1716 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1717, %f1718, %f1719, %f1720 }, { %r858, %r859, %r860, %r861 }, { %r742, %r743 }, { %f1717, %f1718, %f1719, %f1720 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1721, %f1722, %f1723, %f1724 }, { %r858, %r859, %r860, %r861 }, { %r748, %r749 }, { %f1721, %f1722, %f1723, %f1724 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1725, %f1726, %f1727, %f1728 }, { %r858, %r859, %r860, %r861 }, { %r754, %r755 }, { %f1725, %f1726, %f1727, %f1728 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1729, %f1730, %f1731, %f1732 }, { %r858, %r859, %r860, %r861 }, { %r760, %r761 }, { %f1729, %f1730, %f1731, %f1732 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1605, %f1606, %f1607, %f1608 }, { %r906, %r907, %r908, %r909 }, { %r910, %r911 }, { %f1605, %f1606, %f1607, %f1608 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1609, %f1610, %f1611, %f1612 }, { %r906, %r907, %r908, %r909 }, { %r916, %r917 }, { %f1609, %f1610, %f1611, %f1612 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1613, %f1614, %f1615, %f1616 }, { %r906, %r907, %r908, %r909 }, { %r922, %r923 }, { %f1613, %f1614, %f1615, %f1616 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1617, %f1618, %f1619, %f1620 }, { %r906, %r907, %r908, %r909 }, { %r928, %r929 }, { %f1617, %f1618, %f1619, %f1620 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1621, %f1622, %f1623, %f1624 }, { %r906, %r907, %r908, %r909 }, { %r934, %r935 }, { %f1621, %f1622, %f1623, %f1624 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1625, %f1626, %f1627, %f1628 }, { %r906, %r907, %r908, %r909 }, { %r940, %r941 }, { %f1625, %f1626, %f1627, %f1628 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1629, %f1630, %f1631, %f1632 }, { %r906, %r907, %r908, %r909 }, { %r946, %r947 }, { %f1629, %f1630, %f1631, %f1632 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1633, %f1634, %f1635, %f1636 }, { %r906, %r907, %r908, %r909 }, { %r952, %r953 }, { %f1633, %f1634, %f1635, %f1636 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1637, %f1638, %f1639, %f1640 }, { %r954, %r955, %r956, %r957 }, { %r910, %r911 }, { %f1637, %f1638, %f1639, %f1640 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1641, %f1642, %f1643, %f1644 }, { %r954, %r955, %r956, %r957 }, { %r916, %r917 }, { %f1641, %f1642, %f1643, %f1644 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1645, %f1646, %f1647, %f1648 }, { %r954, %r955, %r956, %r957 }, { %r922, %r923 }, { %f1645, %f1646, %f1647, %f1648 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1649, %f1650, %f1651, %f1652 }, { %r954, %r955, %r956, %r957 }, { %r928, %r929 }, { %f1649, %f1650, %f1651, %f1652 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1653, %f1654, %f1655, %f1656 }, { %r954, %r955, %r956, %r957 }, { %r934, %r935 }, { %f1653, %f1654, %f1655, %f1656 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1657, %f1658, %f1659, %f1660 }, { %r954, %r955, %r956, %r957 }, { %r940, %r941 }, { %f1657, %f1658, %f1659, %f1660 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1661, %f1662, %f1663, %f1664 }, { %r954, %r955, %r956, %r957 }, { %r946, %r947 }, { %f1661, %f1662, %f1663, %f1664 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1665, %f1666, %f1667, %f1668 }, { %r954, %r955, %r956, %r957 }, { %r952, %r953 }, { %f1665, %f1666, %f1667, %f1668 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1669, %f1670, %f1671, %f1672 }, { %r1002, %r1003, %r1004, %r1005 }, { %r910, %r911 }, { %f1669, %f1670, %f1671, %f1672 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1673, %f1674, %f1675, %f1676 }, { %r1002, %r1003, %r1004, %r1005 }, { %r916, %r917 }, { %f1673, %f1674, %f1675, %f1676 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1677, %f1678, %f1679, %f1680 }, { %r1002, %r1003, %r1004, %r1005 }, { %r922, %r923 }, { %f1677, %f1678, %f1679, %f1680 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1681, %f1682, %f1683, %f1684 }, { %r1002, %r1003, %r1004, %r1005 }, { %r928, %r929 }, { %f1681, %f1682, %f1683, %f1684 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1685, %f1686, %f1687, %f1688 }, { %r1002, %r1003, %r1004, %r1005 }, { %r934, %r935 }, { %f1685, %f1686, %f1687, %f1688 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1689, %f1690, %f1691, %f1692 }, { %r1002, %r1003, %r1004, %r1005 }, { %r940, %r941 }, { %f1689, %f1690, %f1691, %f1692 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1693, %f1694, %f1695, %f1696 }, { %r1002, %r1003, %r1004, %r1005 }, { %r946, %r947 }, { %f1693, %f1694, %f1695, %f1696 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1697, %f1698, %f1699, %f1700 }, { %r1002, %r1003, %r1004, %r1005 }, { %r952, %r953 }, { %f1697, %f1698, %f1699, %f1700 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1701, %f1702, %f1703, %f1704 }, { %r1050, %r1051, %r1052, %r1053 }, { %r910, %r911 }, { %f1701, %f1702, %f1703, %f1704 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1705, %f1706, %f1707, %f1708 }, { %r1050, %r1051, %r1052, %r1053 }, { %r916, %r917 }, { %f1705, %f1706, %f1707, %f1708 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1709, %f1710, %f1711, %f1712 }, { %r1050, %r1051, %r1052, %r1053 }, { %r922, %r923 }, { %f1709, %f1710, %f1711, %f1712 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1713, %f1714, %f1715, %f1716 }, { %r1050, %r1051, %r1052, %r1053 }, { %r928, %r929 }, { %f1713, %f1714, %f1715, %f1716 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1717, %f1718, %f1719, %f1720 }, { %r1050, %r1051, %r1052, %r1053 }, { %r934, %r935 }, { %f1717, %f1718, %f1719, %f1720 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1721, %f1722, %f1723, %f1724 }, { %r1050, %r1051, %r1052, %r1053 }, { %r940, %r941 }, { %f1721, %f1722, %f1723, %f1724 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1725, %f1726, %f1727, %f1728 }, { %r1050, %r1051, %r1052, %r1053 }, { %r946, %r947 }, { %f1725, %f1726, %f1727, %f1728 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f1729, %f1730, %f1731, %f1732 }, { %r1050, %r1051, %r1052, %r1053 }, { %r952, %r953 }, { %f1729, %f1730, %f1731, %f1732 };
	// end inline asm
	add.s32 	%r1154, %r1336, 1;
	setp.lt.s32 	%p39, %r1154, 2;
	selp.b32 	%r1336, %r1154, 0, %p39;
	add.s64 	%rd232, %rd445, %rd41;
	add.s64 	%rd179, %rd232, 256;
	add.s64 	%rd180, %rd232, 65792;
	add.s64 	%rd181, %rd232, 131328;
	add.s64 	%rd182, %rd232, 196864;
	add.s64 	%rd183, %rd232, 262400;
	add.s64 	%rd184, %rd232, 327936;
	add.s64 	%rd185, %rd232, 393472;
	add.s64 	%rd186, %rd232, 459008;
	shl.b32 	%r1155, %r1336, 13;
	mul.wide.s32 	%rd233, %r1155, 4;
	add.s64 	%rd235, %rd79, %rd233;
	add.s64 	%rd237, %rd235, %rd236;
	add.s64 	%rd239, %rd235, %rd238;
	add.s64 	%rd241, %rd235, %rd240;
	add.s64 	%rd243, %rd235, %rd242;
	add.s64 	%rd245, %rd235, %rd244;
	add.s64 	%rd247, %rd235, %rd246;
	add.s64 	%rd249, %rd235, %rd248;
	add.s64 	%rd251, %rd235, %rd250;
	selp.b32 	%r1099, 16, 0, %p38;
	cvt.u32.u64 	%r1098, %rd237;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r1098 + 0 ], [ %rd179 + 0 ], 0x10, %r1099;
	// end inline asm
	cvt.u32.u64 	%r1100, %rd239;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r1100 + 0 ], [ %rd180 + 0 ], 0x10, %r1099;
	// end inline asm
	cvt.u32.u64 	%r1102, %rd241;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r1102 + 0 ], [ %rd181 + 0 ], 0x10, %r1099;
	// end inline asm
	cvt.u32.u64 	%r1104, %rd243;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r1104 + 0 ], [ %rd182 + 0 ], 0x10, %r1099;
	// end inline asm
	cvt.u32.u64 	%r1106, %rd245;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r1106 + 0 ], [ %rd183 + 0 ], 0x10, %r1099;
	// end inline asm
	cvt.u32.u64 	%r1108, %rd247;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r1108 + 0 ], [ %rd184 + 0 ], 0x10, %r1099;
	// end inline asm
	cvt.u32.u64 	%r1110, %rd249;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r1110 + 0 ], [ %rd185 + 0 ], 0x10, %r1099;
	// end inline asm
	cvt.u32.u64 	%r1112, %rd251;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r1112 + 0 ], [ %rd186 + 0 ], 0x10, %r1099;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	add.s64 	%rd252, %rd444, %rd41;
	add.s64 	%rd187, %rd252, 256;
	add.s64 	%rd188, %rd252, 65792;
	add.s64 	%rd189, %rd252, 131328;
	add.s64 	%rd190, %rd252, 196864;
	shl.b32 	%r1156, %r1336, 12;
	mul.wide.s32 	%rd253, %r1156, 4;
	add.s64 	%rd255, %rd78, %rd253;
	bar.sync 	0;
	add.s64 	%rd257, %rd255, %rd256;
	add.s64 	%rd259, %rd255, %rd258;
	add.s64 	%rd261, %rd255, %rd260;
	add.s64 	%rd263, %rd255, %rd262;
	cvt.u32.u64 	%r1114, %rd257;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r1114 + 0 ], [ %rd187 + 0 ], 0x10, %r1099;
	// end inline asm
	cvt.u32.u64 	%r1116, %rd259;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r1116 + 0 ], [ %rd188 + 0 ], 0x10, %r1099;
	// end inline asm
	cvt.u32.u64 	%r1118, %rd261;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r1118 + 0 ], [ %rd189 + 0 ], 0x10, %r1099;
	// end inline asm
	cvt.u32.u64 	%r1120, %rd263;
	// begin inline asm
	@%p42 cp.async.cg.shared.global [ %r1120 + 0 ], [ %rd190 + 0 ], 0x10, %r1099;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	add.s32 	%r1157, %r1335, 1;
	setp.lt.s32 	%p40, %r1157, 2;
	selp.b32 	%r1335, %r1157, 0, %p40;
	shl.b32 	%r1158, %r1335, 13;
	mul.wide.s32 	%rd264, %r1158, 4;
	add.s64 	%rd447, %rd79, %rd264;
	mov.b32 	%r1332, 0;
	// begin inline asm
	cp.async.wait_group 0x2;
	// end inline asm
	bar.sync 	0;
	shl.b32 	%r1159, %r1335, 12;
	mul.wide.s32 	%rd265, %r1159, 4;
	add.s64 	%rd446, %rd78, %rd265;
	add.s64 	%rd445, %rd445, 128;
	add.s64 	%rd444, %rd444, 128;
	add.s32 	%r35, %r1330, 32;
	add.s64 	%rd443, %rd443, 128;
	setp.lt.u32 	%p41, %r1330, 480;
	mov.u32 	%r1330, %r35;
	@%p41 bra 	$L__BB44_1;
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	or.b32  	%r1288, %r3, 8;
	or.b32  	%r1289, %r3, 16;
	or.b32  	%r1290, %r3, 24;
	or.b32  	%r1291, %r3, 32;
	or.b32  	%r1292, %r3, 40;
	or.b32  	%r1293, %r3, 48;
	or.b32  	%r1294, %r3, 56;
	or.b32  	%r1295, %r3, 64;
	or.b32  	%r1296, %r3, 72;
	or.b32  	%r1297, %r3, 80;
	or.b32  	%r1298, %r3, 88;
	or.b32  	%r1299, %r3, 96;
	or.b32  	%r1300, %r3, 104;
	or.b32  	%r1301, %r3, 112;
	or.b32  	%r1302, %r3, 120;
	or.b32  	%r1303, %r3, 128;
	or.b32  	%r1304, %r3, 136;
	or.b32  	%r1305, %r3, 144;
	or.b32  	%r1306, %r3, 152;
	or.b32  	%r1307, %r3, 160;
	or.b32  	%r1308, %r3, 168;
	or.b32  	%r1309, %r3, 176;
	or.b32  	%r1310, %r3, 184;
	or.b32  	%r1311, %r3, 192;
	or.b32  	%r1312, %r3, 200;
	or.b32  	%r1313, %r3, 208;
	or.b32  	%r1314, %r3, 216;
	or.b32  	%r1315, %r3, 224;
	or.b32  	%r1316, %r3, 232;
	or.b32  	%r1317, %r3, 240;
	or.b32  	%r1318, %r3, 248;
	cvt.u64.u32 	%rd298, %r3;
	cvt.u64.u32 	%rd299, %r1288;
	cvt.u64.u32 	%rd300, %r1289;
	cvt.u64.u32 	%rd301, %r1290;
	cvt.u64.u32 	%rd302, %r1291;
	cvt.u64.u32 	%rd303, %r1292;
	cvt.u64.u32 	%rd304, %r1293;
	cvt.u64.u32 	%rd305, %r1294;
	cvt.u64.u32 	%rd306, %r1295;
	cvt.u64.u32 	%rd307, %r1296;
	cvt.u64.u32 	%rd308, %r1297;
	cvt.u64.u32 	%rd309, %r1298;
	cvt.u64.u32 	%rd310, %r1299;
	cvt.u64.u32 	%rd311, %r1300;
	cvt.u64.u32 	%rd312, %r1301;
	cvt.u64.u32 	%rd313, %r1302;
	cvt.u64.u32 	%rd314, %r1303;
	cvt.u64.u32 	%rd315, %r1304;
	cvt.u64.u32 	%rd316, %r1305;
	cvt.u64.u32 	%rd317, %r1306;
	cvt.u64.u32 	%rd318, %r1307;
	cvt.u64.u32 	%rd319, %r1308;
	cvt.u64.u32 	%rd320, %r1309;
	cvt.u64.u32 	%rd321, %r1310;
	cvt.u64.u32 	%rd322, %r1311;
	cvt.u64.u32 	%rd323, %r1312;
	cvt.u64.u32 	%rd324, %r1313;
	cvt.u64.u32 	%rd325, %r1314;
	cvt.u64.u32 	%rd326, %r1315;
	cvt.u64.u32 	%rd327, %r1316;
	cvt.u64.u32 	%rd328, %r1317;
	cvt.u64.u32 	%rd329, %r1318;
	or.b64  	%rd330, %rd3, %rd298;
	or.b64  	%rd331, %rd3, %rd299;
	or.b64  	%rd332, %rd3, %rd300;
	or.b64  	%rd333, %rd3, %rd301;
	or.b64  	%rd334, %rd3, %rd302;
	or.b64  	%rd335, %rd3, %rd303;
	or.b64  	%rd336, %rd3, %rd304;
	or.b64  	%rd337, %rd3, %rd305;
	or.b64  	%rd338, %rd3, %rd306;
	or.b64  	%rd339, %rd3, %rd307;
	or.b64  	%rd340, %rd3, %rd308;
	or.b64  	%rd341, %rd3, %rd309;
	or.b64  	%rd342, %rd3, %rd310;
	or.b64  	%rd343, %rd3, %rd311;
	or.b64  	%rd344, %rd3, %rd312;
	or.b64  	%rd345, %rd3, %rd313;
	or.b64  	%rd346, %rd3, %rd314;
	or.b64  	%rd347, %rd3, %rd315;
	or.b64  	%rd348, %rd3, %rd316;
	or.b64  	%rd349, %rd3, %rd317;
	or.b64  	%rd350, %rd3, %rd318;
	or.b64  	%rd351, %rd3, %rd319;
	or.b64  	%rd352, %rd3, %rd320;
	or.b64  	%rd353, %rd3, %rd321;
	or.b64  	%rd354, %rd3, %rd322;
	or.b64  	%rd355, %rd3, %rd323;
	or.b64  	%rd356, %rd3, %rd324;
	or.b64  	%rd357, %rd3, %rd325;
	or.b64  	%rd358, %rd3, %rd326;
	or.b64  	%rd359, %rd3, %rd327;
	or.b64  	%rd360, %rd3, %rd328;
	or.b64  	%rd361, %rd3, %rd329;
	and.b32  	%r1319, %r6, 124;
	cvt.u64.u32 	%rd362, %r1319;
	or.b64  	%rd363, %rd4, %rd362;
	mul.lo.s64 	%rd364, %rd330, 1536;
	add.s64 	%rd365, %rd1, %rd364;
	shl.b64 	%rd366, %rd363, 2;
	add.s64 	%rd266, %rd365, %rd366;
	mul.lo.s64 	%rd367, %rd331, 1536;
	add.s64 	%rd368, %rd1, %rd367;
	add.s64 	%rd267, %rd368, %rd366;
	mul.lo.s64 	%rd369, %rd332, 1536;
	add.s64 	%rd370, %rd1, %rd369;
	add.s64 	%rd268, %rd370, %rd366;
	mul.lo.s64 	%rd371, %rd333, 1536;
	add.s64 	%rd372, %rd1, %rd371;
	add.s64 	%rd269, %rd372, %rd366;
	mul.lo.s64 	%rd373, %rd334, 1536;
	add.s64 	%rd374, %rd1, %rd373;
	add.s64 	%rd270, %rd374, %rd366;
	mul.lo.s64 	%rd375, %rd335, 1536;
	add.s64 	%rd376, %rd1, %rd375;
	add.s64 	%rd271, %rd376, %rd366;
	mul.lo.s64 	%rd377, %rd336, 1536;
	add.s64 	%rd378, %rd1, %rd377;
	add.s64 	%rd272, %rd378, %rd366;
	mul.lo.s64 	%rd379, %rd337, 1536;
	add.s64 	%rd380, %rd1, %rd379;
	add.s64 	%rd273, %rd380, %rd366;
	mul.lo.s64 	%rd381, %rd338, 1536;
	add.s64 	%rd382, %rd1, %rd381;
	add.s64 	%rd274, %rd382, %rd366;
	mul.lo.s64 	%rd383, %rd339, 1536;
	add.s64 	%rd384, %rd1, %rd383;
	add.s64 	%rd275, %rd384, %rd366;
	mul.lo.s64 	%rd385, %rd340, 1536;
	add.s64 	%rd386, %rd1, %rd385;
	add.s64 	%rd276, %rd386, %rd366;
	mul.lo.s64 	%rd387, %rd341, 1536;
	add.s64 	%rd388, %rd1, %rd387;
	add.s64 	%rd277, %rd388, %rd366;
	mul.lo.s64 	%rd389, %rd342, 1536;
	add.s64 	%rd390, %rd1, %rd389;
	add.s64 	%rd278, %rd390, %rd366;
	mul.lo.s64 	%rd391, %rd343, 1536;
	add.s64 	%rd392, %rd1, %rd391;
	add.s64 	%rd279, %rd392, %rd366;
	mul.lo.s64 	%rd393, %rd344, 1536;
	add.s64 	%rd394, %rd1, %rd393;
	add.s64 	%rd280, %rd394, %rd366;
	mul.lo.s64 	%rd395, %rd345, 1536;
	add.s64 	%rd396, %rd1, %rd395;
	add.s64 	%rd281, %rd396, %rd366;
	mul.lo.s64 	%rd397, %rd346, 1536;
	add.s64 	%rd398, %rd1, %rd397;
	add.s64 	%rd282, %rd398, %rd366;
	mul.lo.s64 	%rd399, %rd347, 1536;
	add.s64 	%rd400, %rd1, %rd399;
	add.s64 	%rd283, %rd400, %rd366;
	mul.lo.s64 	%rd401, %rd348, 1536;
	add.s64 	%rd402, %rd1, %rd401;
	add.s64 	%rd284, %rd402, %rd366;
	mul.lo.s64 	%rd403, %rd349, 1536;
	add.s64 	%rd404, %rd1, %rd403;
	add.s64 	%rd285, %rd404, %rd366;
	mul.lo.s64 	%rd405, %rd350, 1536;
	add.s64 	%rd406, %rd1, %rd405;
	add.s64 	%rd286, %rd406, %rd366;
	mul.lo.s64 	%rd407, %rd351, 1536;
	add.s64 	%rd408, %rd1, %rd407;
	add.s64 	%rd287, %rd408, %rd366;
	mul.lo.s64 	%rd409, %rd352, 1536;
	add.s64 	%rd410, %rd1, %rd409;
	add.s64 	%rd288, %rd410, %rd366;
	mul.lo.s64 	%rd411, %rd353, 1536;
	add.s64 	%rd412, %rd1, %rd411;
	add.s64 	%rd289, %rd412, %rd366;
	mul.lo.s64 	%rd413, %rd354, 1536;
	add.s64 	%rd414, %rd1, %rd413;
	add.s64 	%rd290, %rd414, %rd366;
	mul.lo.s64 	%rd415, %rd355, 1536;
	add.s64 	%rd416, %rd1, %rd415;
	add.s64 	%rd291, %rd416, %rd366;
	mul.lo.s64 	%rd417, %rd356, 1536;
	add.s64 	%rd418, %rd1, %rd417;
	add.s64 	%rd292, %rd418, %rd366;
	mul.lo.s64 	%rd419, %rd357, 1536;
	add.s64 	%rd420, %rd1, %rd419;
	add.s64 	%rd293, %rd420, %rd366;
	mul.lo.s64 	%rd421, %rd358, 1536;
	add.s64 	%rd422, %rd1, %rd421;
	add.s64 	%rd294, %rd422, %rd366;
	mul.lo.s64 	%rd423, %rd359, 1536;
	add.s64 	%rd424, %rd1, %rd423;
	add.s64 	%rd295, %rd424, %rd366;
	mul.lo.s64 	%rd425, %rd360, 1536;
	add.s64 	%rd426, %rd1, %rd425;
	add.s64 	%rd296, %rd426, %rd366;
	mul.lo.s64 	%rd427, %rd361, 1536;
	add.s64 	%rd428, %rd1, %rd427;
	add.s64 	%rd297, %rd428, %rd366;
	shl.b32 	%r1320, %r1, 1;
	and.b32  	%r1321, %r1320, 6;
	and.b32  	%r1323, %r164, 55;
	or.b32  	%r1324, %r9, %r1321;
	mul.lo.s32 	%r1325, %r1323, 132;
	add.s32 	%r1326, %r1324, %r1325;
	mul.wide.u32 	%rd429, %r1326, 4;
	mov.u64 	%rd430, global_smem;
	add.s64 	%rd431, %rd430, %rd429;
	st.shared.v2.f32 	[%rd431], {%f1605, %f1606};
	add.s32 	%r1327, %r1325, 1056;
	cvt.u64.u32 	%rd432, %r1324;
	cvt.u64.u32 	%rd433, %r1325;
	add.s64 	%rd434, %rd433, %rd432;
	shl.b64 	%rd435, %rd434, 2;
	add.s64 	%rd436, %rd430, %rd435;
	st.shared.v2.f32 	[%rd436+4224], {%f1607, %f1608};
	st.shared.v2.f32 	[%rd436+64], {%f1609, %f1610};
	cvt.u64.u32 	%rd437, %r1327;
	add.s64 	%rd438, %rd432, %rd437;
	shl.b64 	%rd439, %rd438, 2;
	add.s64 	%rd440, %rd430, %rd439;
	st.shared.v2.f32 	[%rd440+64], {%f1611, %f1612};
	st.shared.v2.f32 	[%rd436+128], {%f1613, %f1614};
	st.shared.v2.f32 	[%rd440+128], {%f1615, %f1616};
	st.shared.v2.f32 	[%rd436+192], {%f1617, %f1618};
	st.shared.v2.f32 	[%rd440+192], {%f1619, %f1620};
	st.shared.v2.f32 	[%rd436+256], {%f1621, %f1622};
	st.shared.v2.f32 	[%rd440+256], {%f1623, %f1624};
	st.shared.v2.f32 	[%rd436+320], {%f1625, %f1626};
	st.shared.v2.f32 	[%rd440+320], {%f1627, %f1628};
	st.shared.v2.f32 	[%rd436+384], {%f1629, %f1630};
	st.shared.v2.f32 	[%rd440+384], {%f1631, %f1632};
	st.shared.v2.f32 	[%rd436+448], {%f1633, %f1634};
	st.shared.v2.f32 	[%rd440+448], {%f1635, %f1636};
	bar.sync 	0;
	shl.b32 	%r1328, %r2, 2;
	mad.lo.s32 	%r1329, %r3, 132, %r1328;
	mul.wide.u32 	%rd441, %r1329, 4;
	add.s64 	%rd442, %rd430, %rd441;
	ld.shared.v4.u32 	{%r1160, %r1161, %r1162, %r1163}, [%rd442];
	ld.shared.v4.u32 	{%r1164, %r1165, %r1166, %r1167}, [%rd442+4224];
	ld.shared.v4.u32 	{%r1168, %r1169, %r1170, %r1171}, [%rd442+8448];
	ld.shared.v4.u32 	{%r1172, %r1173, %r1174, %r1175}, [%rd442+12672];
	ld.shared.v4.u32 	{%r1176, %r1177, %r1178, %r1179}, [%rd442+16896];
	ld.shared.v4.u32 	{%r1180, %r1181, %r1182, %r1183}, [%rd442+21120];
	ld.shared.v4.u32 	{%r1184, %r1185, %r1186, %r1187}, [%rd442+25344];
	ld.shared.v4.u32 	{%r1188, %r1189, %r1190, %r1191}, [%rd442+29568];
	bar.sync 	0;
	st.shared.v2.f32 	[%rd431], {%f1637, %f1638};
	st.shared.v2.f32 	[%rd436+4224], {%f1639, %f1640};
	st.shared.v2.f32 	[%rd436+64], {%f1641, %f1642};
	st.shared.v2.f32 	[%rd440+64], {%f1643, %f1644};
	st.shared.v2.f32 	[%rd436+128], {%f1645, %f1646};
	st.shared.v2.f32 	[%rd440+128], {%f1647, %f1648};
	st.shared.v2.f32 	[%rd436+192], {%f1649, %f1650};
	st.shared.v2.f32 	[%rd440+192], {%f1651, %f1652};
	st.shared.v2.f32 	[%rd436+256], {%f1653, %f1654};
	st.shared.v2.f32 	[%rd440+256], {%f1655, %f1656};
	st.shared.v2.f32 	[%rd436+320], {%f1657, %f1658};
	st.shared.v2.f32 	[%rd440+320], {%f1659, %f1660};
	st.shared.v2.f32 	[%rd436+384], {%f1661, %f1662};
	st.shared.v2.f32 	[%rd440+384], {%f1663, %f1664};
	st.shared.v2.f32 	[%rd436+448], {%f1665, %f1666};
	st.shared.v2.f32 	[%rd440+448], {%f1667, %f1668};
	bar.sync 	0;
	ld.shared.v4.u32 	{%r1192, %r1193, %r1194, %r1195}, [%rd442];
	ld.shared.v4.u32 	{%r1196, %r1197, %r1198, %r1199}, [%rd442+4224];
	ld.shared.v4.u32 	{%r1200, %r1201, %r1202, %r1203}, [%rd442+8448];
	ld.shared.v4.u32 	{%r1204, %r1205, %r1206, %r1207}, [%rd442+12672];
	ld.shared.v4.u32 	{%r1208, %r1209, %r1210, %r1211}, [%rd442+16896];
	ld.shared.v4.u32 	{%r1212, %r1213, %r1214, %r1215}, [%rd442+21120];
	ld.shared.v4.u32 	{%r1216, %r1217, %r1218, %r1219}, [%rd442+25344];
	ld.shared.v4.u32 	{%r1220, %r1221, %r1222, %r1223}, [%rd442+29568];
	bar.sync 	0;
	st.shared.v2.f32 	[%rd431], {%f1669, %f1670};
	st.shared.v2.f32 	[%rd436+4224], {%f1671, %f1672};
	st.shared.v2.f32 	[%rd436+64], {%f1673, %f1674};
	st.shared.v2.f32 	[%rd440+64], {%f1675, %f1676};
	st.shared.v2.f32 	[%rd436+128], {%f1677, %f1678};
	st.shared.v2.f32 	[%rd440+128], {%f1679, %f1680};
	st.shared.v2.f32 	[%rd436+192], {%f1681, %f1682};
	st.shared.v2.f32 	[%rd440+192], {%f1683, %f1684};
	st.shared.v2.f32 	[%rd436+256], {%f1685, %f1686};
	st.shared.v2.f32 	[%rd440+256], {%f1687, %f1688};
	st.shared.v2.f32 	[%rd436+320], {%f1689, %f1690};
	st.shared.v2.f32 	[%rd440+320], {%f1691, %f1692};
	st.shared.v2.f32 	[%rd436+384], {%f1693, %f1694};
	st.shared.v2.f32 	[%rd440+384], {%f1695, %f1696};
	st.shared.v2.f32 	[%rd436+448], {%f1697, %f1698};
	st.shared.v2.f32 	[%rd440+448], {%f1699, %f1700};
	bar.sync 	0;
	ld.shared.v4.u32 	{%r1224, %r1225, %r1226, %r1227}, [%rd442];
	ld.shared.v4.u32 	{%r1228, %r1229, %r1230, %r1231}, [%rd442+4224];
	ld.shared.v4.u32 	{%r1232, %r1233, %r1234, %r1235}, [%rd442+8448];
	ld.shared.v4.u32 	{%r1236, %r1237, %r1238, %r1239}, [%rd442+12672];
	ld.shared.v4.u32 	{%r1240, %r1241, %r1242, %r1243}, [%rd442+16896];
	ld.shared.v4.u32 	{%r1244, %r1245, %r1246, %r1247}, [%rd442+21120];
	ld.shared.v4.u32 	{%r1248, %r1249, %r1250, %r1251}, [%rd442+25344];
	ld.shared.v4.u32 	{%r1252, %r1253, %r1254, %r1255}, [%rd442+29568];
	bar.sync 	0;
	st.shared.v2.f32 	[%rd431], {%f1701, %f1702};
	st.shared.v2.f32 	[%rd436+4224], {%f1703, %f1704};
	st.shared.v2.f32 	[%rd436+64], {%f1705, %f1706};
	st.shared.v2.f32 	[%rd440+64], {%f1707, %f1708};
	st.shared.v2.f32 	[%rd436+128], {%f1709, %f1710};
	st.shared.v2.f32 	[%rd440+128], {%f1711, %f1712};
	st.shared.v2.f32 	[%rd436+192], {%f1713, %f1714};
	st.shared.v2.f32 	[%rd440+192], {%f1715, %f1716};
	st.shared.v2.f32 	[%rd436+256], {%f1717, %f1718};
	st.shared.v2.f32 	[%rd440+256], {%f1719, %f1720};
	st.shared.v2.f32 	[%rd436+320], {%f1721, %f1722};
	st.shared.v2.f32 	[%rd440+320], {%f1723, %f1724};
	st.shared.v2.f32 	[%rd436+384], {%f1725, %f1726};
	st.shared.v2.f32 	[%rd440+384], {%f1727, %f1728};
	st.shared.v2.f32 	[%rd436+448], {%f1729, %f1730};
	st.shared.v2.f32 	[%rd440+448], {%f1731, %f1732};
	bar.sync 	0;
	ld.shared.v4.u32 	{%r1256, %r1257, %r1258, %r1259}, [%rd442];
	ld.shared.v4.u32 	{%r1260, %r1261, %r1262, %r1263}, [%rd442+4224];
	ld.shared.v4.u32 	{%r1264, %r1265, %r1266, %r1267}, [%rd442+8448];
	ld.shared.v4.u32 	{%r1268, %r1269, %r1270, %r1271}, [%rd442+12672];
	ld.shared.v4.u32 	{%r1272, %r1273, %r1274, %r1275}, [%rd442+16896];
	ld.shared.v4.u32 	{%r1276, %r1277, %r1278, %r1279}, [%rd442+21120];
	ld.shared.v4.u32 	{%r1280, %r1281, %r1282, %r1283}, [%rd442+25344];
	ld.shared.v4.u32 	{%r1284, %r1285, %r1286, %r1287}, [%rd442+29568];
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd266 + 0 ], { %r1160, %r1161, %r1162, %r1163 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd267 + 0 ], { %r1164, %r1165, %r1166, %r1167 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd268 + 0 ], { %r1168, %r1169, %r1170, %r1171 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd269 + 0 ], { %r1172, %r1173, %r1174, %r1175 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd270 + 0 ], { %r1176, %r1177, %r1178, %r1179 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd271 + 0 ], { %r1180, %r1181, %r1182, %r1183 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd272 + 0 ], { %r1184, %r1185, %r1186, %r1187 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd273 + 0 ], { %r1188, %r1189, %r1190, %r1191 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd274 + 0 ], { %r1192, %r1193, %r1194, %r1195 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd275 + 0 ], { %r1196, %r1197, %r1198, %r1199 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd276 + 0 ], { %r1200, %r1201, %r1202, %r1203 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd277 + 0 ], { %r1204, %r1205, %r1206, %r1207 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd278 + 0 ], { %r1208, %r1209, %r1210, %r1211 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd279 + 0 ], { %r1212, %r1213, %r1214, %r1215 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd280 + 0 ], { %r1216, %r1217, %r1218, %r1219 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd281 + 0 ], { %r1220, %r1221, %r1222, %r1223 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd282 + 0 ], { %r1224, %r1225, %r1226, %r1227 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd283 + 0 ], { %r1228, %r1229, %r1230, %r1231 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd284 + 0 ], { %r1232, %r1233, %r1234, %r1235 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd285 + 0 ], { %r1236, %r1237, %r1238, %r1239 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd286 + 0 ], { %r1240, %r1241, %r1242, %r1243 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd287 + 0 ], { %r1244, %r1245, %r1246, %r1247 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd288 + 0 ], { %r1248, %r1249, %r1250, %r1251 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd289 + 0 ], { %r1252, %r1253, %r1254, %r1255 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd290 + 0 ], { %r1256, %r1257, %r1258, %r1259 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd291 + 0 ], { %r1260, %r1261, %r1262, %r1263 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd292 + 0 ], { %r1264, %r1265, %r1266, %r1267 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd293 + 0 ], { %r1268, %r1269, %r1270, %r1271 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd294 + 0 ], { %r1272, %r1273, %r1274, %r1275 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd295 + 0 ], { %r1276, %r1277, %r1278, %r1279 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd296 + 0 ], { %r1280, %r1281, %r1282, %r1283 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd297 + 0 ], { %r1284, %r1285, %r1286, %r1287 };
	// end inline asm
	ret;

}
	// .globl	gemm_fusion_dot_526_1
.visible .entry gemm_fusion_dot_526_1(
	.param .u64 gemm_fusion_dot_526_1_param_0,
	.param .u64 gemm_fusion_dot_526_1_param_1,
	.param .u64 gemm_fusion_dot_526_1_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<69>;
	.reg .b32 	%r<346>;
	.reg .f32 	%f<197>;
	.reg .b64 	%rd<222>;

	ld.param.u64 	%rd34, [gemm_fusion_dot_526_1_param_0];
	ld.param.u64 	%rd35, [gemm_fusion_dot_526_1_param_2];
	cvta.to.global.u64 	%rd36, %rd35;
	ld.param.u64 	%rd37, [gemm_fusion_dot_526_1_param_1];
	cvta.to.global.u64 	%rd38, %rd37;
	cvta.to.global.u64 	%rd39, %rd34;
	// begin inline asm
	mov.u32 %r1, %ctaid.x;
	// end inline asm
	shr.s32 	%r239, %r1, 31;
	shr.u32 	%r240, %r239, 29;
	add.s32 	%r241, %r1, %r240;
	and.b32  	%r242, %r241, -8;
	mov.b32 	%r243, 200;
	sub.s32 	%r244, %r243, %r242;
	min.s32 	%r245, %r244, 8;
	rem.s32 	%r246, %r1, %r245;
	add.s32 	%r247, %r242, %r246;
	sub.s32 	%r248, %r1, %r242;
	div.s32 	%r249, %r248, %r245;
	shl.b32 	%r250, %r247, 8;
	// begin inline asm
	mov.u32 %r2, %ctaid.y;
	// end inline asm
	mul.lo.s32 	%r251, %r2, 6;
	mul.wide.s32 	%rd40, %r251, 4;
	add.s64 	%rd41, %rd39, %rd40;
	cvt.s64.s32 	%rd42, %r250;
	shl.b32 	%r252, %r249, 4;
	mul.lo.s32 	%r253, %r2, 36;
	mul.wide.s32 	%rd43, %r253, 4;
	add.s64 	%rd44, %rd38, %rd43;
	cvt.s64.s32 	%rd45, %r252;
	mov.u32 	%r254, %tid.x;
	shr.u32 	%r255, %r254, 5;
	shr.u32 	%r256, %r254, 3;
	or.b32  	%r257, %r256, 16;
	or.b32  	%r258, %r256, 32;
	or.b32  	%r259, %r256, 48;
	or.b32  	%r260, %r256, 64;
	or.b32  	%r261, %r256, 80;
	or.b32  	%r262, %r256, 96;
	or.b32  	%r263, %r256, 112;
	or.b32  	%r264, %r256, 128;
	or.b32  	%r265, %r256, 144;
	or.b32  	%r266, %r256, 160;
	or.b32  	%r267, %r256, 176;
	or.b32  	%r268, %r256, 192;
	or.b32  	%r269, %r256, 208;
	or.b32  	%r270, %r256, 224;
	or.b32  	%r271, %r256, 240;
	cvt.u64.u32 	%rd46, %r256;
	cvt.u64.u32 	%rd47, %r257;
	cvt.u64.u32 	%rd48, %r258;
	cvt.u64.u32 	%rd49, %r259;
	cvt.u64.u32 	%rd50, %r260;
	cvt.u64.u32 	%rd51, %r261;
	cvt.u64.u32 	%rd52, %r262;
	cvt.u64.u32 	%rd53, %r263;
	cvt.u64.u32 	%rd54, %r264;
	cvt.u64.u32 	%rd55, %r265;
	cvt.u64.u32 	%rd56, %r266;
	cvt.u64.u32 	%rd57, %r267;
	cvt.u64.u32 	%rd58, %r268;
	cvt.u64.u32 	%rd59, %r269;
	cvt.u64.u32 	%rd60, %r270;
	cvt.u64.u32 	%rd61, %r271;
	or.b64  	%rd62, %rd42, %rd46;
	or.b64  	%rd63, %rd42, %rd47;
	or.b64  	%rd64, %rd42, %rd48;
	or.b64  	%rd65, %rd42, %rd49;
	or.b64  	%rd66, %rd42, %rd50;
	or.b64  	%rd67, %rd42, %rd51;
	or.b64  	%rd68, %rd42, %rd52;
	or.b64  	%rd69, %rd42, %rd53;
	or.b64  	%rd70, %rd42, %rd54;
	or.b64  	%rd71, %rd42, %rd55;
	or.b64  	%rd72, %rd42, %rd56;
	or.b64  	%rd73, %rd42, %rd57;
	or.b64  	%rd74, %rd42, %rd58;
	or.b64  	%rd75, %rd42, %rd59;
	or.b64  	%rd76, %rd42, %rd60;
	or.b64  	%rd77, %rd42, %rd61;
	mul.lo.s64 	%rd78, %rd62, 384;
	mul.lo.s64 	%rd79, %rd63, 384;
	mul.lo.s64 	%rd80, %rd64, 384;
	mul.lo.s64 	%rd81, %rd65, 384;
	mul.lo.s64 	%rd82, %rd66, 384;
	mul.lo.s64 	%rd83, %rd67, 384;
	mul.lo.s64 	%rd84, %rd68, 384;
	mul.lo.s64 	%rd85, %rd69, 384;
	mul.lo.s64 	%rd86, %rd70, 384;
	mul.lo.s64 	%rd87, %rd71, 384;
	mul.lo.s64 	%rd88, %rd72, 384;
	mul.lo.s64 	%rd89, %rd73, 384;
	mul.lo.s64 	%rd90, %rd74, 384;
	mul.lo.s64 	%rd91, %rd75, 384;
	mul.lo.s64 	%rd92, %rd76, 384;
	mul.lo.s64 	%rd93, %rd77, 384;
	shl.b32 	%r272, %r254, 1;
	and.b32  	%r273, %r272, 14;
	cvt.u64.u32 	%rd94, %r273;
	or.b64  	%rd95, %rd78, %rd94;
	or.b64  	%rd96, %rd79, %rd94;
	or.b64  	%rd97, %rd80, %rd94;
	or.b64  	%rd98, %rd81, %rd94;
	or.b64  	%rd99, %rd82, %rd94;
	or.b64  	%rd100, %rd83, %rd94;
	or.b64  	%rd101, %rd84, %rd94;
	or.b64  	%rd102, %rd85, %rd94;
	or.b64  	%rd103, %rd86, %rd94;
	or.b64  	%rd104, %rd87, %rd94;
	or.b64  	%rd105, %rd88, %rd94;
	or.b64  	%rd106, %rd89, %rd94;
	or.b64  	%rd107, %rd90, %rd94;
	or.b64  	%rd108, %rd91, %rd94;
	or.b64  	%rd109, %rd92, %rd94;
	or.b64  	%rd110, %rd93, %rd94;
	shl.b64 	%rd111, %rd95, 2;
	add.s64 	%rd1, %rd41, %rd111;
	shl.b64 	%rd112, %rd96, 2;
	add.s64 	%rd2, %rd41, %rd112;
	shl.b64 	%rd113, %rd97, 2;
	add.s64 	%rd3, %rd41, %rd113;
	shl.b64 	%rd114, %rd98, 2;
	add.s64 	%rd4, %rd41, %rd114;
	shl.b64 	%rd115, %rd99, 2;
	add.s64 	%rd5, %rd41, %rd115;
	shl.b64 	%rd116, %rd100, 2;
	add.s64 	%rd6, %rd41, %rd116;
	shl.b64 	%rd117, %rd101, 2;
	add.s64 	%rd7, %rd41, %rd117;
	shl.b64 	%rd118, %rd102, 2;
	add.s64 	%rd8, %rd41, %rd118;
	shl.b64 	%rd119, %rd103, 2;
	add.s64 	%rd9, %rd41, %rd119;
	shl.b64 	%rd120, %rd104, 2;
	add.s64 	%rd10, %rd41, %rd120;
	shl.b64 	%rd121, %rd105, 2;
	add.s64 	%rd11, %rd41, %rd121;
	shl.b64 	%rd122, %rd106, 2;
	add.s64 	%rd12, %rd41, %rd122;
	shl.b64 	%rd123, %rd107, 2;
	add.s64 	%rd13, %rd41, %rd123;
	shl.b64 	%rd124, %rd108, 2;
	add.s64 	%rd14, %rd41, %rd124;
	shl.b64 	%rd125, %rd109, 2;
	add.s64 	%rd15, %rd41, %rd125;
	shl.b64 	%rd126, %rd110, 2;
	add.s64 	%rd16, %rd41, %rd126;
	setp.lt.u32 	%p1, %r273, 6;
	mov.b32 	%r5, 0;
	// begin inline asm
	mov.u32 %r3, 0x0;
	mov.u32 %r4, 0x0;
	@%p1 ld.global.v2.b32 { %r3, %r4 }, [ %rd1 + 0 ];
	@!%p1 mov.u32 %r3, %r5;
	@!%p1 mov.u32 %r4, %r5;
	// end inline asm
	mov.b32 	%f129, %r3;
	mov.b32 	%f130, %r4;
	// begin inline asm
	mov.u32 %r7, 0x0;
	mov.u32 %r8, 0x0;
	@%p1 ld.global.v2.b32 { %r7, %r8 }, [ %rd2 + 0 ];
	@!%p1 mov.u32 %r7, %r5;
	@!%p1 mov.u32 %r8, %r5;
	// end inline asm
	mov.b32 	%f131, %r7;
	mov.b32 	%f132, %r8;
	// begin inline asm
	mov.u32 %r11, 0x0;
	mov.u32 %r12, 0x0;
	@%p1 ld.global.v2.b32 { %r11, %r12 }, [ %rd3 + 0 ];
	@!%p1 mov.u32 %r11, %r5;
	@!%p1 mov.u32 %r12, %r5;
	// end inline asm
	mov.b32 	%f133, %r11;
	mov.b32 	%f134, %r12;
	// begin inline asm
	mov.u32 %r15, 0x0;
	mov.u32 %r16, 0x0;
	@%p1 ld.global.v2.b32 { %r15, %r16 }, [ %rd4 + 0 ];
	@!%p1 mov.u32 %r15, %r5;
	@!%p1 mov.u32 %r16, %r5;
	// end inline asm
	mov.b32 	%f135, %r15;
	mov.b32 	%f136, %r16;
	// begin inline asm
	mov.u32 %r19, 0x0;
	mov.u32 %r20, 0x0;
	@%p1 ld.global.v2.b32 { %r19, %r20 }, [ %rd5 + 0 ];
	@!%p1 mov.u32 %r19, %r5;
	@!%p1 mov.u32 %r20, %r5;
	// end inline asm
	mov.b32 	%f137, %r19;
	mov.b32 	%f138, %r20;
	// begin inline asm
	mov.u32 %r23, 0x0;
	mov.u32 %r24, 0x0;
	@%p1 ld.global.v2.b32 { %r23, %r24 }, [ %rd6 + 0 ];
	@!%p1 mov.u32 %r23, %r5;
	@!%p1 mov.u32 %r24, %r5;
	// end inline asm
	mov.b32 	%f139, %r23;
	mov.b32 	%f140, %r24;
	// begin inline asm
	mov.u32 %r27, 0x0;
	mov.u32 %r28, 0x0;
	@%p1 ld.global.v2.b32 { %r27, %r28 }, [ %rd7 + 0 ];
	@!%p1 mov.u32 %r27, %r5;
	@!%p1 mov.u32 %r28, %r5;
	// end inline asm
	mov.b32 	%f141, %r27;
	mov.b32 	%f142, %r28;
	// begin inline asm
	mov.u32 %r31, 0x0;
	mov.u32 %r32, 0x0;
	@%p1 ld.global.v2.b32 { %r31, %r32 }, [ %rd8 + 0 ];
	@!%p1 mov.u32 %r31, %r5;
	@!%p1 mov.u32 %r32, %r5;
	// end inline asm
	mov.b32 	%f143, %r31;
	mov.b32 	%f144, %r32;
	// begin inline asm
	mov.u32 %r35, 0x0;
	mov.u32 %r36, 0x0;
	@%p1 ld.global.v2.b32 { %r35, %r36 }, [ %rd9 + 0 ];
	@!%p1 mov.u32 %r35, %r5;
	@!%p1 mov.u32 %r36, %r5;
	// end inline asm
	mov.b32 	%f145, %r35;
	mov.b32 	%f146, %r36;
	// begin inline asm
	mov.u32 %r39, 0x0;
	mov.u32 %r40, 0x0;
	@%p1 ld.global.v2.b32 { %r39, %r40 }, [ %rd10 + 0 ];
	@!%p1 mov.u32 %r39, %r5;
	@!%p1 mov.u32 %r40, %r5;
	// end inline asm
	mov.b32 	%f147, %r39;
	mov.b32 	%f148, %r40;
	// begin inline asm
	mov.u32 %r43, 0x0;
	mov.u32 %r44, 0x0;
	@%p1 ld.global.v2.b32 { %r43, %r44 }, [ %rd11 + 0 ];
	@!%p1 mov.u32 %r43, %r5;
	@!%p1 mov.u32 %r44, %r5;
	// end inline asm
	mov.b32 	%f149, %r43;
	mov.b32 	%f150, %r44;
	// begin inline asm
	mov.u32 %r47, 0x0;
	mov.u32 %r48, 0x0;
	@%p1 ld.global.v2.b32 { %r47, %r48 }, [ %rd12 + 0 ];
	@!%p1 mov.u32 %r47, %r5;
	@!%p1 mov.u32 %r48, %r5;
	// end inline asm
	mov.b32 	%f151, %r47;
	mov.b32 	%f152, %r48;
	// begin inline asm
	mov.u32 %r51, 0x0;
	mov.u32 %r52, 0x0;
	@%p1 ld.global.v2.b32 { %r51, %r52 }, [ %rd13 + 0 ];
	@!%p1 mov.u32 %r51, %r5;
	@!%p1 mov.u32 %r52, %r5;
	// end inline asm
	mov.b32 	%f153, %r51;
	mov.b32 	%f154, %r52;
	// begin inline asm
	mov.u32 %r55, 0x0;
	mov.u32 %r56, 0x0;
	@%p1 ld.global.v2.b32 { %r55, %r56 }, [ %rd14 + 0 ];
	@!%p1 mov.u32 %r55, %r5;
	@!%p1 mov.u32 %r56, %r5;
	// end inline asm
	mov.b32 	%f155, %r55;
	mov.b32 	%f156, %r56;
	// begin inline asm
	mov.u32 %r59, 0x0;
	mov.u32 %r60, 0x0;
	@%p1 ld.global.v2.b32 { %r59, %r60 }, [ %rd15 + 0 ];
	@!%p1 mov.u32 %r59, %r5;
	@!%p1 mov.u32 %r60, %r5;
	// end inline asm
	mov.b32 	%f157, %r59;
	mov.b32 	%f158, %r60;
	// begin inline asm
	mov.u32 %r63, 0x0;
	mov.u32 %r64, 0x0;
	@%p1 ld.global.v2.b32 { %r63, %r64 }, [ %rd16 + 0 ];
	@!%p1 mov.u32 %r63, %r5;
	@!%p1 mov.u32 %r64, %r5;
	// end inline asm
	mov.b32 	%f159, %r63;
	mov.b32 	%f160, %r64;
	or.b64  	%rd127, %rd45, %rd94;
	mul.wide.u32 	%rd128, %r256, 24;
	add.s64 	%rd129, %rd44, %rd128;
	shl.b64 	%rd130, %rd127, 2;
	add.s64 	%rd17, %rd129, %rd130;
	setp.lt.u32 	%p68, %r254, 48;
	setp.lt.u64 	%p52, %rd127, 6;
	and.pred  	%p49, %p68, %p52;
	// begin inline asm
	mov.u32 %r67, 0x0;
	mov.u32 %r68, 0x0;
	@%p49 ld.global.v2.b32 { %r67, %r68 }, [ %rd17 + 0 ];
	@!%p49 mov.u32 %r67, %r5;
	@!%p49 mov.u32 %r68, %r5;
	// end inline asm
	mov.b32 	%f161, %r67;
	mov.b32 	%f162, %r68;
	selp.f32 	%f163, %f129, 0f00000000, %p1;
	selp.f32 	%f164, %f130, 0f00000000, %p1;
	selp.f32 	%f165, %f131, 0f00000000, %p1;
	selp.f32 	%f166, %f132, 0f00000000, %p1;
	selp.f32 	%f167, %f133, 0f00000000, %p1;
	selp.f32 	%f168, %f134, 0f00000000, %p1;
	selp.f32 	%f169, %f135, 0f00000000, %p1;
	selp.f32 	%f170, %f136, 0f00000000, %p1;
	selp.f32 	%f171, %f137, 0f00000000, %p1;
	selp.f32 	%f172, %f138, 0f00000000, %p1;
	selp.f32 	%f173, %f139, 0f00000000, %p1;
	selp.f32 	%f174, %f140, 0f00000000, %p1;
	selp.f32 	%f175, %f141, 0f00000000, %p1;
	selp.f32 	%f176, %f142, 0f00000000, %p1;
	selp.f32 	%f177, %f143, 0f00000000, %p1;
	selp.f32 	%f178, %f144, 0f00000000, %p1;
	selp.f32 	%f179, %f145, 0f00000000, %p1;
	selp.f32 	%f180, %f146, 0f00000000, %p1;
	selp.f32 	%f181, %f147, 0f00000000, %p1;
	selp.f32 	%f182, %f148, 0f00000000, %p1;
	selp.f32 	%f183, %f149, 0f00000000, %p1;
	selp.f32 	%f184, %f150, 0f00000000, %p1;
	selp.f32 	%f185, %f151, 0f00000000, %p1;
	selp.f32 	%f186, %f152, 0f00000000, %p1;
	selp.f32 	%f187, %f153, 0f00000000, %p1;
	selp.f32 	%f188, %f154, 0f00000000, %p1;
	selp.f32 	%f189, %f155, 0f00000000, %p1;
	selp.f32 	%f190, %f156, 0f00000000, %p1;
	selp.f32 	%f191, %f157, 0f00000000, %p1;
	selp.f32 	%f192, %f158, 0f00000000, %p1;
	selp.f32 	%f193, %f159, 0f00000000, %p1;
	selp.f32 	%f194, %f160, 0f00000000, %p1;
	shr.u32 	%r274, %r254, 2;
	and.b32  	%r275, %r274, 12;
	xor.b32  	%r276, %r275, %r273;
	shl.b32 	%r277, %r256, 4;
	or.b32  	%r278, %r276, %r277;
	mul.wide.u32 	%rd131, %r278, 4;
	mov.u64 	%rd132, global_smem;
	add.s64 	%rd133, %rd132, %rd131;
	st.shared.v2.f32 	[%rd133], {%f163, %f164};
	shl.b32 	%r279, %r257, 4;
	or.b32  	%r280, %r279, %r276;
	mul.wide.u32 	%rd134, %r280, 4;
	add.s64 	%rd135, %rd132, %rd134;
	st.shared.v2.f32 	[%rd135], {%f165, %f166};
	shl.b32 	%r281, %r258, 4;
	or.b32  	%r282, %r281, %r276;
	mul.wide.u32 	%rd136, %r282, 4;
	add.s64 	%rd137, %rd132, %rd136;
	st.shared.v2.f32 	[%rd137], {%f167, %f168};
	shl.b32 	%r283, %r259, 4;
	or.b32  	%r284, %r283, %r276;
	mul.wide.u32 	%rd138, %r284, 4;
	add.s64 	%rd139, %rd132, %rd138;
	st.shared.v2.f32 	[%rd139], {%f169, %f170};
	shl.b32 	%r285, %r260, 4;
	or.b32  	%r286, %r285, %r276;
	mul.wide.u32 	%rd140, %r286, 4;
	add.s64 	%rd141, %rd132, %rd140;
	st.shared.v2.f32 	[%rd141], {%f171, %f172};
	shl.b32 	%r287, %r261, 4;
	or.b32  	%r288, %r287, %r276;
	mul.wide.u32 	%rd142, %r288, 4;
	add.s64 	%rd143, %rd132, %rd142;
	st.shared.v2.f32 	[%rd143], {%f173, %f174};
	shl.b32 	%r289, %r262, 4;
	or.b32  	%r290, %r289, %r276;
	mul.wide.u32 	%rd144, %r290, 4;
	add.s64 	%rd145, %rd132, %rd144;
	st.shared.v2.f32 	[%rd145], {%f175, %f176};
	shl.b32 	%r291, %r263, 4;
	or.b32  	%r292, %r291, %r276;
	mul.wide.u32 	%rd146, %r292, 4;
	add.s64 	%rd147, %rd132, %rd146;
	st.shared.v2.f32 	[%rd147], {%f177, %f178};
	shl.b32 	%r293, %r264, 4;
	or.b32  	%r294, %r293, %r276;
	mul.wide.u32 	%rd148, %r294, 4;
	add.s64 	%rd149, %rd132, %rd148;
	st.shared.v2.f32 	[%rd149], {%f179, %f180};
	shl.b32 	%r295, %r265, 4;
	or.b32  	%r296, %r295, %r276;
	mul.wide.u32 	%rd150, %r296, 4;
	add.s64 	%rd151, %rd132, %rd150;
	st.shared.v2.f32 	[%rd151], {%f181, %f182};
	shl.b32 	%r297, %r266, 4;
	or.b32  	%r298, %r297, %r276;
	mul.wide.u32 	%rd152, %r298, 4;
	add.s64 	%rd153, %rd132, %rd152;
	st.shared.v2.f32 	[%rd153], {%f183, %f184};
	shl.b32 	%r299, %r267, 4;
	or.b32  	%r300, %r299, %r276;
	mul.wide.u32 	%rd154, %r300, 4;
	add.s64 	%rd155, %rd132, %rd154;
	st.shared.v2.f32 	[%rd155], {%f185, %f186};
	shl.b32 	%r301, %r268, 4;
	or.b32  	%r302, %r301, %r276;
	mul.wide.u32 	%rd156, %r302, 4;
	add.s64 	%rd157, %rd132, %rd156;
	st.shared.v2.f32 	[%rd157], {%f187, %f188};
	shl.b32 	%r303, %r269, 4;
	or.b32  	%r304, %r303, %r276;
	mul.wide.u32 	%rd158, %r304, 4;
	add.s64 	%rd159, %rd132, %rd158;
	st.shared.v2.f32 	[%rd159], {%f189, %f190};
	shl.b32 	%r305, %r270, 4;
	or.b32  	%r306, %r305, %r276;
	mul.wide.u32 	%rd160, %r306, 4;
	add.s64 	%rd161, %rd132, %rd160;
	st.shared.v2.f32 	[%rd161], {%f191, %f192};
	shl.b32 	%r307, %r271, 4;
	or.b32  	%r308, %r307, %r276;
	mul.wide.u32 	%rd162, %r308, 4;
	add.s64 	%rd163, %rd132, %rd162;
	st.shared.v2.f32 	[%rd163], {%f193, %f194};
	selp.f32 	%f195, %f161, 0f00000000, %p68;
	selp.f32 	%f196, %f162, 0f00000000, %p68;
	shr.u32 	%r309, %r254, 1;
	and.b32  	%r310, %r309, 8;
	xor.b32  	%r311, %r273, %r310;
	or.b32  	%r312, %r311, %r277;
	mul.wide.u32 	%rd164, %r312, 4;
	add.s64 	%rd165, %rd132, 16384;
	add.s64 	%rd166, %rd165, %rd164;
	st.shared.v2.f32 	[%rd166], {%f195, %f196};
	bar.sync 	0;
	and.b32  	%r313, %r254, 7;
	bfe.u32 	%r314, %r254, 3, 2;
	bfe.u32 	%r315, %r254, 4, 1;
	bfe.u32 	%r316, %r254, 1, 2;
	shl.b32 	%r317, %r255, 4;
	and.b32  	%r318, %r254, 15;
	or.b32  	%r319, %r317, %r318;
	xor.b32  	%r320, %r315, %r316;
	shl.b32 	%r321, %r320, 4;
	shl.b32 	%r322, %r319, 6;
	or.b32  	%r323, %r322, %r321;
	cvt.u64.u32 	%rd167, %r323;
	add.s64 	%rd168, %rd132, %rd167;
	cvt.u32.u64 	%r75, %rd168;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r111, %r112, %r113, %r114 }, [ %r75 + 0 ];
	// end inline asm
	or.b32  	%r324, %r315, 2;
	xor.b32  	%r325, %r324, %r316;
	shl.b32 	%r326, %r325, 4;
	or.b32  	%r327, %r326, %r322;
	cvt.u64.u32 	%rd169, %r327;
	add.s64 	%rd170, %rd132, %rd169;
	cvt.u32.u64 	%r80, %rd170;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r159, %r160, %r161, %r162 }, [ %r80 + 0 ];
	// end inline asm
	add.s32 	%r85, %r75, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r123, %r124, %r125, %r126 }, [ %r85 + 0 ];
	// end inline asm
	add.s32 	%r90, %r80, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r171, %r172, %r173, %r174 }, [ %r90 + 0 ];
	// end inline asm
	add.s32 	%r95, %r75, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r135, %r136, %r137, %r138 }, [ %r95 + 0 ];
	// end inline asm
	add.s32 	%r100, %r80, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r183, %r184, %r185, %r186 }, [ %r100 + 0 ];
	// end inline asm
	add.s32 	%r105, %r75, 12288;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r147, %r148, %r149, %r150 }, [ %r105 + 0 ];
	// end inline asm
	add.s32 	%r110, %r80, 12288;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r195, %r196, %r197, %r198 }, [ %r110 + 0 ];
	// end inline asm
	bfe.u32 	%r328, %r254, 2, 3;
	and.b32  	%r329, %r254, 3;
	shl.b32 	%r330, %r254, 2;
	and.b32  	%r331, %r330, 8;
	shl.b32 	%r332, %r329, 4;
	or.b32  	%r333, %r331, %r332;
	or.b32  	%r334, %r333, %r328;
	xor.b32  	%r335, %r334, 8;
	mul.wide.u32 	%rd171, %r334, 4;
	add.s64 	%rd172, %rd165, %rd171;
	mul.wide.u32 	%rd173, %r335, 4;
	add.s64 	%rd174, %rd165, %rd173;
	ld.shared.u32 	%r115, [%rd172];
	ld.shared.u32 	%r121, [%rd174];
	ld.shared.u32 	%r116, [%rd172+256];
	ld.shared.u32 	%r122, [%rd174+256];
	ld.shared.u32 	%r163, [%rd172+512];
	ld.shared.u32 	%r169, [%rd174+512];
	ld.shared.u32 	%r164, [%rd172+768];
	ld.shared.u32 	%r170, [%rd174+768];
	mov.f32 	%f121, 0f00000000;
	mov.f32 	%f65, %f121;
	mov.f32 	%f66, %f121;
	mov.f32 	%f67, %f121;
	mov.f32 	%f68, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f65, %f66, %f67, %f68 }, { %r111, %r112, %r113, %r114 }, { %r115, %r116 }, { %f65, %f66, %f67, %f68 };
	// end inline asm
	mov.f32 	%f73, %f121;
	mov.f32 	%f74, %f121;
	mov.f32 	%f75, %f121;
	mov.f32 	%f76, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f73, %f74, %f75, %f76 }, { %r111, %r112, %r113, %r114 }, { %r121, %r122 }, { %f73, %f74, %f75, %f76 };
	// end inline asm
	mov.f32 	%f81, %f121;
	mov.f32 	%f82, %f121;
	mov.f32 	%f83, %f121;
	mov.f32 	%f84, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f81, %f82, %f83, %f84 }, { %r123, %r124, %r125, %r126 }, { %r115, %r116 }, { %f81, %f82, %f83, %f84 };
	// end inline asm
	mov.f32 	%f89, %f121;
	mov.f32 	%f90, %f121;
	mov.f32 	%f91, %f121;
	mov.f32 	%f92, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f89, %f90, %f91, %f92 }, { %r123, %r124, %r125, %r126 }, { %r121, %r122 }, { %f89, %f90, %f91, %f92 };
	// end inline asm
	mov.f32 	%f97, %f121;
	mov.f32 	%f98, %f121;
	mov.f32 	%f99, %f121;
	mov.f32 	%f100, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f97, %f98, %f99, %f100 }, { %r135, %r136, %r137, %r138 }, { %r115, %r116 }, { %f97, %f98, %f99, %f100 };
	// end inline asm
	mov.f32 	%f105, %f121;
	mov.f32 	%f106, %f121;
	mov.f32 	%f107, %f121;
	mov.f32 	%f108, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f105, %f106, %f107, %f108 }, { %r135, %r136, %r137, %r138 }, { %r121, %r122 }, { %f105, %f106, %f107, %f108 };
	// end inline asm
	mov.f32 	%f113, %f121;
	mov.f32 	%f114, %f121;
	mov.f32 	%f115, %f121;
	mov.f32 	%f116, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f113, %f114, %f115, %f116 }, { %r147, %r148, %r149, %r150 }, { %r115, %r116 }, { %f113, %f114, %f115, %f116 };
	// end inline asm
	mov.f32 	%f122, %f121;
	mov.f32 	%f123, %f121;
	mov.f32 	%f124, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f121, %f122, %f123, %f124 }, { %r147, %r148, %r149, %r150 }, { %r121, %r122 }, { %f121, %f122, %f123, %f124 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f65, %f66, %f67, %f68 }, { %r159, %r160, %r161, %r162 }, { %r163, %r164 }, { %f65, %f66, %f67, %f68 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f73, %f74, %f75, %f76 }, { %r159, %r160, %r161, %r162 }, { %r169, %r170 }, { %f73, %f74, %f75, %f76 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f81, %f82, %f83, %f84 }, { %r171, %r172, %r173, %r174 }, { %r163, %r164 }, { %f81, %f82, %f83, %f84 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f89, %f90, %f91, %f92 }, { %r171, %r172, %r173, %r174 }, { %r169, %r170 }, { %f89, %f90, %f91, %f92 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f97, %f98, %f99, %f100 }, { %r183, %r184, %r185, %r186 }, { %r163, %r164 }, { %f97, %f98, %f99, %f100 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f105, %f106, %f107, %f108 }, { %r183, %r184, %r185, %r186 }, { %r169, %r170 }, { %f105, %f106, %f107, %f108 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f113, %f114, %f115, %f116 }, { %r195, %r196, %r197, %r198 }, { %r163, %r164 }, { %f113, %f114, %f115, %f116 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f121, %f122, %f123, %f124 }, { %r195, %r196, %r197, %r198 }, { %r169, %r170 }, { %f121, %f122, %f123, %f124 };
	// end inline asm
	mul.lo.s32 	%r336, %r2, 307200;
	mul.wide.s32 	%rd175, %r336, 4;
	add.s64 	%rd176, %rd36, %rd175;
	mul.lo.s64 	%rd177, %rd62, 24;
	add.s64 	%rd178, %rd176, %rd177;
	add.s64 	%rd18, %rd178, %rd130;
	mul.lo.s64 	%rd179, %rd63, 24;
	add.s64 	%rd180, %rd176, %rd179;
	add.s64 	%rd19, %rd180, %rd130;
	mul.lo.s64 	%rd181, %rd64, 24;
	add.s64 	%rd182, %rd176, %rd181;
	add.s64 	%rd20, %rd182, %rd130;
	mul.lo.s64 	%rd183, %rd65, 24;
	add.s64 	%rd184, %rd176, %rd183;
	add.s64 	%rd21, %rd184, %rd130;
	mul.lo.s64 	%rd185, %rd66, 24;
	add.s64 	%rd186, %rd176, %rd185;
	add.s64 	%rd22, %rd186, %rd130;
	mul.lo.s64 	%rd187, %rd67, 24;
	add.s64 	%rd188, %rd176, %rd187;
	add.s64 	%rd23, %rd188, %rd130;
	mul.lo.s64 	%rd189, %rd68, 24;
	add.s64 	%rd190, %rd176, %rd189;
	add.s64 	%rd24, %rd190, %rd130;
	mul.lo.s64 	%rd191, %rd69, 24;
	add.s64 	%rd192, %rd176, %rd191;
	add.s64 	%rd25, %rd192, %rd130;
	mul.lo.s64 	%rd193, %rd70, 24;
	add.s64 	%rd194, %rd176, %rd193;
	add.s64 	%rd26, %rd194, %rd130;
	mul.lo.s64 	%rd195, %rd71, 24;
	add.s64 	%rd196, %rd176, %rd195;
	add.s64 	%rd27, %rd196, %rd130;
	mul.lo.s64 	%rd197, %rd72, 24;
	add.s64 	%rd198, %rd176, %rd197;
	add.s64 	%rd28, %rd198, %rd130;
	mul.lo.s64 	%rd199, %rd73, 24;
	add.s64 	%rd200, %rd176, %rd199;
	add.s64 	%rd29, %rd200, %rd130;
	mul.lo.s64 	%rd201, %rd74, 24;
	add.s64 	%rd202, %rd176, %rd201;
	add.s64 	%rd30, %rd202, %rd130;
	mul.lo.s64 	%rd203, %rd75, 24;
	add.s64 	%rd204, %rd176, %rd203;
	add.s64 	%rd31, %rd204, %rd130;
	mul.lo.s64 	%rd205, %rd76, 24;
	add.s64 	%rd206, %rd176, %rd205;
	add.s64 	%rd32, %rd206, %rd130;
	mul.lo.s64 	%rd207, %rd77, 24;
	add.s64 	%rd208, %rd176, %rd207;
	add.s64 	%rd33, %rd208, %rd130;
	bar.sync 	0;
	shl.b32 	%r337, %r329, 1;
	or.b32  	%r338, %r317, %r328;
	mul.lo.s32 	%r339, %r338, 18;
	add.s32 	%r340, %r339, %r337;
	mul.wide.u32 	%rd209, %r340, 4;
	add.s64 	%rd210, %rd132, %rd209;
	st.shared.v2.f32 	[%rd210], {%f65, %f66};
	cvt.u64.u32 	%rd211, %r337;
	cvt.u64.u32 	%rd212, %r339;
	add.s64 	%rd213, %rd212, %rd211;
	shl.b64 	%rd214, %rd213, 2;
	add.s64 	%rd215, %rd132, %rd214;
	st.shared.v2.f32 	[%rd215+576], {%f67, %f68};
	or.b32  	%r341, %r337, 8;
	st.shared.v2.f32 	[%rd215+32], {%f73, %f74};
	cvt.u64.u32 	%rd216, %r341;
	add.s64 	%rd217, %rd212, %rd216;
	shl.b64 	%rd218, %rd217, 2;
	add.s64 	%rd219, %rd132, %rd218;
	st.shared.v2.f32 	[%rd219+576], {%f75, %f76};
	bar.sync 	0;
	shl.b32 	%r342, %r255, 2;
	or.b32  	%r343, %r342, %r314;
	shl.b32 	%r344, %r313, 1;
	mad.lo.s32 	%r345, %r343, 18, %r344;
	mul.wide.u32 	%rd220, %r345, 4;
	add.s64 	%rd221, %rd132, %rd220;
	ld.shared.v2.u32 	{%r207, %r208}, [%rd221];
	ld.shared.v2.u32 	{%r209, %r210}, [%rd221+1152];
	ld.shared.v2.u32 	{%r211, %r212}, [%rd221+2304];
	ld.shared.v2.u32 	{%r213, %r214}, [%rd221+3456];
	bar.sync 	0;
	st.shared.v2.f32 	[%rd210], {%f81, %f82};
	st.shared.v2.f32 	[%rd215+576], {%f83, %f84};
	st.shared.v2.f32 	[%rd215+32], {%f89, %f90};
	st.shared.v2.f32 	[%rd219+576], {%f91, %f92};
	bar.sync 	0;
	ld.shared.v2.u32 	{%r215, %r216}, [%rd221];
	ld.shared.v2.u32 	{%r217, %r218}, [%rd221+1152];
	ld.shared.v2.u32 	{%r219, %r220}, [%rd221+2304];
	ld.shared.v2.u32 	{%r221, %r222}, [%rd221+3456];
	bar.sync 	0;
	st.shared.v2.f32 	[%rd210], {%f97, %f98};
	st.shared.v2.f32 	[%rd215+576], {%f99, %f100};
	st.shared.v2.f32 	[%rd215+32], {%f105, %f106};
	st.shared.v2.f32 	[%rd219+576], {%f107, %f108};
	bar.sync 	0;
	ld.shared.v2.u32 	{%r223, %r224}, [%rd221];
	ld.shared.v2.u32 	{%r225, %r226}, [%rd221+1152];
	ld.shared.v2.u32 	{%r227, %r228}, [%rd221+2304];
	ld.shared.v2.u32 	{%r229, %r230}, [%rd221+3456];
	bar.sync 	0;
	st.shared.v2.f32 	[%rd210], {%f113, %f114};
	st.shared.v2.f32 	[%rd215+576], {%f115, %f116};
	st.shared.v2.f32 	[%rd215+32], {%f121, %f122};
	st.shared.v2.f32 	[%rd219+576], {%f123, %f124};
	bar.sync 	0;
	ld.shared.v2.u32 	{%r231, %r232}, [%rd221];
	ld.shared.v2.u32 	{%r233, %r234}, [%rd221+1152];
	ld.shared.v2.u32 	{%r235, %r236}, [%rd221+2304];
	ld.shared.v2.u32 	{%r237, %r238}, [%rd221+3456];
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd18 + 0 ], { %r207, %r208 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd19 + 0 ], { %r209, %r210 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd20 + 0 ], { %r211, %r212 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd21 + 0 ], { %r213, %r214 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd22 + 0 ], { %r215, %r216 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd23 + 0 ], { %r217, %r218 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd24 + 0 ], { %r219, %r220 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd25 + 0 ], { %r221, %r222 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd26 + 0 ], { %r223, %r224 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd27 + 0 ], { %r225, %r226 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd28 + 0 ], { %r227, %r228 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd29 + 0 ], { %r229, %r230 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd30 + 0 ], { %r231, %r232 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd31 + 0 ], { %r233, %r234 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd32 + 0 ], { %r235, %r236 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd33 + 0 ], { %r237, %r238 };
	// end inline asm
	ret;

}
	// .globl	input_concatenate_fusion_180
.visible .entry input_concatenate_fusion_180(
	.param .u64 input_concatenate_fusion_180_param_0,
	.param .u64 input_concatenate_fusion_180_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<18>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<21>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_180_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_180_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -1431655765;
	shr.u32 	%r6, %r5, 1;
	mul.lo.s32 	%r7, %r6, 3;
	sub.s32 	%r8, %r4, %r7;
	bfe.u32 	%r9, %r5, 1, 9;
	cvt.u16.u32 	%rs1, %r1;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 3;
	mul.hi.u16 	%rs4, %rs3, 5243;
	shr.u16 	%rs5, %rs4, 2;
	mul.lo.s16 	%rs6, %rs5, 50;
	sub.s16 	%rs7, %rs3, %rs6;
	shr.u16 	%rs8, %rs1, 3;
	mul.hi.u16 	%rs9, %rs8, 6991;
	shr.u16 	%rs10, %rs9, 3;
	shl.b32 	%r10, %r8, 1;
	or.b32  	%r11, %r10, 1;
	setp.gt.u32 	%p1, %r8, 1;
	selp.b32 	%r12, 5, %r11, %p1;
	shl.b32 	%r13, %r9, 1;
	shl.b16 	%rs11, %rs7, 10;
	cvt.u32.u16 	%r14, %rs11;
	or.b32  	%r15, %r13, %r14;
	mul.wide.u32 	%rd5, %r12, 4;
	mul.wide.u32 	%rd6, %r15, 24;
	cvt.u32.u16 	%r16, %rs10;
	mul.wide.u32 	%rd7, %r16, 1228800;
	add.s64 	%rd8, %rd4, %rd7;
	add.s64 	%rd9, %rd8, %rd6;
	add.s64 	%rd10, %rd9, %rd5;
	ld.global.nc.f32 	%f1, [%rd10];
	neg.f32 	%f2, %f1;
	mul.wide.u32 	%rd11, %r16, 614400;
	add.s64 	%rd12, %rd3, %rd11;
	cvt.u32.u16 	%r17, %rs7;
	mul.wide.u32 	%rd13, %r17, 12288;
	add.s64 	%rd14, %rd12, %rd13;
	mul.wide.u32 	%rd15, %r9, 24;
	add.s64 	%rd16, %rd14, %rd15;
	mul.wide.u32 	%rd17, %r8, 8;
	add.s64 	%rd18, %rd16, %rd17;
	mul.wide.u32 	%rd19, %r10, 4;
	add.s64 	%rd20, %rd9, %rd19;
	ld.global.nc.f32 	%f3, [%rd20];
	st.global.v2.f32 	[%rd18], {%f2, %f3};
	ret;

}
	// .globl	loop_add_cosine_sine_fusion_6
.visible .entry loop_add_cosine_sine_fusion_6(
	.param .u64 loop_add_cosine_sine_fusion_6_param_0,
	.param .u64 loop_add_cosine_sine_fusion_6_param_1,
	.param .u64 loop_add_cosine_sine_fusion_6_param_2,
	.param .u64 loop_add_cosine_sine_fusion_6_param_3,
	.param .u64 loop_add_cosine_sine_fusion_6_param_4,
	.param .u64 loop_add_cosine_sine_fusion_6_param_5,
	.param .u64 loop_add_cosine_sine_fusion_6_param_6,
	.param .u64 loop_add_cosine_sine_fusion_6_param_7,
	.param .u64 loop_add_cosine_sine_fusion_6_param_8,
	.param .u64 loop_add_cosine_sine_fusion_6_param_9
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot47[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<70>;
	.reg .b32 	%r<424>;
	.reg .f32 	%f<203>;
	.reg .b64 	%rd<154>;
	.reg .f64 	%fd<17>;

	mov.u64 	%SPL, __local_depot47;
	mov.u32 	%r126, %ctaid.x;
	mov.u32 	%r127, %tid.x;
	shl.b32 	%r128, %r126, 7;
	or.b32  	%r1, %r128, %r127;
	setp.lt.u32 	%p1, %r1, 192;
	@%p1 bra 	$L__BB47_2;
	bra.uni 	$L__BB47_1;
$L__BB47_2:
	ld.param.u64 	%rd44, [loop_add_cosine_sine_fusion_6_param_0];
	cvta.to.global.u64 	%rd10, %rd44;
	add.u64 	%rd11, %SPL, 0;
	mul.wide.u32 	%rd62, %r1, 4;
	add.s64 	%rd63, %rd10, %rd62;
	ld.global.nc.f32 	%f45, [%rd63];
	fma.rn.f32 	%f46, %f45, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f47, %f46;
	mov.f32 	%f48, 0f4B400001;
	mov.f32 	%f49, 0f437C0000;
	fma.rm.f32 	%f50, %f47, %f49, %f48;
	add.rn.f32 	%f51, %f50, 0fCB40007F;
	neg.f32 	%f52, %f51;
	fma.rn.f32 	%f53, %f45, 0f3FB8AA3B, %f52;
	fma.rn.f32 	%f54, %f45, 0f32A57060, %f53;
	mov.b32 	%r129, %f50;
	shl.b32 	%r130, %r129, 23;
	mov.b32 	%f55, %r130;
	ex2.approx.ftz.f32 	%f56, %f54;
	mul.rn.f32 	%f1, %f56, %f55;
	add.rn.f32 	%f2, %f1, %f1;
	add.rn.f32 	%f3, %f2, %f2;
	add.rn.f32 	%f4, %f3, %f3;
	mul.rn.f32 	%f57, %f4, 0f3F22F983;
	cvt.rni.s32.f32 	%r407, %f57;
	cvt.rn.f32.s32 	%f58, %r407;
	fma.rn.f32 	%f59, %f58, 0fBFC90FDA, %f4;
	fma.rn.f32 	%f60, %f58, 0fB3A22168, %f59;
	fma.rn.f32 	%f198, %f58, 0fA7C234C5, %f60;
	abs.f32 	%f6, %f4;
	setp.ltu.f32 	%p2, %f6, 0f47CE4780;
	mov.f32 	%f194, 0f00000000;
	setp.neu.f32 	%p67, %f6, 0f7F800000;
	mov.u32 	%r395, %r407;
	mov.f32 	%f195, %f198;
	@%p2 bra 	$L__BB47_10;
	@%p67 bra 	$L__BB47_5;
	mul.rn.f32 	%f195, %f4, %f194;
	mov.b32 	%r395, 0;
	bra.uni 	$L__BB47_10;
$L__BB47_5:
	mov.b32 	%r392, 0;
	mov.b32 	%r3, %f4;
	shr.u32 	%r4, %r3, 23;
	and.b32  	%r132, %r4, 224;
	add.s32 	%r133, %r132, -128;
	shl.b32 	%r134, %r3, 8;
	or.b32  	%r138, %r134, -2147483648;
	shr.u32 	%r6, %r133, 5;
	mov.u64 	%rd146, 0;
	mov.u64 	%rd65, __cudart_i2opi_f;
$L__BB47_6:
	.pragma "nounroll";
	add.s64 	%rd66, %rd65, %rd146;
	ld.global.nc.u32 	%r137, [%rd66];
	// begin inline asm
	{
	mad.lo.cc.u32   %r135, %r137, %r138, %r392;
	madc.hi.u32     %r392, %r137, %r138,  0;
	}
	// end inline asm
	add.s64 	%rd67, %rd11, %rd146;
	st.local.u32 	[%rd67], %r135;
	add.s64 	%rd146, %rd146, 4;
	cvt.u32.u64 	%r140, %rd146;
	setp.ne.s32 	%p4, %r140, 24;
	@%p4 bra 	$L__BB47_6;
	st.local.u32 	[%rd11+24], %r392;
	and.b32  	%r9, %r4, 31;
	mul.wide.u32 	%rd68, %r6, 4;
	sub.s64 	%rd22, %rd11, %rd68;
	ld.local.u32 	%r393, [%rd22+24];
	ld.local.u32 	%r394, [%rd22+20];
	setp.eq.s32 	%p5, %r9, 0;
	@%p5 bra 	$L__BB47_9;
	shl.b32 	%r141, %r394, %r9;
	shl.b32 	%r142, %r393, %r9;
	mov.b32 	%r143, 32;
	sub.s32 	%r144, %r143, %r9;
	shr.u32 	%r145, %r394, %r144;
	add.s32 	%r393, %r145, %r142;
	ld.local.u32 	%r146, [%rd22+16];
	shr.u32 	%r147, %r146, %r144;
	add.s32 	%r394, %r147, %r141;
$L__BB47_9:
	shr.u32 	%r148, %r393, 30;
	shr.u32 	%r149, %r394, 30;
	shl.b32 	%r150, %r393, 2;
	or.b32  	%r151, %r150, %r149;
	shl.b32 	%r152, %r394, 2;
	bfe.u32 	%r153, %r393, 29, 1;
	add.s32 	%r154, %r153, %r148;
	neg.s32 	%r155, %r154;
	setp.lt.s32 	%p6, %r3, 0;
	selp.b32 	%r395, %r155, %r154, %p6;
	xor.b32  	%r156, %r151, %r3;
	bfe.s32 	%r157, %r393, 29, 1;
	xor.b32  	%r158, %r157, %r151;
	xor.b32  	%r159, %r157, %r152;
	cvt.u64.u32 	%rd69, %r158;
	shl.b64 	%rd70, %rd69, 32;
	cvt.u64.u32 	%rd71, %r159;
	or.b64  	%rd72, %rd70, %rd71;
	cvt.rn.f64.s64 	%fd1, %rd72;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f61, %fd2;
	neg.f32 	%f62, %f61;
	setp.lt.s32 	%p7, %r156, 0;
	selp.f32 	%f195, %f62, %f61, %p7;
$L__BB47_10:
	mul.rn.f32 	%f64, %f195, %f195;
	and.b32  	%r161, %r395, 1;
	setp.eq.b32 	%p8, %r161, 1;
	fma.rn.f32 	%f67, %f64, 0f37CBAC00, 0fBAB607ED;
	mul.rn.f32 	%f76, %f1, 0f3F22F983;
	cvt.rni.s32.f32 	%r403, %f76;
	cvt.rn.f32.s32 	%f77, %r403;
	fma.rn.f32 	%f78, %f77, 0fBFC90FDA, %f1;
	fma.rn.f32 	%f79, %f77, 0fB3A22168, %f78;
	fma.rn.f32 	%f197, %f77, 0fA7C234C5, %f79;
	abs.f32 	%f13, %f1;
	setp.ltu.f32 	%p10, %f13, 0f47CE4780;
	setp.neu.f32 	%p66, %f13, 0f7F800000;
	mov.u32 	%r399, %r403;
	mov.f32 	%f196, %f197;
	@%p10 bra 	$L__BB47_18;
	@%p66 bra 	$L__BB47_13;
	mul.rn.f32 	%f196, %f1, %f194;
	mov.b32 	%r399, 0;
	bra.uni 	$L__BB47_18;
$L__BB47_13:
	mov.b32 	%r19, %f1;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r164, %r20, 224;
	add.s32 	%r165, %r164, -128;
	shl.b32 	%r166, %r19, 8;
	or.b32  	%r170, %r166, -2147483648;
	shr.u32 	%r22, %r165, 5;
	mov.b32 	%r396, 0;
	mov.u64 	%rd147, 0;
	mov.u64 	%rd74, __cudart_i2opi_f;
$L__BB47_14:
	.pragma "nounroll";
	add.s64 	%rd75, %rd74, %rd147;
	ld.global.nc.u32 	%r169, [%rd75];
	// begin inline asm
	{
	mad.lo.cc.u32   %r167, %r169, %r170, %r396;
	madc.hi.u32     %r396, %r169, %r170,  0;
	}
	// end inline asm
	add.s64 	%rd76, %rd11, %rd147;
	st.local.u32 	[%rd76], %r167;
	add.s64 	%rd147, %rd147, 4;
	cvt.u32.u64 	%r172, %rd147;
	setp.ne.s32 	%p12, %r172, 24;
	@%p12 bra 	$L__BB47_14;
	st.local.u32 	[%rd11+24], %r396;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd77, %r22, 4;
	sub.s64 	%rd25, %rd11, %rd77;
	ld.local.u32 	%r397, [%rd25+24];
	ld.local.u32 	%r398, [%rd25+20];
	setp.eq.s32 	%p13, %r25, 0;
	@%p13 bra 	$L__BB47_17;
	shl.b32 	%r173, %r398, %r25;
	shl.b32 	%r174, %r397, %r25;
	mov.b32 	%r175, 32;
	sub.s32 	%r176, %r175, %r25;
	shr.u32 	%r177, %r398, %r176;
	add.s32 	%r397, %r177, %r174;
	ld.local.u32 	%r178, [%rd25+16];
	shr.u32 	%r179, %r178, %r176;
	add.s32 	%r398, %r179, %r173;
$L__BB47_17:
	shr.u32 	%r180, %r397, 30;
	shr.u32 	%r181, %r398, 30;
	shl.b32 	%r182, %r397, 2;
	or.b32  	%r183, %r182, %r181;
	shl.b32 	%r184, %r398, 2;
	bfe.u32 	%r185, %r397, 29, 1;
	add.s32 	%r186, %r185, %r180;
	neg.s32 	%r187, %r186;
	setp.lt.s32 	%p14, %r19, 0;
	selp.b32 	%r399, %r187, %r186, %p14;
	xor.b32  	%r188, %r183, %r19;
	bfe.s32 	%r189, %r397, 29, 1;
	xor.b32  	%r190, %r189, %r183;
	xor.b32  	%r191, %r189, %r184;
	cvt.u64.u32 	%rd78, %r190;
	shl.b64 	%rd79, %rd78, 32;
	cvt.u64.u32 	%rd80, %r191;
	or.b64  	%rd81, %rd79, %rd80;
	cvt.rn.f64.s64 	%fd3, %rd81;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f80, %fd4;
	neg.f32 	%f81, %f80;
	setp.lt.s32 	%p15, %r188, 0;
	selp.f32 	%f196, %f81, %f80, %p15;
$L__BB47_18:
	selp.f32 	%f68, %f67, 0fB94D4153, %p8;
	selp.f32 	%f69, 0f3D2AAABB, 0f3C0885E4, %p8;
	mul.rn.f32 	%f83, %f196, %f196;
	and.b32  	%r194, %r399, 1;
	setp.eq.b32 	%p17, %r194, 1;
	fma.rn.f32 	%f86, %f83, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f87, 0fB94D4153, %f86, %p17;
	selp.f32 	%f88, 0f3C0885E4, 0f3D2AAABB, %p17;
	@%p10 bra 	$L__BB47_26;
	@%p66 bra 	$L__BB47_21;
	mul.rn.f32 	%f197, %f1, %f194;
	mov.b32 	%r403, 0;
	bra.uni 	$L__BB47_26;
$L__BB47_21:
	mov.b32 	%r34, %f1;
	shr.u32 	%r35, %r34, 23;
	and.b32  	%r197, %r35, 224;
	add.s32 	%r198, %r197, -128;
	shl.b32 	%r199, %r34, 8;
	or.b32  	%r203, %r199, -2147483648;
	shr.u32 	%r37, %r198, 5;
	mov.b32 	%r400, 0;
	mov.u64 	%rd148, 0;
	mov.u64 	%rd83, __cudart_i2opi_f;
$L__BB47_22:
	.pragma "nounroll";
	add.s64 	%rd84, %rd83, %rd148;
	ld.global.nc.u32 	%r202, [%rd84];
	// begin inline asm
	{
	mad.lo.cc.u32   %r200, %r202, %r203, %r400;
	madc.hi.u32     %r400, %r202, %r203,  0;
	}
	// end inline asm
	add.s64 	%rd85, %rd11, %rd148;
	st.local.u32 	[%rd85], %r200;
	add.s64 	%rd148, %rd148, 4;
	cvt.u32.u64 	%r205, %rd148;
	setp.ne.s32 	%p20, %r205, 24;
	@%p20 bra 	$L__BB47_22;
	st.local.u32 	[%rd11+24], %r400;
	and.b32  	%r40, %r35, 31;
	mul.wide.u32 	%rd86, %r37, 4;
	sub.s64 	%rd28, %rd11, %rd86;
	ld.local.u32 	%r401, [%rd28+24];
	ld.local.u32 	%r402, [%rd28+20];
	setp.eq.s32 	%p21, %r40, 0;
	@%p21 bra 	$L__BB47_25;
	shl.b32 	%r206, %r402, %r40;
	shl.b32 	%r207, %r401, %r40;
	mov.b32 	%r208, 32;
	sub.s32 	%r209, %r208, %r40;
	shr.u32 	%r210, %r402, %r209;
	add.s32 	%r401, %r210, %r207;
	ld.local.u32 	%r211, [%rd28+16];
	shr.u32 	%r212, %r211, %r209;
	add.s32 	%r402, %r212, %r206;
$L__BB47_25:
	shr.u32 	%r213, %r401, 30;
	shr.u32 	%r214, %r402, 30;
	shl.b32 	%r215, %r401, 2;
	or.b32  	%r216, %r215, %r214;
	shl.b32 	%r217, %r402, 2;
	bfe.u32 	%r218, %r401, 29, 1;
	add.s32 	%r219, %r218, %r213;
	neg.s32 	%r220, %r219;
	setp.lt.s32 	%p22, %r34, 0;
	selp.b32 	%r403, %r220, %r219, %p22;
	xor.b32  	%r221, %r216, %r34;
	bfe.s32 	%r222, %r401, 29, 1;
	xor.b32  	%r223, %r222, %r216;
	xor.b32  	%r224, %r222, %r217;
	cvt.u64.u32 	%rd87, %r223;
	shl.b64 	%rd88, %rd87, 32;
	cvt.u64.u32 	%rd89, %r224;
	or.b64  	%rd90, %rd88, %rd89;
	cvt.rn.f64.s64 	%fd5, %rd90;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f95, %fd6;
	neg.f32 	%f96, %f95;
	setp.lt.s32 	%p23, %r221, 0;
	selp.f32 	%f197, %f96, %f95, %p23;
$L__BB47_26:
	selp.f32 	%f65, 0f3F800000, %f195, %p8;
	fma.rn.f32 	%f70, %f68, %f64, %f69;
	selp.f32 	%f71, 0fBEFFFFFF, 0fBE2AAAA8, %p8;
	selp.f32 	%f84, %f196, 0f3F800000, %p17;
	fma.rn.f32 	%f89, %f87, %f83, %f88;
	selp.f32 	%f90, 0fBE2AAAA8, 0fBEFFFFFF, %p17;
	mul.rn.f32 	%f98, %f197, %f197;
	and.b32  	%r226, %r403, 1;
	setp.eq.b32 	%p25, %r226, 1;
	selp.f32 	%f99, 0f3F800000, %f197, %p25;
	fma.rn.f32 	%f101, %f98, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f102, %f101, 0fB94D4153, %p25;
	selp.f32 	%f103, 0f3D2AAABB, 0f3C0885E4, %p25;
	fma.rn.f32 	%f104, %f102, %f98, %f103;
	selp.f32 	%f105, 0fBEFFFFFF, 0fBE2AAAA8, %p25;
	@%p2 bra 	$L__BB47_34;
	@%p67 bra 	$L__BB47_29;
	mul.rn.f32 	%f198, %f4, %f194;
	mov.b32 	%r407, 0;
	bra.uni 	$L__BB47_34;
$L__BB47_29:
	mov.b32 	%r49, %f4;
	shr.u32 	%r50, %r49, 23;
	and.b32  	%r229, %r50, 224;
	add.s32 	%r230, %r229, -128;
	shl.b32 	%r231, %r49, 8;
	or.b32  	%r235, %r231, -2147483648;
	shr.u32 	%r52, %r230, 5;
	mov.b32 	%r404, 0;
	mov.u64 	%rd149, 0;
	mov.u64 	%rd92, __cudart_i2opi_f;
$L__BB47_30:
	.pragma "nounroll";
	add.s64 	%rd93, %rd92, %rd149;
	ld.global.nc.u32 	%r234, [%rd93];
	// begin inline asm
	{
	mad.lo.cc.u32   %r232, %r234, %r235, %r404;
	madc.hi.u32     %r404, %r234, %r235,  0;
	}
	// end inline asm
	add.s64 	%rd94, %rd11, %rd149;
	st.local.u32 	[%rd94], %r232;
	add.s64 	%rd149, %rd149, 4;
	cvt.u32.u64 	%r237, %rd149;
	setp.ne.s32 	%p28, %r237, 24;
	@%p28 bra 	$L__BB47_30;
	st.local.u32 	[%rd11+24], %r404;
	and.b32  	%r55, %r50, 31;
	mul.wide.u32 	%rd95, %r52, 4;
	sub.s64 	%rd31, %rd11, %rd95;
	ld.local.u32 	%r405, [%rd31+24];
	ld.local.u32 	%r406, [%rd31+20];
	setp.eq.s32 	%p29, %r55, 0;
	@%p29 bra 	$L__BB47_33;
	shl.b32 	%r238, %r406, %r55;
	shl.b32 	%r239, %r405, %r55;
	mov.b32 	%r240, 32;
	sub.s32 	%r241, %r240, %r55;
	shr.u32 	%r242, %r406, %r241;
	add.s32 	%r405, %r242, %r239;
	ld.local.u32 	%r243, [%rd31+16];
	shr.u32 	%r244, %r243, %r241;
	add.s32 	%r406, %r244, %r238;
$L__BB47_33:
	shr.u32 	%r245, %r405, 30;
	shr.u32 	%r246, %r406, 30;
	shl.b32 	%r247, %r405, 2;
	or.b32  	%r248, %r247, %r246;
	shl.b32 	%r249, %r406, 2;
	bfe.u32 	%r250, %r405, 29, 1;
	add.s32 	%r251, %r250, %r245;
	neg.s32 	%r252, %r251;
	setp.lt.s32 	%p30, %r49, 0;
	selp.b32 	%r407, %r252, %r251, %p30;
	xor.b32  	%r253, %r248, %r49;
	bfe.s32 	%r254, %r405, 29, 1;
	xor.b32  	%r255, %r254, %r248;
	xor.b32  	%r256, %r254, %r249;
	cvt.u64.u32 	%rd96, %r255;
	shl.b64 	%rd97, %rd96, 32;
	cvt.u64.u32 	%rd98, %r256;
	or.b64  	%rd99, %rd97, %rd98;
	cvt.rn.f64.s64 	%fd7, %rd99;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f110, %fd8;
	neg.f32 	%f111, %f110;
	setp.lt.s32 	%p31, %r253, 0;
	selp.f32 	%f198, %f111, %f110, %p31;
$L__BB47_34:
	fma.rn.f32 	%f66, %f64, %f65, 0f00000000;
	fma.rn.f32 	%f72, %f70, %f64, %f71;
	add.s32 	%r193, %r399, 1;
	fma.rn.f32 	%f85, %f83, %f84, 0f00000000;
	fma.rn.f32 	%f91, %f89, %f83, %f90;
	fma.rn.f32 	%f100, %f98, %f99, 0f00000000;
	fma.rn.f32 	%f106, %f104, %f98, %f105;
	add.s32 	%r258, %r407, 1;
	mul.rn.f32 	%f113, %f198, %f198;
	and.b32  	%r259, %r407, 1;
	setp.eq.b32 	%p32, %r259, 1;
	selp.f32 	%f114, %f198, 0f3F800000, %p32;
	fma.rn.f32 	%f115, %f113, %f114, 0f00000000;
	fma.rn.f32 	%f116, %f113, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f117, 0fB94D4153, %f116, %p32;
	selp.f32 	%f118, 0f3C0885E4, 0f3D2AAABB, %p32;
	fma.rn.f32 	%f119, %f117, %f113, %f118;
	selp.f32 	%f120, 0fBE2AAAA8, 0fBEFFFFFF, %p32;
	fma.rn.f32 	%f121, %f119, %f113, %f120;
	mul.rn.f32 	%f125, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r415, %f125;
	cvt.rn.f32.s32 	%f126, %r415;
	fma.rn.f32 	%f127, %f126, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f128, %f126, 0fB3A22168, %f127;
	fma.rn.f32 	%f200, %f126, 0fA7C234C5, %f128;
	abs.f32 	%f27, %f2;
	setp.ltu.f32 	%p34, %f27, 0f47CE4780;
	setp.neu.f32 	%p68, %f27, 0f7F800000;
	mov.u32 	%r411, %r415;
	mov.f32 	%f199, %f200;
	@%p34 bra 	$L__BB47_42;
	@%p68 bra 	$L__BB47_37;
	mul.rn.f32 	%f199, %f2, %f194;
	mov.b32 	%r411, 0;
	bra.uni 	$L__BB47_42;
$L__BB47_37:
	mov.b32 	%r65, %f2;
	shr.u32 	%r66, %r65, 23;
	and.b32  	%r262, %r66, 224;
	add.s32 	%r263, %r262, -128;
	shl.b32 	%r264, %r65, 8;
	or.b32  	%r268, %r264, -2147483648;
	shr.u32 	%r68, %r263, 5;
	mov.b32 	%r408, 0;
	mov.u64 	%rd150, 0;
	mov.u64 	%rd101, __cudart_i2opi_f;
$L__BB47_38:
	.pragma "nounroll";
	add.s64 	%rd102, %rd101, %rd150;
	ld.global.nc.u32 	%r267, [%rd102];
	// begin inline asm
	{
	mad.lo.cc.u32   %r265, %r267, %r268, %r408;
	madc.hi.u32     %r408, %r267, %r268,  0;
	}
	// end inline asm
	add.s64 	%rd103, %rd11, %rd150;
	st.local.u32 	[%rd103], %r265;
	add.s64 	%rd150, %rd150, 4;
	cvt.u32.u64 	%r270, %rd150;
	setp.ne.s32 	%p36, %r270, 24;
	@%p36 bra 	$L__BB47_38;
	st.local.u32 	[%rd11+24], %r408;
	and.b32  	%r71, %r66, 31;
	mul.wide.u32 	%rd104, %r68, 4;
	sub.s64 	%rd34, %rd11, %rd104;
	ld.local.u32 	%r409, [%rd34+24];
	ld.local.u32 	%r410, [%rd34+20];
	setp.eq.s32 	%p37, %r71, 0;
	@%p37 bra 	$L__BB47_41;
	shl.b32 	%r271, %r410, %r71;
	shl.b32 	%r272, %r409, %r71;
	mov.b32 	%r273, 32;
	sub.s32 	%r274, %r273, %r71;
	shr.u32 	%r275, %r410, %r274;
	add.s32 	%r409, %r275, %r272;
	ld.local.u32 	%r276, [%rd34+16];
	shr.u32 	%r277, %r276, %r274;
	add.s32 	%r410, %r277, %r271;
$L__BB47_41:
	shr.u32 	%r278, %r409, 30;
	shr.u32 	%r279, %r410, 30;
	shl.b32 	%r280, %r409, 2;
	or.b32  	%r281, %r280, %r279;
	shl.b32 	%r282, %r410, 2;
	bfe.u32 	%r283, %r409, 29, 1;
	add.s32 	%r284, %r283, %r278;
	neg.s32 	%r285, %r284;
	setp.lt.s32 	%p38, %r65, 0;
	selp.b32 	%r411, %r285, %r284, %p38;
	xor.b32  	%r286, %r281, %r65;
	bfe.s32 	%r287, %r409, 29, 1;
	xor.b32  	%r288, %r287, %r281;
	xor.b32  	%r289, %r287, %r282;
	cvt.u64.u32 	%rd105, %r288;
	shl.b64 	%rd106, %rd105, 32;
	cvt.u64.u32 	%rd107, %r289;
	or.b64  	%rd108, %rd106, %rd107;
	cvt.rn.f64.s64 	%fd9, %rd108;
	mul.rn.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f129, %fd10;
	neg.f32 	%f130, %f129;
	setp.lt.s32 	%p39, %r286, 0;
	selp.f32 	%f199, %f130, %f129, %p39;
$L__BB47_42:
	fma.rn.f32 	%f73, %f72, %f66, %f65;
	and.b32  	%r162, %r395, 2;
	fma.rn.f32 	%f92, %f91, %f85, %f84;
	and.b32  	%r195, %r193, 2;
	fma.rn.f32 	%f107, %f106, %f100, %f99;
	and.b32  	%r227, %r403, 2;
	fma.rn.f32 	%f122, %f121, %f115, %f114;
	and.b32  	%r260, %r258, 2;
	mul.rn.f32 	%f132, %f199, %f199;
	and.b32  	%r291, %r411, 1;
	setp.eq.b32 	%p41, %r291, 1;
	selp.f32 	%f133, 0f3F800000, %f199, %p41;
	fma.rn.f32 	%f134, %f132, %f133, 0f00000000;
	fma.rn.f32 	%f135, %f132, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f136, %f135, 0fB94D4153, %p41;
	selp.f32 	%f137, 0f3D2AAABB, 0f3C0885E4, %p41;
	fma.rn.f32 	%f138, %f136, %f132, %f137;
	selp.f32 	%f139, 0fBEFFFFFF, 0fBE2AAAA8, %p41;
	fma.rn.f32 	%f140, %f138, %f132, %f139;
	fma.rn.f32 	%f141, %f140, %f134, %f133;
	and.b32  	%r292, %r411, 2;
	@%p34 bra 	$L__BB47_50;
	@%p68 bra 	$L__BB47_45;
	mul.rn.f32 	%f200, %f2, %f194;
	mov.b32 	%r415, 0;
	bra.uni 	$L__BB47_50;
$L__BB47_45:
	mov.b32 	%r80, %f2;
	shr.u32 	%r81, %r80, 23;
	and.b32  	%r294, %r81, 224;
	add.s32 	%r295, %r294, -128;
	shl.b32 	%r296, %r80, 8;
	or.b32  	%r300, %r296, -2147483648;
	shr.u32 	%r83, %r295, 5;
	mov.b32 	%r412, 0;
	mov.u64 	%rd151, 0;
	mov.u64 	%rd110, __cudart_i2opi_f;
$L__BB47_46:
	.pragma "nounroll";
	add.s64 	%rd111, %rd110, %rd151;
	ld.global.nc.u32 	%r299, [%rd111];
	// begin inline asm
	{
	mad.lo.cc.u32   %r297, %r299, %r300, %r412;
	madc.hi.u32     %r412, %r299, %r300,  0;
	}
	// end inline asm
	add.s64 	%rd112, %rd11, %rd151;
	st.local.u32 	[%rd112], %r297;
	add.s64 	%rd151, %rd151, 4;
	cvt.u32.u64 	%r302, %rd151;
	setp.ne.s32 	%p44, %r302, 24;
	@%p44 bra 	$L__BB47_46;
	st.local.u32 	[%rd11+24], %r412;
	and.b32  	%r86, %r81, 31;
	mul.wide.u32 	%rd113, %r83, 4;
	sub.s64 	%rd37, %rd11, %rd113;
	ld.local.u32 	%r413, [%rd37+24];
	ld.local.u32 	%r414, [%rd37+20];
	setp.eq.s32 	%p45, %r86, 0;
	@%p45 bra 	$L__BB47_49;
	shl.b32 	%r303, %r414, %r86;
	shl.b32 	%r304, %r413, %r86;
	mov.b32 	%r305, 32;
	sub.s32 	%r306, %r305, %r86;
	shr.u32 	%r307, %r414, %r306;
	add.s32 	%r413, %r307, %r304;
	ld.local.u32 	%r308, [%rd37+16];
	shr.u32 	%r309, %r308, %r306;
	add.s32 	%r414, %r309, %r303;
$L__BB47_49:
	shr.u32 	%r310, %r413, 30;
	shr.u32 	%r311, %r414, 30;
	shl.b32 	%r312, %r413, 2;
	or.b32  	%r313, %r312, %r311;
	shl.b32 	%r314, %r414, 2;
	bfe.u32 	%r315, %r413, 29, 1;
	add.s32 	%r316, %r315, %r310;
	neg.s32 	%r317, %r316;
	setp.lt.s32 	%p46, %r80, 0;
	selp.b32 	%r415, %r317, %r316, %p46;
	xor.b32  	%r318, %r313, %r80;
	bfe.s32 	%r319, %r413, 29, 1;
	xor.b32  	%r320, %r319, %r313;
	xor.b32  	%r321, %r319, %r314;
	cvt.u64.u32 	%rd114, %r320;
	shl.b64 	%rd115, %rd114, 32;
	cvt.u64.u32 	%rd116, %r321;
	or.b64  	%rd117, %rd115, %rd116;
	cvt.rn.f64.s64 	%fd11, %rd117;
	mul.rn.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f144, %fd12;
	neg.f32 	%f145, %f144;
	setp.lt.s32 	%p47, %r318, 0;
	selp.f32 	%f200, %f145, %f144, %p47;
$L__BB47_50:
	ld.param.u64 	%rd45, [loop_add_cosine_sine_fusion_6_param_9];
	ld.param.u64 	%rd46, [loop_add_cosine_sine_fusion_6_param_1];
	ld.param.u64 	%rd47, [loop_add_cosine_sine_fusion_6_param_8];
	ld.param.u64 	%rd48, [loop_add_cosine_sine_fusion_6_param_2];
	ld.param.u64 	%rd49, [loop_add_cosine_sine_fusion_6_param_7];
	ld.param.u64 	%rd50, [loop_add_cosine_sine_fusion_6_param_3];
	ld.param.u64 	%rd51, [loop_add_cosine_sine_fusion_6_param_6];
	ld.param.u64 	%rd52, [loop_add_cosine_sine_fusion_6_param_4];
	ld.param.u64 	%rd53, [loop_add_cosine_sine_fusion_6_param_5];
	setp.eq.s32 	%p9, %r162, 0;
	sub.rn.f32 	%f75, %f194, %f73;
	setp.eq.s32 	%p18, %r195, 0;
	sub.rn.f32 	%f94, %f194, %f92;
	setp.eq.s32 	%p26, %r227, 0;
	sub.rn.f32 	%f109, %f194, %f107;
	setp.eq.s32 	%p33, %r260, 0;
	sub.rn.f32 	%f124, %f194, %f122;
	setp.eq.s32 	%p42, %r292, 0;
	sub.rn.f32 	%f143, %f194, %f141;
	add.s32 	%r323, %r415, 1;
	mul.rn.f32 	%f147, %f200, %f200;
	and.b32  	%r324, %r415, 1;
	setp.eq.b32 	%p48, %r324, 1;
	selp.f32 	%f148, %f200, 0f3F800000, %p48;
	fma.rn.f32 	%f149, %f147, %f148, 0f00000000;
	fma.rn.f32 	%f150, %f147, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f151, 0fB94D4153, %f150, %p48;
	selp.f32 	%f152, 0f3C0885E4, 0f3D2AAABB, %p48;
	fma.rn.f32 	%f153, %f151, %f147, %f152;
	selp.f32 	%f154, 0fBE2AAAA8, 0fBEFFFFFF, %p48;
	fma.rn.f32 	%f155, %f153, %f147, %f154;
	fma.rn.f32 	%f156, %f155, %f149, %f148;
	and.b32  	%r325, %r323, 2;
	setp.eq.s32 	%p49, %r325, 0;
	sub.rn.f32 	%f158, %f194, %f156;
	mul.rn.f32 	%f159, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r423, %f159;
	cvt.rn.f32.s32 	%f160, %r423;
	fma.rn.f32 	%f161, %f160, 0fBFC90FDA, %f3;
	fma.rn.f32 	%f162, %f160, 0fB3A22168, %f161;
	fma.rn.f32 	%f202, %f160, 0fA7C234C5, %f162;
	abs.f32 	%f37, %f3;
	setp.ltu.f32 	%p50, %f37, 0f47CE4780;
	setp.neu.f32 	%p69, %f37, 0f7F800000;
	mov.u32 	%r419, %r423;
	mov.f32 	%f201, %f202;
	@%p50 bra 	$L__BB47_58;
	@%p69 bra 	$L__BB47_53;
	mul.rn.f32 	%f201, %f3, %f194;
	mov.b32 	%r419, 0;
	bra.uni 	$L__BB47_58;
$L__BB47_53:
	mov.b32 	%r96, %f3;
	shr.u32 	%r97, %r96, 23;
	and.b32  	%r327, %r97, 224;
	add.s32 	%r328, %r327, -128;
	shl.b32 	%r329, %r96, 8;
	or.b32  	%r333, %r329, -2147483648;
	shr.u32 	%r99, %r328, 5;
	mov.b32 	%r416, 0;
	mov.u64 	%rd152, 0;
	mov.u64 	%rd119, __cudart_i2opi_f;
$L__BB47_54:
	.pragma "nounroll";
	add.s64 	%rd120, %rd119, %rd152;
	ld.global.nc.u32 	%r332, [%rd120];
	// begin inline asm
	{
	mad.lo.cc.u32   %r330, %r332, %r333, %r416;
	madc.hi.u32     %r416, %r332, %r333,  0;
	}
	// end inline asm
	add.s64 	%rd121, %rd11, %rd152;
	st.local.u32 	[%rd121], %r330;
	add.s64 	%rd152, %rd152, 4;
	cvt.u32.u64 	%r335, %rd152;
	setp.ne.s32 	%p52, %r335, 24;
	@%p52 bra 	$L__BB47_54;
	st.local.u32 	[%rd11+24], %r416;
	and.b32  	%r102, %r97, 31;
	mul.wide.u32 	%rd122, %r99, 4;
	sub.s64 	%rd40, %rd11, %rd122;
	ld.local.u32 	%r417, [%rd40+24];
	ld.local.u32 	%r418, [%rd40+20];
	setp.eq.s32 	%p53, %r102, 0;
	@%p53 bra 	$L__BB47_57;
	shl.b32 	%r336, %r418, %r102;
	shl.b32 	%r337, %r417, %r102;
	mov.b32 	%r338, 32;
	sub.s32 	%r339, %r338, %r102;
	shr.u32 	%r340, %r418, %r339;
	add.s32 	%r417, %r340, %r337;
	ld.local.u32 	%r341, [%rd40+16];
	shr.u32 	%r342, %r341, %r339;
	add.s32 	%r418, %r342, %r336;
$L__BB47_57:
	shr.u32 	%r343, %r417, 30;
	shr.u32 	%r344, %r418, 30;
	shl.b32 	%r345, %r417, 2;
	or.b32  	%r346, %r345, %r344;
	shl.b32 	%r347, %r418, 2;
	bfe.u32 	%r348, %r417, 29, 1;
	add.s32 	%r349, %r348, %r343;
	neg.s32 	%r350, %r349;
	setp.lt.s32 	%p54, %r96, 0;
	selp.b32 	%r419, %r350, %r349, %p54;
	xor.b32  	%r351, %r346, %r96;
	bfe.s32 	%r352, %r417, 29, 1;
	xor.b32  	%r353, %r352, %r346;
	xor.b32  	%r354, %r352, %r347;
	cvt.u64.u32 	%rd123, %r353;
	shl.b64 	%rd124, %rd123, 32;
	cvt.u64.u32 	%rd125, %r354;
	or.b64  	%rd126, %rd124, %rd125;
	cvt.rn.f64.s64 	%fd13, %rd126;
	mul.rn.f64 	%fd14, %fd13, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f163, %fd14;
	neg.f32 	%f164, %f163;
	setp.lt.s32 	%p55, %r351, 0;
	selp.f32 	%f201, %f164, %f163, %p55;
$L__BB47_58:
	cvta.to.global.u64 	%rd1, %rd45;
	cvta.to.global.u64 	%rd2, %rd47;
	cvta.to.global.u64 	%rd3, %rd49;
	cvta.to.global.u64 	%rd4, %rd51;
	cvta.to.global.u64 	%rd5, %rd53;
	cvta.to.global.u64 	%rd6, %rd52;
	cvta.to.global.u64 	%rd7, %rd50;
	cvta.to.global.u64 	%rd8, %rd48;
	cvta.to.global.u64 	%rd9, %rd46;
	cvt.u64.u32 	%rd19, %r1;
	selp.f32 	%f10, %f73, %f75, %p9;
	add.rn.f32 	%f11, %f4, %f4;
	selp.f32 	%f17, %f92, %f94, %p18;
	selp.f32 	%f21, %f107, %f109, %p26;
	selp.f32 	%f25, %f122, %f124, %p33;
	selp.f32 	%f31, %f141, %f143, %p42;
	selp.f32 	%f35, %f156, %f158, %p49;
	mul.rn.f32 	%f166, %f201, %f201;
	and.b32  	%r356, %r419, 1;
	setp.eq.b32 	%p57, %r356, 1;
	selp.f32 	%f167, 0f3F800000, %f201, %p57;
	fma.rn.f32 	%f168, %f166, %f167, 0f00000000;
	fma.rn.f32 	%f169, %f166, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f170, %f169, 0fB94D4153, %p57;
	selp.f32 	%f171, 0f3D2AAABB, 0f3C0885E4, %p57;
	fma.rn.f32 	%f172, %f170, %f166, %f171;
	selp.f32 	%f173, 0fBEFFFFFF, 0fBE2AAAA8, %p57;
	fma.rn.f32 	%f174, %f172, %f166, %f173;
	fma.rn.f32 	%f175, %f174, %f168, %f167;
	and.b32  	%r357, %r419, 2;
	setp.eq.s32 	%p58, %r357, 0;
	sub.rn.f32 	%f177, %f194, %f175;
	selp.f32 	%f41, %f175, %f177, %p58;
	@%p50 bra 	$L__BB47_66;
	@%p69 bra 	$L__BB47_61;
	mul.rn.f32 	%f202, %f3, %f194;
	mov.b32 	%r423, 0;
	bra.uni 	$L__BB47_66;
$L__BB47_61:
	mov.b32 	%r111, %f3;
	shr.u32 	%r112, %r111, 23;
	and.b32  	%r359, %r112, 224;
	add.s32 	%r360, %r359, -128;
	shl.b32 	%r361, %r111, 8;
	or.b32  	%r365, %r361, -2147483648;
	shr.u32 	%r114, %r360, 5;
	mov.b32 	%r420, 0;
	mov.u64 	%rd153, 0;
	mov.u64 	%rd128, __cudart_i2opi_f;
$L__BB47_62:
	.pragma "nounroll";
	add.s64 	%rd129, %rd128, %rd153;
	ld.global.nc.u32 	%r364, [%rd129];
	// begin inline asm
	{
	mad.lo.cc.u32   %r362, %r364, %r365, %r420;
	madc.hi.u32     %r420, %r364, %r365,  0;
	}
	// end inline asm
	add.s64 	%rd130, %rd11, %rd153;
	st.local.u32 	[%rd130], %r362;
	add.s64 	%rd153, %rd153, 4;
	cvt.u32.u64 	%r367, %rd153;
	setp.ne.s32 	%p60, %r367, 24;
	@%p60 bra 	$L__BB47_62;
	st.local.u32 	[%rd11+24], %r420;
	and.b32  	%r117, %r112, 31;
	mul.wide.u32 	%rd131, %r114, 4;
	sub.s64 	%rd43, %rd11, %rd131;
	ld.local.u32 	%r421, [%rd43+24];
	ld.local.u32 	%r422, [%rd43+20];
	setp.eq.s32 	%p61, %r117, 0;
	@%p61 bra 	$L__BB47_65;
	shl.b32 	%r368, %r422, %r117;
	shl.b32 	%r369, %r421, %r117;
	mov.b32 	%r370, 32;
	sub.s32 	%r371, %r370, %r117;
	shr.u32 	%r372, %r422, %r371;
	add.s32 	%r421, %r372, %r369;
	ld.local.u32 	%r373, [%rd43+16];
	shr.u32 	%r374, %r373, %r371;
	add.s32 	%r422, %r374, %r368;
$L__BB47_65:
	shr.u32 	%r375, %r421, 30;
	shr.u32 	%r376, %r422, 30;
	shl.b32 	%r377, %r421, 2;
	or.b32  	%r378, %r377, %r376;
	shl.b32 	%r379, %r422, 2;
	bfe.u32 	%r380, %r421, 29, 1;
	add.s32 	%r381, %r380, %r375;
	neg.s32 	%r382, %r381;
	setp.lt.s32 	%p62, %r111, 0;
	selp.b32 	%r423, %r382, %r381, %p62;
	xor.b32  	%r383, %r378, %r111;
	bfe.s32 	%r384, %r421, 29, 1;
	xor.b32  	%r385, %r384, %r378;
	xor.b32  	%r386, %r384, %r379;
	cvt.u64.u32 	%rd132, %r385;
	shl.b64 	%rd133, %rd132, 32;
	cvt.u64.u32 	%rd134, %r386;
	or.b64  	%rd135, %rd133, %rd134;
	cvt.rn.f64.s64 	%fd15, %rd135;
	mul.rn.f64 	%fd16, %fd15, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f178, %fd16;
	neg.f32 	%f179, %f178;
	setp.lt.s32 	%p63, %r383, 0;
	selp.f32 	%f202, %f179, %f178, %p63;
$L__BB47_66:
	add.s32 	%r388, %r423, 1;
	mul.rn.f32 	%f181, %f202, %f202;
	and.b32  	%r389, %r423, 1;
	setp.eq.b32 	%p64, %r389, 1;
	selp.f32 	%f182, %f202, 0f3F800000, %p64;
	fma.rn.f32 	%f183, %f181, %f182, 0f00000000;
	fma.rn.f32 	%f184, %f181, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f185, 0fB94D4153, %f184, %p64;
	selp.f32 	%f186, 0f3C0885E4, 0f3D2AAABB, %p64;
	fma.rn.f32 	%f187, %f185, %f181, %f186;
	selp.f32 	%f188, 0fBE2AAAA8, 0fBEFFFFFF, %p64;
	fma.rn.f32 	%f189, %f187, %f181, %f188;
	fma.rn.f32 	%f190, %f189, %f183, %f182;
	and.b32  	%r390, %r388, 2;
	setp.eq.s32 	%p65, %r390, 0;
	sub.rn.f32 	%f192, %f194, %f190;
	selp.f32 	%f193, %f190, %f192, %p65;
	shl.b64 	%rd136, %rd19, 2;
	add.s64 	%rd137, %rd9, %rd136;
	st.global.f32 	[%rd137], %f10;
	add.s64 	%rd138, %rd8, %rd136;
	st.global.f32 	[%rd138], %f11;
	add.s64 	%rd139, %rd7, %rd136;
	st.global.f32 	[%rd139], %f17;
	add.s64 	%rd140, %rd6, %rd136;
	st.global.f32 	[%rd140], %f21;
	add.s64 	%rd141, %rd5, %rd136;
	st.global.f32 	[%rd141], %f25;
	add.s64 	%rd142, %rd4, %rd136;
	st.global.f32 	[%rd142], %f31;
	add.s64 	%rd143, %rd3, %rd136;
	st.global.f32 	[%rd143], %f35;
	add.s64 	%rd144, %rd2, %rd136;
	st.global.f32 	[%rd144], %f41;
	add.s64 	%rd145, %rd1, %rd136;
	st.global.f32 	[%rd145], %f193;
$L__BB47_1:
	ret;

}
	// .globl	loop_slice_fusion_55
.visible .entry loop_slice_fusion_55(
	.param .u64 loop_slice_fusion_55_param_0,
	.param .u64 loop_slice_fusion_55_param_1,
	.param .u64 loop_slice_fusion_55_param_2,
	.param .u64 loop_slice_fusion_55_param_3,
	.param .u64 loop_slice_fusion_55_param_4,
	.param .u64 loop_slice_fusion_55_param_5
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<40>;
	.reg .f32 	%f<42>;
	.reg .b64 	%rd<66>;

	ld.param.u64 	%rd1, [loop_slice_fusion_55_param_0];
	ld.param.u64 	%rd2, [loop_slice_fusion_55_param_5];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_slice_fusion_55_param_1];
	ld.param.u64 	%rd5, [loop_slice_fusion_55_param_4];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_slice_fusion_55_param_2];
	ld.param.u64 	%rd8, [loop_slice_fusion_55_param_3];
	cvta.to.global.u64 	%rd9, %rd8;
	cvta.to.global.u64 	%rd10, %rd7;
	cvta.to.global.u64 	%rd11, %rd4;
	cvta.to.global.u64 	%rd12, %rd1;
	mov.u32 	%r1, %ctaid.x;
	cvt.u16.u32 	%rs1, %r1;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, -9611;
	shr.u16 	%rs4, %rs3, 6;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	or.b32  	%r6, %r5, 3;
	mul.hi.u16 	%rs5, %rs1, -21845;
	shr.u16 	%rs6, %rs5, 1;
	mul.hi.u16 	%rs7, %rs6, 5243;
	shr.u16 	%rs8, %rs7, 2;
	mul.lo.s16 	%rs9, %rs8, 50;
	sub.s16 	%rs10, %rs6, %rs9;
	mul.hi.u32 	%r7, %r6, 715827883;
	mul.lo.s32 	%r8, %r7, 6;
	sub.s32 	%r9, %r6, %r8;
	or.b32  	%r10, %r5, 2;
	mul.hi.u32 	%r11, %r10, 715827883;
	mul.lo.s32 	%r12, %r11, 6;
	sub.s32 	%r13, %r10, %r12;
	or.b32  	%r14, %r5, 1;
	mul.hi.u32 	%r15, %r5, 715827883;
	mul.hi.u32 	%r16, %r14, 715827883;
	mul.lo.s32 	%r17, %r16, 6;
	sub.s32 	%r18, %r14, %r17;
	mul.lo.s32 	%r19, %r15, 6;
	sub.s32 	%r20, %r5, %r19;
	shl.b32 	%r21, %r15, 1;
	and.b32  	%r22, %r21, 510;
	cvt.u32.u16 	%r23, %rs4;
	mul.wide.u32 	%rd13, %r23, 4;
	add.s64 	%rd14, %rd11, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	shr.u32 	%r24, %r20, 1;
	mul.wide.u32 	%rd15, %r24, 4;
	mul.wide.u32 	%rd16, %r23, 12;
	add.s64 	%rd17, %rd6, %rd16;
	add.s64 	%rd18, %rd17, %rd15;
	ld.global.nc.f32 	%f2, [%rd18];
	shl.b32 	%r25, %r22, 1;
	shl.b16 	%rs11, %rs10, 10;
	cvt.u32.u16 	%r26, %rs11;
	or.b32  	%r27, %r25, %r26;
	mul.wide.u32 	%rd19, %r27, 24;
	mul.wide.u32 	%rd20, %r23, 1228800;
	add.s64 	%rd21, %rd12, %rd20;
	add.s64 	%rd22, %rd21, %rd19;
	mul.wide.u32 	%rd23, %r20, 4;
	add.s64 	%rd24, %rd22, %rd23;
	ld.global.nc.f32 	%f3, [%rd24];
	mul.rn.f32 	%f4, %f2, %f3;
	add.s64 	%rd25, %rd9, %rd16;
	add.s64 	%rd26, %rd25, %rd15;
	ld.global.nc.f32 	%f5, [%rd26];
	mul.wide.u32 	%rd27, %r23, 614400;
	add.s64 	%rd28, %rd10, %rd27;
	cvt.u32.u16 	%r28, %rs10;
	mul.wide.u32 	%rd29, %r28, 12288;
	add.s64 	%rd30, %rd28, %rd29;
	mul.wide.u32 	%rd31, %r22, 24;
	add.s64 	%rd32, %rd30, %rd31;
	mul.wide.u32 	%rd33, %r24, 8;
	add.s64 	%rd34, %rd32, %rd33;
	ld.global.nc.f32 	%f6, [%rd34];
	mul.rn.f32 	%f7, %f5, %f6;
	add.rn.f32 	%f8, %f4, %f7;
	mul.rn.f32 	%f9, %f1, %f8;
	ld.global.nc.f32 	%f10, [%rd24+24];
	add.rn.f32 	%f11, %f10, %f9;
	mul.wide.u32 	%rd35, %r5, 4;
	add.s64 	%rd36, %rd3, %rd35;
	shr.u32 	%r29, %r18, 1;
	mul.wide.u32 	%rd37, %r29, 4;
	add.s64 	%rd38, %rd17, %rd37;
	ld.global.nc.f32 	%f12, [%rd38];
	mul.wide.u32 	%rd39, %r18, 4;
	add.s64 	%rd40, %rd22, %rd39;
	ld.global.nc.f32 	%f13, [%rd40];
	mul.rn.f32 	%f14, %f12, %f13;
	add.s64 	%rd41, %rd25, %rd37;
	ld.global.nc.f32 	%f15, [%rd41];
	mul.wide.u32 	%rd42, %r29, 8;
	add.s64 	%rd43, %rd32, %rd42;
	ld.global.nc.f32 	%f16, [%rd43+4];
	mul.rn.f32 	%f17, %f15, %f16;
	add.rn.f32 	%f18, %f14, %f17;
	mul.rn.f32 	%f19, %f1, %f18;
	ld.global.nc.f32 	%f20, [%rd40+24];
	add.rn.f32 	%f21, %f20, %f19;
	shl.b32 	%r30, %r11, 1;
	and.b32  	%r31, %r30, 510;
	shr.u32 	%r32, %r13, 1;
	mul.wide.u32 	%rd44, %r32, 4;
	add.s64 	%rd45, %rd17, %rd44;
	ld.global.nc.f32 	%f22, [%rd45];
	shl.b32 	%r33, %r31, 1;
	or.b32  	%r34, %r33, %r26;
	mul.wide.u32 	%rd46, %r34, 24;
	add.s64 	%rd47, %rd21, %rd46;
	mul.wide.u32 	%rd48, %r13, 4;
	add.s64 	%rd49, %rd47, %rd48;
	ld.global.nc.f32 	%f23, [%rd49];
	mul.rn.f32 	%f24, %f22, %f23;
	add.s64 	%rd50, %rd25, %rd44;
	ld.global.nc.f32 	%f25, [%rd50];
	mul.wide.u32 	%rd51, %r31, 24;
	add.s64 	%rd52, %rd30, %rd51;
	mul.wide.u32 	%rd53, %r32, 8;
	add.s64 	%rd54, %rd52, %rd53;
	ld.global.nc.f32 	%f26, [%rd54];
	mul.rn.f32 	%f27, %f25, %f26;
	add.rn.f32 	%f28, %f24, %f27;
	mul.rn.f32 	%f29, %f1, %f28;
	ld.global.nc.f32 	%f30, [%rd49+24];
	add.rn.f32 	%f31, %f30, %f29;
	shl.b32 	%r35, %r7, 1;
	and.b32  	%r36, %r35, 510;
	shr.u32 	%r37, %r9, 1;
	mul.wide.u32 	%rd55, %r37, 4;
	add.s64 	%rd56, %rd17, %rd55;
	ld.global.nc.f32 	%f32, [%rd56];
	shl.b32 	%r38, %r36, 1;
	or.b32  	%r39, %r38, %r26;
	mul.wide.u32 	%rd57, %r39, 24;
	add.s64 	%rd58, %rd21, %rd57;
	mul.wide.u32 	%rd59, %r9, 4;
	add.s64 	%rd60, %rd58, %rd59;
	ld.global.nc.f32 	%f33, [%rd60];
	mul.rn.f32 	%f34, %f32, %f33;
	add.s64 	%rd61, %rd25, %rd55;
	ld.global.nc.f32 	%f35, [%rd61];
	mul.wide.u32 	%rd62, %r36, 24;
	add.s64 	%rd63, %rd30, %rd62;
	mul.wide.u32 	%rd64, %r37, 8;
	add.s64 	%rd65, %rd63, %rd64;
	ld.global.nc.f32 	%f36, [%rd65+4];
	mul.rn.f32 	%f37, %f35, %f36;
	add.rn.f32 	%f38, %f34, %f37;
	mul.rn.f32 	%f39, %f1, %f38;
	ld.global.nc.f32 	%f40, [%rd60+24];
	add.rn.f32 	%f41, %f40, %f39;
	st.global.v4.f32 	[%rd36], {%f11, %f21, %f31, %f41};
	ret;

}
	// .globl	input_concatenate_fusion_181
.visible .entry input_concatenate_fusion_181(
	.param .u64 input_concatenate_fusion_181_param_0,
	.param .u64 input_concatenate_fusion_181_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<15>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<20>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_181_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_181_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -1431655765;
	shr.u32 	%r6, %r5, 1;
	mul.lo.s32 	%r7, %r6, 3;
	sub.s32 	%r8, %r4, %r7;
	bfe.u32 	%r9, %r5, 1, 8;
	cvt.u16.u32 	%rs1, %r1;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.hi.u16 	%rs4, %rs3, 5243;
	shr.u16 	%rs5, %rs4, 2;
	mul.lo.s16 	%rs6, %rs5, 50;
	sub.s16 	%rs7, %rs3, %rs6;
	shr.u16 	%rs8, %rs1, 2;
	mul.hi.u16 	%rs9, %rs8, 27963;
	shr.u16 	%rs10, %rs9, 5;
	shl.b32 	%r10, %r8, 1;
	or.b32  	%r11, %r10, 1;
	setp.gt.u32 	%p1, %r8, 1;
	selp.b32 	%r12, 5, %r11, %p1;
	mul.wide.u32 	%rd5, %r12, 4;
	cvt.u32.u16 	%r13, %rs10;
	mul.wide.u32 	%rd6, %r13, 307200;
	add.s64 	%rd7, %rd4, %rd6;
	cvt.u32.u16 	%r14, %rs7;
	mul.wide.u32 	%rd8, %r14, 6144;
	add.s64 	%rd9, %rd7, %rd8;
	mul.wide.u32 	%rd10, %r9, 24;
	add.s64 	%rd11, %rd9, %rd10;
	add.s64 	%rd12, %rd11, %rd5;
	ld.global.nc.f32 	%f1, [%rd12];
	neg.f32 	%f2, %f1;
	add.s64 	%rd13, %rd3, %rd6;
	add.s64 	%rd14, %rd13, %rd8;
	add.s64 	%rd15, %rd14, %rd10;
	mul.wide.u32 	%rd16, %r8, 8;
	add.s64 	%rd17, %rd15, %rd16;
	mul.wide.u32 	%rd18, %r10, 4;
	add.s64 	%rd19, %rd11, %rd18;
	ld.global.nc.f32 	%f3, [%rd19];
	st.global.v2.f32 	[%rd17], {%f2, %f3};
	ret;

}
	// .globl	loop_add_fusion_294
.visible .entry loop_add_fusion_294(
	.param .u64 loop_add_fusion_294_param_0,
	.param .u64 loop_add_fusion_294_param_1,
	.param .u64 loop_add_fusion_294_param_2,
	.param .u64 loop_add_fusion_294_param_3,
	.param .u64 loop_add_fusion_294_param_4,
	.param .u64 loop_add_fusion_294_param_5,
	.param .u64 loop_add_fusion_294_param_6,
	.param .u64 loop_add_fusion_294_param_7,
	.param .u64 loop_add_fusion_294_param_8,
	.param .u64 loop_add_fusion_294_param_9,
	.param .u64 loop_add_fusion_294_param_10
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<43>;
	.reg .f32 	%f<79>;
	.reg .b64 	%rd<89>;

	ld.param.u64 	%rd1, [loop_add_fusion_294_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_294_param_10];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_294_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_294_param_9];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_294_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_294_param_8];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_294_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_294_param_7];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_294_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_294_param_6];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_294_param_5];
	cvta.to.global.u64 	%rd17, %rd16;
	cvta.to.global.u64 	%rd18, %rd13;
	cvta.to.global.u64 	%rd19, %rd10;
	cvta.to.global.u64 	%rd20, %rd7;
	cvta.to.global.u64 	%rd21, %rd4;
	cvta.to.global.u64 	%rd22, %rd1;
	mov.u32 	%r1, %ctaid.x;
	cvt.u16.u32 	%rs1, %r1;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, -9611;
	shr.u16 	%rs4, %rs3, 6;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	or.b32  	%r6, %r5, 3;
	mul.hi.u16 	%rs5, %rs1, -21845;
	shr.u16 	%rs6, %rs5, 1;
	mul.hi.u16 	%rs7, %rs6, 5243;
	shr.u16 	%rs8, %rs7, 2;
	mul.lo.s16 	%rs9, %rs8, 50;
	sub.s16 	%rs10, %rs6, %rs9;
	mul.hi.u32 	%r7, %r6, 715827883;
	mul.lo.s32 	%r8, %r7, 6;
	sub.s32 	%r9, %r6, %r8;
	or.b32  	%r10, %r5, 2;
	mul.hi.u32 	%r11, %r10, 715827883;
	mul.lo.s32 	%r12, %r11, 6;
	sub.s32 	%r13, %r10, %r12;
	or.b32  	%r14, %r5, 1;
	mul.hi.u32 	%r15, %r5, 715827883;
	mul.hi.u32 	%r16, %r14, 715827883;
	mul.lo.s32 	%r17, %r16, 6;
	sub.s32 	%r18, %r14, %r17;
	mul.lo.s32 	%r19, %r15, 6;
	sub.s32 	%r20, %r5, %r19;
	cvt.u32.u16 	%r21, %rs4;
	mul.wide.u32 	%rd23, %r21, 4;
	add.s64 	%rd24, %rd20, %rd23;
	ld.global.nc.f32 	%f1, [%rd24];
	shr.u32 	%r22, %r20, 1;
	mul.wide.u32 	%rd25, %r22, 4;
	mul.wide.u32 	%rd26, %r21, 12;
	add.s64 	%rd27, %rd6, %rd26;
	add.s64 	%rd28, %rd27, %rd25;
	ld.global.nc.f32 	%f2, [%rd28];
	mul.wide.u32 	%rd29, %r5, 4;
	add.s64 	%rd30, %rd9, %rd29;
	ld.global.nc.v4.f32 	{%f3, %f4, %f5, %f6}, [%rd30];
	mul.rn.f32 	%f7, %f2, %f3;
	add.s64 	%rd31, %rd12, %rd26;
	add.s64 	%rd32, %rd31, %rd25;
	ld.global.nc.f32 	%f8, [%rd32];
	add.s64 	%rd33, %rd15, %rd29;
	ld.global.nc.v4.f32 	{%f9, %f10, %f11, %f12}, [%rd33];
	mul.rn.f32 	%f13, %f8, %f9;
	add.rn.f32 	%f14, %f7, %f13;
	mul.rn.f32 	%f15, %f1, %f14;
	shl.b32 	%r23, %r15, 1;
	and.b32  	%r24, %r23, 510;
	shl.b32 	%r25, %r24, 1;
	add.s64 	%rd34, %rd21, %rd23;
	ld.global.nc.f32 	%f16, [%rd34];
	add.s64 	%rd35, %rd17, %rd26;
	add.s64 	%rd36, %rd35, %rd25;
	ld.global.nc.f32 	%f17, [%rd36];
	shl.b16 	%rs11, %rs10, 10;
	cvt.u32.u16 	%r26, %rs11;
	or.b32  	%r27, %r25, %r26;
	or.b32  	%r28, %r27, 2;
	mul.wide.u32 	%rd37, %r28, 24;
	mul.wide.u32 	%rd38, %r21, 1228800;
	add.s64 	%rd39, %rd22, %rd38;
	add.s64 	%rd40, %rd39, %rd37;
	mul.wide.u32 	%rd41, %r20, 4;
	add.s64 	%rd42, %rd40, %rd41;
	ld.global.nc.f32 	%f18, [%rd42];
	mul.rn.f32 	%f19, %f17, %f18;
	add.s64 	%rd43, %rd18, %rd26;
	add.s64 	%rd44, %rd43, %rd25;
	ld.global.nc.f32 	%f20, [%rd44];
	mul.wide.u32 	%rd45, %r21, 614400;
	add.s64 	%rd46, %rd19, %rd45;
	cvt.u32.u16 	%r29, %rs10;
	mul.wide.u32 	%rd47, %r29, 12288;
	add.s64 	%rd48, %rd46, %rd47;
	mul.wide.u32 	%rd49, %r24, 24;
	add.s64 	%rd50, %rd48, %rd49;
	mul.wide.u32 	%rd51, %r22, 8;
	add.s64 	%rd52, %rd50, %rd51;
	ld.global.nc.f32 	%f21, [%rd52+24];
	mul.rn.f32 	%f22, %f20, %f21;
	add.rn.f32 	%f23, %f19, %f22;
	mul.rn.f32 	%f24, %f16, %f23;
	ld.global.nc.f32 	%f25, [%rd42+24];
	add.rn.f32 	%f26, %f25, %f24;
	add.rn.f32 	%f27, %f15, %f26;
	add.s64 	%rd53, %rd3, %rd29;
	shr.u32 	%r30, %r18, 1;
	mul.wide.u32 	%rd54, %r30, 4;
	add.s64 	%rd55, %rd27, %rd54;
	ld.global.nc.f32 	%f28, [%rd55];
	mul.rn.f32 	%f29, %f28, %f4;
	add.s64 	%rd56, %rd31, %rd54;
	ld.global.nc.f32 	%f30, [%rd56];
	mul.rn.f32 	%f31, %f30, %f10;
	add.rn.f32 	%f32, %f29, %f31;
	mul.rn.f32 	%f33, %f1, %f32;
	add.s64 	%rd57, %rd35, %rd54;
	ld.global.nc.f32 	%f34, [%rd57];
	mul.wide.u32 	%rd58, %r18, 4;
	add.s64 	%rd59, %rd40, %rd58;
	ld.global.nc.f32 	%f35, [%rd59];
	mul.rn.f32 	%f36, %f34, %f35;
	add.s64 	%rd60, %rd43, %rd54;
	ld.global.nc.f32 	%f37, [%rd60];
	mul.wide.u32 	%rd61, %r30, 8;
	add.s64 	%rd62, %rd50, %rd61;
	ld.global.nc.f32 	%f38, [%rd62+28];
	mul.rn.f32 	%f39, %f37, %f38;
	add.rn.f32 	%f40, %f36, %f39;
	mul.rn.f32 	%f41, %f16, %f40;
	ld.global.nc.f32 	%f42, [%rd59+24];
	add.rn.f32 	%f43, %f42, %f41;
	add.rn.f32 	%f44, %f33, %f43;
	shr.u32 	%r31, %r13, 1;
	mul.wide.u32 	%rd63, %r31, 4;
	add.s64 	%rd64, %rd27, %rd63;
	ld.global.nc.f32 	%f45, [%rd64];
	mul.rn.f32 	%f46, %f45, %f5;
	add.s64 	%rd65, %rd31, %rd63;
	ld.global.nc.f32 	%f47, [%rd65];
	mul.rn.f32 	%f48, %f47, %f11;
	add.rn.f32 	%f49, %f46, %f48;
	mul.rn.f32 	%f50, %f1, %f49;
	shl.b32 	%r32, %r11, 1;
	and.b32  	%r33, %r32, 510;
	shl.b32 	%r34, %r33, 1;
	add.s64 	%rd66, %rd35, %rd63;
	ld.global.nc.f32 	%f51, [%rd66];
	or.b32  	%r35, %r34, %r26;
	or.b32  	%r36, %r35, 2;
	mul.wide.u32 	%rd67, %r36, 24;
	add.s64 	%rd68, %rd39, %rd67;
	mul.wide.u32 	%rd69, %r13, 4;
	add.s64 	%rd70, %rd68, %rd69;
	ld.global.nc.f32 	%f52, [%rd70];
	mul.rn.f32 	%f53, %f51, %f52;
	add.s64 	%rd71, %rd43, %rd63;
	ld.global.nc.f32 	%f54, [%rd71];
	mul.wide.u32 	%rd72, %r33, 24;
	add.s64 	%rd73, %rd48, %rd72;
	mul.wide.u32 	%rd74, %r31, 8;
	add.s64 	%rd75, %rd73, %rd74;
	ld.global.nc.f32 	%f55, [%rd75+24];
	mul.rn.f32 	%f56, %f54, %f55;
	add.rn.f32 	%f57, %f53, %f56;
	mul.rn.f32 	%f58, %f16, %f57;
	ld.global.nc.f32 	%f59, [%rd70+24];
	add.rn.f32 	%f60, %f59, %f58;
	add.rn.f32 	%f61, %f50, %f60;
	shr.u32 	%r37, %r9, 1;
	mul.wide.u32 	%rd76, %r37, 4;
	add.s64 	%rd77, %rd27, %rd76;
	ld.global.nc.f32 	%f62, [%rd77];
	mul.rn.f32 	%f63, %f62, %f6;
	add.s64 	%rd78, %rd31, %rd76;
	ld.global.nc.f32 	%f64, [%rd78];
	mul.rn.f32 	%f65, %f64, %f12;
	add.rn.f32 	%f66, %f63, %f65;
	mul.rn.f32 	%f67, %f1, %f66;
	shl.b32 	%r38, %r7, 1;
	and.b32  	%r39, %r38, 510;
	shl.b32 	%r40, %r39, 1;
	add.s64 	%rd79, %rd35, %rd76;
	ld.global.nc.f32 	%f68, [%rd79];
	or.b32  	%r41, %r40, %r26;
	or.b32  	%r42, %r41, 2;
	mul.wide.u32 	%rd80, %r42, 24;
	add.s64 	%rd81, %rd39, %rd80;
	mul.wide.u32 	%rd82, %r9, 4;
	add.s64 	%rd83, %rd81, %rd82;
	ld.global.nc.f32 	%f69, [%rd83];
	mul.rn.f32 	%f70, %f68, %f69;
	add.s64 	%rd84, %rd43, %rd76;
	ld.global.nc.f32 	%f71, [%rd84];
	mul.wide.u32 	%rd85, %r39, 24;
	add.s64 	%rd86, %rd48, %rd85;
	mul.wide.u32 	%rd87, %r37, 8;
	add.s64 	%rd88, %rd86, %rd87;
	ld.global.nc.f32 	%f72, [%rd88+28];
	mul.rn.f32 	%f73, %f71, %f72;
	add.rn.f32 	%f74, %f70, %f73;
	mul.rn.f32 	%f75, %f16, %f74;
	ld.global.nc.f32 	%f76, [%rd83+24];
	add.rn.f32 	%f77, %f76, %f75;
	add.rn.f32 	%f78, %f67, %f77;
	st.global.v4.f32 	[%rd53], {%f27, %f44, %f61, %f78};
	ret;

}
	// .globl	input_concatenate_fusion_182
.visible .entry input_concatenate_fusion_182(
	.param .u64 input_concatenate_fusion_182_param_0,
	.param .u64 input_concatenate_fusion_182_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<16>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<23>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_182_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_182_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -1431655765;
	shr.u32 	%r6, %r5, 1;
	mul.lo.s32 	%r7, %r6, 3;
	sub.s32 	%r8, %r4, %r7;
	bfe.u32 	%r9, %r5, 1, 7;
	cvt.u16.u32 	%rs1, %r1;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.hi.u16 	%rs4, %rs3, 5243;
	shr.u16 	%rs5, %rs4, 2;
	mul.lo.s16 	%rs6, %rs5, 50;
	sub.s16 	%rs7, %rs3, %rs6;
	shr.u16 	%rs8, %rs1, 1;
	mul.hi.u16 	%rs9, %rs8, -9611;
	shr.u16 	%rs10, %rs9, 6;
	shl.b32 	%r10, %r8, 1;
	or.b32  	%r11, %r10, 1;
	setp.gt.u32 	%p1, %r8, 1;
	selp.b32 	%r12, 5, %r11, %p1;
	shl.b32 	%r13, %r9, 1;
	mul.wide.u32 	%rd5, %r12, 4;
	cvt.u32.u16 	%r14, %rs10;
	mul.wide.u32 	%rd6, %r14, 307200;
	add.s64 	%rd7, %rd4, %rd6;
	cvt.u32.u16 	%r15, %rs7;
	mul.wide.u32 	%rd8, %r15, 6144;
	add.s64 	%rd9, %rd7, %rd8;
	mul.wide.u32 	%rd10, %r13, 24;
	add.s64 	%rd11, %rd9, %rd10;
	add.s64 	%rd12, %rd11, %rd5;
	ld.global.nc.f32 	%f1, [%rd12];
	neg.f32 	%f2, %f1;
	mul.wide.u32 	%rd13, %r14, 153600;
	add.s64 	%rd14, %rd3, %rd13;
	mul.wide.u32 	%rd15, %r15, 3072;
	add.s64 	%rd16, %rd14, %rd15;
	mul.wide.u32 	%rd17, %r9, 24;
	add.s64 	%rd18, %rd16, %rd17;
	mul.wide.u32 	%rd19, %r8, 8;
	add.s64 	%rd20, %rd18, %rd19;
	mul.wide.u32 	%rd21, %r10, 4;
	add.s64 	%rd22, %rd11, %rd21;
	ld.global.nc.f32 	%f3, [%rd22];
	st.global.v2.f32 	[%rd20], {%f2, %f3};
	ret;

}
	// .globl	loop_slice_fusion_56
.visible .entry loop_slice_fusion_56(
	.param .u64 loop_slice_fusion_56_param_0,
	.param .u64 loop_slice_fusion_56_param_1,
	.param .u64 loop_slice_fusion_56_param_2,
	.param .u64 loop_slice_fusion_56_param_3,
	.param .u64 loop_slice_fusion_56_param_4,
	.param .u64 loop_slice_fusion_56_param_5
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<38>;
	.reg .f32 	%f<42>;
	.reg .b64 	%rd<68>;

	ld.param.u64 	%rd1, [loop_slice_fusion_56_param_0];
	ld.param.u64 	%rd2, [loop_slice_fusion_56_param_5];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_slice_fusion_56_param_1];
	ld.param.u64 	%rd5, [loop_slice_fusion_56_param_4];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_slice_fusion_56_param_2];
	ld.param.u64 	%rd8, [loop_slice_fusion_56_param_3];
	cvta.to.global.u64 	%rd9, %rd8;
	cvta.to.global.u64 	%rd10, %rd7;
	cvta.to.global.u64 	%rd11, %rd4;
	cvta.to.global.u64 	%rd12, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	mul.hi.u32 	%r6, %r5, 458129845;
	bfe.u32 	%r7, %r6, 11, 6;
	or.b32  	%r8, %r5, 3;
	mul.hi.u32 	%r9, %r5, 715827883;
	shr.u32 	%r10, %r9, 6;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r8, 715827883;
	mul.lo.s32 	%r12, %r11, 6;
	sub.s32 	%r13, %r8, %r12;
	or.b32  	%r14, %r5, 2;
	mul.hi.u32 	%r15, %r14, 715827883;
	mul.lo.s32 	%r16, %r15, 6;
	sub.s32 	%r17, %r14, %r16;
	or.b32  	%r18, %r5, 1;
	mul.hi.u32 	%r19, %r18, 715827883;
	mul.lo.s32 	%r20, %r19, 6;
	sub.s32 	%r21, %r18, %r20;
	mul.lo.s32 	%r22, %r9, 6;
	sub.s32 	%r23, %r5, %r22;
	shl.b32 	%r24, %r9, 1;
	and.b32  	%r25, %r24, 126;
	mul.wide.u32 	%rd13, %r7, 4;
	add.s64 	%rd14, %rd11, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	shr.u32 	%r26, %r23, 1;
	mul.wide.u32 	%rd15, %r26, 4;
	mul.wide.u32 	%rd16, %r7, 12;
	add.s64 	%rd17, %rd6, %rd16;
	add.s64 	%rd18, %rd17, %rd15;
	ld.global.nc.f32 	%f2, [%rd18];
	shl.b32 	%r27, %r25, 1;
	cvt.u32.u16 	%r28, %rs6;
	mul.wide.u32 	%rd19, %r28, 6144;
	mul.wide.u32 	%rd20, %r7, 307200;
	add.s64 	%rd21, %rd12, %rd20;
	add.s64 	%rd22, %rd21, %rd19;
	mul.wide.u32 	%rd23, %r27, 24;
	add.s64 	%rd24, %rd22, %rd23;
	mul.wide.u32 	%rd25, %r23, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f3, [%rd26];
	mul.rn.f32 	%f4, %f2, %f3;
	add.s64 	%rd27, %rd9, %rd16;
	add.s64 	%rd28, %rd27, %rd15;
	ld.global.nc.f32 	%f5, [%rd28];
	mul.wide.u32 	%rd29, %r28, 3072;
	mul.wide.u32 	%rd30, %r7, 153600;
	add.s64 	%rd31, %rd10, %rd30;
	add.s64 	%rd32, %rd31, %rd29;
	mul.wide.u32 	%rd33, %r25, 24;
	add.s64 	%rd34, %rd32, %rd33;
	mul.wide.u32 	%rd35, %r26, 8;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.nc.f32 	%f6, [%rd36];
	mul.rn.f32 	%f7, %f5, %f6;
	add.rn.f32 	%f8, %f4, %f7;
	mul.rn.f32 	%f9, %f1, %f8;
	ld.global.nc.f32 	%f10, [%rd26+24];
	add.rn.f32 	%f11, %f10, %f9;
	mul.wide.u32 	%rd37, %r5, 4;
	add.s64 	%rd38, %rd3, %rd37;
	shr.u32 	%r29, %r21, 1;
	mul.wide.u32 	%rd39, %r29, 4;
	add.s64 	%rd40, %rd17, %rd39;
	ld.global.nc.f32 	%f12, [%rd40];
	mul.wide.u32 	%rd41, %r21, 4;
	add.s64 	%rd42, %rd24, %rd41;
	ld.global.nc.f32 	%f13, [%rd42];
	mul.rn.f32 	%f14, %f12, %f13;
	add.s64 	%rd43, %rd27, %rd39;
	ld.global.nc.f32 	%f15, [%rd43];
	mul.wide.u32 	%rd44, %r29, 8;
	add.s64 	%rd45, %rd34, %rd44;
	ld.global.nc.f32 	%f16, [%rd45+4];
	mul.rn.f32 	%f17, %f15, %f16;
	add.rn.f32 	%f18, %f14, %f17;
	mul.rn.f32 	%f19, %f1, %f18;
	ld.global.nc.f32 	%f20, [%rd42+24];
	add.rn.f32 	%f21, %f20, %f19;
	shl.b32 	%r30, %r15, 1;
	and.b32  	%r31, %r30, 126;
	shr.u32 	%r32, %r17, 1;
	mul.wide.u32 	%rd46, %r32, 4;
	add.s64 	%rd47, %rd17, %rd46;
	ld.global.nc.f32 	%f22, [%rd47];
	shl.b32 	%r33, %r31, 1;
	mul.wide.u32 	%rd48, %r33, 24;
	add.s64 	%rd49, %rd22, %rd48;
	mul.wide.u32 	%rd50, %r17, 4;
	add.s64 	%rd51, %rd49, %rd50;
	ld.global.nc.f32 	%f23, [%rd51];
	mul.rn.f32 	%f24, %f22, %f23;
	add.s64 	%rd52, %rd27, %rd46;
	ld.global.nc.f32 	%f25, [%rd52];
	mul.wide.u32 	%rd53, %r31, 24;
	add.s64 	%rd54, %rd32, %rd53;
	mul.wide.u32 	%rd55, %r32, 8;
	add.s64 	%rd56, %rd54, %rd55;
	ld.global.nc.f32 	%f26, [%rd56];
	mul.rn.f32 	%f27, %f25, %f26;
	add.rn.f32 	%f28, %f24, %f27;
	mul.rn.f32 	%f29, %f1, %f28;
	ld.global.nc.f32 	%f30, [%rd51+24];
	add.rn.f32 	%f31, %f30, %f29;
	shl.b32 	%r34, %r11, 1;
	and.b32  	%r35, %r34, 126;
	shr.u32 	%r36, %r13, 1;
	mul.wide.u32 	%rd57, %r36, 4;
	add.s64 	%rd58, %rd17, %rd57;
	ld.global.nc.f32 	%f32, [%rd58];
	shl.b32 	%r37, %r35, 1;
	mul.wide.u32 	%rd59, %r37, 24;
	add.s64 	%rd60, %rd22, %rd59;
	mul.wide.u32 	%rd61, %r13, 4;
	add.s64 	%rd62, %rd60, %rd61;
	ld.global.nc.f32 	%f33, [%rd62];
	mul.rn.f32 	%f34, %f32, %f33;
	add.s64 	%rd63, %rd27, %rd57;
	ld.global.nc.f32 	%f35, [%rd63];
	mul.wide.u32 	%rd64, %r35, 24;
	add.s64 	%rd65, %rd32, %rd64;
	mul.wide.u32 	%rd66, %r36, 8;
	add.s64 	%rd67, %rd65, %rd66;
	ld.global.nc.f32 	%f36, [%rd67+4];
	mul.rn.f32 	%f37, %f35, %f36;
	add.rn.f32 	%f38, %f34, %f37;
	mul.rn.f32 	%f39, %f1, %f38;
	ld.global.nc.f32 	%f40, [%rd62+24];
	add.rn.f32 	%f41, %f40, %f39;
	st.global.v4.f32 	[%rd38], {%f11, %f21, %f31, %f41};
	ret;

}
	// .globl	input_concatenate_fusion_183
.visible .entry input_concatenate_fusion_183(
	.param .u64 input_concatenate_fusion_183_param_0,
	.param .u64 input_concatenate_fusion_183_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<16>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<20>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_183_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_183_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -1431655765;
	shr.u32 	%r6, %r5, 1;
	mul.lo.s32 	%r7, %r6, 3;
	sub.s32 	%r8, %r4, %r7;
	bfe.u32 	%r9, %r5, 1, 6;
	shr.u32 	%r10, %r5, 7;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, -19223;
	sub.s16 	%rs9, %rs7, %rs8;
	shr.u16 	%rs10, %rs9, 1;
	add.s16 	%rs11, %rs10, %rs8;
	shr.u16 	%rs12, %rs11, 6;
	shl.b32 	%r11, %r8, 1;
	or.b32  	%r12, %r11, 1;
	setp.gt.u32 	%p1, %r8, 1;
	selp.b32 	%r13, 5, %r12, %p1;
	mul.wide.u32 	%rd5, %r13, 4;
	cvt.u32.u16 	%r14, %rs6;
	mul.wide.u32 	%rd6, %r14, 1536;
	cvt.u32.u16 	%r15, %rs12;
	mul.wide.u32 	%rd7, %r15, 76800;
	add.s64 	%rd8, %rd4, %rd7;
	add.s64 	%rd9, %rd8, %rd6;
	mul.wide.u32 	%rd10, %r9, 24;
	add.s64 	%rd11, %rd9, %rd10;
	add.s64 	%rd12, %rd11, %rd5;
	ld.global.nc.f32 	%f1, [%rd12];
	neg.f32 	%f2, %f1;
	add.s64 	%rd13, %rd3, %rd7;
	add.s64 	%rd14, %rd13, %rd6;
	add.s64 	%rd15, %rd14, %rd10;
	mul.wide.u32 	%rd16, %r8, 8;
	add.s64 	%rd17, %rd15, %rd16;
	mul.wide.u32 	%rd18, %r11, 4;
	add.s64 	%rd19, %rd11, %rd18;
	ld.global.nc.f32 	%f3, [%rd19];
	st.global.v2.f32 	[%rd17], {%f2, %f3};
	ret;

}
	// .globl	loop_add_fusion_295
.visible .entry loop_add_fusion_295(
	.param .u64 loop_add_fusion_295_param_0,
	.param .u64 loop_add_fusion_295_param_1,
	.param .u64 loop_add_fusion_295_param_2,
	.param .u64 loop_add_fusion_295_param_3,
	.param .u64 loop_add_fusion_295_param_4,
	.param .u64 loop_add_fusion_295_param_5,
	.param .u64 loop_add_fusion_295_param_6,
	.param .u64 loop_add_fusion_295_param_7,
	.param .u64 loop_add_fusion_295_param_8,
	.param .u64 loop_add_fusion_295_param_9,
	.param .u64 loop_add_fusion_295_param_10
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<41>;
	.reg .f32 	%f<79>;
	.reg .b64 	%rd<91>;

	ld.param.u64 	%rd1, [loop_add_fusion_295_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_295_param_10];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_295_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_295_param_9];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_295_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_295_param_8];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_295_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_295_param_7];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_295_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_295_param_6];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_295_param_5];
	cvta.to.global.u64 	%rd17, %rd16;
	cvta.to.global.u64 	%rd18, %rd13;
	cvta.to.global.u64 	%rd19, %rd10;
	cvta.to.global.u64 	%rd20, %rd7;
	cvta.to.global.u64 	%rd21, %rd4;
	cvta.to.global.u64 	%rd22, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	mul.hi.u32 	%r6, %r5, 458129845;
	bfe.u32 	%r7, %r6, 11, 6;
	or.b32  	%r8, %r5, 3;
	mul.hi.u32 	%r9, %r5, 715827883;
	shr.u32 	%r10, %r9, 6;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r8, 715827883;
	mul.lo.s32 	%r12, %r11, 6;
	sub.s32 	%r13, %r8, %r12;
	or.b32  	%r14, %r5, 2;
	mul.hi.u32 	%r15, %r14, 715827883;
	mul.lo.s32 	%r16, %r15, 6;
	sub.s32 	%r17, %r14, %r16;
	or.b32  	%r18, %r5, 1;
	mul.hi.u32 	%r19, %r18, 715827883;
	mul.lo.s32 	%r20, %r19, 6;
	sub.s32 	%r21, %r18, %r20;
	mul.lo.s32 	%r22, %r9, 6;
	sub.s32 	%r23, %r5, %r22;
	mul.wide.u32 	%rd23, %r7, 4;
	add.s64 	%rd24, %rd20, %rd23;
	ld.global.nc.f32 	%f1, [%rd24];
	shr.u32 	%r24, %r23, 1;
	mul.wide.u32 	%rd25, %r24, 4;
	mul.wide.u32 	%rd26, %r7, 12;
	add.s64 	%rd27, %rd6, %rd26;
	add.s64 	%rd28, %rd27, %rd25;
	ld.global.nc.f32 	%f2, [%rd28];
	mul.wide.u32 	%rd29, %r5, 4;
	add.s64 	%rd30, %rd15, %rd29;
	ld.global.nc.v4.f32 	{%f3, %f4, %f5, %f6}, [%rd30];
	mul.rn.f32 	%f7, %f2, %f3;
	add.s64 	%rd31, %rd12, %rd26;
	add.s64 	%rd32, %rd31, %rd25;
	ld.global.nc.f32 	%f8, [%rd32];
	add.s64 	%rd33, %rd17, %rd29;
	ld.global.nc.v4.f32 	{%f9, %f10, %f11, %f12}, [%rd33];
	mul.rn.f32 	%f13, %f8, %f9;
	add.rn.f32 	%f14, %f7, %f13;
	mul.rn.f32 	%f15, %f1, %f14;
	shl.b32 	%r25, %r9, 1;
	and.b32  	%r26, %r25, 126;
	shl.b32 	%r27, %r26, 1;
	add.s64 	%rd34, %rd21, %rd23;
	ld.global.nc.f32 	%f16, [%rd34];
	add.s64 	%rd35, %rd9, %rd26;
	add.s64 	%rd36, %rd35, %rd25;
	ld.global.nc.f32 	%f17, [%rd36];
	or.b32  	%r28, %r27, 2;
	cvt.u32.u16 	%r29, %rs6;
	mul.wide.u32 	%rd37, %r29, 6144;
	mul.wide.u32 	%rd38, %r7, 307200;
	add.s64 	%rd39, %rd22, %rd38;
	add.s64 	%rd40, %rd39, %rd37;
	mul.wide.u32 	%rd41, %r28, 24;
	add.s64 	%rd42, %rd40, %rd41;
	mul.wide.u32 	%rd43, %r23, 4;
	add.s64 	%rd44, %rd42, %rd43;
	ld.global.nc.f32 	%f18, [%rd44];
	mul.rn.f32 	%f19, %f17, %f18;
	add.s64 	%rd45, %rd18, %rd26;
	add.s64 	%rd46, %rd45, %rd25;
	ld.global.nc.f32 	%f20, [%rd46];
	mul.wide.u32 	%rd47, %r29, 3072;
	mul.wide.u32 	%rd48, %r7, 153600;
	add.s64 	%rd49, %rd19, %rd48;
	add.s64 	%rd50, %rd49, %rd47;
	mul.wide.u32 	%rd51, %r26, 24;
	add.s64 	%rd52, %rd50, %rd51;
	mul.wide.u32 	%rd53, %r24, 8;
	add.s64 	%rd54, %rd52, %rd53;
	ld.global.nc.f32 	%f21, [%rd54+24];
	mul.rn.f32 	%f22, %f20, %f21;
	add.rn.f32 	%f23, %f19, %f22;
	mul.rn.f32 	%f24, %f16, %f23;
	ld.global.nc.f32 	%f25, [%rd44+24];
	add.rn.f32 	%f26, %f25, %f24;
	add.rn.f32 	%f27, %f15, %f26;
	add.s64 	%rd55, %rd3, %rd29;
	shr.u32 	%r30, %r21, 1;
	mul.wide.u32 	%rd56, %r30, 4;
	add.s64 	%rd57, %rd27, %rd56;
	ld.global.nc.f32 	%f28, [%rd57];
	mul.rn.f32 	%f29, %f28, %f4;
	add.s64 	%rd58, %rd31, %rd56;
	ld.global.nc.f32 	%f30, [%rd58];
	mul.rn.f32 	%f31, %f30, %f10;
	add.rn.f32 	%f32, %f29, %f31;
	mul.rn.f32 	%f33, %f1, %f32;
	add.s64 	%rd59, %rd35, %rd56;
	ld.global.nc.f32 	%f34, [%rd59];
	mul.wide.u32 	%rd60, %r21, 4;
	add.s64 	%rd61, %rd42, %rd60;
	ld.global.nc.f32 	%f35, [%rd61];
	mul.rn.f32 	%f36, %f34, %f35;
	add.s64 	%rd62, %rd45, %rd56;
	ld.global.nc.f32 	%f37, [%rd62];
	mul.wide.u32 	%rd63, %r30, 8;
	add.s64 	%rd64, %rd52, %rd63;
	ld.global.nc.f32 	%f38, [%rd64+28];
	mul.rn.f32 	%f39, %f37, %f38;
	add.rn.f32 	%f40, %f36, %f39;
	mul.rn.f32 	%f41, %f16, %f40;
	ld.global.nc.f32 	%f42, [%rd61+24];
	add.rn.f32 	%f43, %f42, %f41;
	add.rn.f32 	%f44, %f33, %f43;
	shr.u32 	%r31, %r17, 1;
	mul.wide.u32 	%rd65, %r31, 4;
	add.s64 	%rd66, %rd27, %rd65;
	ld.global.nc.f32 	%f45, [%rd66];
	mul.rn.f32 	%f46, %f45, %f5;
	add.s64 	%rd67, %rd31, %rd65;
	ld.global.nc.f32 	%f47, [%rd67];
	mul.rn.f32 	%f48, %f47, %f11;
	add.rn.f32 	%f49, %f46, %f48;
	mul.rn.f32 	%f50, %f1, %f49;
	shl.b32 	%r32, %r15, 1;
	and.b32  	%r33, %r32, 126;
	shl.b32 	%r34, %r33, 1;
	add.s64 	%rd68, %rd35, %rd65;
	ld.global.nc.f32 	%f51, [%rd68];
	or.b32  	%r35, %r34, 2;
	mul.wide.u32 	%rd69, %r35, 24;
	add.s64 	%rd70, %rd40, %rd69;
	mul.wide.u32 	%rd71, %r17, 4;
	add.s64 	%rd72, %rd70, %rd71;
	ld.global.nc.f32 	%f52, [%rd72];
	mul.rn.f32 	%f53, %f51, %f52;
	add.s64 	%rd73, %rd45, %rd65;
	ld.global.nc.f32 	%f54, [%rd73];
	mul.wide.u32 	%rd74, %r33, 24;
	add.s64 	%rd75, %rd50, %rd74;
	mul.wide.u32 	%rd76, %r31, 8;
	add.s64 	%rd77, %rd75, %rd76;
	ld.global.nc.f32 	%f55, [%rd77+24];
	mul.rn.f32 	%f56, %f54, %f55;
	add.rn.f32 	%f57, %f53, %f56;
	mul.rn.f32 	%f58, %f16, %f57;
	ld.global.nc.f32 	%f59, [%rd72+24];
	add.rn.f32 	%f60, %f59, %f58;
	add.rn.f32 	%f61, %f50, %f60;
	shr.u32 	%r36, %r13, 1;
	mul.wide.u32 	%rd78, %r36, 4;
	add.s64 	%rd79, %rd27, %rd78;
	ld.global.nc.f32 	%f62, [%rd79];
	mul.rn.f32 	%f63, %f62, %f6;
	add.s64 	%rd80, %rd31, %rd78;
	ld.global.nc.f32 	%f64, [%rd80];
	mul.rn.f32 	%f65, %f64, %f12;
	add.rn.f32 	%f66, %f63, %f65;
	mul.rn.f32 	%f67, %f1, %f66;
	shl.b32 	%r37, %r11, 1;
	and.b32  	%r38, %r37, 126;
	shl.b32 	%r39, %r38, 1;
	add.s64 	%rd81, %rd35, %rd78;
	ld.global.nc.f32 	%f68, [%rd81];
	or.b32  	%r40, %r39, 2;
	mul.wide.u32 	%rd82, %r40, 24;
	add.s64 	%rd83, %rd40, %rd82;
	mul.wide.u32 	%rd84, %r13, 4;
	add.s64 	%rd85, %rd83, %rd84;
	ld.global.nc.f32 	%f69, [%rd85];
	mul.rn.f32 	%f70, %f68, %f69;
	add.s64 	%rd86, %rd45, %rd78;
	ld.global.nc.f32 	%f71, [%rd86];
	mul.wide.u32 	%rd87, %r38, 24;
	add.s64 	%rd88, %rd50, %rd87;
	mul.wide.u32 	%rd89, %r36, 8;
	add.s64 	%rd90, %rd88, %rd89;
	ld.global.nc.f32 	%f72, [%rd90+28];
	mul.rn.f32 	%f73, %f71, %f72;
	add.rn.f32 	%f74, %f70, %f73;
	mul.rn.f32 	%f75, %f16, %f74;
	ld.global.nc.f32 	%f76, [%rd85+24];
	add.rn.f32 	%f77, %f76, %f75;
	add.rn.f32 	%f78, %f67, %f77;
	st.global.v4.f32 	[%rd55], {%f27, %f44, %f61, %f78};
	ret;

}
	// .globl	input_concatenate_fusion_184
.visible .entry input_concatenate_fusion_184(
	.param .u64 input_concatenate_fusion_184_param_0,
	.param .u64 input_concatenate_fusion_184_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<18>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<23>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_184_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_184_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -1431655765;
	shr.u32 	%r6, %r5, 1;
	mul.lo.s32 	%r7, %r6, 3;
	sub.s32 	%r8, %r4, %r7;
	bfe.u32 	%r9, %r5, 1, 5;
	shr.u32 	%r10, %r5, 6;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r4, 458129845;
	bfe.u32 	%r12, %r11, 9, 6;
	shl.b32 	%r13, %r8, 1;
	or.b32  	%r14, %r13, 1;
	setp.gt.u32 	%p1, %r8, 1;
	selp.b32 	%r15, 5, %r14, %p1;
	shl.b32 	%r16, %r9, 1;
	mul.wide.u32 	%rd5, %r15, 4;
	cvt.u32.u16 	%r17, %rs6;
	mul.wide.u32 	%rd6, %r17, 1536;
	mul.wide.u32 	%rd7, %r12, 76800;
	add.s64 	%rd8, %rd4, %rd7;
	add.s64 	%rd9, %rd8, %rd6;
	mul.wide.u32 	%rd10, %r16, 24;
	add.s64 	%rd11, %rd9, %rd10;
	add.s64 	%rd12, %rd11, %rd5;
	ld.global.nc.f32 	%f1, [%rd12];
	neg.f32 	%f2, %f1;
	mul.wide.u32 	%rd13, %r17, 768;
	mul.wide.u32 	%rd14, %r12, 38400;
	add.s64 	%rd15, %rd3, %rd14;
	add.s64 	%rd16, %rd15, %rd13;
	mul.wide.u32 	%rd17, %r9, 24;
	add.s64 	%rd18, %rd16, %rd17;
	mul.wide.u32 	%rd19, %r8, 8;
	add.s64 	%rd20, %rd18, %rd19;
	mul.wide.u32 	%rd21, %r13, 4;
	add.s64 	%rd22, %rd11, %rd21;
	ld.global.nc.f32 	%f3, [%rd22];
	st.global.v2.f32 	[%rd20], {%f2, %f3};
	ret;

}
	// .globl	loop_slice_fusion_57
.visible .entry loop_slice_fusion_57(
	.param .u64 loop_slice_fusion_57_param_0,
	.param .u64 loop_slice_fusion_57_param_1,
	.param .u64 loop_slice_fusion_57_param_2,
	.param .u64 loop_slice_fusion_57_param_3,
	.param .u64 loop_slice_fusion_57_param_4
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot56[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<122>;
	.reg .f32 	%f<57>;
	.reg .b64 	%rd<70>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot56;
	ld.param.u64 	%rd16, [loop_slice_fusion_57_param_0];
	ld.param.u64 	%rd17, [loop_slice_fusion_57_param_4];
	ld.param.u64 	%rd18, [loop_slice_fusion_57_param_1];
	ld.param.u64 	%rd19, [loop_slice_fusion_57_param_3];
	cvta.to.global.u64 	%rd20, %rd19;
	ld.param.u64 	%rd21, [loop_slice_fusion_57_param_2];
	cvta.to.global.u64 	%rd22, %rd18;
	cvta.to.global.u64 	%rd3, %rd16;
	add.u64 	%rd4, %SPL, 0;
	mov.u32 	%r35, %ctaid.x;
	shl.b32 	%r36, %r35, 7;
	mov.u32 	%r37, %tid.x;
	or.b32  	%r1, %r36, %r37;
	mul.hi.u32 	%r38, %r1, 458129845;
	bfe.u32 	%r39, %r38, 9, 6;
	mul.hi.u32 	%r40, %r1, -1431655765;
	shr.u32 	%r41, %r40, 6;
	cvt.u16.u32 	%rs2, %r41;
	shr.u16 	%rs3, %rs2, 1;
	mul.hi.u16 	%rs4, %rs3, 5243;
	shr.u16 	%rs5, %rs4, 1;
	mul.lo.s16 	%rs6, %rs5, 50;
	sub.s16 	%rs1, %rs2, %rs6;
	shr.u32 	%r42, %r40, 2;
	mul.lo.s32 	%r43, %r42, 6;
	sub.s32 	%r2, %r1, %r43;
	shr.u32 	%r44, %r40, 1;
	and.b32  	%r3, %r44, 30;
	cvt.u64.u32 	%rd6, %r39;
	mul.wide.u32 	%rd25, %r39, 4;
	add.s64 	%rd26, %rd22, %rd25;
	ld.global.nc.f32 	%f1, [%rd26];
	shr.u32 	%r45, %r2, 1;
	mul.wide.u32 	%rd27, %r45, 4;
	mul.wide.u32 	%rd28, %r39, 12;
	add.s64 	%rd29, %rd20, %rd28;
	add.s64 	%rd30, %rd29, %rd27;
	ld.global.nc.f32 	%f2, [%rd30];
	mul.rn.f32 	%f12, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r121, %f12;
	cvt.rn.f32.s32 	%f13, %r121;
	fma.rn.f32 	%f14, %f13, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f15, %f13, 0fB3A22168, %f14;
	fma.rn.f32 	%f56, %f13, 0fA7C234C5, %f15;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p1, %f4, 0f47CE4780;
	setp.neu.f32 	%p17, %f4, 0f7F800000;
	mov.f32 	%f54, 0f00000000;
	mov.u32 	%r117, %r121;
	mov.f32 	%f55, %f56;
	@%p1 bra 	$L__BB56_8;
	@%p17 bra 	$L__BB56_3;
	mul.rn.f32 	%f55, %f2, %f54;
	mov.b32 	%r117, 0;
	bra.uni 	$L__BB56_8;
$L__BB56_3:
	mov.b32 	%r5, %f2;
	shr.u32 	%r6, %r5, 23;
	and.b32  	%r47, %r6, 224;
	add.s32 	%r48, %r47, -128;
	shl.b32 	%r49, %r5, 8;
	or.b32  	%r53, %r49, -2147483648;
	shr.u32 	%r8, %r48, 5;
	mov.b32 	%r114, 0;
	mov.u64 	%rd68, 0;
	mov.u64 	%rd32, __cudart_i2opi_f;
$L__BB56_4:
	.pragma "nounroll";
	add.s64 	%rd33, %rd32, %rd68;
	ld.global.nc.u32 	%r52, [%rd33];
	// begin inline asm
	{
	mad.lo.cc.u32   %r50, %r52, %r53, %r114;
	madc.hi.u32     %r114, %r52, %r53,  0;
	}
	// end inline asm
	add.s64 	%rd34, %rd4, %rd68;
	st.local.u32 	[%rd34], %r50;
	add.s64 	%rd68, %rd68, 4;
	cvt.u32.u64 	%r55, %rd68;
	setp.ne.s32 	%p3, %r55, 24;
	@%p3 bra 	$L__BB56_4;
	st.local.u32 	[%rd4+24], %r114;
	and.b32  	%r11, %r6, 31;
	mul.wide.u32 	%rd35, %r8, 4;
	sub.s64 	%rd10, %rd4, %rd35;
	ld.local.u32 	%r115, [%rd10+24];
	ld.local.u32 	%r116, [%rd10+20];
	setp.eq.s32 	%p4, %r11, 0;
	@%p4 bra 	$L__BB56_7;
	shl.b32 	%r56, %r116, %r11;
	shl.b32 	%r57, %r115, %r11;
	mov.b32 	%r58, 32;
	sub.s32 	%r59, %r58, %r11;
	shr.u32 	%r60, %r116, %r59;
	add.s32 	%r115, %r60, %r57;
	ld.local.u32 	%r61, [%rd10+16];
	shr.u32 	%r62, %r61, %r59;
	add.s32 	%r116, %r62, %r56;
$L__BB56_7:
	shr.u32 	%r63, %r115, 30;
	shr.u32 	%r64, %r116, 30;
	shl.b32 	%r65, %r115, 2;
	or.b32  	%r66, %r65, %r64;
	shl.b32 	%r67, %r116, 2;
	bfe.u32 	%r68, %r115, 29, 1;
	add.s32 	%r69, %r68, %r63;
	neg.s32 	%r70, %r69;
	setp.lt.s32 	%p5, %r5, 0;
	selp.b32 	%r117, %r70, %r69, %p5;
	xor.b32  	%r71, %r66, %r5;
	bfe.s32 	%r72, %r115, 29, 1;
	xor.b32  	%r73, %r72, %r66;
	xor.b32  	%r74, %r72, %r67;
	cvt.u64.u32 	%rd36, %r73;
	shl.b64 	%rd37, %rd36, 32;
	cvt.u64.u32 	%rd38, %r74;
	or.b64  	%rd39, %rd37, %rd38;
	cvt.rn.f64.s64 	%fd1, %rd39;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f16, %fd2;
	neg.f32 	%f17, %f16;
	setp.lt.s32 	%p6, %r71, 0;
	selp.f32 	%f55, %f17, %f16, %p6;
$L__BB56_8:
	cvta.to.global.u64 	%rd1, %rd17;
	cvta.to.global.u64 	%rd2, %rd21;
	cvt.u64.u32 	%rd7, %r45;
	shl.b32 	%r76, %r3, 1;
	cvt.u64.u16 	%rd11, %rs1;
	mul.lo.s64 	%rd40, %rd6, 76800;
	add.s64 	%rd41, %rd3, %rd40;
	cvt.u32.u16 	%r77, %rs1;
	mul.wide.u32 	%rd42, %r77, 1536;
	add.s64 	%rd43, %rd41, %rd42;
	mul.wide.u32 	%rd44, %r76, 24;
	add.s64 	%rd45, %rd43, %rd44;
	mul.wide.u32 	%rd46, %r2, 4;
	add.s64 	%rd12, %rd45, %rd46;
	ld.global.nc.f32 	%f8, [%rd12];
	@%p1 bra 	$L__BB56_16;
	@%p17 bra 	$L__BB56_11;
	mul.rn.f32 	%f56, %f2, %f54;
	mov.b32 	%r121, 0;
	bra.uni 	$L__BB56_16;
$L__BB56_11:
	mov.b32 	%r20, %f2;
	shr.u32 	%r21, %r20, 23;
	and.b32  	%r79, %r21, 224;
	add.s32 	%r80, %r79, -128;
	shl.b32 	%r81, %r20, 8;
	or.b32  	%r85, %r81, -2147483648;
	shr.u32 	%r23, %r80, 5;
	mov.b32 	%r118, 0;
	mov.u64 	%rd69, 0;
	mov.u64 	%rd48, __cudart_i2opi_f;
$L__BB56_12:
	.pragma "nounroll";
	add.s64 	%rd49, %rd48, %rd69;
	ld.global.nc.u32 	%r84, [%rd49];
	// begin inline asm
	{
	mad.lo.cc.u32   %r82, %r84, %r85, %r118;
	madc.hi.u32     %r118, %r84, %r85,  0;
	}
	// end inline asm
	add.s64 	%rd50, %rd4, %rd69;
	st.local.u32 	[%rd50], %r82;
	add.s64 	%rd69, %rd69, 4;
	cvt.u32.u64 	%r87, %rd69;
	setp.ne.s32 	%p9, %r87, 24;
	@%p9 bra 	$L__BB56_12;
	st.local.u32 	[%rd4+24], %r118;
	and.b32  	%r26, %r21, 31;
	mul.wide.u32 	%rd51, %r23, 4;
	sub.s64 	%rd15, %rd4, %rd51;
	ld.local.u32 	%r119, [%rd15+24];
	ld.local.u32 	%r120, [%rd15+20];
	setp.eq.s32 	%p10, %r26, 0;
	@%p10 bra 	$L__BB56_15;
	shl.b32 	%r88, %r120, %r26;
	shl.b32 	%r89, %r119, %r26;
	mov.b32 	%r90, 32;
	sub.s32 	%r91, %r90, %r26;
	shr.u32 	%r92, %r120, %r91;
	add.s32 	%r119, %r92, %r89;
	ld.local.u32 	%r93, [%rd15+16];
	shr.u32 	%r94, %r93, %r91;
	add.s32 	%r120, %r94, %r88;
$L__BB56_15:
	shr.u32 	%r95, %r119, 30;
	shr.u32 	%r96, %r120, 30;
	shl.b32 	%r97, %r119, 2;
	or.b32  	%r98, %r97, %r96;
	shl.b32 	%r99, %r120, 2;
	bfe.u32 	%r100, %r119, 29, 1;
	add.s32 	%r101, %r100, %r95;
	neg.s32 	%r102, %r101;
	setp.lt.s32 	%p11, %r20, 0;
	selp.b32 	%r121, %r102, %r101, %p11;
	xor.b32  	%r103, %r98, %r20;
	bfe.s32 	%r104, %r119, 29, 1;
	xor.b32  	%r105, %r104, %r98;
	xor.b32  	%r106, %r104, %r99;
	cvt.u64.u32 	%rd52, %r105;
	shl.b64 	%rd53, %rd52, 32;
	cvt.u64.u32 	%rd54, %r106;
	or.b64  	%rd55, %rd53, %rd54;
	cvt.rn.f64.s64 	%fd3, %rd55;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f19, %fd4;
	neg.f32 	%f20, %f19;
	setp.lt.s32 	%p12, %r103, 0;
	selp.f32 	%f56, %f20, %f19, %p12;
$L__BB56_16:
	add.s32 	%r108, %r117, 1;
	and.b32  	%r109, %r108, 2;
	setp.eq.s32 	%p13, %r109, 0;
	and.b32  	%r110, %r117, 1;
	setp.eq.b32 	%p14, %r110, 1;
	mul.rn.f32 	%f22, %f55, %f55;
	fma.rn.f32 	%f23, %f22, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f24, 0fB94D4153, %f23, %p14;
	selp.f32 	%f25, 0f3C0885E4, 0f3D2AAABB, %p14;
	fma.rn.f32 	%f26, %f24, %f22, %f25;
	selp.f32 	%f27, 0fBE2AAAA8, 0fBEFFFFFF, %p14;
	fma.rn.f32 	%f28, %f26, %f22, %f27;
	selp.f32 	%f29, %f55, 0f3F800000, %p14;
	fma.rn.f32 	%f30, %f22, %f29, 0f00000000;
	fma.rn.f32 	%f31, %f28, %f30, %f29;
	sub.rn.f32 	%f33, %f54, %f31;
	selp.f32 	%f34, %f31, %f33, %p13;
	mul.rn.f32 	%f35, %f8, %f34;
	mul.rn.f32 	%f36, %f56, %f56;
	and.b32  	%r111, %r121, 1;
	setp.eq.b32 	%p15, %r111, 1;
	selp.f32 	%f37, 0f3F800000, %f56, %p15;
	fma.rn.f32 	%f38, %f36, %f37, 0f00000000;
	fma.rn.f32 	%f39, %f36, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f40, %f39, 0fB94D4153, %p15;
	selp.f32 	%f41, 0f3D2AAABB, 0f3C0885E4, %p15;
	fma.rn.f32 	%f42, %f40, %f36, %f41;
	selp.f32 	%f43, 0fBEFFFFFF, 0fBE2AAAA8, %p15;
	fma.rn.f32 	%f44, %f42, %f36, %f43;
	fma.rn.f32 	%f45, %f44, %f38, %f37;
	and.b32  	%r112, %r121, 2;
	setp.eq.s32 	%p16, %r112, 0;
	sub.rn.f32 	%f46, %f54, %f45;
	selp.f32 	%f47, %f45, %f46, %p16;
	and.b32  	%r113, %r2, 1;
	mul.lo.s64 	%rd56, %rd6, 38400;
	add.s64 	%rd57, %rd2, %rd56;
	mul.lo.s64 	%rd58, %rd11, 768;
	add.s64 	%rd59, %rd57, %rd58;
	mul.wide.u32 	%rd60, %r3, 24;
	add.s64 	%rd61, %rd59, %rd60;
	shl.b64 	%rd62, %rd7, 3;
	add.s64 	%rd63, %rd61, %rd62;
	mul.wide.u32 	%rd64, %r113, 4;
	add.s64 	%rd65, %rd63, %rd64;
	ld.global.nc.f32 	%f48, [%rd65];
	mul.rn.f32 	%f49, %f48, %f47;
	add.rn.f32 	%f50, %f35, %f49;
	mul.rn.f32 	%f51, %f1, %f50;
	ld.global.nc.f32 	%f52, [%rd12+24];
	add.rn.f32 	%f53, %f52, %f51;
	mul.wide.u32 	%rd66, %r1, 4;
	add.s64 	%rd67, %rd1, %rd66;
	st.global.f32 	[%rd67], %f53;
	ret;

}
	// .globl	input_concatenate_fusion_185
.visible .entry input_concatenate_fusion_185(
	.param .u64 input_concatenate_fusion_185_param_0,
	.param .u64 input_concatenate_fusion_185_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<20>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_185_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_185_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -1431655765;
	shr.u32 	%r6, %r5, 1;
	mul.lo.s32 	%r7, %r6, 3;
	sub.s32 	%r8, %r4, %r7;
	bfe.u32 	%r9, %r5, 1, 4;
	shr.u32 	%r10, %r5, 5;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r4, 458129845;
	bfe.u32 	%r12, %r11, 8, 6;
	shl.b32 	%r13, %r8, 1;
	or.b32  	%r14, %r13, 1;
	setp.gt.u32 	%p1, %r8, 1;
	selp.b32 	%r15, 5, %r14, %p1;
	mul.wide.u32 	%rd5, %r15, 4;
	cvt.u32.u16 	%r16, %rs6;
	mul.wide.u32 	%rd6, %r16, 384;
	mul.wide.u32 	%rd7, %r12, 19200;
	add.s64 	%rd8, %rd4, %rd7;
	add.s64 	%rd9, %rd8, %rd6;
	mul.wide.u32 	%rd10, %r9, 24;
	add.s64 	%rd11, %rd9, %rd10;
	add.s64 	%rd12, %rd11, %rd5;
	ld.global.nc.f32 	%f1, [%rd12];
	neg.f32 	%f2, %f1;
	add.s64 	%rd13, %rd3, %rd7;
	add.s64 	%rd14, %rd13, %rd6;
	add.s64 	%rd15, %rd14, %rd10;
	mul.wide.u32 	%rd16, %r8, 8;
	add.s64 	%rd17, %rd15, %rd16;
	mul.wide.u32 	%rd18, %r13, 4;
	add.s64 	%rd19, %rd11, %rd18;
	ld.global.nc.f32 	%f3, [%rd19];
	st.global.v2.f32 	[%rd17], {%f2, %f3};
	ret;

}
	// .globl	loop_add_fusion_296
.visible .entry loop_add_fusion_296(
	.param .u64 loop_add_fusion_296_param_0,
	.param .u64 loop_add_fusion_296_param_1,
	.param .u64 loop_add_fusion_296_param_2,
	.param .u64 loop_add_fusion_296_param_3,
	.param .u64 loop_add_fusion_296_param_4,
	.param .u64 loop_add_fusion_296_param_5,
	.param .u64 loop_add_fusion_296_param_6,
	.param .u64 loop_add_fusion_296_param_7
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot58[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<35>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<231>;
	.reg .f32 	%f<138>;
	.reg .b64 	%rd<113>;
	.reg .f64 	%fd<9>;

	mov.u64 	%SPL, __local_depot58;
	ld.param.u64 	%rd30, [loop_add_fusion_296_param_1];
	ld.param.u64 	%rd31, [loop_add_fusion_296_param_6];
	cvta.to.global.u64 	%rd32, %rd31;
	ld.param.u64 	%rd34, [loop_add_fusion_296_param_5];
	cvta.to.global.u64 	%rd35, %rd34;
	ld.param.u64 	%rd36, [loop_add_fusion_296_param_3];
	ld.param.u64 	%rd37, [loop_add_fusion_296_param_4];
	cvta.to.global.u64 	%rd2, %rd37;
	add.u64 	%rd7, %SPL, 0;
	mov.u32 	%r68, %ctaid.x;
	shl.b32 	%r69, %r68, 7;
	mov.u32 	%r70, %tid.x;
	or.b32  	%r1, %r69, %r70;
	mul.hi.u32 	%r71, %r1, 458129845;
	bfe.u32 	%r72, %r71, 9, 6;
	mul.hi.u32 	%r73, %r1, -1431655765;
	shr.u32 	%r74, %r73, 6;
	cvt.u16.u32 	%rs2, %r74;
	shr.u16 	%rs3, %rs2, 1;
	mul.hi.u16 	%rs4, %rs3, 5243;
	shr.u16 	%rs5, %rs4, 1;
	shr.u32 	%r2, %r73, 2;
	mul.lo.s32 	%r75, %r2, 6;
	sub.s32 	%r3, %r1, %r75;
	mul.wide.u32 	%rd42, %r72, 4;
	add.s64 	%rd43, %rd32, %rd42;
	ld.global.nc.f32 	%f1, [%rd43];
	shr.u32 	%r76, %r3, 1;
	mul.wide.u32 	%rd44, %r76, 4;
	mul.wide.u32 	%rd45, %r72, 12;
	add.s64 	%rd46, %rd35, %rd45;
	add.s64 	%rd47, %rd46, %rd44;
	ld.global.nc.f32 	%f2, [%rd47];
	add.rn.f32 	%f3, %f2, %f2;
	mul.rn.f32 	%f24, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r222, %f24;
	cvt.rn.f32.s32 	%f25, %r222;
	fma.rn.f32 	%f26, %f25, 0fBFC90FDA, %f3;
	fma.rn.f32 	%f27, %f25, 0fB3A22168, %f26;
	fma.rn.f32 	%f135, %f25, 0fA7C234C5, %f27;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p1, %f5, 0f47CE4780;
	setp.neu.f32 	%p33, %f5, 0f7F800000;
	mov.f32 	%f133, 0f00000000;
	mov.u32 	%r218, %r222;
	mov.f32 	%f134, %f135;
	@%p1 bra 	$L__BB58_8;
	@%p33 bra 	$L__BB58_3;
	mul.rn.f32 	%f134, %f3, %f133;
	mov.b32 	%r218, 0;
	bra.uni 	$L__BB58_8;
$L__BB58_3:
	mov.b32 	%r5, %f3;
	shr.u32 	%r6, %r5, 23;
	and.b32  	%r78, %r6, 224;
	add.s32 	%r79, %r78, -128;
	shl.b32 	%r80, %r5, 8;
	or.b32  	%r84, %r80, -2147483648;
	shr.u32 	%r8, %r79, 5;
	mov.b32 	%r215, 0;
	mov.u64 	%rd109, 0;
	mov.u64 	%rd49, __cudart_i2opi_f;
$L__BB58_4:
	.pragma "nounroll";
	add.s64 	%rd50, %rd49, %rd109;
	ld.global.nc.u32 	%r83, [%rd50];
	// begin inline asm
	{
	mad.lo.cc.u32   %r81, %r83, %r84, %r215;
	madc.hi.u32     %r215, %r83, %r84,  0;
	}
	// end inline asm
	add.s64 	%rd51, %rd7, %rd109;
	st.local.u32 	[%rd51], %r81;
	add.s64 	%rd109, %rd109, 4;
	cvt.u32.u64 	%r86, %rd109;
	setp.ne.s32 	%p3, %r86, 24;
	@%p3 bra 	$L__BB58_4;
	st.local.u32 	[%rd7+24], %r215;
	and.b32  	%r11, %r6, 31;
	mul.wide.u32 	%rd52, %r8, 4;
	sub.s64 	%rd15, %rd7, %rd52;
	ld.local.u32 	%r216, [%rd15+24];
	ld.local.u32 	%r217, [%rd15+20];
	setp.eq.s32 	%p4, %r11, 0;
	@%p4 bra 	$L__BB58_7;
	shl.b32 	%r87, %r217, %r11;
	shl.b32 	%r88, %r216, %r11;
	mov.b32 	%r89, 32;
	sub.s32 	%r90, %r89, %r11;
	shr.u32 	%r91, %r217, %r90;
	add.s32 	%r216, %r91, %r88;
	ld.local.u32 	%r92, [%rd15+16];
	shr.u32 	%r93, %r92, %r90;
	add.s32 	%r217, %r93, %r87;
$L__BB58_7:
	shr.u32 	%r94, %r216, 30;
	shr.u32 	%r95, %r217, 30;
	shl.b32 	%r96, %r216, 2;
	or.b32  	%r97, %r96, %r95;
	shl.b32 	%r98, %r217, 2;
	bfe.u32 	%r99, %r216, 29, 1;
	add.s32 	%r100, %r99, %r94;
	neg.s32 	%r101, %r100;
	setp.lt.s32 	%p5, %r5, 0;
	selp.b32 	%r218, %r101, %r100, %p5;
	xor.b32  	%r102, %r97, %r5;
	bfe.s32 	%r103, %r216, 29, 1;
	xor.b32  	%r104, %r103, %r97;
	xor.b32  	%r105, %r103, %r98;
	cvt.u64.u32 	%rd53, %r104;
	shl.b64 	%rd54, %rd53, 32;
	cvt.u64.u32 	%rd55, %r105;
	or.b64  	%rd56, %rd54, %rd55;
	cvt.rn.f64.s64 	%fd1, %rd56;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f28, %fd2;
	neg.f32 	%f29, %f28;
	setp.lt.s32 	%p6, %r102, 0;
	selp.f32 	%f134, %f29, %f28, %p6;
$L__BB58_8:
	ld.param.u64 	%rd28, [loop_add_fusion_296_param_0];
	mul.lo.s16 	%rs6, %rs5, 50;
	cvta.to.global.u64 	%rd3, %rd36;
	cvta.to.global.u64 	%rd5, %rd30;
	cvt.u64.u32 	%rd11, %r72;
	cvt.u64.u32 	%rd16, %r1;
	mul.wide.u32 	%rd57, %r1, 4;
	add.s64 	%rd58, %rd2, %rd57;
	ld.global.nc.f32 	%f9, [%rd58];
	@%p1 bra 	$L__BB58_16;
	@%p33 bra 	$L__BB58_11;
	mul.rn.f32 	%f135, %f3, %f133;
	mov.b32 	%r222, 0;
	bra.uni 	$L__BB58_16;
$L__BB58_11:
	mov.b32 	%r20, %f3;
	shr.u32 	%r21, %r20, 23;
	and.b32  	%r108, %r21, 224;
	add.s32 	%r109, %r108, -128;
	shl.b32 	%r110, %r20, 8;
	or.b32  	%r114, %r110, -2147483648;
	shr.u32 	%r23, %r109, 5;
	mov.b32 	%r219, 0;
	mov.u64 	%rd110, 0;
	mov.u64 	%rd60, __cudart_i2opi_f;
$L__BB58_12:
	.pragma "nounroll";
	add.s64 	%rd61, %rd60, %rd110;
	ld.global.nc.u32 	%r113, [%rd61];
	// begin inline asm
	{
	mad.lo.cc.u32   %r111, %r113, %r114, %r219;
	madc.hi.u32     %r219, %r113, %r114,  0;
	}
	// end inline asm
	add.s64 	%rd62, %rd7, %rd110;
	st.local.u32 	[%rd62], %r111;
	add.s64 	%rd110, %rd110, 4;
	cvt.u32.u64 	%r116, %rd110;
	setp.ne.s32 	%p9, %r116, 24;
	@%p9 bra 	$L__BB58_12;
	st.local.u32 	[%rd7+24], %r219;
	and.b32  	%r26, %r21, 31;
	mul.wide.u32 	%rd63, %r23, 4;
	sub.s64 	%rd19, %rd7, %rd63;
	ld.local.u32 	%r220, [%rd19+24];
	ld.local.u32 	%r221, [%rd19+20];
	setp.eq.s32 	%p10, %r26, 0;
	@%p10 bra 	$L__BB58_15;
	shl.b32 	%r117, %r221, %r26;
	shl.b32 	%r118, %r220, %r26;
	mov.b32 	%r119, 32;
	sub.s32 	%r120, %r119, %r26;
	shr.u32 	%r121, %r221, %r120;
	add.s32 	%r220, %r121, %r118;
	ld.local.u32 	%r122, [%rd19+16];
	shr.u32 	%r123, %r122, %r120;
	add.s32 	%r221, %r123, %r117;
$L__BB58_15:
	shr.u32 	%r124, %r220, 30;
	shr.u32 	%r125, %r221, 30;
	shl.b32 	%r126, %r220, 2;
	or.b32  	%r127, %r126, %r125;
	shl.b32 	%r128, %r221, 2;
	bfe.u32 	%r129, %r220, 29, 1;
	add.s32 	%r130, %r129, %r124;
	neg.s32 	%r131, %r130;
	setp.lt.s32 	%p11, %r20, 0;
	selp.b32 	%r222, %r131, %r130, %p11;
	xor.b32  	%r132, %r127, %r20;
	bfe.s32 	%r133, %r220, 29, 1;
	xor.b32  	%r134, %r133, %r127;
	xor.b32  	%r135, %r133, %r128;
	cvt.u64.u32 	%rd64, %r134;
	shl.b64 	%rd65, %rd64, 32;
	cvt.u64.u32 	%rd66, %r135;
	or.b64  	%rd67, %rd65, %rd66;
	cvt.rn.f64.s64 	%fd3, %rd67;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f31, %fd4;
	neg.f32 	%f32, %f31;
	setp.lt.s32 	%p12, %r132, 0;
	selp.f32 	%f135, %f32, %f31, %p12;
$L__BB58_16:
	ld.param.u64 	%rd29, [loop_add_fusion_296_param_7];
	ld.param.u64 	%rd33, [loop_add_fusion_296_param_2];
	cvta.to.global.u64 	%rd6, %rd28;
	sub.s16 	%rs1, %rs2, %rs6;
	shl.b64 	%rd68, %rd16, 2;
	add.s64 	%rd69, %rd3, %rd68;
	ld.global.nc.f32 	%f13, [%rd69];
	shl.b32 	%r137, %r2, 1;
	and.b32  	%r35, %r137, 30;
	or.b32  	%r36, %r35, 1;
	shl.b64 	%rd70, %rd11, 2;
	add.s64 	%rd71, %rd5, %rd70;
	ld.global.nc.f32 	%f14, [%rd71];
	mul.rn.f32 	%f34, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r230, %f34;
	cvt.rn.f32.s32 	%f35, %r230;
	fma.rn.f32 	%f36, %f35, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f37, %f35, 0fB3A22168, %f36;
	fma.rn.f32 	%f137, %f35, 0fA7C234C5, %f37;
	abs.f32 	%f16, %f2;
	setp.ltu.f32 	%p13, %f16, 0f47CE4780;
	setp.neu.f32 	%p34, %f16, 0f7F800000;
	mov.u32 	%r226, %r230;
	mov.f32 	%f136, %f137;
	@%p13 bra 	$L__BB58_24;
	@%p34 bra 	$L__BB58_19;
	mul.rn.f32 	%f136, %f2, %f133;
	mov.b32 	%r226, 0;
	bra.uni 	$L__BB58_24;
$L__BB58_19:
	mov.b32 	%r38, %f2;
	shr.u32 	%r39, %r38, 23;
	and.b32  	%r139, %r39, 224;
	add.s32 	%r140, %r139, -128;
	shl.b32 	%r141, %r38, 8;
	or.b32  	%r145, %r141, -2147483648;
	shr.u32 	%r41, %r140, 5;
	mov.b32 	%r223, 0;
	mov.u64 	%rd111, 0;
	mov.u64 	%rd73, __cudart_i2opi_f;
$L__BB58_20:
	.pragma "nounroll";
	add.s64 	%rd74, %rd73, %rd111;
	ld.global.nc.u32 	%r144, [%rd74];
	// begin inline asm
	{
	mad.lo.cc.u32   %r142, %r144, %r145, %r223;
	madc.hi.u32     %r223, %r144, %r145,  0;
	}
	// end inline asm
	add.s64 	%rd75, %rd7, %rd111;
	st.local.u32 	[%rd75], %r142;
	add.s64 	%rd111, %rd111, 4;
	cvt.u32.u64 	%r147, %rd111;
	setp.ne.s32 	%p15, %r147, 24;
	@%p15 bra 	$L__BB58_20;
	st.local.u32 	[%rd7+24], %r223;
	and.b32  	%r44, %r39, 31;
	mul.wide.u32 	%rd76, %r41, 4;
	sub.s64 	%rd22, %rd7, %rd76;
	ld.local.u32 	%r224, [%rd22+24];
	ld.local.u32 	%r225, [%rd22+20];
	setp.eq.s32 	%p16, %r44, 0;
	@%p16 bra 	$L__BB58_23;
	shl.b32 	%r148, %r225, %r44;
	shl.b32 	%r149, %r224, %r44;
	mov.b32 	%r150, 32;
	sub.s32 	%r151, %r150, %r44;
	shr.u32 	%r152, %r225, %r151;
	add.s32 	%r224, %r152, %r149;
	ld.local.u32 	%r153, [%rd22+16];
	shr.u32 	%r154, %r153, %r151;
	add.s32 	%r225, %r154, %r148;
$L__BB58_23:
	shr.u32 	%r155, %r224, 30;
	shr.u32 	%r156, %r225, 30;
	shl.b32 	%r157, %r224, 2;
	or.b32  	%r158, %r157, %r156;
	shl.b32 	%r159, %r225, 2;
	bfe.u32 	%r160, %r224, 29, 1;
	add.s32 	%r161, %r160, %r155;
	neg.s32 	%r162, %r161;
	setp.lt.s32 	%p17, %r38, 0;
	selp.b32 	%r226, %r162, %r161, %p17;
	xor.b32  	%r163, %r158, %r38;
	bfe.s32 	%r164, %r224, 29, 1;
	xor.b32  	%r165, %r164, %r158;
	xor.b32  	%r166, %r164, %r159;
	cvt.u64.u32 	%rd77, %r165;
	shl.b64 	%rd78, %rd77, 32;
	cvt.u64.u32 	%rd79, %r166;
	or.b64  	%rd80, %rd78, %rd79;
	cvt.rn.f64.s64 	%fd5, %rd80;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f38, %fd6;
	neg.f32 	%f39, %f38;
	setp.lt.s32 	%p18, %r163, 0;
	selp.f32 	%f136, %f39, %f38, %p18;
$L__BB58_24:
	cvta.to.global.u64 	%rd1, %rd29;
	cvta.to.global.u64 	%rd4, %rd33;
	cvt.u64.u32 	%rd12, %r76;
	shl.b32 	%r168, %r36, 1;
	cvt.u64.u16 	%rd23, %rs1;
	mul.lo.s64 	%rd81, %rd11, 76800;
	add.s64 	%rd82, %rd6, %rd81;
	cvt.u32.u16 	%r169, %rs1;
	mul.wide.u32 	%rd83, %r169, 1536;
	add.s64 	%rd84, %rd82, %rd83;
	mul.wide.u32 	%rd85, %r168, 24;
	add.s64 	%rd86, %rd84, %rd85;
	mul.wide.u32 	%rd87, %r3, 4;
	add.s64 	%rd24, %rd86, %rd87;
	ld.global.nc.f32 	%f20, [%rd24];
	@%p13 bra 	$L__BB58_32;
	@%p34 bra 	$L__BB58_27;
	mul.rn.f32 	%f137, %f2, %f133;
	mov.b32 	%r230, 0;
	bra.uni 	$L__BB58_32;
$L__BB58_27:
	mov.b32 	%r53, %f2;
	shr.u32 	%r54, %r53, 23;
	and.b32  	%r171, %r54, 224;
	add.s32 	%r172, %r171, -128;
	shl.b32 	%r173, %r53, 8;
	or.b32  	%r177, %r173, -2147483648;
	shr.u32 	%r56, %r172, 5;
	mov.b32 	%r227, 0;
	mov.u64 	%rd112, 0;
	mov.u64 	%rd89, __cudart_i2opi_f;
$L__BB58_28:
	.pragma "nounroll";
	add.s64 	%rd90, %rd89, %rd112;
	ld.global.nc.u32 	%r176, [%rd90];
	// begin inline asm
	{
	mad.lo.cc.u32   %r174, %r176, %r177, %r227;
	madc.hi.u32     %r227, %r176, %r177,  0;
	}
	// end inline asm
	add.s64 	%rd91, %rd7, %rd112;
	st.local.u32 	[%rd91], %r174;
	add.s64 	%rd112, %rd112, 4;
	cvt.u32.u64 	%r179, %rd112;
	setp.ne.s32 	%p21, %r179, 24;
	@%p21 bra 	$L__BB58_28;
	st.local.u32 	[%rd7+24], %r227;
	and.b32  	%r59, %r54, 31;
	mul.wide.u32 	%rd92, %r56, 4;
	sub.s64 	%rd27, %rd7, %rd92;
	ld.local.u32 	%r228, [%rd27+24];
	ld.local.u32 	%r229, [%rd27+20];
	setp.eq.s32 	%p22, %r59, 0;
	@%p22 bra 	$L__BB58_31;
	shl.b32 	%r180, %r229, %r59;
	shl.b32 	%r181, %r228, %r59;
	mov.b32 	%r182, 32;
	sub.s32 	%r183, %r182, %r59;
	shr.u32 	%r184, %r229, %r183;
	add.s32 	%r228, %r184, %r181;
	ld.local.u32 	%r185, [%rd27+16];
	shr.u32 	%r186, %r185, %r183;
	add.s32 	%r229, %r186, %r180;
$L__BB58_31:
	shr.u32 	%r187, %r228, 30;
	shr.u32 	%r188, %r229, 30;
	shl.b32 	%r189, %r228, 2;
	or.b32  	%r190, %r189, %r188;
	shl.b32 	%r191, %r229, 2;
	bfe.u32 	%r192, %r228, 29, 1;
	add.s32 	%r193, %r192, %r187;
	neg.s32 	%r194, %r193;
	setp.lt.s32 	%p23, %r53, 0;
	selp.b32 	%r230, %r194, %r193, %p23;
	xor.b32  	%r195, %r190, %r53;
	bfe.s32 	%r196, %r228, 29, 1;
	xor.b32  	%r197, %r196, %r190;
	xor.b32  	%r198, %r196, %r191;
	cvt.u64.u32 	%rd93, %r197;
	shl.b64 	%rd94, %rd93, 32;
	cvt.u64.u32 	%rd95, %r198;
	or.b64  	%rd96, %rd94, %rd95;
	cvt.rn.f64.s64 	%fd7, %rd96;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f41, %fd8;
	neg.f32 	%f42, %f41;
	setp.lt.s32 	%p24, %r195, 0;
	selp.f32 	%f137, %f42, %f41, %p24;
$L__BB58_32:
	add.s32 	%r200, %r226, 1;
	and.b32  	%r201, %r200, 2;
	setp.eq.s32 	%p25, %r201, 0;
	and.b32  	%r202, %r226, 1;
	setp.eq.b32 	%p26, %r202, 1;
	mul.rn.f32 	%f44, %f136, %f136;
	fma.rn.f32 	%f45, %f44, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f46, 0fB94D4153, %f45, %p26;
	selp.f32 	%f47, 0f3C0885E4, 0f3D2AAABB, %p26;
	fma.rn.f32 	%f48, %f46, %f44, %f47;
	selp.f32 	%f49, 0fBE2AAAA8, 0fBEFFFFFF, %p26;
	fma.rn.f32 	%f50, %f48, %f44, %f49;
	selp.f32 	%f51, %f136, 0f3F800000, %p26;
	fma.rn.f32 	%f52, %f44, %f51, 0f00000000;
	fma.rn.f32 	%f53, %f50, %f52, %f51;
	sub.rn.f32 	%f55, %f133, %f53;
	selp.f32 	%f56, %f53, %f55, %p25;
	mul.rn.f32 	%f57, %f20, %f56;
	fma.rn.f32 	%f58, %f1, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f59, %f58;
	mov.f32 	%f60, 0f4B400001;
	mov.f32 	%f61, 0f437C0000;
	fma.rm.f32 	%f62, %f59, %f61, %f60;
	add.rn.f32 	%f63, %f62, 0fCB40007F;
	neg.f32 	%f64, %f63;
	fma.rn.f32 	%f65, %f1, 0f3FB8AA3B, %f64;
	fma.rn.f32 	%f66, %f1, 0f32A57060, %f65;
	ex2.approx.ftz.f32 	%f67, %f66;
	mov.b32 	%r203, %f62;
	shl.b32 	%r204, %r203, 23;
	mov.b32 	%f68, %r204;
	mul.rn.f32 	%f69, %f67, %f68;
	neg.f32 	%f70, %f69;
	sub.rn.f32 	%f71, %f70, %f69;
	add.rn.f32 	%f72, %f71, %f71;
	add.rn.f32 	%f73, %f72, %f72;
	add.rn.f32 	%f74, %f73, %f73;
	add.rn.f32 	%f75, %f74, %f74;
	fma.rn.f32 	%f76, %f75, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f77, %f76;
	fma.rm.f32 	%f78, %f77, %f61, %f60;
	add.rn.f32 	%f79, %f78, 0fCB40007F;
	neg.f32 	%f80, %f79;
	fma.rn.f32 	%f81, %f75, 0f3FB8AA3B, %f80;
	fma.rn.f32 	%f82, %f75, 0f32A57060, %f81;
	ex2.approx.ftz.f32 	%f83, %f82;
	mov.b32 	%r205, %f78;
	shl.b32 	%r206, %r205, 23;
	mov.b32 	%f84, %r206;
	mul.rn.f32 	%f85, %f83, %f84;
	add.s32 	%r207, %r218, 1;
	and.b32  	%r208, %r207, 2;
	setp.eq.s32 	%p27, %r208, 0;
	and.b32  	%r209, %r218, 1;
	setp.eq.b32 	%p28, %r209, 1;
	mul.rn.f32 	%f86, %f134, %f134;
	fma.rn.f32 	%f87, %f86, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f88, 0fB94D4153, %f87, %p28;
	selp.f32 	%f89, 0f3C0885E4, 0f3D2AAABB, %p28;
	fma.rn.f32 	%f90, %f88, %f86, %f89;
	selp.f32 	%f91, 0fBE2AAAA8, 0fBEFFFFFF, %p28;
	fma.rn.f32 	%f92, %f90, %f86, %f91;
	selp.f32 	%f93, %f134, 0f3F800000, %p28;
	fma.rn.f32 	%f94, %f86, %f93, 0f00000000;
	fma.rn.f32 	%f95, %f92, %f94, %f93;
	sub.rn.f32 	%f96, %f133, %f95;
	selp.f32 	%f97, %f95, %f96, %p27;
	mul.rn.f32 	%f98, %f9, %f97;
	and.b32  	%r210, %r222, 2;
	setp.eq.s32 	%p29, %r210, 0;
	and.b32  	%r211, %r222, 1;
	setp.eq.b32 	%p30, %r211, 1;
	mul.rn.f32 	%f99, %f135, %f135;
	fma.rn.f32 	%f100, %f99, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f101, %f100, 0fB94D4153, %p30;
	selp.f32 	%f102, 0f3D2AAABB, 0f3C0885E4, %p30;
	fma.rn.f32 	%f103, %f101, %f99, %f102;
	selp.f32 	%f104, 0fBEFFFFFF, 0fBE2AAAA8, %p30;
	fma.rn.f32 	%f105, %f103, %f99, %f104;
	selp.f32 	%f106, 0f3F800000, %f135, %p30;
	fma.rn.f32 	%f107, %f99, %f106, 0f00000000;
	fma.rn.f32 	%f108, %f105, %f107, %f106;
	sub.rn.f32 	%f109, %f133, %f108;
	selp.f32 	%f110, %f108, %f109, %p29;
	mul.rn.f32 	%f111, %f13, %f110;
	add.rn.f32 	%f112, %f98, %f111;
	mul.rn.f32 	%f113, %f112, %f85;
	mul.rn.f32 	%f114, %f137, %f137;
	and.b32  	%r212, %r230, 1;
	setp.eq.b32 	%p31, %r212, 1;
	selp.f32 	%f115, 0f3F800000, %f137, %p31;
	fma.rn.f32 	%f116, %f114, %f115, 0f00000000;
	fma.rn.f32 	%f117, %f114, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f118, %f117, 0fB94D4153, %p31;
	selp.f32 	%f119, 0f3D2AAABB, 0f3C0885E4, %p31;
	fma.rn.f32 	%f120, %f118, %f114, %f119;
	selp.f32 	%f121, 0fBEFFFFFF, 0fBE2AAAA8, %p31;
	fma.rn.f32 	%f122, %f120, %f114, %f121;
	fma.rn.f32 	%f123, %f122, %f116, %f115;
	and.b32  	%r213, %r230, 2;
	setp.eq.s32 	%p32, %r213, 0;
	sub.rn.f32 	%f124, %f133, %f123;
	selp.f32 	%f125, %f123, %f124, %p32;
	and.b32  	%r214, %r3, 1;
	mul.lo.s64 	%rd97, %rd11, 38400;
	add.s64 	%rd98, %rd4, %rd97;
	mul.lo.s64 	%rd99, %rd23, 768;
	add.s64 	%rd100, %rd98, %rd99;
	mul.wide.u32 	%rd101, %r35, 24;
	add.s64 	%rd102, %rd100, %rd101;
	shl.b64 	%rd103, %rd12, 3;
	add.s64 	%rd104, %rd102, %rd103;
	mul.wide.u32 	%rd105, %r214, 4;
	add.s64 	%rd106, %rd104, %rd105;
	ld.global.nc.f32 	%f126, [%rd106+24];
	mul.rn.f32 	%f127, %f126, %f125;
	add.rn.f32 	%f128, %f57, %f127;
	mul.rn.f32 	%f129, %f14, %f128;
	ld.global.nc.f32 	%f130, [%rd24+24];
	add.rn.f32 	%f131, %f130, %f129;
	add.rn.f32 	%f132, %f131, %f113;
	add.s64 	%rd108, %rd1, %rd68;
	st.global.f32 	[%rd108], %f132;
	ret;

}
	// .globl	input_concatenate_fusion_186
.visible .entry input_concatenate_fusion_186(
	.param .u64 input_concatenate_fusion_186_param_0,
	.param .u64 input_concatenate_fusion_186_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<18>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<23>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_186_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_186_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -1431655765;
	shr.u32 	%r6, %r5, 1;
	mul.lo.s32 	%r7, %r6, 3;
	sub.s32 	%r8, %r4, %r7;
	bfe.u32 	%r9, %r5, 1, 3;
	shr.u32 	%r10, %r5, 4;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r4, 458129845;
	bfe.u32 	%r12, %r11, 7, 6;
	shl.b32 	%r13, %r8, 1;
	or.b32  	%r14, %r13, 1;
	setp.gt.u32 	%p1, %r8, 1;
	selp.b32 	%r15, 5, %r14, %p1;
	shl.b32 	%r16, %r9, 1;
	mul.wide.u32 	%rd5, %r15, 4;
	cvt.u32.u16 	%r17, %rs6;
	mul.wide.u32 	%rd6, %r17, 384;
	mul.wide.u32 	%rd7, %r12, 19200;
	add.s64 	%rd8, %rd4, %rd7;
	add.s64 	%rd9, %rd8, %rd6;
	mul.wide.u32 	%rd10, %r16, 24;
	add.s64 	%rd11, %rd9, %rd10;
	add.s64 	%rd12, %rd11, %rd5;
	ld.global.nc.f32 	%f1, [%rd12];
	neg.f32 	%f2, %f1;
	mul.wide.u32 	%rd13, %r17, 192;
	mul.wide.u32 	%rd14, %r12, 9600;
	add.s64 	%rd15, %rd3, %rd14;
	add.s64 	%rd16, %rd15, %rd13;
	mul.wide.u32 	%rd17, %r9, 24;
	add.s64 	%rd18, %rd16, %rd17;
	mul.wide.u32 	%rd19, %r8, 8;
	add.s64 	%rd20, %rd18, %rd19;
	mul.wide.u32 	%rd21, %r13, 4;
	add.s64 	%rd22, %rd11, %rd21;
	ld.global.nc.f32 	%f3, [%rd22];
	st.global.v2.f32 	[%rd20], {%f2, %f3};
	ret;

}
	// .globl	input_concatenate_fusion_187
.visible .entry input_concatenate_fusion_187(
	.param .u64 input_concatenate_fusion_187_param_0,
	.param .u64 input_concatenate_fusion_187_param_1,
	.param .u64 input_concatenate_fusion_187_param_2,
	.param .u64 input_concatenate_fusion_187_param_3,
	.param .u64 input_concatenate_fusion_187_param_4
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot60[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<36>;
	.reg .b16 	%rs<20>;
	.reg .b32 	%r<227>;
	.reg .f32 	%f<146>;
	.reg .b64 	%rd<127>;
	.reg .f64 	%fd<9>;

	mov.u64 	%SPL, __local_depot60;
	ld.param.u64 	%rd30, [input_concatenate_fusion_187_param_0];
	ld.param.u64 	%rd31, [input_concatenate_fusion_187_param_4];
	ld.param.u64 	%rd32, [input_concatenate_fusion_187_param_1];
	ld.param.u64 	%rd33, [input_concatenate_fusion_187_param_3];
	cvta.to.global.u64 	%rd34, %rd33;
	ld.param.u64 	%rd35, [input_concatenate_fusion_187_param_2];
	cvta.to.global.u64 	%rd2, %rd35;
	cvta.to.global.u64 	%rd4, %rd30;
	add.u64 	%rd5, %SPL, 0;
	mov.u32 	%r65, %ctaid.x;
	mov.u32 	%r66, %tid.x;
	shl.b32 	%r67, %r65, 7;
	or.b32  	%r68, %r67, %r66;
	cvt.u16.u32 	%rs6, %r68;
	mul.hi.u16 	%rs7, %rs6, -21845;
	shr.u16 	%rs8, %rs7, 1;
	mul.lo.s16 	%rs9, %rs8, 3;
	sub.s16 	%rs1, %rs6, %rs9;
	and.b16  	%rs2, %rs8, 3;
	cvt.u32.u16 	%r1, %rs2;
	shr.u16 	%rs10, %rs7, 3;
	mul.hi.u16 	%rs11, %rs10, 5243;
	shr.u16 	%rs12, %rs11, 2;
	mul.lo.s16 	%rs13, %rs12, 50;
	sub.s16 	%rs3, %rs10, %rs13;
	shr.u16 	%rs14, %rs6, 3;
	mul.hi.u16 	%rs15, %rs14, 6991;
	shr.u16 	%rs16, %rs15, 3;
	and.b16  	%rs17, %rs16, 63;
	shl.b16 	%rs4, %rs1, 1;
	or.b16  	%rs18, %rs4, 1;
	setp.gt.u16 	%p1, %rs1, 1;
	selp.b16 	%rs5, 5, %rs18, %p1;
	cvt.u64.u16 	%rd9, %rs17;
	cvt.u32.u16 	%r69, %rs17;
	mul.wide.u32 	%rd40, %r69, 4;
	add.s64 	%rd41, %rd34, %rd40;
	ld.global.nc.f32 	%f22, [%rd41];
	fma.rn.f32 	%f23, %f22, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f24, %f23;
	mov.f32 	%f25, 0f4B400001;
	mov.f32 	%f26, 0f437C0000;
	fma.rm.f32 	%f27, %f24, %f26, %f25;
	add.rn.f32 	%f28, %f27, 0fCB40007F;
	neg.f32 	%f29, %f28;
	fma.rn.f32 	%f30, %f22, 0f3FB8AA3B, %f29;
	fma.rn.f32 	%f31, %f22, 0f32A57060, %f30;
	mov.b32 	%r70, %f27;
	shl.b32 	%r71, %r70, 23;
	mov.b32 	%f32, %r71;
	ex2.approx.ftz.f32 	%f33, %f31;
	mul.rn.f32 	%f34, %f33, %f32;
	neg.f32 	%f35, %f34;
	sub.rn.f32 	%f36, %f35, %f34;
	add.rn.f32 	%f37, %f36, %f36;
	add.rn.f32 	%f38, %f37, %f37;
	add.rn.f32 	%f39, %f38, %f38;
	add.rn.f32 	%f40, %f39, %f39;
	add.rn.f32 	%f41, %f40, %f40;
	fma.rn.f32 	%f42, %f41, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f43, %f42;
	fma.rm.f32 	%f44, %f43, %f26, %f25;
	add.rn.f32 	%f45, %f44, 0fCB40007F;
	neg.f32 	%f46, %f45;
	fma.rn.f32 	%f47, %f41, 0f3FB8AA3B, %f46;
	fma.rn.f32 	%f48, %f41, 0f32A57060, %f47;
	mov.b32 	%r72, %f44;
	shl.b32 	%r73, %r72, 23;
	mov.b32 	%f49, %r73;
	ex2.approx.ftz.f32 	%f50, %f48;
	shr.u16 	%rs19, %rs5, 1;
	cvt.u32.u16 	%r74, %rs19;
	mul.wide.u32 	%rd42, %r74, 4;
	mul.wide.u32 	%rd43, %r69, 12;
	add.s64 	%rd44, %rd2, %rd43;
	add.s64 	%rd45, %rd44, %rd42;
	ld.global.nc.f32 	%f51, [%rd45];
	add.rn.f32 	%f52, %f51, %f51;
	add.rn.f32 	%f2, %f52, %f52;
	mul.rn.f32 	%f53, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r218, %f53;
	cvt.rn.f32.s32 	%f54, %r218;
	fma.rn.f32 	%f55, %f54, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f56, %f54, 0fB3A22168, %f55;
	fma.rn.f32 	%f143, %f54, 0fA7C234C5, %f56;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p2, %f4, 0f47CE4780;
	mov.f32 	%f141, 0f00000000;
	setp.neu.f32 	%p34, %f4, 0f7F800000;
	mov.u32 	%r214, %r218;
	mov.f32 	%f142, %f143;
	@%p2 bra 	$L__BB60_8;
	@%p34 bra 	$L__BB60_3;
	mul.rn.f32 	%f142, %f2, %f141;
	mov.b32 	%r214, 0;
	bra.uni 	$L__BB60_8;
$L__BB60_3:
	mov.b32 	%r4, %f2;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r76, %r5, 224;
	add.s32 	%r77, %r76, -128;
	shl.b32 	%r78, %r4, 8;
	or.b32  	%r82, %r78, -2147483648;
	shr.u32 	%r7, %r77, 5;
	mov.b32 	%r211, 0;
	mov.u64 	%rd123, 0;
	mov.u64 	%rd47, __cudart_i2opi_f;
$L__BB60_4:
	.pragma "nounroll";
	add.s64 	%rd48, %rd47, %rd123;
	ld.global.nc.u32 	%r81, [%rd48];
	// begin inline asm
	{
	mad.lo.cc.u32   %r79, %r81, %r82, %r211;
	madc.hi.u32     %r211, %r81, %r82,  0;
	}
	// end inline asm
	add.s64 	%rd49, %rd5, %rd123;
	st.local.u32 	[%rd49], %r79;
	add.s64 	%rd123, %rd123, 4;
	cvt.u32.u64 	%r84, %rd123;
	setp.ne.s32 	%p4, %r84, 24;
	@%p4 bra 	$L__BB60_4;
	st.local.u32 	[%rd5+24], %r211;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd50, %r7, 4;
	sub.s64 	%rd13, %rd5, %rd50;
	ld.local.u32 	%r212, [%rd13+24];
	ld.local.u32 	%r213, [%rd13+20];
	setp.eq.s32 	%p5, %r10, 0;
	@%p5 bra 	$L__BB60_7;
	shl.b32 	%r85, %r213, %r10;
	shl.b32 	%r86, %r212, %r10;
	mov.b32 	%r87, 32;
	sub.s32 	%r88, %r87, %r10;
	shr.u32 	%r89, %r213, %r88;
	add.s32 	%r212, %r89, %r86;
	ld.local.u32 	%r90, [%rd13+16];
	shr.u32 	%r91, %r90, %r88;
	add.s32 	%r213, %r91, %r85;
$L__BB60_7:
	shr.u32 	%r92, %r212, 30;
	shr.u32 	%r93, %r213, 30;
	shl.b32 	%r94, %r212, 2;
	or.b32  	%r95, %r94, %r93;
	shl.b32 	%r96, %r213, 2;
	bfe.u32 	%r97, %r212, 29, 1;
	add.s32 	%r98, %r97, %r92;
	neg.s32 	%r99, %r98;
	setp.lt.s32 	%p6, %r4, 0;
	selp.b32 	%r214, %r99, %r98, %p6;
	xor.b32  	%r100, %r95, %r4;
	bfe.s32 	%r101, %r212, 29, 1;
	xor.b32  	%r102, %r101, %r95;
	xor.b32  	%r103, %r101, %r96;
	cvt.u64.u32 	%rd51, %r102;
	shl.b64 	%rd52, %rd51, 32;
	cvt.u64.u32 	%rd53, %r103;
	or.b64  	%rd54, %rd52, %rd53;
	cvt.rn.f64.s64 	%fd1, %rd54;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f57, %fd2;
	neg.f32 	%f58, %f57;
	setp.lt.s32 	%p7, %r100, 0;
	selp.f32 	%f142, %f58, %f57, %p7;
$L__BB60_8:
	cvta.to.global.u64 	%rd1, %rd31;
	cvta.to.global.u64 	%rd3, %rd32;
	mul.wide.u16 	%r2, %rs2, 2;
	mul.rn.f32 	%f1, %f50, %f49;
	cvt.u64.u16 	%rd10, %rs19;
	add.s32 	%r105, %r214, 1;
	mul.rn.f32 	%f60, %f142, %f142;
	and.b32  	%r106, %r214, 1;
	setp.eq.b32 	%p9, %r106, 1;
	selp.f32 	%f61, %f142, 0f3F800000, %p9;
	fma.rn.f32 	%f62, %f60, %f61, 0f00000000;
	fma.rn.f32 	%f63, %f60, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f64, 0fB94D4153, %f63, %p9;
	selp.f32 	%f65, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f66, %f64, %f60, %f65;
	selp.f32 	%f67, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f68, %f66, %f60, %f67;
	fma.rn.f32 	%f69, %f68, %f62, %f61;
	and.b32  	%r107, %r105, 2;
	setp.eq.s32 	%p10, %r107, 0;
	sub.rn.f32 	%f71, %f141, %f69;
	selp.f32 	%f72, %f69, %f71, %p10;
	shl.b32 	%r108, %r1, 2;
	cvt.u64.u16 	%rd14, %rs3;
	mul.lo.s64 	%rd55, %rd9, 19200;
	add.s64 	%rd56, %rd4, %rd55;
	cvt.u32.u16 	%r109, %rs3;
	mul.wide.u32 	%rd57, %r109, 384;
	add.s64 	%rd58, %rd56, %rd57;
	mul.wide.u32 	%rd59, %r108, 24;
	add.s64 	%rd60, %rd58, %rd59;
	cvt.u32.u16 	%r110, %rs5;
	mul.wide.u32 	%rd61, %r110, 4;
	add.s64 	%rd16, %rd60, %rd61;
	ld.global.nc.f32 	%f73, [%rd16];
	mul.rn.f32 	%f8, %f73, %f72;
	@%p2 bra 	$L__BB60_16;
	@%p34 bra 	$L__BB60_11;
	mul.rn.f32 	%f143, %f2, %f141;
	mov.b32 	%r218, 0;
	bra.uni 	$L__BB60_16;
$L__BB60_11:
	mov.b32 	%r19, %f2;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r112, %r20, 224;
	add.s32 	%r113, %r112, -128;
	shl.b32 	%r114, %r19, 8;
	or.b32  	%r118, %r114, -2147483648;
	shr.u32 	%r22, %r113, 5;
	mov.b32 	%r215, 0;
	mov.u64 	%rd124, 0;
	mov.u64 	%rd63, __cudart_i2opi_f;
$L__BB60_12:
	.pragma "nounroll";
	add.s64 	%rd64, %rd63, %rd124;
	ld.global.nc.u32 	%r117, [%rd64];
	// begin inline asm
	{
	mad.lo.cc.u32   %r115, %r117, %r118, %r215;
	madc.hi.u32     %r215, %r117, %r118,  0;
	}
	// end inline asm
	add.s64 	%rd65, %rd5, %rd124;
	st.local.u32 	[%rd65], %r115;
	add.s64 	%rd124, %rd124, 4;
	cvt.u32.u64 	%r120, %rd124;
	setp.ne.s32 	%p12, %r120, 24;
	@%p12 bra 	$L__BB60_12;
	st.local.u32 	[%rd5+24], %r215;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd66, %r22, 4;
	sub.s64 	%rd19, %rd5, %rd66;
	ld.local.u32 	%r216, [%rd19+24];
	ld.local.u32 	%r217, [%rd19+20];
	setp.eq.s32 	%p13, %r25, 0;
	@%p13 bra 	$L__BB60_15;
	shl.b32 	%r121, %r217, %r25;
	shl.b32 	%r122, %r216, %r25;
	mov.b32 	%r123, 32;
	sub.s32 	%r124, %r123, %r25;
	shr.u32 	%r125, %r217, %r124;
	add.s32 	%r216, %r125, %r122;
	ld.local.u32 	%r126, [%rd19+16];
	shr.u32 	%r127, %r126, %r124;
	add.s32 	%r217, %r127, %r121;
$L__BB60_15:
	shr.u32 	%r128, %r216, 30;
	shr.u32 	%r129, %r217, 30;
	shl.b32 	%r130, %r216, 2;
	or.b32  	%r131, %r130, %r129;
	shl.b32 	%r132, %r217, 2;
	bfe.u32 	%r133, %r216, 29, 1;
	add.s32 	%r134, %r133, %r128;
	neg.s32 	%r135, %r134;
	setp.lt.s32 	%p14, %r19, 0;
	selp.b32 	%r218, %r135, %r134, %p14;
	xor.b32  	%r136, %r131, %r19;
	bfe.s32 	%r137, %r216, 29, 1;
	xor.b32  	%r138, %r137, %r131;
	xor.b32  	%r139, %r137, %r132;
	cvt.u64.u32 	%rd67, %r138;
	shl.b64 	%rd68, %rd67, 32;
	cvt.u64.u32 	%rd69, %r139;
	or.b64  	%rd70, %rd68, %rd69;
	cvt.rn.f64.s64 	%fd3, %rd70;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f74, %fd4;
	neg.f32 	%f75, %f74;
	setp.lt.s32 	%p15, %r136, 0;
	selp.f32 	%f143, %f75, %f74, %p15;
$L__BB60_16:
	cvt.u64.u32 	%rd15, %r108;
	mul.rn.f32 	%f77, %f143, %f143;
	and.b32  	%r141, %r218, 1;
	setp.eq.b32 	%p16, %r141, 1;
	selp.f32 	%f78, 0f3F800000, %f143, %p16;
	fma.rn.f32 	%f79, %f77, %f78, 0f00000000;
	fma.rn.f32 	%f80, %f77, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f81, %f80, 0fB94D4153, %p16;
	selp.f32 	%f82, 0f3D2AAABB, 0f3C0885E4, %p16;
	fma.rn.f32 	%f83, %f81, %f77, %f82;
	selp.f32 	%f84, 0fBEFFFFFF, 0fBE2AAAA8, %p16;
	fma.rn.f32 	%f85, %f83, %f77, %f84;
	fma.rn.f32 	%f86, %f85, %f79, %f78;
	and.b32  	%r142, %r218, 2;
	setp.eq.s32 	%p17, %r142, 0;
	sub.rn.f32 	%f88, %f141, %f86;
	selp.f32 	%f89, %f86, %f88, %p17;
	mul.lo.s64 	%rd71, %rd9, 9600;
	add.s64 	%rd72, %rd3, %rd71;
	mul.lo.s64 	%rd73, %rd14, 192;
	add.s64 	%rd74, %rd72, %rd73;
	mul.wide.u32 	%rd75, %r2, 24;
	add.s64 	%rd76, %rd74, %rd75;
	shl.b64 	%rd77, %rd10, 3;
	add.s64 	%rd78, %rd76, %rd77;
	ld.global.nc.f32 	%f90, [%rd78+4];
	mul.rn.f32 	%f91, %f90, %f89;
	add.rn.f32 	%f92, %f8, %f91;
	mul.rn.f32 	%f93, %f1, %f92;
	ld.global.nc.f32 	%f94, [%rd16+24];
	add.rn.f32 	%f95, %f94, %f93;
	neg.f32 	%f96, %f95;
	mul.lo.s64 	%rd79, %rd9, 4800;
	add.s64 	%rd80, %rd1, %rd79;
	mul.lo.s64 	%rd81, %rd14, 96;
	add.s64 	%rd82, %rd80, %rd81;
	mul.wide.u32 	%rd83, %r1, 24;
	add.s64 	%rd84, %rd82, %rd83;
	cvt.u32.u16 	%r144, %rs1;
	mul.wide.u32 	%rd85, %r144, 8;
	add.s64 	%rd22, %rd84, %rd85;
	st.global.f32 	[%rd22], %f96;
	mul.lo.s64 	%rd86, %rd9, 12;
	add.s64 	%rd87, %rd2, %rd86;
	mul.wide.u32 	%rd88, %r144, 4;
	add.s64 	%rd89, %rd87, %rd88;
	ld.global.nc.f32 	%f97, [%rd89];
	add.rn.f32 	%f98, %f97, %f97;
	add.rn.f32 	%f12, %f98, %f98;
	mul.rn.f32 	%f99, %f12, 0f3F22F983;
	cvt.rni.s32.f32 	%r226, %f99;
	cvt.rn.f32.s32 	%f100, %r226;
	fma.rn.f32 	%f101, %f100, 0fBFC90FDA, %f12;
	fma.rn.f32 	%f102, %f100, 0fB3A22168, %f101;
	fma.rn.f32 	%f145, %f100, 0fA7C234C5, %f102;
	abs.f32 	%f14, %f12;
	setp.ltu.f32 	%p18, %f14, 0f47CE4780;
	setp.neu.f32 	%p35, %f14, 0f7F800000;
	mov.u32 	%r222, %r226;
	mov.f32 	%f144, %f145;
	@%p18 bra 	$L__BB60_24;
	@%p35 bra 	$L__BB60_19;
	mul.rn.f32 	%f144, %f12, %f141;
	mov.b32 	%r222, 0;
	bra.uni 	$L__BB60_24;
$L__BB60_19:
	mov.b32 	%r35, %f12;
	shr.u32 	%r36, %r35, 23;
	and.b32  	%r146, %r36, 224;
	add.s32 	%r147, %r146, -128;
	shl.b32 	%r148, %r35, 8;
	or.b32  	%r152, %r148, -2147483648;
	shr.u32 	%r38, %r147, 5;
	mov.b32 	%r219, 0;
	mov.u64 	%rd125, 0;
	mov.u64 	%rd91, __cudart_i2opi_f;
$L__BB60_20:
	.pragma "nounroll";
	add.s64 	%rd92, %rd91, %rd125;
	ld.global.nc.u32 	%r151, [%rd92];
	// begin inline asm
	{
	mad.lo.cc.u32   %r149, %r151, %r152, %r219;
	madc.hi.u32     %r219, %r151, %r152,  0;
	}
	// end inline asm
	add.s64 	%rd93, %rd5, %rd125;
	st.local.u32 	[%rd93], %r149;
	add.s64 	%rd125, %rd125, 4;
	cvt.u32.u64 	%r154, %rd125;
	setp.ne.s32 	%p20, %r154, 24;
	@%p20 bra 	$L__BB60_20;
	st.local.u32 	[%rd5+24], %r219;
	and.b32  	%r41, %r36, 31;
	mul.wide.u32 	%rd94, %r38, 4;
	sub.s64 	%rd25, %rd5, %rd94;
	ld.local.u32 	%r220, [%rd25+24];
	ld.local.u32 	%r221, [%rd25+20];
	setp.eq.s32 	%p21, %r41, 0;
	@%p21 bra 	$L__BB60_23;
	shl.b32 	%r155, %r221, %r41;
	shl.b32 	%r156, %r220, %r41;
	mov.b32 	%r157, 32;
	sub.s32 	%r158, %r157, %r41;
	shr.u32 	%r159, %r221, %r158;
	add.s32 	%r220, %r159, %r156;
	ld.local.u32 	%r160, [%rd25+16];
	shr.u32 	%r161, %r160, %r158;
	add.s32 	%r221, %r161, %r155;
$L__BB60_23:
	shr.u32 	%r162, %r220, 30;
	shr.u32 	%r163, %r221, 30;
	shl.b32 	%r164, %r220, 2;
	or.b32  	%r165, %r164, %r163;
	shl.b32 	%r166, %r221, 2;
	bfe.u32 	%r167, %r220, 29, 1;
	add.s32 	%r168, %r167, %r162;
	neg.s32 	%r169, %r168;
	setp.lt.s32 	%p22, %r35, 0;
	selp.b32 	%r222, %r169, %r168, %p22;
	xor.b32  	%r170, %r165, %r35;
	bfe.s32 	%r171, %r220, 29, 1;
	xor.b32  	%r172, %r171, %r165;
	xor.b32  	%r173, %r171, %r166;
	cvt.u64.u32 	%rd95, %r172;
	shl.b64 	%rd96, %rd95, 32;
	cvt.u64.u32 	%rd97, %r173;
	or.b64  	%rd98, %rd96, %rd97;
	cvt.rn.f64.s64 	%fd5, %rd98;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f103, %fd6;
	neg.f32 	%f104, %f103;
	setp.lt.s32 	%p23, %r170, 0;
	selp.f32 	%f144, %f104, %f103, %p23;
$L__BB60_24:
	cvt.u64.u32 	%rd20, %r2;
	cvt.u64.u16 	%rd21, %rs1;
	mul.lo.s64 	%rd101, %rd14, 384;
	add.s64 	%rd102, %rd56, %rd101;
	mul.lo.s64 	%rd103, %rd15, 24;
	add.s64 	%rd104, %rd102, %rd103;
	cvt.u32.u16 	%r175, %rs4;
	mul.wide.u32 	%rd105, %r175, 4;
	add.s64 	%rd26, %rd104, %rd105;
	ld.global.nc.f32 	%f18, [%rd26];
	@%p18 bra 	$L__BB60_32;
	@%p35 bra 	$L__BB60_27;
	mul.rn.f32 	%f145, %f12, %f141;
	mov.b32 	%r226, 0;
	bra.uni 	$L__BB60_32;
$L__BB60_27:
	mov.b32 	%r50, %f12;
	shr.u32 	%r51, %r50, 23;
	and.b32  	%r177, %r51, 224;
	add.s32 	%r178, %r177, -128;
	shl.b32 	%r179, %r50, 8;
	or.b32  	%r183, %r179, -2147483648;
	shr.u32 	%r53, %r178, 5;
	mov.b32 	%r223, 0;
	mov.u64 	%rd126, 0;
	mov.u64 	%rd107, __cudart_i2opi_f;
$L__BB60_28:
	.pragma "nounroll";
	add.s64 	%rd108, %rd107, %rd126;
	ld.global.nc.u32 	%r182, [%rd108];
	// begin inline asm
	{
	mad.lo.cc.u32   %r180, %r182, %r183, %r223;
	madc.hi.u32     %r223, %r182, %r183,  0;
	}
	// end inline asm
	add.s64 	%rd109, %rd5, %rd126;
	st.local.u32 	[%rd109], %r180;
	add.s64 	%rd126, %rd126, 4;
	cvt.u32.u64 	%r185, %rd126;
	setp.ne.s32 	%p26, %r185, 24;
	@%p26 bra 	$L__BB60_28;
	st.local.u32 	[%rd5+24], %r223;
	and.b32  	%r56, %r51, 31;
	mul.wide.u32 	%rd110, %r53, 4;
	sub.s64 	%rd29, %rd5, %rd110;
	ld.local.u32 	%r224, [%rd29+24];
	ld.local.u32 	%r225, [%rd29+20];
	setp.eq.s32 	%p27, %r56, 0;
	@%p27 bra 	$L__BB60_31;
	shl.b32 	%r186, %r225, %r56;
	shl.b32 	%r187, %r224, %r56;
	mov.b32 	%r188, 32;
	sub.s32 	%r189, %r188, %r56;
	shr.u32 	%r190, %r225, %r189;
	add.s32 	%r224, %r190, %r187;
	ld.local.u32 	%r191, [%rd29+16];
	shr.u32 	%r192, %r191, %r189;
	add.s32 	%r225, %r192, %r186;
$L__BB60_31:
	shr.u32 	%r193, %r224, 30;
	shr.u32 	%r194, %r225, 30;
	shl.b32 	%r195, %r224, 2;
	or.b32  	%r196, %r195, %r194;
	shl.b32 	%r197, %r225, 2;
	bfe.u32 	%r198, %r224, 29, 1;
	add.s32 	%r199, %r198, %r193;
	neg.s32 	%r200, %r199;
	setp.lt.s32 	%p28, %r50, 0;
	selp.b32 	%r226, %r200, %r199, %p28;
	xor.b32  	%r201, %r196, %r50;
	bfe.s32 	%r202, %r224, 29, 1;
	xor.b32  	%r203, %r202, %r196;
	xor.b32  	%r204, %r202, %r197;
	cvt.u64.u32 	%rd111, %r203;
	shl.b64 	%rd112, %rd111, 32;
	cvt.u64.u32 	%rd113, %r204;
	or.b64  	%rd114, %rd112, %rd113;
	cvt.rn.f64.s64 	%fd7, %rd114;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f106, %fd8;
	neg.f32 	%f107, %f106;
	setp.lt.s32 	%p29, %r201, 0;
	selp.f32 	%f145, %f107, %f106, %p29;
$L__BB60_32:
	add.s32 	%r206, %r222, 1;
	and.b32  	%r207, %r206, 2;
	setp.eq.s32 	%p30, %r207, 0;
	and.b32  	%r208, %r222, 1;
	setp.eq.b32 	%p31, %r208, 1;
	mul.rn.f32 	%f109, %f144, %f144;
	fma.rn.f32 	%f110, %f109, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f111, 0fB94D4153, %f110, %p31;
	selp.f32 	%f112, 0f3C0885E4, 0f3D2AAABB, %p31;
	fma.rn.f32 	%f113, %f111, %f109, %f112;
	selp.f32 	%f114, 0fBE2AAAA8, 0fBEFFFFFF, %p31;
	fma.rn.f32 	%f115, %f113, %f109, %f114;
	selp.f32 	%f116, %f144, 0f3F800000, %p31;
	fma.rn.f32 	%f117, %f109, %f116, 0f00000000;
	fma.rn.f32 	%f118, %f115, %f117, %f116;
	sub.rn.f32 	%f120, %f141, %f118;
	selp.f32 	%f121, %f118, %f120, %p30;
	mul.rn.f32 	%f122, %f18, %f121;
	mul.rn.f32 	%f123, %f145, %f145;
	and.b32  	%r209, %r226, 1;
	setp.eq.b32 	%p32, %r209, 1;
	selp.f32 	%f124, 0f3F800000, %f145, %p32;
	fma.rn.f32 	%f125, %f123, %f124, 0f00000000;
	fma.rn.f32 	%f126, %f123, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f127, %f126, 0fB94D4153, %p32;
	selp.f32 	%f128, 0f3D2AAABB, 0f3C0885E4, %p32;
	fma.rn.f32 	%f129, %f127, %f123, %f128;
	selp.f32 	%f130, 0fBEFFFFFF, 0fBE2AAAA8, %p32;
	fma.rn.f32 	%f131, %f129, %f123, %f130;
	fma.rn.f32 	%f132, %f131, %f125, %f124;
	and.b32  	%r210, %r226, 2;
	setp.eq.s32 	%p33, %r210, 0;
	sub.rn.f32 	%f133, %f141, %f132;
	selp.f32 	%f134, %f132, %f133, %p33;
	mul.lo.s64 	%rd119, %rd20, 24;
	add.s64 	%rd120, %rd74, %rd119;
	shl.b64 	%rd121, %rd21, 3;
	add.s64 	%rd122, %rd120, %rd121;
	ld.global.nc.f32 	%f135, [%rd122];
	mul.rn.f32 	%f136, %f135, %f134;
	add.rn.f32 	%f137, %f122, %f136;
	mul.rn.f32 	%f138, %f1, %f137;
	ld.global.nc.f32 	%f139, [%rd26+24];
	add.rn.f32 	%f140, %f139, %f138;
	st.global.f32 	[%rd22+4], %f140;
	ret;

}
	// .globl	loop_add_fusion_297
.visible .entry loop_add_fusion_297(
	.param .u64 loop_add_fusion_297_param_0,
	.param .u64 loop_add_fusion_297_param_1,
	.param .u64 loop_add_fusion_297_param_2,
	.param .u64 loop_add_fusion_297_param_3,
	.param .u64 loop_add_fusion_297_param_4,
	.param .u64 loop_add_fusion_297_param_5
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot61[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<51>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<338>;
	.reg .f32 	%f<196>;
	.reg .b64 	%rd<144>;
	.reg .f64 	%fd<13>;

	mov.u64 	%SPL, __local_depot61;
	ld.param.u64 	%rd37, [loop_add_fusion_297_param_0];
	ld.param.u64 	%rd41, [loop_add_fusion_297_param_2];
	ld.param.u64 	%rd42, [loop_add_fusion_297_param_3];
	cvta.to.global.u64 	%rd43, %rd42;
	cvta.to.global.u64 	%rd44, %rd41;
	add.u64 	%rd5, %SPL, 0;
	mov.u32 	%r98, %ctaid.x;
	shl.b32 	%r99, %r98, 7;
	mov.u32 	%r100, %tid.x;
	or.b32  	%r1, %r99, %r100;
	mul.hi.u32 	%r101, %r1, 458129845;
	bfe.u32 	%r102, %r101, 7, 6;
	mul.hi.u32 	%r103, %r1, -1431655765;
	shr.u32 	%r104, %r103, 4;
	cvt.u16.u32 	%rs2, %r104;
	shr.u16 	%rs3, %rs2, 1;
	mul.hi.u16 	%rs4, %rs3, 5243;
	shr.u16 	%rs5, %rs4, 1;
	mul.lo.s16 	%rs6, %rs5, 50;
	shr.u32 	%r2, %r103, 2;
	mul.lo.s32 	%r105, %r2, 6;
	sub.s32 	%r3, %r1, %r105;
	mul.wide.u32 	%rd51, %r102, 4;
	add.s64 	%rd52, %rd43, %rd51;
	ld.global.nc.f32 	%f1, [%rd52];
	shr.u32 	%r106, %r3, 1;
	mul.wide.u32 	%rd53, %r106, 4;
	mul.wide.u32 	%rd54, %r102, 12;
	add.s64 	%rd55, %rd44, %rd54;
	add.s64 	%rd56, %rd55, %rd53;
	ld.global.nc.f32 	%f31, [%rd56];
	add.rn.f32 	%f32, %f31, %f31;
	add.rn.f32 	%f2, %f32, %f32;
	add.rn.f32 	%f3, %f2, %f2;
	mul.rn.f32 	%f33, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r329, %f33;
	cvt.rn.f32.s32 	%f34, %r329;
	fma.rn.f32 	%f35, %f34, 0fBFC90FDA, %f3;
	fma.rn.f32 	%f36, %f34, 0fB3A22168, %f35;
	fma.rn.f32 	%f193, %f34, 0fA7C234C5, %f36;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p1, %f5, 0f47CE4780;
	setp.neu.f32 	%p50, %f5, 0f7F800000;
	mov.f32 	%f189, 0f00000000;
	mov.u32 	%r317, %r329;
	mov.f32 	%f190, %f193;
	@%p1 bra 	$L__BB61_8;
	@%p50 bra 	$L__BB61_3;
	mul.rn.f32 	%f190, %f3, %f189;
	mov.b32 	%r317, 0;
	bra.uni 	$L__BB61_8;
$L__BB61_3:
	mov.b32 	%r314, 0;
	mov.b32 	%r5, %f3;
	shr.u32 	%r6, %r5, 23;
	and.b32  	%r108, %r6, 224;
	add.s32 	%r109, %r108, -128;
	shl.b32 	%r110, %r5, 8;
	or.b32  	%r114, %r110, -2147483648;
	shr.u32 	%r8, %r109, 5;
	mov.u64 	%rd138, 0;
	mov.u64 	%rd58, __cudart_i2opi_f;
$L__BB61_4:
	.pragma "nounroll";
	add.s64 	%rd59, %rd58, %rd138;
	ld.global.nc.u32 	%r113, [%rd59];
	// begin inline asm
	{
	mad.lo.cc.u32   %r111, %r113, %r114, %r314;
	madc.hi.u32     %r314, %r113, %r114,  0;
	}
	// end inline asm
	add.s64 	%rd60, %rd5, %rd138;
	st.local.u32 	[%rd60], %r111;
	add.s64 	%rd138, %rd138, 4;
	cvt.u32.u64 	%r116, %rd138;
	setp.ne.s32 	%p3, %r116, 24;
	@%p3 bra 	$L__BB61_4;
	st.local.u32 	[%rd5+24], %r314;
	and.b32  	%r11, %r6, 31;
	mul.wide.u32 	%rd61, %r8, 4;
	sub.s64 	%rd15, %rd5, %rd61;
	ld.local.u32 	%r315, [%rd15+24];
	ld.local.u32 	%r316, [%rd15+20];
	setp.eq.s32 	%p4, %r11, 0;
	@%p4 bra 	$L__BB61_7;
	shl.b32 	%r117, %r316, %r11;
	shl.b32 	%r118, %r315, %r11;
	mov.b32 	%r119, 32;
	sub.s32 	%r120, %r119, %r11;
	shr.u32 	%r121, %r316, %r120;
	add.s32 	%r315, %r121, %r118;
	ld.local.u32 	%r122, [%rd15+16];
	shr.u32 	%r123, %r122, %r120;
	add.s32 	%r316, %r123, %r117;
$L__BB61_7:
	shr.u32 	%r124, %r315, 30;
	shr.u32 	%r125, %r316, 30;
	shl.b32 	%r126, %r315, 2;
	or.b32  	%r127, %r126, %r125;
	shl.b32 	%r128, %r316, 2;
	bfe.u32 	%r129, %r315, 29, 1;
	add.s32 	%r130, %r129, %r124;
	neg.s32 	%r131, %r130;
	setp.lt.s32 	%p5, %r5, 0;
	selp.b32 	%r317, %r131, %r130, %p5;
	xor.b32  	%r132, %r127, %r5;
	bfe.s32 	%r133, %r315, 29, 1;
	xor.b32  	%r134, %r133, %r127;
	xor.b32  	%r135, %r133, %r128;
	cvt.u64.u32 	%rd62, %r134;
	shl.b64 	%rd63, %rd62, 32;
	cvt.u64.u32 	%rd64, %r135;
	or.b64  	%rd65, %rd63, %rd64;
	cvt.rn.f64.s64 	%fd1, %rd65;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f37, %fd2;
	neg.f32 	%f38, %f37;
	setp.lt.s32 	%p6, %r132, 0;
	selp.f32 	%f190, %f38, %f37, %p6;
$L__BB61_8:
	ld.param.u64 	%rd40, [loop_add_fusion_297_param_4];
	cvta.to.global.u64 	%rd4, %rd37;
	sub.s16 	%rs1, %rs2, %rs6;
	cvt.u64.u32 	%rd11, %r102;
	shl.b32 	%r137, %r2, 1;
	and.b32  	%r20, %r137, 6;
	mul.rn.f32 	%f40, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r337, %f40;
	cvt.rn.f32.s32 	%f41, %r337;
	fma.rn.f32 	%f42, %f41, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f43, %f41, 0fB3A22168, %f42;
	fma.rn.f32 	%f195, %f41, 0fA7C234C5, %f43;
	abs.f32 	%f10, %f2;
	setp.ltu.f32 	%p7, %f10, 0f47CE4780;
	setp.neu.f32 	%p49, %f10, 0f7F800000;
	mov.u32 	%r321, %r337;
	mov.f32 	%f191, %f195;
	@%p7 bra 	$L__BB61_16;
	@%p49 bra 	$L__BB61_11;
	mul.rn.f32 	%f191, %f2, %f189;
	mov.b32 	%r321, 0;
	bra.uni 	$L__BB61_16;
$L__BB61_11:
	mov.b32 	%r22, %f2;
	shr.u32 	%r23, %r22, 23;
	and.b32  	%r139, %r23, 224;
	add.s32 	%r140, %r139, -128;
	shl.b32 	%r141, %r22, 8;
	or.b32  	%r145, %r141, -2147483648;
	shr.u32 	%r25, %r140, 5;
	mov.b32 	%r318, 0;
	mov.u64 	%rd139, 0;
	mov.u64 	%rd67, __cudart_i2opi_f;
$L__BB61_12:
	.pragma "nounroll";
	add.s64 	%rd68, %rd67, %rd139;
	ld.global.nc.u32 	%r144, [%rd68];
	// begin inline asm
	{
	mad.lo.cc.u32   %r142, %r144, %r145, %r318;
	madc.hi.u32     %r318, %r144, %r145,  0;
	}
	// end inline asm
	add.s64 	%rd69, %rd5, %rd139;
	st.local.u32 	[%rd69], %r142;
	add.s64 	%rd139, %rd139, 4;
	cvt.u32.u64 	%r147, %rd139;
	setp.ne.s32 	%p9, %r147, 24;
	@%p9 bra 	$L__BB61_12;
	st.local.u32 	[%rd5+24], %r318;
	and.b32  	%r28, %r23, 31;
	mul.wide.u32 	%rd70, %r25, 4;
	sub.s64 	%rd18, %rd5, %rd70;
	ld.local.u32 	%r319, [%rd18+24];
	ld.local.u32 	%r320, [%rd18+20];
	setp.eq.s32 	%p10, %r28, 0;
	@%p10 bra 	$L__BB61_15;
	shl.b32 	%r148, %r320, %r28;
	shl.b32 	%r149, %r319, %r28;
	mov.b32 	%r150, 32;
	sub.s32 	%r151, %r150, %r28;
	shr.u32 	%r152, %r320, %r151;
	add.s32 	%r319, %r152, %r149;
	ld.local.u32 	%r153, [%rd18+16];
	shr.u32 	%r154, %r153, %r151;
	add.s32 	%r320, %r154, %r148;
$L__BB61_15:
	shr.u32 	%r155, %r319, 30;
	shr.u32 	%r156, %r320, 30;
	shl.b32 	%r157, %r319, 2;
	or.b32  	%r158, %r157, %r156;
	shl.b32 	%r159, %r320, 2;
	bfe.u32 	%r160, %r319, 29, 1;
	add.s32 	%r161, %r160, %r155;
	neg.s32 	%r162, %r161;
	setp.lt.s32 	%p11, %r22, 0;
	selp.b32 	%r321, %r162, %r161, %p11;
	xor.b32  	%r163, %r158, %r22;
	bfe.s32 	%r164, %r319, 29, 1;
	xor.b32  	%r165, %r164, %r158;
	xor.b32  	%r166, %r164, %r159;
	cvt.u64.u32 	%rd71, %r165;
	shl.b64 	%rd72, %rd71, 32;
	cvt.u64.u32 	%rd73, %r166;
	or.b64  	%rd74, %rd72, %rd73;
	cvt.rn.f64.s64 	%fd3, %rd74;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f44, %fd4;
	neg.f32 	%f45, %f44;
	setp.lt.s32 	%p12, %r163, 0;
	selp.f32 	%f191, %f45, %f44, %p12;
$L__BB61_16:
	ld.param.u64 	%rd39, [loop_add_fusion_297_param_1];
	cvta.to.global.u64 	%rd2, %rd40;
	cvt.u64.u32 	%rd12, %r106;
	shl.b32 	%r168, %r20, 1;
	cvt.u64.u16 	%rd19, %rs1;
	mul.lo.s64 	%rd75, %rd11, 19200;
	add.s64 	%rd76, %rd4, %rd75;
	cvt.u32.u16 	%r169, %rs1;
	mul.wide.u32 	%rd77, %r169, 384;
	add.s64 	%rd78, %rd76, %rd77;
	mul.wide.u32 	%rd79, %r168, 24;
	add.s64 	%rd80, %rd78, %rd79;
	mul.wide.u32 	%rd81, %r3, 4;
	add.s64 	%rd21, %rd80, %rd81;
	ld.global.nc.f32 	%f14, [%rd21];
	mov.u32 	%r325, %r337;
	mov.f32 	%f192, %f195;
	@%p7 bra 	$L__BB61_24;
	@%p49 bra 	$L__BB61_19;
	mul.rn.f32 	%f192, %f2, %f189;
	mov.b32 	%r325, 0;
	bra.uni 	$L__BB61_24;
$L__BB61_19:
	mov.b32 	%r37, %f2;
	shr.u32 	%r38, %r37, 23;
	and.b32  	%r171, %r38, 224;
	add.s32 	%r172, %r171, -128;
	shl.b32 	%r173, %r37, 8;
	or.b32  	%r177, %r173, -2147483648;
	shr.u32 	%r40, %r172, 5;
	mov.b32 	%r322, 0;
	mov.u64 	%rd140, 0;
	mov.u64 	%rd83, __cudart_i2opi_f;
$L__BB61_20:
	.pragma "nounroll";
	add.s64 	%rd84, %rd83, %rd140;
	ld.global.nc.u32 	%r176, [%rd84];
	// begin inline asm
	{
	mad.lo.cc.u32   %r174, %r176, %r177, %r322;
	madc.hi.u32     %r322, %r176, %r177,  0;
	}
	// end inline asm
	add.s64 	%rd85, %rd5, %rd140;
	st.local.u32 	[%rd85], %r174;
	add.s64 	%rd140, %rd140, 4;
	cvt.u32.u64 	%r179, %rd140;
	setp.ne.s32 	%p15, %r179, 24;
	@%p15 bra 	$L__BB61_20;
	st.local.u32 	[%rd5+24], %r322;
	and.b32  	%r43, %r38, 31;
	mul.wide.u32 	%rd86, %r40, 4;
	sub.s64 	%rd24, %rd5, %rd86;
	ld.local.u32 	%r323, [%rd24+24];
	ld.local.u32 	%r324, [%rd24+20];
	setp.eq.s32 	%p16, %r43, 0;
	@%p16 bra 	$L__BB61_23;
	shl.b32 	%r180, %r324, %r43;
	shl.b32 	%r181, %r323, %r43;
	mov.b32 	%r182, 32;
	sub.s32 	%r183, %r182, %r43;
	shr.u32 	%r184, %r324, %r183;
	add.s32 	%r323, %r184, %r181;
	ld.local.u32 	%r185, [%rd24+16];
	shr.u32 	%r186, %r185, %r183;
	add.s32 	%r324, %r186, %r180;
$L__BB61_23:
	shr.u32 	%r187, %r323, 30;
	shr.u32 	%r188, %r324, 30;
	shl.b32 	%r189, %r323, 2;
	or.b32  	%r190, %r189, %r188;
	shl.b32 	%r191, %r324, 2;
	bfe.u32 	%r192, %r323, 29, 1;
	add.s32 	%r193, %r192, %r187;
	neg.s32 	%r194, %r193;
	setp.lt.s32 	%p17, %r37, 0;
	selp.b32 	%r325, %r194, %r193, %p17;
	xor.b32  	%r195, %r190, %r37;
	bfe.s32 	%r196, %r323, 29, 1;
	xor.b32  	%r197, %r196, %r190;
	xor.b32  	%r198, %r196, %r191;
	cvt.u64.u32 	%rd87, %r197;
	shl.b64 	%rd88, %rd87, 32;
	cvt.u64.u32 	%rd89, %r198;
	or.b64  	%rd90, %rd88, %rd89;
	cvt.rn.f64.s64 	%fd5, %rd90;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f47, %fd6;
	neg.f32 	%f48, %f47;
	setp.lt.s32 	%p18, %r195, 0;
	selp.f32 	%f192, %f48, %f47, %p18;
$L__BB61_24:
	cvta.to.global.u64 	%rd3, %rd39;
	and.b32  	%r200, %r3, 1;
	mul.lo.s64 	%rd91, %rd11, 9600;
	add.s64 	%rd92, %rd2, %rd91;
	mul.lo.s64 	%rd93, %rd19, 192;
	add.s64 	%rd94, %rd92, %rd93;
	mul.wide.u32 	%rd95, %r20, 24;
	add.s64 	%rd96, %rd94, %rd95;
	shl.b64 	%rd97, %rd12, 3;
	add.s64 	%rd98, %rd96, %rd97;
	mul.wide.u32 	%rd99, %r200, 4;
	add.s64 	%rd25, %rd98, %rd99;
	ld.global.nc.f32 	%f18, [%rd25];
	ld.global.nc.f32 	%f19, [%rd21+24];
	@%p1 bra 	$L__BB61_32;
	@%p50 bra 	$L__BB61_27;
	mul.rn.f32 	%f193, %f3, %f189;
	mov.b32 	%r329, 0;
	bra.uni 	$L__BB61_32;
$L__BB61_27:
	mov.b32 	%r52, %f3;
	shr.u32 	%r53, %r52, 23;
	and.b32  	%r202, %r53, 224;
	add.s32 	%r203, %r202, -128;
	shl.b32 	%r204, %r52, 8;
	or.b32  	%r208, %r204, -2147483648;
	shr.u32 	%r55, %r203, 5;
	mov.b32 	%r326, 0;
	mov.u64 	%rd141, 0;
	mov.u64 	%rd101, __cudart_i2opi_f;
$L__BB61_28:
	.pragma "nounroll";
	add.s64 	%rd102, %rd101, %rd141;
	ld.global.nc.u32 	%r207, [%rd102];
	// begin inline asm
	{
	mad.lo.cc.u32   %r205, %r207, %r208, %r326;
	madc.hi.u32     %r326, %r207, %r208,  0;
	}
	// end inline asm
	add.s64 	%rd103, %rd5, %rd141;
	st.local.u32 	[%rd103], %r205;
	add.s64 	%rd141, %rd141, 4;
	cvt.u32.u64 	%r210, %rd141;
	setp.ne.s32 	%p21, %r210, 24;
	@%p21 bra 	$L__BB61_28;
	st.local.u32 	[%rd5+24], %r326;
	and.b32  	%r58, %r53, 31;
	mul.wide.u32 	%rd104, %r55, 4;
	sub.s64 	%rd28, %rd5, %rd104;
	ld.local.u32 	%r327, [%rd28+24];
	ld.local.u32 	%r328, [%rd28+20];
	setp.eq.s32 	%p22, %r58, 0;
	@%p22 bra 	$L__BB61_31;
	shl.b32 	%r211, %r328, %r58;
	shl.b32 	%r212, %r327, %r58;
	mov.b32 	%r213, 32;
	sub.s32 	%r214, %r213, %r58;
	shr.u32 	%r215, %r328, %r214;
	add.s32 	%r327, %r215, %r212;
	ld.local.u32 	%r216, [%rd28+16];
	shr.u32 	%r217, %r216, %r214;
	add.s32 	%r328, %r217, %r211;
$L__BB61_31:
	shr.u32 	%r218, %r327, 30;
	shr.u32 	%r219, %r328, 30;
	shl.b32 	%r220, %r327, 2;
	or.b32  	%r221, %r220, %r219;
	shl.b32 	%r222, %r328, 2;
	bfe.u32 	%r223, %r327, 29, 1;
	add.s32 	%r224, %r223, %r218;
	neg.s32 	%r225, %r224;
	setp.lt.s32 	%p23, %r52, 0;
	selp.b32 	%r329, %r225, %r224, %p23;
	xor.b32  	%r226, %r221, %r52;
	bfe.s32 	%r227, %r327, 29, 1;
	xor.b32  	%r228, %r227, %r221;
	xor.b32  	%r229, %r227, %r222;
	cvt.u64.u32 	%rd105, %r228;
	shl.b64 	%rd106, %rd105, 32;
	cvt.u64.u32 	%rd107, %r229;
	or.b64  	%rd108, %rd106, %rd107;
	cvt.rn.f64.s64 	%fd7, %rd108;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f50, %fd8;
	neg.f32 	%f51, %f50;
	setp.lt.s32 	%p24, %r226, 0;
	selp.f32 	%f193, %f51, %f50, %p24;
$L__BB61_32:
	ld.param.u64 	%rd38, [loop_add_fusion_297_param_5];
	cvt.u64.u32 	%rd20, %r3;
	mul.wide.u32 	%rd109, %r1, 4;
	add.s64 	%rd110, %rd3, %rd109;
	ld.global.nc.f32 	%f23, [%rd110];
	or.b32  	%r67, %r20, 1;
	mov.u32 	%r333, %r337;
	mov.f32 	%f194, %f195;
	@%p7 bra 	$L__BB61_40;
	@%p49 bra 	$L__BB61_35;
	mul.rn.f32 	%f194, %f2, %f189;
	mov.b32 	%r333, 0;
	bra.uni 	$L__BB61_40;
$L__BB61_35:
	mov.b32 	%r68, %f2;
	shr.u32 	%r69, %r68, 23;
	and.b32  	%r232, %r69, 224;
	add.s32 	%r233, %r232, -128;
	shl.b32 	%r234, %r68, 8;
	or.b32  	%r238, %r234, -2147483648;
	shr.u32 	%r71, %r233, 5;
	mov.b32 	%r330, 0;
	mov.u64 	%rd142, 0;
	mov.u64 	%rd112, __cudart_i2opi_f;
$L__BB61_36:
	.pragma "nounroll";
	add.s64 	%rd113, %rd112, %rd142;
	ld.global.nc.u32 	%r237, [%rd113];
	// begin inline asm
	{
	mad.lo.cc.u32   %r235, %r237, %r238, %r330;
	madc.hi.u32     %r330, %r237, %r238,  0;
	}
	// end inline asm
	add.s64 	%rd114, %rd5, %rd142;
	st.local.u32 	[%rd114], %r235;
	add.s64 	%rd142, %rd142, 4;
	cvt.u32.u64 	%r240, %rd142;
	setp.ne.s32 	%p27, %r240, 24;
	@%p27 bra 	$L__BB61_36;
	st.local.u32 	[%rd5+24], %r330;
	and.b32  	%r74, %r69, 31;
	mul.wide.u32 	%rd115, %r71, 4;
	sub.s64 	%rd32, %rd5, %rd115;
	ld.local.u32 	%r331, [%rd32+24];
	ld.local.u32 	%r332, [%rd32+20];
	setp.eq.s32 	%p28, %r74, 0;
	@%p28 bra 	$L__BB61_39;
	shl.b32 	%r241, %r332, %r74;
	shl.b32 	%r242, %r331, %r74;
	mov.b32 	%r243, 32;
	sub.s32 	%r244, %r243, %r74;
	shr.u32 	%r245, %r332, %r244;
	add.s32 	%r331, %r245, %r242;
	ld.local.u32 	%r246, [%rd32+16];
	shr.u32 	%r247, %r246, %r244;
	add.s32 	%r332, %r247, %r241;
$L__BB61_39:
	shr.u32 	%r248, %r331, 30;
	shr.u32 	%r249, %r332, 30;
	shl.b32 	%r250, %r331, 2;
	or.b32  	%r251, %r250, %r249;
	shl.b32 	%r252, %r332, 2;
	bfe.u32 	%r253, %r331, 29, 1;
	add.s32 	%r254, %r253, %r248;
	neg.s32 	%r255, %r254;
	setp.lt.s32 	%p29, %r68, 0;
	selp.b32 	%r333, %r255, %r254, %p29;
	xor.b32  	%r256, %r251, %r68;
	bfe.s32 	%r257, %r331, 29, 1;
	xor.b32  	%r258, %r257, %r251;
	xor.b32  	%r259, %r257, %r252;
	cvt.u64.u32 	%rd116, %r258;
	shl.b64 	%rd117, %rd116, 32;
	cvt.u64.u32 	%rd118, %r259;
	or.b64  	%rd119, %rd117, %rd118;
	cvt.rn.f64.s64 	%fd9, %rd119;
	mul.rn.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f53, %fd10;
	neg.f32 	%f54, %f53;
	setp.lt.s32 	%p30, %r256, 0;
	selp.f32 	%f194, %f54, %f53, %p30;
$L__BB61_40:
	cvta.to.global.u64 	%rd1, %rd38;
	cvt.u64.u32 	%rd29, %r1;
	shl.b32 	%r261, %r67, 1;
	mul.lo.s64 	%rd122, %rd19, 384;
	add.s64 	%rd123, %rd76, %rd122;
	mul.wide.u32 	%rd124, %r261, 24;
	add.s64 	%rd125, %rd123, %rd124;
	shl.b64 	%rd126, %rd20, 2;
	add.s64 	%rd33, %rd125, %rd126;
	ld.global.nc.f32 	%f27, [%rd33];
	@%p7 bra 	$L__BB61_48;
	@%p49 bra 	$L__BB61_43;
	mul.rn.f32 	%f195, %f2, %f189;
	mov.b32 	%r337, 0;
	bra.uni 	$L__BB61_48;
$L__BB61_43:
	mov.b32 	%r83, %f2;
	shr.u32 	%r84, %r83, 23;
	and.b32  	%r263, %r84, 224;
	add.s32 	%r264, %r263, -128;
	shl.b32 	%r265, %r83, 8;
	or.b32  	%r269, %r265, -2147483648;
	shr.u32 	%r86, %r264, 5;
	mov.b32 	%r334, 0;
	mov.u64 	%rd143, 0;
	mov.u64 	%rd128, __cudart_i2opi_f;
$L__BB61_44:
	.pragma "nounroll";
	add.s64 	%rd129, %rd128, %rd143;
	ld.global.nc.u32 	%r268, [%rd129];
	// begin inline asm
	{
	mad.lo.cc.u32   %r266, %r268, %r269, %r334;
	madc.hi.u32     %r334, %r268, %r269,  0;
	}
	// end inline asm
	add.s64 	%rd130, %rd5, %rd143;
	st.local.u32 	[%rd130], %r266;
	add.s64 	%rd143, %rd143, 4;
	cvt.u32.u64 	%r271, %rd143;
	setp.ne.s32 	%p33, %r271, 24;
	@%p33 bra 	$L__BB61_44;
	st.local.u32 	[%rd5+24], %r334;
	and.b32  	%r89, %r84, 31;
	mul.wide.u32 	%rd131, %r86, 4;
	sub.s64 	%rd36, %rd5, %rd131;
	ld.local.u32 	%r335, [%rd36+24];
	ld.local.u32 	%r336, [%rd36+20];
	setp.eq.s32 	%p34, %r89, 0;
	@%p34 bra 	$L__BB61_47;
	shl.b32 	%r272, %r336, %r89;
	shl.b32 	%r273, %r335, %r89;
	mov.b32 	%r274, 32;
	sub.s32 	%r275, %r274, %r89;
	shr.u32 	%r276, %r336, %r275;
	add.s32 	%r335, %r276, %r273;
	ld.local.u32 	%r277, [%rd36+16];
	shr.u32 	%r278, %r277, %r275;
	add.s32 	%r336, %r278, %r272;
$L__BB61_47:
	shr.u32 	%r279, %r335, 30;
	shr.u32 	%r280, %r336, 30;
	shl.b32 	%r281, %r335, 2;
	or.b32  	%r282, %r281, %r280;
	shl.b32 	%r283, %r336, 2;
	bfe.u32 	%r284, %r335, 29, 1;
	add.s32 	%r285, %r284, %r279;
	neg.s32 	%r286, %r285;
	setp.lt.s32 	%p35, %r83, 0;
	selp.b32 	%r337, %r286, %r285, %p35;
	xor.b32  	%r287, %r282, %r83;
	bfe.s32 	%r288, %r335, 29, 1;
	xor.b32  	%r289, %r288, %r282;
	xor.b32  	%r290, %r288, %r283;
	cvt.u64.u32 	%rd132, %r289;
	shl.b64 	%rd133, %rd132, 32;
	cvt.u64.u32 	%rd134, %r290;
	or.b64  	%rd135, %rd133, %rd134;
	cvt.rn.f64.s64 	%fd11, %rd135;
	mul.rn.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f56, %fd12;
	neg.f32 	%f57, %f56;
	setp.lt.s32 	%p36, %r287, 0;
	selp.f32 	%f195, %f57, %f56, %p36;
$L__BB61_48:
	add.s32 	%r292, %r333, 1;
	and.b32  	%r293, %r292, 2;
	setp.eq.s32 	%p37, %r293, 0;
	and.b32  	%r294, %r333, 1;
	setp.eq.b32 	%p38, %r294, 1;
	mul.rn.f32 	%f59, %f194, %f194;
	fma.rn.f32 	%f60, %f59, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f61, 0fB94D4153, %f60, %p38;
	selp.f32 	%f62, 0f3C0885E4, 0f3D2AAABB, %p38;
	fma.rn.f32 	%f63, %f61, %f59, %f62;
	selp.f32 	%f64, 0fBE2AAAA8, 0fBEFFFFFF, %p38;
	fma.rn.f32 	%f65, %f63, %f59, %f64;
	selp.f32 	%f66, %f194, 0f3F800000, %p38;
	fma.rn.f32 	%f67, %f59, %f66, 0f00000000;
	fma.rn.f32 	%f68, %f65, %f67, %f66;
	sub.rn.f32 	%f70, %f189, %f68;
	selp.f32 	%f71, %f68, %f70, %p37;
	mul.rn.f32 	%f72, %f27, %f71;
	fma.rn.f32 	%f73, %f1, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f74, %f73;
	mov.f32 	%f75, 0f4B400001;
	mov.f32 	%f76, 0f437C0000;
	fma.rm.f32 	%f77, %f74, %f76, %f75;
	add.rn.f32 	%f78, %f77, 0fCB40007F;
	neg.f32 	%f79, %f78;
	fma.rn.f32 	%f80, %f1, 0f3FB8AA3B, %f79;
	fma.rn.f32 	%f81, %f1, 0f32A57060, %f80;
	ex2.approx.ftz.f32 	%f82, %f81;
	mov.b32 	%r295, %f77;
	shl.b32 	%r296, %r295, 23;
	mov.b32 	%f83, %r296;
	mul.rn.f32 	%f84, %f82, %f83;
	neg.f32 	%f85, %f84;
	sub.rn.f32 	%f86, %f85, %f84;
	add.rn.f32 	%f87, %f86, %f86;
	add.rn.f32 	%f88, %f87, %f87;
	add.rn.f32 	%f89, %f88, %f88;
	add.rn.f32 	%f90, %f89, %f89;
	add.rn.f32 	%f91, %f90, %f90;
	add.rn.f32 	%f92, %f91, %f91;
	fma.rn.f32 	%f93, %f92, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f94, %f93;
	fma.rm.f32 	%f95, %f94, %f76, %f75;
	add.rn.f32 	%f96, %f95, 0fCB40007F;
	neg.f32 	%f97, %f96;
	fma.rn.f32 	%f98, %f92, 0f3FB8AA3B, %f97;
	fma.rn.f32 	%f99, %f92, 0f32A57060, %f98;
	ex2.approx.ftz.f32 	%f100, %f99;
	mov.b32 	%r297, %f95;
	shl.b32 	%r298, %r297, 23;
	mov.b32 	%f101, %r298;
	mul.rn.f32 	%f102, %f100, %f101;
	add.s32 	%r299, %r317, 1;
	and.b32  	%r300, %r299, 2;
	setp.eq.s32 	%p39, %r300, 0;
	and.b32  	%r301, %r317, 1;
	setp.eq.b32 	%p40, %r301, 1;
	mul.rn.f32 	%f103, %f190, %f190;
	fma.rn.f32 	%f104, %f103, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f105, 0fB94D4153, %f104, %p40;
	selp.f32 	%f106, 0f3C0885E4, 0f3D2AAABB, %p40;
	fma.rn.f32 	%f107, %f105, %f103, %f106;
	selp.f32 	%f108, 0fBE2AAAA8, 0fBEFFFFFF, %p40;
	fma.rn.f32 	%f109, %f107, %f103, %f108;
	selp.f32 	%f110, %f190, 0f3F800000, %p40;
	fma.rn.f32 	%f111, %f103, %f110, 0f00000000;
	fma.rn.f32 	%f112, %f109, %f111, %f110;
	sub.rn.f32 	%f113, %f189, %f112;
	selp.f32 	%f114, %f112, %f113, %p39;
	fma.rn.f32 	%f115, %f91, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f116, %f115;
	fma.rm.f32 	%f117, %f116, %f76, %f75;
	add.rn.f32 	%f118, %f117, 0fCB40007F;
	neg.f32 	%f119, %f118;
	fma.rn.f32 	%f120, %f91, 0f3FB8AA3B, %f119;
	fma.rn.f32 	%f121, %f91, 0f32A57060, %f120;
	ex2.approx.ftz.f32 	%f122, %f121;
	mov.b32 	%r302, %f117;
	shl.b32 	%r303, %r302, 23;
	mov.b32 	%f123, %r303;
	mul.rn.f32 	%f124, %f122, %f123;
	add.s32 	%r304, %r321, 1;
	and.b32  	%r305, %r304, 2;
	setp.eq.s32 	%p41, %r305, 0;
	and.b32  	%r306, %r321, 1;
	setp.eq.b32 	%p42, %r306, 1;
	mul.rn.f32 	%f125, %f191, %f191;
	fma.rn.f32 	%f126, %f125, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f127, 0fB94D4153, %f126, %p42;
	selp.f32 	%f128, 0f3C0885E4, 0f3D2AAABB, %p42;
	fma.rn.f32 	%f129, %f127, %f125, %f128;
	selp.f32 	%f130, 0fBE2AAAA8, 0fBEFFFFFF, %p42;
	fma.rn.f32 	%f131, %f129, %f125, %f130;
	selp.f32 	%f132, %f191, 0f3F800000, %p42;
	fma.rn.f32 	%f133, %f125, %f132, 0f00000000;
	fma.rn.f32 	%f134, %f131, %f133, %f132;
	sub.rn.f32 	%f135, %f189, %f134;
	selp.f32 	%f136, %f134, %f135, %p41;
	mul.rn.f32 	%f137, %f14, %f136;
	and.b32  	%r307, %r325, 2;
	setp.eq.s32 	%p43, %r307, 0;
	and.b32  	%r308, %r325, 1;
	setp.eq.b32 	%p44, %r308, 1;
	mul.rn.f32 	%f138, %f192, %f192;
	fma.rn.f32 	%f139, %f138, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f140, %f139, 0fB94D4153, %p44;
	selp.f32 	%f141, 0f3D2AAABB, 0f3C0885E4, %p44;
	fma.rn.f32 	%f142, %f140, %f138, %f141;
	selp.f32 	%f143, 0fBEFFFFFF, 0fBE2AAAA8, %p44;
	fma.rn.f32 	%f144, %f142, %f138, %f143;
	selp.f32 	%f145, 0f3F800000, %f192, %p44;
	fma.rn.f32 	%f146, %f138, %f145, 0f00000000;
	fma.rn.f32 	%f147, %f144, %f146, %f145;
	sub.rn.f32 	%f148, %f189, %f147;
	selp.f32 	%f149, %f147, %f148, %p43;
	mul.rn.f32 	%f150, %f18, %f149;
	add.rn.f32 	%f151, %f137, %f150;
	mul.rn.f32 	%f152, %f151, %f124;
	add.rn.f32 	%f153, %f19, %f152;
	mul.rn.f32 	%f154, %f114, %f153;
	and.b32  	%r309, %r329, 2;
	setp.eq.s32 	%p45, %r309, 0;
	and.b32  	%r310, %r329, 1;
	setp.eq.b32 	%p46, %r310, 1;
	mul.rn.f32 	%f155, %f193, %f193;
	fma.rn.f32 	%f156, %f155, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f157, %f156, 0fB94D4153, %p46;
	selp.f32 	%f158, 0f3D2AAABB, 0f3C0885E4, %p46;
	fma.rn.f32 	%f159, %f157, %f155, %f158;
	selp.f32 	%f160, 0fBEFFFFFF, 0fBE2AAAA8, %p46;
	fma.rn.f32 	%f161, %f159, %f155, %f160;
	selp.f32 	%f162, 0f3F800000, %f193, %p46;
	fma.rn.f32 	%f163, %f155, %f162, 0f00000000;
	fma.rn.f32 	%f164, %f161, %f163, %f162;
	sub.rn.f32 	%f165, %f189, %f164;
	selp.f32 	%f166, %f164, %f165, %p45;
	mul.rn.f32 	%f167, %f23, %f166;
	add.rn.f32 	%f168, %f167, %f154;
	mul.rn.f32 	%f169, %f102, %f168;
	mul.rn.f32 	%f170, %f195, %f195;
	and.b32  	%r311, %r337, 1;
	setp.eq.b32 	%p47, %r311, 1;
	selp.f32 	%f171, 0f3F800000, %f195, %p47;
	fma.rn.f32 	%f172, %f170, %f171, 0f00000000;
	fma.rn.f32 	%f173, %f170, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f174, %f173, 0fB94D4153, %p47;
	selp.f32 	%f175, 0f3D2AAABB, 0f3C0885E4, %p47;
	fma.rn.f32 	%f176, %f174, %f170, %f175;
	selp.f32 	%f177, 0fBEFFFFFF, 0fBE2AAAA8, %p47;
	fma.rn.f32 	%f178, %f176, %f170, %f177;
	fma.rn.f32 	%f179, %f178, %f172, %f171;
	and.b32  	%r312, %r337, 2;
	setp.eq.s32 	%p48, %r312, 0;
	sub.rn.f32 	%f180, %f189, %f179;
	selp.f32 	%f181, %f179, %f180, %p48;
	ld.global.nc.f32 	%f182, [%rd25+24];
	mul.rn.f32 	%f183, %f182, %f181;
	add.rn.f32 	%f184, %f72, %f183;
	mul.rn.f32 	%f185, %f184, %f124;
	ld.global.nc.f32 	%f186, [%rd33+24];
	add.rn.f32 	%f187, %f186, %f185;
	add.rn.f32 	%f188, %f187, %f169;
	shl.b64 	%rd136, %rd29, 2;
	add.s64 	%rd137, %rd1, %rd136;
	st.global.f32 	[%rd137], %f188;
	ret;

}
	// .globl	input_concatenate_fusion_188
.visible .entry input_concatenate_fusion_188(
	.param .u64 input_concatenate_fusion_188_param_0,
	.param .u64 input_concatenate_fusion_188_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<20>;
	.reg .b32 	%r<12>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<23>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_188_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_188_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs3, 1;
	shr.u16 	%rs7, %rs2, 2;
	mul.hi.u16 	%rs8, %rs7, 5243;
	shr.u16 	%rs9, %rs8, 2;
	mul.lo.s16 	%rs10, %rs9, 50;
	sub.s16 	%rs11, %rs7, %rs10;
	shr.u16 	%rs12, %rs1, 2;
	mul.hi.u16 	%rs13, %rs12, 27963;
	shr.u16 	%rs14, %rs13, 5;
	and.b16  	%rs15, %rs14, 63;
	shl.b16 	%rs16, %rs5, 1;
	or.b16  	%rs17, %rs16, 1;
	setp.gt.u16 	%p1, %rs5, 1;
	shl.b16 	%rs18, %rs6, 1;
	selp.b16 	%rs19, 5, %rs17, %p1;
	cvt.u32.u16 	%r5, %rs19;
	mul.wide.u32 	%rd5, %r5, 4;
	cvt.u32.u16 	%r6, %rs11;
	mul.wide.u32 	%rd6, %r6, 96;
	cvt.u32.u16 	%r7, %rs15;
	mul.wide.u32 	%rd7, %r7, 4800;
	add.s64 	%rd8, %rd4, %rd7;
	add.s64 	%rd9, %rd8, %rd6;
	cvt.u32.u16 	%r8, %rs18;
	mul.wide.u32 	%rd10, %r8, 24;
	add.s64 	%rd11, %rd9, %rd10;
	add.s64 	%rd12, %rd11, %rd5;
	ld.global.nc.f32 	%f1, [%rd12];
	neg.f32 	%f2, %f1;
	mul.wide.u32 	%rd13, %r6, 48;
	mul.wide.u32 	%rd14, %r7, 2400;
	add.s64 	%rd15, %rd3, %rd14;
	add.s64 	%rd16, %rd15, %rd13;
	cvt.u32.u16 	%r9, %rs6;
	mul.wide.u32 	%rd17, %r9, 24;
	add.s64 	%rd18, %rd16, %rd17;
	cvt.u32.u16 	%r10, %rs5;
	mul.wide.u32 	%rd19, %r10, 8;
	add.s64 	%rd20, %rd18, %rd19;
	cvt.u32.u16 	%r11, %rs16;
	mul.wide.u32 	%rd21, %r11, 4;
	add.s64 	%rd22, %rd11, %rd21;
	ld.global.nc.f32 	%f3, [%rd22];
	st.global.v2.f32 	[%rd20], {%f2, %f3};
	ret;

}
	// .globl	loop_add_fusion_298
.visible .entry loop_add_fusion_298(
	.param .u64 loop_add_fusion_298_param_0,
	.param .u64 loop_add_fusion_298_param_1,
	.param .u64 loop_add_fusion_298_param_2,
	.param .u64 loop_add_fusion_298_param_3,
	.param .u64 loop_add_fusion_298_param_4
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot63[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<104>;
	.reg .b16 	%rs<16>;
	.reg .b32 	%r<653>;
	.reg .f32 	%f<413>;
	.reg .b64 	%rd<268>;
	.reg .f64 	%fd<25>;

	mov.u64 	%SPL, __local_depot63;
	ld.param.u64 	%rd66, [loop_add_fusion_298_param_0];
	ld.param.u64 	%rd67, [loop_add_fusion_298_param_4];
	ld.param.u64 	%rd68, [loop_add_fusion_298_param_1];
	ld.param.u64 	%rd69, [loop_add_fusion_298_param_3];
	cvta.to.global.u64 	%rd2, %rd69;
	ld.param.u64 	%rd70, [loop_add_fusion_298_param_2];
	cvta.to.global.u64 	%rd3, %rd70;
	cvta.to.global.u64 	%rd4, %rd68;
	cvta.to.global.u64 	%rd5, %rd66;
	add.u64 	%rd6, %SPL, 0;
	mov.u32 	%r190, %ctaid.x;
	mov.u32 	%r191, %tid.x;
	shl.b32 	%r192, %r190, 7;
	or.b32  	%r1, %r192, %r191;
	cvt.u16.u32 	%rs5, %r1;
	mul.hi.u16 	%rs6, %rs5, -21845;
	shr.u16 	%rs7, %rs6, 2;
	mul.lo.s16 	%rs8, %rs7, 6;
	sub.s16 	%rs1, %rs5, %rs8;
	cvt.u32.u16 	%r2, %rs1;
	and.b16  	%rs2, %rs7, 1;
	shr.u16 	%rs9, %rs6, 3;
	mul.hi.u16 	%rs10, %rs9, 5243;
	shr.u16 	%rs11, %rs10, 2;
	mul.lo.s16 	%rs12, %rs11, 50;
	sub.s16 	%rs3, %rs9, %rs12;
	shr.u16 	%rs13, %rs5, 3;
	mul.hi.u16 	%rs14, %rs13, 6991;
	shr.u16 	%rs15, %rs14, 3;
	and.b16  	%rs4, %rs15, 63;
	setp.eq.s16 	%p1, %rs2, 0;
	mov.f32 	%f399, 0f00000000;
	mov.f32 	%f398, %f399;
	@%p1 bra 	$L__BB63_3;
	bra.uni 	$L__BB63_1;
$L__BB63_3:
	cvt.u64.u16 	%rd18, %rs4;
	cvt.u32.u16 	%r193, %rs4;
	mul.wide.u32 	%rd83, %r193, 4;
	add.s64 	%rd84, %rd3, %rd83;
	ld.global.nc.f32 	%f70, [%rd84];
	fma.rn.f32 	%f71, %f70, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f72, %f71;
	mov.f32 	%f73, 0f4B400001;
	mov.f32 	%f74, 0f437C0000;
	fma.rm.f32 	%f75, %f72, %f74, %f73;
	add.rn.f32 	%f76, %f75, 0fCB40007F;
	neg.f32 	%f77, %f76;
	fma.rn.f32 	%f78, %f70, 0f3FB8AA3B, %f77;
	fma.rn.f32 	%f79, %f70, 0f32A57060, %f78;
	mov.b32 	%r194, %f75;
	shl.b32 	%r195, %r194, 23;
	mov.b32 	%f80, %r195;
	ex2.approx.ftz.f32 	%f81, %f79;
	mul.rn.f32 	%f82, %f81, %f80;
	neg.f32 	%f83, %f82;
	sub.rn.f32 	%f84, %f83, %f82;
	add.rn.f32 	%f85, %f84, %f84;
	add.rn.f32 	%f86, %f85, %f85;
	add.rn.f32 	%f87, %f86, %f86;
	add.rn.f32 	%f88, %f87, %f87;
	add.rn.f32 	%f89, %f88, %f88;
	add.rn.f32 	%f90, %f89, %f89;
	add.rn.f32 	%f91, %f90, %f90;
	fma.rn.f32 	%f92, %f91, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f93, %f92;
	fma.rm.f32 	%f94, %f93, %f74, %f73;
	add.rn.f32 	%f95, %f94, 0fCB40007F;
	neg.f32 	%f96, %f95;
	fma.rn.f32 	%f97, %f91, 0f3FB8AA3B, %f96;
	fma.rn.f32 	%f98, %f91, 0f32A57060, %f97;
	mov.b32 	%r196, %f94;
	shl.b32 	%r197, %r196, 23;
	mov.b32 	%f99, %r197;
	ex2.approx.ftz.f32 	%f100, %f98;
	shr.u32 	%r198, %r2, 1;
	mul.wide.u32 	%rd85, %r193, 12;
	add.s64 	%rd86, %rd2, %rd85;
	mul.wide.u32 	%rd87, %r198, 4;
	add.s64 	%rd88, %rd86, %rd87;
	ld.global.nc.f32 	%f101, [%rd88];
	add.rn.f32 	%f102, %f101, %f101;
	add.rn.f32 	%f103, %f102, %f102;
	add.rn.f32 	%f104, %f103, %f103;
	add.rn.f32 	%f4, %f104, %f104;
	mul.rn.f32 	%f105, %f4, 0f3F22F983;
	cvt.rni.s32.f32 	%r612, %f105;
	cvt.rn.f32.s32 	%f106, %r612;
	fma.rn.f32 	%f107, %f106, 0fBFC90FDA, %f4;
	fma.rn.f32 	%f108, %f106, 0fB3A22168, %f107;
	fma.rn.f32 	%f401, %f106, 0fA7C234C5, %f108;
	abs.f32 	%f6, %f4;
	setp.ltu.f32 	%p2, %f6, 0f47CE4780;
	setp.neu.f32 	%p103, %f6, 0f7F800000;
	mov.u32 	%r608, %r612;
	mov.f32 	%f400, %f401;
	@%p2 bra 	$L__BB63_11;
	@%p103 bra 	$L__BB63_6;
	mov.f32 	%f111, 0f00000000;
	mul.rn.f32 	%f400, %f4, %f111;
	mov.b32 	%r608, 0;
	bra.uni 	$L__BB63_11;
$L__BB63_6:
	mov.b32 	%r4, %f4;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r200, %r5, 224;
	add.s32 	%r201, %r200, -128;
	shl.b32 	%r202, %r4, 8;
	or.b32  	%r206, %r202, -2147483648;
	shr.u32 	%r7, %r201, 5;
	mov.b32 	%r605, 0;
	mov.u64 	%rd256, 0;
	mov.u64 	%rd90, __cudart_i2opi_f;
$L__BB63_7:
	.pragma "nounroll";
	add.s64 	%rd91, %rd90, %rd256;
	ld.global.nc.u32 	%r205, [%rd91];
	// begin inline asm
	{
	mad.lo.cc.u32   %r203, %r205, %r206, %r605;
	madc.hi.u32     %r605, %r205, %r206,  0;
	}
	// end inline asm
	add.s64 	%rd92, %rd6, %rd256;
	st.local.u32 	[%rd92], %r203;
	add.s64 	%rd256, %rd256, 4;
	cvt.u32.u64 	%r208, %rd256;
	setp.ne.s32 	%p4, %r208, 24;
	@%p4 bra 	$L__BB63_7;
	st.local.u32 	[%rd6+24], %r605;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd93, %r7, 4;
	sub.s64 	%rd22, %rd6, %rd93;
	ld.local.u32 	%r606, [%rd22+24];
	ld.local.u32 	%r607, [%rd22+20];
	setp.eq.s32 	%p5, %r10, 0;
	@%p5 bra 	$L__BB63_10;
	shl.b32 	%r209, %r607, %r10;
	shl.b32 	%r210, %r606, %r10;
	mov.b32 	%r211, 32;
	sub.s32 	%r212, %r211, %r10;
	shr.u32 	%r213, %r607, %r212;
	add.s32 	%r606, %r213, %r210;
	ld.local.u32 	%r214, [%rd22+16];
	shr.u32 	%r215, %r214, %r212;
	add.s32 	%r607, %r215, %r209;
$L__BB63_10:
	shr.u32 	%r216, %r606, 30;
	shr.u32 	%r217, %r607, 30;
	shl.b32 	%r218, %r606, 2;
	or.b32  	%r219, %r218, %r217;
	shl.b32 	%r220, %r607, 2;
	bfe.u32 	%r221, %r606, 29, 1;
	add.s32 	%r222, %r221, %r216;
	neg.s32 	%r223, %r222;
	setp.lt.s32 	%p6, %r4, 0;
	selp.b32 	%r608, %r223, %r222, %p6;
	xor.b32  	%r224, %r219, %r4;
	bfe.s32 	%r225, %r606, 29, 1;
	xor.b32  	%r226, %r225, %r219;
	xor.b32  	%r227, %r225, %r220;
	cvt.u64.u32 	%rd94, %r226;
	shl.b64 	%rd95, %rd94, 32;
	cvt.u64.u32 	%rd96, %r227;
	or.b64  	%rd97, %rd95, %rd96;
	cvt.rn.f64.s64 	%fd1, %rd97;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f109, %fd2;
	neg.f32 	%f110, %f109;
	setp.lt.s32 	%p7, %r224, 0;
	selp.f32 	%f400, %f110, %f109, %p7;
$L__BB63_11:
	mul.rn.f32 	%f3, %f100, %f99;
	cvt.u64.u32 	%rd19, %r198;
	add.s32 	%r229, %r608, 1;
	mul.rn.f32 	%f112, %f400, %f400;
	and.b32  	%r230, %r608, 1;
	setp.eq.b32 	%p9, %r230, 1;
	selp.f32 	%f113, %f400, 0f3F800000, %p9;
	fma.rn.f32 	%f114, %f112, %f113, 0f00000000;
	fma.rn.f32 	%f115, %f112, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f116, 0fB94D4153, %f115, %p9;
	selp.f32 	%f117, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f118, %f116, %f112, %f117;
	selp.f32 	%f119, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f120, %f118, %f112, %f119;
	fma.rn.f32 	%f121, %f120, %f114, %f113;
	and.b32  	%r231, %r229, 2;
	setp.eq.s32 	%p10, %r231, 0;
	mov.f32 	%f122, 0f00000000;
	sub.rn.f32 	%f123, %f122, %f121;
	selp.f32 	%f124, %f121, %f123, %p10;
	cvt.u64.u16 	%rd23, %rs3;
	mul.lo.s64 	%rd98, %rd18, 4800;
	add.s64 	%rd99, %rd5, %rd98;
	cvt.u32.u16 	%r232, %rs3;
	mul.wide.u32 	%rd100, %r232, 96;
	add.s64 	%rd101, %rd99, %rd100;
	mul.wide.u32 	%rd102, %r2, 4;
	add.s64 	%rd24, %rd101, %rd102;
	ld.global.nc.f32 	%f125, [%rd24];
	mul.rn.f32 	%f10, %f125, %f124;
	@%p2 bra 	$L__BB63_19;
	@%p103 bra 	$L__BB63_14;
	mul.rn.f32 	%f401, %f4, %f122;
	mov.b32 	%r612, 0;
	bra.uni 	$L__BB63_19;
$L__BB63_14:
	mov.b32 	%r19, %f4;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r235, %r20, 224;
	add.s32 	%r236, %r235, -128;
	shl.b32 	%r237, %r19, 8;
	or.b32  	%r241, %r237, -2147483648;
	shr.u32 	%r22, %r236, 5;
	mov.b32 	%r609, 0;
	mov.u64 	%rd257, 0;
	mov.u64 	%rd104, __cudart_i2opi_f;
$L__BB63_15:
	.pragma "nounroll";
	add.s64 	%rd105, %rd104, %rd257;
	ld.global.nc.u32 	%r240, [%rd105];
	// begin inline asm
	{
	mad.lo.cc.u32   %r238, %r240, %r241, %r609;
	madc.hi.u32     %r609, %r240, %r241,  0;
	}
	// end inline asm
	add.s64 	%rd106, %rd6, %rd257;
	st.local.u32 	[%rd106], %r238;
	add.s64 	%rd257, %rd257, 4;
	cvt.u32.u64 	%r243, %rd257;
	setp.ne.s32 	%p12, %r243, 24;
	@%p12 bra 	$L__BB63_15;
	st.local.u32 	[%rd6+24], %r609;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd107, %r22, 4;
	sub.s64 	%rd27, %rd6, %rd107;
	ld.local.u32 	%r610, [%rd27+24];
	ld.local.u32 	%r611, [%rd27+20];
	setp.eq.s32 	%p13, %r25, 0;
	@%p13 bra 	$L__BB63_18;
	shl.b32 	%r244, %r611, %r25;
	shl.b32 	%r245, %r610, %r25;
	mov.b32 	%r246, 32;
	sub.s32 	%r247, %r246, %r25;
	shr.u32 	%r248, %r611, %r247;
	add.s32 	%r610, %r248, %r245;
	ld.local.u32 	%r249, [%rd27+16];
	shr.u32 	%r250, %r249, %r247;
	add.s32 	%r611, %r250, %r244;
$L__BB63_18:
	shr.u32 	%r251, %r610, 30;
	shr.u32 	%r252, %r611, 30;
	shl.b32 	%r253, %r610, 2;
	or.b32  	%r254, %r253, %r252;
	shl.b32 	%r255, %r611, 2;
	bfe.u32 	%r256, %r610, 29, 1;
	add.s32 	%r257, %r256, %r251;
	neg.s32 	%r258, %r257;
	setp.lt.s32 	%p14, %r19, 0;
	selp.b32 	%r612, %r258, %r257, %p14;
	xor.b32  	%r259, %r254, %r19;
	bfe.s32 	%r260, %r610, 29, 1;
	xor.b32  	%r261, %r260, %r254;
	xor.b32  	%r262, %r260, %r255;
	cvt.u64.u32 	%rd108, %r261;
	shl.b64 	%rd109, %rd108, 32;
	cvt.u64.u32 	%rd110, %r262;
	or.b64  	%rd111, %rd109, %rd110;
	cvt.rn.f64.s64 	%fd3, %rd111;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f126, %fd4;
	neg.f32 	%f127, %f126;
	setp.lt.s32 	%p15, %r259, 0;
	selp.f32 	%f401, %f127, %f126, %p15;
$L__BB63_19:
	mul.rn.f32 	%f129, %f401, %f401;
	and.b32  	%r264, %r612, 1;
	setp.eq.b32 	%p16, %r264, 1;
	selp.f32 	%f130, 0f3F800000, %f401, %p16;
	fma.rn.f32 	%f131, %f129, %f130, 0f00000000;
	fma.rn.f32 	%f132, %f129, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f133, %f132, 0fB94D4153, %p16;
	selp.f32 	%f134, 0f3D2AAABB, 0f3C0885E4, %p16;
	fma.rn.f32 	%f135, %f133, %f129, %f134;
	selp.f32 	%f136, 0fBEFFFFFF, 0fBE2AAAA8, %p16;
	fma.rn.f32 	%f137, %f135, %f129, %f136;
	fma.rn.f32 	%f138, %f137, %f131, %f130;
	and.b32  	%r265, %r612, 2;
	setp.eq.s32 	%p17, %r265, 0;
	sub.rn.f32 	%f140, %f122, %f138;
	selp.f32 	%f141, %f138, %f140, %p17;
	and.b32  	%r266, %r2, 1;
	mul.lo.s64 	%rd112, %rd18, 2400;
	add.s64 	%rd113, %rd4, %rd112;
	mul.lo.s64 	%rd114, %rd23, 48;
	add.s64 	%rd115, %rd113, %rd114;
	shl.b64 	%rd116, %rd19, 3;
	add.s64 	%rd117, %rd115, %rd116;
	mul.wide.u32 	%rd118, %r266, 4;
	add.s64 	%rd119, %rd117, %rd118;
	ld.global.nc.f32 	%f142, [%rd119];
	mul.rn.f32 	%f143, %f142, %f141;
	add.rn.f32 	%f144, %f10, %f143;
	mul.rn.f32 	%f145, %f3, %f144;
	ld.global.nc.f32 	%f146, [%rd24+24];
	add.rn.f32 	%f398, %f146, %f145;
$L__BB63_1:
	cvta.to.global.u64 	%rd1, %rd67;
	setp.ne.s16 	%p18, %rs2, 0;
	@%p18 bra 	$L__BB63_20;
	bra.uni 	$L__BB63_2;
$L__BB63_20:
	cvt.u32.u16 	%r267, %rs4;
	mul.wide.u32 	%rd120, %r267, 4;
	add.s64 	%rd121, %rd3, %rd120;
	ld.global.nc.f32 	%f148, [%rd121];
	fma.rn.f32 	%f149, %f148, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f150, %f149;
	mov.f32 	%f151, 0f4B400001;
	mov.f32 	%f152, 0f437C0000;
	fma.rm.f32 	%f153, %f150, %f152, %f151;
	add.rn.f32 	%f154, %f153, 0fCB40007F;
	neg.f32 	%f155, %f154;
	fma.rn.f32 	%f156, %f148, 0f3FB8AA3B, %f155;
	fma.rn.f32 	%f157, %f148, 0f32A57060, %f156;
	mov.b32 	%r268, %f153;
	shl.b32 	%r269, %r268, 23;
	mov.b32 	%f158, %r269;
	ex2.approx.ftz.f32 	%f159, %f157;
	mul.rn.f32 	%f160, %f159, %f158;
	neg.f32 	%f161, %f160;
	sub.rn.f32 	%f162, %f161, %f160;
	add.rn.f32 	%f163, %f162, %f162;
	add.rn.f32 	%f164, %f163, %f163;
	add.rn.f32 	%f165, %f164, %f164;
	add.rn.f32 	%f166, %f165, %f165;
	add.rn.f32 	%f167, %f166, %f166;
	add.rn.f32 	%f168, %f167, %f167;
	add.rn.f32 	%f15, %f168, %f168;
	add.rn.f32 	%f169, %f15, %f15;
	fma.rn.f32 	%f170, %f169, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f171, %f170;
	fma.rm.f32 	%f172, %f171, %f152, %f151;
	add.rn.f32 	%f173, %f172, 0fCB40007F;
	shr.u32 	%r272, %r2, 1;
	mul.wide.u32 	%rd122, %r267, 12;
	add.s64 	%rd123, %rd2, %rd122;
	mul.wide.u32 	%rd124, %r272, 4;
	add.s64 	%rd125, %rd123, %rd124;
	ld.global.nc.f32 	%f179, [%rd125];
	add.rn.f32 	%f180, %f179, %f179;
	add.rn.f32 	%f181, %f180, %f180;
	add.rn.f32 	%f182, %f181, %f181;
	add.rn.f32 	%f17, %f182, %f182;
	add.rn.f32 	%f18, %f17, %f17;
	mul.rn.f32 	%f183, %f18, 0f3F22F983;
	cvt.rni.s32.f32 	%r628, %f183;
	cvt.rn.f32.s32 	%f184, %r628;
	fma.rn.f32 	%f185, %f184, 0fBFC90FDA, %f18;
	fma.rn.f32 	%f186, %f184, 0fB3A22168, %f185;
	fma.rn.f32 	%f405, %f184, 0fA7C234C5, %f186;
	abs.f32 	%f20, %f18;
	setp.ltu.f32 	%p19, %f20, 0f47CE4780;
	setp.neu.f32 	%p102, %f20, 0f7F800000;
	mov.u32 	%r616, %r628;
	mov.f32 	%f402, %f405;
	@%p19 bra 	$L__BB63_28;
	@%p102 bra 	$L__BB63_23;
	mov.f32 	%f189, 0f00000000;
	mul.rn.f32 	%f402, %f18, %f189;
	mov.b32 	%r616, 0;
	bra.uni 	$L__BB63_28;
$L__BB63_23:
	mov.b32 	%r613, 0;
	mov.b32 	%r35, %f18;
	shr.u32 	%r36, %r35, 23;
	and.b32  	%r274, %r36, 224;
	add.s32 	%r275, %r274, -128;
	shl.b32 	%r276, %r35, 8;
	or.b32  	%r280, %r276, -2147483648;
	shr.u32 	%r38, %r275, 5;
	mov.u64 	%rd258, 0;
	mov.u64 	%rd127, __cudart_i2opi_f;
$L__BB63_24:
	.pragma "nounroll";
	add.s64 	%rd128, %rd127, %rd258;
	ld.global.nc.u32 	%r279, [%rd128];
	// begin inline asm
	{
	mad.lo.cc.u32   %r277, %r279, %r280, %r613;
	madc.hi.u32     %r613, %r279, %r280,  0;
	}
	// end inline asm
	add.s64 	%rd129, %rd6, %rd258;
	st.local.u32 	[%rd129], %r277;
	add.s64 	%rd258, %rd258, 4;
	cvt.u32.u64 	%r282, %rd258;
	setp.ne.s32 	%p21, %r282, 24;
	@%p21 bra 	$L__BB63_24;
	st.local.u32 	[%rd6+24], %r613;
	and.b32  	%r41, %r36, 31;
	mul.wide.u32 	%rd130, %r38, 4;
	sub.s64 	%rd32, %rd6, %rd130;
	ld.local.u32 	%r614, [%rd32+24];
	ld.local.u32 	%r615, [%rd32+20];
	setp.eq.s32 	%p22, %r41, 0;
	@%p22 bra 	$L__BB63_27;
	shl.b32 	%r283, %r615, %r41;
	shl.b32 	%r284, %r614, %r41;
	mov.b32 	%r285, 32;
	sub.s32 	%r286, %r285, %r41;
	shr.u32 	%r287, %r615, %r286;
	add.s32 	%r614, %r287, %r284;
	ld.local.u32 	%r288, [%rd32+16];
	shr.u32 	%r289, %r288, %r286;
	add.s32 	%r615, %r289, %r283;
$L__BB63_27:
	shr.u32 	%r290, %r614, 30;
	shr.u32 	%r291, %r615, 30;
	shl.b32 	%r292, %r614, 2;
	or.b32  	%r293, %r292, %r291;
	shl.b32 	%r294, %r615, 2;
	bfe.u32 	%r295, %r614, 29, 1;
	add.s32 	%r296, %r295, %r290;
	neg.s32 	%r297, %r296;
	setp.lt.s32 	%p23, %r35, 0;
	selp.b32 	%r616, %r297, %r296, %p23;
	xor.b32  	%r298, %r293, %r35;
	bfe.s32 	%r299, %r614, 29, 1;
	xor.b32  	%r300, %r299, %r293;
	xor.b32  	%r301, %r299, %r294;
	cvt.u64.u32 	%rd131, %r300;
	shl.b64 	%rd132, %rd131, 32;
	cvt.u64.u32 	%rd133, %r301;
	or.b64  	%rd134, %rd132, %rd133;
	cvt.rn.f64.s64 	%fd5, %rd134;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f187, %fd6;
	neg.f32 	%f188, %f187;
	setp.lt.s32 	%p24, %r298, 0;
	selp.f32 	%f402, %f188, %f187, %p24;
$L__BB63_28:
	neg.f32 	%f174, %f173;
	cvt.u64.u16 	%rd28, %rs4;
	add.s32 	%r303, %r616, 1;
	mul.rn.f32 	%f190, %f402, %f402;
	and.b32  	%r304, %r616, 1;
	setp.eq.b32 	%p25, %r304, 1;
	selp.f32 	%f191, %f402, 0f3F800000, %p25;
	fma.rn.f32 	%f192, %f190, %f191, 0f00000000;
	fma.rn.f32 	%f193, %f190, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f194, 0fB94D4153, %f193, %p25;
	selp.f32 	%f195, 0f3C0885E4, 0f3D2AAABB, %p25;
	fma.rn.f32 	%f196, %f194, %f190, %f195;
	selp.f32 	%f197, 0fBE2AAAA8, 0fBEFFFFFF, %p25;
	fma.rn.f32 	%f198, %f196, %f190, %f197;
	fma.rn.f32 	%f199, %f198, %f192, %f191;
	and.b32  	%r305, %r303, 2;
	mov.f32 	%f200, 0f00000000;
	fma.rn.f32 	%f202, %f15, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f203, %f202;
	fma.rm.f32 	%f206, %f203, %f152, %f151;
	add.rn.f32 	%f207, %f206, 0fCB40007F;
	neg.f32 	%f208, %f207;
	fma.rn.f32 	%f209, %f15, 0f3FB8AA3B, %f208;
	fma.rn.f32 	%f210, %f15, 0f32A57060, %f209;
	mov.b32 	%r306, %f206;
	shl.b32 	%r307, %r306, 23;
	mov.b32 	%f211, %r307;
	ex2.approx.ftz.f32 	%f212, %f210;
	mul.rn.f32 	%f213, %f17, 0f3F22F983;
	cvt.rni.s32.f32 	%r652, %f213;
	cvt.rn.f32.s32 	%f214, %r652;
	fma.rn.f32 	%f215, %f214, 0fBFC90FDA, %f17;
	fma.rn.f32 	%f216, %f214, 0fB3A22168, %f215;
	fma.rn.f32 	%f412, %f214, 0fA7C234C5, %f216;
	abs.f32 	%f27, %f17;
	setp.ltu.f32 	%p27, %f27, 0f47CE4780;
	setp.neu.f32 	%p101, %f27, 0f7F800000;
	mov.u32 	%r620, %r652;
	mov.f32 	%f403, %f412;
	@%p27 bra 	$L__BB63_36;
	@%p101 bra 	$L__BB63_31;
	mul.rn.f32 	%f403, %f17, %f200;
	mov.b32 	%r620, 0;
	bra.uni 	$L__BB63_36;
$L__BB63_31:
	mov.b32 	%r51, %f17;
	shr.u32 	%r52, %r51, 23;
	and.b32  	%r309, %r52, 224;
	add.s32 	%r310, %r309, -128;
	shl.b32 	%r311, %r51, 8;
	or.b32  	%r315, %r311, -2147483648;
	shr.u32 	%r54, %r310, 5;
	mov.b32 	%r617, 0;
	mov.u64 	%rd259, 0;
	mov.u64 	%rd136, __cudart_i2opi_f;
$L__BB63_32:
	.pragma "nounroll";
	add.s64 	%rd137, %rd136, %rd259;
	ld.global.nc.u32 	%r314, [%rd137];
	// begin inline asm
	{
	mad.lo.cc.u32   %r312, %r314, %r315, %r617;
	madc.hi.u32     %r617, %r314, %r315,  0;
	}
	// end inline asm
	add.s64 	%rd138, %rd6, %rd259;
	st.local.u32 	[%rd138], %r312;
	add.s64 	%rd259, %rd259, 4;
	cvt.u32.u64 	%r317, %rd259;
	setp.ne.s32 	%p29, %r317, 24;
	@%p29 bra 	$L__BB63_32;
	st.local.u32 	[%rd6+24], %r617;
	and.b32  	%r57, %r52, 31;
	mul.wide.u32 	%rd139, %r54, 4;
	sub.s64 	%rd35, %rd6, %rd139;
	ld.local.u32 	%r618, [%rd35+24];
	ld.local.u32 	%r619, [%rd35+20];
	setp.eq.s32 	%p30, %r57, 0;
	@%p30 bra 	$L__BB63_35;
	shl.b32 	%r318, %r619, %r57;
	shl.b32 	%r319, %r618, %r57;
	mov.b32 	%r320, 32;
	sub.s32 	%r321, %r320, %r57;
	shr.u32 	%r322, %r619, %r321;
	add.s32 	%r618, %r322, %r319;
	ld.local.u32 	%r323, [%rd35+16];
	shr.u32 	%r324, %r323, %r321;
	add.s32 	%r619, %r324, %r318;
$L__BB63_35:
	shr.u32 	%r325, %r618, 30;
	shr.u32 	%r326, %r619, 30;
	shl.b32 	%r327, %r618, 2;
	or.b32  	%r328, %r327, %r326;
	shl.b32 	%r329, %r619, 2;
	bfe.u32 	%r330, %r618, 29, 1;
	add.s32 	%r331, %r330, %r325;
	neg.s32 	%r332, %r331;
	setp.lt.s32 	%p31, %r51, 0;
	selp.b32 	%r620, %r332, %r331, %p31;
	xor.b32  	%r333, %r328, %r51;
	bfe.s32 	%r334, %r618, 29, 1;
	xor.b32  	%r335, %r334, %r328;
	xor.b32  	%r336, %r334, %r329;
	cvt.u64.u32 	%rd140, %r335;
	shl.b64 	%rd141, %rd140, 32;
	cvt.u64.u32 	%rd142, %r336;
	or.b64  	%rd143, %rd141, %rd142;
	cvt.rn.f64.s64 	%fd7, %rd143;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f217, %fd8;
	neg.f32 	%f218, %f217;
	setp.lt.s32 	%p32, %r333, 0;
	selp.f32 	%f403, %f218, %f217, %p32;
$L__BB63_36:
	fma.rn.f32 	%f175, %f169, 0f3FB8AA3B, %f174;
	mov.b32 	%r270, %f172;
	setp.eq.s32 	%p26, %r305, 0;
	sub.rn.f32 	%f201, %f200, %f199;
	cvt.u64.u32 	%rd29, %r272;
	mul.rn.f32 	%f25, %f212, %f211;
	add.s32 	%r338, %r620, 1;
	mul.rn.f32 	%f220, %f403, %f403;
	and.b32  	%r339, %r620, 1;
	setp.eq.b32 	%p34, %r339, 1;
	selp.f32 	%f221, %f403, 0f3F800000, %p34;
	fma.rn.f32 	%f222, %f220, %f221, 0f00000000;
	fma.rn.f32 	%f223, %f220, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f224, 0fB94D4153, %f223, %p34;
	selp.f32 	%f225, 0f3C0885E4, 0f3D2AAABB, %p34;
	fma.rn.f32 	%f226, %f224, %f220, %f225;
	selp.f32 	%f227, 0fBE2AAAA8, 0fBEFFFFFF, %p34;
	fma.rn.f32 	%f228, %f226, %f220, %f227;
	fma.rn.f32 	%f229, %f228, %f222, %f221;
	and.b32  	%r340, %r338, 2;
	setp.eq.s32 	%p35, %r340, 0;
	sub.rn.f32 	%f231, %f200, %f229;
	selp.f32 	%f232, %f229, %f231, %p35;
	cvt.u64.u16 	%rd36, %rs3;
	mul.lo.s64 	%rd144, %rd28, 4800;
	add.s64 	%rd145, %rd5, %rd144;
	cvt.u32.u16 	%r341, %rs3;
	mul.wide.u32 	%rd146, %r341, 96;
	add.s64 	%rd147, %rd145, %rd146;
	mul.wide.u32 	%rd148, %r2, 4;
	add.s64 	%rd37, %rd147, %rd148;
	ld.global.nc.f32 	%f233, [%rd37];
	mul.rn.f32 	%f31, %f233, %f232;
	mov.u32 	%r624, %r652;
	mov.f32 	%f404, %f412;
	@%p27 bra 	$L__BB63_44;
	@%p101 bra 	$L__BB63_39;
	mul.rn.f32 	%f404, %f17, %f200;
	mov.b32 	%r624, 0;
	bra.uni 	$L__BB63_44;
$L__BB63_39:
	mov.b32 	%r66, %f17;
	shr.u32 	%r67, %r66, 23;
	and.b32  	%r344, %r67, 224;
	add.s32 	%r345, %r344, -128;
	shl.b32 	%r346, %r66, 8;
	or.b32  	%r350, %r346, -2147483648;
	shr.u32 	%r69, %r345, 5;
	mov.b32 	%r621, 0;
	mov.u64 	%rd260, 0;
	mov.u64 	%rd150, __cudart_i2opi_f;
$L__BB63_40:
	.pragma "nounroll";
	add.s64 	%rd151, %rd150, %rd260;
	ld.global.nc.u32 	%r349, [%rd151];
	// begin inline asm
	{
	mad.lo.cc.u32   %r347, %r349, %r350, %r621;
	madc.hi.u32     %r621, %r349, %r350,  0;
	}
	// end inline asm
	add.s64 	%rd152, %rd6, %rd260;
	st.local.u32 	[%rd152], %r347;
	add.s64 	%rd260, %rd260, 4;
	cvt.u32.u64 	%r352, %rd260;
	setp.ne.s32 	%p37, %r352, 24;
	@%p37 bra 	$L__BB63_40;
	st.local.u32 	[%rd6+24], %r621;
	and.b32  	%r72, %r67, 31;
	mul.wide.u32 	%rd153, %r69, 4;
	sub.s64 	%rd40, %rd6, %rd153;
	ld.local.u32 	%r622, [%rd40+24];
	ld.local.u32 	%r623, [%rd40+20];
	setp.eq.s32 	%p38, %r72, 0;
	@%p38 bra 	$L__BB63_43;
	shl.b32 	%r353, %r623, %r72;
	shl.b32 	%r354, %r622, %r72;
	mov.b32 	%r355, 32;
	sub.s32 	%r356, %r355, %r72;
	shr.u32 	%r357, %r623, %r356;
	add.s32 	%r622, %r357, %r354;
	ld.local.u32 	%r358, [%rd40+16];
	shr.u32 	%r359, %r358, %r356;
	add.s32 	%r623, %r359, %r353;
$L__BB63_43:
	shr.u32 	%r360, %r622, 30;
	shr.u32 	%r361, %r623, 30;
	shl.b32 	%r362, %r622, 2;
	or.b32  	%r363, %r362, %r361;
	shl.b32 	%r364, %r623, 2;
	bfe.u32 	%r365, %r622, 29, 1;
	add.s32 	%r366, %r365, %r360;
	neg.s32 	%r367, %r366;
	setp.lt.s32 	%p39, %r66, 0;
	selp.b32 	%r624, %r367, %r366, %p39;
	xor.b32  	%r368, %r363, %r66;
	bfe.s32 	%r369, %r622, 29, 1;
	xor.b32  	%r370, %r369, %r363;
	xor.b32  	%r371, %r369, %r364;
	cvt.u64.u32 	%rd154, %r370;
	shl.b64 	%rd155, %rd154, 32;
	cvt.u64.u32 	%rd156, %r371;
	or.b64  	%rd157, %rd155, %rd156;
	cvt.rn.f64.s64 	%fd9, %rd157;
	mul.rn.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f234, %fd10;
	neg.f32 	%f235, %f234;
	setp.lt.s32 	%p40, %r368, 0;
	selp.f32 	%f404, %f235, %f234, %p40;
$L__BB63_44:
	fma.rn.f32 	%f176, %f169, 0f32A57060, %f175;
	shl.b32 	%r271, %r270, 23;
	selp.f32 	%f24, %f199, %f201, %p26;
	mul.rn.f32 	%f237, %f404, %f404;
	and.b32  	%r373, %r624, 1;
	setp.eq.b32 	%p42, %r373, 1;
	selp.f32 	%f238, 0f3F800000, %f404, %p42;
	fma.rn.f32 	%f239, %f237, %f238, 0f00000000;
	fma.rn.f32 	%f240, %f237, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f241, %f240, 0fB94D4153, %p42;
	selp.f32 	%f242, 0f3D2AAABB, 0f3C0885E4, %p42;
	fma.rn.f32 	%f243, %f241, %f237, %f242;
	selp.f32 	%f244, 0fBEFFFFFF, 0fBE2AAAA8, %p42;
	fma.rn.f32 	%f245, %f243, %f237, %f244;
	fma.rn.f32 	%f246, %f245, %f239, %f238;
	and.b32  	%r374, %r624, 2;
	setp.eq.s32 	%p43, %r374, 0;
	sub.rn.f32 	%f248, %f200, %f246;
	selp.f32 	%f249, %f246, %f248, %p43;
	and.b32  	%r81, %r2, 1;
	mul.lo.s64 	%rd158, %rd28, 2400;
	add.s64 	%rd159, %rd4, %rd158;
	mul.lo.s64 	%rd160, %rd36, 48;
	add.s64 	%rd161, %rd159, %rd160;
	shl.b64 	%rd162, %rd29, 3;
	add.s64 	%rd163, %rd161, %rd162;
	mul.wide.u32 	%rd164, %r81, 4;
	add.s64 	%rd41, %rd163, %rd164;
	ld.global.nc.f32 	%f250, [%rd41];
	mul.rn.f32 	%f251, %f250, %f249;
	add.rn.f32 	%f252, %f31, %f251;
	mul.rn.f32 	%f253, %f25, %f252;
	ld.global.nc.f32 	%f254, [%rd37+24];
	add.rn.f32 	%f255, %f254, %f253;
	@%p19 bra 	$L__BB63_52;
	@%p102 bra 	$L__BB63_47;
	mul.rn.f32 	%f405, %f18, %f200;
	mov.b32 	%r628, 0;
	bra.uni 	$L__BB63_52;
$L__BB63_47:
	mov.b32 	%r82, %f18;
	shr.u32 	%r83, %r82, 23;
	and.b32  	%r376, %r83, 224;
	add.s32 	%r377, %r376, -128;
	shl.b32 	%r378, %r82, 8;
	or.b32  	%r382, %r378, -2147483648;
	shr.u32 	%r85, %r377, 5;
	mov.b32 	%r625, 0;
	mov.u64 	%rd261, 0;
	mov.u64 	%rd166, __cudart_i2opi_f;
$L__BB63_48:
	.pragma "nounroll";
	add.s64 	%rd167, %rd166, %rd261;
	ld.global.nc.u32 	%r381, [%rd167];
	// begin inline asm
	{
	mad.lo.cc.u32   %r379, %r381, %r382, %r625;
	madc.hi.u32     %r625, %r381, %r382,  0;
	}
	// end inline asm
	add.s64 	%rd168, %rd6, %rd261;
	st.local.u32 	[%rd168], %r379;
	add.s64 	%rd261, %rd261, 4;
	cvt.u32.u64 	%r384, %rd261;
	setp.ne.s32 	%p45, %r384, 24;
	@%p45 bra 	$L__BB63_48;
	st.local.u32 	[%rd6+24], %r625;
	and.b32  	%r88, %r83, 31;
	mul.wide.u32 	%rd169, %r85, 4;
	sub.s64 	%rd44, %rd6, %rd169;
	ld.local.u32 	%r626, [%rd44+24];
	ld.local.u32 	%r627, [%rd44+20];
	setp.eq.s32 	%p46, %r88, 0;
	@%p46 bra 	$L__BB63_51;
	shl.b32 	%r385, %r627, %r88;
	shl.b32 	%r386, %r626, %r88;
	mov.b32 	%r387, 32;
	sub.s32 	%r388, %r387, %r88;
	shr.u32 	%r389, %r627, %r388;
	add.s32 	%r626, %r389, %r386;
	ld.local.u32 	%r390, [%rd44+16];
	shr.u32 	%r391, %r390, %r388;
	add.s32 	%r627, %r391, %r385;
$L__BB63_51:
	shr.u32 	%r392, %r626, 30;
	shr.u32 	%r393, %r627, 30;
	shl.b32 	%r394, %r626, 2;
	or.b32  	%r395, %r394, %r393;
	shl.b32 	%r396, %r627, 2;
	bfe.u32 	%r397, %r626, 29, 1;
	add.s32 	%r398, %r397, %r392;
	neg.s32 	%r399, %r398;
	setp.lt.s32 	%p47, %r82, 0;
	selp.b32 	%r628, %r399, %r398, %p47;
	xor.b32  	%r400, %r395, %r82;
	bfe.s32 	%r401, %r626, 29, 1;
	xor.b32  	%r402, %r401, %r395;
	xor.b32  	%r403, %r401, %r396;
	cvt.u64.u32 	%rd170, %r402;
	shl.b64 	%rd171, %rd170, 32;
	cvt.u64.u32 	%rd172, %r403;
	or.b64  	%rd173, %rd171, %rd172;
	cvt.rn.f64.s64 	%fd11, %rd173;
	mul.rn.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f256, %fd12;
	neg.f32 	%f257, %f256;
	setp.lt.s32 	%p48, %r400, 0;
	selp.f32 	%f405, %f257, %f256, %p48;
$L__BB63_52:
	mov.b32 	%f177, %r271;
	ex2.approx.ftz.f32 	%f178, %f176;
	mul.rn.f32 	%f35, %f24, %f255;
	mul.rn.f32 	%f259, %f405, %f405;
	and.b32  	%r405, %r628, 1;
	setp.eq.b32 	%p49, %r405, 1;
	selp.f32 	%f260, 0f3F800000, %f405, %p49;
	fma.rn.f32 	%f261, %f259, %f260, 0f00000000;
	fma.rn.f32 	%f262, %f259, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f263, %f262, 0fB94D4153, %p49;
	selp.f32 	%f264, 0f3D2AAABB, 0f3C0885E4, %p49;
	fma.rn.f32 	%f265, %f263, %f259, %f264;
	selp.f32 	%f266, 0fBEFFFFFF, 0fBE2AAAA8, %p49;
	fma.rn.f32 	%f267, %f265, %f259, %f266;
	fma.rn.f32 	%f268, %f267, %f261, %f260;
	and.b32  	%r406, %r628, 2;
	setp.eq.s32 	%p50, %r406, 0;
	sub.rn.f32 	%f270, %f200, %f268;
	selp.f32 	%f39, %f268, %f270, %p50;
	setp.ne.s32 	%p51, %r81, 0;
	@%p51 bra 	$L__BB63_70;
	or.b32  	%r472, %r2, 1;
	setp.gt.u16 	%p68, %rs1, 3;
	selp.b32 	%r97, 5, %r472, %p68;
	shr.u32 	%r473, %r97, 1;
	mul.lo.s64 	%rd203, %rd28, 12;
	add.s64 	%rd204, %rd2, %rd203;
	mul.wide.u32 	%rd205, %r473, 4;
	add.s64 	%rd206, %rd204, %rd205;
	ld.global.nc.f32 	%f309, [%rd206];
	add.rn.f32 	%f310, %f309, %f309;
	add.rn.f32 	%f311, %f310, %f310;
	add.rn.f32 	%f312, %f311, %f311;
	add.rn.f32 	%f40, %f312, %f312;
	mul.rn.f32 	%f313, %f40, 0f3F22F983;
	cvt.rni.s32.f32 	%r636, %f313;
	cvt.rn.f32.s32 	%f314, %r636;
	fma.rn.f32 	%f315, %f314, 0fBFC90FDA, %f40;
	fma.rn.f32 	%f316, %f314, 0fB3A22168, %f315;
	fma.rn.f32 	%f407, %f314, 0fA7C234C5, %f316;
	abs.f32 	%f42, %f40;
	setp.ltu.f32 	%p69, %f42, 0f47CE4780;
	mov.u32 	%r632, %r636;
	mov.f32 	%f406, %f407;
	@%p69 bra 	$L__BB63_61;
	setp.neu.f32 	%p70, %f42, 0f7F800000;
	@%p70 bra 	$L__BB63_56;
	mul.rn.f32 	%f406, %f40, %f200;
	mov.b32 	%r632, 0;
	bra.uni 	$L__BB63_61;
$L__BB63_70:
	and.b32  	%r129, %r2, 6;
	mov.u32 	%r640, %r652;
	mov.f32 	%f408, %f412;
	@%p27 bra 	$L__BB63_78;
	@%p101 bra 	$L__BB63_73;
	mul.rn.f32 	%f408, %f17, %f200;
	mov.b32 	%r640, 0;
	bra.uni 	$L__BB63_78;
$L__BB63_56:
	mov.b32 	%r99, %f40;
	shr.u32 	%r100, %r99, 23;
	and.b32  	%r475, %r100, 224;
	add.s32 	%r476, %r475, -128;
	shl.b32 	%r477, %r99, 8;
	or.b32  	%r481, %r477, -2147483648;
	shr.u32 	%r102, %r476, 5;
	mov.b32 	%r629, 0;
	mov.u64 	%rd262, 0;
	mov.u64 	%rd208, __cudart_i2opi_f;
$L__BB63_57:
	.pragma "nounroll";
	add.s64 	%rd209, %rd208, %rd262;
	ld.global.nc.u32 	%r480, [%rd209];
	// begin inline asm
	{
	mad.lo.cc.u32   %r478, %r480, %r481, %r629;
	madc.hi.u32     %r629, %r480, %r481,  0;
	}
	// end inline asm
	add.s64 	%rd210, %rd6, %rd262;
	st.local.u32 	[%rd210], %r478;
	add.s64 	%rd262, %rd262, 4;
	cvt.u32.u64 	%r483, %rd262;
	setp.ne.s32 	%p71, %r483, 24;
	@%p71 bra 	$L__BB63_57;
	st.local.u32 	[%rd6+24], %r629;
	and.b32  	%r105, %r100, 31;
	mul.wide.u32 	%rd211, %r102, 4;
	sub.s64 	%rd48, %rd6, %rd211;
	ld.local.u32 	%r630, [%rd48+24];
	ld.local.u32 	%r631, [%rd48+20];
	setp.eq.s32 	%p72, %r105, 0;
	@%p72 bra 	$L__BB63_60;
	shl.b32 	%r484, %r631, %r105;
	shl.b32 	%r485, %r630, %r105;
	mov.b32 	%r486, 32;
	sub.s32 	%r487, %r486, %r105;
	shr.u32 	%r488, %r631, %r487;
	add.s32 	%r630, %r488, %r485;
	ld.local.u32 	%r489, [%rd48+16];
	shr.u32 	%r490, %r489, %r487;
	add.s32 	%r631, %r490, %r484;
$L__BB63_60:
	shr.u32 	%r491, %r630, 30;
	shr.u32 	%r492, %r631, 30;
	shl.b32 	%r493, %r630, 2;
	or.b32  	%r494, %r493, %r492;
	shl.b32 	%r495, %r631, 2;
	bfe.u32 	%r496, %r630, 29, 1;
	add.s32 	%r497, %r496, %r491;
	neg.s32 	%r498, %r497;
	setp.lt.s32 	%p73, %r99, 0;
	selp.b32 	%r632, %r498, %r497, %p73;
	xor.b32  	%r499, %r494, %r99;
	bfe.s32 	%r500, %r630, 29, 1;
	xor.b32  	%r501, %r500, %r494;
	xor.b32  	%r502, %r500, %r495;
	cvt.u64.u32 	%rd212, %r501;
	shl.b64 	%rd213, %rd212, 32;
	cvt.u64.u32 	%rd214, %r502;
	or.b64  	%rd215, %rd213, %rd214;
	cvt.rn.f64.s64 	%fd17, %rd215;
	mul.rn.f64 	%fd18, %fd17, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f317, %fd18;
	neg.f32 	%f318, %f317;
	setp.lt.s32 	%p74, %r499, 0;
	selp.f32 	%f406, %f318, %f317, %p74;
$L__BB63_61:
	cvt.u64.u32 	%rd45, %r473;
	add.s32 	%r504, %r632, 1;
	mul.rn.f32 	%f320, %f406, %f406;
	and.b32  	%r505, %r632, 1;
	setp.eq.b32 	%p76, %r505, 1;
	selp.f32 	%f321, %f406, 0f3F800000, %p76;
	fma.rn.f32 	%f322, %f320, %f321, 0f00000000;
	fma.rn.f32 	%f323, %f320, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f324, 0fB94D4153, %f323, %p76;
	selp.f32 	%f325, 0f3C0885E4, 0f3D2AAABB, %p76;
	fma.rn.f32 	%f326, %f324, %f320, %f325;
	selp.f32 	%f327, 0fBE2AAAA8, 0fBEFFFFFF, %p76;
	fma.rn.f32 	%f328, %f326, %f320, %f327;
	fma.rn.f32 	%f329, %f328, %f322, %f321;
	and.b32  	%r506, %r504, 2;
	setp.eq.s32 	%p77, %r506, 0;
	sub.rn.f32 	%f331, %f200, %f329;
	selp.f32 	%f332, %f329, %f331, %p77;
	mul.lo.s64 	%rd218, %rd36, 96;
	add.s64 	%rd219, %rd145, %rd218;
	mul.wide.u32 	%rd220, %r97, 4;
	add.s64 	%rd49, %rd219, %rd220;
	ld.global.nc.f32 	%f333, [%rd49];
	mul.rn.f32 	%f46, %f333, %f332;
	@%p69 bra 	$L__BB63_69;
	setp.neu.f32 	%p78, %f42, 0f7F800000;
	@%p78 bra 	$L__BB63_64;
	mul.rn.f32 	%f407, %f40, %f200;
	mov.b32 	%r636, 0;
	bra.uni 	$L__BB63_69;
$L__BB63_73:
	mov.b32 	%r130, %f17;
	shr.u32 	%r131, %r130, 23;
	and.b32  	%r408, %r131, 224;
	add.s32 	%r409, %r408, -128;
	shl.b32 	%r410, %r130, 8;
	or.b32  	%r414, %r410, -2147483648;
	shr.u32 	%r133, %r409, 5;
	mov.b32 	%r637, 0;
	mov.u64 	%rd264, 0;
	mov.u64 	%rd175, __cudart_i2opi_f;
$L__BB63_74:
	.pragma "nounroll";
	add.s64 	%rd176, %rd175, %rd264;
	ld.global.nc.u32 	%r413, [%rd176];
	// begin inline asm
	{
	mad.lo.cc.u32   %r411, %r413, %r414, %r637;
	madc.hi.u32     %r637, %r413, %r414,  0;
	}
	// end inline asm
	add.s64 	%rd177, %rd6, %rd264;
	st.local.u32 	[%rd177], %r411;
	add.s64 	%rd264, %rd264, 4;
	cvt.u32.u64 	%r416, %rd264;
	setp.ne.s32 	%p54, %r416, 24;
	@%p54 bra 	$L__BB63_74;
	st.local.u32 	[%rd6+24], %r637;
	and.b32  	%r136, %r131, 31;
	mul.wide.u32 	%rd178, %r133, 4;
	sub.s64 	%rd55, %rd6, %rd178;
	ld.local.u32 	%r638, [%rd55+24];
	ld.local.u32 	%r639, [%rd55+20];
	setp.eq.s32 	%p55, %r136, 0;
	@%p55 bra 	$L__BB63_77;
	shl.b32 	%r417, %r639, %r136;
	shl.b32 	%r418, %r638, %r136;
	mov.b32 	%r419, 32;
	sub.s32 	%r420, %r419, %r136;
	shr.u32 	%r421, %r639, %r420;
	add.s32 	%r638, %r421, %r418;
	ld.local.u32 	%r422, [%rd55+16];
	shr.u32 	%r423, %r422, %r420;
	add.s32 	%r639, %r423, %r417;
$L__BB63_77:
	shr.u32 	%r424, %r638, 30;
	shr.u32 	%r425, %r639, 30;
	shl.b32 	%r426, %r638, 2;
	or.b32  	%r427, %r426, %r425;
	shl.b32 	%r428, %r639, 2;
	bfe.u32 	%r429, %r638, 29, 1;
	add.s32 	%r430, %r429, %r424;
	neg.s32 	%r431, %r430;
	setp.lt.s32 	%p56, %r130, 0;
	selp.b32 	%r640, %r431, %r430, %p56;
	xor.b32  	%r432, %r427, %r130;
	bfe.s32 	%r433, %r638, 29, 1;
	xor.b32  	%r434, %r433, %r427;
	xor.b32  	%r435, %r433, %r428;
	cvt.u64.u32 	%rd179, %r434;
	shl.b64 	%rd180, %rd179, 32;
	cvt.u64.u32 	%rd181, %r435;
	or.b64  	%rd182, %rd180, %rd181;
	cvt.rn.f64.s64 	%fd13, %rd182;
	mul.rn.f64 	%fd14, %fd13, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f271, %fd14;
	neg.f32 	%f272, %f271;
	setp.lt.s32 	%p57, %r432, 0;
	selp.f32 	%f408, %f272, %f271, %p57;
$L__BB63_78:
	add.s32 	%r437, %r640, 1;
	mul.rn.f32 	%f274, %f408, %f408;
	and.b32  	%r438, %r640, 1;
	setp.eq.b32 	%p59, %r438, 1;
	selp.f32 	%f275, %f408, 0f3F800000, %p59;
	fma.rn.f32 	%f276, %f274, %f275, 0f00000000;
	fma.rn.f32 	%f277, %f274, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f278, 0fB94D4153, %f277, %p59;
	selp.f32 	%f279, 0f3C0885E4, 0f3D2AAABB, %p59;
	fma.rn.f32 	%f280, %f278, %f274, %f279;
	selp.f32 	%f281, 0fBE2AAAA8, 0fBEFFFFFF, %p59;
	fma.rn.f32 	%f282, %f280, %f274, %f281;
	fma.rn.f32 	%f283, %f282, %f276, %f275;
	and.b32  	%r439, %r437, 2;
	setp.eq.s32 	%p60, %r439, 0;
	sub.rn.f32 	%f285, %f200, %f283;
	selp.f32 	%f286, %f283, %f285, %p60;
	mul.lo.s64 	%rd185, %rd36, 96;
	add.s64 	%rd186, %rd145, %rd185;
	mul.wide.u32 	%rd187, %r129, 4;
	add.s64 	%rd56, %rd186, %rd187;
	ld.global.nc.f32 	%f287, [%rd56];
	mul.rn.f32 	%f54, %f287, %f286;
	mov.u32 	%r644, %r652;
	mov.f32 	%f409, %f412;
	@%p27 bra 	$L__BB63_86;
	@%p101 bra 	$L__BB63_81;
	mul.rn.f32 	%f409, %f17, %f200;
	mov.b32 	%r644, 0;
	bra.uni 	$L__BB63_86;
$L__BB63_64:
	mov.b32 	%r114, %f40;
	shr.u32 	%r115, %r114, 23;
	and.b32  	%r508, %r115, 224;
	add.s32 	%r509, %r508, -128;
	shl.b32 	%r510, %r114, 8;
	or.b32  	%r514, %r510, -2147483648;
	shr.u32 	%r117, %r509, 5;
	mov.b32 	%r633, 0;
	mov.u64 	%rd263, 0;
	mov.u64 	%rd222, __cudart_i2opi_f;
$L__BB63_65:
	.pragma "nounroll";
	add.s64 	%rd223, %rd222, %rd263;
	ld.global.nc.u32 	%r513, [%rd223];
	// begin inline asm
	{
	mad.lo.cc.u32   %r511, %r513, %r514, %r633;
	madc.hi.u32     %r633, %r513, %r514,  0;
	}
	// end inline asm
	add.s64 	%rd224, %rd6, %rd263;
	st.local.u32 	[%rd224], %r511;
	add.s64 	%rd263, %rd263, 4;
	cvt.u32.u64 	%r516, %rd263;
	setp.ne.s32 	%p79, %r516, 24;
	@%p79 bra 	$L__BB63_65;
	st.local.u32 	[%rd6+24], %r633;
	and.b32  	%r120, %r115, 31;
	mul.wide.u32 	%rd225, %r117, 4;
	sub.s64 	%rd52, %rd6, %rd225;
	ld.local.u32 	%r634, [%rd52+24];
	ld.local.u32 	%r635, [%rd52+20];
	setp.eq.s32 	%p80, %r120, 0;
	@%p80 bra 	$L__BB63_68;
	shl.b32 	%r517, %r635, %r120;
	shl.b32 	%r518, %r634, %r120;
	mov.b32 	%r519, 32;
	sub.s32 	%r520, %r519, %r120;
	shr.u32 	%r521, %r635, %r520;
	add.s32 	%r634, %r521, %r518;
	ld.local.u32 	%r522, [%rd52+16];
	shr.u32 	%r523, %r522, %r520;
	add.s32 	%r635, %r523, %r517;
$L__BB63_68:
	shr.u32 	%r524, %r634, 30;
	shr.u32 	%r525, %r635, 30;
	shl.b32 	%r526, %r634, 2;
	or.b32  	%r527, %r526, %r525;
	shl.b32 	%r528, %r635, 2;
	bfe.u32 	%r529, %r634, 29, 1;
	add.s32 	%r530, %r529, %r524;
	neg.s32 	%r531, %r530;
	setp.lt.s32 	%p81, %r114, 0;
	selp.b32 	%r636, %r531, %r530, %p81;
	xor.b32  	%r532, %r527, %r114;
	bfe.s32 	%r533, %r634, 29, 1;
	xor.b32  	%r534, %r533, %r527;
	xor.b32  	%r535, %r533, %r528;
	cvt.u64.u32 	%rd226, %r534;
	shl.b64 	%rd227, %rd226, 32;
	cvt.u64.u32 	%rd228, %r535;
	or.b64  	%rd229, %rd227, %rd228;
	cvt.rn.f64.s64 	%fd19, %rd229;
	mul.rn.f64 	%fd20, %fd19, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f334, %fd20;
	neg.f32 	%f335, %f334;
	setp.lt.s32 	%p82, %r532, 0;
	selp.f32 	%f407, %f335, %f334, %p82;
$L__BB63_69:
	mul.rn.f32 	%f337, %f407, %f407;
	and.b32  	%r537, %r636, 1;
	setp.eq.b32 	%p83, %r537, 1;
	selp.f32 	%f338, 0f3F800000, %f407, %p83;
	fma.rn.f32 	%f339, %f337, %f338, 0f00000000;
	fma.rn.f32 	%f340, %f337, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f341, %f340, 0fB94D4153, %p83;
	selp.f32 	%f342, 0f3D2AAABB, 0f3C0885E4, %p83;
	fma.rn.f32 	%f343, %f341, %f337, %f342;
	selp.f32 	%f344, 0fBEFFFFFF, 0fBE2AAAA8, %p83;
	fma.rn.f32 	%f345, %f343, %f337, %f344;
	fma.rn.f32 	%f346, %f345, %f339, %f338;
	and.b32  	%r538, %r636, 2;
	setp.eq.s32 	%p84, %r538, 0;
	sub.rn.f32 	%f348, %f200, %f346;
	selp.f32 	%f349, %f346, %f348, %p84;
	shl.b64 	%rd234, %rd45, 3;
	add.s64 	%rd235, %rd161, %rd234;
	ld.global.nc.f32 	%f350, [%rd235+4];
	mul.rn.f32 	%f351, %f350, %f349;
	add.rn.f32 	%f352, %f46, %f351;
	mul.rn.f32 	%f353, %f25, %f352;
	ld.global.nc.f32 	%f354, [%rd49+24];
	add.rn.f32 	%f355, %f354, %f353;
	neg.f32 	%f410, %f355;
	bra.uni 	$L__BB63_87;
$L__BB63_81:
	mov.b32 	%r145, %f17;
	shr.u32 	%r146, %r145, 23;
	and.b32  	%r441, %r146, 224;
	add.s32 	%r442, %r441, -128;
	shl.b32 	%r443, %r145, 8;
	or.b32  	%r447, %r443, -2147483648;
	shr.u32 	%r148, %r442, 5;
	mov.b32 	%r641, 0;
	mov.u64 	%rd265, 0;
	mov.u64 	%rd189, __cudart_i2opi_f;
$L__BB63_82:
	.pragma "nounroll";
	add.s64 	%rd190, %rd189, %rd265;
	ld.global.nc.u32 	%r446, [%rd190];
	// begin inline asm
	{
	mad.lo.cc.u32   %r444, %r446, %r447, %r641;
	madc.hi.u32     %r641, %r446, %r447,  0;
	}
	// end inline asm
	add.s64 	%rd191, %rd6, %rd265;
	st.local.u32 	[%rd191], %r444;
	add.s64 	%rd265, %rd265, 4;
	cvt.u32.u64 	%r449, %rd265;
	setp.ne.s32 	%p62, %r449, 24;
	@%p62 bra 	$L__BB63_82;
	st.local.u32 	[%rd6+24], %r641;
	and.b32  	%r151, %r146, 31;
	mul.wide.u32 	%rd192, %r148, 4;
	sub.s64 	%rd59, %rd6, %rd192;
	ld.local.u32 	%r642, [%rd59+24];
	ld.local.u32 	%r643, [%rd59+20];
	setp.eq.s32 	%p63, %r151, 0;
	@%p63 bra 	$L__BB63_85;
	shl.b32 	%r450, %r643, %r151;
	shl.b32 	%r451, %r642, %r151;
	mov.b32 	%r452, 32;
	sub.s32 	%r453, %r452, %r151;
	shr.u32 	%r454, %r643, %r453;
	add.s32 	%r642, %r454, %r451;
	ld.local.u32 	%r455, [%rd59+16];
	shr.u32 	%r456, %r455, %r453;
	add.s32 	%r643, %r456, %r450;
$L__BB63_85:
	shr.u32 	%r457, %r642, 30;
	shr.u32 	%r458, %r643, 30;
	shl.b32 	%r459, %r642, 2;
	or.b32  	%r460, %r459, %r458;
	shl.b32 	%r461, %r643, 2;
	bfe.u32 	%r462, %r642, 29, 1;
	add.s32 	%r463, %r462, %r457;
	neg.s32 	%r464, %r463;
	setp.lt.s32 	%p64, %r145, 0;
	selp.b32 	%r644, %r464, %r463, %p64;
	xor.b32  	%r465, %r460, %r145;
	bfe.s32 	%r466, %r642, 29, 1;
	xor.b32  	%r467, %r466, %r460;
	xor.b32  	%r468, %r466, %r461;
	cvt.u64.u32 	%rd193, %r467;
	shl.b64 	%rd194, %rd193, 32;
	cvt.u64.u32 	%rd195, %r468;
	or.b64  	%rd196, %rd194, %rd195;
	cvt.rn.f64.s64 	%fd15, %rd196;
	mul.rn.f64 	%fd16, %fd15, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f288, %fd16;
	neg.f32 	%f289, %f288;
	setp.lt.s32 	%p65, %r465, 0;
	selp.f32 	%f409, %f289, %f288, %p65;
$L__BB63_86:
	mul.rn.f32 	%f291, %f409, %f409;
	and.b32  	%r470, %r644, 1;
	setp.eq.b32 	%p66, %r470, 1;
	selp.f32 	%f292, 0f3F800000, %f409, %p66;
	fma.rn.f32 	%f293, %f291, %f292, 0f00000000;
	fma.rn.f32 	%f294, %f291, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f295, %f294, 0fB94D4153, %p66;
	selp.f32 	%f296, 0f3D2AAABB, 0f3C0885E4, %p66;
	fma.rn.f32 	%f297, %f295, %f291, %f296;
	selp.f32 	%f298, 0fBEFFFFFF, 0fBE2AAAA8, %p66;
	fma.rn.f32 	%f299, %f297, %f291, %f298;
	fma.rn.f32 	%f300, %f299, %f293, %f292;
	and.b32  	%r471, %r644, 2;
	setp.eq.s32 	%p67, %r471, 0;
	sub.rn.f32 	%f302, %f200, %f300;
	selp.f32 	%f303, %f300, %f302, %p67;
	ld.global.nc.f32 	%f304, [%rd163];
	mul.rn.f32 	%f305, %f304, %f303;
	add.rn.f32 	%f306, %f54, %f305;
	mul.rn.f32 	%f307, %f25, %f306;
	ld.global.nc.f32 	%f308, [%rd56+24];
	add.rn.f32 	%f410, %f308, %f307;
$L__BB63_87:
	mul.rn.f32 	%f16, %f178, %f177;
	mul.rn.f32 	%f356, %f39, %f410;
	add.rn.f32 	%f357, %f35, %f356;
	mov.u32 	%r648, %r652;
	mov.f32 	%f411, %f412;
	@%p27 bra 	$L__BB63_95;
	@%p101 bra 	$L__BB63_90;
	mul.rn.f32 	%f411, %f17, %f200;
	mov.b32 	%r648, 0;
	bra.uni 	$L__BB63_95;
$L__BB63_90:
	mov.b32 	%r160, %f17;
	shr.u32 	%r161, %r160, 23;
	and.b32  	%r540, %r161, 224;
	add.s32 	%r541, %r540, -128;
	shl.b32 	%r542, %r160, 8;
	or.b32  	%r546, %r542, -2147483648;
	shr.u32 	%r163, %r541, 5;
	mov.b32 	%r645, 0;
	mov.u64 	%rd266, 0;
	mov.u64 	%rd237, __cudart_i2opi_f;
$L__BB63_91:
	.pragma "nounroll";
	add.s64 	%rd238, %rd237, %rd266;
	ld.global.nc.u32 	%r545, [%rd238];
	// begin inline asm
	{
	mad.lo.cc.u32   %r543, %r545, %r546, %r645;
	madc.hi.u32     %r645, %r545, %r546,  0;
	}
	// end inline asm
	add.s64 	%rd239, %rd6, %rd266;
	st.local.u32 	[%rd239], %r543;
	add.s64 	%rd266, %rd266, 4;
	cvt.u32.u64 	%r548, %rd266;
	setp.ne.s32 	%p87, %r548, 24;
	@%p87 bra 	$L__BB63_91;
	st.local.u32 	[%rd6+24], %r645;
	and.b32  	%r166, %r161, 31;
	mul.wide.u32 	%rd240, %r163, 4;
	sub.s64 	%rd62, %rd6, %rd240;
	ld.local.u32 	%r646, [%rd62+24];
	ld.local.u32 	%r647, [%rd62+20];
	setp.eq.s32 	%p88, %r166, 0;
	@%p88 bra 	$L__BB63_94;
	shl.b32 	%r549, %r647, %r166;
	shl.b32 	%r550, %r646, %r166;
	mov.b32 	%r551, 32;
	sub.s32 	%r552, %r551, %r166;
	shr.u32 	%r553, %r647, %r552;
	add.s32 	%r646, %r553, %r550;
	ld.local.u32 	%r554, [%rd62+16];
	shr.u32 	%r555, %r554, %r552;
	add.s32 	%r647, %r555, %r549;
$L__BB63_94:
	shr.u32 	%r556, %r646, 30;
	shr.u32 	%r557, %r647, 30;
	shl.b32 	%r558, %r646, 2;
	or.b32  	%r559, %r558, %r557;
	shl.b32 	%r560, %r647, 2;
	bfe.u32 	%r561, %r646, 29, 1;
	add.s32 	%r562, %r561, %r556;
	neg.s32 	%r563, %r562;
	setp.lt.s32 	%p89, %r160, 0;
	selp.b32 	%r648, %r563, %r562, %p89;
	xor.b32  	%r564, %r559, %r160;
	bfe.s32 	%r565, %r646, 29, 1;
	xor.b32  	%r566, %r565, %r559;
	xor.b32  	%r567, %r565, %r560;
	cvt.u64.u32 	%rd241, %r566;
	shl.b64 	%rd242, %rd241, 32;
	cvt.u64.u32 	%rd243, %r567;
	or.b64  	%rd244, %rd242, %rd243;
	cvt.rn.f64.s64 	%fd21, %rd244;
	mul.rn.f64 	%fd22, %fd21, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f358, %fd22;
	neg.f32 	%f359, %f358;
	setp.lt.s32 	%p90, %r564, 0;
	selp.f32 	%f411, %f359, %f358, %p90;
$L__BB63_95:
	mul.rn.f32 	%f60, %f16, %f357;
	add.s32 	%r569, %r648, 1;
	mul.rn.f32 	%f361, %f411, %f411;
	and.b32  	%r570, %r648, 1;
	setp.eq.b32 	%p92, %r570, 1;
	selp.f32 	%f362, %f411, 0f3F800000, %p92;
	fma.rn.f32 	%f363, %f361, %f362, 0f00000000;
	fma.rn.f32 	%f364, %f361, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f365, 0fB94D4153, %f364, %p92;
	selp.f32 	%f366, 0f3C0885E4, 0f3D2AAABB, %p92;
	fma.rn.f32 	%f367, %f365, %f361, %f366;
	selp.f32 	%f368, 0fBE2AAAA8, 0fBEFFFFFF, %p92;
	fma.rn.f32 	%f369, %f367, %f361, %f368;
	fma.rn.f32 	%f370, %f369, %f363, %f362;
	and.b32  	%r571, %r569, 2;
	setp.eq.s32 	%p93, %r571, 0;
	sub.rn.f32 	%f372, %f200, %f370;
	selp.f32 	%f373, %f370, %f372, %p93;
	ld.global.nc.f32 	%f374, [%rd37+48];
	mul.rn.f32 	%f64, %f374, %f373;
	@%p27 bra 	$L__BB63_103;
	@%p101 bra 	$L__BB63_98;
	mul.rn.f32 	%f412, %f17, %f200;
	mov.b32 	%r652, 0;
	bra.uni 	$L__BB63_103;
$L__BB63_98:
	mov.b32 	%r175, %f17;
	shr.u32 	%r176, %r175, 23;
	and.b32  	%r573, %r176, 224;
	add.s32 	%r574, %r573, -128;
	shl.b32 	%r575, %r175, 8;
	or.b32  	%r579, %r575, -2147483648;
	shr.u32 	%r178, %r574, 5;
	mov.b32 	%r649, 0;
	mov.u64 	%rd267, 0;
	mov.u64 	%rd246, __cudart_i2opi_f;
$L__BB63_99:
	.pragma "nounroll";
	add.s64 	%rd247, %rd246, %rd267;
	ld.global.nc.u32 	%r578, [%rd247];
	// begin inline asm
	{
	mad.lo.cc.u32   %r576, %r578, %r579, %r649;
	madc.hi.u32     %r649, %r578, %r579,  0;
	}
	// end inline asm
	add.s64 	%rd248, %rd6, %rd267;
	st.local.u32 	[%rd248], %r576;
	add.s64 	%rd267, %rd267, 4;
	cvt.u32.u64 	%r581, %rd267;
	setp.ne.s32 	%p95, %r581, 24;
	@%p95 bra 	$L__BB63_99;
	st.local.u32 	[%rd6+24], %r649;
	and.b32  	%r181, %r176, 31;
	mul.wide.u32 	%rd249, %r178, 4;
	sub.s64 	%rd65, %rd6, %rd249;
	ld.local.u32 	%r650, [%rd65+24];
	ld.local.u32 	%r651, [%rd65+20];
	setp.eq.s32 	%p96, %r181, 0;
	@%p96 bra 	$L__BB63_102;
	shl.b32 	%r582, %r651, %r181;
	shl.b32 	%r583, %r650, %r181;
	mov.b32 	%r584, 32;
	sub.s32 	%r585, %r584, %r181;
	shr.u32 	%r586, %r651, %r585;
	add.s32 	%r650, %r586, %r583;
	ld.local.u32 	%r587, [%rd65+16];
	shr.u32 	%r588, %r587, %r585;
	add.s32 	%r651, %r588, %r582;
$L__BB63_102:
	shr.u32 	%r589, %r650, 30;
	shr.u32 	%r590, %r651, 30;
	shl.b32 	%r591, %r650, 2;
	or.b32  	%r592, %r591, %r590;
	shl.b32 	%r593, %r651, 2;
	bfe.u32 	%r594, %r650, 29, 1;
	add.s32 	%r595, %r594, %r589;
	neg.s32 	%r596, %r595;
	setp.lt.s32 	%p97, %r175, 0;
	selp.b32 	%r652, %r596, %r595, %p97;
	xor.b32  	%r597, %r592, %r175;
	bfe.s32 	%r598, %r650, 29, 1;
	xor.b32  	%r599, %r598, %r592;
	xor.b32  	%r600, %r598, %r593;
	cvt.u64.u32 	%rd250, %r599;
	shl.b64 	%rd251, %rd250, 32;
	cvt.u64.u32 	%rd252, %r600;
	or.b64  	%rd253, %rd251, %rd252;
	cvt.rn.f64.s64 	%fd23, %rd253;
	mul.rn.f64 	%fd24, %fd23, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f375, %fd24;
	neg.f32 	%f376, %f375;
	setp.lt.s32 	%p98, %r597, 0;
	selp.f32 	%f412, %f376, %f375, %p98;
$L__BB63_103:
	mul.rn.f32 	%f378, %f412, %f412;
	and.b32  	%r602, %r652, 1;
	setp.eq.b32 	%p99, %r602, 1;
	selp.f32 	%f379, 0f3F800000, %f412, %p99;
	fma.rn.f32 	%f380, %f378, %f379, 0f00000000;
	fma.rn.f32 	%f381, %f378, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f382, %f381, 0fB94D4153, %p99;
	selp.f32 	%f383, 0f3D2AAABB, 0f3C0885E4, %p99;
	fma.rn.f32 	%f384, %f382, %f378, %f383;
	selp.f32 	%f385, 0fBEFFFFFF, 0fBE2AAAA8, %p99;
	fma.rn.f32 	%f386, %f384, %f378, %f385;
	fma.rn.f32 	%f387, %f386, %f380, %f379;
	and.b32  	%r603, %r652, 2;
	setp.eq.s32 	%p100, %r603, 0;
	sub.rn.f32 	%f389, %f200, %f387;
	selp.f32 	%f390, %f387, %f389, %p100;
	ld.global.nc.f32 	%f391, [%rd41+24];
	mul.rn.f32 	%f392, %f391, %f390;
	add.rn.f32 	%f393, %f64, %f392;
	mul.rn.f32 	%f394, %f25, %f393;
	ld.global.nc.f32 	%f395, [%rd37+72];
	add.rn.f32 	%f396, %f395, %f394;
	add.rn.f32 	%f399, %f60, %f396;
$L__BB63_2:
	add.rn.f32 	%f397, %f398, %f399;
	mul.wide.u32 	%rd254, %r1, 4;
	add.s64 	%rd255, %rd1, %rd254;
	st.global.f32 	[%rd255], %f397;
	ret;

}
	// .globl	input_concatenate_fusion_189
.visible .entry input_concatenate_fusion_189(
	.param .u64 input_concatenate_fusion_189_param_0,
	.param .u64 input_concatenate_fusion_189_param_1,
	.param .u64 input_concatenate_fusion_189_param_2,
	.param .u64 input_concatenate_fusion_189_param_3,
	.param .u64 input_concatenate_fusion_189_param_4
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot64[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<120>;
	.reg .f32 	%f<97>;
	.reg .b64 	%rd<81>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot64;
	ld.param.u64 	%rd15, [input_concatenate_fusion_189_param_0];
	ld.param.u64 	%rd16, [input_concatenate_fusion_189_param_4];
	cvta.to.global.u64 	%rd17, %rd16;
	ld.param.u64 	%rd18, [input_concatenate_fusion_189_param_1];
	ld.param.u64 	%rd19, [input_concatenate_fusion_189_param_3];
	cvta.to.global.u64 	%rd20, %rd19;
	ld.param.u64 	%rd21, [input_concatenate_fusion_189_param_2];
	cvta.to.global.u64 	%rd22, %rd21;
	cvta.to.global.u64 	%rd1, %rd18;
	cvta.to.global.u64 	%rd23, %rd15;
	add.u64 	%rd2, %SPL, 0;
	mov.u32 	%r33, %ctaid.x;
	mov.u32 	%r34, %tid.x;
	shl.b32 	%r35, %r33, 7;
	or.b32  	%r36, %r35, %r34;
	cvt.u16.u32 	%rs2, %r36;
	mul.hi.u16 	%rs3, %rs2, -21845;
	shr.u16 	%rs4, %rs3, 2;
	mul.lo.s16 	%rs5, %rs4, 6;
	sub.s16 	%rs1, %rs2, %rs5;
	cvt.u32.u16 	%r1, %rs1;
	mul.hi.u16 	%rs6, %rs4, 5243;
	shr.u16 	%rs7, %rs6, 2;
	mul.lo.s16 	%rs8, %rs7, 50;
	sub.s16 	%rs9, %rs4, %rs8;
	shr.u16 	%rs10, %rs2, 2;
	mul.hi.u16 	%rs11, %rs10, 27963;
	shr.u16 	%rs12, %rs11, 5;
	and.b16  	%rs13, %rs12, 63;
	cvt.u64.u16 	%rd4, %rs13;
	cvt.u64.u16 	%rd5, %rs9;
	cvt.u64.u16 	%rd6, %rs1;
	cvt.u32.u16 	%r37, %rs9;
	mul.wide.u32 	%rd26, %r37, 96;
	cvt.u32.u16 	%r38, %rs13;
	mul.wide.u32 	%rd27, %r38, 4800;
	add.s64 	%rd28, %rd23, %rd27;
	add.s64 	%rd29, %rd28, %rd26;
	mul.wide.u32 	%rd30, %r1, 4;
	add.s64 	%rd7, %rd29, %rd30;
	ld.global.nc.f32 	%f15, [%rd7];
	mul.wide.u32 	%rd31, %r37, 48;
	mul.wide.u32 	%rd32, %r38, 2400;
	add.s64 	%rd33, %rd17, %rd32;
	add.s64 	%rd34, %rd33, %rd31;
	add.s64 	%rd8, %rd34, %rd30;
	st.global.f32 	[%rd8], %f15;
	mul.wide.u32 	%rd35, %r38, 4;
	add.s64 	%rd36, %rd22, %rd35;
	ld.global.nc.f32 	%f1, [%rd36];
	shr.u32 	%r39, %r1, 1;
	mul.wide.u32 	%rd37, %r39, 4;
	mul.wide.u32 	%rd38, %r38, 12;
	add.s64 	%rd39, %rd20, %rd38;
	add.s64 	%rd40, %rd39, %rd37;
	ld.global.nc.f32 	%f16, [%rd40];
	add.rn.f32 	%f17, %f16, %f16;
	add.rn.f32 	%f18, %f17, %f17;
	add.rn.f32 	%f19, %f18, %f18;
	add.rn.f32 	%f2, %f19, %f19;
	mul.rn.f32 	%f20, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r119, %f20;
	cvt.rn.f32.s32 	%f21, %r119;
	fma.rn.f32 	%f22, %f21, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f23, %f21, 0fB3A22168, %f22;
	fma.rn.f32 	%f95, %f21, 0fA7C234C5, %f23;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p1, %f4, 0f47CE4780;
	setp.neu.f32 	%p21, %f4, 0f7F800000;
	mov.f32 	%f93, 0f00000000;
	mov.u32 	%r115, %r119;
	mov.f32 	%f94, %f95;
	@%p1 bra 	$L__BB64_8;
	@%p21 bra 	$L__BB64_3;
	mul.rn.f32 	%f94, %f2, %f93;
	mov.b32 	%r115, 0;
	bra.uni 	$L__BB64_8;
$L__BB64_3:
	mov.b32 	%r3, %f2;
	shr.u32 	%r4, %r3, 23;
	and.b32  	%r41, %r4, 224;
	add.s32 	%r42, %r41, -128;
	shl.b32 	%r43, %r3, 8;
	or.b32  	%r47, %r43, -2147483648;
	shr.u32 	%r6, %r42, 5;
	mov.b32 	%r112, 0;
	mov.u64 	%rd79, 0;
	mov.u64 	%rd42, __cudart_i2opi_f;
$L__BB64_4:
	.pragma "nounroll";
	add.s64 	%rd43, %rd42, %rd79;
	ld.global.nc.u32 	%r46, [%rd43];
	// begin inline asm
	{
	mad.lo.cc.u32   %r44, %r46, %r47, %r112;
	madc.hi.u32     %r112, %r46, %r47,  0;
	}
	// end inline asm
	add.s64 	%rd44, %rd2, %rd79;
	st.local.u32 	[%rd44], %r44;
	add.s64 	%rd79, %rd79, 4;
	cvt.u32.u64 	%r49, %rd79;
	setp.ne.s32 	%p3, %r49, 24;
	@%p3 bra 	$L__BB64_4;
	st.local.u32 	[%rd2+24], %r112;
	and.b32  	%r9, %r4, 31;
	mul.wide.u32 	%rd45, %r6, 4;
	sub.s64 	%rd11, %rd2, %rd45;
	ld.local.u32 	%r113, [%rd11+24];
	ld.local.u32 	%r114, [%rd11+20];
	setp.eq.s32 	%p4, %r9, 0;
	@%p4 bra 	$L__BB64_7;
	shl.b32 	%r50, %r114, %r9;
	shl.b32 	%r51, %r113, %r9;
	mov.b32 	%r52, 32;
	sub.s32 	%r53, %r52, %r9;
	shr.u32 	%r54, %r114, %r53;
	add.s32 	%r113, %r54, %r51;
	ld.local.u32 	%r55, [%rd11+16];
	shr.u32 	%r56, %r55, %r53;
	add.s32 	%r114, %r56, %r50;
$L__BB64_7:
	shr.u32 	%r57, %r113, 30;
	shr.u32 	%r58, %r114, 30;
	shl.b32 	%r59, %r113, 2;
	or.b32  	%r60, %r59, %r58;
	shl.b32 	%r61, %r114, 2;
	bfe.u32 	%r62, %r113, 29, 1;
	add.s32 	%r63, %r62, %r57;
	neg.s32 	%r64, %r63;
	setp.lt.s32 	%p5, %r3, 0;
	selp.b32 	%r115, %r64, %r63, %p5;
	xor.b32  	%r65, %r60, %r3;
	bfe.s32 	%r66, %r113, 29, 1;
	xor.b32  	%r67, %r66, %r60;
	xor.b32  	%r68, %r66, %r61;
	cvt.u64.u32 	%rd46, %r67;
	shl.b64 	%rd47, %rd46, 32;
	cvt.u64.u32 	%rd48, %r68;
	or.b64  	%rd49, %rd47, %rd48;
	cvt.rn.f64.s64 	%fd1, %rd49;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f24, %fd2;
	neg.f32 	%f25, %f24;
	setp.lt.s32 	%p6, %r65, 0;
	selp.f32 	%f94, %f25, %f24, %p6;
$L__BB64_8:
	mul.lo.s64 	%rd50, %rd4, 2400;
	add.s64 	%rd51, %rd1, %rd50;
	mul.lo.s64 	%rd52, %rd5, 48;
	add.s64 	%rd53, %rd51, %rd52;
	shl.b64 	%rd54, %rd6, 2;
	add.s64 	%rd55, %rd53, %rd54;
	ld.global.nc.f32 	%f8, [%rd55];
	@%p1 bra 	$L__BB64_16;
	@%p21 bra 	$L__BB64_11;
	mul.rn.f32 	%f95, %f2, %f93;
	mov.b32 	%r119, 0;
	bra.uni 	$L__BB64_16;
$L__BB64_11:
	mov.b32 	%r18, %f2;
	shr.u32 	%r19, %r18, 23;
	and.b32  	%r71, %r19, 224;
	add.s32 	%r72, %r71, -128;
	shl.b32 	%r73, %r18, 8;
	or.b32  	%r77, %r73, -2147483648;
	shr.u32 	%r21, %r72, 5;
	mov.b32 	%r116, 0;
	mov.u64 	%rd80, 0;
	mov.u64 	%rd57, __cudart_i2opi_f;
$L__BB64_12:
	.pragma "nounroll";
	add.s64 	%rd58, %rd57, %rd80;
	ld.global.nc.u32 	%r76, [%rd58];
	// begin inline asm
	{
	mad.lo.cc.u32   %r74, %r76, %r77, %r116;
	madc.hi.u32     %r116, %r76, %r77,  0;
	}
	// end inline asm
	add.s64 	%rd59, %rd2, %rd80;
	st.local.u32 	[%rd59], %r74;
	add.s64 	%rd80, %rd80, 4;
	cvt.u32.u64 	%r79, %rd80;
	setp.ne.s32 	%p9, %r79, 24;
	@%p9 bra 	$L__BB64_12;
	st.local.u32 	[%rd2+24], %r116;
	and.b32  	%r24, %r19, 31;
	mul.wide.u32 	%rd60, %r21, 4;
	sub.s64 	%rd14, %rd2, %rd60;
	ld.local.u32 	%r117, [%rd14+24];
	ld.local.u32 	%r118, [%rd14+20];
	setp.eq.s32 	%p10, %r24, 0;
	@%p10 bra 	$L__BB64_15;
	shl.b32 	%r80, %r118, %r24;
	shl.b32 	%r81, %r117, %r24;
	mov.b32 	%r82, 32;
	sub.s32 	%r83, %r82, %r24;
	shr.u32 	%r84, %r118, %r83;
	add.s32 	%r117, %r84, %r81;
	ld.local.u32 	%r85, [%rd14+16];
	shr.u32 	%r86, %r85, %r83;
	add.s32 	%r118, %r86, %r80;
$L__BB64_15:
	shr.u32 	%r87, %r117, 30;
	shr.u32 	%r88, %r118, 30;
	shl.b32 	%r89, %r117, 2;
	or.b32  	%r90, %r89, %r88;
	shl.b32 	%r91, %r118, 2;
	bfe.u32 	%r92, %r117, 29, 1;
	add.s32 	%r93, %r92, %r87;
	neg.s32 	%r94, %r93;
	setp.lt.s32 	%p11, %r18, 0;
	selp.b32 	%r119, %r94, %r93, %p11;
	xor.b32  	%r95, %r90, %r18;
	bfe.s32 	%r96, %r117, 29, 1;
	xor.b32  	%r97, %r96, %r90;
	xor.b32  	%r98, %r96, %r91;
	cvt.u64.u32 	%rd61, %r97;
	shl.b64 	%rd62, %rd61, 32;
	cvt.u64.u32 	%rd63, %r98;
	or.b64  	%rd64, %rd62, %rd63;
	cvt.rn.f64.s64 	%fd3, %rd64;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f27, %fd4;
	neg.f32 	%f28, %f27;
	setp.lt.s32 	%p12, %r95, 0;
	selp.f32 	%f95, %f28, %f27, %p12;
$L__BB64_16:
	and.b32  	%r100, %r1, 1;
	setp.eq.b32 	%p13, %r100, 1;
	mov.pred 	%p14, 0;
	xor.pred  	%p15, %p13, %p14;
	@%p15 bra 	$L__BB64_18;
	or.b32  	%r102, %r1, 1;
	setp.gt.u16 	%p16, %rs1, 3;
	cvt.u64.u32 	%rd71, %r102;
	selp.b64 	%rd72, 5, %rd71, %p16;
	shl.b64 	%rd77, %rd72, 2;
	add.s64 	%rd78, %rd53, %rd77;
	ld.global.nc.f32 	%f30, [%rd78];
	neg.f32 	%f96, %f30;
	bra.uni 	$L__BB64_19;
$L__BB64_18:
	and.b32  	%r101, %r1, 6;
	mul.wide.u32 	%rd69, %r101, 4;
	add.s64 	%rd70, %rd53, %rd69;
	ld.global.nc.f32 	%f96, [%rd70];
$L__BB64_19:
	and.b32  	%r103, %r119, 2;
	setp.eq.s32 	%p17, %r103, 0;
	and.b32  	%r104, %r119, 1;
	setp.eq.b32 	%p18, %r104, 1;
	mul.rn.f32 	%f31, %f95, %f95;
	fma.rn.f32 	%f32, %f31, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f33, %f32, 0fB94D4153, %p18;
	selp.f32 	%f34, 0f3D2AAABB, 0f3C0885E4, %p18;
	fma.rn.f32 	%f35, %f33, %f31, %f34;
	selp.f32 	%f36, 0fBEFFFFFF, 0fBE2AAAA8, %p18;
	fma.rn.f32 	%f37, %f35, %f31, %f36;
	selp.f32 	%f38, 0f3F800000, %f95, %p18;
	fma.rn.f32 	%f39, %f31, %f38, 0f00000000;
	fma.rn.f32 	%f40, %f37, %f39, %f38;
	sub.rn.f32 	%f42, %f93, %f40;
	selp.f32 	%f43, %f40, %f42, %p17;
	add.s32 	%r105, %r115, 1;
	and.b32  	%r106, %r105, 2;
	setp.eq.s32 	%p19, %r106, 0;
	and.b32  	%r107, %r115, 1;
	setp.eq.b32 	%p20, %r107, 1;
	mul.rn.f32 	%f44, %f94, %f94;
	fma.rn.f32 	%f45, %f44, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f46, 0fB94D4153, %f45, %p20;
	selp.f32 	%f47, 0f3C0885E4, 0f3D2AAABB, %p20;
	fma.rn.f32 	%f48, %f46, %f44, %f47;
	selp.f32 	%f49, 0fBE2AAAA8, 0fBEFFFFFF, %p20;
	fma.rn.f32 	%f50, %f48, %f44, %f49;
	selp.f32 	%f51, %f94, 0f3F800000, %p20;
	fma.rn.f32 	%f52, %f44, %f51, 0f00000000;
	fma.rn.f32 	%f53, %f50, %f52, %f51;
	sub.rn.f32 	%f54, %f93, %f53;
	selp.f32 	%f55, %f53, %f54, %p19;
	mul.rn.f32 	%f56, %f8, %f55;
	fma.rn.f32 	%f57, %f1, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f58, %f57;
	mov.f32 	%f59, 0f4B400001;
	mov.f32 	%f60, 0f437C0000;
	fma.rm.f32 	%f61, %f58, %f60, %f59;
	add.rn.f32 	%f62, %f61, 0fCB40007F;
	neg.f32 	%f63, %f62;
	fma.rn.f32 	%f64, %f1, 0f3FB8AA3B, %f63;
	fma.rn.f32 	%f65, %f1, 0f32A57060, %f64;
	ex2.approx.ftz.f32 	%f66, %f65;
	mov.b32 	%r108, %f61;
	shl.b32 	%r109, %r108, 23;
	mov.b32 	%f67, %r109;
	mul.rn.f32 	%f68, %f66, %f67;
	neg.f32 	%f69, %f68;
	sub.rn.f32 	%f70, %f69, %f68;
	add.rn.f32 	%f71, %f70, %f70;
	add.rn.f32 	%f72, %f71, %f71;
	add.rn.f32 	%f73, %f72, %f72;
	add.rn.f32 	%f74, %f73, %f73;
	add.rn.f32 	%f75, %f74, %f74;
	add.rn.f32 	%f76, %f75, %f75;
	add.rn.f32 	%f77, %f76, %f76;
	fma.rn.f32 	%f78, %f77, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f79, %f78;
	fma.rm.f32 	%f80, %f79, %f60, %f59;
	add.rn.f32 	%f81, %f80, 0fCB40007F;
	neg.f32 	%f82, %f81;
	fma.rn.f32 	%f83, %f77, 0f3FB8AA3B, %f82;
	fma.rn.f32 	%f84, %f77, 0f32A57060, %f83;
	ex2.approx.ftz.f32 	%f85, %f84;
	mov.b32 	%r110, %f80;
	shl.b32 	%r111, %r110, 23;
	mov.b32 	%f86, %r111;
	mul.rn.f32 	%f87, %f85, %f86;
	mul.rn.f32 	%f88, %f43, %f96;
	add.rn.f32 	%f89, %f56, %f88;
	mul.rn.f32 	%f90, %f89, %f87;
	ld.global.nc.f32 	%f91, [%rd7+48];
	add.rn.f32 	%f92, %f91, %f90;
	st.global.f32 	[%rd8+24], %f92;
	ret;

}
	// .globl	input_concatenate_fusion_190
.visible .entry input_concatenate_fusion_190(
	.param .u64 input_concatenate_fusion_190_param_0,
	.param .u64 input_concatenate_fusion_190_param_1,
	.param .u64 input_concatenate_fusion_190_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<21>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<20>;
	.reg .b64 	%rd<48>;

	ld.param.u64 	%rd14, [input_concatenate_fusion_190_param_0];
	ld.param.u64 	%rd15, [input_concatenate_fusion_190_param_2];
	ld.param.u64 	%rd16, [input_concatenate_fusion_190_param_1];
	cvta.to.global.u64 	%rd2, %rd16;
	cvta.to.global.u64 	%rd3, %rd14;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 7;
	or.b32  	%r5, %r4, %r3;
	cvt.u16.u32 	%rs4, %r5;
	mul.hi.u16 	%rs5, %rs4, -21845;
	shr.u16 	%rs6, %rs5, 1;
	mul.lo.s16 	%rs7, %rs6, 3;
	sub.s16 	%rs1, %rs4, %rs7;
	mul.hi.u16 	%rs8, %rs6, 21846;
	mul.lo.s16 	%rs9, %rs8, 3;
	sub.s16 	%rs2, %rs6, %rs9;
	cvt.u32.u16 	%r6, %rs2;
	mul.hi.u16 	%rs10, %rs4, -7281;
	shr.u16 	%rs11, %rs10, 3;
	mul.hi.u16 	%rs12, %rs11, 5243;
	shr.u16 	%rs13, %rs12, 2;
	mul.lo.s16 	%rs14, %rs13, 50;
	sub.s16 	%rs15, %rs11, %rs14;
	mul.hi.u16 	%rs16, %rs4, -28253;
	shr.u16 	%rs17, %rs16, 8;
	and.b16  	%rs18, %rs17, 63;
	shl.b16 	%rs3, %rs1, 1;
	or.b16  	%rs19, %rs3, 1;
	setp.gt.u16 	%p1, %rs1, 1;
	selp.b16 	%rs20, 5, %rs19, %p1;
	and.b32  	%r1, %r6, 1;
	setp.eq.s32 	%p2, %r1, 0;
	cvt.u64.u16 	%rd4, %rs18;
	cvt.u64.u16 	%rd5, %rs15;
	shr.u32 	%r7, %r6, 1;
	mov.f32 	%f19, 0f00000000;
	mov.f32 	%f16, %f19;
	@%p2 bra 	$L__BB65_6;
	bra.uni 	$L__BB65_1;
$L__BB65_6:
	cvt.u32.u16 	%r8, %rs15;
	mul.wide.u32 	%rd17, %r8, 48;
	cvt.u32.u16 	%r9, %rs18;
	mul.wide.u32 	%rd18, %r9, 2400;
	add.s64 	%rd19, %rd2, %rd18;
	add.s64 	%rd20, %rd19, %rd17;
	mul.wide.u32 	%rd21, %r7, 24;
	add.s64 	%rd22, %rd20, %rd21;
	cvt.u32.u16 	%r10, %rs20;
	mul.wide.u32 	%rd23, %r10, 4;
	add.s64 	%rd8, %rd22, %rd23;
	ld.global.nc.f32 	%f16, [%rd8];
$L__BB65_1:
	cvta.to.global.u64 	%rd1, %rd15;
	setp.ne.s32 	%p3, %r1, 0;
	mul.lo.s64 	%rd24, %rd4, 2400;
	add.s64 	%rd25, %rd3, %rd24;
	mul.lo.s64 	%rd26, %rd5, 48;
	add.s64 	%rd27, %rd25, %rd26;
	mov.f32 	%f17, %f19;
	@%p3 bra 	$L__BB65_7;
	bra.uni 	$L__BB65_2;
$L__BB65_7:
	cvt.u64.u16 	%rd7, %rs20;
	shl.b64 	%rd28, %rd7, 2;
	add.s64 	%rd9, %rd27, %rd28;
	ld.global.nc.f32 	%f17, [%rd9];
$L__BB65_2:
	add.rn.f32 	%f12, %f16, %f17;
	neg.f32 	%f13, %f12;
	mul.lo.s64 	%rd29, %rd4, 3600;
	add.s64 	%rd30, %rd1, %rd29;
	mul.lo.s64 	%rd31, %rd5, 72;
	add.s64 	%rd32, %rd30, %rd31;
	mul.wide.u32 	%rd33, %r6, 24;
	add.s64 	%rd34, %rd32, %rd33;
	cvt.u32.u16 	%r12, %rs1;
	mul.wide.u32 	%rd35, %r12, 8;
	add.s64 	%rd10, %rd34, %rd35;
	st.global.f32 	[%rd10], %f13;
	mov.f32 	%f18, %f19;
	@%p2 bra 	$L__BB65_3;
	bra.uni 	$L__BB65_4;
$L__BB65_3:
	cvt.u64.u32 	%rd6, %r7;
	add.s64 	%rd37, %rd2, %rd24;
	add.s64 	%rd39, %rd37, %rd26;
	mul.lo.s64 	%rd40, %rd6, 24;
	add.s64 	%rd41, %rd39, %rd40;
	cvt.u32.u16 	%r13, %rs3;
	mul.wide.u32 	%rd42, %r13, 4;
	add.s64 	%rd12, %rd41, %rd42;
	ld.global.nc.f32 	%f18, [%rd12];
$L__BB65_4:
	@%p3 bra 	$L__BB65_8;
	bra.uni 	$L__BB65_5;
$L__BB65_8:
	cvt.u64.u16 	%rd11, %rs3;
	shl.b64 	%rd47, %rd11, 2;
	add.s64 	%rd13, %rd27, %rd47;
	ld.global.nc.f32 	%f19, [%rd13];
$L__BB65_5:
	add.rn.f32 	%f15, %f18, %f19;
	st.global.f32 	[%rd10+4], %f15;
	ret;

}
	// .globl	input_concatenate_fusion_191
.visible .entry input_concatenate_fusion_191(
	.param .u64 input_concatenate_fusion_191_param_0,
	.param .u64 input_concatenate_fusion_191_param_1,
	.param .u64 input_concatenate_fusion_191_param_2,
	.param .u64 input_concatenate_fusion_191_param_3,
	.param .u64 input_concatenate_fusion_191_param_4,
	.param .u64 input_concatenate_fusion_191_param_5,
	.param .u64 input_concatenate_fusion_191_param_6,
	.param .u64 input_concatenate_fusion_191_param_7
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot66[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<54>;
	.reg .b16 	%rs<16>;
	.reg .b32 	%r<352>;
	.reg .f32 	%f<249>;
	.reg .b64 	%rd<192>;
	.reg .f64 	%fd<13>;

	mov.u64 	%SPL, __local_depot66;
	ld.param.u64 	%rd46, [input_concatenate_fusion_191_param_0];
	ld.param.u64 	%rd47, [input_concatenate_fusion_191_param_7];
	cvta.to.global.u64 	%rd1, %rd47;
	ld.param.u64 	%rd49, [input_concatenate_fusion_191_param_6];
	cvta.to.global.u64 	%rd2, %rd49;
	ld.param.u64 	%rd51, [input_concatenate_fusion_191_param_5];
	cvta.to.global.u64 	%rd3, %rd51;
	ld.param.u64 	%rd53, [input_concatenate_fusion_191_param_4];
	cvta.to.global.u64 	%rd4, %rd53;
	cvta.to.global.u64 	%rd8, %rd46;
	add.u64 	%rd9, %SPL, 0;
	mov.u32 	%r101, %ctaid.x;
	mov.u32 	%r102, %tid.x;
	shl.b32 	%r103, %r101, 7;
	or.b32  	%r1, %r103, %r102;
	cvt.u16.u32 	%rs1, %r1;
	mul.hi.u16 	%rs5, %rs1, -21845;
	shr.u16 	%rs2, %rs5, 2;
	mul.lo.s16 	%rs6, %rs2, 6;
	sub.s16 	%rs3, %rs1, %rs6;
	cvt.u32.u16 	%r2, %rs3;
	setp.lt.u32 	%p1, %r1, 19200;
	mov.f32 	%f238, 0f4B400001;
	mov.f32 	%f239, 0f437C0000;
	shr.u32 	%r326, %r2, 1;
	cvt.u64.u16 	%rd184, %rs3;
	and.b32  	%r327, %r2, 1;
	@%p1 bra 	$L__BB66_16;
	bra.uni 	$L__BB66_1;
$L__BB66_16:
	shr.u16 	%rs7, %rs1, 2;
	mul.hi.u16 	%rs8, %rs7, 27963;
	shr.u16 	%rs9, %rs8, 5;
	mul.hi.u16 	%rs10, %rs2, 5243;
	shr.u16 	%rs11, %rs10, 2;
	mul.lo.s16 	%rs12, %rs11, 50;
	sub.s16 	%rs4, %rs2, %rs12;
	cvt.u64.u16 	%rd24, %rs9;
	cvt.u32.u16 	%r105, %rs9;
	mul.wide.u32 	%rd60, %r105, 4;
	add.s64 	%rd61, %rd3, %rd60;
	ld.global.nc.f32 	%f37, [%rd61];
	fma.rn.f32 	%f38, %f37, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f39, %f38;
	fma.rm.f32 	%f42, %f39, %f239, %f238;
	add.rn.f32 	%f43, %f42, 0fCB40007F;
	neg.f32 	%f44, %f43;
	fma.rn.f32 	%f45, %f37, 0f3FB8AA3B, %f44;
	fma.rn.f32 	%f46, %f37, 0f32A57060, %f45;
	mov.b32 	%r106, %f42;
	shl.b32 	%r107, %r106, 23;
	mov.b32 	%f47, %r107;
	ex2.approx.ftz.f32 	%f48, %f46;
	mul.rn.f32 	%f49, %f48, %f47;
	neg.f32 	%f50, %f49;
	sub.rn.f32 	%f51, %f50, %f49;
	add.rn.f32 	%f52, %f51, %f51;
	add.rn.f32 	%f53, %f52, %f52;
	add.rn.f32 	%f54, %f53, %f53;
	add.rn.f32 	%f55, %f54, %f54;
	add.rn.f32 	%f56, %f55, %f55;
	fma.rn.f32 	%f57, %f56, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f58, %f57;
	fma.rm.f32 	%f59, %f58, %f239, %f238;
	add.rn.f32 	%f60, %f59, 0fCB40007F;
	neg.f32 	%f61, %f60;
	fma.rn.f32 	%f62, %f56, 0f3FB8AA3B, %f61;
	fma.rn.f32 	%f63, %f56, 0f32A57060, %f62;
	mov.b32 	%r108, %f59;
	shl.b32 	%r109, %r108, 23;
	mov.b32 	%f64, %r109;
	ex2.approx.ftz.f32 	%f65, %f63;
	mul.wide.u32 	%rd62, %r105, 12;
	add.s64 	%rd63, %rd4, %rd62;
	mul.wide.u32 	%rd64, %r326, 4;
	add.s64 	%rd65, %rd63, %rd64;
	ld.global.nc.f32 	%f66, [%rd65];
	add.rn.f32 	%f67, %f66, %f66;
	add.rn.f32 	%f10, %f67, %f67;
	mul.rn.f32 	%f68, %f10, 0f3F22F983;
	cvt.rni.s32.f32 	%r339, %f68;
	cvt.rn.f32.s32 	%f69, %r339;
	fma.rn.f32 	%f70, %f69, 0fBFC90FDA, %f10;
	fma.rn.f32 	%f71, %f69, 0fB3A22168, %f70;
	fma.rn.f32 	%f243, %f69, 0fA7C234C5, %f71;
	abs.f32 	%f12, %f10;
	setp.ltu.f32 	%p2, %f12, 0f47CE4780;
	mov.u32 	%r335, %r339;
	mov.f32 	%f242, %f243;
	@%p2 bra 	$L__BB66_24;
	setp.neu.f32 	%p3, %f12, 0f7F800000;
	@%p3 bra 	$L__BB66_19;
	mov.f32 	%f74, 0f00000000;
	mul.rn.f32 	%f242, %f10, %f74;
	mov.b32 	%r335, 0;
	bra.uni 	$L__BB66_24;
$L__BB66_1:
	cvt.u64.u32 	%rd16, %r326;
	bra.uni 	$L__BB66_2;
$L__BB66_19:
	mov.b32 	%r23, %f10;
	shr.u32 	%r24, %r23, 23;
	and.b32  	%r112, %r24, 224;
	add.s32 	%r113, %r112, -128;
	shl.b32 	%r114, %r23, 8;
	or.b32  	%r118, %r114, -2147483648;
	shr.u32 	%r26, %r113, 5;
	mov.b32 	%r332, 0;
	mov.u64 	%rd187, 0;
	mov.u64 	%rd67, __cudart_i2opi_f;
$L__BB66_20:
	.pragma "nounroll";
	add.s64 	%rd68, %rd67, %rd187;
	ld.global.nc.u32 	%r117, [%rd68];
	// begin inline asm
	{
	mad.lo.cc.u32   %r115, %r117, %r118, %r332;
	madc.hi.u32     %r332, %r117, %r118,  0;
	}
	// end inline asm
	add.s64 	%rd69, %rd9, %rd187;
	st.local.u32 	[%rd69], %r115;
	add.s64 	%rd187, %rd187, 4;
	cvt.u32.u64 	%r120, %rd187;
	setp.ne.s32 	%p4, %r120, 24;
	@%p4 bra 	$L__BB66_20;
	st.local.u32 	[%rd9+24], %r332;
	and.b32  	%r29, %r24, 31;
	mul.wide.u32 	%rd70, %r26, 4;
	sub.s64 	%rd28, %rd9, %rd70;
	ld.local.u32 	%r333, [%rd28+24];
	ld.local.u32 	%r334, [%rd28+20];
	setp.eq.s32 	%p5, %r29, 0;
	@%p5 bra 	$L__BB66_23;
	shl.b32 	%r121, %r334, %r29;
	shl.b32 	%r122, %r333, %r29;
	mov.b32 	%r123, 32;
	sub.s32 	%r124, %r123, %r29;
	shr.u32 	%r125, %r334, %r124;
	add.s32 	%r333, %r125, %r122;
	ld.local.u32 	%r126, [%rd28+16];
	shr.u32 	%r127, %r126, %r124;
	add.s32 	%r334, %r127, %r121;
$L__BB66_23:
	shr.u32 	%r128, %r333, 30;
	shr.u32 	%r129, %r334, 30;
	shl.b32 	%r130, %r333, 2;
	or.b32  	%r131, %r130, %r129;
	shl.b32 	%r132, %r334, 2;
	bfe.u32 	%r133, %r333, 29, 1;
	add.s32 	%r134, %r133, %r128;
	neg.s32 	%r135, %r134;
	setp.lt.s32 	%p6, %r23, 0;
	selp.b32 	%r335, %r135, %r134, %p6;
	xor.b32  	%r136, %r131, %r23;
	bfe.s32 	%r137, %r333, 29, 1;
	xor.b32  	%r138, %r137, %r131;
	xor.b32  	%r139, %r137, %r132;
	cvt.u64.u32 	%rd71, %r138;
	shl.b64 	%rd72, %rd71, 32;
	cvt.u64.u32 	%rd73, %r139;
	or.b64  	%rd74, %rd72, %rd73;
	cvt.rn.f64.s64 	%fd1, %rd74;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f72, %fd2;
	neg.f32 	%f73, %f72;
	setp.lt.s32 	%p7, %r136, 0;
	selp.f32 	%f242, %f73, %f72, %p7;
$L__BB66_24:
	mul.rn.f32 	%f9, %f65, %f64;
	cvt.u64.u32 	%rd16, %r326;
	add.s32 	%r141, %r335, 1;
	mul.rn.f32 	%f75, %f242, %f242;
	and.b32  	%r142, %r335, 1;
	setp.eq.b32 	%p9, %r142, 1;
	selp.f32 	%f76, %f242, 0f3F800000, %p9;
	fma.rn.f32 	%f77, %f75, %f76, 0f00000000;
	fma.rn.f32 	%f78, %f75, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f79, 0fB94D4153, %f78, %p9;
	selp.f32 	%f80, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f81, %f79, %f75, %f80;
	selp.f32 	%f82, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f83, %f81, %f75, %f82;
	fma.rn.f32 	%f84, %f83, %f77, %f76;
	and.b32  	%r143, %r141, 2;
	setp.eq.s32 	%p10, %r143, 0;
	mov.f32 	%f85, 0f00000000;
	sub.rn.f32 	%f86, %f85, %f84;
	selp.f32 	%f87, %f84, %f86, %p10;
	cvt.u64.u16 	%rd29, %rs4;
	mul.lo.s64 	%rd75, %rd24, 19200;
	add.s64 	%rd76, %rd8, %rd75;
	cvt.u32.u16 	%r144, %rs4;
	mul.wide.u32 	%rd77, %r144, 384;
	add.s64 	%rd78, %rd76, %rd77;
	mul.wide.u32 	%rd79, %r2, 4;
	add.s64 	%rd31, %rd78, %rd79;
	ld.global.nc.f32 	%f88, [%rd31];
	mul.rn.f32 	%f16, %f88, %f87;
	@%p2 bra 	$L__BB66_32;
	setp.neu.f32 	%p11, %f12, 0f7F800000;
	@%p11 bra 	$L__BB66_27;
	mul.rn.f32 	%f243, %f10, %f85;
	mov.b32 	%r339, 0;
	bra.uni 	$L__BB66_32;
$L__BB66_27:
	mov.b32 	%r38, %f10;
	shr.u32 	%r39, %r38, 23;
	and.b32  	%r147, %r39, 224;
	add.s32 	%r148, %r147, -128;
	shl.b32 	%r149, %r38, 8;
	or.b32  	%r153, %r149, -2147483648;
	shr.u32 	%r41, %r148, 5;
	mov.b32 	%r336, 0;
	mov.u64 	%rd188, 0;
	mov.u64 	%rd81, __cudart_i2opi_f;
$L__BB66_28:
	.pragma "nounroll";
	add.s64 	%rd82, %rd81, %rd188;
	ld.global.nc.u32 	%r152, [%rd82];
	// begin inline asm
	{
	mad.lo.cc.u32   %r150, %r152, %r153, %r336;
	madc.hi.u32     %r336, %r152, %r153,  0;
	}
	// end inline asm
	add.s64 	%rd83, %rd9, %rd188;
	st.local.u32 	[%rd83], %r150;
	add.s64 	%rd188, %rd188, 4;
	cvt.u32.u64 	%r155, %rd188;
	setp.ne.s32 	%p12, %r155, 24;
	@%p12 bra 	$L__BB66_28;
	st.local.u32 	[%rd9+24], %r336;
	and.b32  	%r44, %r39, 31;
	mul.wide.u32 	%rd84, %r41, 4;
	sub.s64 	%rd34, %rd9, %rd84;
	ld.local.u32 	%r337, [%rd34+24];
	ld.local.u32 	%r338, [%rd34+20];
	setp.eq.s32 	%p13, %r44, 0;
	@%p13 bra 	$L__BB66_31;
	shl.b32 	%r156, %r338, %r44;
	shl.b32 	%r157, %r337, %r44;
	mov.b32 	%r158, 32;
	sub.s32 	%r159, %r158, %r44;
	shr.u32 	%r160, %r338, %r159;
	add.s32 	%r337, %r160, %r157;
	ld.local.u32 	%r161, [%rd34+16];
	shr.u32 	%r162, %r161, %r159;
	add.s32 	%r338, %r162, %r156;
$L__BB66_31:
	shr.u32 	%r163, %r337, 30;
	shr.u32 	%r164, %r338, 30;
	shl.b32 	%r165, %r337, 2;
	or.b32  	%r166, %r165, %r164;
	shl.b32 	%r167, %r338, 2;
	bfe.u32 	%r168, %r337, 29, 1;
	add.s32 	%r169, %r168, %r163;
	neg.s32 	%r170, %r169;
	setp.lt.s32 	%p14, %r38, 0;
	selp.b32 	%r339, %r170, %r169, %p14;
	xor.b32  	%r171, %r166, %r38;
	bfe.s32 	%r172, %r337, 29, 1;
	xor.b32  	%r173, %r172, %r166;
	xor.b32  	%r174, %r172, %r167;
	cvt.u64.u32 	%rd85, %r173;
	shl.b64 	%rd86, %rd85, 32;
	cvt.u64.u32 	%rd87, %r174;
	or.b64  	%rd88, %rd86, %rd87;
	cvt.rn.f64.s64 	%fd3, %rd88;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f89, %fd4;
	neg.f32 	%f90, %f89;
	setp.lt.s32 	%p15, %r171, 0;
	selp.f32 	%f243, %f90, %f89, %p15;
$L__BB66_32:
	mul.rn.f32 	%f92, %f243, %f243;
	and.b32  	%r176, %r339, 1;
	setp.eq.b32 	%p16, %r176, 1;
	selp.f32 	%f93, 0f3F800000, %f243, %p16;
	fma.rn.f32 	%f94, %f92, %f93, 0f00000000;
	fma.rn.f32 	%f95, %f92, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f96, %f95, 0fB94D4153, %p16;
	selp.f32 	%f97, 0f3D2AAABB, 0f3C0885E4, %p16;
	fma.rn.f32 	%f98, %f96, %f92, %f97;
	selp.f32 	%f99, 0fBEFFFFFF, 0fBE2AAAA8, %p16;
	fma.rn.f32 	%f100, %f98, %f92, %f99;
	fma.rn.f32 	%f101, %f100, %f94, %f93;
	and.b32  	%r177, %r339, 2;
	setp.eq.s32 	%p17, %r177, 0;
	sub.rn.f32 	%f103, %f85, %f101;
	selp.f32 	%f104, %f101, %f103, %p17;
	mul.lo.s64 	%rd89, %rd24, 9600;
	add.s64 	%rd90, %rd2, %rd89;
	mul.lo.s64 	%rd91, %rd29, 192;
	add.s64 	%rd92, %rd90, %rd91;
	shl.b64 	%rd93, %rd16, 3;
	add.s64 	%rd94, %rd92, %rd93;
	mul.wide.u32 	%rd95, %r327, 4;
	add.s64 	%rd96, %rd94, %rd95;
	ld.global.nc.f32 	%f105, [%rd96];
	mul.rn.f32 	%f106, %f105, %f104;
	add.rn.f32 	%f107, %f16, %f106;
	mul.rn.f32 	%f108, %f9, %f107;
	ld.global.nc.f32 	%f109, [%rd31+24];
	add.rn.f32 	%f110, %f109, %f108;
	mul.lo.s64 	%rd97, %rd24, 4800;
	add.s64 	%rd98, %rd1, %rd97;
	mul.lo.s64 	%rd99, %rd29, 96;
	add.s64 	%rd100, %rd98, %rd99;
	shl.b64 	%rd101, %rd184, 2;
	add.s64 	%rd102, %rd100, %rd101;
	st.global.f32 	[%rd102], %f110;
$L__BB66_2:
	mov.f32 	%f245, 0f00000000;
	mul.hi.u16 	%rs13, %rs2, 21846;
	mul.lo.s16 	%rs14, %rs13, 3;
	sub.s16 	%rs15, %rs2, %rs14;
	cvt.u32.u16 	%r3, %rs15;
	mul.hi.u32 	%r179, %r1, 954437177;
	shr.u32 	%r180, %r179, 2;
	mul.hi.u32 	%r181, %r180, 85899346;
	mul.lo.s32 	%r182, %r181, 50;
	mul.hi.u32 	%r183, %r1, -1851608123;
	bfe.u32 	%r184, %r183, 9, 6;
	cvt.u64.u32 	%rd17, %r184;
	mul.wide.u32 	%rd103, %r184, 4;
	add.s64 	%rd104, %rd3, %rd103;
	ld.global.nc.f32 	%f1, [%rd104];
	mul.wide.u32 	%rd105, %r184, 12;
	add.s64 	%rd106, %rd4, %rd105;
	shl.b64 	%rd107, %rd16, 2;
	add.s64 	%rd108, %rd106, %rd107;
	ld.global.nc.f32 	%f111, [%rd108];
	add.rn.f32 	%f112, %f111, %f111;
	add.rn.f32 	%f2, %f112, %f112;
	add.rn.f32 	%f3, %f2, %f2;
	mul.rn.f32 	%f113, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r343, %f113;
	cvt.rn.f32.s32 	%f114, %r343;
	fma.rn.f32 	%f115, %f114, 0fBFC90FDA, %f3;
	fma.rn.f32 	%f116, %f114, 0fB3A22168, %f115;
	fma.rn.f32 	%f246, %f114, 0fA7C234C5, %f116;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p18, %f5, 0f47CE4780;
	setp.neu.f32 	%p52, %f5, 0f7F800000;
	mov.u32 	%r331, %r343;
	mov.f32 	%f241, %f246;
	@%p18 bra 	$L__BB66_10;
	@%p52 bra 	$L__BB66_5;
	mul.rn.f32 	%f241, %f3, %f245;
	mov.b32 	%r331, 0;
	bra.uni 	$L__BB66_10;
$L__BB66_5:
	mov.b32 	%r328, 0;
	mov.b32 	%r6, %f3;
	shr.u32 	%r7, %r6, 23;
	and.b32  	%r186, %r7, 224;
	add.s32 	%r187, %r186, -128;
	shl.b32 	%r188, %r6, 8;
	or.b32  	%r192, %r188, -2147483648;
	shr.u32 	%r9, %r187, 5;
	mov.u64 	%rd186, 0;
	mov.u64 	%rd110, __cudart_i2opi_f;
$L__BB66_6:
	.pragma "nounroll";
	add.s64 	%rd111, %rd110, %rd186;
	ld.global.nc.u32 	%r191, [%rd111];
	// begin inline asm
	{
	mad.lo.cc.u32   %r189, %r191, %r192, %r328;
	madc.hi.u32     %r328, %r191, %r192,  0;
	}
	// end inline asm
	add.s64 	%rd112, %rd9, %rd186;
	st.local.u32 	[%rd112], %r189;
	add.s64 	%rd186, %rd186, 4;
	cvt.u32.u64 	%r194, %rd186;
	setp.ne.s32 	%p20, %r194, 24;
	@%p20 bra 	$L__BB66_6;
	st.local.u32 	[%rd9+24], %r328;
	and.b32  	%r12, %r7, 31;
	mul.wide.u32 	%rd113, %r9, 4;
	sub.s64 	%rd20, %rd9, %rd113;
	ld.local.u32 	%r329, [%rd20+24];
	ld.local.u32 	%r330, [%rd20+20];
	setp.eq.s32 	%p21, %r12, 0;
	@%p21 bra 	$L__BB66_9;
	shl.b32 	%r195, %r330, %r12;
	shl.b32 	%r196, %r329, %r12;
	mov.b32 	%r197, 32;
	sub.s32 	%r198, %r197, %r12;
	shr.u32 	%r199, %r330, %r198;
	add.s32 	%r329, %r199, %r196;
	ld.local.u32 	%r200, [%rd20+16];
	shr.u32 	%r201, %r200, %r198;
	add.s32 	%r330, %r201, %r195;
$L__BB66_9:
	shr.u32 	%r202, %r329, 30;
	shr.u32 	%r203, %r330, 30;
	shl.b32 	%r204, %r329, 2;
	or.b32  	%r205, %r204, %r203;
	shl.b32 	%r206, %r330, 2;
	bfe.u32 	%r207, %r329, 29, 1;
	add.s32 	%r208, %r207, %r202;
	neg.s32 	%r209, %r208;
	setp.lt.s32 	%p22, %r6, 0;
	selp.b32 	%r331, %r209, %r208, %p22;
	xor.b32  	%r210, %r205, %r6;
	bfe.s32 	%r211, %r329, 29, 1;
	xor.b32  	%r212, %r211, %r205;
	xor.b32  	%r213, %r211, %r206;
	cvt.u64.u32 	%rd114, %r212;
	shl.b64 	%rd115, %rd114, 32;
	cvt.u64.u32 	%rd116, %r213;
	or.b64  	%rd117, %rd115, %rd116;
	cvt.rn.f64.s64 	%fd5, %rd117;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f117, %fd6;
	neg.f32 	%f118, %f117;
	setp.lt.s32 	%p23, %r210, 0;
	selp.f32 	%f241, %f118, %f117, %p23;
$L__BB66_10:
	sub.s32 	%r4, %r180, %r182;
	and.b32  	%r21, %r3, 1;
	setp.eq.s32 	%p24, %r21, 0;
	mul.lo.s64 	%rd118, %rd17, 2400;
	mov.f32 	%f244, %f245;
	@%p24 bra 	$L__BB66_11;
	bra.uni 	$L__BB66_12;
$L__BB66_11:
	ld.param.u64 	%rd52, [input_concatenate_fusion_191_param_3];
	cvta.to.global.u64 	%rd5, %rd52;
	shr.u32 	%r215, %r3, 1;
	add.s64 	%rd119, %rd5, %rd118;
	mul.wide.u32 	%rd120, %r4, 48;
	add.s64 	%rd121, %rd119, %rd120;
	mul.wide.u32 	%rd122, %r215, 24;
	add.s64 	%rd123, %rd121, %rd122;
	mul.wide.u32 	%rd124, %r2, 4;
	add.s64 	%rd23, %rd123, %rd124;
	ld.global.nc.f32 	%f244, [%rd23];
$L__BB66_12:
	ld.param.u64 	%rd48, [input_concatenate_fusion_191_param_1];
	cvt.u64.u32 	%rd21, %r4;
	setp.ne.s32 	%p25, %r21, 0;
	shl.b64 	%rd129, %rd184, 2;
	@%p25 bra 	$L__BB66_55;
	bra.uni 	$L__BB66_13;
$L__BB66_55:
	ld.param.u64 	%rd50, [input_concatenate_fusion_191_param_2];
	cvta.to.global.u64 	%rd6, %rd50;
	add.s64 	%rd126, %rd6, %rd118;
	mul.lo.s64 	%rd127, %rd21, 48;
	add.s64 	%rd128, %rd126, %rd127;
	add.s64 	%rd35, %rd128, %rd129;
	ld.global.nc.f32 	%f245, [%rd35];
$L__BB66_13:
	cvta.to.global.u64 	%rd7, %rd48;
	@%p18 bra 	$L__BB66_38;
	@%p52 bra 	$L__BB66_33;
	mov.f32 	%f124, 0f00000000;
	mul.rn.f32 	%f246, %f3, %f124;
	mov.b32 	%r343, 0;
	bra.uni 	$L__BB66_38;
$L__BB66_33:
	mov.b32 	%r53, %f3;
	shr.u32 	%r54, %r53, 23;
	and.b32  	%r218, %r54, 224;
	add.s32 	%r219, %r218, -128;
	shl.b32 	%r220, %r53, 8;
	or.b32  	%r224, %r220, -2147483648;
	shr.u32 	%r56, %r219, 5;
	mov.b32 	%r340, 0;
	mov.u64 	%rd189, 0;
	mov.u64 	%rd131, __cudart_i2opi_f;
$L__BB66_34:
	.pragma "nounroll";
	add.s64 	%rd132, %rd131, %rd189;
	ld.global.nc.u32 	%r223, [%rd132];
	// begin inline asm
	{
	mad.lo.cc.u32   %r221, %r223, %r224, %r340;
	madc.hi.u32     %r340, %r223, %r224,  0;
	}
	// end inline asm
	add.s64 	%rd133, %rd9, %rd189;
	st.local.u32 	[%rd133], %r221;
	add.s64 	%rd189, %rd189, 4;
	cvt.u32.u64 	%r226, %rd189;
	setp.ne.s32 	%p28, %r226, 24;
	@%p28 bra 	$L__BB66_34;
	st.local.u32 	[%rd9+24], %r340;
	and.b32  	%r59, %r54, 31;
	mul.wide.u32 	%rd134, %r56, 4;
	sub.s64 	%rd38, %rd9, %rd134;
	ld.local.u32 	%r341, [%rd38+24];
	ld.local.u32 	%r342, [%rd38+20];
	setp.eq.s32 	%p29, %r59, 0;
	@%p29 bra 	$L__BB66_37;
	shl.b32 	%r227, %r342, %r59;
	shl.b32 	%r228, %r341, %r59;
	mov.b32 	%r229, 32;
	sub.s32 	%r230, %r229, %r59;
	shr.u32 	%r231, %r342, %r230;
	add.s32 	%r341, %r231, %r228;
	ld.local.u32 	%r232, [%rd38+16];
	shr.u32 	%r233, %r232, %r230;
	add.s32 	%r342, %r233, %r227;
$L__BB66_37:
	shr.u32 	%r234, %r341, 30;
	shr.u32 	%r235, %r342, 30;
	shl.b32 	%r236, %r341, 2;
	or.b32  	%r237, %r236, %r235;
	shl.b32 	%r238, %r342, 2;
	bfe.u32 	%r239, %r341, 29, 1;
	add.s32 	%r240, %r239, %r234;
	neg.s32 	%r241, %r240;
	setp.lt.s32 	%p30, %r53, 0;
	selp.b32 	%r343, %r241, %r240, %p30;
	xor.b32  	%r242, %r237, %r53;
	bfe.s32 	%r243, %r341, 29, 1;
	xor.b32  	%r244, %r243, %r237;
	xor.b32  	%r245, %r243, %r238;
	cvt.u64.u32 	%rd135, %r244;
	shl.b64 	%rd136, %rd135, 32;
	cvt.u64.u32 	%rd137, %r245;
	or.b64  	%rd138, %rd136, %rd137;
	cvt.rn.f64.s64 	%fd7, %rd138;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f122, %fd8;
	neg.f32 	%f123, %f122;
	setp.lt.s32 	%p31, %r242, 0;
	selp.f32 	%f246, %f123, %f122, %p31;
$L__BB66_38:
	mul.wide.u32 	%rd139, %r1, 4;
	add.s64 	%rd140, %rd7, %rd139;
	ld.global.nc.f32 	%f25, [%rd140];
	shl.b32 	%r68, %r3, 1;
	add.s32 	%r69, %r68, 2;
	mul.rn.f32 	%f125, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r351, %f125;
	cvt.rn.f32.s32 	%f126, %r351;
	fma.rn.f32 	%f127, %f126, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f128, %f126, 0fB3A22168, %f127;
	fma.rn.f32 	%f248, %f126, 0fA7C234C5, %f128;
	abs.f32 	%f27, %f2;
	setp.ltu.f32 	%p32, %f27, 0f47CE4780;
	setp.neu.f32 	%p53, %f27, 0f7F800000;
	mov.u32 	%r347, %r351;
	mov.f32 	%f247, %f248;
	@%p32 bra 	$L__BB66_46;
	@%p53 bra 	$L__BB66_41;
	mov.f32 	%f131, 0f00000000;
	mul.rn.f32 	%f247, %f2, %f131;
	mov.b32 	%r347, 0;
	bra.uni 	$L__BB66_46;
$L__BB66_41:
	mov.b32 	%r71, %f2;
	shr.u32 	%r72, %r71, 23;
	and.b32  	%r248, %r72, 224;
	add.s32 	%r249, %r248, -128;
	shl.b32 	%r250, %r71, 8;
	or.b32  	%r254, %r250, -2147483648;
	shr.u32 	%r74, %r249, 5;
	mov.b32 	%r344, 0;
	mov.u64 	%rd190, 0;
	mov.u64 	%rd142, __cudart_i2opi_f;
$L__BB66_42:
	.pragma "nounroll";
	add.s64 	%rd143, %rd142, %rd190;
	ld.global.nc.u32 	%r253, [%rd143];
	// begin inline asm
	{
	mad.lo.cc.u32   %r251, %r253, %r254, %r344;
	madc.hi.u32     %r344, %r253, %r254,  0;
	}
	// end inline asm
	add.s64 	%rd144, %rd9, %rd190;
	st.local.u32 	[%rd144], %r251;
	add.s64 	%rd190, %rd190, 4;
	cvt.u32.u64 	%r256, %rd190;
	setp.ne.s32 	%p34, %r256, 24;
	@%p34 bra 	$L__BB66_42;
	st.local.u32 	[%rd9+24], %r344;
	and.b32  	%r77, %r72, 31;
	mul.wide.u32 	%rd145, %r74, 4;
	sub.s64 	%rd41, %rd9, %rd145;
	ld.local.u32 	%r345, [%rd41+24];
	ld.local.u32 	%r346, [%rd41+20];
	setp.eq.s32 	%p35, %r77, 0;
	@%p35 bra 	$L__BB66_45;
	shl.b32 	%r257, %r346, %r77;
	shl.b32 	%r258, %r345, %r77;
	mov.b32 	%r259, 32;
	sub.s32 	%r260, %r259, %r77;
	shr.u32 	%r261, %r346, %r260;
	add.s32 	%r345, %r261, %r258;
	ld.local.u32 	%r262, [%rd41+16];
	shr.u32 	%r263, %r262, %r260;
	add.s32 	%r346, %r263, %r257;
$L__BB66_45:
	shr.u32 	%r264, %r345, 30;
	shr.u32 	%r265, %r346, 30;
	shl.b32 	%r266, %r345, 2;
	or.b32  	%r267, %r266, %r265;
	shl.b32 	%r268, %r346, 2;
	bfe.u32 	%r269, %r345, 29, 1;
	add.s32 	%r270, %r269, %r264;
	neg.s32 	%r271, %r270;
	setp.lt.s32 	%p36, %r71, 0;
	selp.b32 	%r347, %r271, %r270, %p36;
	xor.b32  	%r272, %r267, %r71;
	bfe.s32 	%r273, %r345, 29, 1;
	xor.b32  	%r274, %r273, %r267;
	xor.b32  	%r275, %r273, %r268;
	cvt.u64.u32 	%rd146, %r274;
	shl.b64 	%rd147, %rd146, 32;
	cvt.u64.u32 	%rd148, %r275;
	or.b64  	%rd149, %rd147, %rd148;
	cvt.rn.f64.s64 	%fd9, %rd149;
	mul.rn.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f129, %fd10;
	neg.f32 	%f130, %f129;
	setp.lt.s32 	%p37, %r272, 0;
	selp.f32 	%f247, %f130, %f129, %p37;
$L__BB66_46:
	shl.b32 	%r277, %r69, 1;
	mul.lo.s64 	%rd150, %rd17, 19200;
	add.s64 	%rd151, %rd8, %rd150;
	mul.lo.s64 	%rd152, %rd21, 384;
	add.s64 	%rd153, %rd151, %rd152;
	mul.wide.u32 	%rd154, %r277, 24;
	add.s64 	%rd155, %rd153, %rd154;
	add.s64 	%rd42, %rd155, %rd129;
	ld.global.nc.f32 	%f31, [%rd42];
	@%p32 bra 	$L__BB66_54;
	@%p53 bra 	$L__BB66_49;
	mov.f32 	%f134, 0f00000000;
	mul.rn.f32 	%f248, %f2, %f134;
	mov.b32 	%r351, 0;
	bra.uni 	$L__BB66_54;
$L__BB66_49:
	mov.b32 	%r86, %f2;
	shr.u32 	%r87, %r86, 23;
	and.b32  	%r279, %r87, 224;
	add.s32 	%r280, %r279, -128;
	shl.b32 	%r281, %r86, 8;
	or.b32  	%r285, %r281, -2147483648;
	shr.u32 	%r89, %r280, 5;
	mov.b32 	%r348, 0;
	mov.u64 	%rd191, 0;
	mov.u64 	%rd158, __cudart_i2opi_f;
$L__BB66_50:
	.pragma "nounroll";
	add.s64 	%rd159, %rd158, %rd191;
	ld.global.nc.u32 	%r284, [%rd159];
	// begin inline asm
	{
	mad.lo.cc.u32   %r282, %r284, %r285, %r348;
	madc.hi.u32     %r348, %r284, %r285,  0;
	}
	// end inline asm
	add.s64 	%rd160, %rd9, %rd191;
	st.local.u32 	[%rd160], %r282;
	add.s64 	%rd191, %rd191, 4;
	cvt.u32.u64 	%r287, %rd191;
	setp.ne.s32 	%p40, %r287, 24;
	@%p40 bra 	$L__BB66_50;
	st.local.u32 	[%rd9+24], %r348;
	and.b32  	%r92, %r87, 31;
	mul.wide.u32 	%rd161, %r89, 4;
	sub.s64 	%rd45, %rd9, %rd161;
	ld.local.u32 	%r349, [%rd45+24];
	ld.local.u32 	%r350, [%rd45+20];
	setp.eq.s32 	%p41, %r92, 0;
	@%p41 bra 	$L__BB66_53;
	shl.b32 	%r288, %r350, %r92;
	shl.b32 	%r289, %r349, %r92;
	mov.b32 	%r290, 32;
	sub.s32 	%r291, %r290, %r92;
	shr.u32 	%r292, %r350, %r291;
	add.s32 	%r349, %r292, %r289;
	ld.local.u32 	%r293, [%rd45+16];
	shr.u32 	%r294, %r293, %r291;
	add.s32 	%r350, %r294, %r288;
$L__BB66_53:
	shr.u32 	%r295, %r349, 30;
	shr.u32 	%r296, %r350, 30;
	shl.b32 	%r297, %r349, 2;
	or.b32  	%r298, %r297, %r296;
	shl.b32 	%r299, %r350, 2;
	bfe.u32 	%r300, %r349, 29, 1;
	add.s32 	%r301, %r300, %r295;
	neg.s32 	%r302, %r301;
	setp.lt.s32 	%p42, %r86, 0;
	selp.b32 	%r351, %r302, %r301, %p42;
	xor.b32  	%r303, %r298, %r86;
	bfe.s32 	%r304, %r349, 29, 1;
	xor.b32  	%r305, %r304, %r298;
	xor.b32  	%r306, %r304, %r299;
	cvt.u64.u32 	%rd162, %r305;
	shl.b64 	%rd163, %rd162, 32;
	cvt.u64.u32 	%rd164, %r306;
	or.b64  	%rd165, %rd163, %rd164;
	cvt.rn.f64.s64 	%fd11, %rd165;
	mul.rn.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f132, %fd12;
	neg.f32 	%f133, %f132;
	setp.lt.s32 	%p43, %r303, 0;
	selp.f32 	%f248, %f133, %f132, %p43;
$L__BB66_54:
	add.s32 	%r308, %r347, 1;
	and.b32  	%r309, %r308, 2;
	setp.eq.s32 	%p44, %r309, 0;
	and.b32  	%r310, %r347, 1;
	setp.eq.b32 	%p45, %r310, 1;
	mul.rn.f32 	%f135, %f247, %f247;
	fma.rn.f32 	%f136, %f135, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f137, 0fB94D4153, %f136, %p45;
	selp.f32 	%f138, 0f3C0885E4, 0f3D2AAABB, %p45;
	fma.rn.f32 	%f139, %f137, %f135, %f138;
	selp.f32 	%f140, 0fBE2AAAA8, 0fBEFFFFFF, %p45;
	fma.rn.f32 	%f141, %f139, %f135, %f140;
	selp.f32 	%f142, %f247, 0f3F800000, %p45;
	fma.rn.f32 	%f143, %f135, %f142, 0f00000000;
	fma.rn.f32 	%f144, %f141, %f143, %f142;
	mov.f32 	%f145, 0f00000000;
	sub.rn.f32 	%f146, %f145, %f144;
	selp.f32 	%f147, %f144, %f146, %p44;
	mul.rn.f32 	%f148, %f31, %f147;
	fma.rn.f32 	%f149, %f1, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f150, %f149;
	fma.rm.f32 	%f153, %f150, %f239, %f238;
	add.rn.f32 	%f154, %f153, 0fCB40007F;
	neg.f32 	%f155, %f154;
	fma.rn.f32 	%f156, %f1, 0f3FB8AA3B, %f155;
	fma.rn.f32 	%f157, %f1, 0f32A57060, %f156;
	ex2.approx.ftz.f32 	%f158, %f157;
	mov.b32 	%r311, %f153;
	shl.b32 	%r312, %r311, 23;
	mov.b32 	%f159, %r312;
	mul.rn.f32 	%f160, %f158, %f159;
	neg.f32 	%f161, %f160;
	sub.rn.f32 	%f162, %f161, %f160;
	add.rn.f32 	%f163, %f162, %f162;
	add.rn.f32 	%f164, %f163, %f163;
	add.rn.f32 	%f165, %f164, %f164;
	add.rn.f32 	%f166, %f165, %f165;
	add.rn.f32 	%f167, %f166, %f166;
	fma.rn.f32 	%f168, %f167, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f169, %f168;
	fma.rm.f32 	%f170, %f169, %f239, %f238;
	add.rn.f32 	%f171, %f170, 0fCB40007F;
	neg.f32 	%f172, %f171;
	fma.rn.f32 	%f173, %f167, 0f3FB8AA3B, %f172;
	fma.rn.f32 	%f174, %f167, 0f32A57060, %f173;
	ex2.approx.ftz.f32 	%f175, %f174;
	mov.b32 	%r313, %f170;
	shl.b32 	%r314, %r313, 23;
	mov.b32 	%f176, %r314;
	mul.rn.f32 	%f177, %f175, %f176;
	add.rn.f32 	%f178, %f167, %f167;
	fma.rn.f32 	%f179, %f178, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f180, %f179;
	fma.rm.f32 	%f181, %f180, %f239, %f238;
	add.rn.f32 	%f182, %f181, 0fCB40007F;
	neg.f32 	%f183, %f182;
	fma.rn.f32 	%f184, %f178, 0f3FB8AA3B, %f183;
	fma.rn.f32 	%f185, %f178, 0f32A57060, %f184;
	ex2.approx.ftz.f32 	%f186, %f185;
	mov.b32 	%r315, %f181;
	shl.b32 	%r316, %r315, 23;
	mov.b32 	%f187, %r316;
	mul.rn.f32 	%f188, %f186, %f187;
	add.s32 	%r317, %r331, 1;
	and.b32  	%r318, %r317, 2;
	setp.eq.s32 	%p46, %r318, 0;
	and.b32  	%r319, %r331, 1;
	setp.eq.b32 	%p47, %r319, 1;
	mul.rn.f32 	%f189, %f241, %f241;
	fma.rn.f32 	%f190, %f189, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f191, 0fB94D4153, %f190, %p47;
	selp.f32 	%f192, 0f3C0885E4, 0f3D2AAABB, %p47;
	fma.rn.f32 	%f193, %f191, %f189, %f192;
	selp.f32 	%f194, 0fBE2AAAA8, 0fBEFFFFFF, %p47;
	fma.rn.f32 	%f195, %f193, %f189, %f194;
	selp.f32 	%f196, %f241, 0f3F800000, %p47;
	fma.rn.f32 	%f197, %f189, %f196, 0f00000000;
	fma.rn.f32 	%f198, %f195, %f197, %f196;
	sub.rn.f32 	%f199, %f145, %f198;
	selp.f32 	%f200, %f198, %f199, %p46;
	add.rn.f32 	%f201, %f244, %f245;
	mul.rn.f32 	%f202, %f200, %f201;
	and.b32  	%r320, %r343, 2;
	setp.eq.s32 	%p48, %r320, 0;
	and.b32  	%r321, %r343, 1;
	setp.eq.b32 	%p49, %r321, 1;
	mul.rn.f32 	%f203, %f246, %f246;
	fma.rn.f32 	%f204, %f203, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f205, %f204, 0fB94D4153, %p49;
	selp.f32 	%f206, 0f3D2AAABB, 0f3C0885E4, %p49;
	fma.rn.f32 	%f207, %f205, %f203, %f206;
	selp.f32 	%f208, 0fBEFFFFFF, 0fBE2AAAA8, %p49;
	fma.rn.f32 	%f209, %f207, %f203, %f208;
	selp.f32 	%f210, 0f3F800000, %f246, %p49;
	fma.rn.f32 	%f211, %f203, %f210, 0f00000000;
	fma.rn.f32 	%f212, %f209, %f211, %f210;
	sub.rn.f32 	%f213, %f145, %f212;
	selp.f32 	%f214, %f212, %f213, %p48;
	mul.rn.f32 	%f215, %f25, %f214;
	add.rn.f32 	%f216, %f202, %f215;
	mul.rn.f32 	%f217, %f216, %f188;
	mul.rn.f32 	%f218, %f248, %f248;
	and.b32  	%r322, %r351, 1;
	setp.eq.b32 	%p50, %r322, 1;
	selp.f32 	%f219, 0f3F800000, %f248, %p50;
	fma.rn.f32 	%f220, %f218, %f219, 0f00000000;
	fma.rn.f32 	%f221, %f218, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f222, %f221, 0fB94D4153, %p50;
	selp.f32 	%f223, 0f3D2AAABB, 0f3C0885E4, %p50;
	fma.rn.f32 	%f224, %f222, %f218, %f223;
	selp.f32 	%f225, 0fBEFFFFFF, 0fBE2AAAA8, %p50;
	fma.rn.f32 	%f226, %f224, %f218, %f225;
	fma.rn.f32 	%f227, %f226, %f220, %f219;
	and.b32  	%r323, %r351, 2;
	setp.eq.s32 	%p51, %r323, 0;
	sub.rn.f32 	%f228, %f145, %f227;
	selp.f32 	%f229, %f227, %f228, %p51;
	mul.lo.s64 	%rd166, %rd17, 9600;
	add.s64 	%rd167, %rd2, %rd166;
	mul.lo.s64 	%rd168, %rd21, 192;
	add.s64 	%rd169, %rd167, %rd168;
	mul.wide.u32 	%rd170, %r68, 24;
	add.s64 	%rd171, %rd169, %rd170;
	shl.b64 	%rd172, %rd16, 3;
	add.s64 	%rd173, %rd171, %rd172;
	mul.wide.u32 	%rd174, %r327, 4;
	add.s64 	%rd175, %rd173, %rd174;
	ld.global.nc.f32 	%f230, [%rd175+48];
	mul.rn.f32 	%f231, %f230, %f229;
	add.rn.f32 	%f232, %f148, %f231;
	mul.rn.f32 	%f233, %f232, %f177;
	ld.global.nc.f32 	%f234, [%rd42+24];
	add.rn.f32 	%f235, %f234, %f233;
	add.rn.f32 	%f236, %f217, %f235;
	mul.lo.s64 	%rd176, %rd17, 4800;
	add.s64 	%rd177, %rd1, %rd176;
	mul.lo.s64 	%rd178, %rd21, 96;
	add.s64 	%rd179, %rd177, %rd178;
	mul.wide.u32 	%rd180, %r3, 24;
	add.s64 	%rd181, %rd179, %rd180;
	add.s64 	%rd183, %rd181, %rd129;
	st.global.f32 	[%rd183+24], %f236;
	ret;

}
	// .globl	loop_negate_fusion_6
.visible .entry loop_negate_fusion_6(
	.param .u64 loop_negate_fusion_6_param_0,
	.param .u64 loop_negate_fusion_6_param_1,
	.param .u64 loop_negate_fusion_6_param_2,
	.param .u64 loop_negate_fusion_6_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<14>;
	.reg .b16 	%rs<16>;
	.reg .b32 	%r<26>;
	.reg .f32 	%f<19>;
	.reg .b64 	%rd<36>;

	ld.param.u64 	%rd11, [loop_negate_fusion_6_param_3];
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	shl.b32 	%r7, %r5, 7;
	or.b32  	%r1, %r7, %r6;
	mul.hi.u32 	%r8, %r1, -1431655765;
	shr.u32 	%r9, %r8, 1;
	cvt.u16.u32 	%rs2, %r9;
	mul.hi.u16 	%rs3, %rs2, 9363;
	sub.s16 	%rs4, %rs2, %rs3;
	shr.u16 	%rs5, %rs4, 1;
	add.s16 	%rs6, %rs5, %rs3;
	shr.u16 	%rs7, %rs6, 2;
	mul.lo.s16 	%rs8, %rs7, 7;
	sub.s16 	%rs1, %rs2, %rs8;
	cvt.u32.u16 	%r2, %rs1;
	mul.hi.u32 	%r10, %r1, -2045222521;
	sub.s32 	%r11, %r1, %r10;
	shr.u32 	%r12, %r11, 1;
	add.s32 	%r13, %r12, %r10;
	shr.u32 	%r14, %r13, 4;
	cvt.u16.u32 	%rs9, %r14;
	shr.u16 	%rs10, %rs9, 1;
	mul.hi.u16 	%rs11, %rs10, 5243;
	shr.u16 	%rs12, %rs11, 1;
	mul.lo.s16 	%rs13, %rs12, 50;
	sub.s16 	%rs14, %rs9, %rs13;
	mul.hi.u32 	%r15, %r1, -106351571;
	bfe.u32 	%r16, %r15, 10, 6;
	mul.lo.s32 	%r17, %r9, 3;
	sub.s32 	%r18, %r1, %r17;
	shl.b32 	%r19, %r18, 1;
	or.b32  	%r20, %r19, 1;
	setp.gt.u32 	%p1, %r18, 1;
	selp.b32 	%r21, 5, %r20, %p1;
	and.b16  	%rs15, %rs1, 1;
	setp.eq.b16 	%p2, %rs15, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f32 	%f16, 0f00000000;
	mov.f32 	%f15, %f16;
	@%p5 bra 	$L__BB67_3;
	bra.uni 	$L__BB67_1;
$L__BB67_3:
	ld.param.u64 	%rd13, [loop_negate_fusion_6_param_2];
	cvta.to.global.u64 	%rd14, %rd13;
	shr.u32 	%r22, %r2, 1;
	cvt.u32.u16 	%r23, %rs14;
	mul.wide.u32 	%rd15, %r23, 96;
	mul.wide.u32 	%rd16, %r16, 4800;
	add.s64 	%rd17, %rd14, %rd16;
	add.s64 	%rd18, %rd17, %rd15;
	mul.wide.u32 	%rd19, %r22, 24;
	add.s64 	%rd20, %rd18, %rd19;
	mul.wide.u32 	%rd21, %r21, 4;
	add.s64 	%rd7, %rd20, %rd21;
	ld.global.nc.f32 	%f15, [%rd7];
$L__BB67_1:
	cvta.to.global.u64 	%rd1, %rd11;
	add.s32 	%r3, %r2, -1;
	and.b32  	%r24, %r3, 1;
	setp.eq.b32 	%p6, %r24, 1;
	xor.pred  	%p8, %p6, %p3;
	not.pred 	%p9, %p8;
	@%p9 bra 	$L__BB67_4;
	bra.uni 	$L__BB67_2;
$L__BB67_4:
	cvt.u64.u32 	%rd4, %r16;
	cvt.u64.u16 	%rd5, %rs14;
	cvt.u64.u32 	%rd6, %r21;
	bfe.u32 	%r4, %r3, 1, 1;
	setp.eq.s32 	%p10, %r4, 0;
	mul.lo.s64 	%rd22, %rd4, 2400;
	mul.lo.s64 	%rd24, %rd5, 48;
	shl.b64 	%rd28, %rd6, 2;
	mov.f32 	%f18, 0f00000000;
	mov.f32 	%f17, %f18;
	@%p10 bra 	$L__BB67_7;
	bra.uni 	$L__BB67_5;
$L__BB67_7:
	ld.param.u64 	%rd12, [loop_negate_fusion_6_param_1];
	cvta.to.global.u64 	%rd2, %rd12;
	bfe.u32 	%r25, %r3, 2, 6;
	add.s64 	%rd23, %rd2, %rd22;
	add.s64 	%rd25, %rd23, %rd24;
	mul.wide.u32 	%rd26, %r25, 24;
	add.s64 	%rd27, %rd25, %rd26;
	add.s64 	%rd8, %rd27, %rd28;
	ld.global.nc.f32 	%f17, [%rd8];
$L__BB67_5:
	setp.gt.u16 	%p11, %rs1, 2;
	setp.ne.s32 	%p12, %r4, 0;
	and.pred  	%p13, %p11, %p12;
	@%p13 bra 	$L__BB67_8;
	bra.uni 	$L__BB67_6;
$L__BB67_8:
	ld.param.u64 	%rd10, [loop_negate_fusion_6_param_0];
	cvta.to.global.u64 	%rd3, %rd10;
	add.s64 	%rd30, %rd3, %rd22;
	add.s64 	%rd32, %rd30, %rd24;
	add.s64 	%rd9, %rd32, %rd28;
	ld.global.nc.f32 	%f18, [%rd9];
$L__BB67_6:
	add.rn.f32 	%f16, %f17, %f18;
$L__BB67_2:
	add.rn.f32 	%f13, %f15, %f16;
	neg.f32 	%f14, %f13;
	mul.wide.u32 	%rd34, %r1, 4;
	add.s64 	%rd35, %rd1, %rd34;
	st.global.f32 	[%rd35], %f14;
	ret;

}
	// .globl	input_concatenate_fusion_192
.visible .entry input_concatenate_fusion_192(
	.param .u64 input_concatenate_fusion_192_param_0,
	.param .u64 input_concatenate_fusion_192_param_1,
	.param .u64 input_concatenate_fusion_192_param_2,
	.param .u64 input_concatenate_fusion_192_param_3,
	.param .u64 input_concatenate_fusion_192_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<16>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<19>;
	.reg .b64 	%rd<46>;

	ld.param.u64 	%rd10, [input_concatenate_fusion_192_param_0];
	ld.param.u64 	%rd11, [input_concatenate_fusion_192_param_4];
	cvta.to.global.u64 	%rd12, %rd11;
	cvta.to.global.u64 	%rd17, %rd10;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	shl.b32 	%r6, %r4, 7;
	or.b32  	%r7, %r6, %r5;
	mul.hi.u32 	%r8, %r7, -1431655765;
	shr.u32 	%r9, %r8, 1;
	mul.lo.s32 	%r10, %r9, 3;
	sub.s32 	%r11, %r7, %r10;
	cvt.u16.u32 	%rs2, %r9;
	mul.hi.u16 	%rs3, %rs2, 9363;
	sub.s16 	%rs4, %rs2, %rs3;
	shr.u16 	%rs5, %rs4, 1;
	add.s16 	%rs6, %rs5, %rs3;
	shr.u16 	%rs7, %rs6, 2;
	mul.lo.s16 	%rs8, %rs7, 7;
	sub.s16 	%rs1, %rs2, %rs8;
	cvt.u32.u16 	%r1, %rs1;
	mul.hi.u32 	%r12, %r7, -2045222521;
	sub.s32 	%r13, %r7, %r12;
	shr.u32 	%r14, %r13, 1;
	add.s32 	%r15, %r14, %r12;
	shr.u32 	%r16, %r15, 4;
	cvt.u16.u32 	%rs9, %r16;
	shr.u16 	%rs10, %rs9, 1;
	mul.hi.u16 	%rs11, %rs10, 5243;
	shr.u16 	%rs12, %rs11, 1;
	mul.lo.s16 	%rs13, %rs12, 50;
	sub.s16 	%rs14, %rs9, %rs13;
	mul.hi.u32 	%r17, %r7, -106351571;
	bfe.u32 	%r18, %r17, 10, 6;
	mul.wide.u32 	%rd18, %r7, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.nc.f32 	%f10, [%rd19];
	cvt.u32.u16 	%r19, %rs14;
	mul.wide.u32 	%rd20, %r19, 168;
	mul.wide.u32 	%rd21, %r18, 8400;
	add.s64 	%rd22, %rd12, %rd21;
	add.s64 	%rd23, %rd22, %rd20;
	mul.wide.u32 	%rd24, %r1, 24;
	add.s64 	%rd25, %rd23, %rd24;
	mul.wide.u32 	%rd26, %r11, 8;
	add.s64 	%rd5, %rd25, %rd26;
	st.global.f32 	[%rd5], %f10;
	shl.b32 	%r20, %r11, 1;
	and.b16  	%rs15, %rs1, 1;
	setp.eq.b16 	%p1, %rs15, 1;
	mov.pred 	%p2, 0;
	xor.pred  	%p3, %p1, %p2;
	not.pred 	%p4, %p3;
	mov.f32 	%f16, 0f00000000;
	mov.f32 	%f15, %f16;
	@%p4 bra 	$L__BB68_3;
	bra.uni 	$L__BB68_1;
$L__BB68_3:
	ld.param.u64 	%rd14, [input_concatenate_fusion_192_param_3];
	cvta.to.global.u64 	%rd15, %rd14;
	shr.u32 	%r21, %r1, 1;
	mul.wide.u32 	%rd27, %r19, 96;
	mul.wide.u32 	%rd28, %r18, 4800;
	add.s64 	%rd29, %rd15, %rd28;
	add.s64 	%rd30, %rd29, %rd27;
	mul.wide.u32 	%rd31, %r21, 24;
	add.s64 	%rd32, %rd30, %rd31;
	mul.wide.u32 	%rd33, %r20, 4;
	add.s64 	%rd7, %rd32, %rd33;
	ld.global.nc.f32 	%f15, [%rd7];
$L__BB68_1:
	add.s32 	%r2, %r1, -1;
	and.b32  	%r22, %r2, 1;
	setp.eq.b32 	%p5, %r22, 1;
	xor.pred  	%p7, %p5, %p2;
	not.pred 	%p8, %p7;
	@%p8 bra 	$L__BB68_4;
	bra.uni 	$L__BB68_2;
$L__BB68_4:
	cvt.u64.u32 	%rd3, %r18;
	cvt.u64.u16 	%rd4, %rs14;
	cvt.u64.u32 	%rd6, %r20;
	bfe.u32 	%r3, %r2, 1, 1;
	setp.eq.s32 	%p9, %r3, 0;
	mul.lo.s64 	%rd34, %rd3, 2400;
	mul.lo.s64 	%rd36, %rd4, 48;
	shl.b64 	%rd40, %rd6, 2;
	mov.f32 	%f18, 0f00000000;
	mov.f32 	%f17, %f18;
	@%p9 bra 	$L__BB68_7;
	bra.uni 	$L__BB68_5;
$L__BB68_7:
	ld.param.u64 	%rd16, [input_concatenate_fusion_192_param_2];
	cvta.to.global.u64 	%rd1, %rd16;
	bfe.u32 	%r23, %r2, 2, 6;
	add.s64 	%rd35, %rd1, %rd34;
	add.s64 	%rd37, %rd35, %rd36;
	mul.wide.u32 	%rd38, %r23, 24;
	add.s64 	%rd39, %rd37, %rd38;
	add.s64 	%rd8, %rd39, %rd40;
	ld.global.nc.f32 	%f17, [%rd8];
$L__BB68_5:
	setp.gt.u16 	%p10, %rs1, 2;
	setp.ne.s32 	%p11, %r3, 0;
	and.pred  	%p12, %p10, %p11;
	@%p12 bra 	$L__BB68_8;
	bra.uni 	$L__BB68_6;
$L__BB68_8:
	ld.param.u64 	%rd13, [input_concatenate_fusion_192_param_1];
	cvta.to.global.u64 	%rd2, %rd13;
	add.s64 	%rd42, %rd2, %rd34;
	add.s64 	%rd44, %rd42, %rd36;
	add.s64 	%rd9, %rd44, %rd40;
	ld.global.nc.f32 	%f18, [%rd9];
$L__BB68_6:
	add.rn.f32 	%f16, %f17, %f18;
$L__BB68_2:
	add.rn.f32 	%f14, %f15, %f16;
	st.global.f32 	[%rd5+4], %f14;
	ret;

}
	// .globl	loop_add_fusion_299
.visible .entry loop_add_fusion_299(
	.param .u64 loop_add_fusion_299_param_0,
	.param .u64 loop_add_fusion_299_param_1,
	.param .u64 loop_add_fusion_299_param_2,
	.param .u64 loop_add_fusion_299_param_3,
	.param .u64 loop_add_fusion_299_param_4,
	.param .u64 loop_add_fusion_299_param_5
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot69[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<15>;
	.reg .b32 	%r<128>;
	.reg .f32 	%f<71>;
	.reg .b64 	%rd<75>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot69;
	ld.param.u64 	%rd23, [loop_add_fusion_299_param_4];
	cvta.to.global.u64 	%rd24, %rd23;
	add.u64 	%rd6, %SPL, 0;
	mov.u32 	%r37, %ctaid.x;
	mov.u32 	%r38, %tid.x;
	shl.b32 	%r39, %r37, 7;
	or.b32  	%r1, %r39, %r38;
	mul.hi.u32 	%r40, %r1, -1431655765;
	shr.u32 	%r41, %r40, 2;
	mul.lo.s32 	%r42, %r41, 6;
	sub.s32 	%r2, %r1, %r42;
	cvt.u16.u32 	%rs3, %r41;
	mul.hi.u16 	%rs4, %rs3, 9363;
	sub.s16 	%rs5, %rs3, %rs4;
	shr.u16 	%rs6, %rs5, 1;
	add.s16 	%rs7, %rs6, %rs4;
	shr.u16 	%rs8, %rs7, 2;
	mul.lo.s16 	%rs9, %rs8, 7;
	sub.s16 	%rs1, %rs3, %rs9;
	cvt.u32.u16 	%r3, %rs1;
	shr.u32 	%r43, %r1, 1;
	mul.hi.u32 	%r44, %r43, 818089009;
	shr.u32 	%r45, %r44, 2;
	cvt.u16.u32 	%rs10, %r45;
	shr.u16 	%rs11, %rs10, 1;
	mul.hi.u16 	%rs12, %rs11, 5243;
	shr.u16 	%rs13, %rs12, 1;
	mul.lo.s16 	%rs14, %rs13, 50;
	mul.hi.u32 	%r46, %r1, -106351571;
	bfe.u32 	%r47, %r46, 11, 6;
	shr.u32 	%r48, %r2, 1;
	mul.wide.u32 	%rd29, %r48, 4;
	mul.wide.u32 	%rd30, %r47, 12;
	add.s64 	%rd31, %rd24, %rd30;
	add.s64 	%rd32, %rd31, %rd29;
	ld.global.nc.f32 	%f18, [%rd32];
	add.rn.f32 	%f19, %f18, %f18;
	add.rn.f32 	%f1, %f19, %f19;
	mul.rn.f32 	%f20, %f1, 0f3F22F983;
	cvt.rni.s32.f32 	%r127, %f20;
	cvt.rn.f32.s32 	%f21, %r127;
	fma.rn.f32 	%f22, %f21, 0fBFC90FDA, %f1;
	fma.rn.f32 	%f23, %f21, 0fB3A22168, %f22;
	fma.rn.f32 	%f68, %f21, 0fA7C234C5, %f23;
	abs.f32 	%f3, %f1;
	setp.ltu.f32 	%p1, %f3, 0f47CE4780;
	mov.f32 	%f67, 0f00000000;
	setp.neu.f32 	%p29, %f3, 0f7F800000;
	mov.u32 	%r123, %r127;
	mov.f32 	%f65, %f68;
	@%p1 bra 	$L__BB69_8;
	@%p29 bra 	$L__BB69_3;
	mul.rn.f32 	%f65, %f1, %f67;
	mov.b32 	%r123, 0;
	bra.uni 	$L__BB69_8;
$L__BB69_3:
	mov.b32 	%r5, %f1;
	shr.u32 	%r6, %r5, 23;
	and.b32  	%r50, %r6, 224;
	add.s32 	%r51, %r50, -128;
	shl.b32 	%r52, %r5, 8;
	or.b32  	%r56, %r52, -2147483648;
	shr.u32 	%r8, %r51, 5;
	mov.b32 	%r120, 0;
	mov.u64 	%rd73, 0;
	mov.u64 	%rd34, __cudart_i2opi_f;
$L__BB69_4:
	.pragma "nounroll";
	add.s64 	%rd35, %rd34, %rd73;
	ld.global.nc.u32 	%r55, [%rd35];
	// begin inline asm
	{
	mad.lo.cc.u32   %r53, %r55, %r56, %r120;
	madc.hi.u32     %r120, %r55, %r56,  0;
	}
	// end inline asm
	add.s64 	%rd36, %rd6, %rd73;
	st.local.u32 	[%rd36], %r53;
	add.s64 	%rd73, %rd73, 4;
	cvt.u32.u64 	%r58, %rd73;
	setp.ne.s32 	%p3, %r58, 24;
	@%p3 bra 	$L__BB69_4;
	st.local.u32 	[%rd6+24], %r120;
	and.b32  	%r11, %r6, 31;
	mul.wide.u32 	%rd37, %r8, 4;
	sub.s64 	%rd11, %rd6, %rd37;
	ld.local.u32 	%r121, [%rd11+24];
	ld.local.u32 	%r122, [%rd11+20];
	setp.eq.s32 	%p4, %r11, 0;
	@%p4 bra 	$L__BB69_7;
	shl.b32 	%r59, %r122, %r11;
	shl.b32 	%r60, %r121, %r11;
	mov.b32 	%r61, 32;
	sub.s32 	%r62, %r61, %r11;
	shr.u32 	%r63, %r122, %r62;
	add.s32 	%r121, %r63, %r60;
	ld.local.u32 	%r64, [%rd11+16];
	shr.u32 	%r65, %r64, %r62;
	add.s32 	%r122, %r65, %r59;
$L__BB69_7:
	shr.u32 	%r66, %r121, 30;
	shr.u32 	%r67, %r122, 30;
	shl.b32 	%r68, %r121, 2;
	or.b32  	%r69, %r68, %r67;
	shl.b32 	%r70, %r122, 2;
	bfe.u32 	%r71, %r121, 29, 1;
	add.s32 	%r72, %r71, %r66;
	neg.s32 	%r73, %r72;
	setp.lt.s32 	%p5, %r5, 0;
	selp.b32 	%r123, %r73, %r72, %p5;
	xor.b32  	%r74, %r69, %r5;
	bfe.s32 	%r75, %r121, 29, 1;
	xor.b32  	%r76, %r75, %r69;
	xor.b32  	%r77, %r75, %r70;
	cvt.u64.u32 	%rd38, %r76;
	shl.b64 	%rd39, %rd38, 32;
	cvt.u64.u32 	%rd40, %r77;
	or.b64  	%rd41, %rd39, %rd40;
	cvt.rn.f64.s64 	%fd1, %rd41;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f24, %fd2;
	neg.f32 	%f25, %f24;
	setp.lt.s32 	%p6, %r74, 0;
	selp.f32 	%f65, %f25, %f24, %p6;
$L__BB69_8:
	sub.s16 	%rs2, %rs10, %rs14;
	cvt.u64.u32 	%rd8, %r47;
	and.b32  	%r79, %r3, 1;
	setp.eq.b32 	%p7, %r79, 1;
	mov.pred 	%p8, 0;
	xor.pred  	%p9, %p7, %p8;
	not.pred 	%p10, %p9;
	mov.f32 	%f66, %f67;
	@%p10 bra 	$L__BB69_19;
	bra.uni 	$L__BB69_9;
$L__BB69_19:
	ld.param.u64 	%rd22, [loop_add_fusion_299_param_1];
	cvta.to.global.u64 	%rd4, %rd22;
	shr.u32 	%r80, %r3, 1;
	mul.lo.s64 	%rd42, %rd8, 4800;
	add.s64 	%rd43, %rd4, %rd42;
	cvt.u32.u16 	%r81, %rs2;
	mul.wide.u32 	%rd44, %r81, 96;
	add.s64 	%rd45, %rd43, %rd44;
	mul.wide.u32 	%rd46, %r80, 24;
	add.s64 	%rd47, %rd45, %rd46;
	mul.wide.u32 	%rd48, %r2, 4;
	add.s64 	%rd14, %rd47, %rd48;
	ld.global.nc.f32 	%f66, [%rd14];
$L__BB69_9:
	ld.param.u64 	%rd20, [loop_add_fusion_299_param_0];
	ld.param.u64 	%rd21, [loop_add_fusion_299_param_5];
	add.s32 	%r20, %r3, -1;
	and.b32  	%r82, %r20, 1;
	setp.eq.b32 	%p11, %r82, 1;
	xor.pred  	%p13, %p11, %p8;
	not.pred 	%p14, %p13;
	@%p14 bra 	$L__BB69_20;
	bra.uni 	$L__BB69_10;
$L__BB69_20:
	cvt.u64.u16 	%rd12, %rs2;
	cvt.u64.u32 	%rd13, %r2;
	bfe.u32 	%r36, %r20, 1, 1;
	setp.eq.s32 	%p15, %r36, 0;
	mul.lo.s64 	%rd49, %rd8, 2400;
	mul.lo.s64 	%rd51, %rd12, 48;
	shl.b64 	%rd55, %rd13, 2;
	mov.f32 	%f70, 0f00000000;
	mov.f32 	%f69, %f70;
	@%p15 bra 	$L__BB69_23;
	bra.uni 	$L__BB69_21;
$L__BB69_23:
	ld.param.u64 	%rd26, [loop_add_fusion_299_param_3];
	cvta.to.global.u64 	%rd2, %rd26;
	shr.s32 	%r83, %r20, 1;
	shr.u32 	%r84, %r83, 1;
	add.s64 	%rd50, %rd2, %rd49;
	add.s64 	%rd52, %rd50, %rd51;
	mul.wide.u32 	%rd53, %r84, 24;
	add.s64 	%rd54, %rd52, %rd53;
	add.s64 	%rd18, %rd54, %rd55;
	ld.global.nc.f32 	%f69, [%rd18];
$L__BB69_21:
	setp.gt.u16 	%p16, %rs1, 2;
	setp.ne.s32 	%p17, %r36, 0;
	and.pred  	%p18, %p16, %p17;
	@%p18 bra 	$L__BB69_24;
	bra.uni 	$L__BB69_22;
$L__BB69_24:
	ld.param.u64 	%rd25, [loop_add_fusion_299_param_2];
	cvta.to.global.u64 	%rd3, %rd25;
	add.s64 	%rd57, %rd3, %rd49;
	add.s64 	%rd59, %rd57, %rd51;
	add.s64 	%rd19, %rd59, %rd55;
	ld.global.nc.f32 	%f70, [%rd19];
$L__BB69_22:
	add.rn.f32 	%f67, %f69, %f70;
$L__BB69_10:
	cvta.to.global.u64 	%rd1, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	@%p1 bra 	$L__BB69_18;
	@%p29 bra 	$L__BB69_13;
	mov.f32 	%f33, 0f00000000;
	mul.rn.f32 	%f68, %f1, %f33;
	mov.b32 	%r127, 0;
	bra.uni 	$L__BB69_18;
$L__BB69_13:
	mov.b32 	%r21, %f1;
	shr.u32 	%r22, %r21, 23;
	and.b32  	%r86, %r22, 224;
	add.s32 	%r87, %r86, -128;
	shl.b32 	%r88, %r21, 8;
	or.b32  	%r92, %r88, -2147483648;
	shr.u32 	%r24, %r87, 5;
	mov.b32 	%r124, 0;
	mov.u64 	%rd74, 0;
	mov.u64 	%rd62, __cudart_i2opi_f;
$L__BB69_14:
	.pragma "nounroll";
	add.s64 	%rd63, %rd62, %rd74;
	ld.global.nc.u32 	%r91, [%rd63];
	// begin inline asm
	{
	mad.lo.cc.u32   %r89, %r91, %r92, %r124;
	madc.hi.u32     %r124, %r91, %r92,  0;
	}
	// end inline asm
	add.s64 	%rd64, %rd6, %rd74;
	st.local.u32 	[%rd64], %r89;
	add.s64 	%rd74, %rd74, 4;
	cvt.u32.u64 	%r94, %rd74;
	setp.ne.s32 	%p21, %r94, 24;
	@%p21 bra 	$L__BB69_14;
	st.local.u32 	[%rd6+24], %r124;
	and.b32  	%r27, %r22, 31;
	mul.wide.u32 	%rd65, %r24, 4;
	sub.s64 	%rd17, %rd6, %rd65;
	ld.local.u32 	%r125, [%rd17+24];
	ld.local.u32 	%r126, [%rd17+20];
	setp.eq.s32 	%p22, %r27, 0;
	@%p22 bra 	$L__BB69_17;
	shl.b32 	%r95, %r126, %r27;
	shl.b32 	%r96, %r125, %r27;
	mov.b32 	%r97, 32;
	sub.s32 	%r98, %r97, %r27;
	shr.u32 	%r99, %r126, %r98;
	add.s32 	%r125, %r99, %r96;
	ld.local.u32 	%r100, [%rd17+16];
	shr.u32 	%r101, %r100, %r98;
	add.s32 	%r126, %r101, %r95;
$L__BB69_17:
	shr.u32 	%r102, %r125, 30;
	shr.u32 	%r103, %r126, 30;
	shl.b32 	%r104, %r125, 2;
	or.b32  	%r105, %r104, %r103;
	shl.b32 	%r106, %r126, 2;
	bfe.u32 	%r107, %r125, 29, 1;
	add.s32 	%r108, %r107, %r102;
	neg.s32 	%r109, %r108;
	setp.lt.s32 	%p23, %r21, 0;
	selp.b32 	%r127, %r109, %r108, %p23;
	xor.b32  	%r110, %r105, %r21;
	bfe.s32 	%r111, %r125, 29, 1;
	xor.b32  	%r112, %r111, %r105;
	xor.b32  	%r113, %r111, %r106;
	cvt.u64.u32 	%rd66, %r112;
	shl.b64 	%rd67, %rd66, 32;
	cvt.u64.u32 	%rd68, %r113;
	or.b64  	%rd69, %rd67, %rd68;
	cvt.rn.f64.s64 	%fd3, %rd69;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f31, %fd4;
	neg.f32 	%f32, %f31;
	setp.lt.s32 	%p24, %r110, 0;
	selp.f32 	%f68, %f32, %f31, %p24;
$L__BB69_18:
	add.s32 	%r115, %r123, 1;
	and.b32  	%r116, %r115, 2;
	setp.eq.s32 	%p25, %r116, 0;
	and.b32  	%r117, %r123, 1;
	setp.eq.b32 	%p26, %r117, 1;
	mul.rn.f32 	%f34, %f65, %f65;
	fma.rn.f32 	%f35, %f34, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f36, 0fB94D4153, %f35, %p26;
	selp.f32 	%f37, 0f3C0885E4, 0f3D2AAABB, %p26;
	fma.rn.f32 	%f38, %f36, %f34, %f37;
	selp.f32 	%f39, 0fBE2AAAA8, 0fBEFFFFFF, %p26;
	fma.rn.f32 	%f40, %f38, %f34, %f39;
	selp.f32 	%f41, %f65, 0f3F800000, %p26;
	fma.rn.f32 	%f42, %f34, %f41, 0f00000000;
	fma.rn.f32 	%f43, %f40, %f42, %f41;
	mov.f32 	%f44, 0f00000000;
	sub.rn.f32 	%f45, %f44, %f43;
	selp.f32 	%f46, %f43, %f45, %p25;
	add.rn.f32 	%f47, %f66, %f67;
	mul.rn.f32 	%f48, %f46, %f47;
	mul.rn.f32 	%f49, %f68, %f68;
	and.b32  	%r118, %r127, 1;
	setp.eq.b32 	%p27, %r118, 1;
	selp.f32 	%f50, 0f3F800000, %f68, %p27;
	fma.rn.f32 	%f51, %f49, %f50, 0f00000000;
	fma.rn.f32 	%f52, %f49, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f53, %f52, 0fB94D4153, %p27;
	selp.f32 	%f54, 0f3D2AAABB, 0f3C0885E4, %p27;
	fma.rn.f32 	%f55, %f53, %f49, %f54;
	selp.f32 	%f56, 0fBEFFFFFF, 0fBE2AAAA8, %p27;
	fma.rn.f32 	%f57, %f55, %f49, %f56;
	fma.rn.f32 	%f58, %f57, %f51, %f50;
	and.b32  	%r119, %r127, 2;
	setp.eq.s32 	%p28, %r119, 0;
	sub.rn.f32 	%f59, %f44, %f58;
	selp.f32 	%f60, %f58, %f59, %p28;
	mul.wide.u32 	%rd70, %r1, 4;
	add.s64 	%rd71, %rd5, %rd70;
	ld.global.nc.f32 	%f61, [%rd71];
	mul.rn.f32 	%f62, %f61, %f60;
	add.rn.f32 	%f63, %f48, %f62;
	add.s64 	%rd72, %rd1, %rd70;
	st.global.f32 	[%rd72], %f63;
	ret;

}
	// .globl	loop_add_fusion_300
.visible .entry loop_add_fusion_300(
	.param .u64 loop_add_fusion_300_param_0,
	.param .u64 loop_add_fusion_300_param_1,
	.param .u64 loop_add_fusion_300_param_2,
	.param .u64 loop_add_fusion_300_param_3,
	.param .u64 loop_add_fusion_300_param_4,
	.param .u64 loop_add_fusion_300_param_5,
	.param .u64 loop_add_fusion_300_param_6
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<97>;
	.reg .b16 	%rs<46>;
	.reg .b32 	%r<134>;
	.reg .f32 	%f<237>;
	.reg .b64 	%rd<226>;

	ld.param.u64 	%rd33, [loop_add_fusion_300_param_0];
	ld.param.u64 	%rd34, [loop_add_fusion_300_param_6];
	ld.param.u64 	%rd35, [loop_add_fusion_300_param_1];
	ld.param.u64 	%rd36, [loop_add_fusion_300_param_5];
	cvta.to.global.u64 	%rd2, %rd36;
	ld.param.u64 	%rd37, [loop_add_fusion_300_param_2];
	ld.param.u64 	%rd38, [loop_add_fusion_300_param_4];
	ld.param.u64 	%rd39, [loop_add_fusion_300_param_3];
	cvta.to.global.u64 	%rd5, %rd37;
	cvta.to.global.u64 	%rd6, %rd35;
	mov.u32 	%r24, %ctaid.x;
	mov.u32 	%r25, %tid.x;
	shl.b32 	%r26, %r24, 9;
	shl.b32 	%r27, %r25, 2;
	or.b32  	%r1, %r26, %r27;
	mul.hi.u32 	%r28, %r1, 715827883;
	mul.lo.s32 	%r29, %r28, 6;
	sub.s32 	%r2, %r1, %r29;
	and.b32  	%r3, %r28, 15;
	shr.u32 	%r30, %r28, 4;
	cvt.u16.u32 	%rs2, %r30;
	shr.u16 	%rs3, %rs2, 1;
	mul.hi.u16 	%rs4, %rs3, 5243;
	shr.u16 	%rs5, %rs4, 1;
	mul.lo.s16 	%rs6, %rs5, 50;
	sub.s16 	%rs1, %rs2, %rs6;
	mul.hi.u32 	%r31, %r1, 458129845;
	bfe.u32 	%r4, %r31, 9, 6;
	or.b32  	%r32, %r1, 1;
	mul.hi.u32 	%r33, %r32, 715827883;
	and.b32  	%r12, %r28, 1;
	setp.eq.s32 	%p1, %r12, 0;
	bfe.u32 	%r13, %r28, 1, 3;
	mov.f32 	%f220, 0f00000000;
	setp.gt.u32 	%p96, %r3, 1;
	cvt.u32.u16 	%r133, %rs1;
	mov.f32 	%f213, %f220;
	@%p1 bra 	$L__BB70_9;
	bra.uni 	$L__BB70_1;
$L__BB70_9:
	@%p96 bra 	$L__BB70_11;
	mul.wide.u32 	%rd57, %r4, 19200;
	add.s64 	%rd58, %rd6, %rd57;
	mul.wide.u32 	%rd59, %r133, 384;
	add.s64 	%rd60, %rd58, %rd59;
	mul.wide.u32 	%rd61, %r2, 4;
	add.s64 	%rd62, %rd60, %rd61;
	ld.global.nc.f32 	%f213, [%rd62];
	bra.uni 	$L__BB70_1;
$L__BB70_11:
	shl.b32 	%r39, %r13, 1;
	mul.wide.u32 	%rd40, %r4, 4;
	add.s64 	%rd41, %rd2, %rd40;
	ld.global.nc.f32 	%f54, [%rd41];
	fma.rn.f32 	%f55, %f54, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f56, %f55;
	mov.f32 	%f57, 0f4B400001;
	mov.f32 	%f58, 0f437C0000;
	fma.rm.f32 	%f59, %f56, %f58, %f57;
	add.rn.f32 	%f60, %f59, 0fCB40007F;
	neg.f32 	%f61, %f60;
	fma.rn.f32 	%f62, %f54, 0f3FB8AA3B, %f61;
	fma.rn.f32 	%f63, %f54, 0f32A57060, %f62;
	mov.b32 	%r40, %f59;
	shl.b32 	%r41, %r40, 23;
	mov.b32 	%f64, %r41;
	ex2.approx.ftz.f32 	%f65, %f63;
	mul.rn.f32 	%f66, %f65, %f64;
	neg.f32 	%f67, %f66;
	sub.rn.f32 	%f68, %f67, %f66;
	add.rn.f32 	%f69, %f68, %f68;
	add.rn.f32 	%f70, %f69, %f69;
	add.rn.f32 	%f71, %f70, %f70;
	add.rn.f32 	%f72, %f71, %f71;
	add.rn.f32 	%f73, %f72, %f72;
	fma.rn.f32 	%f74, %f73, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f75, %f74;
	fma.rm.f32 	%f76, %f75, %f58, %f57;
	add.rn.f32 	%f77, %f76, 0fCB40007F;
	neg.f32 	%f78, %f77;
	fma.rn.f32 	%f79, %f73, 0f3FB8AA3B, %f78;
	fma.rn.f32 	%f80, %f73, 0f32A57060, %f79;
	mov.b32 	%r42, %f76;
	shl.b32 	%r43, %r42, 23;
	mov.b32 	%f81, %r43;
	ex2.approx.ftz.f32 	%f82, %f80;
	mul.rn.f32 	%f83, %f82, %f81;
	mul.wide.u32 	%rd42, %r4, 8400;
	add.s64 	%rd43, %rd5, %rd42;
	mul.wide.u32 	%rd44, %r133, 168;
	add.s64 	%rd45, %rd43, %rd44;
	mul.wide.u32 	%rd46, %r13, 24;
	add.s64 	%rd47, %rd45, %rd46;
	mul.wide.u32 	%rd48, %r2, 4;
	add.s64 	%rd49, %rd47, %rd48;
	ld.global.nc.f32 	%f84, [%rd49+-24];
	mul.rn.f32 	%f85, %f84, %f83;
	add.s32 	%r45, %r39, -2;
	mul.wide.u32 	%rd50, %r4, 19200;
	add.s64 	%rd51, %rd6, %rd50;
	mul.wide.u32 	%rd52, %r133, 384;
	add.s64 	%rd53, %rd51, %rd52;
	mul.wide.u32 	%rd54, %r45, 24;
	add.s64 	%rd55, %rd53, %rd54;
	add.s64 	%rd56, %rd55, %rd48;
	ld.global.nc.f32 	%f86, [%rd56+48];
	add.rn.f32 	%f213, %f86, %f85;
$L__BB70_1:
	or.b32  	%r35, %r1, 2;
	mul.lo.s32 	%r34, %r33, 6;
	cvta.to.global.u64 	%rd1, %rd34;
	cvta.to.global.u64 	%rd3, %rd38;
	cvta.to.global.u64 	%rd4, %rd39;
	cvta.to.global.u64 	%rd7, %rd33;
	add.s32 	%r47, %r3, -1;
	and.b32  	%r14, %r47, 1;
	setp.eq.s32 	%p3, %r14, 0;
	cvt.u16.u32 	%rs7, %r47;
	and.b16  	%rs8, %rs7, 128;
	shr.u16 	%rs9, %rs8, 7;
	add.s16 	%rs10, %rs7, %rs9;
	shr.u16 	%rs11, %rs10, 1;
	cvt.u32.u16 	%r48, %rs11;
	and.b32  	%r15, %r48, 255;
	and.b32  	%r129, %r15, 1;
	mov.pred 	%p94, 0;
	cvt.u64.u32 	%rd223, %r4;
	cvt.u64.u16 	%rd224, %rs1;
	shr.u32 	%r130, %r15, 1;
	mul.wide.u32 	%rd225, %r4, 4800;
	add.s32 	%r132, %r15, -1;
	setp.gt.u32 	%p95, %r3, 2;
	mov.f32 	%f214, %f220;
	@%p3 bra 	$L__BB70_12;
	bra.uni 	$L__BB70_2;
$L__BB70_12:
	setp.eq.b32 	%p4, %r129, 1;
	xor.pred  	%p6, %p4, %p94;
	not.pred 	%p7, %p6;
	mov.f32 	%f222, 0f00000000;
	mov.f32 	%f221, %f222;
	@%p7 bra 	$L__BB70_15;
	bra.uni 	$L__BB70_13;
$L__BB70_15:
	add.s64 	%rd64, %rd7, %rd225;
	mul.wide.u32 	%rd65, %r133, 96;
	add.s64 	%rd66, %rd64, %rd65;
	mul.wide.u32 	%rd67, %r130, 24;
	add.s64 	%rd68, %rd66, %rd67;
	mul.wide.u32 	%rd69, %r2, 4;
	add.s64 	%rd12, %rd68, %rd69;
	ld.global.nc.f32 	%f221, [%rd12];
$L__BB70_13:
	and.b32  	%r53, %r132, 1;
	setp.eq.b32 	%p9, %r53, 1;
	not.pred 	%p10, %p9;
	and.pred  	%p11, %p95, %p10;
	@%p11 bra 	$L__BB70_16;
	bra.uni 	$L__BB70_14;
$L__BB70_16:
	cvt.u64.u32 	%rd11, %r2;
	cvt.u16.u32 	%rs12, %r132;
	and.b16  	%rs13, %rs12, 128;
	shr.u16 	%rs14, %rs13, 7;
	add.s16 	%rs15, %rs12, %rs14;
	cvt.s16.s8 	%rs16, %rs15;
	shr.u16 	%rs17, %rs16, 1;
	cvt.u32.u16 	%r54, %rs17;
	and.b32  	%r20, %r54, 255;
	and.b32  	%r55, %r20, 1;
	setp.eq.b32 	%p12, %r55, 1;
	xor.pred  	%p14, %p12, %p94;
	not.pred 	%p15, %p14;
	mul.lo.s64 	%rd70, %rd223, 2400;
	mul.lo.s64 	%rd72, %rd224, 48;
	shl.b64 	%rd76, %rd11, 2;
	mov.f32 	%f224, 0f00000000;
	mov.f32 	%f223, %f224;
	@%p15 bra 	$L__BB70_19;
	bra.uni 	$L__BB70_17;
$L__BB70_19:
	shr.u32 	%r56, %r20, 1;
	add.s64 	%rd71, %rd3, %rd70;
	add.s64 	%rd73, %rd71, %rd72;
	mul.wide.u32 	%rd74, %r56, 24;
	add.s64 	%rd75, %rd73, %rd74;
	add.s64 	%rd13, %rd75, %rd76;
	ld.global.nc.f32 	%f223, [%rd13];
$L__BB70_17:
	add.s32 	%r57, %r20, -1;
	setp.gt.u32 	%p16, %r3, 6;
	and.b32  	%r58, %r57, 1;
	setp.eq.b32 	%p17, %r58, 1;
	not.pred 	%p18, %p17;
	and.pred  	%p19, %p16, %p18;
	@%p19 bra 	$L__BB70_20;
	bra.uni 	$L__BB70_18;
$L__BB70_20:
	setp.gt.u32 	%p20, %r57, 1;
	add.s64 	%rd78, %rd4, %rd70;
	add.s64 	%rd80, %rd78, %rd72;
	selp.u32 	%r59, 1, 0, %p20;
	mul.wide.u32 	%rd81, %r59, 24;
	add.s64 	%rd82, %rd80, %rd81;
	add.s64 	%rd14, %rd82, %rd76;
	ld.global.nc.f32 	%f224, [%rd14];
$L__BB70_18:
	add.rn.f32 	%f222, %f223, %f224;
$L__BB70_14:
	add.rn.f32 	%f214, %f221, %f222;
$L__BB70_2:
	mul.hi.u32 	%r6, %r35, 715827883;
	sub.s32 	%r5, %r32, %r34;
	add.rn.f32 	%f93, %f213, %f214;
	mul.wide.u32 	%rd84, %r1, 4;
	add.s64 	%rd8, %rd1, %rd84;
	st.global.f32 	[%rd8], %f93;
	mov.f32 	%f215, %f220;
	@%p1 bra 	$L__BB70_21;
	bra.uni 	$L__BB70_3;
$L__BB70_21:
	@%p96 bra 	$L__BB70_23;
	mul.wide.u32 	%rd102, %r4, 19200;
	add.s64 	%rd103, %rd6, %rd102;
	mul.wide.u32 	%rd104, %r133, 384;
	add.s64 	%rd105, %rd103, %rd104;
	mul.wide.u32 	%rd106, %r5, 4;
	add.s64 	%rd107, %rd105, %rd106;
	ld.global.nc.f32 	%f215, [%rd107];
	bra.uni 	$L__BB70_3;
$L__BB70_23:
	shl.b32 	%r60, %r13, 1;
	mul.wide.u32 	%rd85, %r4, 4;
	add.s64 	%rd86, %rd2, %rd85;
	ld.global.nc.f32 	%f94, [%rd86];
	fma.rn.f32 	%f95, %f94, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f96, %f95;
	mov.f32 	%f97, 0f4B400001;
	mov.f32 	%f98, 0f437C0000;
	fma.rm.f32 	%f99, %f96, %f98, %f97;
	add.rn.f32 	%f100, %f99, 0fCB40007F;
	neg.f32 	%f101, %f100;
	fma.rn.f32 	%f102, %f94, 0f3FB8AA3B, %f101;
	fma.rn.f32 	%f103, %f94, 0f32A57060, %f102;
	mov.b32 	%r61, %f99;
	shl.b32 	%r62, %r61, 23;
	mov.b32 	%f104, %r62;
	ex2.approx.ftz.f32 	%f105, %f103;
	mul.rn.f32 	%f106, %f105, %f104;
	neg.f32 	%f107, %f106;
	sub.rn.f32 	%f108, %f107, %f106;
	add.rn.f32 	%f109, %f108, %f108;
	add.rn.f32 	%f110, %f109, %f109;
	add.rn.f32 	%f111, %f110, %f110;
	add.rn.f32 	%f112, %f111, %f111;
	add.rn.f32 	%f113, %f112, %f112;
	fma.rn.f32 	%f114, %f113, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f115, %f114;
	fma.rm.f32 	%f116, %f115, %f98, %f97;
	add.rn.f32 	%f117, %f116, 0fCB40007F;
	neg.f32 	%f118, %f117;
	fma.rn.f32 	%f119, %f113, 0f3FB8AA3B, %f118;
	fma.rn.f32 	%f120, %f113, 0f32A57060, %f119;
	mov.b32 	%r63, %f116;
	shl.b32 	%r64, %r63, 23;
	mov.b32 	%f121, %r64;
	ex2.approx.ftz.f32 	%f122, %f120;
	mul.rn.f32 	%f123, %f122, %f121;
	mul.wide.u32 	%rd87, %r4, 8400;
	add.s64 	%rd88, %rd5, %rd87;
	mul.wide.u32 	%rd89, %r133, 168;
	add.s64 	%rd90, %rd88, %rd89;
	mul.wide.u32 	%rd91, %r13, 24;
	add.s64 	%rd92, %rd90, %rd91;
	mul.wide.u32 	%rd93, %r5, 4;
	add.s64 	%rd94, %rd92, %rd93;
	ld.global.nc.f32 	%f124, [%rd94+-24];
	mul.rn.f32 	%f125, %f124, %f123;
	add.s32 	%r66, %r60, -2;
	mul.wide.u32 	%rd95, %r4, 19200;
	add.s64 	%rd96, %rd6, %rd95;
	mul.wide.u32 	%rd97, %r133, 384;
	add.s64 	%rd98, %rd96, %rd97;
	mul.wide.u32 	%rd99, %r66, 24;
	add.s64 	%rd100, %rd98, %rd99;
	add.s64 	%rd101, %rd100, %rd93;
	ld.global.nc.f32 	%f126, [%rd101+48];
	add.rn.f32 	%f215, %f126, %f125;
$L__BB70_3:
	or.b32  	%r37, %r1, 3;
	mul.lo.s32 	%r36, %r6, 6;
	mov.f32 	%f216, %f220;
	@%p3 bra 	$L__BB70_24;
	bra.uni 	$L__BB70_4;
$L__BB70_24:
	setp.eq.b32 	%p24, %r129, 1;
	xor.pred  	%p26, %p24, %p94;
	not.pred 	%p27, %p26;
	mov.f32 	%f226, 0f00000000;
	mov.f32 	%f225, %f226;
	@%p27 bra 	$L__BB70_27;
	bra.uni 	$L__BB70_25;
$L__BB70_27:
	add.s64 	%rd109, %rd7, %rd225;
	mul.wide.u32 	%rd110, %r133, 96;
	add.s64 	%rd111, %rd109, %rd110;
	mul.wide.u32 	%rd112, %r130, 24;
	add.s64 	%rd113, %rd111, %rd112;
	mul.wide.u32 	%rd114, %r5, 4;
	add.s64 	%rd18, %rd113, %rd114;
	ld.global.nc.f32 	%f225, [%rd18];
$L__BB70_25:
	and.b32  	%r72, %r132, 1;
	setp.eq.b32 	%p29, %r72, 1;
	not.pred 	%p30, %p29;
	and.pred  	%p31, %p95, %p30;
	@%p31 bra 	$L__BB70_28;
	bra.uni 	$L__BB70_26;
$L__BB70_28:
	cvt.u64.u32 	%rd17, %r5;
	cvt.u16.u32 	%rs18, %r132;
	and.b16  	%rs19, %rs18, 128;
	shr.u16 	%rs20, %rs19, 7;
	add.s16 	%rs21, %rs18, %rs20;
	cvt.s16.s8 	%rs22, %rs21;
	shr.u16 	%rs23, %rs22, 1;
	cvt.u32.u16 	%r73, %rs23;
	and.b32  	%r21, %r73, 255;
	and.b32  	%r74, %r21, 1;
	setp.eq.b32 	%p32, %r74, 1;
	xor.pred  	%p34, %p32, %p94;
	not.pred 	%p35, %p34;
	mul.lo.s64 	%rd115, %rd223, 2400;
	mul.lo.s64 	%rd117, %rd224, 48;
	shl.b64 	%rd121, %rd17, 2;
	mov.f32 	%f228, 0f00000000;
	mov.f32 	%f227, %f228;
	@%p35 bra 	$L__BB70_31;
	bra.uni 	$L__BB70_29;
$L__BB70_31:
	shr.u32 	%r75, %r21, 1;
	add.s64 	%rd116, %rd3, %rd115;
	add.s64 	%rd118, %rd116, %rd117;
	mul.wide.u32 	%rd119, %r75, 24;
	add.s64 	%rd120, %rd118, %rd119;
	add.s64 	%rd19, %rd120, %rd121;
	ld.global.nc.f32 	%f227, [%rd19];
$L__BB70_29:
	add.s32 	%r76, %r21, -1;
	setp.gt.u32 	%p36, %r3, 6;
	and.b32  	%r77, %r76, 1;
	setp.eq.b32 	%p37, %r77, 1;
	not.pred 	%p38, %p37;
	and.pred  	%p39, %p36, %p38;
	@%p39 bra 	$L__BB70_32;
	bra.uni 	$L__BB70_30;
$L__BB70_32:
	setp.gt.u32 	%p40, %r76, 1;
	add.s64 	%rd123, %rd4, %rd115;
	add.s64 	%rd125, %rd123, %rd117;
	selp.u32 	%r78, 1, 0, %p40;
	mul.wide.u32 	%rd126, %r78, 24;
	add.s64 	%rd127, %rd125, %rd126;
	add.s64 	%rd20, %rd127, %rd121;
	ld.global.nc.f32 	%f228, [%rd20];
$L__BB70_30:
	add.rn.f32 	%f226, %f227, %f228;
$L__BB70_26:
	add.rn.f32 	%f216, %f225, %f226;
$L__BB70_4:
	mul.hi.u32 	%r9, %r37, 715827883;
	and.b32  	%r8, %r6, 15;
	sub.s32 	%r7, %r35, %r36;
	add.rn.f32 	%f133, %f215, %f216;
	st.global.f32 	[%rd8+4], %f133;
	and.b32  	%r79, %r6, 1;
	setp.eq.b32 	%p41, %r79, 1;
	xor.pred  	%p43, %p41, %p94;
	not.pred 	%p44, %p43;
	mov.f32 	%f217, %f220;
	@%p44 bra 	$L__BB70_33;
	bra.uni 	$L__BB70_5;
$L__BB70_33:
	setp.gt.u32 	%p45, %r8, 1;
	@%p45 bra 	$L__BB70_35;
	mul.wide.u32 	%rd146, %r4, 19200;
	add.s64 	%rd147, %rd6, %rd146;
	mul.wide.u32 	%rd148, %r133, 384;
	add.s64 	%rd149, %rd147, %rd148;
	mul.wide.u32 	%rd150, %r7, 4;
	add.s64 	%rd151, %rd149, %rd150;
	ld.global.nc.f32 	%f217, [%rd151];
	bra.uni 	$L__BB70_5;
$L__BB70_35:
	shr.u32 	%r16, %r8, 1;
	shl.b32 	%r80, %r16, 1;
	mul.wide.u32 	%rd129, %r4, 4;
	add.s64 	%rd130, %rd2, %rd129;
	ld.global.nc.f32 	%f134, [%rd130];
	fma.rn.f32 	%f135, %f134, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f136, %f135;
	mov.f32 	%f137, 0f4B400001;
	mov.f32 	%f138, 0f437C0000;
	fma.rm.f32 	%f139, %f136, %f138, %f137;
	add.rn.f32 	%f140, %f139, 0fCB40007F;
	neg.f32 	%f141, %f140;
	fma.rn.f32 	%f142, %f134, 0f3FB8AA3B, %f141;
	fma.rn.f32 	%f143, %f134, 0f32A57060, %f142;
	mov.b32 	%r81, %f139;
	shl.b32 	%r82, %r81, 23;
	mov.b32 	%f144, %r82;
	ex2.approx.ftz.f32 	%f145, %f143;
	mul.rn.f32 	%f146, %f145, %f144;
	neg.f32 	%f147, %f146;
	sub.rn.f32 	%f148, %f147, %f146;
	add.rn.f32 	%f149, %f148, %f148;
	add.rn.f32 	%f150, %f149, %f149;
	add.rn.f32 	%f151, %f150, %f150;
	add.rn.f32 	%f152, %f151, %f151;
	add.rn.f32 	%f153, %f152, %f152;
	fma.rn.f32 	%f154, %f153, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f155, %f154;
	fma.rm.f32 	%f156, %f155, %f138, %f137;
	add.rn.f32 	%f157, %f156, 0fCB40007F;
	neg.f32 	%f158, %f157;
	fma.rn.f32 	%f159, %f153, 0f3FB8AA3B, %f158;
	fma.rn.f32 	%f160, %f153, 0f32A57060, %f159;
	mov.b32 	%r83, %f156;
	shl.b32 	%r84, %r83, 23;
	mov.b32 	%f161, %r84;
	ex2.approx.ftz.f32 	%f162, %f160;
	mul.rn.f32 	%f163, %f162, %f161;
	mul.wide.u32 	%rd131, %r4, 8400;
	add.s64 	%rd132, %rd5, %rd131;
	mul.wide.u32 	%rd133, %r133, 168;
	add.s64 	%rd134, %rd132, %rd133;
	mul.wide.u32 	%rd135, %r16, 24;
	add.s64 	%rd136, %rd134, %rd135;
	mul.wide.u32 	%rd137, %r7, 4;
	add.s64 	%rd138, %rd136, %rd137;
	ld.global.nc.f32 	%f164, [%rd138+-24];
	mul.rn.f32 	%f165, %f164, %f163;
	add.s32 	%r86, %r80, -2;
	mul.wide.u32 	%rd139, %r4, 19200;
	add.s64 	%rd140, %rd6, %rd139;
	mul.wide.u32 	%rd141, %r133, 384;
	add.s64 	%rd142, %rd140, %rd141;
	mul.wide.u32 	%rd143, %r86, 24;
	add.s64 	%rd144, %rd142, %rd143;
	add.s64 	%rd145, %rd144, %rd137;
	ld.global.nc.f32 	%f166, [%rd145+48];
	add.rn.f32 	%f217, %f166, %f165;
$L__BB70_5:
	mul.lo.s32 	%r38, %r9, 6;
	add.s32 	%r88, %r8, -1;
	and.b32  	%r89, %r88, 1;
	setp.eq.b32 	%p46, %r89, 1;
	xor.pred  	%p48, %p46, %p94;
	not.pred 	%p49, %p48;
	mov.f32 	%f218, %f220;
	@%p49 bra 	$L__BB70_36;
	bra.uni 	$L__BB70_6;
$L__BB70_36:
	cvt.u16.u32 	%rs24, %r88;
	and.b16  	%rs25, %rs24, 128;
	shr.u16 	%rs26, %rs25, 7;
	add.s16 	%rs27, %rs24, %rs26;
	shr.u16 	%rs28, %rs27, 1;
	cvt.u32.u16 	%r90, %rs28;
	and.b32  	%r17, %r90, 255;
	and.b32  	%r91, %r17, 1;
	setp.eq.b32 	%p50, %r91, 1;
	xor.pred  	%p52, %p50, %p94;
	not.pred 	%p53, %p52;
	mov.f32 	%f230, 0f00000000;
	mov.f32 	%f229, %f230;
	@%p53 bra 	$L__BB70_39;
	bra.uni 	$L__BB70_37;
$L__BB70_39:
	shr.u32 	%r92, %r17, 1;
	add.s64 	%rd153, %rd7, %rd225;
	mul.wide.u32 	%rd154, %r133, 96;
	add.s64 	%rd155, %rd153, %rd154;
	mul.wide.u32 	%rd156, %r92, 24;
	add.s64 	%rd157, %rd155, %rd156;
	mul.wide.u32 	%rd158, %r7, 4;
	add.s64 	%rd24, %rd157, %rd158;
	ld.global.nc.f32 	%f229, [%rd24];
$L__BB70_37:
	add.s32 	%r94, %r17, -1;
	setp.gt.u32 	%p54, %r8, 2;
	and.b32  	%r95, %r94, 1;
	setp.eq.b32 	%p55, %r95, 1;
	not.pred 	%p56, %p55;
	and.pred  	%p57, %p54, %p56;
	@%p57 bra 	$L__BB70_40;
	bra.uni 	$L__BB70_38;
$L__BB70_40:
	cvt.u64.u32 	%rd23, %r7;
	cvt.u16.u32 	%rs29, %r94;
	and.b16  	%rs30, %rs29, 128;
	shr.u16 	%rs31, %rs30, 7;
	add.s16 	%rs32, %rs29, %rs31;
	cvt.s16.s8 	%rs33, %rs32;
	shr.u16 	%rs34, %rs33, 1;
	cvt.u32.u16 	%r96, %rs34;
	and.b32  	%r22, %r96, 255;
	and.b32  	%r97, %r22, 1;
	setp.eq.b32 	%p58, %r97, 1;
	xor.pred  	%p60, %p58, %p94;
	not.pred 	%p61, %p60;
	mul.lo.s64 	%rd159, %rd223, 2400;
	mul.lo.s64 	%rd161, %rd224, 48;
	shl.b64 	%rd165, %rd23, 2;
	mov.f32 	%f232, 0f00000000;
	mov.f32 	%f231, %f232;
	@%p61 bra 	$L__BB70_43;
	bra.uni 	$L__BB70_41;
$L__BB70_43:
	shr.u32 	%r98, %r22, 1;
	add.s64 	%rd160, %rd3, %rd159;
	add.s64 	%rd162, %rd160, %rd161;
	mul.wide.u32 	%rd163, %r98, 24;
	add.s64 	%rd164, %rd162, %rd163;
	add.s64 	%rd25, %rd164, %rd165;
	ld.global.nc.f32 	%f231, [%rd25];
$L__BB70_41:
	add.s32 	%r99, %r22, -1;
	setp.gt.u32 	%p62, %r8, 6;
	and.b32  	%r100, %r99, 1;
	setp.eq.b32 	%p63, %r100, 1;
	not.pred 	%p64, %p63;
	and.pred  	%p65, %p62, %p64;
	@%p65 bra 	$L__BB70_44;
	bra.uni 	$L__BB70_42;
$L__BB70_44:
	setp.gt.u32 	%p66, %r99, 1;
	add.s64 	%rd167, %rd4, %rd159;
	add.s64 	%rd169, %rd167, %rd161;
	selp.u32 	%r101, 1, 0, %p66;
	mul.wide.u32 	%rd170, %r101, 24;
	add.s64 	%rd171, %rd169, %rd170;
	add.s64 	%rd26, %rd171, %rd165;
	ld.global.nc.f32 	%f232, [%rd26];
$L__BB70_42:
	add.rn.f32 	%f230, %f231, %f232;
$L__BB70_38:
	add.rn.f32 	%f218, %f229, %f230;
$L__BB70_6:
	and.b32  	%r11, %r9, 15;
	sub.s32 	%r10, %r37, %r38;
	add.rn.f32 	%f173, %f217, %f218;
	st.global.f32 	[%rd8+8], %f173;
	and.b32  	%r102, %r9, 1;
	setp.eq.b32 	%p67, %r102, 1;
	xor.pred  	%p69, %p67, %p94;
	not.pred 	%p70, %p69;
	mov.f32 	%f219, %f220;
	@%p70 bra 	$L__BB70_45;
	bra.uni 	$L__BB70_7;
$L__BB70_45:
	setp.gt.u32 	%p71, %r11, 1;
	@%p71 bra 	$L__BB70_47;
	mul.wide.u32 	%rd190, %r4, 19200;
	add.s64 	%rd191, %rd6, %rd190;
	mul.wide.u32 	%rd192, %r133, 384;
	add.s64 	%rd193, %rd191, %rd192;
	mul.wide.u32 	%rd194, %r10, 4;
	add.s64 	%rd195, %rd193, %rd194;
	ld.global.nc.f32 	%f219, [%rd195];
	bra.uni 	$L__BB70_7;
$L__BB70_47:
	shr.u32 	%r18, %r11, 1;
	shl.b32 	%r103, %r18, 1;
	mul.wide.u32 	%rd173, %r4, 4;
	add.s64 	%rd174, %rd2, %rd173;
	ld.global.nc.f32 	%f174, [%rd174];
	fma.rn.f32 	%f175, %f174, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f176, %f175;
	mov.f32 	%f177, 0f4B400001;
	mov.f32 	%f178, 0f437C0000;
	fma.rm.f32 	%f179, %f176, %f178, %f177;
	add.rn.f32 	%f180, %f179, 0fCB40007F;
	neg.f32 	%f181, %f180;
	fma.rn.f32 	%f182, %f174, 0f3FB8AA3B, %f181;
	fma.rn.f32 	%f183, %f174, 0f32A57060, %f182;
	mov.b32 	%r104, %f179;
	shl.b32 	%r105, %r104, 23;
	mov.b32 	%f184, %r105;
	ex2.approx.ftz.f32 	%f185, %f183;
	mul.rn.f32 	%f186, %f185, %f184;
	neg.f32 	%f187, %f186;
	sub.rn.f32 	%f188, %f187, %f186;
	add.rn.f32 	%f189, %f188, %f188;
	add.rn.f32 	%f190, %f189, %f189;
	add.rn.f32 	%f191, %f190, %f190;
	add.rn.f32 	%f192, %f191, %f191;
	add.rn.f32 	%f193, %f192, %f192;
	fma.rn.f32 	%f194, %f193, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f195, %f194;
	fma.rm.f32 	%f196, %f195, %f178, %f177;
	add.rn.f32 	%f197, %f196, 0fCB40007F;
	neg.f32 	%f198, %f197;
	fma.rn.f32 	%f199, %f193, 0f3FB8AA3B, %f198;
	fma.rn.f32 	%f200, %f193, 0f32A57060, %f199;
	mov.b32 	%r106, %f196;
	shl.b32 	%r107, %r106, 23;
	mov.b32 	%f201, %r107;
	ex2.approx.ftz.f32 	%f202, %f200;
	mul.rn.f32 	%f203, %f202, %f201;
	mul.wide.u32 	%rd175, %r4, 8400;
	add.s64 	%rd176, %rd5, %rd175;
	mul.wide.u32 	%rd177, %r133, 168;
	add.s64 	%rd178, %rd176, %rd177;
	mul.wide.u32 	%rd179, %r18, 24;
	add.s64 	%rd180, %rd178, %rd179;
	mul.wide.u32 	%rd181, %r10, 4;
	add.s64 	%rd182, %rd180, %rd181;
	ld.global.nc.f32 	%f204, [%rd182+-24];
	mul.rn.f32 	%f205, %f204, %f203;
	add.s32 	%r109, %r103, -2;
	mul.wide.u32 	%rd183, %r4, 19200;
	add.s64 	%rd184, %rd6, %rd183;
	mul.wide.u32 	%rd185, %r133, 384;
	add.s64 	%rd186, %rd184, %rd185;
	mul.wide.u32 	%rd187, %r109, 24;
	add.s64 	%rd188, %rd186, %rd187;
	add.s64 	%rd189, %rd188, %rd181;
	ld.global.nc.f32 	%f206, [%rd189+48];
	add.rn.f32 	%f219, %f206, %f205;
$L__BB70_7:
	add.s32 	%r111, %r11, -1;
	and.b32  	%r112, %r111, 1;
	setp.eq.b32 	%p72, %r112, 1;
	xor.pred  	%p74, %p72, %p94;
	not.pred 	%p75, %p74;
	@%p75 bra 	$L__BB70_48;
	bra.uni 	$L__BB70_8;
$L__BB70_48:
	cvt.u16.u32 	%rs35, %r111;
	and.b16  	%rs36, %rs35, 128;
	shr.u16 	%rs37, %rs36, 7;
	add.s16 	%rs38, %rs35, %rs37;
	shr.u16 	%rs39, %rs38, 1;
	cvt.u32.u16 	%r113, %rs39;
	and.b32  	%r19, %r113, 255;
	and.b32  	%r114, %r19, 1;
	setp.eq.b32 	%p76, %r114, 1;
	xor.pred  	%p78, %p76, %p94;
	not.pred 	%p79, %p78;
	mov.f32 	%f234, 0f00000000;
	mov.f32 	%f233, %f234;
	@%p79 bra 	$L__BB70_51;
	bra.uni 	$L__BB70_49;
$L__BB70_51:
	shr.u32 	%r115, %r19, 1;
	add.s64 	%rd197, %rd7, %rd225;
	mul.wide.u32 	%rd198, %r133, 96;
	add.s64 	%rd199, %rd197, %rd198;
	mul.wide.u32 	%rd200, %r115, 24;
	add.s64 	%rd201, %rd199, %rd200;
	mul.wide.u32 	%rd202, %r10, 4;
	add.s64 	%rd30, %rd201, %rd202;
	ld.global.nc.f32 	%f233, [%rd30];
$L__BB70_49:
	add.s32 	%r117, %r19, -1;
	setp.gt.u32 	%p80, %r11, 2;
	and.b32  	%r118, %r117, 1;
	setp.eq.b32 	%p81, %r118, 1;
	not.pred 	%p82, %p81;
	and.pred  	%p83, %p80, %p82;
	@%p83 bra 	$L__BB70_52;
	bra.uni 	$L__BB70_50;
$L__BB70_52:
	cvt.u64.u32 	%rd29, %r10;
	cvt.u16.u32 	%rs40, %r117;
	and.b16  	%rs41, %rs40, 128;
	shr.u16 	%rs42, %rs41, 7;
	add.s16 	%rs43, %rs40, %rs42;
	cvt.s16.s8 	%rs44, %rs43;
	shr.u16 	%rs45, %rs44, 1;
	cvt.u32.u16 	%r119, %rs45;
	and.b32  	%r23, %r119, 255;
	and.b32  	%r120, %r23, 1;
	setp.eq.b32 	%p84, %r120, 1;
	xor.pred  	%p86, %p84, %p94;
	not.pred 	%p87, %p86;
	mul.lo.s64 	%rd203, %rd223, 2400;
	mul.lo.s64 	%rd205, %rd224, 48;
	shl.b64 	%rd209, %rd29, 2;
	mov.f32 	%f236, 0f00000000;
	mov.f32 	%f235, %f236;
	@%p87 bra 	$L__BB70_55;
	bra.uni 	$L__BB70_53;
$L__BB70_55:
	shr.u32 	%r121, %r23, 1;
	add.s64 	%rd204, %rd3, %rd203;
	add.s64 	%rd206, %rd204, %rd205;
	mul.wide.u32 	%rd207, %r121, 24;
	add.s64 	%rd208, %rd206, %rd207;
	add.s64 	%rd31, %rd208, %rd209;
	ld.global.nc.f32 	%f235, [%rd31];
$L__BB70_53:
	add.s32 	%r122, %r23, -1;
	setp.gt.u32 	%p88, %r11, 6;
	and.b32  	%r123, %r122, 1;
	setp.eq.b32 	%p89, %r123, 1;
	not.pred 	%p90, %p89;
	and.pred  	%p91, %p88, %p90;
	@%p91 bra 	$L__BB70_56;
	bra.uni 	$L__BB70_54;
$L__BB70_56:
	setp.gt.u32 	%p92, %r122, 1;
	add.s64 	%rd211, %rd4, %rd203;
	add.s64 	%rd213, %rd211, %rd205;
	selp.u32 	%r124, 1, 0, %p92;
	mul.wide.u32 	%rd214, %r124, 24;
	add.s64 	%rd215, %rd213, %rd214;
	add.s64 	%rd32, %rd215, %rd209;
	ld.global.nc.f32 	%f236, [%rd32];
$L__BB70_54:
	add.rn.f32 	%f234, %f235, %f236;
$L__BB70_50:
	add.rn.f32 	%f220, %f233, %f234;
$L__BB70_8:
	add.rn.f32 	%f212, %f219, %f220;
	st.global.f32 	[%rd8+12], %f212;
	ret;

}
	// .globl	input_concatenate_fusion_193
.visible .entry input_concatenate_fusion_193(
	.param .u64 input_concatenate_fusion_193_param_0,
	.param .u64 input_concatenate_fusion_193_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<22>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_193_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_193_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -1431655765;
	shr.u32 	%r6, %r5, 1;
	mul.lo.s32 	%r7, %r6, 3;
	sub.s32 	%r8, %r4, %r7;
	mul.hi.u32 	%r9, %r6, -2004318071;
	shr.u32 	%r10, %r9, 3;
	mul.lo.s32 	%r11, %r10, 15;
	sub.s32 	%r12, %r6, %r11;
	mul.hi.u32 	%r13, %r4, 1813430637;
	sub.s32 	%r14, %r4, %r13;
	shr.u32 	%r15, %r14, 1;
	add.s32 	%r16, %r15, %r13;
	shr.u32 	%r17, %r16, 5;
	cvt.u16.u32 	%rs1, %r17;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r18, %r4, -385592619;
	bfe.u32 	%r19, %r18, 11, 6;
	shl.b32 	%r20, %r8, 1;
	or.b32  	%r21, %r20, 1;
	setp.gt.u32 	%p1, %r8, 1;
	selp.b32 	%r22, 5, %r21, %p1;
	cvt.u32.u16 	%r23, %rs6;
	mul.wide.u32 	%rd5, %r23, 384;
	mul.wide.u32 	%rd6, %r19, 19200;
	add.s64 	%rd7, %rd4, %rd6;
	add.s64 	%rd8, %rd7, %rd5;
	mul.wide.u32 	%rd9, %r12, 24;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r22, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	neg.f32 	%f2, %f1;
	mul.wide.u32 	%rd13, %r23, 360;
	mul.wide.u32 	%rd14, %r19, 18000;
	add.s64 	%rd15, %rd3, %rd14;
	add.s64 	%rd16, %rd15, %rd13;
	add.s64 	%rd17, %rd16, %rd9;
	mul.wide.u32 	%rd18, %r8, 8;
	add.s64 	%rd19, %rd17, %rd18;
	mul.wide.u32 	%rd20, %r20, 4;
	add.s64 	%rd21, %rd10, %rd20;
	ld.global.nc.f32 	%f3, [%rd21];
	st.global.v2.f32 	[%rd19], {%f2, %f3};
	ret;

}
	// .globl	input_concatenate_fusion_194
.visible .entry input_concatenate_fusion_194(
	.param .u64 input_concatenate_fusion_194_param_0,
	.param .u64 input_concatenate_fusion_194_param_1,
	.param .u64 input_concatenate_fusion_194_param_2,
	.param .u64 input_concatenate_fusion_194_param_3,
	.param .u64 input_concatenate_fusion_194_param_4,
	.param .u64 input_concatenate_fusion_194_param_5,
	.param .u64 input_concatenate_fusion_194_param_6,
	.param .u64 input_concatenate_fusion_194_param_7
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot72[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<52>;
	.reg .b16 	%rs<5>;
	.reg .b32 	%r<350>;
	.reg .f32 	%f<195>;
	.reg .b64 	%rd<190>;
	.reg .f64 	%fd<13>;

	mov.u64 	%SPL, __local_depot72;
	ld.param.u64 	%rd45, [input_concatenate_fusion_194_param_0];
	ld.param.u64 	%rd46, [input_concatenate_fusion_194_param_7];
	cvta.to.global.u64 	%rd1, %rd46;
	ld.param.u64 	%rd47, [input_concatenate_fusion_194_param_1];
	ld.param.u64 	%rd48, [input_concatenate_fusion_194_param_6];
	cvta.to.global.u64 	%rd2, %rd48;
	ld.param.u64 	%rd50, [input_concatenate_fusion_194_param_5];
	cvta.to.global.u64 	%rd3, %rd50;
	ld.param.u64 	%rd51, [input_concatenate_fusion_194_param_3];
	ld.param.u64 	%rd52, [input_concatenate_fusion_194_param_4];
	cvta.to.global.u64 	%rd4, %rd52;
	cvta.to.global.u64 	%rd7, %rd47;
	cvta.to.global.u64 	%rd8, %rd45;
	add.u64 	%rd9, %SPL, 0;
	mov.u32 	%r102, %ctaid.x;
	mov.u32 	%r103, %tid.x;
	shl.b32 	%r104, %r102, 7;
	or.b32  	%r1, %r104, %r103;
	mul.hi.u32 	%r105, %r1, -1431655765;
	shr.u32 	%r2, %r105, 2;
	mul.lo.s32 	%r106, %r2, 6;
	sub.s32 	%r3, %r1, %r106;
	setp.lt.u32 	%p1, %r1, 19200;
	shr.u32 	%r324, %r3, 1;
	mov.f32 	%f188, 0f00000000;
	cvt.u64.u32 	%rd181, %r3;
	mul.wide.u32 	%rd182, %r3, 4;
	and.b32  	%r325, %r3, 1;
	@%p1 bra 	$L__BB72_2;
	bra.uni 	$L__BB72_1;
$L__BB72_2:
	cvt.u16.u32 	%rs1, %r1;
	shr.u16 	%rs2, %rs1, 2;
	mul.hi.u16 	%rs3, %rs2, 27963;
	shr.u16 	%rs4, %rs3, 5;
	mul.hi.u32 	%r108, %r2, 85899346;
	mul.lo.s32 	%r109, %r108, 50;
	sub.s32 	%r4, %r2, %r109;
	cvt.u64.u16 	%rd16, %rs4;
	cvt.u32.u16 	%r110, %rs4;
	mul.wide.u32 	%rd59, %r110, 4;
	add.s64 	%rd60, %rd7, %rd59;
	ld.global.nc.f32 	%f1, [%rd60];
	mul.wide.u32 	%rd61, %r110, 12;
	add.s64 	%rd62, %rd3, %rd61;
	mul.wide.u32 	%rd63, %r324, 4;
	add.s64 	%rd64, %rd62, %rd63;
	ld.global.nc.f32 	%f2, [%rd64];
	mul.rn.f32 	%f35, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r333, %f35;
	cvt.rn.f32.s32 	%f36, %r333;
	fma.rn.f32 	%f37, %f36, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f38, %f36, 0fB3A22168, %f37;
	fma.rn.f32 	%f190, %f36, 0fA7C234C5, %f38;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p2, %f4, 0f47CE4780;
	mov.u32 	%r329, %r333;
	mov.f32 	%f189, %f190;
	@%p2 bra 	$L__BB72_10;
	setp.neu.f32 	%p3, %f4, 0f7F800000;
	@%p3 bra 	$L__BB72_5;
	mul.rn.f32 	%f189, %f2, %f188;
	mov.b32 	%r329, 0;
	bra.uni 	$L__BB72_10;
$L__BB72_1:
	cvt.u64.u32 	%rd185, %r324;
	bra.uni 	$L__BB72_19;
$L__BB72_5:
	mov.b32 	%r6, %f2;
	shr.u32 	%r7, %r6, 23;
	and.b32  	%r113, %r7, 224;
	add.s32 	%r114, %r113, -128;
	shl.b32 	%r115, %r6, 8;
	or.b32  	%r119, %r115, -2147483648;
	shr.u32 	%r9, %r114, 5;
	mov.b32 	%r326, 0;
	mov.u64 	%rd183, 0;
	mov.u64 	%rd66, __cudart_i2opi_f;
$L__BB72_6:
	.pragma "nounroll";
	add.s64 	%rd67, %rd66, %rd183;
	ld.global.nc.u32 	%r118, [%rd67];
	// begin inline asm
	{
	mad.lo.cc.u32   %r116, %r118, %r119, %r326;
	madc.hi.u32     %r326, %r118, %r119,  0;
	}
	// end inline asm
	add.s64 	%rd68, %rd9, %rd183;
	st.local.u32 	[%rd68], %r116;
	add.s64 	%rd183, %rd183, 4;
	cvt.u32.u64 	%r121, %rd183;
	setp.ne.s32 	%p4, %r121, 24;
	@%p4 bra 	$L__BB72_6;
	st.local.u32 	[%rd9+24], %r326;
	and.b32  	%r12, %r7, 31;
	mul.wide.u32 	%rd69, %r9, 4;
	sub.s64 	%rd20, %rd9, %rd69;
	ld.local.u32 	%r327, [%rd20+24];
	ld.local.u32 	%r328, [%rd20+20];
	setp.eq.s32 	%p5, %r12, 0;
	@%p5 bra 	$L__BB72_9;
	shl.b32 	%r122, %r328, %r12;
	shl.b32 	%r123, %r327, %r12;
	mov.b32 	%r124, 32;
	sub.s32 	%r125, %r124, %r12;
	shr.u32 	%r126, %r328, %r125;
	add.s32 	%r327, %r126, %r123;
	ld.local.u32 	%r127, [%rd20+16];
	shr.u32 	%r128, %r127, %r125;
	add.s32 	%r328, %r128, %r122;
$L__BB72_9:
	shr.u32 	%r129, %r327, 30;
	shr.u32 	%r130, %r328, 30;
	shl.b32 	%r131, %r327, 2;
	or.b32  	%r132, %r131, %r130;
	shl.b32 	%r133, %r328, 2;
	bfe.u32 	%r134, %r327, 29, 1;
	add.s32 	%r135, %r134, %r129;
	neg.s32 	%r136, %r135;
	setp.lt.s32 	%p6, %r6, 0;
	selp.b32 	%r329, %r136, %r135, %p6;
	xor.b32  	%r137, %r132, %r6;
	bfe.s32 	%r138, %r327, 29, 1;
	xor.b32  	%r139, %r138, %r132;
	xor.b32  	%r140, %r138, %r133;
	cvt.u64.u32 	%rd70, %r139;
	shl.b64 	%rd71, %rd70, 32;
	cvt.u64.u32 	%rd72, %r140;
	or.b64  	%rd73, %rd71, %rd72;
	cvt.rn.f64.s64 	%fd1, %rd73;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f39, %fd2;
	neg.f32 	%f40, %f39;
	setp.lt.s32 	%p7, %r137, 0;
	selp.f32 	%f189, %f40, %f39, %p7;
$L__BB72_10:
	cvt.u64.u32 	%rd185, %r324;
	add.s32 	%r142, %r329, 1;
	mul.rn.f32 	%f42, %f189, %f189;
	and.b32  	%r143, %r329, 1;
	setp.eq.b32 	%p9, %r143, 1;
	selp.f32 	%f43, %f189, 0f3F800000, %p9;
	fma.rn.f32 	%f44, %f42, %f43, 0f00000000;
	fma.rn.f32 	%f45, %f42, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f46, 0fB94D4153, %f45, %p9;
	selp.f32 	%f47, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f48, %f46, %f42, %f47;
	selp.f32 	%f49, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f50, %f48, %f42, %f49;
	fma.rn.f32 	%f51, %f50, %f44, %f43;
	and.b32  	%r144, %r142, 2;
	setp.eq.s32 	%p10, %r144, 0;
	sub.rn.f32 	%f53, %f188, %f51;
	selp.f32 	%f54, %f51, %f53, %p10;
	cvt.u64.u32 	%rd21, %r4;
	mul.lo.s64 	%rd74, %rd16, 76800;
	add.s64 	%rd75, %rd8, %rd74;
	mul.wide.u32 	%rd76, %r4, 1536;
	add.s64 	%rd77, %rd75, %rd76;
	add.s64 	%rd23, %rd77, %rd182;
	ld.global.nc.f32 	%f55, [%rd23];
	mul.rn.f32 	%f8, %f55, %f54;
	@%p2 bra 	$L__BB72_18;
	setp.neu.f32 	%p11, %f4, 0f7F800000;
	@%p11 bra 	$L__BB72_13;
	mul.rn.f32 	%f190, %f2, %f188;
	mov.b32 	%r333, 0;
	bra.uni 	$L__BB72_18;
$L__BB72_13:
	mov.b32 	%r21, %f2;
	shr.u32 	%r22, %r21, 23;
	and.b32  	%r146, %r22, 224;
	add.s32 	%r147, %r146, -128;
	shl.b32 	%r148, %r21, 8;
	or.b32  	%r152, %r148, -2147483648;
	shr.u32 	%r24, %r147, 5;
	mov.b32 	%r330, 0;
	mov.u64 	%rd184, 0;
	mov.u64 	%rd80, __cudart_i2opi_f;
$L__BB72_14:
	.pragma "nounroll";
	add.s64 	%rd81, %rd80, %rd184;
	ld.global.nc.u32 	%r151, [%rd81];
	// begin inline asm
	{
	mad.lo.cc.u32   %r149, %r151, %r152, %r330;
	madc.hi.u32     %r330, %r151, %r152,  0;
	}
	// end inline asm
	add.s64 	%rd82, %rd9, %rd184;
	st.local.u32 	[%rd82], %r149;
	add.s64 	%rd184, %rd184, 4;
	cvt.u32.u64 	%r154, %rd184;
	setp.ne.s32 	%p12, %r154, 24;
	@%p12 bra 	$L__BB72_14;
	st.local.u32 	[%rd9+24], %r330;
	and.b32  	%r27, %r22, 31;
	mul.wide.u32 	%rd83, %r24, 4;
	sub.s64 	%rd26, %rd9, %rd83;
	ld.local.u32 	%r331, [%rd26+24];
	ld.local.u32 	%r332, [%rd26+20];
	setp.eq.s32 	%p13, %r27, 0;
	@%p13 bra 	$L__BB72_17;
	shl.b32 	%r155, %r332, %r27;
	shl.b32 	%r156, %r331, %r27;
	mov.b32 	%r157, 32;
	sub.s32 	%r158, %r157, %r27;
	shr.u32 	%r159, %r332, %r158;
	add.s32 	%r331, %r159, %r156;
	ld.local.u32 	%r160, [%rd26+16];
	shr.u32 	%r161, %r160, %r158;
	add.s32 	%r332, %r161, %r155;
$L__BB72_17:
	shr.u32 	%r162, %r331, 30;
	shr.u32 	%r163, %r332, 30;
	shl.b32 	%r164, %r331, 2;
	or.b32  	%r165, %r164, %r163;
	shl.b32 	%r166, %r332, 2;
	bfe.u32 	%r167, %r331, 29, 1;
	add.s32 	%r168, %r167, %r162;
	neg.s32 	%r169, %r168;
	setp.lt.s32 	%p14, %r21, 0;
	selp.b32 	%r333, %r169, %r168, %p14;
	xor.b32  	%r170, %r165, %r21;
	bfe.s32 	%r171, %r331, 29, 1;
	xor.b32  	%r172, %r171, %r165;
	xor.b32  	%r173, %r171, %r166;
	cvt.u64.u32 	%rd84, %r172;
	shl.b64 	%rd85, %rd84, 32;
	cvt.u64.u32 	%rd86, %r173;
	or.b64  	%rd87, %rd85, %rd86;
	cvt.rn.f64.s64 	%fd3, %rd87;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f56, %fd4;
	neg.f32 	%f57, %f56;
	setp.lt.s32 	%p15, %r170, 0;
	selp.f32 	%f190, %f57, %f56, %p15;
$L__BB72_18:
	mul.rn.f32 	%f59, %f190, %f190;
	and.b32  	%r175, %r333, 1;
	setp.eq.b32 	%p16, %r175, 1;
	selp.f32 	%f60, 0f3F800000, %f190, %p16;
	fma.rn.f32 	%f61, %f59, %f60, 0f00000000;
	fma.rn.f32 	%f62, %f59, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f63, %f62, 0fB94D4153, %p16;
	selp.f32 	%f64, 0f3D2AAABB, 0f3C0885E4, %p16;
	fma.rn.f32 	%f65, %f63, %f59, %f64;
	selp.f32 	%f66, 0fBEFFFFFF, 0fBE2AAAA8, %p16;
	fma.rn.f32 	%f67, %f65, %f59, %f66;
	fma.rn.f32 	%f68, %f67, %f61, %f60;
	and.b32  	%r176, %r333, 2;
	setp.eq.s32 	%p17, %r176, 0;
	sub.rn.f32 	%f70, %f188, %f68;
	selp.f32 	%f71, %f68, %f70, %p17;
	mul.lo.s64 	%rd88, %rd16, 38400;
	add.s64 	%rd89, %rd4, %rd88;
	mul.lo.s64 	%rd90, %rd21, 768;
	add.s64 	%rd91, %rd89, %rd90;
	shl.b64 	%rd92, %rd185, 3;
	add.s64 	%rd93, %rd91, %rd92;
	mul.wide.u32 	%rd94, %r325, 4;
	add.s64 	%rd95, %rd93, %rd94;
	ld.global.nc.f32 	%f72, [%rd95];
	mul.rn.f32 	%f73, %f72, %f71;
	add.rn.f32 	%f74, %f8, %f73;
	mul.rn.f32 	%f75, %f1, %f74;
	ld.global.nc.f32 	%f76, [%rd23+24];
	add.rn.f32 	%f77, %f76, %f75;
	mul.lo.s64 	%rd96, %rd16, 19200;
	add.s64 	%rd97, %rd1, %rd96;
	mul.lo.s64 	%rd98, %rd21, 384;
	add.s64 	%rd99, %rd97, %rd98;
	shl.b64 	%rd100, %rd181, 2;
	add.s64 	%rd101, %rd99, %rd100;
	st.global.f32 	[%rd101], %f77;
$L__BB72_19:
	ld.param.u64 	%rd49, [input_concatenate_fusion_194_param_2];
	cvta.to.global.u64 	%rd5, %rd51;
	mul.hi.u32 	%r178, %r1, -385592619;
	bfe.u32 	%r179, %r178, 12, 6;
	shr.u32 	%r180, %r1, 1;
	mul.hi.u32 	%r181, %r180, -1240768329;
	shr.u32 	%r182, %r181, 5;
	mul.hi.u32 	%r183, %r182, 85899346;
	mul.lo.s32 	%r184, %r183, 50;
	sub.s32 	%r36, %r182, %r184;
	mul.hi.u32 	%r185, %r2, 1145324613;
	shr.u32 	%r186, %r185, 2;
	mul.lo.s32 	%r187, %r186, 15;
	sub.s32 	%r37, %r2, %r187;
	cvt.u64.u32 	%rd28, %r179;
	mul.wide.u32 	%rd102, %r179, 4;
	add.s64 	%rd103, %rd2, %rd102;
	ld.global.nc.f32 	%f12, [%rd103];
	mul.wide.u32 	%rd104, %r179, 12;
	add.s64 	%rd105, %rd3, %rd104;
	shl.b64 	%rd106, %rd185, 2;
	add.s64 	%rd107, %rd105, %rd106;
	ld.global.nc.f32 	%f13, [%rd107];
	add.rn.f32 	%f14, %f13, %f13;
	mul.rn.f32 	%f78, %f14, 0f3F22F983;
	cvt.rni.s32.f32 	%r341, %f78;
	cvt.rn.f32.s32 	%f79, %r341;
	fma.rn.f32 	%f80, %f79, 0fBFC90FDA, %f14;
	fma.rn.f32 	%f81, %f79, 0fB3A22168, %f80;
	fma.rn.f32 	%f192, %f79, 0fA7C234C5, %f81;
	abs.f32 	%f16, %f14;
	setp.ltu.f32 	%p18, %f16, 0f47CE4780;
	setp.neu.f32 	%p50, %f16, 0f7F800000;
	mov.u32 	%r337, %r341;
	mov.f32 	%f191, %f192;
	@%p18 bra 	$L__BB72_27;
	@%p50 bra 	$L__BB72_22;
	mul.rn.f32 	%f191, %f14, %f188;
	mov.b32 	%r337, 0;
	bra.uni 	$L__BB72_27;
$L__BB72_22:
	mov.b32 	%r39, %f14;
	shr.u32 	%r40, %r39, 23;
	and.b32  	%r189, %r40, 224;
	add.s32 	%r190, %r189, -128;
	shl.b32 	%r191, %r39, 8;
	or.b32  	%r195, %r191, -2147483648;
	shr.u32 	%r42, %r190, 5;
	mov.b32 	%r334, 0;
	mov.u64 	%rd186, 0;
	mov.u64 	%rd109, __cudart_i2opi_f;
$L__BB72_23:
	.pragma "nounroll";
	add.s64 	%rd110, %rd109, %rd186;
	ld.global.nc.u32 	%r194, [%rd110];
	// begin inline asm
	{
	mad.lo.cc.u32   %r192, %r194, %r195, %r334;
	madc.hi.u32     %r334, %r194, %r195,  0;
	}
	// end inline asm
	add.s64 	%rd111, %rd9, %rd186;
	st.local.u32 	[%rd111], %r192;
	add.s64 	%rd186, %rd186, 4;
	cvt.u32.u64 	%r197, %rd186;
	setp.ne.s32 	%p20, %r197, 24;
	@%p20 bra 	$L__BB72_23;
	st.local.u32 	[%rd9+24], %r334;
	and.b32  	%r45, %r40, 31;
	mul.wide.u32 	%rd112, %r42, 4;
	sub.s64 	%rd31, %rd9, %rd112;
	ld.local.u32 	%r335, [%rd31+24];
	ld.local.u32 	%r336, [%rd31+20];
	setp.eq.s32 	%p21, %r45, 0;
	@%p21 bra 	$L__BB72_26;
	shl.b32 	%r198, %r336, %r45;
	shl.b32 	%r199, %r335, %r45;
	mov.b32 	%r200, 32;
	sub.s32 	%r201, %r200, %r45;
	shr.u32 	%r202, %r336, %r201;
	add.s32 	%r335, %r202, %r199;
	ld.local.u32 	%r203, [%rd31+16];
	shr.u32 	%r204, %r203, %r201;
	add.s32 	%r336, %r204, %r198;
$L__BB72_26:
	shr.u32 	%r205, %r335, 30;
	shr.u32 	%r206, %r336, 30;
	shl.b32 	%r207, %r335, 2;
	or.b32  	%r208, %r207, %r206;
	shl.b32 	%r209, %r336, 2;
	bfe.u32 	%r210, %r335, 29, 1;
	add.s32 	%r211, %r210, %r205;
	neg.s32 	%r212, %r211;
	setp.lt.s32 	%p22, %r39, 0;
	selp.b32 	%r337, %r212, %r211, %p22;
	xor.b32  	%r213, %r208, %r39;
	bfe.s32 	%r214, %r335, 29, 1;
	xor.b32  	%r215, %r214, %r208;
	xor.b32  	%r216, %r214, %r209;
	cvt.u64.u32 	%rd113, %r215;
	shl.b64 	%rd114, %rd113, 32;
	cvt.u64.u32 	%rd115, %r216;
	or.b64  	%rd116, %rd114, %rd115;
	cvt.rn.f64.s64 	%fd5, %rd116;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f82, %fd6;
	neg.f32 	%f83, %f82;
	setp.lt.s32 	%p23, %r213, 0;
	selp.f32 	%f191, %f83, %f82, %p23;
$L__BB72_27:
	cvta.to.global.u64 	%rd6, %rd49;
	mul.lo.s64 	%rd117, %rd28, 19200;
	add.s64 	%rd118, %rd5, %rd117;
	mul.wide.u32 	%rd119, %r36, 384;
	add.s64 	%rd120, %rd118, %rd119;
	mul.wide.u32 	%rd121, %r37, 24;
	add.s64 	%rd122, %rd120, %rd121;
	add.s64 	%rd124, %rd122, %rd182;
	ld.global.nc.f32 	%f20, [%rd124];
	@%p18 bra 	$L__BB72_35;
	@%p50 bra 	$L__BB72_30;
	mul.rn.f32 	%f192, %f14, %f188;
	mov.b32 	%r341, 0;
	bra.uni 	$L__BB72_35;
$L__BB72_30:
	mov.b32 	%r54, %f14;
	shr.u32 	%r55, %r54, 23;
	and.b32  	%r219, %r55, 224;
	add.s32 	%r220, %r219, -128;
	shl.b32 	%r221, %r54, 8;
	or.b32  	%r225, %r221, -2147483648;
	shr.u32 	%r57, %r220, 5;
	mov.b32 	%r338, 0;
	mov.u64 	%rd187, 0;
	mov.u64 	%rd126, __cudart_i2opi_f;
$L__BB72_31:
	.pragma "nounroll";
	add.s64 	%rd127, %rd126, %rd187;
	ld.global.nc.u32 	%r224, [%rd127];
	// begin inline asm
	{
	mad.lo.cc.u32   %r222, %r224, %r225, %r338;
	madc.hi.u32     %r338, %r224, %r225,  0;
	}
	// end inline asm
	add.s64 	%rd128, %rd9, %rd187;
	st.local.u32 	[%rd128], %r222;
	add.s64 	%rd187, %rd187, 4;
	cvt.u32.u64 	%r227, %rd187;
	setp.ne.s32 	%p26, %r227, 24;
	@%p26 bra 	$L__BB72_31;
	st.local.u32 	[%rd9+24], %r338;
	and.b32  	%r60, %r55, 31;
	mul.wide.u32 	%rd129, %r57, 4;
	sub.s64 	%rd37, %rd9, %rd129;
	ld.local.u32 	%r339, [%rd37+24];
	ld.local.u32 	%r340, [%rd37+20];
	setp.eq.s32 	%p27, %r60, 0;
	@%p27 bra 	$L__BB72_34;
	shl.b32 	%r228, %r340, %r60;
	shl.b32 	%r229, %r339, %r60;
	mov.b32 	%r230, 32;
	sub.s32 	%r231, %r230, %r60;
	shr.u32 	%r232, %r340, %r231;
	add.s32 	%r339, %r232, %r229;
	ld.local.u32 	%r233, [%rd37+16];
	shr.u32 	%r234, %r233, %r231;
	add.s32 	%r340, %r234, %r228;
$L__BB72_34:
	shr.u32 	%r235, %r339, 30;
	shr.u32 	%r236, %r340, 30;
	shl.b32 	%r237, %r339, 2;
	or.b32  	%r238, %r237, %r236;
	shl.b32 	%r239, %r340, 2;
	bfe.u32 	%r240, %r339, 29, 1;
	add.s32 	%r241, %r240, %r235;
	neg.s32 	%r242, %r241;
	setp.lt.s32 	%p28, %r54, 0;
	selp.b32 	%r341, %r242, %r241, %p28;
	xor.b32  	%r243, %r238, %r54;
	bfe.s32 	%r244, %r339, 29, 1;
	xor.b32  	%r245, %r244, %r238;
	xor.b32  	%r246, %r244, %r239;
	cvt.u64.u32 	%rd130, %r245;
	shl.b64 	%rd131, %rd130, 32;
	cvt.u64.u32 	%rd132, %r246;
	or.b64  	%rd133, %rd131, %rd132;
	cvt.rn.f64.s64 	%fd7, %rd133;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f85, %fd8;
	neg.f32 	%f86, %f85;
	setp.lt.s32 	%p29, %r243, 0;
	selp.f32 	%f192, %f86, %f85, %p29;
$L__BB72_35:
	cvt.u64.u32 	%rd32, %r36;
	mul.wide.u32 	%rd134, %r1, 4;
	add.s64 	%rd135, %rd6, %rd134;
	ld.global.nc.f32 	%f24, [%rd135];
	shl.b32 	%r69, %r37, 1;
	add.s32 	%r70, %r69, 2;
	shl.b64 	%rd136, %rd28, 2;
	add.s64 	%rd137, %rd7, %rd136;
	ld.global.nc.f32 	%f25, [%rd137];
	mul.rn.f32 	%f88, %f13, 0f3F22F983;
	cvt.rni.s32.f32 	%r349, %f88;
	cvt.rn.f32.s32 	%f89, %r349;
	fma.rn.f32 	%f90, %f89, 0fBFC90FDA, %f13;
	fma.rn.f32 	%f91, %f89, 0fB3A22168, %f90;
	fma.rn.f32 	%f194, %f89, 0fA7C234C5, %f91;
	abs.f32 	%f27, %f13;
	setp.ltu.f32 	%p30, %f27, 0f47CE4780;
	setp.neu.f32 	%p51, %f27, 0f7F800000;
	mov.u32 	%r345, %r349;
	mov.f32 	%f193, %f194;
	@%p30 bra 	$L__BB72_43;
	@%p51 bra 	$L__BB72_38;
	mul.rn.f32 	%f193, %f13, %f188;
	mov.b32 	%r345, 0;
	bra.uni 	$L__BB72_43;
$L__BB72_38:
	mov.b32 	%r72, %f13;
	shr.u32 	%r73, %r72, 23;
	and.b32  	%r249, %r73, 224;
	add.s32 	%r250, %r249, -128;
	shl.b32 	%r251, %r72, 8;
	or.b32  	%r255, %r251, -2147483648;
	shr.u32 	%r75, %r250, 5;
	mov.b32 	%r342, 0;
	mov.u64 	%rd188, 0;
	mov.u64 	%rd139, __cudart_i2opi_f;
$L__BB72_39:
	.pragma "nounroll";
	add.s64 	%rd140, %rd139, %rd188;
	ld.global.nc.u32 	%r254, [%rd140];
	// begin inline asm
	{
	mad.lo.cc.u32   %r252, %r254, %r255, %r342;
	madc.hi.u32     %r342, %r254, %r255,  0;
	}
	// end inline asm
	add.s64 	%rd141, %rd9, %rd188;
	st.local.u32 	[%rd141], %r252;
	add.s64 	%rd188, %rd188, 4;
	cvt.u32.u64 	%r257, %rd188;
	setp.ne.s32 	%p32, %r257, 24;
	@%p32 bra 	$L__BB72_39;
	st.local.u32 	[%rd9+24], %r342;
	and.b32  	%r78, %r73, 31;
	mul.wide.u32 	%rd142, %r75, 4;
	sub.s64 	%rd40, %rd9, %rd142;
	ld.local.u32 	%r343, [%rd40+24];
	ld.local.u32 	%r344, [%rd40+20];
	setp.eq.s32 	%p33, %r78, 0;
	@%p33 bra 	$L__BB72_42;
	shl.b32 	%r258, %r344, %r78;
	shl.b32 	%r259, %r343, %r78;
	mov.b32 	%r260, 32;
	sub.s32 	%r261, %r260, %r78;
	shr.u32 	%r262, %r344, %r261;
	add.s32 	%r343, %r262, %r259;
	ld.local.u32 	%r263, [%rd40+16];
	shr.u32 	%r264, %r263, %r261;
	add.s32 	%r344, %r264, %r258;
$L__BB72_42:
	shr.u32 	%r265, %r343, 30;
	shr.u32 	%r266, %r344, 30;
	shl.b32 	%r267, %r343, 2;
	or.b32  	%r268, %r267, %r266;
	shl.b32 	%r269, %r344, 2;
	bfe.u32 	%r270, %r343, 29, 1;
	add.s32 	%r271, %r270, %r265;
	neg.s32 	%r272, %r271;
	setp.lt.s32 	%p34, %r72, 0;
	selp.b32 	%r345, %r272, %r271, %p34;
	xor.b32  	%r273, %r268, %r72;
	bfe.s32 	%r274, %r343, 29, 1;
	xor.b32  	%r275, %r274, %r268;
	xor.b32  	%r276, %r274, %r269;
	cvt.u64.u32 	%rd143, %r275;
	shl.b64 	%rd144, %rd143, 32;
	cvt.u64.u32 	%rd145, %r276;
	or.b64  	%rd146, %rd144, %rd145;
	cvt.rn.f64.s64 	%fd9, %rd146;
	mul.rn.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f92, %fd10;
	neg.f32 	%f93, %f92;
	setp.lt.s32 	%p35, %r273, 0;
	selp.f32 	%f193, %f93, %f92, %p35;
$L__BB72_43:
	cvt.u64.u32 	%rd33, %r37;
	shl.b32 	%r278, %r70, 1;
	mul.lo.s64 	%rd147, %rd28, 76800;
	add.s64 	%rd148, %rd8, %rd147;
	mul.lo.s64 	%rd149, %rd32, 1536;
	add.s64 	%rd150, %rd148, %rd149;
	mul.wide.u32 	%rd151, %r278, 24;
	add.s64 	%rd152, %rd150, %rd151;
	shl.b64 	%rd153, %rd181, 2;
	add.s64 	%rd41, %rd152, %rd153;
	ld.global.nc.f32 	%f31, [%rd41];
	@%p30 bra 	$L__BB72_51;
	@%p51 bra 	$L__BB72_46;
	mul.rn.f32 	%f194, %f13, %f188;
	mov.b32 	%r349, 0;
	bra.uni 	$L__BB72_51;
$L__BB72_46:
	mov.b32 	%r87, %f13;
	shr.u32 	%r88, %r87, 23;
	and.b32  	%r280, %r88, 224;
	add.s32 	%r281, %r280, -128;
	shl.b32 	%r282, %r87, 8;
	or.b32  	%r286, %r282, -2147483648;
	shr.u32 	%r90, %r281, 5;
	mov.b32 	%r346, 0;
	mov.u64 	%rd189, 0;
	mov.u64 	%rd155, __cudart_i2opi_f;
$L__BB72_47:
	.pragma "nounroll";
	add.s64 	%rd156, %rd155, %rd189;
	ld.global.nc.u32 	%r285, [%rd156];
	// begin inline asm
	{
	mad.lo.cc.u32   %r283, %r285, %r286, %r346;
	madc.hi.u32     %r346, %r285, %r286,  0;
	}
	// end inline asm
	add.s64 	%rd157, %rd9, %rd189;
	st.local.u32 	[%rd157], %r283;
	add.s64 	%rd189, %rd189, 4;
	cvt.u32.u64 	%r288, %rd189;
	setp.ne.s32 	%p38, %r288, 24;
	@%p38 bra 	$L__BB72_47;
	st.local.u32 	[%rd9+24], %r346;
	and.b32  	%r93, %r88, 31;
	mul.wide.u32 	%rd158, %r90, 4;
	sub.s64 	%rd44, %rd9, %rd158;
	ld.local.u32 	%r347, [%rd44+24];
	ld.local.u32 	%r348, [%rd44+20];
	setp.eq.s32 	%p39, %r93, 0;
	@%p39 bra 	$L__BB72_50;
	shl.b32 	%r289, %r348, %r93;
	shl.b32 	%r290, %r347, %r93;
	mov.b32 	%r291, 32;
	sub.s32 	%r292, %r291, %r93;
	shr.u32 	%r293, %r348, %r292;
	add.s32 	%r347, %r293, %r290;
	ld.local.u32 	%r294, [%rd44+16];
	shr.u32 	%r295, %r294, %r292;
	add.s32 	%r348, %r295, %r289;
$L__BB72_50:
	shr.u32 	%r296, %r347, 30;
	shr.u32 	%r297, %r348, 30;
	shl.b32 	%r298, %r347, 2;
	or.b32  	%r299, %r298, %r297;
	shl.b32 	%r300, %r348, 2;
	bfe.u32 	%r301, %r347, 29, 1;
	add.s32 	%r302, %r301, %r296;
	neg.s32 	%r303, %r302;
	setp.lt.s32 	%p40, %r87, 0;
	selp.b32 	%r349, %r303, %r302, %p40;
	xor.b32  	%r304, %r299, %r87;
	bfe.s32 	%r305, %r347, 29, 1;
	xor.b32  	%r306, %r305, %r299;
	xor.b32  	%r307, %r305, %r300;
	cvt.u64.u32 	%rd159, %r306;
	shl.b64 	%rd160, %rd159, 32;
	cvt.u64.u32 	%rd161, %r307;
	or.b64  	%rd162, %rd160, %rd161;
	cvt.rn.f64.s64 	%fd11, %rd162;
	mul.rn.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f95, %fd12;
	neg.f32 	%f96, %f95;
	setp.lt.s32 	%p41, %r304, 0;
	selp.f32 	%f194, %f96, %f95, %p41;
$L__BB72_51:
	add.s32 	%r309, %r345, 1;
	and.b32  	%r310, %r309, 2;
	setp.eq.s32 	%p42, %r310, 0;
	and.b32  	%r311, %r345, 1;
	setp.eq.b32 	%p43, %r311, 1;
	mul.rn.f32 	%f98, %f193, %f193;
	fma.rn.f32 	%f99, %f98, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f100, 0fB94D4153, %f99, %p43;
	selp.f32 	%f101, 0f3C0885E4, 0f3D2AAABB, %p43;
	fma.rn.f32 	%f102, %f100, %f98, %f101;
	selp.f32 	%f103, 0fBE2AAAA8, 0fBEFFFFFF, %p43;
	fma.rn.f32 	%f104, %f102, %f98, %f103;
	selp.f32 	%f105, %f193, 0f3F800000, %p43;
	fma.rn.f32 	%f106, %f98, %f105, 0f00000000;
	fma.rn.f32 	%f107, %f104, %f106, %f105;
	sub.rn.f32 	%f109, %f188, %f107;
	selp.f32 	%f110, %f107, %f109, %p42;
	mul.rn.f32 	%f111, %f31, %f110;
	fma.rn.f32 	%f112, %f12, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f113, %f112;
	mov.f32 	%f114, 0f4B400001;
	mov.f32 	%f115, 0f437C0000;
	fma.rm.f32 	%f116, %f113, %f115, %f114;
	add.rn.f32 	%f117, %f116, 0fCB40007F;
	neg.f32 	%f118, %f117;
	fma.rn.f32 	%f119, %f12, 0f3FB8AA3B, %f118;
	fma.rn.f32 	%f120, %f12, 0f32A57060, %f119;
	ex2.approx.ftz.f32 	%f121, %f120;
	mov.b32 	%r312, %f116;
	shl.b32 	%r313, %r312, 23;
	mov.b32 	%f122, %r313;
	mul.rn.f32 	%f123, %f121, %f122;
	neg.f32 	%f124, %f123;
	sub.rn.f32 	%f125, %f124, %f123;
	add.rn.f32 	%f126, %f125, %f125;
	add.rn.f32 	%f127, %f126, %f126;
	add.rn.f32 	%f128, %f127, %f127;
	add.rn.f32 	%f129, %f128, %f128;
	fma.rn.f32 	%f130, %f129, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f131, %f130;
	fma.rm.f32 	%f132, %f131, %f115, %f114;
	add.rn.f32 	%f133, %f132, 0fCB40007F;
	neg.f32 	%f134, %f133;
	fma.rn.f32 	%f135, %f129, 0f3FB8AA3B, %f134;
	fma.rn.f32 	%f136, %f129, 0f32A57060, %f135;
	ex2.approx.ftz.f32 	%f137, %f136;
	mov.b32 	%r314, %f132;
	shl.b32 	%r315, %r314, 23;
	mov.b32 	%f138, %r315;
	mul.rn.f32 	%f139, %f137, %f138;
	add.s32 	%r316, %r337, 1;
	and.b32  	%r317, %r316, 2;
	setp.eq.s32 	%p44, %r317, 0;
	and.b32  	%r318, %r337, 1;
	setp.eq.b32 	%p45, %r318, 1;
	mul.rn.f32 	%f140, %f191, %f191;
	fma.rn.f32 	%f141, %f140, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f142, 0fB94D4153, %f141, %p45;
	selp.f32 	%f143, 0f3C0885E4, 0f3D2AAABB, %p45;
	fma.rn.f32 	%f144, %f142, %f140, %f143;
	selp.f32 	%f145, 0fBE2AAAA8, 0fBEFFFFFF, %p45;
	fma.rn.f32 	%f146, %f144, %f140, %f145;
	selp.f32 	%f147, %f191, 0f3F800000, %p45;
	fma.rn.f32 	%f148, %f140, %f147, 0f00000000;
	fma.rn.f32 	%f149, %f146, %f148, %f147;
	sub.rn.f32 	%f150, %f188, %f149;
	selp.f32 	%f151, %f149, %f150, %p44;
	mul.rn.f32 	%f152, %f20, %f151;
	and.b32  	%r319, %r341, 2;
	setp.eq.s32 	%p46, %r319, 0;
	and.b32  	%r320, %r341, 1;
	setp.eq.b32 	%p47, %r320, 1;
	mul.rn.f32 	%f153, %f192, %f192;
	fma.rn.f32 	%f154, %f153, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f155, %f154, 0fB94D4153, %p47;
	selp.f32 	%f156, 0f3D2AAABB, 0f3C0885E4, %p47;
	fma.rn.f32 	%f157, %f155, %f153, %f156;
	selp.f32 	%f158, 0fBEFFFFFF, 0fBE2AAAA8, %p47;
	fma.rn.f32 	%f159, %f157, %f153, %f158;
	selp.f32 	%f160, 0f3F800000, %f192, %p47;
	fma.rn.f32 	%f161, %f153, %f160, 0f00000000;
	fma.rn.f32 	%f162, %f159, %f161, %f160;
	sub.rn.f32 	%f163, %f188, %f162;
	selp.f32 	%f164, %f162, %f163, %p46;
	mul.rn.f32 	%f165, %f24, %f164;
	add.rn.f32 	%f166, %f152, %f165;
	mul.rn.f32 	%f167, %f166, %f139;
	mul.rn.f32 	%f168, %f194, %f194;
	and.b32  	%r321, %r349, 1;
	setp.eq.b32 	%p48, %r321, 1;
	selp.f32 	%f169, 0f3F800000, %f194, %p48;
	fma.rn.f32 	%f170, %f168, %f169, 0f00000000;
	fma.rn.f32 	%f171, %f168, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f172, %f171, 0fB94D4153, %p48;
	selp.f32 	%f173, 0f3D2AAABB, 0f3C0885E4, %p48;
	fma.rn.f32 	%f174, %f172, %f168, %f173;
	selp.f32 	%f175, 0fBEFFFFFF, 0fBE2AAAA8, %p48;
	fma.rn.f32 	%f176, %f174, %f168, %f175;
	fma.rn.f32 	%f177, %f176, %f170, %f169;
	and.b32  	%r322, %r349, 2;
	setp.eq.s32 	%p49, %r322, 0;
	sub.rn.f32 	%f178, %f188, %f177;
	selp.f32 	%f179, %f177, %f178, %p49;
	mul.lo.s64 	%rd163, %rd28, 38400;
	add.s64 	%rd164, %rd4, %rd163;
	mul.lo.s64 	%rd165, %rd32, 768;
	add.s64 	%rd166, %rd164, %rd165;
	mul.wide.u32 	%rd167, %r69, 24;
	add.s64 	%rd168, %rd166, %rd167;
	shl.b64 	%rd169, %rd185, 3;
	add.s64 	%rd170, %rd168, %rd169;
	mul.wide.u32 	%rd171, %r325, 4;
	add.s64 	%rd172, %rd170, %rd171;
	ld.global.nc.f32 	%f180, [%rd172+48];
	mul.rn.f32 	%f181, %f180, %f179;
	add.rn.f32 	%f182, %f111, %f181;
	mul.rn.f32 	%f183, %f25, %f182;
	ld.global.nc.f32 	%f184, [%rd41+24];
	add.rn.f32 	%f185, %f184, %f183;
	add.rn.f32 	%f186, %f185, %f167;
	add.s64 	%rd174, %rd1, %rd117;
	mul.lo.s64 	%rd175, %rd32, 384;
	add.s64 	%rd176, %rd174, %rd175;
	mul.lo.s64 	%rd177, %rd33, 24;
	add.s64 	%rd178, %rd176, %rd177;
	add.s64 	%rd180, %rd178, %rd153;
	st.global.f32 	[%rd180+24], %f186;
	ret;

}
	// .globl	input_concatenate_fusion_195
.visible .entry input_concatenate_fusion_195(
	.param .u64 input_concatenate_fusion_195_param_0,
	.param .u64 input_concatenate_fusion_195_param_1,
	.param .u64 input_concatenate_fusion_195_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<29>;
	.reg .f32 	%f<20>;
	.reg .b64 	%rd<54>;

	ld.param.u64 	%rd13, [input_concatenate_fusion_195_param_0];
	ld.param.u64 	%rd14, [input_concatenate_fusion_195_param_2];
	ld.param.u64 	%rd15, [input_concatenate_fusion_195_param_1];
	cvta.to.global.u64 	%rd2, %rd15;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	shl.b32 	%r9, %r7, 7;
	or.b32  	%r10, %r9, %r8;
	mul.hi.u32 	%r11, %r10, -1431655765;
	shr.u32 	%r12, %r11, 1;
	mul.lo.s32 	%r13, %r12, 3;
	sub.s32 	%r1, %r10, %r13;
	mul.hi.u32 	%r14, %r12, -2078209981;
	shr.u32 	%r15, %r14, 4;
	mul.lo.s32 	%r16, %r15, 31;
	sub.s32 	%r2, %r12, %r16;
	mul.hi.u32 	%r17, %r10, -1339290877;
	shr.u32 	%r18, %r17, 6;
	cvt.u16.u32 	%rs1, %r18;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	shr.u32 	%r19, %r10, 1;
	mul.hi.u32 	%r20, %r19, -511701479;
	bfe.u32 	%r21, %r20, 11, 6;
	shl.b32 	%r3, %r1, 1;
	or.b32  	%r22, %r3, 1;
	setp.gt.u32 	%p1, %r1, 1;
	selp.b32 	%r23, 5, %r22, %p1;
	and.b32  	%r4, %r2, 1;
	setp.eq.s32 	%p2, %r4, 0;
	cvt.u64.u32 	%rd4, %r21;
	cvt.u64.u16 	%rd5, %rs6;
	shr.u32 	%r24, %r2, 1;
	mov.f32 	%f19, 0f00000000;
	mov.f32 	%f16, %f19;
	@%p2 bra 	$L__BB73_6;
	bra.uni 	$L__BB73_1;
$L__BB73_6:
	cvt.u32.u16 	%r25, %rs6;
	mul.wide.u32 	%rd16, %r25, 384;
	mul.wide.u32 	%rd17, %r21, 19200;
	add.s64 	%rd18, %rd2, %rd17;
	add.s64 	%rd19, %rd18, %rd16;
	mul.wide.u32 	%rd20, %r24, 24;
	add.s64 	%rd21, %rd19, %rd20;
	mul.wide.u32 	%rd22, %r23, 4;
	add.s64 	%rd8, %rd21, %rd22;
	ld.global.nc.f32 	%f16, [%rd8];
$L__BB73_1:
	cvta.to.global.u64 	%rd1, %rd14;
	cvta.to.global.u64 	%rd3, %rd13;
	add.s32 	%r5, %r2, -1;
	and.b32  	%r6, %r5, 1;
	setp.eq.s32 	%p3, %r6, 0;
	shr.u32 	%r28, %r5, 1;
	mul.lo.s64 	%rd52, %rd4, 19200;
	mul.lo.s64 	%rd53, %rd5, 384;
	mov.f32 	%f17, %f19;
	@%p3 bra 	$L__BB73_7;
	bra.uni 	$L__BB73_2;
$L__BB73_7:
	cvt.u64.u32 	%rd7, %r23;
	add.s64 	%rd24, %rd3, %rd52;
	add.s64 	%rd26, %rd24, %rd53;
	mul.wide.u32 	%rd27, %r28, 24;
	add.s64 	%rd28, %rd26, %rd27;
	shl.b64 	%rd29, %rd7, 2;
	add.s64 	%rd30, %rd28, %rd29;
	ld.global.nc.f32 	%f17, [%rd30];
$L__BB73_2:
	add.rn.f32 	%f12, %f16, %f17;
	neg.f32 	%f13, %f12;
	mul.lo.s64 	%rd31, %rd4, 37200;
	add.s64 	%rd32, %rd1, %rd31;
	mul.lo.s64 	%rd33, %rd5, 744;
	add.s64 	%rd34, %rd32, %rd33;
	mul.wide.u32 	%rd35, %r2, 24;
	add.s64 	%rd36, %rd34, %rd35;
	mul.wide.u32 	%rd37, %r1, 8;
	add.s64 	%rd9, %rd36, %rd37;
	st.global.f32 	[%rd9], %f13;
	mov.f32 	%f18, %f19;
	@%p2 bra 	$L__BB73_3;
	bra.uni 	$L__BB73_4;
$L__BB73_3:
	cvt.u64.u32 	%rd6, %r24;
	add.s64 	%rd39, %rd2, %rd52;
	add.s64 	%rd41, %rd39, %rd53;
	mul.lo.s64 	%rd42, %rd6, 24;
	add.s64 	%rd43, %rd41, %rd42;
	mul.wide.u32 	%rd44, %r3, 4;
	add.s64 	%rd11, %rd43, %rd44;
	ld.global.nc.f32 	%f18, [%rd11];
$L__BB73_4:
	@%p3 bra 	$L__BB73_8;
	bra.uni 	$L__BB73_5;
$L__BB73_8:
	cvt.u64.u32 	%rd10, %r3;
	add.s64 	%rd46, %rd3, %rd52;
	add.s64 	%rd48, %rd46, %rd53;
	mul.wide.u32 	%rd49, %r28, 24;
	add.s64 	%rd50, %rd48, %rd49;
	shl.b64 	%rd51, %rd10, 2;
	add.s64 	%rd12, %rd50, %rd51;
	ld.global.nc.f32 	%f19, [%rd12];
$L__BB73_5:
	add.rn.f32 	%f15, %f18, %f19;
	st.global.f32 	[%rd9+4], %f15;
	ret;

}
	// .globl	loop_add_fusion_301
.visible .entry loop_add_fusion_301(
	.param .u64 loop_add_fusion_301_param_0,
	.param .u64 loop_add_fusion_301_param_1,
	.param .u64 loop_add_fusion_301_param_2,
	.param .u64 loop_add_fusion_301_param_3,
	.param .u64 loop_add_fusion_301_param_4,
	.param .u64 loop_add_fusion_301_param_5,
	.param .u64 loop_add_fusion_301_param_6
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot74[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<41>;
	.reg .b16 	%rs<15>;
	.reg .b32 	%r<140>;
	.reg .f32 	%f<81>;
	.reg .b64 	%rd<116>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot74;
	ld.param.u64 	%rd28, [loop_add_fusion_301_param_6];
	ld.param.u64 	%rd31, [loop_add_fusion_301_param_2];
	ld.param.u64 	%rd33, [loop_add_fusion_301_param_3];
	cvta.to.global.u64 	%rd4, %rd33;
	cvta.to.global.u64 	%rd5, %rd31;
	mov.u32 	%r39, %ctaid.x;
	mov.u32 	%r40, %tid.x;
	shl.b32 	%r41, %r39, 7;
	or.b32  	%r1, %r41, %r40;
	mul.hi.u32 	%r42, %r1, -1431655765;
	shr.u32 	%r2, %r42, 2;
	mul.lo.s32 	%r43, %r2, 6;
	sub.s32 	%r3, %r1, %r43;
	bfe.u32 	%r4, %r42, 2, 6;
	cvt.u16.u32 	%rs3, %r39;
	mul.hi.u16 	%rs4, %rs3, -21845;
	shr.u16 	%rs5, %rs4, 1;
	mul.hi.u16 	%rs6, %rs5, 5243;
	shr.u16 	%rs7, %rs6, 2;
	mul.lo.s16 	%rs8, %rs7, 50;
	sub.s16 	%rs1, %rs5, %rs8;
	shr.u16 	%rs9, %rs3, 1;
	mul.hi.u16 	%rs10, %rs9, -9611;
	shr.u16 	%rs2, %rs10, 6;
	and.b32  	%r44, %r2, 1;
	setp.eq.b32 	%p1, %r44, 1;
	mov.pred 	%p2, 0;
	xor.pred  	%p3, %p1, %p2;
	not.pred 	%p4, %p3;
	mov.f32 	%f74, 0f00000000;
	mov.f32 	%f73, %f74;
	@%p4 bra 	$L__BB74_13;
	bra.uni 	$L__BB74_1;
$L__BB74_13:
	ld.param.u64 	%rd27, [loop_add_fusion_301_param_0];
	cvta.to.global.u64 	%rd7, %rd27;
	setp.gt.u32 	%p5, %r4, 1;
	@%p5 bra 	$L__BB74_15;
	cvt.u32.u16 	%r120, %rs2;
	mul.wide.u32 	%rd92, %r120, 76800;
	add.s64 	%rd93, %rd7, %rd92;
	cvt.u32.u16 	%r121, %rs1;
	mul.wide.u32 	%rd94, %r121, 1536;
	add.s64 	%rd95, %rd93, %rd94;
	mul.wide.u32 	%rd96, %r3, 4;
	add.s64 	%rd97, %rd95, %rd96;
	ld.global.nc.f32 	%f73, [%rd97];
	bra.uni 	$L__BB74_1;
$L__BB74_15:
	ld.param.u64 	%rd29, [loop_add_fusion_301_param_1];
	ld.param.u64 	%rd30, [loop_add_fusion_301_param_5];
	cvta.to.global.u64 	%rd2, %rd30;
	cvta.to.global.u64 	%rd6, %rd29;
	add.u64 	%rd8, %SPL, 0;
	bfe.u32 	%r5, %r2, 1, 5;
	add.s32 	%r22, %r5, -1;
	cvt.u64.u16 	%rd14, %rs2;
	cvt.u32.u16 	%r45, %rs2;
	mul.wide.u32 	%rd36, %r45, 4;
	add.s64 	%rd37, %rd6, %rd36;
	ld.global.nc.f32 	%f11, [%rd37];
	shr.u32 	%r46, %r3, 1;
	mul.wide.u32 	%rd38, %r45, 12;
	add.s64 	%rd39, %rd2, %rd38;
	mul.wide.u32 	%rd40, %r46, 4;
	add.s64 	%rd41, %rd39, %rd40;
	ld.global.nc.f32 	%f12, [%rd41];
	mul.rn.f32 	%f27, %f12, 0f3F22F983;
	cvt.rni.s32.f32 	%r135, %f27;
	cvt.rn.f32.s32 	%f28, %r135;
	fma.rn.f32 	%f29, %f28, 0fBFC90FDA, %f12;
	fma.rn.f32 	%f30, %f28, 0fB3A22168, %f29;
	fma.rn.f32 	%f77, %f28, 0fA7C234C5, %f30;
	abs.f32 	%f14, %f12;
	setp.ltu.f32 	%p6, %f14, 0f47CE4780;
	setp.neu.f32 	%p40, %f14, 0f7F800000;
	mov.u32 	%r139, %r135;
	mov.f32 	%f78, %f77;
	@%p6 bra 	$L__BB74_23;
	@%p40 bra 	$L__BB74_18;
	mov.f32 	%f33, 0f00000000;
	mul.rn.f32 	%f78, %f12, %f33;
	mov.b32 	%r139, 0;
	bra.uni 	$L__BB74_23;
$L__BB74_18:
	mov.b32 	%r24, %f12;
	shr.u32 	%r25, %r24, 23;
	and.b32  	%r48, %r25, 224;
	add.s32 	%r49, %r48, -128;
	shl.b32 	%r50, %r24, 8;
	or.b32  	%r54, %r50, -2147483648;
	shr.u32 	%r27, %r49, 5;
	mov.b32 	%r136, 0;
	mov.u64 	%rd115, 0;
	mov.u64 	%rd43, __cudart_i2opi_f;
$L__BB74_19:
	.pragma "nounroll";
	add.s64 	%rd44, %rd43, %rd115;
	ld.global.nc.u32 	%r53, [%rd44];
	// begin inline asm
	{
	mad.lo.cc.u32   %r51, %r53, %r54, %r136;
	madc.hi.u32     %r136, %r53, %r54,  0;
	}
	// end inline asm
	add.s64 	%rd45, %rd8, %rd115;
	st.local.u32 	[%rd45], %r51;
	add.s64 	%rd115, %rd115, 4;
	cvt.u32.u64 	%r56, %rd115;
	setp.ne.s32 	%p8, %r56, 24;
	@%p8 bra 	$L__BB74_19;
	st.local.u32 	[%rd8+24], %r136;
	and.b32  	%r30, %r25, 31;
	mul.wide.u32 	%rd46, %r27, 4;
	sub.s64 	%rd18, %rd8, %rd46;
	ld.local.u32 	%r137, [%rd18+24];
	ld.local.u32 	%r138, [%rd18+20];
	setp.eq.s32 	%p9, %r30, 0;
	@%p9 bra 	$L__BB74_22;
	shl.b32 	%r57, %r138, %r30;
	shl.b32 	%r58, %r137, %r30;
	mov.b32 	%r59, 32;
	sub.s32 	%r60, %r59, %r30;
	shr.u32 	%r61, %r138, %r60;
	add.s32 	%r137, %r61, %r58;
	ld.local.u32 	%r62, [%rd18+16];
	shr.u32 	%r63, %r62, %r60;
	add.s32 	%r138, %r63, %r57;
$L__BB74_22:
	shr.u32 	%r64, %r137, 30;
	shr.u32 	%r65, %r138, 30;
	shl.b32 	%r66, %r137, 2;
	or.b32  	%r67, %r66, %r65;
	shl.b32 	%r68, %r138, 2;
	bfe.u32 	%r69, %r137, 29, 1;
	add.s32 	%r70, %r69, %r64;
	neg.s32 	%r71, %r70;
	setp.lt.s32 	%p10, %r24, 0;
	selp.b32 	%r139, %r71, %r70, %p10;
	xor.b32  	%r72, %r67, %r24;
	bfe.s32 	%r73, %r137, 29, 1;
	xor.b32  	%r74, %r73, %r67;
	xor.b32  	%r75, %r73, %r68;
	cvt.u64.u32 	%rd47, %r74;
	shl.b64 	%rd48, %rd47, 32;
	cvt.u64.u32 	%rd49, %r75;
	or.b64  	%rd50, %rd48, %rd49;
	cvt.rn.f64.s64 	%fd1, %rd50;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f31, %fd2;
	neg.f32 	%f32, %f31;
	setp.lt.s32 	%p11, %r72, 0;
	selp.f32 	%f78, %f32, %f31, %p11;
$L__BB74_23:
	add.s32 	%r77, %r139, 1;
	mul.rn.f32 	%f35, %f78, %f78;
	and.b32  	%r78, %r139, 1;
	setp.eq.b32 	%p12, %r78, 1;
	selp.f32 	%f36, %f78, 0f3F800000, %p12;
	fma.rn.f32 	%f37, %f35, %f36, 0f00000000;
	fma.rn.f32 	%f38, %f35, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f39, 0fB94D4153, %f38, %p12;
	selp.f32 	%f40, 0f3C0885E4, 0f3D2AAABB, %p12;
	fma.rn.f32 	%f41, %f39, %f35, %f40;
	selp.f32 	%f42, 0fBE2AAAA8, 0fBEFFFFFF, %p12;
	fma.rn.f32 	%f43, %f41, %f35, %f42;
	fma.rn.f32 	%f44, %f43, %f37, %f36;
	and.b32  	%r79, %r77, 2;
	setp.eq.s32 	%p13, %r79, 0;
	mov.f32 	%f76, 0f00000000;
	sub.rn.f32 	%f45, %f76, %f44;
	and.b32  	%r80, %r22, 1;
	setp.eq.b32 	%p14, %r80, 1;
	xor.pred  	%p16, %p14, %p2;
	cvt.u64.u32 	%rd20, %r3;
	mul.lo.s64 	%rd51, %rd14, 19200;
	mov.f32 	%f75, %f76;
	@%p16 bra 	$L__BB74_3;
	shr.u32 	%r81, %r22, 1;
	add.s64 	%rd52, %rd4, %rd51;
	cvt.u32.u16 	%r82, %rs1;
	mul.wide.u32 	%rd53, %r82, 384;
	add.s64 	%rd54, %rd52, %rd53;
	mul.wide.u32 	%rd55, %r81, 24;
	add.s64 	%rd56, %rd54, %rd55;
	mul.wide.u32 	%rd57, %r3, 4;
	add.s64 	%rd21, %rd56, %rd57;
	ld.global.nc.f32 	%f75, [%rd21];
$L__BB74_3:
	ld.param.u64 	%rd32, [loop_add_fusion_301_param_4];
	selp.f32 	%f18, %f44, %f45, %p13;
	cvt.u64.u16 	%rd19, %rs1;
	setp.gt.u32 	%p17, %r4, 3;
	and.b32  	%r83, %r2, 2;
	setp.eq.s32 	%p18, %r83, 0;
	and.pred  	%p19, %p17, %p18;
	shl.b64 	%rd64, %rd20, 2;
	@%p19 bra 	$L__BB74_25;
	bra.uni 	$L__BB74_4;
$L__BB74_25:
	add.s32 	%r84, %r5, -2;
	shr.s32 	%r85, %r84, 1;
	add.s64 	%rd59, %rd5, %rd51;
	mul.lo.s64 	%rd60, %rd19, 384;
	add.s64 	%rd61, %rd59, %rd60;
	mul.wide.s32 	%rd62, %r85, 24;
	add.s64 	%rd63, %rd61, %rd62;
	add.s64 	%rd10, %rd63, %rd64;
	ld.global.nc.f32 	%f76, [%rd10];
$L__BB74_4:
	cvta.to.global.u64 	%rd3, %rd32;
	cvt.u64.u32 	%rd15, %r46;
	add.rn.f32 	%f47, %f75, %f76;
	mul.rn.f32 	%f5, %f18, %f47;
	@%p6 bra 	$L__BB74_12;
	@%p40 bra 	$L__BB74_7;
	mov.f32 	%f50, 0f00000000;
	mul.rn.f32 	%f77, %f12, %f50;
	mov.b32 	%r135, 0;
	bra.uni 	$L__BB74_12;
$L__BB74_7:
	mov.b32 	%r7, %f12;
	shr.u32 	%r8, %r7, 23;
	and.b32  	%r87, %r8, 224;
	add.s32 	%r88, %r87, -128;
	shl.b32 	%r89, %r7, 8;
	or.b32  	%r93, %r89, -2147483648;
	shr.u32 	%r10, %r88, 5;
	mov.b32 	%r132, 0;
	mov.u64 	%rd114, 0;
	mov.u64 	%rd66, __cudart_i2opi_f;
$L__BB74_8:
	.pragma "nounroll";
	add.s64 	%rd67, %rd66, %rd114;
	ld.global.nc.u32 	%r92, [%rd67];
	// begin inline asm
	{
	mad.lo.cc.u32   %r90, %r92, %r93, %r132;
	madc.hi.u32     %r132, %r92, %r93,  0;
	}
	// end inline asm
	add.s64 	%rd68, %rd8, %rd114;
	st.local.u32 	[%rd68], %r90;
	add.s64 	%rd114, %rd114, 4;
	cvt.u32.u64 	%r95, %rd114;
	setp.ne.s32 	%p22, %r95, 24;
	@%p22 bra 	$L__BB74_8;
	st.local.u32 	[%rd8+24], %r132;
	and.b32  	%r13, %r8, 31;
	mul.wide.u32 	%rd69, %r10, 4;
	sub.s64 	%rd13, %rd8, %rd69;
	ld.local.u32 	%r133, [%rd13+24];
	ld.local.u32 	%r134, [%rd13+20];
	setp.eq.s32 	%p23, %r13, 0;
	@%p23 bra 	$L__BB74_11;
	shl.b32 	%r96, %r134, %r13;
	shl.b32 	%r97, %r133, %r13;
	mov.b32 	%r98, 32;
	sub.s32 	%r99, %r98, %r13;
	shr.u32 	%r100, %r134, %r99;
	add.s32 	%r133, %r100, %r97;
	ld.local.u32 	%r101, [%rd13+16];
	shr.u32 	%r102, %r101, %r99;
	add.s32 	%r134, %r102, %r96;
$L__BB74_11:
	shr.u32 	%r103, %r133, 30;
	shr.u32 	%r104, %r134, 30;
	shl.b32 	%r105, %r133, 2;
	or.b32  	%r106, %r105, %r104;
	shl.b32 	%r107, %r134, 2;
	bfe.u32 	%r108, %r133, 29, 1;
	add.s32 	%r109, %r108, %r103;
	neg.s32 	%r110, %r109;
	setp.lt.s32 	%p24, %r7, 0;
	selp.b32 	%r135, %r110, %r109, %p24;
	xor.b32  	%r111, %r106, %r7;
	bfe.s32 	%r112, %r133, 29, 1;
	xor.b32  	%r113, %r112, %r106;
	xor.b32  	%r114, %r112, %r107;
	cvt.u64.u32 	%rd70, %r113;
	shl.b64 	%rd71, %rd70, 32;
	cvt.u64.u32 	%rd72, %r114;
	or.b64  	%rd73, %rd71, %rd72;
	cvt.rn.f64.s64 	%fd3, %rd73;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f48, %fd4;
	neg.f32 	%f49, %f48;
	setp.lt.s32 	%p25, %r111, 0;
	selp.f32 	%f77, %f49, %f48, %p25;
$L__BB74_12:
	mul.rn.f32 	%f51, %f77, %f77;
	and.b32  	%r116, %r135, 1;
	setp.eq.b32 	%p26, %r116, 1;
	selp.f32 	%f52, 0f3F800000, %f77, %p26;
	fma.rn.f32 	%f53, %f51, %f52, 0f00000000;
	fma.rn.f32 	%f54, %f51, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f55, %f54, 0fB94D4153, %p26;
	selp.f32 	%f56, 0f3D2AAABB, 0f3C0885E4, %p26;
	fma.rn.f32 	%f57, %f55, %f51, %f56;
	selp.f32 	%f58, 0fBEFFFFFF, 0fBE2AAAA8, %p26;
	fma.rn.f32 	%f59, %f57, %f51, %f58;
	fma.rn.f32 	%f60, %f59, %f53, %f52;
	and.b32  	%r117, %r135, 2;
	setp.eq.s32 	%p27, %r117, 0;
	mov.f32 	%f61, 0f00000000;
	sub.rn.f32 	%f62, %f61, %f60;
	selp.f32 	%f63, %f60, %f62, %p27;
	and.b32  	%r118, %r3, 1;
	mul.lo.s64 	%rd74, %rd14, 37200;
	add.s64 	%rd75, %rd3, %rd74;
	mul.lo.s64 	%rd76, %rd19, 744;
	add.s64 	%rd77, %rd75, %rd76;
	mul.wide.u32 	%rd78, %r5, 24;
	add.s64 	%rd79, %rd77, %rd78;
	shl.b64 	%rd80, %rd15, 3;
	add.s64 	%rd81, %rd79, %rd80;
	mul.wide.u32 	%rd82, %r118, 4;
	add.s64 	%rd83, %rd81, %rd82;
	ld.global.nc.f32 	%f64, [%rd83+-24];
	mul.rn.f32 	%f65, %f64, %f63;
	add.rn.f32 	%f66, %f5, %f65;
	mul.rn.f32 	%f67, %f11, %f66;
	shl.b32 	%r119, %r22, 1;
	mul.lo.s64 	%rd84, %rd14, 76800;
	add.s64 	%rd85, %rd7, %rd84;
	mul.lo.s64 	%rd86, %rd19, 1536;
	add.s64 	%rd87, %rd85, %rd86;
	mul.wide.u32 	%rd88, %r119, 24;
	add.s64 	%rd89, %rd87, %rd88;
	add.s64 	%rd91, %rd89, %rd64;
	ld.global.nc.f32 	%f68, [%rd91+48];
	add.rn.f32 	%f73, %f68, %f67;
$L__BB74_1:
	cvta.to.global.u64 	%rd1, %rd28;
	add.s32 	%r122, %r4, -1;
	and.b32  	%r123, %r122, 1;
	setp.eq.b32 	%p28, %r123, 1;
	xor.pred  	%p30, %p28, %p2;
	not.pred 	%p31, %p30;
	@%p31 bra 	$L__BB74_26;
	bra.uni 	$L__BB74_2;
$L__BB74_26:
	cvt.u16.u32 	%rs11, %r122;
	shr.u32 	%r124, %r122, 31;
	cvt.u16.u32 	%rs12, %r124;
	add.s16 	%rs13, %rs11, %rs12;
	shr.s16 	%rs14, %rs13, 1;
	cvt.s32.s16 	%r6, %rs14;
	and.b32  	%r125, %r6, 1;
	setp.eq.b32 	%p32, %r125, 1;
	xor.pred  	%p34, %p32, %p2;
	not.pred 	%p35, %p34;
	mov.f32 	%f80, 0f00000000;
	mov.f32 	%f79, %f80;
	@%p35 bra 	$L__BB74_29;
	bra.uni 	$L__BB74_27;
$L__BB74_29:
	shr.u32 	%r126, %r6, 1;
	cvt.u32.u16 	%r127, %rs2;
	mul.wide.u32 	%rd98, %r127, 19200;
	add.s64 	%rd99, %rd4, %rd98;
	cvt.u32.u16 	%r128, %rs1;
	mul.wide.u32 	%rd100, %r128, 384;
	add.s64 	%rd101, %rd99, %rd100;
	mul.wide.u32 	%rd102, %r126, 24;
	add.s64 	%rd103, %rd101, %rd102;
	mul.wide.u32 	%rd104, %r3, 4;
	add.s64 	%rd25, %rd103, %rd104;
	ld.global.nc.f32 	%f79, [%rd25];
$L__BB74_27:
	add.s32 	%r129, %r6, -1;
	setp.gt.u32 	%p36, %r4, 2;
	and.b32  	%r130, %r129, 1;
	setp.eq.b32 	%p37, %r130, 1;
	not.pred 	%p38, %p37;
	and.pred  	%p39, %p36, %p38;
	@%p39 bra 	$L__BB74_30;
	bra.uni 	$L__BB74_28;
$L__BB74_30:
	cvt.u64.u16 	%rd22, %rs2;
	cvt.u64.u16 	%rd23, %rs1;
	cvt.u64.u32 	%rd24, %r3;
	shr.s32 	%r131, %r129, 1;
	mul.lo.s64 	%rd105, %rd22, 19200;
	add.s64 	%rd106, %rd5, %rd105;
	mul.lo.s64 	%rd107, %rd23, 384;
	add.s64 	%rd108, %rd106, %rd107;
	mul.wide.s32 	%rd109, %r131, 24;
	add.s64 	%rd110, %rd108, %rd109;
	shl.b64 	%rd111, %rd24, 2;
	add.s64 	%rd26, %rd110, %rd111;
	ld.global.nc.f32 	%f80, [%rd26];
$L__BB74_28:
	add.rn.f32 	%f74, %f79, %f80;
$L__BB74_2:
	add.rn.f32 	%f72, %f73, %f74;
	mul.wide.u32 	%rd112, %r1, 4;
	add.s64 	%rd113, %rd1, %rd112;
	st.global.f32 	[%rd113], %f72;
	ret;

}
	// .globl	input_concatenate_fusion_196
.visible .entry input_concatenate_fusion_196(
	.param .u64 input_concatenate_fusion_196_param_0,
	.param .u64 input_concatenate_fusion_196_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<22>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_196_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_196_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -1431655765;
	shr.u32 	%r6, %r5, 1;
	mul.lo.s32 	%r7, %r6, 3;
	sub.s32 	%r8, %r4, %r7;
	mul.hi.u32 	%r9, %r6, -2113396605;
	shr.u32 	%r10, %r9, 5;
	mul.lo.s32 	%r11, %r10, 63;
	sub.s32 	%r12, %r6, %r11;
	mul.hi.u32 	%r13, %r4, 1522554545;
	sub.s32 	%r14, %r4, %r13;
	shr.u32 	%r15, %r14, 1;
	add.s32 	%r16, %r15, %r13;
	shr.u32 	%r17, %r16, 7;
	cvt.u16.u32 	%rs1, %r17;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r18, %r4, 1861606989;
	bfe.u32 	%r19, %r18, 12, 6;
	shl.b32 	%r20, %r8, 1;
	or.b32  	%r21, %r20, 1;
	setp.gt.u32 	%p1, %r8, 1;
	selp.b32 	%r22, 5, %r21, %p1;
	cvt.u32.u16 	%r23, %rs6;
	mul.wide.u32 	%rd5, %r23, 1536;
	mul.wide.u32 	%rd6, %r19, 76800;
	add.s64 	%rd7, %rd4, %rd6;
	add.s64 	%rd8, %rd7, %rd5;
	mul.wide.u32 	%rd9, %r12, 24;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r22, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	neg.f32 	%f2, %f1;
	mul.wide.u32 	%rd13, %r23, 1512;
	mul.wide.u32 	%rd14, %r19, 75600;
	add.s64 	%rd15, %rd3, %rd14;
	add.s64 	%rd16, %rd15, %rd13;
	add.s64 	%rd17, %rd16, %rd9;
	mul.wide.u32 	%rd18, %r8, 8;
	add.s64 	%rd19, %rd17, %rd18;
	mul.wide.u32 	%rd20, %r20, 4;
	add.s64 	%rd21, %rd10, %rd20;
	ld.global.nc.f32 	%f3, [%rd21];
	st.global.v2.f32 	[%rd19], {%f2, %f3};
	ret;

}
	// .globl	input_concatenate_fusion_197
.visible .entry input_concatenate_fusion_197(
	.param .u64 input_concatenate_fusion_197_param_0,
	.param .u64 input_concatenate_fusion_197_param_1,
	.param .u64 input_concatenate_fusion_197_param_2,
	.param .u64 input_concatenate_fusion_197_param_3,
	.param .u64 input_concatenate_fusion_197_param_4,
	.param .u64 input_concatenate_fusion_197_param_5,
	.param .u64 input_concatenate_fusion_197_param_6,
	.param .u64 input_concatenate_fusion_197_param_7,
	.param .u64 input_concatenate_fusion_197_param_8,
	.param .u64 input_concatenate_fusion_197_param_9,
	.param .u64 input_concatenate_fusion_197_param_10
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<30>;
	.reg .f32 	%f<33>;
	.reg .b64 	%rd<106>;

	ld.param.u64 	%rd21, [input_concatenate_fusion_197_param_0];
	ld.param.u64 	%rd22, [input_concatenate_fusion_197_param_10];
	cvta.to.global.u64 	%rd1, %rd22;
	ld.param.u64 	%rd23, [input_concatenate_fusion_197_param_1];
	ld.param.u64 	%rd24, [input_concatenate_fusion_197_param_9];
	cvta.to.global.u64 	%rd2, %rd24;
	ld.param.u64 	%rd25, [input_concatenate_fusion_197_param_2];
	ld.param.u64 	%rd26, [input_concatenate_fusion_197_param_8];
	cvta.to.global.u64 	%rd3, %rd26;
	ld.param.u64 	%rd27, [input_concatenate_fusion_197_param_3];
	ld.param.u64 	%rd28, [input_concatenate_fusion_197_param_7];
	cvta.to.global.u64 	%rd4, %rd28;
	ld.param.u64 	%rd29, [input_concatenate_fusion_197_param_4];
	ld.param.u64 	%rd30, [input_concatenate_fusion_197_param_6];
	cvta.to.global.u64 	%rd5, %rd30;
	ld.param.u64 	%rd31, [input_concatenate_fusion_197_param_5];
	cvta.to.global.u64 	%rd6, %rd31;
	cvta.to.global.u64 	%rd7, %rd29;
	cvta.to.global.u64 	%rd8, %rd27;
	cvta.to.global.u64 	%rd9, %rd25;
	cvta.to.global.u64 	%rd10, %rd23;
	cvta.to.global.u64 	%rd11, %rd21;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	shl.b32 	%r6, %r4, 7;
	or.b32  	%r1, %r6, %r5;
	mul.hi.u32 	%r7, %r1, -1431655765;
	shr.u32 	%r2, %r7, 2;
	mul.lo.s32 	%r8, %r2, 6;
	sub.s32 	%r3, %r1, %r8;
	setp.lt.u32 	%p1, %r1, 19200;
	@%p1 bra 	$L__BB76_2;
	bra.uni 	$L__BB76_1;
$L__BB76_2:
	cvt.u16.u32 	%rs1, %r1;
	shr.u16 	%rs2, %rs1, 2;
	mul.hi.u16 	%rs3, %rs2, 27963;
	shr.u16 	%rs4, %rs3, 5;
	mul.hi.u32 	%r11, %r2, 85899346;
	mul.lo.s32 	%r12, %r11, 50;
	sub.s32 	%r13, %r2, %r12;
	cvt.u32.u16 	%r14, %rs4;
	mul.wide.u32 	%rd32, %r14, 4;
	add.s64 	%rd33, %rd10, %rd32;
	ld.global.nc.f32 	%f1, [%rd33];
	shr.u32 	%r15, %r3, 1;
	cvt.u64.u32 	%rd105, %r15;
	mul.wide.u32 	%rd34, %r14, 12;
	add.s64 	%rd35, %rd3, %rd34;
	mul.wide.u32 	%rd36, %r15, 4;
	add.s64 	%rd37, %rd35, %rd36;
	ld.global.nc.f32 	%f2, [%rd37];
	cvt.u64.u32 	%rd104, %r3;
	mul.wide.u32 	%rd38, %r14, 307200;
	add.s64 	%rd39, %rd11, %rd38;
	mul.wide.u32 	%rd40, %r13, 6144;
	add.s64 	%rd41, %rd39, %rd40;
	mul.wide.u32 	%rd42, %r3, 4;
	add.s64 	%rd43, %rd41, %rd42;
	ld.global.nc.f32 	%f3, [%rd43];
	mul.rn.f32 	%f4, %f2, %f3;
	add.s64 	%rd44, %rd5, %rd34;
	add.s64 	%rd45, %rd44, %rd36;
	ld.global.nc.f32 	%f5, [%rd45];
	and.b32  	%r16, %r3, 1;
	cvt.u64.u32 	%rd103, %r16;
	mul.wide.u32 	%rd46, %r14, 153600;
	add.s64 	%rd47, %rd6, %rd46;
	mul.wide.u32 	%rd48, %r13, 3072;
	add.s64 	%rd49, %rd47, %rd48;
	mul.wide.u32 	%rd50, %r15, 8;
	add.s64 	%rd51, %rd49, %rd50;
	mul.wide.u32 	%rd52, %r16, 4;
	add.s64 	%rd53, %rd51, %rd52;
	ld.global.nc.f32 	%f6, [%rd53];
	mul.rn.f32 	%f7, %f5, %f6;
	add.rn.f32 	%f8, %f4, %f7;
	mul.rn.f32 	%f9, %f1, %f8;
	ld.global.nc.f32 	%f10, [%rd43+24];
	add.rn.f32 	%f11, %f10, %f9;
	mul.wide.u32 	%rd54, %r14, 76800;
	add.s64 	%rd55, %rd1, %rd54;
	mul.wide.u32 	%rd56, %r13, 1536;
	add.s64 	%rd57, %rd55, %rd56;
	add.s64 	%rd58, %rd57, %rd42;
	st.global.f32 	[%rd58], %f11;
	bra.uni 	$L__BB76_3;
$L__BB76_1:
	shr.u32 	%r9, %r3, 1;
	cvt.u64.u32 	%rd105, %r9;
	cvt.u64.u32 	%rd104, %r3;
	and.b32  	%r10, %r3, 1;
	cvt.u64.u32 	%rd103, %r10;
$L__BB76_3:
	mul.hi.u32 	%r17, %r1, 1861606989;
	bfe.u32 	%r18, %r17, 13, 6;
	shr.u32 	%r19, %r1, 1;
	mul.hi.u32 	%r20, %r19, -1386206375;
	shr.u32 	%r21, %r20, 7;
	cvt.u16.u32 	%rs5, %r21;
	shr.u16 	%rs6, %rs5, 1;
	mul.hi.u16 	%rs7, %rs6, 5243;
	shr.u16 	%rs8, %rs7, 1;
	mul.lo.s16 	%rs9, %rs8, 50;
	sub.s16 	%rs10, %rs5, %rs9;
	mul.hi.u32 	%r22, %r2, 545392673;
	shr.u32 	%r23, %r22, 3;
	mul.lo.s32 	%r24, %r23, 63;
	sub.s32 	%r25, %r2, %r24;
	mul.wide.u32 	%rd59, %r18, 4;
	add.s64 	%rd60, %rd9, %rd59;
	ld.global.nc.f32 	%f12, [%rd60];
	mul.wide.u32 	%rd61, %r18, 12;
	add.s64 	%rd62, %rd2, %rd61;
	shl.b64 	%rd63, %rd105, 2;
	add.s64 	%rd64, %rd62, %rd63;
	ld.global.nc.f32 	%f13, [%rd64];
	mul.wide.u32 	%rd65, %r18, 76800;
	add.s64 	%rd66, %rd7, %rd65;
	cvt.u32.u16 	%r26, %rs10;
	mul.wide.u32 	%rd67, %r26, 1536;
	add.s64 	%rd68, %rd66, %rd67;
	mul.wide.u32 	%rd69, %r25, 24;
	add.s64 	%rd70, %rd68, %rd69;
	shl.b64 	%rd71, %rd104, 2;
	add.s64 	%rd72, %rd70, %rd71;
	ld.global.nc.f32 	%f14, [%rd72];
	mul.rn.f32 	%f15, %f13, %f14;
	add.s64 	%rd73, %rd4, %rd61;
	add.s64 	%rd74, %rd73, %rd63;
	ld.global.nc.f32 	%f16, [%rd74];
	mul.wide.u32 	%rd75, %r1, 4;
	add.s64 	%rd76, %rd8, %rd75;
	ld.global.nc.f32 	%f17, [%rd76];
	mul.rn.f32 	%f18, %f16, %f17;
	add.rn.f32 	%f19, %f15, %f18;
	mul.rn.f32 	%f20, %f12, %f19;
	shl.b32 	%r27, %r25, 1;
	shl.b32 	%r28, %r25, 2;
	add.s64 	%rd77, %rd10, %rd59;
	ld.global.nc.f32 	%f21, [%rd77];
	add.s64 	%rd78, %rd3, %rd61;
	add.s64 	%rd79, %rd78, %rd63;
	ld.global.nc.f32 	%f22, [%rd79];
	add.s32 	%r29, %r28, 4;
	mul.wide.u32 	%rd80, %r18, 307200;
	add.s64 	%rd81, %rd11, %rd80;
	mul.wide.u32 	%rd82, %r26, 6144;
	add.s64 	%rd83, %rd81, %rd82;
	mul.wide.u32 	%rd84, %r29, 24;
	add.s64 	%rd85, %rd83, %rd84;
	add.s64 	%rd86, %rd85, %rd71;
	ld.global.nc.f32 	%f23, [%rd86];
	mul.rn.f32 	%f24, %f22, %f23;
	add.s64 	%rd87, %rd5, %rd61;
	add.s64 	%rd88, %rd87, %rd63;
	ld.global.nc.f32 	%f25, [%rd88];
	mul.wide.u32 	%rd89, %r18, 153600;
	add.s64 	%rd90, %rd6, %rd89;
	mul.wide.u32 	%rd91, %r26, 3072;
	add.s64 	%rd92, %rd90, %rd91;
	mul.wide.u32 	%rd93, %r27, 24;
	add.s64 	%rd94, %rd92, %rd93;
	shl.b64 	%rd95, %rd105, 3;
	add.s64 	%rd96, %rd94, %rd95;
	shl.b64 	%rd97, %rd103, 2;
	add.s64 	%rd98, %rd96, %rd97;
	ld.global.nc.f32 	%f26, [%rd98+48];
	mul.rn.f32 	%f27, %f25, %f26;
	add.rn.f32 	%f28, %f24, %f27;
	mul.rn.f32 	%f29, %f21, %f28;
	ld.global.nc.f32 	%f30, [%rd86+24];
	add.rn.f32 	%f31, %f30, %f29;
	add.rn.f32 	%f32, %f20, %f31;
	add.s64 	%rd99, %rd1, %rd65;
	add.s64 	%rd100, %rd99, %rd67;
	add.s64 	%rd101, %rd100, %rd69;
	add.s64 	%rd102, %rd101, %rd71;
	st.global.f32 	[%rd102+24], %f32;
	ret;

}
	// .globl	input_concatenate_fusion_198
.visible .entry input_concatenate_fusion_198(
	.param .u64 input_concatenate_fusion_198_param_0,
	.param .u64 input_concatenate_fusion_198_param_1,
	.param .u64 input_concatenate_fusion_198_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<28>;
	.reg .f32 	%f<20>;
	.reg .b64 	%rd<54>;

	ld.param.u64 	%rd13, [input_concatenate_fusion_198_param_0];
	ld.param.u64 	%rd14, [input_concatenate_fusion_198_param_2];
	ld.param.u64 	%rd15, [input_concatenate_fusion_198_param_1];
	cvta.to.global.u64 	%rd2, %rd15;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	shl.b32 	%r9, %r7, 7;
	or.b32  	%r10, %r9, %r8;
	mul.hi.u32 	%r11, %r10, -1431655765;
	shr.u32 	%r12, %r11, 1;
	mul.lo.s32 	%r13, %r12, 3;
	sub.s32 	%r1, %r10, %r13;
	mul.hi.u32 	%r14, %r12, -2130574327;
	shr.u32 	%r15, %r14, 6;
	mul.lo.s32 	%r16, %r15, 127;
	sub.s32 	%r2, %r12, %r16;
	mul.hi.u32 	%r17, %r10, -1409110005;
	shr.u32 	%r18, %r17, 8;
	cvt.u16.u32 	%rs1, %r18;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r19, %r10, -601069963;
	bfe.u32 	%r20, %r19, 14, 6;
	shl.b32 	%r3, %r1, 1;
	or.b32  	%r21, %r3, 1;
	setp.gt.u32 	%p1, %r1, 1;
	selp.b32 	%r22, 5, %r21, %p1;
	and.b32  	%r4, %r2, 1;
	setp.eq.s32 	%p2, %r4, 0;
	cvt.u64.u32 	%rd4, %r20;
	cvt.u64.u16 	%rd5, %rs6;
	shr.u32 	%r23, %r2, 1;
	mov.f32 	%f19, 0f00000000;
	mov.f32 	%f16, %f19;
	@%p2 bra 	$L__BB77_6;
	bra.uni 	$L__BB77_1;
$L__BB77_6:
	cvt.u32.u16 	%r24, %rs6;
	mul.wide.u32 	%rd16, %r24, 1536;
	mul.wide.u32 	%rd17, %r20, 76800;
	add.s64 	%rd18, %rd2, %rd17;
	add.s64 	%rd19, %rd18, %rd16;
	mul.wide.u32 	%rd20, %r23, 24;
	add.s64 	%rd21, %rd19, %rd20;
	mul.wide.u32 	%rd22, %r22, 4;
	add.s64 	%rd8, %rd21, %rd22;
	ld.global.nc.f32 	%f16, [%rd8];
$L__BB77_1:
	cvta.to.global.u64 	%rd1, %rd14;
	cvta.to.global.u64 	%rd3, %rd13;
	add.s32 	%r5, %r2, -1;
	and.b32  	%r6, %r5, 1;
	setp.eq.s32 	%p3, %r6, 0;
	shr.u32 	%r27, %r5, 1;
	mul.lo.s64 	%rd52, %rd4, 76800;
	mul.lo.s64 	%rd53, %rd5, 1536;
	mov.f32 	%f17, %f19;
	@%p3 bra 	$L__BB77_7;
	bra.uni 	$L__BB77_2;
$L__BB77_7:
	cvt.u64.u32 	%rd7, %r22;
	add.s64 	%rd24, %rd3, %rd52;
	add.s64 	%rd26, %rd24, %rd53;
	mul.wide.u32 	%rd27, %r27, 24;
	add.s64 	%rd28, %rd26, %rd27;
	shl.b64 	%rd29, %rd7, 2;
	add.s64 	%rd30, %rd28, %rd29;
	ld.global.nc.f32 	%f17, [%rd30];
$L__BB77_2:
	add.rn.f32 	%f12, %f16, %f17;
	neg.f32 	%f13, %f12;
	mul.lo.s64 	%rd31, %rd4, 152400;
	add.s64 	%rd32, %rd1, %rd31;
	mul.lo.s64 	%rd33, %rd5, 3048;
	add.s64 	%rd34, %rd32, %rd33;
	mul.wide.u32 	%rd35, %r2, 24;
	add.s64 	%rd36, %rd34, %rd35;
	mul.wide.u32 	%rd37, %r1, 8;
	add.s64 	%rd9, %rd36, %rd37;
	st.global.f32 	[%rd9], %f13;
	mov.f32 	%f18, %f19;
	@%p2 bra 	$L__BB77_3;
	bra.uni 	$L__BB77_4;
$L__BB77_3:
	cvt.u64.u32 	%rd6, %r23;
	add.s64 	%rd39, %rd2, %rd52;
	add.s64 	%rd41, %rd39, %rd53;
	mul.lo.s64 	%rd42, %rd6, 24;
	add.s64 	%rd43, %rd41, %rd42;
	mul.wide.u32 	%rd44, %r3, 4;
	add.s64 	%rd11, %rd43, %rd44;
	ld.global.nc.f32 	%f18, [%rd11];
$L__BB77_4:
	@%p3 bra 	$L__BB77_8;
	bra.uni 	$L__BB77_5;
$L__BB77_8:
	cvt.u64.u32 	%rd10, %r3;
	add.s64 	%rd46, %rd3, %rd52;
	add.s64 	%rd48, %rd46, %rd53;
	mul.wide.u32 	%rd49, %r27, 24;
	add.s64 	%rd50, %rd48, %rd49;
	shl.b64 	%rd51, %rd10, 2;
	add.s64 	%rd12, %rd50, %rd51;
	ld.global.nc.f32 	%f19, [%rd12];
$L__BB77_5:
	add.rn.f32 	%f15, %f18, %f19;
	st.global.f32 	[%rd9+4], %f15;
	ret;

}
	// .globl	loop_add_fusion_302
.visible .entry loop_add_fusion_302(
	.param .u64 loop_add_fusion_302_param_0,
	.param .u64 loop_add_fusion_302_param_1,
	.param .u64 loop_add_fusion_302_param_2,
	.param .u64 loop_add_fusion_302_param_3,
	.param .u64 loop_add_fusion_302_param_4,
	.param .u64 loop_add_fusion_302_param_5,
	.param .u64 loop_add_fusion_302_param_6,
	.param .u64 loop_add_fusion_302_param_7
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<87>;
	.reg .b16 	%rs<39>;
	.reg .b32 	%r<126>;
	.reg .f32 	%f<145>;
	.reg .b64 	%rd<319>;

	ld.param.u64 	%rd50, [loop_add_fusion_302_param_0];
	ld.param.u64 	%rd51, [loop_add_fusion_302_param_7];
	ld.param.u64 	%rd52, [loop_add_fusion_302_param_1];
	ld.param.u64 	%rd53, [loop_add_fusion_302_param_6];
	cvta.to.global.u64 	%rd2, %rd53;
	ld.param.u64 	%rd54, [loop_add_fusion_302_param_2];
	ld.param.u64 	%rd55, [loop_add_fusion_302_param_5];
	cvta.to.global.u64 	%rd3, %rd55;
	ld.param.u64 	%rd56, [loop_add_fusion_302_param_3];
	ld.param.u64 	%rd57, [loop_add_fusion_302_param_4];
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	cvta.to.global.u64 	%rd6, %rd54;
	cvta.to.global.u64 	%rd7, %rd52;
	cvta.to.global.u64 	%rd8, %rd50;
	mov.u32 	%r24, %ctaid.x;
	mov.u32 	%r25, %tid.x;
	shl.b32 	%r26, %r24, 9;
	shl.b32 	%r27, %r25, 2;
	or.b32  	%r1, %r26, %r27;
	mul.hi.u32 	%r2, %r1, 715827883;
	mul.lo.s32 	%r28, %r2, 6;
	sub.s32 	%r3, %r1, %r28;
	and.b32  	%r4, %r2, 255;
	cvt.u16.u32 	%rs3, %r24;
	mul.hi.u16 	%rs4, %rs3, -21845;
	shr.u16 	%rs5, %rs4, 1;
	mul.hi.u16 	%rs6, %rs5, 5243;
	shr.u16 	%rs7, %rs6, 2;
	mul.lo.s16 	%rs8, %rs7, 50;
	sub.s16 	%rs1, %rs5, %rs8;
	shr.u16 	%rs9, %rs3, 1;
	mul.hi.u16 	%rs10, %rs9, -9611;
	shr.u16 	%rs2, %rs10, 6;
	or.b32  	%r29, %r1, 1;
	mul.hi.u32 	%r30, %r29, 715827883;
	and.b32  	%r12, %r2, 1;
	setp.eq.s32 	%p1, %r12, 0;
	bfe.u32 	%r13, %r2, 1, 7;
	mov.f32 	%f128, 0f00000000;
	setp.gt.u32 	%p85, %r4, 1;
	cvt.u64.u16 	%rd316, %rs2;
	cvt.u32.u16 	%r124, %rs2;
	mov.pred 	%p86, 0;
	cvt.u64.u16 	%rd317, %rs1;
	cvt.u32.u16 	%r125, %rs1;
	mov.f32 	%f121, %f128;
	@%p1 bra 	$L__BB78_11;
	bra.uni 	$L__BB78_1;
$L__BB78_11:
	@%p85 bra 	$L__BB78_13;
	mul.wide.u32 	%rd99, %r124, 307200;
	add.s64 	%rd100, %rd8, %rd99;
	mul.wide.u32 	%rd101, %r125, 6144;
	add.s64 	%rd102, %rd100, %rd101;
	mul.wide.u32 	%rd103, %r3, 4;
	add.s64 	%rd104, %rd102, %rd103;
	ld.global.nc.f32 	%f121, [%rd104];
	bra.uni 	$L__BB78_1;
$L__BB78_13:
	add.s32 	%r20, %r13, -1;
	mul.wide.u32 	%rd58, %r124, 4;
	add.s64 	%rd59, %rd7, %rd58;
	ld.global.nc.f32 	%f13, [%rd59];
	shr.u32 	%r37, %r3, 1;
	mul.wide.u32 	%rd60, %r124, 12;
	add.s64 	%rd61, %rd2, %rd60;
	mul.wide.u32 	%rd62, %r37, 4;
	add.s64 	%rd63, %rd61, %rd62;
	ld.global.nc.f32 	%f14, [%rd63];
	and.b32  	%r38, %r20, 1;
	setp.eq.b32 	%p3, %r38, 1;
	xor.pred  	%p5, %p3, %p86;
	cvt.u64.u32 	%rd13, %r3;
	mov.f32 	%f130, 0f00000000;
	mov.f32 	%f129, %f130;
	@%p5 bra 	$L__BB78_9;
	shr.u32 	%r39, %r20, 1;
	mul.wide.u32 	%rd64, %r124, 76800;
	add.s64 	%rd65, %rd5, %rd64;
	mul.wide.u32 	%rd66, %r125, 1536;
	add.s64 	%rd67, %rd65, %rd66;
	mul.wide.u32 	%rd68, %r39, 24;
	add.s64 	%rd69, %rd67, %rd68;
	mul.wide.u32 	%rd70, %r3, 4;
	add.s64 	%rd14, %rd69, %rd70;
	ld.global.nc.f32 	%f129, [%rd14];
$L__BB78_9:
	cvt.u64.u32 	%rd11, %r37;
	setp.gt.u32 	%p6, %r4, 3;
	and.b32  	%r41, %r2, 2;
	setp.eq.s32 	%p7, %r41, 0;
	and.pred  	%p8, %p6, %p7;
	shl.b64 	%rd318, %rd13, 2;
	@%p8 bra 	$L__BB78_15;
	bra.uni 	$L__BB78_10;
$L__BB78_15:
	cvt.u16.u32 	%rs11, %r13;
	add.s16 	%rs12, %rs11, -2;
	cvt.s16.s8 	%rs13, %rs12;
	shr.s16 	%rs14, %rs13, 1;
	mul.lo.s64 	%rd71, %rd316, 76800;
	add.s64 	%rd72, %rd6, %rd71;
	mul.lo.s64 	%rd73, %rd317, 1536;
	add.s64 	%rd74, %rd72, %rd73;
	cvt.s32.s16 	%r42, %rs14;
	mul.wide.s32 	%rd75, %r42, 24;
	add.s64 	%rd76, %rd74, %rd75;
	add.s64 	%rd78, %rd76, %rd318;
	ld.global.nc.f32 	%f130, [%rd78];
$L__BB78_10:
	add.rn.f32 	%f64, %f129, %f130;
	mul.rn.f32 	%f65, %f14, %f64;
	mul.lo.s64 	%rd79, %rd316, 12;
	add.s64 	%rd80, %rd3, %rd79;
	shl.b64 	%rd81, %rd11, 2;
	add.s64 	%rd82, %rd80, %rd81;
	ld.global.nc.f32 	%f66, [%rd82];
	mul.lo.s64 	%rd83, %rd316, 152400;
	add.s64 	%rd84, %rd4, %rd83;
	mul.lo.s64 	%rd85, %rd317, 3048;
	add.s64 	%rd86, %rd84, %rd85;
	mul.wide.u32 	%rd87, %r13, 24;
	add.s64 	%rd88, %rd86, %rd87;
	shl.b64 	%rd89, %rd11, 3;
	add.s64 	%rd90, %rd88, %rd89;
	ld.global.nc.f32 	%f67, [%rd90+-24];
	mul.rn.f32 	%f68, %f66, %f67;
	add.rn.f32 	%f69, %f65, %f68;
	mul.rn.f32 	%f70, %f13, %f69;
	shl.b32 	%r43, %r20, 1;
	mul.lo.s64 	%rd91, %rd316, 307200;
	add.s64 	%rd92, %rd8, %rd91;
	mul.lo.s64 	%rd93, %rd317, 6144;
	add.s64 	%rd94, %rd92, %rd93;
	mul.wide.u32 	%rd95, %r43, 24;
	add.s64 	%rd96, %rd94, %rd95;
	add.s64 	%rd98, %rd96, %rd318;
	ld.global.nc.f32 	%f71, [%rd98+48];
	add.rn.f32 	%f121, %f71, %f70;
$L__BB78_1:
	or.b32  	%r32, %r1, 2;
	mul.lo.s32 	%r31, %r30, 6;
	cvta.to.global.u64 	%rd1, %rd51;
	add.s32 	%r46, %r4, -1;
	and.b32  	%r14, %r46, 1;
	setp.eq.s32 	%p9, %r14, 0;
	cvt.u16.u32 	%rs15, %r46;
	shr.u16 	%rs16, %rs15, 15;
	add.s16 	%rs17, %rs15, %rs16;
	shr.s16 	%rs18, %rs17, 1;
	cvt.u32.u16 	%r15, %rs18;
	and.b32  	%r119, %r15, 1;
	shr.u32 	%r120, %r15, 1;
	add.s32 	%r123, %r15, -1;
	setp.gt.u32 	%p84, %r4, 2;
	mov.f32 	%f122, %f128;
	@%p9 bra 	$L__BB78_16;
	bra.uni 	$L__BB78_2;
$L__BB78_16:
	setp.eq.b32 	%p10, %r119, 1;
	xor.pred  	%p12, %p10, %p86;
	not.pred 	%p13, %p12;
	mov.f32 	%f132, 0f00000000;
	mov.f32 	%f131, %f132;
	@%p13 bra 	$L__BB78_19;
	bra.uni 	$L__BB78_17;
$L__BB78_19:
	mul.wide.u32 	%rd105, %r124, 76800;
	add.s64 	%rd106, %rd5, %rd105;
	mul.wide.u32 	%rd107, %r125, 1536;
	add.s64 	%rd108, %rd106, %rd107;
	mul.wide.u32 	%rd109, %r120, 24;
	add.s64 	%rd110, %rd108, %rd109;
	mul.wide.u32 	%rd111, %r3, 4;
	add.s64 	%rd18, %rd110, %rd111;
	ld.global.nc.f32 	%f131, [%rd18];
$L__BB78_17:
	and.b32  	%r52, %r123, 1;
	setp.eq.b32 	%p15, %r52, 1;
	not.pred 	%p16, %p15;
	and.pred  	%p17, %p84, %p16;
	@%p17 bra 	$L__BB78_20;
	bra.uni 	$L__BB78_18;
$L__BB78_20:
	cvt.u64.u32 	%rd17, %r3;
	shr.u32 	%r53, %r123, 1;
	mul.lo.s64 	%rd112, %rd316, 76800;
	add.s64 	%rd113, %rd6, %rd112;
	mul.lo.s64 	%rd114, %rd317, 1536;
	add.s64 	%rd115, %rd113, %rd114;
	mul.wide.u32 	%rd116, %r53, 24;
	add.s64 	%rd117, %rd115, %rd116;
	shl.b64 	%rd118, %rd17, 2;
	add.s64 	%rd19, %rd117, %rd118;
	ld.global.nc.f32 	%f132, [%rd19];
$L__BB78_18:
	add.rn.f32 	%f122, %f131, %f132;
$L__BB78_2:
	mul.hi.u32 	%r6, %r32, 715827883;
	sub.s32 	%r5, %r29, %r31;
	add.rn.f32 	%f76, %f121, %f122;
	mul.wide.u32 	%rd119, %r1, 4;
	add.s64 	%rd9, %rd1, %rd119;
	st.global.f32 	[%rd9], %f76;
	mov.f32 	%f123, %f128;
	@%p1 bra 	$L__BB78_23;
	bra.uni 	$L__BB78_3;
$L__BB78_23:
	@%p85 bra 	$L__BB78_25;
	mul.wide.u32 	%rd161, %r124, 307200;
	add.s64 	%rd162, %rd8, %rd161;
	mul.wide.u32 	%rd163, %r125, 6144;
	add.s64 	%rd164, %rd162, %rd163;
	mul.wide.u32 	%rd165, %r5, 4;
	add.s64 	%rd166, %rd164, %rd165;
	ld.global.nc.f32 	%f123, [%rd166];
	bra.uni 	$L__BB78_3;
$L__BB78_25:
	add.s32 	%r21, %r13, -1;
	mul.wide.u32 	%rd120, %r124, 4;
	add.s64 	%rd121, %rd7, %rd120;
	ld.global.nc.f32 	%f26, [%rd121];
	shr.u32 	%r55, %r5, 1;
	mul.wide.u32 	%rd122, %r124, 12;
	add.s64 	%rd123, %rd2, %rd122;
	mul.wide.u32 	%rd124, %r55, 4;
	add.s64 	%rd125, %rd123, %rd124;
	ld.global.nc.f32 	%f27, [%rd125];
	and.b32  	%r56, %r21, 1;
	setp.eq.b32 	%p20, %r56, 1;
	xor.pred  	%p22, %p20, %p86;
	cvt.u64.u32 	%rd23, %r5;
	mov.f32 	%f134, 0f00000000;
	mov.f32 	%f133, %f134;
	@%p22 bra 	$L__BB78_21;
	shr.u32 	%r57, %r21, 1;
	mul.wide.u32 	%rd126, %r124, 76800;
	add.s64 	%rd127, %rd5, %rd126;
	mul.wide.u32 	%rd128, %r125, 1536;
	add.s64 	%rd129, %rd127, %rd128;
	mul.wide.u32 	%rd130, %r57, 24;
	add.s64 	%rd131, %rd129, %rd130;
	mul.wide.u32 	%rd132, %r5, 4;
	add.s64 	%rd24, %rd131, %rd132;
	ld.global.nc.f32 	%f133, [%rd24];
$L__BB78_21:
	cvt.u64.u32 	%rd21, %r55;
	setp.gt.u32 	%p23, %r4, 3;
	and.b32  	%r59, %r2, 2;
	setp.eq.s32 	%p24, %r59, 0;
	and.pred  	%p25, %p23, %p24;
	shl.b64 	%rd313, %rd23, 2;
	@%p25 bra 	$L__BB78_27;
	bra.uni 	$L__BB78_22;
$L__BB78_27:
	cvt.u16.u32 	%rs19, %r13;
	add.s16 	%rs20, %rs19, -2;
	cvt.s16.s8 	%rs21, %rs20;
	shr.s16 	%rs22, %rs21, 1;
	mul.lo.s64 	%rd133, %rd316, 76800;
	add.s64 	%rd134, %rd6, %rd133;
	mul.lo.s64 	%rd135, %rd317, 1536;
	add.s64 	%rd136, %rd134, %rd135;
	cvt.s32.s16 	%r60, %rs22;
	mul.wide.s32 	%rd137, %r60, 24;
	add.s64 	%rd138, %rd136, %rd137;
	add.s64 	%rd140, %rd138, %rd313;
	ld.global.nc.f32 	%f134, [%rd140];
$L__BB78_22:
	add.rn.f32 	%f79, %f133, %f134;
	mul.rn.f32 	%f80, %f27, %f79;
	mul.lo.s64 	%rd141, %rd316, 12;
	add.s64 	%rd142, %rd3, %rd141;
	shl.b64 	%rd143, %rd21, 2;
	add.s64 	%rd144, %rd142, %rd143;
	ld.global.nc.f32 	%f81, [%rd144];
	mul.lo.s64 	%rd145, %rd316, 152400;
	add.s64 	%rd146, %rd4, %rd145;
	mul.lo.s64 	%rd147, %rd317, 3048;
	add.s64 	%rd148, %rd146, %rd147;
	mul.wide.u32 	%rd149, %r13, 24;
	add.s64 	%rd150, %rd148, %rd149;
	shl.b64 	%rd151, %rd21, 3;
	add.s64 	%rd152, %rd150, %rd151;
	ld.global.nc.f32 	%f82, [%rd152+-20];
	mul.rn.f32 	%f83, %f81, %f82;
	add.rn.f32 	%f84, %f80, %f83;
	mul.rn.f32 	%f85, %f26, %f84;
	shl.b32 	%r61, %r21, 1;
	mul.lo.s64 	%rd153, %rd316, 307200;
	add.s64 	%rd154, %rd8, %rd153;
	mul.lo.s64 	%rd155, %rd317, 6144;
	add.s64 	%rd156, %rd154, %rd155;
	mul.wide.u32 	%rd157, %r61, 24;
	add.s64 	%rd158, %rd156, %rd157;
	add.s64 	%rd160, %rd158, %rd313;
	ld.global.nc.f32 	%f86, [%rd160+48];
	add.rn.f32 	%f123, %f86, %f85;
$L__BB78_3:
	or.b32  	%r34, %r1, 3;
	mul.lo.s32 	%r33, %r6, 6;
	mov.f32 	%f124, %f128;
	@%p9 bra 	$L__BB78_28;
	bra.uni 	$L__BB78_4;
$L__BB78_28:
	setp.eq.b32 	%p27, %r119, 1;
	xor.pred  	%p29, %p27, %p86;
	not.pred 	%p30, %p29;
	mov.f32 	%f136, 0f00000000;
	mov.f32 	%f135, %f136;
	@%p30 bra 	$L__BB78_31;
	bra.uni 	$L__BB78_29;
$L__BB78_31:
	mul.wide.u32 	%rd167, %r124, 76800;
	add.s64 	%rd168, %rd5, %rd167;
	mul.wide.u32 	%rd169, %r125, 1536;
	add.s64 	%rd170, %rd168, %rd169;
	mul.wide.u32 	%rd171, %r120, 24;
	add.s64 	%rd172, %rd170, %rd171;
	mul.wide.u32 	%rd173, %r5, 4;
	add.s64 	%rd28, %rd172, %rd173;
	ld.global.nc.f32 	%f135, [%rd28];
$L__BB78_29:
	and.b32  	%r69, %r123, 1;
	setp.eq.b32 	%p32, %r69, 1;
	not.pred 	%p33, %p32;
	and.pred  	%p34, %p84, %p33;
	@%p34 bra 	$L__BB78_32;
	bra.uni 	$L__BB78_30;
$L__BB78_32:
	cvt.u64.u32 	%rd27, %r5;
	shr.u32 	%r70, %r123, 1;
	mul.lo.s64 	%rd174, %rd316, 76800;
	add.s64 	%rd175, %rd6, %rd174;
	mul.lo.s64 	%rd176, %rd317, 1536;
	add.s64 	%rd177, %rd175, %rd176;
	mul.wide.u32 	%rd178, %r70, 24;
	add.s64 	%rd179, %rd177, %rd178;
	shl.b64 	%rd180, %rd27, 2;
	add.s64 	%rd29, %rd179, %rd180;
	ld.global.nc.f32 	%f136, [%rd29];
$L__BB78_30:
	add.rn.f32 	%f124, %f135, %f136;
$L__BB78_4:
	mul.hi.u32 	%r9, %r34, 715827883;
	and.b32  	%r8, %r6, 255;
	sub.s32 	%r7, %r32, %r33;
	add.rn.f32 	%f91, %f123, %f124;
	st.global.f32 	[%rd9+4], %f91;
	and.b32  	%r71, %r6, 1;
	setp.eq.b32 	%p35, %r71, 1;
	xor.pred  	%p37, %p35, %p86;
	not.pred 	%p38, %p37;
	mov.f32 	%f125, %f128;
	@%p38 bra 	$L__BB78_35;
	bra.uni 	$L__BB78_5;
$L__BB78_35:
	setp.gt.u32 	%p39, %r8, 1;
	@%p39 bra 	$L__BB78_37;
	mul.wide.u32 	%rd222, %r124, 307200;
	add.s64 	%rd223, %rd8, %rd222;
	mul.wide.u32 	%rd224, %r125, 6144;
	add.s64 	%rd225, %rd223, %rd224;
	mul.wide.u32 	%rd226, %r7, 4;
	add.s64 	%rd227, %rd225, %rd226;
	ld.global.nc.f32 	%f125, [%rd227];
	bra.uni 	$L__BB78_5;
$L__BB78_37:
	shr.u32 	%r16, %r8, 1;
	add.s32 	%r22, %r16, -1;
	mul.wide.u32 	%rd181, %r124, 4;
	add.s64 	%rd182, %rd7, %rd181;
	ld.global.nc.f32 	%f39, [%rd182];
	shr.u32 	%r73, %r7, 1;
	mul.wide.u32 	%rd183, %r124, 12;
	add.s64 	%rd184, %rd2, %rd183;
	mul.wide.u32 	%rd185, %r73, 4;
	add.s64 	%rd186, %rd184, %rd185;
	ld.global.nc.f32 	%f40, [%rd186];
	and.b32  	%r74, %r22, 1;
	setp.eq.b32 	%p40, %r74, 1;
	xor.pred  	%p42, %p40, %p86;
	cvt.u64.u32 	%rd33, %r7;
	mov.f32 	%f138, 0f00000000;
	mov.f32 	%f137, %f138;
	@%p42 bra 	$L__BB78_33;
	shr.u32 	%r75, %r22, 1;
	mul.wide.u32 	%rd187, %r124, 76800;
	add.s64 	%rd188, %rd5, %rd187;
	mul.wide.u32 	%rd189, %r125, 1536;
	add.s64 	%rd190, %rd188, %rd189;
	mul.wide.u32 	%rd191, %r75, 24;
	add.s64 	%rd192, %rd190, %rd191;
	mul.wide.u32 	%rd193, %r7, 4;
	add.s64 	%rd34, %rd192, %rd193;
	ld.global.nc.f32 	%f137, [%rd34];
$L__BB78_33:
	cvt.u64.u32 	%rd31, %r73;
	setp.gt.u32 	%p43, %r8, 3;
	and.b32  	%r77, %r6, 2;
	setp.eq.s32 	%p44, %r77, 0;
	and.pred  	%p45, %p43, %p44;
	shl.b64 	%rd308, %rd33, 2;
	@%p45 bra 	$L__BB78_39;
	bra.uni 	$L__BB78_34;
$L__BB78_39:
	cvt.u16.u32 	%rs23, %r16;
	add.s16 	%rs24, %rs23, -2;
	cvt.s16.s8 	%rs25, %rs24;
	shr.s16 	%rs26, %rs25, 1;
	mul.lo.s64 	%rd194, %rd316, 76800;
	add.s64 	%rd195, %rd6, %rd194;
	mul.lo.s64 	%rd196, %rd317, 1536;
	add.s64 	%rd197, %rd195, %rd196;
	cvt.s32.s16 	%r78, %rs26;
	mul.wide.s32 	%rd198, %r78, 24;
	add.s64 	%rd199, %rd197, %rd198;
	add.s64 	%rd201, %rd199, %rd308;
	ld.global.nc.f32 	%f138, [%rd201];
$L__BB78_34:
	add.rn.f32 	%f94, %f137, %f138;
	mul.rn.f32 	%f95, %f40, %f94;
	mul.lo.s64 	%rd202, %rd316, 12;
	add.s64 	%rd203, %rd3, %rd202;
	shl.b64 	%rd204, %rd31, 2;
	add.s64 	%rd205, %rd203, %rd204;
	ld.global.nc.f32 	%f96, [%rd205];
	mul.lo.s64 	%rd206, %rd316, 152400;
	add.s64 	%rd207, %rd4, %rd206;
	mul.lo.s64 	%rd208, %rd317, 3048;
	add.s64 	%rd209, %rd207, %rd208;
	mul.wide.u32 	%rd210, %r16, 24;
	add.s64 	%rd211, %rd209, %rd210;
	shl.b64 	%rd212, %rd31, 3;
	add.s64 	%rd213, %rd211, %rd212;
	ld.global.nc.f32 	%f97, [%rd213+-24];
	mul.rn.f32 	%f98, %f96, %f97;
	add.rn.f32 	%f99, %f95, %f98;
	mul.rn.f32 	%f100, %f39, %f99;
	shl.b32 	%r79, %r22, 1;
	mul.lo.s64 	%rd214, %rd316, 307200;
	add.s64 	%rd215, %rd8, %rd214;
	mul.lo.s64 	%rd216, %rd317, 6144;
	add.s64 	%rd217, %rd215, %rd216;
	mul.wide.u32 	%rd218, %r79, 24;
	add.s64 	%rd219, %rd217, %rd218;
	add.s64 	%rd221, %rd219, %rd308;
	ld.global.nc.f32 	%f101, [%rd221+48];
	add.rn.f32 	%f125, %f101, %f100;
$L__BB78_5:
	mul.lo.s32 	%r35, %r9, 6;
	add.s32 	%r82, %r8, -1;
	and.b32  	%r83, %r82, 1;
	setp.eq.b32 	%p46, %r83, 1;
	xor.pred  	%p48, %p46, %p86;
	not.pred 	%p49, %p48;
	mov.f32 	%f126, %f128;
	@%p49 bra 	$L__BB78_40;
	bra.uni 	$L__BB78_6;
$L__BB78_40:
	cvt.u16.u32 	%rs27, %r82;
	shr.u16 	%rs28, %rs27, 15;
	add.s16 	%rs29, %rs27, %rs28;
	shr.s16 	%rs30, %rs29, 1;
	cvt.u32.u16 	%r17, %rs30;
	and.b32  	%r84, %r17, 1;
	setp.eq.b32 	%p50, %r84, 1;
	xor.pred  	%p52, %p50, %p86;
	not.pred 	%p53, %p52;
	mov.f32 	%f140, 0f00000000;
	mov.f32 	%f139, %f140;
	@%p53 bra 	$L__BB78_43;
	bra.uni 	$L__BB78_41;
$L__BB78_43:
	shr.u32 	%r85, %r17, 1;
	mul.wide.u32 	%rd228, %r124, 76800;
	add.s64 	%rd229, %rd5, %rd228;
	mul.wide.u32 	%rd230, %r125, 1536;
	add.s64 	%rd231, %rd229, %rd230;
	mul.wide.u32 	%rd232, %r85, 24;
	add.s64 	%rd233, %rd231, %rd232;
	mul.wide.u32 	%rd234, %r7, 4;
	add.s64 	%rd38, %rd233, %rd234;
	ld.global.nc.f32 	%f139, [%rd38];
$L__BB78_41:
	add.s32 	%r88, %r17, -1;
	setp.gt.u32 	%p54, %r8, 2;
	and.b32  	%r89, %r88, 1;
	setp.eq.b32 	%p55, %r89, 1;
	not.pred 	%p56, %p55;
	and.pred  	%p57, %p54, %p56;
	@%p57 bra 	$L__BB78_44;
	bra.uni 	$L__BB78_42;
$L__BB78_44:
	cvt.u64.u32 	%rd37, %r7;
	shr.u32 	%r90, %r88, 1;
	mul.lo.s64 	%rd235, %rd316, 76800;
	add.s64 	%rd236, %rd6, %rd235;
	mul.lo.s64 	%rd237, %rd317, 1536;
	add.s64 	%rd238, %rd236, %rd237;
	mul.wide.u32 	%rd239, %r90, 24;
	add.s64 	%rd240, %rd238, %rd239;
	shl.b64 	%rd241, %rd37, 2;
	add.s64 	%rd39, %rd240, %rd241;
	ld.global.nc.f32 	%f140, [%rd39];
$L__BB78_42:
	add.rn.f32 	%f126, %f139, %f140;
$L__BB78_6:
	and.b32  	%r11, %r9, 255;
	sub.s32 	%r10, %r34, %r35;
	add.rn.f32 	%f106, %f125, %f126;
	st.global.f32 	[%rd9+8], %f106;
	and.b32  	%r91, %r9, 1;
	setp.eq.b32 	%p58, %r91, 1;
	xor.pred  	%p60, %p58, %p86;
	not.pred 	%p61, %p60;
	mov.f32 	%f127, %f128;
	@%p61 bra 	$L__BB78_47;
	bra.uni 	$L__BB78_7;
$L__BB78_47:
	setp.gt.u32 	%p62, %r11, 1;
	@%p62 bra 	$L__BB78_49;
	mul.wide.u32 	%rd283, %r124, 307200;
	add.s64 	%rd284, %rd8, %rd283;
	mul.wide.u32 	%rd285, %r125, 6144;
	add.s64 	%rd286, %rd284, %rd285;
	mul.wide.u32 	%rd287, %r10, 4;
	add.s64 	%rd288, %rd286, %rd287;
	ld.global.nc.f32 	%f127, [%rd288];
	bra.uni 	$L__BB78_7;
$L__BB78_49:
	shr.u32 	%r18, %r11, 1;
	add.s32 	%r23, %r18, -1;
	mul.wide.u32 	%rd242, %r124, 4;
	add.s64 	%rd243, %rd7, %rd242;
	ld.global.nc.f32 	%f52, [%rd243];
	shr.u32 	%r93, %r10, 1;
	mul.wide.u32 	%rd244, %r124, 12;
	add.s64 	%rd245, %rd2, %rd244;
	mul.wide.u32 	%rd246, %r93, 4;
	add.s64 	%rd247, %rd245, %rd246;
	ld.global.nc.f32 	%f53, [%rd247];
	and.b32  	%r94, %r23, 1;
	setp.eq.b32 	%p63, %r94, 1;
	xor.pred  	%p65, %p63, %p86;
	cvt.u64.u32 	%rd43, %r10;
	mov.f32 	%f142, 0f00000000;
	mov.f32 	%f141, %f142;
	@%p65 bra 	$L__BB78_45;
	shr.u32 	%r95, %r23, 1;
	mul.wide.u32 	%rd248, %r124, 76800;
	add.s64 	%rd249, %rd5, %rd248;
	mul.wide.u32 	%rd250, %r125, 1536;
	add.s64 	%rd251, %rd249, %rd250;
	mul.wide.u32 	%rd252, %r95, 24;
	add.s64 	%rd253, %rd251, %rd252;
	mul.wide.u32 	%rd254, %r10, 4;
	add.s64 	%rd44, %rd253, %rd254;
	ld.global.nc.f32 	%f141, [%rd44];
$L__BB78_45:
	cvt.u64.u32 	%rd41, %r93;
	setp.gt.u32 	%p66, %r11, 3;
	and.b32  	%r97, %r9, 2;
	setp.eq.s32 	%p67, %r97, 0;
	and.pred  	%p68, %p66, %p67;
	shl.b64 	%rd303, %rd43, 2;
	@%p68 bra 	$L__BB78_51;
	bra.uni 	$L__BB78_46;
$L__BB78_51:
	cvt.u16.u32 	%rs31, %r18;
	add.s16 	%rs32, %rs31, -2;
	cvt.s16.s8 	%rs33, %rs32;
	shr.s16 	%rs34, %rs33, 1;
	mul.lo.s64 	%rd255, %rd316, 76800;
	add.s64 	%rd256, %rd6, %rd255;
	mul.lo.s64 	%rd257, %rd317, 1536;
	add.s64 	%rd258, %rd256, %rd257;
	cvt.s32.s16 	%r98, %rs34;
	mul.wide.s32 	%rd259, %r98, 24;
	add.s64 	%rd260, %rd258, %rd259;
	add.s64 	%rd262, %rd260, %rd303;
	ld.global.nc.f32 	%f142, [%rd262];
$L__BB78_46:
	add.rn.f32 	%f109, %f141, %f142;
	mul.rn.f32 	%f110, %f53, %f109;
	mul.lo.s64 	%rd263, %rd316, 12;
	add.s64 	%rd264, %rd3, %rd263;
	shl.b64 	%rd265, %rd41, 2;
	add.s64 	%rd266, %rd264, %rd265;
	ld.global.nc.f32 	%f111, [%rd266];
	mul.lo.s64 	%rd267, %rd316, 152400;
	add.s64 	%rd268, %rd4, %rd267;
	mul.lo.s64 	%rd269, %rd317, 3048;
	add.s64 	%rd270, %rd268, %rd269;
	mul.wide.u32 	%rd271, %r18, 24;
	add.s64 	%rd272, %rd270, %rd271;
	shl.b64 	%rd273, %rd41, 3;
	add.s64 	%rd274, %rd272, %rd273;
	ld.global.nc.f32 	%f112, [%rd274+-20];
	mul.rn.f32 	%f113, %f111, %f112;
	add.rn.f32 	%f114, %f110, %f113;
	mul.rn.f32 	%f115, %f52, %f114;
	shl.b32 	%r99, %r23, 1;
	mul.lo.s64 	%rd275, %rd316, 307200;
	add.s64 	%rd276, %rd8, %rd275;
	mul.lo.s64 	%rd277, %rd317, 6144;
	add.s64 	%rd278, %rd276, %rd277;
	mul.wide.u32 	%rd279, %r99, 24;
	add.s64 	%rd280, %rd278, %rd279;
	add.s64 	%rd282, %rd280, %rd303;
	ld.global.nc.f32 	%f116, [%rd282+48];
	add.rn.f32 	%f127, %f116, %f115;
$L__BB78_7:
	add.s32 	%r102, %r11, -1;
	and.b32  	%r103, %r102, 1;
	setp.eq.b32 	%p69, %r103, 1;
	xor.pred  	%p71, %p69, %p86;
	not.pred 	%p72, %p71;
	@%p72 bra 	$L__BB78_52;
	bra.uni 	$L__BB78_8;
$L__BB78_52:
	cvt.u16.u32 	%rs35, %r102;
	shr.u16 	%rs36, %rs35, 15;
	add.s16 	%rs37, %rs35, %rs36;
	shr.s16 	%rs38, %rs37, 1;
	cvt.u32.u16 	%r19, %rs38;
	and.b32  	%r104, %r19, 1;
	setp.eq.b32 	%p73, %r104, 1;
	xor.pred  	%p75, %p73, %p86;
	not.pred 	%p76, %p75;
	mov.f32 	%f144, 0f00000000;
	mov.f32 	%f143, %f144;
	@%p76 bra 	$L__BB78_55;
	bra.uni 	$L__BB78_53;
$L__BB78_55:
	shr.u32 	%r105, %r19, 1;
	mul.wide.u32 	%rd289, %r124, 76800;
	add.s64 	%rd290, %rd5, %rd289;
	mul.wide.u32 	%rd291, %r125, 1536;
	add.s64 	%rd292, %rd290, %rd291;
	mul.wide.u32 	%rd293, %r105, 24;
	add.s64 	%rd294, %rd292, %rd293;
	mul.wide.u32 	%rd295, %r10, 4;
	add.s64 	%rd48, %rd294, %rd295;
	ld.global.nc.f32 	%f143, [%rd48];
$L__BB78_53:
	add.s32 	%r108, %r19, -1;
	setp.gt.u32 	%p77, %r11, 2;
	and.b32  	%r109, %r108, 1;
	setp.eq.b32 	%p78, %r109, 1;
	not.pred 	%p79, %p78;
	and.pred  	%p80, %p77, %p79;
	@%p80 bra 	$L__BB78_56;
	bra.uni 	$L__BB78_54;
$L__BB78_56:
	cvt.u64.u32 	%rd47, %r10;
	shr.u32 	%r110, %r108, 1;
	mul.lo.s64 	%rd296, %rd316, 76800;
	add.s64 	%rd297, %rd6, %rd296;
	mul.lo.s64 	%rd298, %rd317, 1536;
	add.s64 	%rd299, %rd297, %rd298;
	mul.wide.u32 	%rd300, %r110, 24;
	add.s64 	%rd301, %rd299, %rd300;
	shl.b64 	%rd302, %rd47, 2;
	add.s64 	%rd49, %rd301, %rd302;
	ld.global.nc.f32 	%f144, [%rd49];
$L__BB78_54:
	add.rn.f32 	%f128, %f143, %f144;
$L__BB78_8:
	add.rn.f32 	%f120, %f127, %f128;
	st.global.f32 	[%rd9+12], %f120;
	ret;

}
	// .globl	input_concatenate_fusion_199
.visible .entry input_concatenate_fusion_199(
	.param .u64 input_concatenate_fusion_199_param_0,
	.param .u64 input_concatenate_fusion_199_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<21>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<22>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_199_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_199_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -1431655765;
	shr.u32 	%r6, %r5, 1;
	mul.lo.s32 	%r7, %r6, 3;
	sub.s32 	%r8, %r4, %r7;
	mul.hi.u32 	%r9, %r6, -2139062143;
	shr.u32 	%r10, %r9, 7;
	mul.lo.s32 	%r11, %r10, 255;
	sub.s32 	%r12, %r6, %r11;
	mul.hi.u32 	%r13, %r4, 718635051;
	shr.u32 	%r14, %r13, 7;
	cvt.u16.u32 	%rs1, %r14;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r15, %r4, -615555835;
	bfe.u32 	%r16, %r15, 15, 6;
	shl.b32 	%r17, %r8, 1;
	or.b32  	%r18, %r17, 1;
	setp.gt.u32 	%p1, %r8, 1;
	selp.b32 	%r19, 5, %r18, %p1;
	cvt.u32.u16 	%r20, %rs6;
	mul.wide.u32 	%rd5, %r20, 6144;
	mul.wide.u32 	%rd6, %r16, 307200;
	add.s64 	%rd7, %rd4, %rd6;
	add.s64 	%rd8, %rd7, %rd5;
	mul.wide.u32 	%rd9, %r12, 24;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r19, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	neg.f32 	%f2, %f1;
	mul.wide.u32 	%rd13, %r20, 6120;
	mul.wide.u32 	%rd14, %r16, 306000;
	add.s64 	%rd15, %rd3, %rd14;
	add.s64 	%rd16, %rd15, %rd13;
	add.s64 	%rd17, %rd16, %rd9;
	mul.wide.u32 	%rd18, %r8, 8;
	add.s64 	%rd19, %rd17, %rd18;
	mul.wide.u32 	%rd20, %r17, 4;
	add.s64 	%rd21, %rd10, %rd20;
	ld.global.nc.f32 	%f3, [%rd21];
	st.global.v2.f32 	[%rd19], {%f2, %f3};
	ret;

}
	// .globl	input_concatenate_fusion_200
.visible .entry input_concatenate_fusion_200(
	.param .u64 input_concatenate_fusion_200_param_0,
	.param .u64 input_concatenate_fusion_200_param_1,
	.param .u64 input_concatenate_fusion_200_param_2,
	.param .u64 input_concatenate_fusion_200_param_3,
	.param .u64 input_concatenate_fusion_200_param_4,
	.param .u64 input_concatenate_fusion_200_param_5,
	.param .u64 input_concatenate_fusion_200_param_6,
	.param .u64 input_concatenate_fusion_200_param_7,
	.param .u64 input_concatenate_fusion_200_param_8,
	.param .u64 input_concatenate_fusion_200_param_9,
	.param .u64 input_concatenate_fusion_200_param_10
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<32>;
	.reg .f32 	%f<33>;
	.reg .b64 	%rd<110>;

	ld.param.u64 	%rd21, [input_concatenate_fusion_200_param_0];
	ld.param.u64 	%rd22, [input_concatenate_fusion_200_param_10];
	cvta.to.global.u64 	%rd1, %rd22;
	ld.param.u64 	%rd23, [input_concatenate_fusion_200_param_1];
	ld.param.u64 	%rd24, [input_concatenate_fusion_200_param_9];
	cvta.to.global.u64 	%rd2, %rd24;
	ld.param.u64 	%rd25, [input_concatenate_fusion_200_param_2];
	ld.param.u64 	%rd26, [input_concatenate_fusion_200_param_8];
	cvta.to.global.u64 	%rd3, %rd26;
	ld.param.u64 	%rd27, [input_concatenate_fusion_200_param_3];
	ld.param.u64 	%rd28, [input_concatenate_fusion_200_param_7];
	cvta.to.global.u64 	%rd4, %rd28;
	ld.param.u64 	%rd29, [input_concatenate_fusion_200_param_4];
	ld.param.u64 	%rd30, [input_concatenate_fusion_200_param_6];
	cvta.to.global.u64 	%rd5, %rd30;
	ld.param.u64 	%rd31, [input_concatenate_fusion_200_param_5];
	cvta.to.global.u64 	%rd6, %rd31;
	cvta.to.global.u64 	%rd7, %rd29;
	cvta.to.global.u64 	%rd8, %rd27;
	cvta.to.global.u64 	%rd9, %rd25;
	cvta.to.global.u64 	%rd10, %rd23;
	cvta.to.global.u64 	%rd11, %rd21;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	shl.b32 	%r6, %r4, 7;
	or.b32  	%r1, %r6, %r5;
	mul.hi.u32 	%r7, %r1, -1431655765;
	shr.u32 	%r2, %r7, 2;
	mul.lo.s32 	%r8, %r2, 6;
	sub.s32 	%r3, %r1, %r8;
	setp.lt.u32 	%p1, %r1, 19200;
	@%p1 bra 	$L__BB80_2;
	bra.uni 	$L__BB80_1;
$L__BB80_2:
	cvt.u16.u32 	%rs1, %r1;
	shr.u16 	%rs2, %rs1, 2;
	mul.hi.u16 	%rs3, %rs2, 27963;
	shr.u16 	%rs4, %rs3, 5;
	mul.hi.u32 	%r11, %r2, 85899346;
	mul.lo.s32 	%r12, %r11, 50;
	sub.s32 	%r13, %r2, %r12;
	cvt.u32.u16 	%r14, %rs4;
	mul.wide.u32 	%rd32, %r14, 4;
	add.s64 	%rd33, %rd10, %rd32;
	ld.global.nc.f32 	%f1, [%rd33];
	shr.u32 	%r15, %r3, 1;
	cvt.u64.u32 	%rd109, %r15;
	mul.wide.u32 	%rd34, %r14, 12;
	add.s64 	%rd35, %rd4, %rd34;
	mul.wide.u32 	%rd36, %r15, 4;
	add.s64 	%rd37, %rd35, %rd36;
	ld.global.nc.f32 	%f2, [%rd37];
	shl.b32 	%r16, %r13, 10;
	cvt.u64.u32 	%rd108, %r3;
	mul.wide.u32 	%rd38, %r14, 1228800;
	add.s64 	%rd39, %rd11, %rd38;
	mul.wide.u32 	%rd40, %r16, 24;
	add.s64 	%rd41, %rd39, %rd40;
	mul.wide.u32 	%rd42, %r3, 4;
	add.s64 	%rd43, %rd41, %rd42;
	ld.global.nc.f32 	%f3, [%rd43];
	mul.rn.f32 	%f4, %f2, %f3;
	add.s64 	%rd44, %rd5, %rd34;
	add.s64 	%rd45, %rd44, %rd36;
	ld.global.nc.f32 	%f5, [%rd45];
	and.b32  	%r17, %r3, 1;
	cvt.u64.u32 	%rd107, %r17;
	mul.wide.u32 	%rd46, %r14, 614400;
	add.s64 	%rd47, %rd6, %rd46;
	mul.wide.u32 	%rd48, %r13, 12288;
	add.s64 	%rd49, %rd47, %rd48;
	mul.wide.u32 	%rd50, %r15, 8;
	add.s64 	%rd51, %rd49, %rd50;
	mul.wide.u32 	%rd52, %r17, 4;
	add.s64 	%rd53, %rd51, %rd52;
	ld.global.nc.f32 	%f6, [%rd53];
	mul.rn.f32 	%f7, %f5, %f6;
	add.rn.f32 	%f8, %f4, %f7;
	mul.rn.f32 	%f9, %f1, %f8;
	ld.global.nc.f32 	%f10, [%rd43+24];
	add.rn.f32 	%f11, %f10, %f9;
	mul.wide.u32 	%rd54, %r14, 307200;
	add.s64 	%rd55, %rd1, %rd54;
	mul.wide.u32 	%rd56, %r13, 6144;
	add.s64 	%rd57, %rd55, %rd56;
	add.s64 	%rd58, %rd57, %rd42;
	st.global.f32 	[%rd58], %f11;
	bra.uni 	$L__BB80_3;
$L__BB80_1:
	shr.u32 	%r9, %r3, 1;
	cvt.u64.u32 	%rd109, %r9;
	cvt.u64.u32 	%rd108, %r3;
	and.b32  	%r10, %r3, 1;
	cvt.u64.u32 	%rd107, %r10;
$L__BB80_3:
	mul.hi.u32 	%r18, %r1, -615555835;
	bfe.u32 	%r19, %r18, 16, 6;
	mul.hi.u32 	%r20, %r1, 718635051;
	shr.u32 	%r21, %r20, 8;
	cvt.u16.u32 	%rs5, %r21;
	shr.u16 	%rs6, %rs5, 1;
	mul.hi.u16 	%rs7, %rs6, 5243;
	shr.u16 	%rs8, %rs7, 1;
	mul.lo.s16 	%rs9, %rs8, 50;
	sub.s16 	%rs10, %rs5, %rs9;
	mul.hi.u32 	%r22, %r2, 1077952577;
	shr.u32 	%r23, %r22, 6;
	mul.lo.s32 	%r24, %r23, 255;
	sub.s32 	%r25, %r2, %r24;
	mul.wide.u32 	%rd59, %r19, 4;
	add.s64 	%rd60, %rd9, %rd59;
	ld.global.nc.f32 	%f12, [%rd60];
	mul.wide.u32 	%rd61, %r19, 12;
	add.s64 	%rd62, %rd3, %rd61;
	shl.b64 	%rd63, %rd109, 2;
	add.s64 	%rd64, %rd62, %rd63;
	ld.global.nc.f32 	%f13, [%rd64];
	mul.wide.u32 	%rd65, %r19, 307200;
	add.s64 	%rd66, %rd7, %rd65;
	cvt.u32.u16 	%r26, %rs10;
	mul.wide.u32 	%rd67, %r26, 6144;
	add.s64 	%rd68, %rd66, %rd67;
	mul.wide.u32 	%rd69, %r25, 24;
	add.s64 	%rd70, %rd68, %rd69;
	shl.b64 	%rd71, %rd108, 2;
	add.s64 	%rd72, %rd70, %rd71;
	ld.global.nc.f32 	%f14, [%rd72];
	mul.rn.f32 	%f15, %f13, %f14;
	add.s64 	%rd73, %rd2, %rd61;
	add.s64 	%rd74, %rd73, %rd63;
	ld.global.nc.f32 	%f16, [%rd74];
	mul.wide.u32 	%rd75, %r1, 4;
	add.s64 	%rd76, %rd8, %rd75;
	ld.global.nc.f32 	%f17, [%rd76];
	mul.rn.f32 	%f18, %f16, %f17;
	add.rn.f32 	%f19, %f15, %f18;
	mul.rn.f32 	%f20, %f12, %f19;
	shl.b32 	%r27, %r25, 1;
	shl.b32 	%r28, %r25, 2;
	add.s64 	%rd77, %rd10, %rd59;
	ld.global.nc.f32 	%f21, [%rd77];
	add.s64 	%rd78, %rd4, %rd61;
	add.s64 	%rd79, %rd78, %rd63;
	ld.global.nc.f32 	%f22, [%rd79];
	add.s32 	%r29, %r28, 4;
	shl.b16 	%rs11, %rs10, 10;
	cvt.u32.u16 	%r30, %rs11;
	add.s32 	%r31, %r29, %r30;
	mul.wide.u32 	%rd80, %r31, 24;
	mul.wide.u32 	%rd81, %r19, 1228800;
	add.s64 	%rd82, %rd11, %rd81;
	add.s64 	%rd83, %rd82, %rd80;
	add.s64 	%rd84, %rd83, %rd71;
	ld.global.nc.f32 	%f23, [%rd84];
	mul.rn.f32 	%f24, %f22, %f23;
	add.s64 	%rd85, %rd5, %rd61;
	add.s64 	%rd86, %rd85, %rd63;
	ld.global.nc.f32 	%f25, [%rd86];
	mul.wide.u32 	%rd87, %r19, 614400;
	add.s64 	%rd88, %rd6, %rd87;
	mul.wide.u32 	%rd89, %r26, 12288;
	add.s64 	%rd90, %rd88, %rd89;
	mul.wide.u32 	%rd91, %r27, 24;
	add.s64 	%rd92, %rd90, %rd91;
	shl.b64 	%rd93, %rd109, 3;
	add.s64 	%rd94, %rd92, %rd93;
	shl.b64 	%rd95, %rd107, 2;
	add.s64 	%rd96, %rd94, %rd95;
	ld.global.nc.f32 	%f26, [%rd96+48];
	mul.rn.f32 	%f27, %f25, %f26;
	add.rn.f32 	%f28, %f24, %f27;
	mul.rn.f32 	%f29, %f21, %f28;
	cvt.u64.u16 	%rd97, %rs11;
	cvt.u64.u32 	%rd98, %r29;
	add.s64 	%rd99, %rd98, %rd97;
	mul.lo.s64 	%rd100, %rd99, 24;
	add.s64 	%rd101, %rd82, %rd100;
	add.s64 	%rd102, %rd101, %rd71;
	ld.global.nc.f32 	%f30, [%rd102+24];
	add.rn.f32 	%f31, %f30, %f29;
	add.rn.f32 	%f32, %f20, %f31;
	add.s64 	%rd103, %rd1, %rd65;
	add.s64 	%rd104, %rd103, %rd67;
	add.s64 	%rd105, %rd104, %rd69;
	add.s64 	%rd106, %rd105, %rd71;
	st.global.f32 	[%rd106+24], %f32;
	ret;

}
	// .globl	input_concatenate_fusion_201
.visible .entry input_concatenate_fusion_201(
	.param .u64 input_concatenate_fusion_201_param_0,
	.param .u64 input_concatenate_fusion_201_param_1,
	.param .u64 input_concatenate_fusion_201_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<31>;
	.reg .f32 	%f<20>;
	.reg .b64 	%rd<54>;

	ld.param.u64 	%rd13, [input_concatenate_fusion_201_param_0];
	ld.param.u64 	%rd14, [input_concatenate_fusion_201_param_2];
	ld.param.u64 	%rd15, [input_concatenate_fusion_201_param_1];
	cvta.to.global.u64 	%rd2, %rd15;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	shl.b32 	%r9, %r7, 7;
	or.b32  	%r10, %r9, %r8;
	mul.hi.u32 	%r11, %r10, -1431655765;
	shr.u32 	%r12, %r11, 1;
	mul.lo.s32 	%r13, %r12, 3;
	sub.s32 	%r1, %r10, %r13;
	mul.hi.u32 	%r14, %r12, -2143281135;
	shr.u32 	%r15, %r14, 8;
	mul.lo.s32 	%r16, %r15, 511;
	sub.s32 	%r2, %r12, %r16;
	mul.hi.u32 	%r17, %r10, 1442862465;
	sub.s32 	%r18, %r10, %r17;
	shr.u32 	%r19, %r18, 1;
	add.s32 	%r20, %r19, %r17;
	shr.u32 	%r21, %r20, 10;
	cvt.u16.u32 	%rs1, %r21;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r22, %r10, -622756249;
	bfe.u32 	%r23, %r22, 16, 6;
	shl.b32 	%r3, %r1, 1;
	or.b32  	%r24, %r3, 1;
	setp.gt.u32 	%p1, %r1, 1;
	selp.b32 	%r25, 5, %r24, %p1;
	and.b32  	%r4, %r2, 1;
	setp.eq.s32 	%p2, %r4, 0;
	cvt.u64.u32 	%rd4, %r23;
	cvt.u64.u16 	%rd5, %rs6;
	shr.u32 	%r26, %r2, 1;
	mov.f32 	%f19, 0f00000000;
	mov.f32 	%f16, %f19;
	@%p2 bra 	$L__BB81_6;
	bra.uni 	$L__BB81_1;
$L__BB81_6:
	cvt.u32.u16 	%r27, %rs6;
	mul.wide.u32 	%rd16, %r27, 6144;
	mul.wide.u32 	%rd17, %r23, 307200;
	add.s64 	%rd18, %rd2, %rd17;
	add.s64 	%rd19, %rd18, %rd16;
	mul.wide.u32 	%rd20, %r26, 24;
	add.s64 	%rd21, %rd19, %rd20;
	mul.wide.u32 	%rd22, %r25, 4;
	add.s64 	%rd8, %rd21, %rd22;
	ld.global.nc.f32 	%f16, [%rd8];
$L__BB81_1:
	cvta.to.global.u64 	%rd1, %rd14;
	cvta.to.global.u64 	%rd3, %rd13;
	add.s32 	%r5, %r2, -1;
	and.b32  	%r6, %r5, 1;
	setp.eq.s32 	%p3, %r6, 0;
	shr.u32 	%r30, %r5, 1;
	mul.lo.s64 	%rd52, %rd4, 307200;
	mul.lo.s64 	%rd53, %rd5, 6144;
	mov.f32 	%f17, %f19;
	@%p3 bra 	$L__BB81_7;
	bra.uni 	$L__BB81_2;
$L__BB81_7:
	cvt.u64.u32 	%rd7, %r25;
	add.s64 	%rd24, %rd3, %rd52;
	add.s64 	%rd26, %rd24, %rd53;
	mul.wide.u32 	%rd27, %r30, 24;
	add.s64 	%rd28, %rd26, %rd27;
	shl.b64 	%rd29, %rd7, 2;
	add.s64 	%rd30, %rd28, %rd29;
	ld.global.nc.f32 	%f17, [%rd30];
$L__BB81_2:
	add.rn.f32 	%f12, %f16, %f17;
	neg.f32 	%f13, %f12;
	mul.lo.s64 	%rd31, %rd4, 613200;
	add.s64 	%rd32, %rd1, %rd31;
	mul.lo.s64 	%rd33, %rd5, 12264;
	add.s64 	%rd34, %rd32, %rd33;
	mul.wide.u32 	%rd35, %r2, 24;
	add.s64 	%rd36, %rd34, %rd35;
	mul.wide.u32 	%rd37, %r1, 8;
	add.s64 	%rd9, %rd36, %rd37;
	st.global.f32 	[%rd9], %f13;
	mov.f32 	%f18, %f19;
	@%p2 bra 	$L__BB81_3;
	bra.uni 	$L__BB81_4;
$L__BB81_3:
	cvt.u64.u32 	%rd6, %r26;
	add.s64 	%rd39, %rd2, %rd52;
	add.s64 	%rd41, %rd39, %rd53;
	mul.lo.s64 	%rd42, %rd6, 24;
	add.s64 	%rd43, %rd41, %rd42;
	mul.wide.u32 	%rd44, %r3, 4;
	add.s64 	%rd11, %rd43, %rd44;
	ld.global.nc.f32 	%f18, [%rd11];
$L__BB81_4:
	@%p3 bra 	$L__BB81_8;
	bra.uni 	$L__BB81_5;
$L__BB81_8:
	cvt.u64.u32 	%rd10, %r3;
	add.s64 	%rd46, %rd3, %rd52;
	add.s64 	%rd48, %rd46, %rd53;
	mul.wide.u32 	%rd49, %r30, 24;
	add.s64 	%rd50, %rd48, %rd49;
	shl.b64 	%rd51, %rd10, 2;
	add.s64 	%rd12, %rd50, %rd51;
	ld.global.nc.f32 	%f19, [%rd12];
$L__BB81_5:
	add.rn.f32 	%f15, %f18, %f19;
	st.global.f32 	[%rd9+4], %f15;
	ret;

}
	// .globl	loop_add_fusion_303
.visible .entry loop_add_fusion_303(
	.param .u64 loop_add_fusion_303_param_0,
	.param .u64 loop_add_fusion_303_param_1,
	.param .u64 loop_add_fusion_303_param_2,
	.param .u64 loop_add_fusion_303_param_3,
	.param .u64 loop_add_fusion_303_param_4,
	.param .u64 loop_add_fusion_303_param_5,
	.param .u64 loop_add_fusion_303_param_6,
	.param .u64 loop_add_fusion_303_param_7
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<87>;
	.reg .b16 	%rs<35>;
	.reg .b32 	%r<114>;
	.reg .f32 	%f<145>;
	.reg .b64 	%rd<326>;

	ld.param.u64 	%rd50, [loop_add_fusion_303_param_0];
	ld.param.u64 	%rd51, [loop_add_fusion_303_param_7];
	ld.param.u64 	%rd52, [loop_add_fusion_303_param_1];
	ld.param.u64 	%rd53, [loop_add_fusion_303_param_6];
	cvta.to.global.u64 	%rd2, %rd53;
	ld.param.u64 	%rd54, [loop_add_fusion_303_param_2];
	ld.param.u64 	%rd55, [loop_add_fusion_303_param_5];
	cvta.to.global.u64 	%rd3, %rd55;
	ld.param.u64 	%rd56, [loop_add_fusion_303_param_3];
	ld.param.u64 	%rd57, [loop_add_fusion_303_param_4];
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	cvta.to.global.u64 	%rd6, %rd54;
	cvta.to.global.u64 	%rd7, %rd52;
	cvta.to.global.u64 	%rd8, %rd50;
	mov.u32 	%r25, %ctaid.x;
	mov.u32 	%r26, %tid.x;
	shl.b32 	%r27, %r25, 9;
	shl.b32 	%r28, %r26, 2;
	or.b32  	%r1, %r27, %r28;
	mul.hi.u32 	%r2, %r1, 715827883;
	mul.lo.s32 	%r29, %r2, 6;
	sub.s32 	%r3, %r1, %r29;
	and.b32  	%r4, %r2, 1023;
	cvt.u16.u32 	%rs3, %r25;
	mul.hi.u16 	%rs4, %rs3, -21845;
	shr.u16 	%rs5, %rs4, 3;
	mul.hi.u16 	%rs6, %rs5, 5243;
	shr.u16 	%rs7, %rs6, 2;
	mul.lo.s16 	%rs8, %rs7, 50;
	sub.s16 	%rs1, %rs5, %rs8;
	cvt.u32.u16 	%r5, %rs1;
	shr.u16 	%rs9, %rs3, 3;
	mul.hi.u16 	%rs10, %rs9, 6991;
	shr.u16 	%rs2, %rs10, 3;
	or.b32  	%r30, %r1, 1;
	mul.hi.u32 	%r31, %r30, 715827883;
	and.b32  	%r13, %r2, 1;
	setp.eq.s32 	%p1, %r13, 0;
	bfe.u32 	%r14, %r2, 1, 9;
	mov.f32 	%f128, 0f00000000;
	setp.gt.u32 	%p85, %r4, 1;
	cvt.u64.u16 	%rd322, %rs2;
	mov.pred 	%p86, 0;
	cvt.u64.u16 	%rd323, %rs1;
	mov.f32 	%f121, %f128;
	@%p1 bra 	$L__BB82_11;
	bra.uni 	$L__BB82_1;
$L__BB82_11:
	mul.lo.s64 	%rd325, %rd322, 1228800;
	@%p85 bra 	$L__BB82_13;
	shl.b32 	%r45, %r5, 10;
	add.s64 	%rd101, %rd8, %rd325;
	mul.wide.u32 	%rd102, %r45, 24;
	add.s64 	%rd103, %rd101, %rd102;
	mul.wide.u32 	%rd104, %r3, 4;
	add.s64 	%rd105, %rd103, %rd104;
	ld.global.nc.f32 	%f121, [%rd105];
	bra.uni 	$L__BB82_1;
$L__BB82_13:
	add.s32 	%r21, %r14, -1;
	shl.b64 	%rd58, %rd322, 2;
	add.s64 	%rd59, %rd7, %rd58;
	ld.global.nc.f32 	%f13, [%rd59];
	shr.u32 	%r37, %r3, 1;
	mul.lo.s64 	%rd60, %rd322, 12;
	add.s64 	%rd61, %rd3, %rd60;
	mul.wide.u32 	%rd62, %r37, 4;
	add.s64 	%rd63, %rd61, %rd62;
	ld.global.nc.f32 	%f14, [%rd63];
	and.b32  	%r38, %r21, 1;
	setp.eq.b32 	%p3, %r38, 1;
	xor.pred  	%p5, %p3, %p86;
	cvt.u64.u32 	%rd13, %r3;
	mul.lo.s64 	%rd64, %rd322, 307200;
	mov.f32 	%f130, 0f00000000;
	mov.f32 	%f129, %f130;
	@%p5 bra 	$L__BB82_9;
	shr.u32 	%r39, %r21, 1;
	add.s64 	%rd65, %rd5, %rd64;
	mul.wide.u32 	%rd66, %r5, 6144;
	add.s64 	%rd67, %rd65, %rd66;
	mul.wide.u32 	%rd68, %r39, 24;
	add.s64 	%rd69, %rd67, %rd68;
	mul.wide.u32 	%rd70, %r3, 4;
	add.s64 	%rd14, %rd69, %rd70;
	ld.global.nc.f32 	%f129, [%rd14];
$L__BB82_9:
	cvt.u64.u32 	%rd11, %r37;
	setp.gt.u32 	%p6, %r4, 3;
	and.b32  	%r41, %r2, 2;
	setp.eq.s32 	%p7, %r41, 0;
	and.pred  	%p8, %p6, %p7;
	shl.b64 	%rd324, %rd13, 2;
	@%p8 bra 	$L__BB82_15;
	bra.uni 	$L__BB82_10;
$L__BB82_15:
	cvt.u16.u32 	%rs11, %r14;
	add.s16 	%rs12, %rs11, -2;
	shr.s16 	%rs13, %rs12, 1;
	add.s64 	%rd72, %rd6, %rd64;
	mul.lo.s64 	%rd73, %rd323, 6144;
	add.s64 	%rd74, %rd72, %rd73;
	cvt.s32.s16 	%r42, %rs13;
	mul.wide.s32 	%rd75, %r42, 24;
	add.s64 	%rd76, %rd74, %rd75;
	add.s64 	%rd78, %rd76, %rd324;
	ld.global.nc.f32 	%f130, [%rd78];
$L__BB82_10:
	add.rn.f32 	%f64, %f129, %f130;
	mul.rn.f32 	%f65, %f14, %f64;
	add.s64 	%rd80, %rd2, %rd60;
	shl.b64 	%rd81, %rd11, 2;
	add.s64 	%rd82, %rd80, %rd81;
	ld.global.nc.f32 	%f66, [%rd82];
	mul.lo.s64 	%rd83, %rd322, 613200;
	add.s64 	%rd84, %rd4, %rd83;
	mul.lo.s64 	%rd85, %rd323, 12264;
	add.s64 	%rd86, %rd84, %rd85;
	mul.wide.u32 	%rd87, %r14, 24;
	add.s64 	%rd88, %rd86, %rd87;
	shl.b64 	%rd89, %rd11, 3;
	add.s64 	%rd90, %rd88, %rd89;
	ld.global.nc.f32 	%f67, [%rd90+-24];
	mul.rn.f32 	%f68, %f66, %f67;
	add.rn.f32 	%f69, %f65, %f68;
	mul.rn.f32 	%f70, %f13, %f69;
	shl.b32 	%r43, %r21, 1;
	shl.b32 	%r44, %r5, 10;
	cvt.u64.u32 	%rd91, %r43;
	cvt.u64.u32 	%rd92, %r44;
	add.s64 	%rd93, %rd92, %rd91;
	add.s64 	%rd95, %rd8, %rd325;
	mul.lo.s64 	%rd96, %rd93, 24;
	add.s64 	%rd97, %rd95, %rd96;
	add.s64 	%rd99, %rd97, %rd324;
	ld.global.nc.f32 	%f71, [%rd99+48];
	add.rn.f32 	%f121, %f71, %f70;
$L__BB82_1:
	or.b32  	%r33, %r1, 2;
	mul.lo.s32 	%r32, %r31, 6;
	cvta.to.global.u64 	%rd1, %rd51;
	add.s32 	%r46, %r4, -1;
	and.b32  	%r15, %r46, 1;
	setp.eq.s32 	%p9, %r15, 0;
	cvt.u16.u32 	%rs14, %r46;
	shr.u16 	%rs15, %rs14, 15;
	add.s16 	%rs16, %rs14, %rs15;
	shr.s16 	%rs17, %rs16, 1;
	cvt.u32.u16 	%r16, %rs17;
	and.b32  	%r110, %r16, 1;
	shr.u32 	%r111, %r16, 1;
	cvt.u32.u16 	%r112, %rs2;
	add.s32 	%r113, %r16, -1;
	setp.gt.u32 	%p84, %r4, 2;
	mov.f32 	%f122, %f128;
	@%p9 bra 	$L__BB82_16;
	bra.uni 	$L__BB82_2;
$L__BB82_16:
	setp.eq.b32 	%p10, %r110, 1;
	xor.pred  	%p12, %p10, %p86;
	not.pred 	%p13, %p12;
	mov.f32 	%f132, 0f00000000;
	mov.f32 	%f131, %f132;
	@%p13 bra 	$L__BB82_19;
	bra.uni 	$L__BB82_17;
$L__BB82_19:
	mul.wide.u32 	%rd106, %r112, 307200;
	add.s64 	%rd107, %rd5, %rd106;
	mul.wide.u32 	%rd108, %r5, 6144;
	add.s64 	%rd109, %rd107, %rd108;
	mul.wide.u32 	%rd110, %r111, 24;
	add.s64 	%rd111, %rd109, %rd110;
	mul.wide.u32 	%rd112, %r3, 4;
	add.s64 	%rd18, %rd111, %rd112;
	ld.global.nc.f32 	%f131, [%rd18];
$L__BB82_17:
	and.b32  	%r52, %r113, 1;
	setp.eq.b32 	%p15, %r52, 1;
	not.pred 	%p16, %p15;
	and.pred  	%p17, %p84, %p16;
	@%p17 bra 	$L__BB82_20;
	bra.uni 	$L__BB82_18;
$L__BB82_20:
	cvt.u64.u32 	%rd17, %r3;
	shr.u32 	%r53, %r113, 1;
	mul.lo.s64 	%rd113, %rd322, 307200;
	add.s64 	%rd114, %rd6, %rd113;
	mul.lo.s64 	%rd115, %rd323, 6144;
	add.s64 	%rd116, %rd114, %rd115;
	mul.wide.u32 	%rd117, %r53, 24;
	add.s64 	%rd118, %rd116, %rd117;
	shl.b64 	%rd119, %rd17, 2;
	add.s64 	%rd19, %rd118, %rd119;
	ld.global.nc.f32 	%f132, [%rd19];
$L__BB82_18:
	add.rn.f32 	%f122, %f131, %f132;
$L__BB82_2:
	mul.hi.u32 	%r7, %r33, 715827883;
	sub.s32 	%r6, %r30, %r32;
	add.rn.f32 	%f76, %f121, %f122;
	mul.wide.u32 	%rd120, %r1, 4;
	add.s64 	%rd9, %rd1, %rd120;
	st.global.f32 	[%rd9], %f76;
	mov.f32 	%f123, %f128;
	@%p1 bra 	$L__BB82_23;
	bra.uni 	$L__BB82_3;
$L__BB82_23:
	mul.lo.s64 	%rd319, %rd322, 1228800;
	@%p85 bra 	$L__BB82_25;
	shl.b32 	%r62, %r5, 10;
	add.s64 	%rd164, %rd8, %rd319;
	mul.wide.u32 	%rd165, %r62, 24;
	add.s64 	%rd166, %rd164, %rd165;
	mul.wide.u32 	%rd167, %r6, 4;
	add.s64 	%rd168, %rd166, %rd167;
	ld.global.nc.f32 	%f123, [%rd168];
	bra.uni 	$L__BB82_3;
$L__BB82_25:
	add.s32 	%r22, %r14, -1;
	shl.b64 	%rd121, %rd322, 2;
	add.s64 	%rd122, %rd7, %rd121;
	ld.global.nc.f32 	%f26, [%rd122];
	shr.u32 	%r54, %r6, 1;
	mul.lo.s64 	%rd123, %rd322, 12;
	add.s64 	%rd124, %rd3, %rd123;
	mul.wide.u32 	%rd125, %r54, 4;
	add.s64 	%rd126, %rd124, %rd125;
	ld.global.nc.f32 	%f27, [%rd126];
	and.b32  	%r55, %r22, 1;
	setp.eq.b32 	%p20, %r55, 1;
	xor.pred  	%p22, %p20, %p86;
	cvt.u64.u32 	%rd23, %r6;
	mul.lo.s64 	%rd127, %rd322, 307200;
	mov.f32 	%f134, 0f00000000;
	mov.f32 	%f133, %f134;
	@%p22 bra 	$L__BB82_21;
	shr.u32 	%r56, %r22, 1;
	add.s64 	%rd128, %rd5, %rd127;
	mul.wide.u32 	%rd129, %r5, 6144;
	add.s64 	%rd130, %rd128, %rd129;
	mul.wide.u32 	%rd131, %r56, 24;
	add.s64 	%rd132, %rd130, %rd131;
	mul.wide.u32 	%rd133, %r6, 4;
	add.s64 	%rd24, %rd132, %rd133;
	ld.global.nc.f32 	%f133, [%rd24];
$L__BB82_21:
	cvt.u64.u32 	%rd21, %r54;
	setp.gt.u32 	%p23, %r4, 3;
	and.b32  	%r58, %r2, 2;
	setp.eq.s32 	%p24, %r58, 0;
	and.pred  	%p25, %p23, %p24;
	shl.b64 	%rd318, %rd23, 2;
	@%p25 bra 	$L__BB82_27;
	bra.uni 	$L__BB82_22;
$L__BB82_27:
	cvt.u16.u32 	%rs18, %r14;
	add.s16 	%rs19, %rs18, -2;
	shr.s16 	%rs20, %rs19, 1;
	add.s64 	%rd135, %rd6, %rd127;
	mul.lo.s64 	%rd136, %rd323, 6144;
	add.s64 	%rd137, %rd135, %rd136;
	cvt.s32.s16 	%r59, %rs20;
	mul.wide.s32 	%rd138, %r59, 24;
	add.s64 	%rd139, %rd137, %rd138;
	add.s64 	%rd141, %rd139, %rd318;
	ld.global.nc.f32 	%f134, [%rd141];
$L__BB82_22:
	add.rn.f32 	%f79, %f133, %f134;
	mul.rn.f32 	%f80, %f27, %f79;
	add.s64 	%rd143, %rd2, %rd123;
	shl.b64 	%rd144, %rd21, 2;
	add.s64 	%rd145, %rd143, %rd144;
	ld.global.nc.f32 	%f81, [%rd145];
	mul.lo.s64 	%rd146, %rd322, 613200;
	add.s64 	%rd147, %rd4, %rd146;
	mul.lo.s64 	%rd148, %rd323, 12264;
	add.s64 	%rd149, %rd147, %rd148;
	mul.wide.u32 	%rd150, %r14, 24;
	add.s64 	%rd151, %rd149, %rd150;
	shl.b64 	%rd152, %rd21, 3;
	add.s64 	%rd153, %rd151, %rd152;
	ld.global.nc.f32 	%f82, [%rd153+-20];
	mul.rn.f32 	%f83, %f81, %f82;
	add.rn.f32 	%f84, %f80, %f83;
	mul.rn.f32 	%f85, %f26, %f84;
	shl.b32 	%r60, %r22, 1;
	shl.b32 	%r61, %r5, 10;
	cvt.u64.u32 	%rd154, %r60;
	cvt.u64.u32 	%rd155, %r61;
	add.s64 	%rd156, %rd155, %rd154;
	add.s64 	%rd158, %rd8, %rd319;
	mul.lo.s64 	%rd159, %rd156, 24;
	add.s64 	%rd160, %rd158, %rd159;
	add.s64 	%rd162, %rd160, %rd318;
	ld.global.nc.f32 	%f86, [%rd162+48];
	add.rn.f32 	%f123, %f86, %f85;
$L__BB82_3:
	or.b32  	%r35, %r1, 3;
	mul.lo.s32 	%r34, %r7, 6;
	mov.f32 	%f124, %f128;
	@%p9 bra 	$L__BB82_28;
	bra.uni 	$L__BB82_4;
$L__BB82_28:
	setp.eq.b32 	%p27, %r110, 1;
	xor.pred  	%p29, %p27, %p86;
	not.pred 	%p30, %p29;
	mov.f32 	%f136, 0f00000000;
	mov.f32 	%f135, %f136;
	@%p30 bra 	$L__BB82_31;
	bra.uni 	$L__BB82_29;
$L__BB82_31:
	mul.wide.u32 	%rd169, %r112, 307200;
	add.s64 	%rd170, %rd5, %rd169;
	mul.wide.u32 	%rd171, %r5, 6144;
	add.s64 	%rd172, %rd170, %rd171;
	mul.wide.u32 	%rd173, %r111, 24;
	add.s64 	%rd174, %rd172, %rd173;
	mul.wide.u32 	%rd175, %r6, 4;
	add.s64 	%rd28, %rd174, %rd175;
	ld.global.nc.f32 	%f135, [%rd28];
$L__BB82_29:
	and.b32  	%r68, %r113, 1;
	setp.eq.b32 	%p32, %r68, 1;
	not.pred 	%p33, %p32;
	and.pred  	%p34, %p84, %p33;
	@%p34 bra 	$L__BB82_32;
	bra.uni 	$L__BB82_30;
$L__BB82_32:
	cvt.u64.u32 	%rd27, %r6;
	shr.u32 	%r69, %r113, 1;
	mul.lo.s64 	%rd176, %rd322, 307200;
	add.s64 	%rd177, %rd6, %rd176;
	mul.lo.s64 	%rd178, %rd323, 6144;
	add.s64 	%rd179, %rd177, %rd178;
	mul.wide.u32 	%rd180, %r69, 24;
	add.s64 	%rd181, %rd179, %rd180;
	shl.b64 	%rd182, %rd27, 2;
	add.s64 	%rd29, %rd181, %rd182;
	ld.global.nc.f32 	%f136, [%rd29];
$L__BB82_30:
	add.rn.f32 	%f124, %f135, %f136;
$L__BB82_4:
	mul.hi.u32 	%r10, %r35, 715827883;
	and.b32  	%r9, %r7, 1023;
	sub.s32 	%r8, %r33, %r34;
	add.rn.f32 	%f91, %f123, %f124;
	st.global.f32 	[%rd9+4], %f91;
	and.b32  	%r70, %r7, 1;
	setp.eq.b32 	%p35, %r70, 1;
	xor.pred  	%p37, %p35, %p86;
	not.pred 	%p38, %p37;
	mov.f32 	%f125, %f128;
	@%p38 bra 	$L__BB82_35;
	bra.uni 	$L__BB82_5;
$L__BB82_35:
	setp.gt.u32 	%p39, %r9, 1;
	@%p39 bra 	$L__BB82_37;
	shl.b32 	%r79, %r5, 10;
	mul.lo.s64 	%rd225, %rd322, 1228800;
	add.s64 	%rd226, %rd8, %rd225;
	mul.wide.u32 	%rd227, %r79, 24;
	add.s64 	%rd228, %rd226, %rd227;
	mul.wide.u32 	%rd229, %r8, 4;
	add.s64 	%rd230, %rd228, %rd229;
	ld.global.nc.f32 	%f125, [%rd230];
	bra.uni 	$L__BB82_5;
$L__BB82_37:
	shr.u32 	%r17, %r9, 1;
	add.s32 	%r23, %r17, -1;
	shl.b64 	%rd183, %rd322, 2;
	add.s64 	%rd184, %rd7, %rd183;
	ld.global.nc.f32 	%f39, [%rd184];
	shr.u32 	%r71, %r8, 1;
	mul.lo.s64 	%rd185, %rd322, 12;
	add.s64 	%rd186, %rd3, %rd185;
	mul.wide.u32 	%rd187, %r71, 4;
	add.s64 	%rd188, %rd186, %rd187;
	ld.global.nc.f32 	%f40, [%rd188];
	and.b32  	%r72, %r23, 1;
	setp.eq.b32 	%p40, %r72, 1;
	xor.pred  	%p42, %p40, %p86;
	cvt.u64.u32 	%rd33, %r8;
	mul.lo.s64 	%rd189, %rd322, 307200;
	mov.f32 	%f138, 0f00000000;
	mov.f32 	%f137, %f138;
	@%p42 bra 	$L__BB82_33;
	shr.u32 	%r73, %r23, 1;
	add.s64 	%rd190, %rd5, %rd189;
	mul.wide.u32 	%rd191, %r5, 6144;
	add.s64 	%rd192, %rd190, %rd191;
	mul.wide.u32 	%rd193, %r73, 24;
	add.s64 	%rd194, %rd192, %rd193;
	mul.wide.u32 	%rd195, %r8, 4;
	add.s64 	%rd34, %rd194, %rd195;
	ld.global.nc.f32 	%f137, [%rd34];
$L__BB82_33:
	cvt.u64.u32 	%rd31, %r71;
	setp.gt.u32 	%p43, %r9, 3;
	and.b32  	%r75, %r7, 2;
	setp.eq.s32 	%p44, %r75, 0;
	and.pred  	%p45, %p43, %p44;
	shl.b64 	%rd313, %rd33, 2;
	@%p45 bra 	$L__BB82_39;
	bra.uni 	$L__BB82_34;
$L__BB82_39:
	cvt.u16.u32 	%rs21, %r17;
	add.s16 	%rs22, %rs21, -2;
	shr.s16 	%rs23, %rs22, 1;
	add.s64 	%rd197, %rd6, %rd189;
	mul.lo.s64 	%rd198, %rd323, 6144;
	add.s64 	%rd199, %rd197, %rd198;
	cvt.s32.s16 	%r76, %rs23;
	mul.wide.s32 	%rd200, %r76, 24;
	add.s64 	%rd201, %rd199, %rd200;
	add.s64 	%rd203, %rd201, %rd313;
	ld.global.nc.f32 	%f138, [%rd203];
$L__BB82_34:
	add.rn.f32 	%f94, %f137, %f138;
	mul.rn.f32 	%f95, %f40, %f94;
	add.s64 	%rd205, %rd2, %rd185;
	shl.b64 	%rd206, %rd31, 2;
	add.s64 	%rd207, %rd205, %rd206;
	ld.global.nc.f32 	%f96, [%rd207];
	mul.lo.s64 	%rd208, %rd322, 613200;
	add.s64 	%rd209, %rd4, %rd208;
	mul.lo.s64 	%rd210, %rd323, 12264;
	add.s64 	%rd211, %rd209, %rd210;
	mul.wide.u32 	%rd212, %r17, 24;
	add.s64 	%rd213, %rd211, %rd212;
	shl.b64 	%rd214, %rd31, 3;
	add.s64 	%rd215, %rd213, %rd214;
	ld.global.nc.f32 	%f97, [%rd215+-24];
	mul.rn.f32 	%f98, %f96, %f97;
	add.rn.f32 	%f99, %f95, %f98;
	mul.rn.f32 	%f100, %f39, %f99;
	shl.b32 	%r77, %r23, 1;
	shl.b32 	%r78, %r5, 10;
	cvt.u64.u32 	%rd216, %r77;
	cvt.u64.u32 	%rd217, %r78;
	add.s64 	%rd218, %rd217, %rd216;
	mul.lo.s64 	%rd219, %rd322, 1228800;
	add.s64 	%rd220, %rd8, %rd219;
	mul.lo.s64 	%rd221, %rd218, 24;
	add.s64 	%rd222, %rd220, %rd221;
	add.s64 	%rd224, %rd222, %rd313;
	ld.global.nc.f32 	%f101, [%rd224+48];
	add.rn.f32 	%f125, %f101, %f100;
$L__BB82_5:
	mul.lo.s32 	%r36, %r10, 6;
	add.s32 	%r80, %r9, -1;
	and.b32  	%r81, %r80, 1;
	setp.eq.b32 	%p46, %r81, 1;
	xor.pred  	%p48, %p46, %p86;
	not.pred 	%p49, %p48;
	mov.f32 	%f126, %f128;
	@%p49 bra 	$L__BB82_40;
	bra.uni 	$L__BB82_6;
$L__BB82_40:
	cvt.u16.u32 	%rs24, %r80;
	shr.u16 	%rs25, %rs24, 15;
	add.s16 	%rs26, %rs24, %rs25;
	shr.s16 	%rs27, %rs26, 1;
	cvt.u32.u16 	%r18, %rs27;
	and.b32  	%r82, %r18, 1;
	setp.eq.b32 	%p50, %r82, 1;
	xor.pred  	%p52, %p50, %p86;
	not.pred 	%p53, %p52;
	mov.f32 	%f140, 0f00000000;
	mov.f32 	%f139, %f140;
	@%p53 bra 	$L__BB82_43;
	bra.uni 	$L__BB82_41;
$L__BB82_43:
	shr.u32 	%r83, %r18, 1;
	mul.wide.u32 	%rd231, %r112, 307200;
	add.s64 	%rd232, %rd5, %rd231;
	mul.wide.u32 	%rd233, %r5, 6144;
	add.s64 	%rd234, %rd232, %rd233;
	mul.wide.u32 	%rd235, %r83, 24;
	add.s64 	%rd236, %rd234, %rd235;
	mul.wide.u32 	%rd237, %r8, 4;
	add.s64 	%rd38, %rd236, %rd237;
	ld.global.nc.f32 	%f139, [%rd38];
$L__BB82_41:
	add.s32 	%r86, %r18, -1;
	setp.gt.u32 	%p54, %r9, 2;
	and.b32  	%r87, %r86, 1;
	setp.eq.b32 	%p55, %r87, 1;
	not.pred 	%p56, %p55;
	and.pred  	%p57, %p54, %p56;
	@%p57 bra 	$L__BB82_44;
	bra.uni 	$L__BB82_42;
$L__BB82_44:
	cvt.u64.u32 	%rd37, %r8;
	shr.u32 	%r88, %r86, 1;
	mul.lo.s64 	%rd238, %rd322, 307200;
	add.s64 	%rd239, %rd6, %rd238;
	mul.lo.s64 	%rd240, %rd323, 6144;
	add.s64 	%rd241, %rd239, %rd240;
	mul.wide.u32 	%rd242, %r88, 24;
	add.s64 	%rd243, %rd241, %rd242;
	shl.b64 	%rd244, %rd37, 2;
	add.s64 	%rd39, %rd243, %rd244;
	ld.global.nc.f32 	%f140, [%rd39];
$L__BB82_42:
	add.rn.f32 	%f126, %f139, %f140;
$L__BB82_6:
	and.b32  	%r12, %r10, 1023;
	sub.s32 	%r11, %r35, %r36;
	add.rn.f32 	%f106, %f125, %f126;
	st.global.f32 	[%rd9+8], %f106;
	and.b32  	%r89, %r10, 1;
	setp.eq.b32 	%p58, %r89, 1;
	xor.pred  	%p60, %p58, %p86;
	not.pred 	%p61, %p60;
	mov.f32 	%f127, %f128;
	@%p61 bra 	$L__BB82_47;
	bra.uni 	$L__BB82_7;
$L__BB82_47:
	setp.gt.u32 	%p62, %r12, 1;
	@%p62 bra 	$L__BB82_49;
	shl.b32 	%r98, %r5, 10;
	mul.lo.s64 	%rd287, %rd322, 1228800;
	add.s64 	%rd288, %rd8, %rd287;
	mul.wide.u32 	%rd289, %r98, 24;
	add.s64 	%rd290, %rd288, %rd289;
	mul.wide.u32 	%rd291, %r11, 4;
	add.s64 	%rd292, %rd290, %rd291;
	ld.global.nc.f32 	%f127, [%rd292];
	bra.uni 	$L__BB82_7;
$L__BB82_49:
	shr.u32 	%r19, %r12, 1;
	add.s32 	%r24, %r19, -1;
	shl.b64 	%rd245, %rd322, 2;
	add.s64 	%rd246, %rd7, %rd245;
	ld.global.nc.f32 	%f52, [%rd246];
	shr.u32 	%r90, %r11, 1;
	mul.lo.s64 	%rd247, %rd322, 12;
	add.s64 	%rd248, %rd3, %rd247;
	mul.wide.u32 	%rd249, %r90, 4;
	add.s64 	%rd250, %rd248, %rd249;
	ld.global.nc.f32 	%f53, [%rd250];
	and.b32  	%r91, %r24, 1;
	setp.eq.b32 	%p63, %r91, 1;
	xor.pred  	%p65, %p63, %p86;
	cvt.u64.u32 	%rd43, %r11;
	mul.lo.s64 	%rd251, %rd322, 307200;
	mov.f32 	%f142, 0f00000000;
	mov.f32 	%f141, %f142;
	@%p65 bra 	$L__BB82_45;
	shr.u32 	%r92, %r24, 1;
	add.s64 	%rd252, %rd5, %rd251;
	mul.wide.u32 	%rd253, %r5, 6144;
	add.s64 	%rd254, %rd252, %rd253;
	mul.wide.u32 	%rd255, %r92, 24;
	add.s64 	%rd256, %rd254, %rd255;
	mul.wide.u32 	%rd257, %r11, 4;
	add.s64 	%rd44, %rd256, %rd257;
	ld.global.nc.f32 	%f141, [%rd44];
$L__BB82_45:
	cvt.u64.u32 	%rd41, %r90;
	setp.gt.u32 	%p66, %r12, 3;
	and.b32  	%r94, %r10, 2;
	setp.eq.s32 	%p67, %r94, 0;
	and.pred  	%p68, %p66, %p67;
	shl.b64 	%rd308, %rd43, 2;
	@%p68 bra 	$L__BB82_51;
	bra.uni 	$L__BB82_46;
$L__BB82_51:
	cvt.u16.u32 	%rs28, %r19;
	add.s16 	%rs29, %rs28, -2;
	shr.s16 	%rs30, %rs29, 1;
	add.s64 	%rd259, %rd6, %rd251;
	mul.lo.s64 	%rd260, %rd323, 6144;
	add.s64 	%rd261, %rd259, %rd260;
	cvt.s32.s16 	%r95, %rs30;
	mul.wide.s32 	%rd262, %r95, 24;
	add.s64 	%rd263, %rd261, %rd262;
	add.s64 	%rd265, %rd263, %rd308;
	ld.global.nc.f32 	%f142, [%rd265];
$L__BB82_46:
	add.rn.f32 	%f109, %f141, %f142;
	mul.rn.f32 	%f110, %f53, %f109;
	add.s64 	%rd267, %rd2, %rd247;
	shl.b64 	%rd268, %rd41, 2;
	add.s64 	%rd269, %rd267, %rd268;
	ld.global.nc.f32 	%f111, [%rd269];
	mul.lo.s64 	%rd270, %rd322, 613200;
	add.s64 	%rd271, %rd4, %rd270;
	mul.lo.s64 	%rd272, %rd323, 12264;
	add.s64 	%rd273, %rd271, %rd272;
	mul.wide.u32 	%rd274, %r19, 24;
	add.s64 	%rd275, %rd273, %rd274;
	shl.b64 	%rd276, %rd41, 3;
	add.s64 	%rd277, %rd275, %rd276;
	ld.global.nc.f32 	%f112, [%rd277+-20];
	mul.rn.f32 	%f113, %f111, %f112;
	add.rn.f32 	%f114, %f110, %f113;
	mul.rn.f32 	%f115, %f52, %f114;
	shl.b32 	%r96, %r24, 1;
	shl.b32 	%r97, %r5, 10;
	cvt.u64.u32 	%rd278, %r96;
	cvt.u64.u32 	%rd279, %r97;
	add.s64 	%rd280, %rd279, %rd278;
	mul.lo.s64 	%rd281, %rd322, 1228800;
	add.s64 	%rd282, %rd8, %rd281;
	mul.lo.s64 	%rd283, %rd280, 24;
	add.s64 	%rd284, %rd282, %rd283;
	add.s64 	%rd286, %rd284, %rd308;
	ld.global.nc.f32 	%f116, [%rd286+48];
	add.rn.f32 	%f127, %f116, %f115;
$L__BB82_7:
	add.s32 	%r99, %r12, -1;
	and.b32  	%r100, %r99, 1;
	setp.eq.b32 	%p69, %r100, 1;
	xor.pred  	%p71, %p69, %p86;
	not.pred 	%p72, %p71;
	@%p72 bra 	$L__BB82_52;
	bra.uni 	$L__BB82_8;
$L__BB82_52:
	cvt.u16.u32 	%rs31, %r99;
	shr.u16 	%rs32, %rs31, 15;
	add.s16 	%rs33, %rs31, %rs32;
	shr.s16 	%rs34, %rs33, 1;
	cvt.u32.u16 	%r20, %rs34;
	and.b32  	%r101, %r20, 1;
	setp.eq.b32 	%p73, %r101, 1;
	xor.pred  	%p75, %p73, %p86;
	not.pred 	%p76, %p75;
	mov.f32 	%f144, 0f00000000;
	mov.f32 	%f143, %f144;
	@%p76 bra 	$L__BB82_55;
	bra.uni 	$L__BB82_53;
$L__BB82_55:
	shr.u32 	%r102, %r20, 1;
	mul.wide.u32 	%rd293, %r112, 307200;
	add.s64 	%rd294, %rd5, %rd293;
	mul.wide.u32 	%rd295, %r5, 6144;
	add.s64 	%rd296, %rd294, %rd295;
	mul.wide.u32 	%rd297, %r102, 24;
	add.s64 	%rd298, %rd296, %rd297;
	mul.wide.u32 	%rd299, %r11, 4;
	add.s64 	%rd48, %rd298, %rd299;
	ld.global.nc.f32 	%f143, [%rd48];
$L__BB82_53:
	add.s32 	%r105, %r20, -1;
	setp.gt.u32 	%p77, %r12, 2;
	and.b32  	%r106, %r105, 1;
	setp.eq.b32 	%p78, %r106, 1;
	not.pred 	%p79, %p78;
	and.pred  	%p80, %p77, %p79;
	@%p80 bra 	$L__BB82_56;
	bra.uni 	$L__BB82_54;
$L__BB82_56:
	cvt.u64.u32 	%rd47, %r11;
	shr.u32 	%r107, %r105, 1;
	mul.lo.s64 	%rd300, %rd322, 307200;
	add.s64 	%rd301, %rd6, %rd300;
	mul.lo.s64 	%rd302, %rd323, 6144;
	add.s64 	%rd303, %rd301, %rd302;
	mul.wide.u32 	%rd304, %r107, 24;
	add.s64 	%rd305, %rd303, %rd304;
	shl.b64 	%rd306, %rd47, 2;
	add.s64 	%rd49, %rd305, %rd306;
	ld.global.nc.f32 	%f144, [%rd49];
$L__BB82_54:
	add.rn.f32 	%f128, %f143, %f144;
$L__BB82_8:
	add.rn.f32 	%f120, %f127, %f128;
	st.global.f32 	[%rd9+12], %f120;
	ret;

}
	// .globl	gemm_fusion_dot_527_1
.visible .entry gemm_fusion_dot_527_1(
	.param .u64 gemm_fusion_dot_527_1_param_0,
	.param .u64 gemm_fusion_dot_527_1_param_1,
	.param .u64 gemm_fusion_dot_527_1_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<69>;
	.reg .b32 	%r<358>;
	.reg .f32 	%f<197>;
	.reg .b64 	%rd<207>;

	ld.param.u64 	%rd34, [gemm_fusion_dot_527_1_param_0];
	ld.param.u64 	%rd35, [gemm_fusion_dot_527_1_param_2];
	cvta.to.global.u64 	%rd36, %rd35;
	ld.param.u64 	%rd37, [gemm_fusion_dot_527_1_param_1];
	cvta.to.global.u64 	%rd38, %rd37;
	cvta.to.global.u64 	%rd39, %rd34;
	// begin inline asm
	mov.u32 %r1, %ctaid.x;
	// end inline asm
	shr.s32 	%r249, %r1, 31;
	shr.u32 	%r250, %r249, 29;
	add.s32 	%r251, %r1, %r250;
	and.b32  	%r252, %r251, -8;
	mov.b32 	%r253, 200;
	sub.s32 	%r254, %r253, %r252;
	min.s32 	%r255, %r254, 8;
	rem.s32 	%r256, %r1, %r255;
	add.s32 	%r257, %r252, %r256;
	sub.s32 	%r258, %r1, %r252;
	div.s32 	%r259, %r258, %r255;
	shl.b32 	%r260, %r257, 8;
	// begin inline asm
	mov.u32 %r2, %ctaid.y;
	// end inline asm
	mul.lo.s32 	%r261, %r2, 307200;
	mul.wide.s32 	%rd40, %r261, 4;
	add.s64 	%rd41, %rd39, %rd40;
	cvt.s64.s32 	%rd42, %r260;
	shl.b32 	%r262, %r259, 4;
	mul.lo.s32 	%r263, %r2, 36;
	mul.wide.s32 	%rd43, %r263, 4;
	add.s64 	%rd44, %rd38, %rd43;
	cvt.s64.s32 	%rd45, %r262;
	mov.u32 	%r264, %tid.x;
	and.b32  	%r265, %r264, 31;
	shr.u32 	%r266, %r264, 5;
	shr.u32 	%r267, %r264, 3;
	or.b32  	%r268, %r267, 16;
	or.b32  	%r269, %r267, 32;
	or.b32  	%r270, %r267, 48;
	or.b32  	%r271, %r267, 64;
	or.b32  	%r272, %r267, 80;
	or.b32  	%r273, %r267, 96;
	or.b32  	%r274, %r267, 112;
	or.b32  	%r275, %r267, 128;
	or.b32  	%r276, %r267, 144;
	or.b32  	%r277, %r267, 160;
	or.b32  	%r278, %r267, 176;
	or.b32  	%r279, %r267, 192;
	or.b32  	%r280, %r267, 208;
	or.b32  	%r281, %r267, 224;
	or.b32  	%r282, %r267, 240;
	cvt.u64.u32 	%rd46, %r267;
	cvt.u64.u32 	%rd47, %r268;
	cvt.u64.u32 	%rd48, %r269;
	cvt.u64.u32 	%rd49, %r270;
	cvt.u64.u32 	%rd50, %r271;
	cvt.u64.u32 	%rd51, %r272;
	cvt.u64.u32 	%rd52, %r273;
	cvt.u64.u32 	%rd53, %r274;
	cvt.u64.u32 	%rd54, %r275;
	cvt.u64.u32 	%rd55, %r276;
	cvt.u64.u32 	%rd56, %r277;
	cvt.u64.u32 	%rd57, %r278;
	cvt.u64.u32 	%rd58, %r279;
	cvt.u64.u32 	%rd59, %r280;
	cvt.u64.u32 	%rd60, %r281;
	cvt.u64.u32 	%rd61, %r282;
	or.b64  	%rd62, %rd42, %rd46;
	or.b64  	%rd63, %rd42, %rd47;
	or.b64  	%rd64, %rd42, %rd48;
	or.b64  	%rd65, %rd42, %rd49;
	or.b64  	%rd66, %rd42, %rd50;
	or.b64  	%rd67, %rd42, %rd51;
	or.b64  	%rd68, %rd42, %rd52;
	or.b64  	%rd69, %rd42, %rd53;
	or.b64  	%rd70, %rd42, %rd54;
	or.b64  	%rd71, %rd42, %rd55;
	or.b64  	%rd72, %rd42, %rd56;
	or.b64  	%rd73, %rd42, %rd57;
	or.b64  	%rd74, %rd42, %rd58;
	or.b64  	%rd75, %rd42, %rd59;
	or.b64  	%rd76, %rd42, %rd60;
	or.b64  	%rd77, %rd42, %rd61;
	shl.b32 	%r283, %r264, 1;
	and.b32  	%r284, %r283, 14;
	cvt.u64.u32 	%rd78, %r284;
	mul.lo.s64 	%rd79, %rd62, 24;
	add.s64 	%rd80, %rd41, %rd79;
	mul.wide.u32 	%rd81, %r284, 4;
	add.s64 	%rd1, %rd80, %rd81;
	mul.lo.s64 	%rd82, %rd63, 24;
	add.s64 	%rd83, %rd41, %rd82;
	add.s64 	%rd2, %rd83, %rd81;
	mul.lo.s64 	%rd84, %rd64, 24;
	add.s64 	%rd85, %rd41, %rd84;
	add.s64 	%rd3, %rd85, %rd81;
	mul.lo.s64 	%rd86, %rd65, 24;
	add.s64 	%rd87, %rd41, %rd86;
	add.s64 	%rd4, %rd87, %rd81;
	mul.lo.s64 	%rd88, %rd66, 24;
	add.s64 	%rd89, %rd41, %rd88;
	add.s64 	%rd5, %rd89, %rd81;
	mul.lo.s64 	%rd90, %rd67, 24;
	add.s64 	%rd91, %rd41, %rd90;
	add.s64 	%rd6, %rd91, %rd81;
	mul.lo.s64 	%rd92, %rd68, 24;
	add.s64 	%rd93, %rd41, %rd92;
	add.s64 	%rd7, %rd93, %rd81;
	mul.lo.s64 	%rd94, %rd69, 24;
	add.s64 	%rd95, %rd41, %rd94;
	add.s64 	%rd8, %rd95, %rd81;
	mul.lo.s64 	%rd96, %rd70, 24;
	add.s64 	%rd97, %rd41, %rd96;
	add.s64 	%rd9, %rd97, %rd81;
	mul.lo.s64 	%rd98, %rd71, 24;
	add.s64 	%rd99, %rd41, %rd98;
	add.s64 	%rd10, %rd99, %rd81;
	mul.lo.s64 	%rd100, %rd72, 24;
	add.s64 	%rd101, %rd41, %rd100;
	add.s64 	%rd11, %rd101, %rd81;
	mul.lo.s64 	%rd102, %rd73, 24;
	add.s64 	%rd103, %rd41, %rd102;
	add.s64 	%rd12, %rd103, %rd81;
	mul.lo.s64 	%rd104, %rd74, 24;
	add.s64 	%rd105, %rd41, %rd104;
	add.s64 	%rd13, %rd105, %rd81;
	mul.lo.s64 	%rd106, %rd75, 24;
	add.s64 	%rd107, %rd41, %rd106;
	add.s64 	%rd14, %rd107, %rd81;
	mul.lo.s64 	%rd108, %rd76, 24;
	add.s64 	%rd109, %rd41, %rd108;
	add.s64 	%rd15, %rd109, %rd81;
	mul.lo.s64 	%rd110, %rd77, 24;
	add.s64 	%rd111, %rd41, %rd110;
	add.s64 	%rd16, %rd111, %rd81;
	setp.lt.u32 	%p1, %r284, 6;
	mov.b32 	%r5, 0;
	// begin inline asm
	mov.u32 %r3, 0x0;
	mov.u32 %r4, 0x0;
	@%p1 ld.global.v2.b32 { %r3, %r4 }, [ %rd1 + 0 ];
	@!%p1 mov.u32 %r3, %r5;
	@!%p1 mov.u32 %r4, %r5;
	// end inline asm
	mov.b32 	%f129, %r3;
	mov.b32 	%f130, %r4;
	// begin inline asm
	mov.u32 %r7, 0x0;
	mov.u32 %r8, 0x0;
	@%p1 ld.global.v2.b32 { %r7, %r8 }, [ %rd2 + 0 ];
	@!%p1 mov.u32 %r7, %r5;
	@!%p1 mov.u32 %r8, %r5;
	// end inline asm
	mov.b32 	%f131, %r7;
	mov.b32 	%f132, %r8;
	// begin inline asm
	mov.u32 %r11, 0x0;
	mov.u32 %r12, 0x0;
	@%p1 ld.global.v2.b32 { %r11, %r12 }, [ %rd3 + 0 ];
	@!%p1 mov.u32 %r11, %r5;
	@!%p1 mov.u32 %r12, %r5;
	// end inline asm
	mov.b32 	%f133, %r11;
	mov.b32 	%f134, %r12;
	// begin inline asm
	mov.u32 %r15, 0x0;
	mov.u32 %r16, 0x0;
	@%p1 ld.global.v2.b32 { %r15, %r16 }, [ %rd4 + 0 ];
	@!%p1 mov.u32 %r15, %r5;
	@!%p1 mov.u32 %r16, %r5;
	// end inline asm
	mov.b32 	%f135, %r15;
	mov.b32 	%f136, %r16;
	// begin inline asm
	mov.u32 %r19, 0x0;
	mov.u32 %r20, 0x0;
	@%p1 ld.global.v2.b32 { %r19, %r20 }, [ %rd5 + 0 ];
	@!%p1 mov.u32 %r19, %r5;
	@!%p1 mov.u32 %r20, %r5;
	// end inline asm
	mov.b32 	%f137, %r19;
	mov.b32 	%f138, %r20;
	// begin inline asm
	mov.u32 %r23, 0x0;
	mov.u32 %r24, 0x0;
	@%p1 ld.global.v2.b32 { %r23, %r24 }, [ %rd6 + 0 ];
	@!%p1 mov.u32 %r23, %r5;
	@!%p1 mov.u32 %r24, %r5;
	// end inline asm
	mov.b32 	%f139, %r23;
	mov.b32 	%f140, %r24;
	// begin inline asm
	mov.u32 %r27, 0x0;
	mov.u32 %r28, 0x0;
	@%p1 ld.global.v2.b32 { %r27, %r28 }, [ %rd7 + 0 ];
	@!%p1 mov.u32 %r27, %r5;
	@!%p1 mov.u32 %r28, %r5;
	// end inline asm
	mov.b32 	%f141, %r27;
	mov.b32 	%f142, %r28;
	// begin inline asm
	mov.u32 %r31, 0x0;
	mov.u32 %r32, 0x0;
	@%p1 ld.global.v2.b32 { %r31, %r32 }, [ %rd8 + 0 ];
	@!%p1 mov.u32 %r31, %r5;
	@!%p1 mov.u32 %r32, %r5;
	// end inline asm
	mov.b32 	%f143, %r31;
	mov.b32 	%f144, %r32;
	// begin inline asm
	mov.u32 %r35, 0x0;
	mov.u32 %r36, 0x0;
	@%p1 ld.global.v2.b32 { %r35, %r36 }, [ %rd9 + 0 ];
	@!%p1 mov.u32 %r35, %r5;
	@!%p1 mov.u32 %r36, %r5;
	// end inline asm
	mov.b32 	%f145, %r35;
	mov.b32 	%f146, %r36;
	// begin inline asm
	mov.u32 %r39, 0x0;
	mov.u32 %r40, 0x0;
	@%p1 ld.global.v2.b32 { %r39, %r40 }, [ %rd10 + 0 ];
	@!%p1 mov.u32 %r39, %r5;
	@!%p1 mov.u32 %r40, %r5;
	// end inline asm
	mov.b32 	%f147, %r39;
	mov.b32 	%f148, %r40;
	// begin inline asm
	mov.u32 %r43, 0x0;
	mov.u32 %r44, 0x0;
	@%p1 ld.global.v2.b32 { %r43, %r44 }, [ %rd11 + 0 ];
	@!%p1 mov.u32 %r43, %r5;
	@!%p1 mov.u32 %r44, %r5;
	// end inline asm
	mov.b32 	%f149, %r43;
	mov.b32 	%f150, %r44;
	// begin inline asm
	mov.u32 %r47, 0x0;
	mov.u32 %r48, 0x0;
	@%p1 ld.global.v2.b32 { %r47, %r48 }, [ %rd12 + 0 ];
	@!%p1 mov.u32 %r47, %r5;
	@!%p1 mov.u32 %r48, %r5;
	// end inline asm
	mov.b32 	%f151, %r47;
	mov.b32 	%f152, %r48;
	// begin inline asm
	mov.u32 %r51, 0x0;
	mov.u32 %r52, 0x0;
	@%p1 ld.global.v2.b32 { %r51, %r52 }, [ %rd13 + 0 ];
	@!%p1 mov.u32 %r51, %r5;
	@!%p1 mov.u32 %r52, %r5;
	// end inline asm
	mov.b32 	%f153, %r51;
	mov.b32 	%f154, %r52;
	// begin inline asm
	mov.u32 %r55, 0x0;
	mov.u32 %r56, 0x0;
	@%p1 ld.global.v2.b32 { %r55, %r56 }, [ %rd14 + 0 ];
	@!%p1 mov.u32 %r55, %r5;
	@!%p1 mov.u32 %r56, %r5;
	// end inline asm
	mov.b32 	%f155, %r55;
	mov.b32 	%f156, %r56;
	// begin inline asm
	mov.u32 %r59, 0x0;
	mov.u32 %r60, 0x0;
	@%p1 ld.global.v2.b32 { %r59, %r60 }, [ %rd15 + 0 ];
	@!%p1 mov.u32 %r59, %r5;
	@!%p1 mov.u32 %r60, %r5;
	// end inline asm
	mov.b32 	%f157, %r59;
	mov.b32 	%f158, %r60;
	// begin inline asm
	mov.u32 %r63, 0x0;
	mov.u32 %r64, 0x0;
	@%p1 ld.global.v2.b32 { %r63, %r64 }, [ %rd16 + 0 ];
	@!%p1 mov.u32 %r63, %r5;
	@!%p1 mov.u32 %r64, %r5;
	// end inline asm
	mov.b32 	%f159, %r63;
	mov.b32 	%f160, %r64;
	or.b64  	%rd112, %rd45, %rd46;
	or.b64  	%rd113, %rd45, %rd78;
	mul.lo.s64 	%rd114, %rd112, 24;
	add.s64 	%rd115, %rd44, %rd114;
	add.s64 	%rd17, %rd115, %rd81;
	setp.lt.u64 	%p68, %rd112, 6;
	setp.lt.u64 	%p52, %rd113, 6;
	and.pred  	%p49, %p1, %p68;
	// begin inline asm
	mov.u32 %r67, 0x0;
	mov.u32 %r68, 0x0;
	@%p49 ld.global.v2.b32 { %r67, %r68 }, [ %rd17 + 0 ];
	@!%p49 mov.u32 %r67, %r5;
	@!%p49 mov.u32 %r68, %r5;
	// end inline asm
	mov.b32 	%f161, %r67;
	mov.b32 	%f162, %r68;
	selp.f32 	%f163, %f129, 0f00000000, %p1;
	selp.f32 	%f164, %f130, 0f00000000, %p1;
	selp.f32 	%f165, %f131, 0f00000000, %p1;
	selp.f32 	%f166, %f132, 0f00000000, %p1;
	selp.f32 	%f167, %f133, 0f00000000, %p1;
	selp.f32 	%f168, %f134, 0f00000000, %p1;
	selp.f32 	%f169, %f135, 0f00000000, %p1;
	selp.f32 	%f170, %f136, 0f00000000, %p1;
	selp.f32 	%f171, %f137, 0f00000000, %p1;
	selp.f32 	%f172, %f138, 0f00000000, %p1;
	selp.f32 	%f173, %f139, 0f00000000, %p1;
	selp.f32 	%f174, %f140, 0f00000000, %p1;
	selp.f32 	%f175, %f141, 0f00000000, %p1;
	selp.f32 	%f176, %f142, 0f00000000, %p1;
	selp.f32 	%f177, %f143, 0f00000000, %p1;
	selp.f32 	%f178, %f144, 0f00000000, %p1;
	selp.f32 	%f179, %f145, 0f00000000, %p1;
	selp.f32 	%f180, %f146, 0f00000000, %p1;
	selp.f32 	%f181, %f147, 0f00000000, %p1;
	selp.f32 	%f182, %f148, 0f00000000, %p1;
	selp.f32 	%f183, %f149, 0f00000000, %p1;
	selp.f32 	%f184, %f150, 0f00000000, %p1;
	selp.f32 	%f185, %f151, 0f00000000, %p1;
	selp.f32 	%f186, %f152, 0f00000000, %p1;
	selp.f32 	%f187, %f153, 0f00000000, %p1;
	selp.f32 	%f188, %f154, 0f00000000, %p1;
	selp.f32 	%f189, %f155, 0f00000000, %p1;
	selp.f32 	%f190, %f156, 0f00000000, %p1;
	selp.f32 	%f191, %f157, 0f00000000, %p1;
	selp.f32 	%f192, %f158, 0f00000000, %p1;
	selp.f32 	%f193, %f159, 0f00000000, %p1;
	selp.f32 	%f194, %f160, 0f00000000, %p1;
	shr.u32 	%r285, %r264, 2;
	and.b32  	%r286, %r285, 12;
	xor.b32  	%r287, %r286, %r284;
	shl.b32 	%r288, %r267, 4;
	or.b32  	%r289, %r287, %r288;
	mul.wide.u32 	%rd116, %r289, 4;
	mov.u64 	%rd117, global_smem;
	add.s64 	%rd118, %rd117, %rd116;
	st.shared.v2.f32 	[%rd118], {%f163, %f164};
	shl.b32 	%r290, %r268, 4;
	or.b32  	%r291, %r290, %r287;
	mul.wide.u32 	%rd119, %r291, 4;
	add.s64 	%rd120, %rd117, %rd119;
	st.shared.v2.f32 	[%rd120], {%f165, %f166};
	shl.b32 	%r292, %r269, 4;
	or.b32  	%r293, %r292, %r287;
	mul.wide.u32 	%rd121, %r293, 4;
	add.s64 	%rd122, %rd117, %rd121;
	st.shared.v2.f32 	[%rd122], {%f167, %f168};
	shl.b32 	%r294, %r270, 4;
	or.b32  	%r295, %r294, %r287;
	mul.wide.u32 	%rd123, %r295, 4;
	add.s64 	%rd124, %rd117, %rd123;
	st.shared.v2.f32 	[%rd124], {%f169, %f170};
	shl.b32 	%r296, %r271, 4;
	or.b32  	%r297, %r296, %r287;
	mul.wide.u32 	%rd125, %r297, 4;
	add.s64 	%rd126, %rd117, %rd125;
	st.shared.v2.f32 	[%rd126], {%f171, %f172};
	shl.b32 	%r298, %r272, 4;
	or.b32  	%r299, %r298, %r287;
	mul.wide.u32 	%rd127, %r299, 4;
	add.s64 	%rd128, %rd117, %rd127;
	st.shared.v2.f32 	[%rd128], {%f173, %f174};
	shl.b32 	%r300, %r273, 4;
	or.b32  	%r301, %r300, %r287;
	mul.wide.u32 	%rd129, %r301, 4;
	add.s64 	%rd130, %rd117, %rd129;
	st.shared.v2.f32 	[%rd130], {%f175, %f176};
	shl.b32 	%r302, %r274, 4;
	or.b32  	%r303, %r302, %r287;
	mul.wide.u32 	%rd131, %r303, 4;
	add.s64 	%rd132, %rd117, %rd131;
	st.shared.v2.f32 	[%rd132], {%f177, %f178};
	shl.b32 	%r304, %r275, 4;
	or.b32  	%r305, %r304, %r287;
	mul.wide.u32 	%rd133, %r305, 4;
	add.s64 	%rd134, %rd117, %rd133;
	st.shared.v2.f32 	[%rd134], {%f179, %f180};
	shl.b32 	%r306, %r276, 4;
	or.b32  	%r307, %r306, %r287;
	mul.wide.u32 	%rd135, %r307, 4;
	add.s64 	%rd136, %rd117, %rd135;
	st.shared.v2.f32 	[%rd136], {%f181, %f182};
	shl.b32 	%r308, %r277, 4;
	or.b32  	%r309, %r308, %r287;
	mul.wide.u32 	%rd137, %r309, 4;
	add.s64 	%rd138, %rd117, %rd137;
	st.shared.v2.f32 	[%rd138], {%f183, %f184};
	shl.b32 	%r310, %r278, 4;
	or.b32  	%r311, %r310, %r287;
	mul.wide.u32 	%rd139, %r311, 4;
	add.s64 	%rd140, %rd117, %rd139;
	st.shared.v2.f32 	[%rd140], {%f185, %f186};
	shl.b32 	%r312, %r279, 4;
	or.b32  	%r313, %r312, %r287;
	mul.wide.u32 	%rd141, %r313, 4;
	add.s64 	%rd142, %rd117, %rd141;
	st.shared.v2.f32 	[%rd142], {%f187, %f188};
	shl.b32 	%r314, %r280, 4;
	or.b32  	%r315, %r314, %r287;
	mul.wide.u32 	%rd143, %r315, 4;
	add.s64 	%rd144, %rd117, %rd143;
	st.shared.v2.f32 	[%rd144], {%f189, %f190};
	shl.b32 	%r316, %r281, 4;
	or.b32  	%r317, %r316, %r287;
	mul.wide.u32 	%rd145, %r317, 4;
	add.s64 	%rd146, %rd117, %rd145;
	st.shared.v2.f32 	[%rd146], {%f191, %f192};
	shl.b32 	%r318, %r282, 4;
	or.b32  	%r319, %r318, %r287;
	mul.wide.u32 	%rd147, %r319, 4;
	add.s64 	%rd148, %rd117, %rd147;
	st.shared.v2.f32 	[%rd148], {%f193, %f194};
	selp.f32 	%f195, %f161, 0f00000000, %p1;
	selp.f32 	%f196, %f162, 0f00000000, %p1;
	add.s64 	%rd149, %rd117, 16384;
	add.s64 	%rd150, %rd149, %rd116;
	st.shared.v2.f32 	[%rd150], {%f195, %f196};
	bar.sync 	0;
	and.b32  	%r320, %r264, 7;
	bfe.u32 	%r321, %r264, 3, 2;
	bfe.u32 	%r322, %r265, 3, 1;
	bfe.u32 	%r323, %r264, 4, 1;
	bfe.u32 	%r324, %r264, 1, 2;
	shl.b32 	%r325, %r266, 4;
	shl.b32 	%r326, %r322, 3;
	or.b32  	%r327, %r326, %r325;
	or.b32  	%r328, %r327, %r320;
	xor.b32  	%r329, %r323, %r324;
	shl.b32 	%r330, %r329, 4;
	shl.b32 	%r331, %r328, 6;
	or.b32  	%r332, %r331, %r330;
	cvt.u64.u32 	%rd151, %r332;
	add.s64 	%rd152, %rd117, %rd151;
	cvt.u32.u64 	%r75, %rd152;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r121, %r122, %r123, %r124 }, [ %r75 + 0 ];
	// end inline asm
	or.b32  	%r333, %r323, 2;
	xor.b32  	%r334, %r333, %r324;
	shl.b32 	%r335, %r334, 4;
	or.b32  	%r336, %r335, %r331;
	cvt.u64.u32 	%rd153, %r336;
	add.s64 	%rd154, %rd117, %rd153;
	cvt.u32.u64 	%r80, %rd154;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r169, %r170, %r171, %r172 }, [ %r80 + 0 ];
	// end inline asm
	add.s32 	%r85, %r75, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r133, %r134, %r135, %r136 }, [ %r85 + 0 ];
	// end inline asm
	add.s32 	%r90, %r80, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r181, %r182, %r183, %r184 }, [ %r90 + 0 ];
	// end inline asm
	add.s32 	%r95, %r75, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r145, %r146, %r147, %r148 }, [ %r95 + 0 ];
	// end inline asm
	add.s32 	%r100, %r80, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r193, %r194, %r195, %r196 }, [ %r100 + 0 ];
	// end inline asm
	add.s32 	%r105, %r75, 12288;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r157, %r158, %r159, %r160 }, [ %r105 + 0 ];
	// end inline asm
	add.s32 	%r110, %r80, 12288;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r205, %r206, %r207, %r208 }, [ %r110 + 0 ];
	// end inline asm
	xor.b32  	%r337, %r322, %r324;
	shl.b32 	%r338, %r337, 4;
	shl.b32 	%r339, %r320, 6;
	shl.b32 	%r340, %r323, 9;
	or.b32  	%r341, %r340, %r339;
	or.b32  	%r342, %r338, %r341;
	cvt.u64.u32 	%rd155, %r342;
	add.s64 	%rd156, %rd149, %rd155;
	cvt.u32.u64 	%r115, %rd156;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r125, %r126, %r131, %r132 }, [ %r115 + 0 ];
	// end inline asm
	or.b32  	%r343, %r321, 2;
	xor.b32  	%r344, %r343, %r324;
	shl.b32 	%r345, %r344, 4;
	or.b32  	%r346, %r345, %r341;
	cvt.u64.u32 	%rd157, %r346;
	add.s64 	%rd158, %rd149, %rd157;
	cvt.u32.u64 	%r120, %rd158;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r173, %r174, %r179, %r180 }, [ %r120 + 0 ];
	// end inline asm
	mov.f32 	%f121, 0f00000000;
	mov.f32 	%f65, %f121;
	mov.f32 	%f66, %f121;
	mov.f32 	%f67, %f121;
	mov.f32 	%f68, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f65, %f66, %f67, %f68 }, { %r121, %r122, %r123, %r124 }, { %r125, %r126 }, { %f65, %f66, %f67, %f68 };
	// end inline asm
	mov.f32 	%f73, %f121;
	mov.f32 	%f74, %f121;
	mov.f32 	%f75, %f121;
	mov.f32 	%f76, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f73, %f74, %f75, %f76 }, { %r121, %r122, %r123, %r124 }, { %r131, %r132 }, { %f73, %f74, %f75, %f76 };
	// end inline asm
	mov.f32 	%f81, %f121;
	mov.f32 	%f82, %f121;
	mov.f32 	%f83, %f121;
	mov.f32 	%f84, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f81, %f82, %f83, %f84 }, { %r133, %r134, %r135, %r136 }, { %r125, %r126 }, { %f81, %f82, %f83, %f84 };
	// end inline asm
	mov.f32 	%f89, %f121;
	mov.f32 	%f90, %f121;
	mov.f32 	%f91, %f121;
	mov.f32 	%f92, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f89, %f90, %f91, %f92 }, { %r133, %r134, %r135, %r136 }, { %r131, %r132 }, { %f89, %f90, %f91, %f92 };
	// end inline asm
	mov.f32 	%f97, %f121;
	mov.f32 	%f98, %f121;
	mov.f32 	%f99, %f121;
	mov.f32 	%f100, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f97, %f98, %f99, %f100 }, { %r145, %r146, %r147, %r148 }, { %r125, %r126 }, { %f97, %f98, %f99, %f100 };
	// end inline asm
	mov.f32 	%f105, %f121;
	mov.f32 	%f106, %f121;
	mov.f32 	%f107, %f121;
	mov.f32 	%f108, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f105, %f106, %f107, %f108 }, { %r145, %r146, %r147, %r148 }, { %r131, %r132 }, { %f105, %f106, %f107, %f108 };
	// end inline asm
	mov.f32 	%f113, %f121;
	mov.f32 	%f114, %f121;
	mov.f32 	%f115, %f121;
	mov.f32 	%f116, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f113, %f114, %f115, %f116 }, { %r157, %r158, %r159, %r160 }, { %r125, %r126 }, { %f113, %f114, %f115, %f116 };
	// end inline asm
	mov.f32 	%f122, %f121;
	mov.f32 	%f123, %f121;
	mov.f32 	%f124, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f121, %f122, %f123, %f124 }, { %r157, %r158, %r159, %r160 }, { %r131, %r132 }, { %f121, %f122, %f123, %f124 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f65, %f66, %f67, %f68 }, { %r169, %r170, %r171, %r172 }, { %r173, %r174 }, { %f65, %f66, %f67, %f68 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f73, %f74, %f75, %f76 }, { %r169, %r170, %r171, %r172 }, { %r179, %r180 }, { %f73, %f74, %f75, %f76 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f81, %f82, %f83, %f84 }, { %r181, %r182, %r183, %r184 }, { %r173, %r174 }, { %f81, %f82, %f83, %f84 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f89, %f90, %f91, %f92 }, { %r181, %r182, %r183, %r184 }, { %r179, %r180 }, { %f89, %f90, %f91, %f92 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f97, %f98, %f99, %f100 }, { %r193, %r194, %r195, %r196 }, { %r173, %r174 }, { %f97, %f98, %f99, %f100 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f105, %f106, %f107, %f108 }, { %r193, %r194, %r195, %r196 }, { %r179, %r180 }, { %f105, %f106, %f107, %f108 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f113, %f114, %f115, %f116 }, { %r205, %r206, %r207, %r208 }, { %r173, %r174 }, { %f113, %f114, %f115, %f116 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f121, %f122, %f123, %f124 }, { %r205, %r206, %r207, %r208 }, { %r179, %r180 }, { %f121, %f122, %f123, %f124 };
	// end inline asm
	mul.lo.s32 	%r347, %r2, 6;
	mul.wide.s32 	%rd159, %r347, 4;
	add.s64 	%rd160, %rd36, %rd159;
	mul.lo.s64 	%rd161, %rd62, 1536;
	add.s64 	%rd162, %rd160, %rd161;
	shl.b64 	%rd163, %rd113, 2;
	add.s64 	%rd18, %rd162, %rd163;
	mul.lo.s64 	%rd164, %rd63, 1536;
	add.s64 	%rd165, %rd160, %rd164;
	add.s64 	%rd19, %rd165, %rd163;
	mul.lo.s64 	%rd166, %rd64, 1536;
	add.s64 	%rd167, %rd160, %rd166;
	add.s64 	%rd20, %rd167, %rd163;
	mul.lo.s64 	%rd168, %rd65, 1536;
	add.s64 	%rd169, %rd160, %rd168;
	add.s64 	%rd21, %rd169, %rd163;
	mul.lo.s64 	%rd170, %rd66, 1536;
	add.s64 	%rd171, %rd160, %rd170;
	add.s64 	%rd22, %rd171, %rd163;
	mul.lo.s64 	%rd172, %rd67, 1536;
	add.s64 	%rd173, %rd160, %rd172;
	add.s64 	%rd23, %rd173, %rd163;
	mul.lo.s64 	%rd174, %rd68, 1536;
	add.s64 	%rd175, %rd160, %rd174;
	add.s64 	%rd24, %rd175, %rd163;
	mul.lo.s64 	%rd176, %rd69, 1536;
	add.s64 	%rd177, %rd160, %rd176;
	add.s64 	%rd25, %rd177, %rd163;
	mul.lo.s64 	%rd178, %rd70, 1536;
	add.s64 	%rd179, %rd160, %rd178;
	add.s64 	%rd26, %rd179, %rd163;
	mul.lo.s64 	%rd180, %rd71, 1536;
	add.s64 	%rd181, %rd160, %rd180;
	add.s64 	%rd27, %rd181, %rd163;
	mul.lo.s64 	%rd182, %rd72, 1536;
	add.s64 	%rd183, %rd160, %rd182;
	add.s64 	%rd28, %rd183, %rd163;
	mul.lo.s64 	%rd184, %rd73, 1536;
	add.s64 	%rd185, %rd160, %rd184;
	add.s64 	%rd29, %rd185, %rd163;
	mul.lo.s64 	%rd186, %rd74, 1536;
	add.s64 	%rd187, %rd160, %rd186;
	add.s64 	%rd30, %rd187, %rd163;
	mul.lo.s64 	%rd188, %rd75, 1536;
	add.s64 	%rd189, %rd160, %rd188;
	add.s64 	%rd31, %rd189, %rd163;
	mul.lo.s64 	%rd190, %rd76, 1536;
	add.s64 	%rd191, %rd160, %rd190;
	add.s64 	%rd32, %rd191, %rd163;
	mul.lo.s64 	%rd192, %rd77, 1536;
	add.s64 	%rd193, %rd160, %rd192;
	add.s64 	%rd33, %rd193, %rd163;
	bar.sync 	0;
	bfe.u32 	%r348, %r264, 2, 3;
	and.b32  	%r349, %r283, 6;
	or.b32  	%r350, %r325, %r348;
	mul.lo.s32 	%r351, %r350, 18;
	add.s32 	%r352, %r351, %r349;
	mul.wide.u32 	%rd194, %r352, 4;
	add.s64 	%rd195, %rd117, %rd194;
	st.shared.v2.f32 	[%rd195], {%f65, %f66};
	cvt.u64.u32 	%rd196, %r349;
	cvt.u64.u32 	%rd197, %r351;
	add.s64 	%rd198, %rd197, %rd196;
	shl.b64 	%rd199, %rd198, 2;
	add.s64 	%rd200, %rd117, %rd199;
	st.shared.v2.f32 	[%rd200+576], {%f67, %f68};
	or.b32  	%r353, %r349, 8;
	st.shared.v2.f32 	[%rd200+32], {%f73, %f74};
	cvt.u64.u32 	%rd201, %r353;
	add.s64 	%rd202, %rd197, %rd201;
	shl.b64 	%rd203, %rd202, 2;
	add.s64 	%rd204, %rd117, %rd203;
	st.shared.v2.f32 	[%rd204+576], {%f75, %f76};
	bar.sync 	0;
	shl.b32 	%r354, %r266, 2;
	or.b32  	%r355, %r354, %r321;
	shl.b32 	%r356, %r320, 1;
	mad.lo.s32 	%r357, %r355, 18, %r356;
	mul.wide.u32 	%rd205, %r357, 4;
	add.s64 	%rd206, %rd117, %rd205;
	ld.shared.v2.u32 	{%r217, %r218}, [%rd206];
	ld.shared.v2.u32 	{%r219, %r220}, [%rd206+1152];
	ld.shared.v2.u32 	{%r221, %r222}, [%rd206+2304];
	ld.shared.v2.u32 	{%r223, %r224}, [%rd206+3456];
	bar.sync 	0;
	st.shared.v2.f32 	[%rd195], {%f81, %f82};
	st.shared.v2.f32 	[%rd200+576], {%f83, %f84};
	st.shared.v2.f32 	[%rd200+32], {%f89, %f90};
	st.shared.v2.f32 	[%rd204+576], {%f91, %f92};
	bar.sync 	0;
	ld.shared.v2.u32 	{%r225, %r226}, [%rd206];
	ld.shared.v2.u32 	{%r227, %r228}, [%rd206+1152];
	ld.shared.v2.u32 	{%r229, %r230}, [%rd206+2304];
	ld.shared.v2.u32 	{%r231, %r232}, [%rd206+3456];
	bar.sync 	0;
	st.shared.v2.f32 	[%rd195], {%f97, %f98};
	st.shared.v2.f32 	[%rd200+576], {%f99, %f100};
	st.shared.v2.f32 	[%rd200+32], {%f105, %f106};
	st.shared.v2.f32 	[%rd204+576], {%f107, %f108};
	bar.sync 	0;
	ld.shared.v2.u32 	{%r233, %r234}, [%rd206];
	ld.shared.v2.u32 	{%r235, %r236}, [%rd206+1152];
	ld.shared.v2.u32 	{%r237, %r238}, [%rd206+2304];
	ld.shared.v2.u32 	{%r239, %r240}, [%rd206+3456];
	bar.sync 	0;
	st.shared.v2.f32 	[%rd195], {%f113, %f114};
	st.shared.v2.f32 	[%rd200+576], {%f115, %f116};
	st.shared.v2.f32 	[%rd200+32], {%f121, %f122};
	st.shared.v2.f32 	[%rd204+576], {%f123, %f124};
	bar.sync 	0;
	ld.shared.v2.u32 	{%r241, %r242}, [%rd206];
	ld.shared.v2.u32 	{%r243, %r244}, [%rd206+1152];
	ld.shared.v2.u32 	{%r245, %r246}, [%rd206+2304];
	ld.shared.v2.u32 	{%r247, %r248}, [%rd206+3456];
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd18 + 0 ], { %r217, %r218 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd19 + 0 ], { %r219, %r220 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd20 + 0 ], { %r221, %r222 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd21 + 0 ], { %r223, %r224 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd22 + 0 ], { %r225, %r226 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd23 + 0 ], { %r227, %r228 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd24 + 0 ], { %r229, %r230 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd25 + 0 ], { %r231, %r232 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd26 + 0 ], { %r233, %r234 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd27 + 0 ], { %r235, %r236 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd28 + 0 ], { %r237, %r238 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd29 + 0 ], { %r239, %r240 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd30 + 0 ], { %r241, %r242 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd31 + 0 ], { %r243, %r244 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd32 + 0 ], { %r245, %r246 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd33 + 0 ], { %r247, %r248 };
	// end inline asm
	ret;

}
	// .globl	loop_slice_fusion_58
.visible .entry loop_slice_fusion_58(
	.param .u64 loop_slice_fusion_58_param_0,
	.param .u64 loop_slice_fusion_58_param_1
)
.reqntid 50, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<163>;
	.reg .b64 	%rd<7>;

	ld.param.u64 	%rd3, [loop_slice_fusion_58_param_0];
	ld.param.u64 	%rd4, [loop_slice_fusion_58_param_1];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd3;
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r2, %r1, 1;
	setp.gt.u32 	%p1, %r1, 24;
	ld.global.nc.u32 	%r3, [%rd2+4];
	@%p1 bra 	$L__BB84_2;
	ld.global.nc.u32 	%r86, [%rd2];
	add.s32 	%r87, %r86, %r2;
	add.s32 	%r88, %r2, %r3;
	add.s32 	%r89, %r88, 50;
	add.s32 	%r90, %r87, %r89;
	shf.l.wrap.b32 	%r91, %r89, %r89, 13;
	xor.b32  	%r92, %r90, %r91;
	add.s32 	%r93, %r92, %r90;
	shf.l.wrap.b32 	%r94, %r92, %r92, 15;
	xor.b32  	%r95, %r93, %r94;
	add.s32 	%r96, %r95, %r93;
	shf.l.wrap.b32 	%r97, %r95, %r95, 26;
	xor.b32  	%r98, %r96, %r97;
	add.s32 	%r99, %r98, %r96;
	add.s32 	%r100, %r99, %r3;
	shf.l.wrap.b32 	%r101, %r98, %r98, 6;
	xor.b32  	%r102, %r99, %r101;
	xor.b32  	%r103, %r86, %r3;
	xor.b32  	%r104, %r103, 466688986;
	add.s32 	%r105, %r104, %r102;
	add.s32 	%r106, %r105, 1;
	add.s32 	%r107, %r100, %r106;
	shf.l.wrap.b32 	%r108, %r106, %r106, 17;
	xor.b32  	%r109, %r107, %r108;
	add.s32 	%r110, %r109, %r107;
	shf.l.wrap.b32 	%r111, %r109, %r109, 29;
	xor.b32  	%r112, %r110, %r111;
	add.s32 	%r113, %r112, %r110;
	shf.l.wrap.b32 	%r114, %r112, %r112, 16;
	xor.b32  	%r115, %r113, %r114;
	add.s32 	%r116, %r115, %r113;
	add.s32 	%r117, %r116, %r104;
	shf.l.wrap.b32 	%r118, %r115, %r115, 24;
	xor.b32  	%r119, %r116, %r118;
	add.s32 	%r120, %r86, %r119;
	add.s32 	%r121, %r120, 2;
	add.s32 	%r122, %r117, %r121;
	shf.l.wrap.b32 	%r123, %r121, %r121, 13;
	xor.b32  	%r124, %r122, %r123;
	add.s32 	%r125, %r124, %r122;
	shf.l.wrap.b32 	%r126, %r124, %r124, 15;
	xor.b32  	%r127, %r125, %r126;
	add.s32 	%r128, %r127, %r125;
	shf.l.wrap.b32 	%r129, %r127, %r127, 26;
	xor.b32  	%r130, %r128, %r129;
	add.s32 	%r131, %r130, %r128;
	add.s32 	%r132, %r131, %r86;
	shf.l.wrap.b32 	%r133, %r130, %r130, 6;
	xor.b32  	%r134, %r131, %r133;
	add.s32 	%r135, %r3, %r134;
	add.s32 	%r136, %r135, 3;
	add.s32 	%r137, %r132, %r136;
	shf.l.wrap.b32 	%r138, %r136, %r136, 17;
	xor.b32  	%r139, %r137, %r138;
	add.s32 	%r140, %r139, %r137;
	shf.l.wrap.b32 	%r141, %r139, %r139, 29;
	xor.b32  	%r142, %r140, %r141;
	add.s32 	%r143, %r142, %r140;
	shf.l.wrap.b32 	%r144, %r142, %r142, 16;
	xor.b32  	%r145, %r143, %r144;
	add.s32 	%r146, %r145, %r143;
	add.s32 	%r147, %r146, %r3;
	shf.l.wrap.b32 	%r148, %r145, %r145, 24;
	xor.b32  	%r149, %r146, %r148;
	add.s32 	%r150, %r104, %r149;
	add.s32 	%r151, %r150, 4;
	add.s32 	%r152, %r147, %r151;
	shf.l.wrap.b32 	%r153, %r151, %r151, 13;
	xor.b32  	%r154, %r152, %r153;
	add.s32 	%r155, %r154, %r152;
	shf.l.wrap.b32 	%r156, %r154, %r154, 15;
	xor.b32  	%r157, %r155, %r156;
	add.s32 	%r158, %r157, %r155;
	shf.l.wrap.b32 	%r159, %r157, %r157, 26;
	xor.b32  	%r160, %r158, %r159;
	add.s32 	%r161, %r158, %r104;
	add.s32 	%r162, %r161, %r160;
	bra.uni 	$L__BB84_3;
$L__BB84_2:
	ld.global.nc.u32 	%r7, [%rd2];
	add.s32 	%r8, %r2, %r7;
	add.s32 	%r9, %r3, %r2;
	add.s32 	%r10, %r8, %r9;
	add.s32 	%r11, %r10, -50;
	shf.l.wrap.b32 	%r12, %r9, %r9, 13;
	xor.b32  	%r13, %r11, %r12;
	add.s32 	%r14, %r13, %r11;
	shf.l.wrap.b32 	%r15, %r13, %r13, 15;
	xor.b32  	%r16, %r14, %r15;
	add.s32 	%r17, %r16, %r14;
	shf.l.wrap.b32 	%r18, %r16, %r16, 26;
	xor.b32  	%r19, %r17, %r18;
	add.s32 	%r20, %r19, %r17;
	add.s32 	%r21, %r20, %r3;
	shf.l.wrap.b32 	%r22, %r19, %r19, 6;
	xor.b32  	%r23, %r20, %r22;
	xor.b32  	%r24, %r7, %r3;
	xor.b32  	%r25, %r24, 466688986;
	add.s32 	%r26, %r25, %r23;
	add.s32 	%r27, %r26, 1;
	add.s32 	%r28, %r21, %r27;
	shf.l.wrap.b32 	%r29, %r27, %r27, 17;
	xor.b32  	%r30, %r28, %r29;
	add.s32 	%r31, %r30, %r28;
	shf.l.wrap.b32 	%r32, %r30, %r30, 29;
	xor.b32  	%r33, %r31, %r32;
	add.s32 	%r34, %r33, %r31;
	shf.l.wrap.b32 	%r35, %r33, %r33, 16;
	xor.b32  	%r36, %r34, %r35;
	add.s32 	%r37, %r36, %r34;
	add.s32 	%r38, %r37, %r25;
	shf.l.wrap.b32 	%r39, %r36, %r36, 24;
	xor.b32  	%r40, %r37, %r39;
	add.s32 	%r41, %r7, %r40;
	add.s32 	%r42, %r41, 2;
	add.s32 	%r43, %r38, %r42;
	shf.l.wrap.b32 	%r44, %r42, %r42, 13;
	xor.b32  	%r45, %r43, %r44;
	add.s32 	%r46, %r45, %r43;
	shf.l.wrap.b32 	%r47, %r45, %r45, 15;
	xor.b32  	%r48, %r46, %r47;
	add.s32 	%r49, %r48, %r46;
	shf.l.wrap.b32 	%r50, %r48, %r48, 26;
	xor.b32  	%r51, %r49, %r50;
	add.s32 	%r52, %r51, %r49;
	add.s32 	%r53, %r52, %r7;
	shf.l.wrap.b32 	%r54, %r51, %r51, 6;
	xor.b32  	%r55, %r52, %r54;
	add.s32 	%r56, %r3, %r55;
	add.s32 	%r57, %r56, 3;
	add.s32 	%r58, %r53, %r57;
	shf.l.wrap.b32 	%r59, %r57, %r57, 17;
	xor.b32  	%r60, %r58, %r59;
	add.s32 	%r61, %r60, %r58;
	shf.l.wrap.b32 	%r62, %r60, %r60, 29;
	xor.b32  	%r63, %r61, %r62;
	add.s32 	%r64, %r63, %r61;
	shf.l.wrap.b32 	%r65, %r63, %r63, 16;
	xor.b32  	%r66, %r64, %r65;
	add.s32 	%r67, %r66, %r64;
	add.s32 	%r68, %r67, %r3;
	shf.l.wrap.b32 	%r69, %r66, %r66, 24;
	xor.b32  	%r70, %r67, %r69;
	add.s32 	%r71, %r25, %r70;
	add.s32 	%r72, %r71, 4;
	add.s32 	%r73, %r68, %r72;
	shf.l.wrap.b32 	%r74, %r72, %r72, 13;
	xor.b32  	%r75, %r73, %r74;
	add.s32 	%r76, %r75, %r73;
	shf.l.wrap.b32 	%r77, %r75, %r75, 15;
	xor.b32  	%r78, %r76, %r77;
	add.s32 	%r79, %r78, %r76;
	shf.l.wrap.b32 	%r80, %r78, %r78, 26;
	xor.b32  	%r81, %r79, %r80;
	add.s32 	%r82, %r81, %r79;
	shf.l.wrap.b32 	%r83, %r81, %r81, 6;
	xor.b32  	%r84, %r82, %r83;
	add.s32 	%r85, %r7, %r84;
	add.s32 	%r162, %r85, 5;
$L__BB84_3:
	mul.wide.u32 	%rd5, %r1, 4;
	add.s64 	%rd6, %rd1, %rd5;
	st.global.u32 	[%rd6], %r162;
	ret;

}
	// .globl	loop_add_xor_fusion_1
.visible .entry loop_add_xor_fusion_1(
	.param .u64 loop_add_xor_fusion_1_param_0,
	.param .u64 loop_add_xor_fusion_1_param_1,
	.param .u64 loop_add_xor_fusion_1_param_2,
	.param .u64 loop_add_xor_fusion_1_param_3,
	.param .u64 loop_add_xor_fusion_1_param_4,
	.param .u64 loop_add_xor_fusion_1_param_5,
	.param .u64 loop_add_xor_fusion_1_param_6,
	.param .u64 loop_add_xor_fusion_1_param_7,
	.param .u64 loop_add_xor_fusion_1_param_8,
	.param .u64 loop_add_xor_fusion_1_param_9,
	.param .u64 loop_add_xor_fusion_1_param_10,
	.param .u64 loop_add_xor_fusion_1_param_11,
	.param .u64 loop_add_xor_fusion_1_param_12,
	.param .u64 loop_add_xor_fusion_1_param_13,
	.param .u64 loop_add_xor_fusion_1_param_14,
	.param .u64 loop_add_xor_fusion_1_param_15,
	.param .u64 loop_add_xor_fusion_1_param_16,
	.param .u64 loop_add_xor_fusion_1_param_17,
	.param .u64 loop_add_xor_fusion_1_param_18,
	.param .u64 loop_add_xor_fusion_1_param_19,
	.param .u64 loop_add_xor_fusion_1_param_20,
	.param .u64 loop_add_xor_fusion_1_param_21,
	.param .u64 loop_add_xor_fusion_1_param_22,
	.param .u64 loop_add_xor_fusion_1_param_23,
	.param .u64 loop_add_xor_fusion_1_param_24,
	.param .u64 loop_add_xor_fusion_1_param_25,
	.param .u64 loop_add_xor_fusion_1_param_26,
	.param .u64 loop_add_xor_fusion_1_param_27,
	.param .u64 loop_add_xor_fusion_1_param_28,
	.param .u64 loop_add_xor_fusion_1_param_29,
	.param .u64 loop_add_xor_fusion_1_param_30,
	.param .u64 loop_add_xor_fusion_1_param_31,
	.param .u64 loop_add_xor_fusion_1_param_32,
	.param .u64 loop_add_xor_fusion_1_param_33,
	.param .u64 loop_add_xor_fusion_1_param_34,
	.param .u64 loop_add_xor_fusion_1_param_35,
	.param .u64 loop_add_xor_fusion_1_param_36
)
.reqntid 50, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<1048>;
	.reg .b64 	%rd<114>;

	ld.param.u64 	%rd39, [loop_add_xor_fusion_1_param_0];
	ld.param.u64 	%rd40, [loop_add_xor_fusion_1_param_36];
	cvta.to.global.u64 	%rd1, %rd40;
	ld.param.u64 	%rd41, [loop_add_xor_fusion_1_param_1];
	ld.param.u64 	%rd42, [loop_add_xor_fusion_1_param_35];
	cvta.to.global.u64 	%rd2, %rd42;
	ld.param.u64 	%rd43, [loop_add_xor_fusion_1_param_2];
	ld.param.u64 	%rd44, [loop_add_xor_fusion_1_param_34];
	cvta.to.global.u64 	%rd3, %rd44;
	ld.param.u64 	%rd45, [loop_add_xor_fusion_1_param_3];
	ld.param.u64 	%rd46, [loop_add_xor_fusion_1_param_33];
	cvta.to.global.u64 	%rd4, %rd46;
	ld.param.u64 	%rd47, [loop_add_xor_fusion_1_param_4];
	ld.param.u64 	%rd48, [loop_add_xor_fusion_1_param_32];
	cvta.to.global.u64 	%rd5, %rd48;
	ld.param.u64 	%rd49, [loop_add_xor_fusion_1_param_5];
	ld.param.u64 	%rd50, [loop_add_xor_fusion_1_param_31];
	cvta.to.global.u64 	%rd6, %rd50;
	ld.param.u64 	%rd51, [loop_add_xor_fusion_1_param_6];
	ld.param.u64 	%rd52, [loop_add_xor_fusion_1_param_30];
	cvta.to.global.u64 	%rd7, %rd52;
	ld.param.u64 	%rd53, [loop_add_xor_fusion_1_param_7];
	ld.param.u64 	%rd54, [loop_add_xor_fusion_1_param_29];
	cvta.to.global.u64 	%rd8, %rd54;
	ld.param.u64 	%rd55, [loop_add_xor_fusion_1_param_8];
	ld.param.u64 	%rd56, [loop_add_xor_fusion_1_param_28];
	cvta.to.global.u64 	%rd9, %rd56;
	ld.param.u64 	%rd57, [loop_add_xor_fusion_1_param_9];
	ld.param.u64 	%rd58, [loop_add_xor_fusion_1_param_27];
	cvta.to.global.u64 	%rd10, %rd58;
	ld.param.u64 	%rd59, [loop_add_xor_fusion_1_param_10];
	ld.param.u64 	%rd60, [loop_add_xor_fusion_1_param_26];
	cvta.to.global.u64 	%rd11, %rd60;
	ld.param.u64 	%rd61, [loop_add_xor_fusion_1_param_11];
	ld.param.u64 	%rd62, [loop_add_xor_fusion_1_param_25];
	cvta.to.global.u64 	%rd12, %rd62;
	ld.param.u64 	%rd63, [loop_add_xor_fusion_1_param_12];
	ld.param.u64 	%rd64, [loop_add_xor_fusion_1_param_24];
	cvta.to.global.u64 	%rd13, %rd64;
	ld.param.u64 	%rd65, [loop_add_xor_fusion_1_param_13];
	ld.param.u64 	%rd66, [loop_add_xor_fusion_1_param_23];
	cvta.to.global.u64 	%rd14, %rd66;
	ld.param.u64 	%rd67, [loop_add_xor_fusion_1_param_14];
	ld.param.u64 	%rd68, [loop_add_xor_fusion_1_param_22];
	cvta.to.global.u64 	%rd15, %rd68;
	ld.param.u64 	%rd69, [loop_add_xor_fusion_1_param_15];
	ld.param.u64 	%rd70, [loop_add_xor_fusion_1_param_21];
	cvta.to.global.u64 	%rd16, %rd70;
	ld.param.u64 	%rd71, [loop_add_xor_fusion_1_param_16];
	ld.param.u64 	%rd72, [loop_add_xor_fusion_1_param_20];
	cvta.to.global.u64 	%rd17, %rd72;
	ld.param.u64 	%rd73, [loop_add_xor_fusion_1_param_17];
	ld.param.u64 	%rd74, [loop_add_xor_fusion_1_param_19];
	cvta.to.global.u64 	%rd18, %rd74;
	ld.param.u64 	%rd75, [loop_add_xor_fusion_1_param_18];
	cvta.to.global.u64 	%rd19, %rd75;
	cvta.to.global.u64 	%rd20, %rd73;
	cvta.to.global.u64 	%rd21, %rd71;
	cvta.to.global.u64 	%rd22, %rd69;
	cvta.to.global.u64 	%rd23, %rd67;
	cvta.to.global.u64 	%rd24, %rd65;
	cvta.to.global.u64 	%rd25, %rd63;
	cvta.to.global.u64 	%rd26, %rd61;
	cvta.to.global.u64 	%rd27, %rd59;
	cvta.to.global.u64 	%rd28, %rd57;
	cvta.to.global.u64 	%rd29, %rd55;
	cvta.to.global.u64 	%rd30, %rd53;
	cvta.to.global.u64 	%rd31, %rd51;
	cvta.to.global.u64 	%rd32, %rd49;
	cvta.to.global.u64 	%rd33, %rd47;
	cvta.to.global.u64 	%rd34, %rd45;
	cvta.to.global.u64 	%rd35, %rd43;
	cvta.to.global.u64 	%rd36, %rd41;
	cvta.to.global.u64 	%rd76, %rd39;
	mov.u32 	%r8, %tid.x;
	cvt.u64.u32 	%rd37, %r8;
	mul.wide.u32 	%rd77, %r8, 4;
	add.s64 	%rd38, %rd76, %rd77;
	ld.global.u32 	%r1, [%rd38];
	shl.b32 	%r2, %r8, 1;
	or.b32  	%r3, %r2, 1;
	setp.gt.u32 	%p1, %r3, 49;
	ld.global.nc.u32 	%r4, [%rd36+4];
	@%p1 bra 	$L__BB85_2;
	ld.global.nc.u32 	%r88, [%rd36];
	add.s32 	%r89, %r88, %r3;
	add.s32 	%r90, %r2, %r4;
	add.s32 	%r91, %r90, 51;
	add.s32 	%r92, %r89, %r91;
	shf.l.wrap.b32 	%r93, %r91, %r91, 13;
	xor.b32  	%r94, %r92, %r93;
	add.s32 	%r95, %r94, %r92;
	shf.l.wrap.b32 	%r96, %r94, %r94, 15;
	xor.b32  	%r97, %r95, %r96;
	add.s32 	%r98, %r97, %r95;
	shf.l.wrap.b32 	%r99, %r97, %r97, 26;
	xor.b32  	%r100, %r98, %r99;
	add.s32 	%r101, %r100, %r98;
	add.s32 	%r102, %r101, %r4;
	shf.l.wrap.b32 	%r103, %r100, %r100, 6;
	xor.b32  	%r104, %r101, %r103;
	xor.b32  	%r105, %r88, %r4;
	xor.b32  	%r106, %r105, 466688986;
	add.s32 	%r107, %r106, %r104;
	add.s32 	%r108, %r107, 1;
	add.s32 	%r109, %r102, %r108;
	shf.l.wrap.b32 	%r110, %r108, %r108, 17;
	xor.b32  	%r111, %r109, %r110;
	add.s32 	%r112, %r111, %r109;
	shf.l.wrap.b32 	%r113, %r111, %r111, 29;
	xor.b32  	%r114, %r112, %r113;
	add.s32 	%r115, %r114, %r112;
	shf.l.wrap.b32 	%r116, %r114, %r114, 16;
	xor.b32  	%r117, %r115, %r116;
	add.s32 	%r118, %r117, %r115;
	add.s32 	%r119, %r118, %r106;
	shf.l.wrap.b32 	%r120, %r117, %r117, 24;
	xor.b32  	%r121, %r118, %r120;
	add.s32 	%r122, %r88, %r121;
	add.s32 	%r123, %r122, 2;
	add.s32 	%r124, %r119, %r123;
	shf.l.wrap.b32 	%r125, %r123, %r123, 13;
	xor.b32  	%r126, %r124, %r125;
	add.s32 	%r127, %r126, %r124;
	shf.l.wrap.b32 	%r128, %r126, %r126, 15;
	xor.b32  	%r129, %r127, %r128;
	add.s32 	%r130, %r129, %r127;
	shf.l.wrap.b32 	%r131, %r129, %r129, 26;
	xor.b32  	%r132, %r130, %r131;
	add.s32 	%r133, %r132, %r130;
	add.s32 	%r134, %r133, %r88;
	shf.l.wrap.b32 	%r135, %r132, %r132, 6;
	xor.b32  	%r136, %r133, %r135;
	add.s32 	%r137, %r4, %r136;
	add.s32 	%r138, %r137, 3;
	add.s32 	%r139, %r134, %r138;
	shf.l.wrap.b32 	%r140, %r138, %r138, 17;
	xor.b32  	%r141, %r139, %r140;
	add.s32 	%r142, %r141, %r139;
	shf.l.wrap.b32 	%r143, %r141, %r141, 29;
	xor.b32  	%r144, %r142, %r143;
	add.s32 	%r145, %r144, %r142;
	shf.l.wrap.b32 	%r146, %r144, %r144, 16;
	xor.b32  	%r147, %r145, %r146;
	add.s32 	%r148, %r147, %r145;
	add.s32 	%r149, %r148, %r4;
	shf.l.wrap.b32 	%r150, %r147, %r147, 24;
	xor.b32  	%r151, %r148, %r150;
	add.s32 	%r152, %r106, %r151;
	add.s32 	%r153, %r152, 4;
	add.s32 	%r154, %r149, %r153;
	shf.l.wrap.b32 	%r155, %r153, %r153, 13;
	xor.b32  	%r156, %r154, %r155;
	add.s32 	%r157, %r156, %r154;
	shf.l.wrap.b32 	%r158, %r156, %r156, 15;
	xor.b32  	%r159, %r157, %r158;
	add.s32 	%r160, %r159, %r157;
	shf.l.wrap.b32 	%r161, %r159, %r159, 26;
	xor.b32  	%r162, %r160, %r161;
	add.s32 	%r163, %r160, %r106;
	add.s32 	%r1047, %r163, %r162;
	bra.uni 	$L__BB85_3;
$L__BB85_2:
	ld.global.nc.u32 	%r9, [%rd36];
	add.s32 	%r10, %r2, %r9;
	add.s32 	%r11, %r4, %r3;
	add.s32 	%r12, %r10, %r11;
	add.s32 	%r13, %r12, -49;
	shf.l.wrap.b32 	%r14, %r11, %r11, 13;
	xor.b32  	%r15, %r13, %r14;
	add.s32 	%r16, %r15, %r13;
	shf.l.wrap.b32 	%r17, %r15, %r15, 15;
	xor.b32  	%r18, %r16, %r17;
	add.s32 	%r19, %r18, %r16;
	shf.l.wrap.b32 	%r20, %r18, %r18, 26;
	xor.b32  	%r21, %r19, %r20;
	add.s32 	%r22, %r21, %r19;
	add.s32 	%r23, %r22, %r4;
	shf.l.wrap.b32 	%r24, %r21, %r21, 6;
	xor.b32  	%r25, %r22, %r24;
	xor.b32  	%r26, %r9, %r4;
	xor.b32  	%r27, %r26, 466688986;
	add.s32 	%r28, %r27, %r25;
	add.s32 	%r29, %r28, 1;
	add.s32 	%r30, %r23, %r29;
	shf.l.wrap.b32 	%r31, %r29, %r29, 17;
	xor.b32  	%r32, %r30, %r31;
	add.s32 	%r33, %r32, %r30;
	shf.l.wrap.b32 	%r34, %r32, %r32, 29;
	xor.b32  	%r35, %r33, %r34;
	add.s32 	%r36, %r35, %r33;
	shf.l.wrap.b32 	%r37, %r35, %r35, 16;
	xor.b32  	%r38, %r36, %r37;
	add.s32 	%r39, %r38, %r36;
	add.s32 	%r40, %r39, %r27;
	shf.l.wrap.b32 	%r41, %r38, %r38, 24;
	xor.b32  	%r42, %r39, %r41;
	add.s32 	%r43, %r9, %r42;
	add.s32 	%r44, %r43, 2;
	add.s32 	%r45, %r40, %r44;
	shf.l.wrap.b32 	%r46, %r44, %r44, 13;
	xor.b32  	%r47, %r45, %r46;
	add.s32 	%r48, %r47, %r45;
	shf.l.wrap.b32 	%r49, %r47, %r47, 15;
	xor.b32  	%r50, %r48, %r49;
	add.s32 	%r51, %r50, %r48;
	shf.l.wrap.b32 	%r52, %r50, %r50, 26;
	xor.b32  	%r53, %r51, %r52;
	add.s32 	%r54, %r53, %r51;
	add.s32 	%r55, %r54, %r9;
	shf.l.wrap.b32 	%r56, %r53, %r53, 6;
	xor.b32  	%r57, %r54, %r56;
	add.s32 	%r58, %r4, %r57;
	add.s32 	%r59, %r58, 3;
	add.s32 	%r60, %r55, %r59;
	shf.l.wrap.b32 	%r61, %r59, %r59, 17;
	xor.b32  	%r62, %r60, %r61;
	add.s32 	%r63, %r62, %r60;
	shf.l.wrap.b32 	%r64, %r62, %r62, 29;
	xor.b32  	%r65, %r63, %r64;
	add.s32 	%r66, %r65, %r63;
	shf.l.wrap.b32 	%r67, %r65, %r65, 16;
	xor.b32  	%r68, %r66, %r67;
	add.s32 	%r69, %r68, %r66;
	add.s32 	%r70, %r69, %r4;
	shf.l.wrap.b32 	%r71, %r68, %r68, 24;
	xor.b32  	%r72, %r69, %r71;
	add.s32 	%r73, %r27, %r72;
	add.s32 	%r74, %r73, 4;
	add.s32 	%r75, %r70, %r74;
	shf.l.wrap.b32 	%r76, %r74, %r74, 13;
	xor.b32  	%r77, %r75, %r76;
	add.s32 	%r78, %r77, %r75;
	shf.l.wrap.b32 	%r79, %r77, %r77, 15;
	xor.b32  	%r80, %r78, %r79;
	add.s32 	%r81, %r80, %r78;
	shf.l.wrap.b32 	%r82, %r80, %r80, 26;
	xor.b32  	%r83, %r81, %r82;
	add.s32 	%r84, %r83, %r81;
	shf.l.wrap.b32 	%r85, %r83, %r83, 6;
	xor.b32  	%r86, %r84, %r85;
	add.s32 	%r87, %r9, %r86;
	add.s32 	%r1047, %r87, 5;
$L__BB85_3:
	add.s32 	%r164, %r1047, 206867568;
	add.s32 	%r165, %r164, %r1;
	shf.l.wrap.b32 	%r166, %r164, %r164, 13;
	xor.b32  	%r167, %r165, %r166;
	add.s32 	%r168, %r167, %r165;
	shf.l.wrap.b32 	%r169, %r167, %r167, 15;
	xor.b32  	%r170, %r168, %r169;
	add.s32 	%r171, %r170, %r168;
	shf.l.wrap.b32 	%r172, %r170, %r170, 26;
	xor.b32  	%r173, %r171, %r172;
	add.s32 	%r174, %r173, %r171;
	add.s32 	%r175, %r174, %r1047;
	shf.l.wrap.b32 	%r176, %r173, %r173, 6;
	xor.b32  	%r177, %r174, %r176;
	xor.b32  	%r178, %r1, %r1047;
	xor.b32  	%r179, %r178, 466688986;
	add.s32 	%r180, %r179, 1;
	add.s32 	%r181, %r180, %r177;
	add.s32 	%r182, %r175, %r181;
	shf.l.wrap.b32 	%r183, %r181, %r181, 17;
	xor.b32  	%r184, %r182, %r183;
	add.s32 	%r185, %r184, %r182;
	shf.l.wrap.b32 	%r186, %r184, %r184, 29;
	xor.b32  	%r187, %r185, %r186;
	add.s32 	%r188, %r187, %r185;
	shf.l.wrap.b32 	%r189, %r187, %r187, 16;
	xor.b32  	%r190, %r188, %r189;
	add.s32 	%r191, %r190, %r188;
	add.s32 	%r192, %r191, %r179;
	shf.l.wrap.b32 	%r193, %r190, %r190, 24;
	xor.b32  	%r194, %r191, %r193;
	add.s32 	%r195, %r1, 2;
	add.s32 	%r196, %r195, %r194;
	add.s32 	%r197, %r192, %r196;
	shf.l.wrap.b32 	%r198, %r196, %r196, 13;
	xor.b32  	%r199, %r197, %r198;
	add.s32 	%r200, %r199, %r197;
	shf.l.wrap.b32 	%r201, %r199, %r199, 15;
	xor.b32  	%r202, %r200, %r201;
	add.s32 	%r203, %r202, %r200;
	shf.l.wrap.b32 	%r204, %r202, %r202, 26;
	xor.b32  	%r205, %r203, %r204;
	add.s32 	%r206, %r205, %r203;
	add.s32 	%r207, %r206, %r1;
	shf.l.wrap.b32 	%r208, %r205, %r205, 6;
	xor.b32  	%r209, %r206, %r208;
	add.s32 	%r210, %r1047, 3;
	add.s32 	%r211, %r210, %r209;
	add.s32 	%r212, %r207, %r211;
	shf.l.wrap.b32 	%r213, %r211, %r211, 17;
	xor.b32  	%r214, %r212, %r213;
	add.s32 	%r215, %r214, %r212;
	shf.l.wrap.b32 	%r216, %r214, %r214, 29;
	xor.b32  	%r217, %r215, %r216;
	add.s32 	%r218, %r217, %r215;
	shf.l.wrap.b32 	%r219, %r217, %r217, 16;
	xor.b32  	%r220, %r218, %r219;
	add.s32 	%r221, %r220, %r218;
	add.s32 	%r222, %r221, %r1047;
	shf.l.wrap.b32 	%r223, %r220, %r220, 24;
	xor.b32  	%r224, %r221, %r223;
	add.s32 	%r225, %r179, 4;
	add.s32 	%r226, %r225, %r224;
	add.s32 	%r227, %r222, %r226;
	shf.l.wrap.b32 	%r228, %r226, %r226, 13;
	xor.b32  	%r229, %r227, %r228;
	add.s32 	%r230, %r229, %r227;
	shf.l.wrap.b32 	%r231, %r229, %r229, 15;
	xor.b32  	%r232, %r230, %r231;
	add.s32 	%r233, %r232, %r230;
	shf.l.wrap.b32 	%r234, %r232, %r232, 26;
	xor.b32  	%r235, %r233, %r234;
	add.s32 	%r236, %r235, %r233;
	add.s32 	%r237, %r236, %r179;
	shf.l.wrap.b32 	%r238, %r235, %r235, 6;
	xor.b32  	%r239, %r236, %r238;
	add.s32 	%r240, %r1, 5;
	add.s32 	%r241, %r240, %r239;
	xor.b32  	%r242, %r237, %r241;
	xor.b32  	%r243, %r242, 466688986;
	add.s32 	%r244, %r1047, -1963884216;
	add.s32 	%r245, %r244, %r1;
	shf.l.wrap.b32 	%r246, %r244, %r244, 13;
	xor.b32  	%r247, %r245, %r246;
	add.s32 	%r248, %r247, %r245;
	shf.l.wrap.b32 	%r249, %r247, %r247, 15;
	xor.b32  	%r250, %r248, %r249;
	add.s32 	%r251, %r250, %r248;
	shf.l.wrap.b32 	%r252, %r250, %r250, 26;
	xor.b32  	%r253, %r251, %r252;
	add.s32 	%r254, %r253, %r251;
	add.s32 	%r255, %r254, %r1047;
	shf.l.wrap.b32 	%r256, %r253, %r253, 6;
	xor.b32  	%r257, %r254, %r256;
	add.s32 	%r258, %r180, %r257;
	add.s32 	%r259, %r255, %r258;
	shf.l.wrap.b32 	%r260, %r258, %r258, 17;
	xor.b32  	%r261, %r259, %r260;
	add.s32 	%r262, %r261, %r259;
	shf.l.wrap.b32 	%r263, %r261, %r261, 29;
	xor.b32  	%r264, %r262, %r263;
	add.s32 	%r265, %r264, %r262;
	shf.l.wrap.b32 	%r266, %r264, %r264, 16;
	xor.b32  	%r267, %r265, %r266;
	add.s32 	%r268, %r267, %r265;
	add.s32 	%r269, %r268, %r179;
	shf.l.wrap.b32 	%r270, %r267, %r267, 24;
	xor.b32  	%r271, %r268, %r270;
	add.s32 	%r272, %r195, %r271;
	add.s32 	%r273, %r269, %r272;
	shf.l.wrap.b32 	%r274, %r272, %r272, 13;
	xor.b32  	%r275, %r273, %r274;
	add.s32 	%r276, %r275, %r273;
	shf.l.wrap.b32 	%r277, %r275, %r275, 15;
	xor.b32  	%r278, %r276, %r277;
	add.s32 	%r279, %r278, %r276;
	shf.l.wrap.b32 	%r280, %r278, %r278, 26;
	xor.b32  	%r281, %r279, %r280;
	add.s32 	%r282, %r281, %r279;
	add.s32 	%r283, %r282, %r1;
	shf.l.wrap.b32 	%r284, %r281, %r281, 6;
	xor.b32  	%r285, %r282, %r284;
	add.s32 	%r286, %r210, %r285;
	add.s32 	%r287, %r283, %r286;
	shf.l.wrap.b32 	%r288, %r286, %r286, 17;
	xor.b32  	%r289, %r287, %r288;
	add.s32 	%r290, %r289, %r287;
	shf.l.wrap.b32 	%r291, %r289, %r289, 29;
	xor.b32  	%r292, %r290, %r291;
	add.s32 	%r293, %r292, %r290;
	shf.l.wrap.b32 	%r294, %r292, %r292, 16;
	xor.b32  	%r295, %r293, %r294;
	add.s32 	%r296, %r295, %r293;
	add.s32 	%r297, %r296, %r1047;
	shf.l.wrap.b32 	%r298, %r295, %r295, 24;
	xor.b32  	%r299, %r296, %r298;
	add.s32 	%r300, %r225, %r299;
	add.s32 	%r301, %r297, %r300;
	shf.l.wrap.b32 	%r302, %r300, %r300, 13;
	xor.b32  	%r303, %r301, %r302;
	add.s32 	%r304, %r303, %r301;
	shf.l.wrap.b32 	%r305, %r303, %r303, 15;
	xor.b32  	%r306, %r304, %r305;
	add.s32 	%r307, %r306, %r304;
	shf.l.wrap.b32 	%r308, %r306, %r306, 26;
	xor.b32  	%r309, %r307, %r308;
	add.s32 	%r310, %r309, %r307;
	add.s32 	%r311, %r310, %r179;
	shf.l.wrap.b32 	%r312, %r309, %r309, 6;
	xor.b32  	%r313, %r310, %r312;
	add.s32 	%r314, %r240, %r313;
	xor.b32  	%r315, %r311, %r314;
	xor.b32  	%r316, %r315, 466688986;
	add.s32 	%r317, %r1047, -2014515409;
	add.s32 	%r318, %r317, %r1;
	shf.l.wrap.b32 	%r319, %r317, %r317, 13;
	xor.b32  	%r320, %r318, %r319;
	add.s32 	%r321, %r320, %r318;
	shf.l.wrap.b32 	%r322, %r320, %r320, 15;
	xor.b32  	%r323, %r321, %r322;
	add.s32 	%r324, %r323, %r321;
	shf.l.wrap.b32 	%r325, %r323, %r323, 26;
	xor.b32  	%r326, %r324, %r325;
	add.s32 	%r327, %r326, %r324;
	add.s32 	%r328, %r327, %r1047;
	shf.l.wrap.b32 	%r329, %r326, %r326, 6;
	xor.b32  	%r330, %r327, %r329;
	add.s32 	%r331, %r180, %r330;
	add.s32 	%r332, %r328, %r331;
	shf.l.wrap.b32 	%r333, %r331, %r331, 17;
	xor.b32  	%r334, %r332, %r333;
	add.s32 	%r335, %r334, %r332;
	shf.l.wrap.b32 	%r336, %r334, %r334, 29;
	xor.b32  	%r337, %r335, %r336;
	add.s32 	%r338, %r337, %r335;
	shf.l.wrap.b32 	%r339, %r337, %r337, 16;
	xor.b32  	%r340, %r338, %r339;
	add.s32 	%r341, %r340, %r338;
	add.s32 	%r342, %r341, %r179;
	shf.l.wrap.b32 	%r343, %r340, %r340, 24;
	xor.b32  	%r344, %r341, %r343;
	add.s32 	%r345, %r195, %r344;
	add.s32 	%r346, %r342, %r345;
	shf.l.wrap.b32 	%r347, %r345, %r345, 13;
	xor.b32  	%r348, %r346, %r347;
	add.s32 	%r349, %r348, %r346;
	shf.l.wrap.b32 	%r350, %r348, %r348, 15;
	xor.b32  	%r351, %r349, %r350;
	add.s32 	%r352, %r351, %r349;
	shf.l.wrap.b32 	%r353, %r351, %r351, 26;
	xor.b32  	%r354, %r352, %r353;
	add.s32 	%r355, %r354, %r352;
	add.s32 	%r356, %r355, %r1;
	shf.l.wrap.b32 	%r357, %r354, %r354, 6;
	xor.b32  	%r358, %r355, %r357;
	add.s32 	%r359, %r210, %r358;
	add.s32 	%r360, %r356, %r359;
	shf.l.wrap.b32 	%r361, %r359, %r359, 17;
	xor.b32  	%r362, %r360, %r361;
	add.s32 	%r363, %r362, %r360;
	shf.l.wrap.b32 	%r364, %r362, %r362, 29;
	xor.b32  	%r365, %r363, %r364;
	add.s32 	%r366, %r365, %r363;
	shf.l.wrap.b32 	%r367, %r365, %r365, 16;
	xor.b32  	%r368, %r366, %r367;
	add.s32 	%r369, %r368, %r366;
	add.s32 	%r370, %r369, %r1047;
	shf.l.wrap.b32 	%r371, %r368, %r368, 24;
	xor.b32  	%r372, %r369, %r371;
	add.s32 	%r373, %r225, %r372;
	add.s32 	%r374, %r370, %r373;
	shf.l.wrap.b32 	%r375, %r373, %r373, 13;
	xor.b32  	%r376, %r374, %r375;
	add.s32 	%r377, %r376, %r374;
	shf.l.wrap.b32 	%r378, %r376, %r376, 15;
	xor.b32  	%r379, %r377, %r378;
	add.s32 	%r380, %r379, %r377;
	shf.l.wrap.b32 	%r381, %r379, %r379, 26;
	xor.b32  	%r382, %r380, %r381;
	add.s32 	%r383, %r382, %r380;
	add.s32 	%r384, %r383, %r179;
	shf.l.wrap.b32 	%r385, %r382, %r382, 6;
	xor.b32  	%r386, %r383, %r385;
	add.s32 	%r387, %r240, %r386;
	xor.b32  	%r388, %r384, %r387;
	xor.b32  	%r389, %r388, 466688986;
	add.s32 	%r390, %r1047, -193685661;
	add.s32 	%r391, %r390, %r1;
	shf.l.wrap.b32 	%r392, %r390, %r390, 13;
	xor.b32  	%r393, %r391, %r392;
	add.s32 	%r394, %r393, %r391;
	shf.l.wrap.b32 	%r395, %r393, %r393, 15;
	xor.b32  	%r396, %r394, %r395;
	add.s32 	%r397, %r396, %r394;
	shf.l.wrap.b32 	%r398, %r396, %r396, 26;
	xor.b32  	%r399, %r397, %r398;
	add.s32 	%r400, %r399, %r397;
	add.s32 	%r401, %r400, %r1047;
	shf.l.wrap.b32 	%r402, %r399, %r399, 6;
	xor.b32  	%r403, %r400, %r402;
	add.s32 	%r404, %r180, %r403;
	add.s32 	%r405, %r401, %r404;
	shf.l.wrap.b32 	%r406, %r404, %r404, 17;
	xor.b32  	%r407, %r405, %r406;
	add.s32 	%r408, %r407, %r405;
	shf.l.wrap.b32 	%r409, %r407, %r407, 29;
	xor.b32  	%r410, %r408, %r409;
	add.s32 	%r411, %r410, %r408;
	shf.l.wrap.b32 	%r412, %r410, %r410, 16;
	xor.b32  	%r413, %r411, %r412;
	add.s32 	%r414, %r413, %r411;
	add.s32 	%r415, %r414, %r179;
	shf.l.wrap.b32 	%r416, %r413, %r413, 24;
	xor.b32  	%r417, %r414, %r416;
	add.s32 	%r418, %r195, %r417;
	add.s32 	%r419, %r415, %r418;
	shf.l.wrap.b32 	%r420, %r418, %r418, 13;
	xor.b32  	%r421, %r419, %r420;
	add.s32 	%r422, %r421, %r419;
	shf.l.wrap.b32 	%r423, %r421, %r421, 15;
	xor.b32  	%r424, %r422, %r423;
	add.s32 	%r425, %r424, %r422;
	shf.l.wrap.b32 	%r426, %r424, %r424, 26;
	xor.b32  	%r427, %r425, %r426;
	add.s32 	%r428, %r427, %r425;
	add.s32 	%r429, %r428, %r1;
	shf.l.wrap.b32 	%r430, %r427, %r427, 6;
	xor.b32  	%r431, %r428, %r430;
	add.s32 	%r432, %r210, %r431;
	add.s32 	%r433, %r429, %r432;
	shf.l.wrap.b32 	%r434, %r432, %r432, 17;
	xor.b32  	%r435, %r433, %r434;
	add.s32 	%r436, %r435, %r433;
	shf.l.wrap.b32 	%r437, %r435, %r435, 29;
	xor.b32  	%r438, %r436, %r437;
	add.s32 	%r439, %r438, %r436;
	shf.l.wrap.b32 	%r440, %r438, %r438, 16;
	xor.b32  	%r441, %r439, %r440;
	add.s32 	%r442, %r441, %r439;
	add.s32 	%r443, %r442, %r1047;
	shf.l.wrap.b32 	%r444, %r441, %r441, 24;
	xor.b32  	%r445, %r442, %r444;
	add.s32 	%r446, %r225, %r445;
	add.s32 	%r447, %r443, %r446;
	shf.l.wrap.b32 	%r448, %r446, %r446, 13;
	xor.b32  	%r449, %r447, %r448;
	add.s32 	%r450, %r449, %r447;
	shf.l.wrap.b32 	%r451, %r449, %r449, 15;
	xor.b32  	%r452, %r450, %r451;
	add.s32 	%r453, %r452, %r450;
	shf.l.wrap.b32 	%r454, %r452, %r452, 26;
	xor.b32  	%r455, %r453, %r454;
	add.s32 	%r456, %r455, %r453;
	add.s32 	%r457, %r456, %r179;
	shf.l.wrap.b32 	%r458, %r455, %r455, 6;
	xor.b32  	%r459, %r456, %r458;
	add.s32 	%r460, %r240, %r459;
	xor.b32  	%r461, %r457, %r460;
	xor.b32  	%r462, %r461, 466688986;
	add.s32 	%r463, %r1047, -1669046184;
	add.s32 	%r464, %r463, %r1;
	shf.l.wrap.b32 	%r465, %r463, %r463, 13;
	xor.b32  	%r466, %r464, %r465;
	add.s32 	%r467, %r466, %r464;
	shf.l.wrap.b32 	%r468, %r466, %r466, 15;
	xor.b32  	%r469, %r467, %r468;
	add.s32 	%r470, %r469, %r467;
	shf.l.wrap.b32 	%r471, %r469, %r469, 26;
	xor.b32  	%r472, %r470, %r471;
	add.s32 	%r473, %r472, %r470;
	add.s32 	%r474, %r473, %r1047;
	shf.l.wrap.b32 	%r475, %r472, %r472, 6;
	xor.b32  	%r476, %r473, %r475;
	add.s32 	%r477, %r180, %r476;
	add.s32 	%r478, %r474, %r477;
	shf.l.wrap.b32 	%r479, %r477, %r477, 17;
	xor.b32  	%r480, %r478, %r479;
	add.s32 	%r481, %r480, %r478;
	shf.l.wrap.b32 	%r482, %r480, %r480, 29;
	xor.b32  	%r483, %r481, %r482;
	add.s32 	%r484, %r483, %r481;
	shf.l.wrap.b32 	%r485, %r483, %r483, 16;
	xor.b32  	%r486, %r484, %r485;
	add.s32 	%r487, %r486, %r484;
	add.s32 	%r488, %r487, %r179;
	shf.l.wrap.b32 	%r489, %r486, %r486, 24;
	xor.b32  	%r490, %r487, %r489;
	add.s32 	%r491, %r195, %r490;
	add.s32 	%r492, %r488, %r491;
	shf.l.wrap.b32 	%r493, %r491, %r491, 13;
	xor.b32  	%r494, %r492, %r493;
	add.s32 	%r495, %r494, %r492;
	shf.l.wrap.b32 	%r496, %r494, %r494, 15;
	xor.b32  	%r497, %r495, %r496;
	add.s32 	%r498, %r497, %r495;
	shf.l.wrap.b32 	%r499, %r497, %r497, 26;
	xor.b32  	%r500, %r498, %r499;
	add.s32 	%r501, %r500, %r498;
	add.s32 	%r502, %r501, %r1;
	shf.l.wrap.b32 	%r503, %r500, %r500, 6;
	xor.b32  	%r504, %r501, %r503;
	add.s32 	%r505, %r210, %r504;
	add.s32 	%r506, %r502, %r505;
	shf.l.wrap.b32 	%r507, %r505, %r505, 17;
	xor.b32  	%r508, %r506, %r507;
	add.s32 	%r509, %r508, %r506;
	shf.l.wrap.b32 	%r510, %r508, %r508, 29;
	xor.b32  	%r511, %r509, %r510;
	add.s32 	%r512, %r511, %r509;
	shf.l.wrap.b32 	%r513, %r511, %r511, 16;
	xor.b32  	%r514, %r512, %r513;
	add.s32 	%r515, %r514, %r512;
	add.s32 	%r516, %r515, %r1047;
	shf.l.wrap.b32 	%r517, %r514, %r514, 24;
	xor.b32  	%r518, %r515, %r517;
	add.s32 	%r519, %r225, %r518;
	add.s32 	%r520, %r516, %r519;
	shf.l.wrap.b32 	%r521, %r519, %r519, 13;
	xor.b32  	%r522, %r520, %r521;
	add.s32 	%r523, %r522, %r520;
	shf.l.wrap.b32 	%r524, %r522, %r522, 15;
	xor.b32  	%r525, %r523, %r524;
	add.s32 	%r526, %r525, %r523;
	shf.l.wrap.b32 	%r527, %r525, %r525, 26;
	xor.b32  	%r528, %r526, %r527;
	add.s32 	%r529, %r528, %r526;
	add.s32 	%r530, %r529, %r179;
	shf.l.wrap.b32 	%r531, %r528, %r528, 6;
	xor.b32  	%r532, %r529, %r531;
	add.s32 	%r533, %r240, %r532;
	xor.b32  	%r534, %r530, %r533;
	xor.b32  	%r535, %r534, 466688986;
	add.s32 	%r536, %r1047, 480162853;
	add.s32 	%r537, %r536, %r1;
	shf.l.wrap.b32 	%r538, %r536, %r536, 13;
	xor.b32  	%r539, %r537, %r538;
	add.s32 	%r540, %r539, %r537;
	shf.l.wrap.b32 	%r541, %r539, %r539, 15;
	xor.b32  	%r542, %r540, %r541;
	add.s32 	%r543, %r542, %r540;
	shf.l.wrap.b32 	%r544, %r542, %r542, 26;
	xor.b32  	%r545, %r543, %r544;
	add.s32 	%r546, %r545, %r543;
	add.s32 	%r547, %r546, %r1047;
	shf.l.wrap.b32 	%r548, %r545, %r545, 6;
	xor.b32  	%r549, %r546, %r548;
	add.s32 	%r550, %r180, %r549;
	add.s32 	%r551, %r547, %r550;
	shf.l.wrap.b32 	%r552, %r550, %r550, 17;
	xor.b32  	%r553, %r551, %r552;
	add.s32 	%r554, %r553, %r551;
	shf.l.wrap.b32 	%r555, %r553, %r553, 29;
	xor.b32  	%r556, %r554, %r555;
	add.s32 	%r557, %r556, %r554;
	shf.l.wrap.b32 	%r558, %r556, %r556, 16;
	xor.b32  	%r559, %r557, %r558;
	add.s32 	%r560, %r559, %r557;
	add.s32 	%r561, %r560, %r179;
	shf.l.wrap.b32 	%r562, %r559, %r559, 24;
	xor.b32  	%r563, %r560, %r562;
	add.s32 	%r564, %r195, %r563;
	add.s32 	%r565, %r561, %r564;
	shf.l.wrap.b32 	%r566, %r564, %r564, 13;
	xor.b32  	%r567, %r565, %r566;
	add.s32 	%r568, %r567, %r565;
	shf.l.wrap.b32 	%r569, %r567, %r567, 15;
	xor.b32  	%r570, %r568, %r569;
	add.s32 	%r571, %r570, %r568;
	shf.l.wrap.b32 	%r572, %r570, %r570, 26;
	xor.b32  	%r573, %r571, %r572;
	add.s32 	%r574, %r573, %r571;
	add.s32 	%r575, %r574, %r1;
	shf.l.wrap.b32 	%r576, %r573, %r573, 6;
	xor.b32  	%r577, %r574, %r576;
	add.s32 	%r578, %r210, %r577;
	add.s32 	%r579, %r575, %r578;
	shf.l.wrap.b32 	%r580, %r578, %r578, 17;
	xor.b32  	%r581, %r579, %r580;
	add.s32 	%r582, %r581, %r579;
	shf.l.wrap.b32 	%r583, %r581, %r581, 29;
	xor.b32  	%r584, %r582, %r583;
	add.s32 	%r585, %r584, %r582;
	shf.l.wrap.b32 	%r586, %r584, %r584, 16;
	xor.b32  	%r587, %r585, %r586;
	add.s32 	%r588, %r587, %r585;
	add.s32 	%r589, %r588, %r1047;
	shf.l.wrap.b32 	%r590, %r587, %r587, 24;
	xor.b32  	%r591, %r588, %r590;
	add.s32 	%r592, %r225, %r591;
	add.s32 	%r593, %r589, %r592;
	shf.l.wrap.b32 	%r594, %r592, %r592, 13;
	xor.b32  	%r595, %r593, %r594;
	add.s32 	%r596, %r595, %r593;
	shf.l.wrap.b32 	%r597, %r595, %r595, 15;
	xor.b32  	%r598, %r596, %r597;
	add.s32 	%r599, %r598, %r596;
	shf.l.wrap.b32 	%r600, %r598, %r598, 26;
	xor.b32  	%r601, %r599, %r600;
	add.s32 	%r602, %r601, %r599;
	add.s32 	%r603, %r602, %r179;
	shf.l.wrap.b32 	%r604, %r601, %r601, 6;
	xor.b32  	%r605, %r602, %r604;
	add.s32 	%r606, %r240, %r605;
	xor.b32  	%r607, %r603, %r606;
	xor.b32  	%r608, %r607, 466688986;
	add.s32 	%r609, %r1047, -72931437;
	add.s32 	%r610, %r609, %r1;
	shf.l.wrap.b32 	%r611, %r609, %r609, 13;
	xor.b32  	%r612, %r610, %r611;
	add.s32 	%r613, %r612, %r610;
	shf.l.wrap.b32 	%r614, %r612, %r612, 15;
	xor.b32  	%r615, %r613, %r614;
	add.s32 	%r616, %r615, %r613;
	shf.l.wrap.b32 	%r617, %r615, %r615, 26;
	xor.b32  	%r618, %r616, %r617;
	add.s32 	%r619, %r618, %r616;
	add.s32 	%r620, %r619, %r1047;
	shf.l.wrap.b32 	%r621, %r618, %r618, 6;
	xor.b32  	%r622, %r619, %r621;
	add.s32 	%r623, %r180, %r622;
	add.s32 	%r624, %r620, %r623;
	shf.l.wrap.b32 	%r625, %r623, %r623, 17;
	xor.b32  	%r626, %r624, %r625;
	add.s32 	%r627, %r626, %r624;
	shf.l.wrap.b32 	%r628, %r626, %r626, 29;
	xor.b32  	%r629, %r627, %r628;
	add.s32 	%r630, %r629, %r627;
	shf.l.wrap.b32 	%r631, %r629, %r629, 16;
	xor.b32  	%r632, %r630, %r631;
	add.s32 	%r633, %r632, %r630;
	add.s32 	%r634, %r633, %r179;
	shf.l.wrap.b32 	%r635, %r632, %r632, 24;
	xor.b32  	%r636, %r633, %r635;
	add.s32 	%r637, %r195, %r636;
	add.s32 	%r638, %r634, %r637;
	shf.l.wrap.b32 	%r639, %r637, %r637, 13;
	xor.b32  	%r640, %r638, %r639;
	add.s32 	%r641, %r640, %r638;
	shf.l.wrap.b32 	%r642, %r640, %r640, 15;
	xor.b32  	%r643, %r641, %r642;
	add.s32 	%r644, %r643, %r641;
	shf.l.wrap.b32 	%r645, %r643, %r643, 26;
	xor.b32  	%r646, %r644, %r645;
	add.s32 	%r647, %r646, %r644;
	add.s32 	%r648, %r647, %r1;
	shf.l.wrap.b32 	%r649, %r646, %r646, 6;
	xor.b32  	%r650, %r647, %r649;
	add.s32 	%r651, %r210, %r650;
	add.s32 	%r652, %r648, %r651;
	shf.l.wrap.b32 	%r653, %r651, %r651, 17;
	xor.b32  	%r654, %r652, %r653;
	add.s32 	%r655, %r654, %r652;
	shf.l.wrap.b32 	%r656, %r654, %r654, 29;
	xor.b32  	%r657, %r655, %r656;
	add.s32 	%r658, %r657, %r655;
	shf.l.wrap.b32 	%r659, %r657, %r657, 16;
	xor.b32  	%r660, %r658, %r659;
	add.s32 	%r661, %r660, %r658;
	add.s32 	%r662, %r661, %r1047;
	shf.l.wrap.b32 	%r663, %r660, %r660, 24;
	xor.b32  	%r664, %r661, %r663;
	add.s32 	%r665, %r225, %r664;
	add.s32 	%r666, %r662, %r665;
	shf.l.wrap.b32 	%r667, %r665, %r665, 13;
	xor.b32  	%r668, %r666, %r667;
	add.s32 	%r669, %r668, %r666;
	shf.l.wrap.b32 	%r670, %r668, %r668, 15;
	xor.b32  	%r671, %r669, %r670;
	add.s32 	%r672, %r671, %r669;
	shf.l.wrap.b32 	%r673, %r671, %r671, 26;
	xor.b32  	%r674, %r672, %r673;
	add.s32 	%r675, %r674, %r672;
	add.s32 	%r676, %r675, %r179;
	shf.l.wrap.b32 	%r677, %r674, %r674, 6;
	xor.b32  	%r678, %r675, %r677;
	add.s32 	%r679, %r240, %r678;
	xor.b32  	%r680, %r676, %r679;
	xor.b32  	%r681, %r680, 466688986;
	add.s32 	%r682, %r1047, 442253254;
	add.s32 	%r683, %r682, %r1;
	shf.l.wrap.b32 	%r684, %r682, %r682, 13;
	xor.b32  	%r685, %r683, %r684;
	add.s32 	%r686, %r685, %r683;
	shf.l.wrap.b32 	%r687, %r685, %r685, 15;
	xor.b32  	%r688, %r686, %r687;
	add.s32 	%r689, %r688, %r686;
	shf.l.wrap.b32 	%r690, %r688, %r688, 26;
	xor.b32  	%r691, %r689, %r690;
	add.s32 	%r692, %r691, %r689;
	add.s32 	%r693, %r692, %r1047;
	shf.l.wrap.b32 	%r694, %r691, %r691, 6;
	xor.b32  	%r695, %r692, %r694;
	add.s32 	%r696, %r180, %r695;
	add.s32 	%r697, %r693, %r696;
	shf.l.wrap.b32 	%r698, %r696, %r696, 17;
	xor.b32  	%r699, %r697, %r698;
	add.s32 	%r700, %r699, %r697;
	shf.l.wrap.b32 	%r701, %r699, %r699, 29;
	xor.b32  	%r702, %r700, %r701;
	add.s32 	%r703, %r702, %r700;
	shf.l.wrap.b32 	%r704, %r702, %r702, 16;
	xor.b32  	%r705, %r703, %r704;
	add.s32 	%r706, %r705, %r703;
	add.s32 	%r707, %r706, %r179;
	shf.l.wrap.b32 	%r708, %r705, %r705, 24;
	xor.b32  	%r709, %r706, %r708;
	add.s32 	%r710, %r195, %r709;
	add.s32 	%r711, %r707, %r710;
	shf.l.wrap.b32 	%r712, %r710, %r710, 13;
	xor.b32  	%r713, %r711, %r712;
	add.s32 	%r714, %r713, %r711;
	shf.l.wrap.b32 	%r715, %r713, %r713, 15;
	xor.b32  	%r716, %r714, %r715;
	add.s32 	%r717, %r716, %r714;
	shf.l.wrap.b32 	%r718, %r716, %r716, 26;
	xor.b32  	%r719, %r717, %r718;
	add.s32 	%r720, %r719, %r717;
	add.s32 	%r721, %r720, %r1;
	shf.l.wrap.b32 	%r722, %r719, %r719, 6;
	xor.b32  	%r723, %r720, %r722;
	add.s32 	%r724, %r210, %r723;
	add.s32 	%r725, %r721, %r724;
	shf.l.wrap.b32 	%r726, %r724, %r724, 17;
	xor.b32  	%r727, %r725, %r726;
	add.s32 	%r728, %r727, %r725;
	shf.l.wrap.b32 	%r729, %r727, %r727, 29;
	xor.b32  	%r730, %r728, %r729;
	add.s32 	%r731, %r730, %r728;
	shf.l.wrap.b32 	%r732, %r730, %r730, 16;
	xor.b32  	%r733, %r731, %r732;
	add.s32 	%r734, %r733, %r731;
	add.s32 	%r735, %r734, %r1047;
	shf.l.wrap.b32 	%r736, %r733, %r733, 24;
	xor.b32  	%r737, %r734, %r736;
	add.s32 	%r738, %r225, %r737;
	add.s32 	%r739, %r735, %r738;
	shf.l.wrap.b32 	%r740, %r738, %r738, 13;
	xor.b32  	%r741, %r739, %r740;
	add.s32 	%r742, %r741, %r739;
	shf.l.wrap.b32 	%r743, %r741, %r741, 15;
	xor.b32  	%r744, %r742, %r743;
	add.s32 	%r745, %r744, %r742;
	shf.l.wrap.b32 	%r746, %r744, %r744, 26;
	xor.b32  	%r747, %r745, %r746;
	add.s32 	%r748, %r747, %r745;
	add.s32 	%r749, %r748, %r179;
	shf.l.wrap.b32 	%r750, %r747, %r747, 6;
	xor.b32  	%r751, %r748, %r750;
	add.s32 	%r752, %r240, %r751;
	xor.b32  	%r753, %r749, %r752;
	xor.b32  	%r754, %r753, 466688986;
	add.s32 	%r755, %r1047, 1932346663;
	add.s32 	%r756, %r755, %r1;
	shf.l.wrap.b32 	%r757, %r755, %r755, 13;
	xor.b32  	%r758, %r756, %r757;
	add.s32 	%r759, %r758, %r756;
	shf.l.wrap.b32 	%r760, %r758, %r758, 15;
	xor.b32  	%r761, %r759, %r760;
	add.s32 	%r762, %r761, %r759;
	shf.l.wrap.b32 	%r763, %r761, %r761, 26;
	xor.b32  	%r764, %r762, %r763;
	add.s32 	%r765, %r764, %r762;
	add.s32 	%r766, %r765, %r1047;
	shf.l.wrap.b32 	%r767, %r764, %r764, 6;
	xor.b32  	%r768, %r765, %r767;
	add.s32 	%r769, %r180, %r768;
	add.s32 	%r770, %r766, %r769;
	shf.l.wrap.b32 	%r771, %r769, %r769, 17;
	xor.b32  	%r772, %r770, %r771;
	add.s32 	%r773, %r772, %r770;
	shf.l.wrap.b32 	%r774, %r772, %r772, 29;
	xor.b32  	%r775, %r773, %r774;
	add.s32 	%r776, %r775, %r773;
	shf.l.wrap.b32 	%r777, %r775, %r775, 16;
	xor.b32  	%r778, %r776, %r777;
	add.s32 	%r779, %r778, %r776;
	add.s32 	%r780, %r779, %r179;
	shf.l.wrap.b32 	%r781, %r778, %r778, 24;
	xor.b32  	%r782, %r779, %r781;
	add.s32 	%r783, %r195, %r782;
	add.s32 	%r784, %r780, %r783;
	shf.l.wrap.b32 	%r785, %r783, %r783, 13;
	xor.b32  	%r786, %r784, %r785;
	add.s32 	%r787, %r786, %r784;
	shf.l.wrap.b32 	%r788, %r786, %r786, 15;
	xor.b32  	%r789, %r787, %r788;
	add.s32 	%r790, %r789, %r787;
	shf.l.wrap.b32 	%r791, %r789, %r789, 26;
	xor.b32  	%r792, %r790, %r791;
	add.s32 	%r793, %r792, %r790;
	add.s32 	%r794, %r793, %r1;
	shf.l.wrap.b32 	%r795, %r792, %r792, 6;
	xor.b32  	%r796, %r793, %r795;
	add.s32 	%r797, %r210, %r796;
	add.s32 	%r798, %r794, %r797;
	shf.l.wrap.b32 	%r799, %r797, %r797, 17;
	xor.b32  	%r800, %r798, %r799;
	add.s32 	%r801, %r800, %r798;
	shf.l.wrap.b32 	%r802, %r800, %r800, 29;
	xor.b32  	%r803, %r801, %r802;
	add.s32 	%r804, %r803, %r801;
	shf.l.wrap.b32 	%r805, %r803, %r803, 16;
	xor.b32  	%r806, %r804, %r805;
	add.s32 	%r807, %r806, %r804;
	add.s32 	%r808, %r807, %r1047;
	shf.l.wrap.b32 	%r809, %r806, %r806, 24;
	xor.b32  	%r810, %r807, %r809;
	add.s32 	%r811, %r225, %r810;
	add.s32 	%r812, %r808, %r811;
	shf.l.wrap.b32 	%r813, %r811, %r811, 13;
	xor.b32  	%r814, %r812, %r813;
	add.s32 	%r815, %r814, %r812;
	shf.l.wrap.b32 	%r816, %r814, %r814, 15;
	xor.b32  	%r817, %r815, %r816;
	add.s32 	%r818, %r817, %r815;
	shf.l.wrap.b32 	%r819, %r817, %r817, 26;
	xor.b32  	%r820, %r818, %r819;
	add.s32 	%r821, %r820, %r818;
	add.s32 	%r822, %r821, %r179;
	shf.l.wrap.b32 	%r823, %r820, %r820, 6;
	xor.b32  	%r824, %r821, %r823;
	add.s32 	%r825, %r240, %r824;
	xor.b32  	%r826, %r822, %r825;
	xor.b32  	%r827, %r826, 466688986;
	add.s32 	%r828, %r1047, 115576830;
	add.s32 	%r829, %r828, %r1;
	shf.l.wrap.b32 	%r830, %r828, %r828, 13;
	xor.b32  	%r831, %r829, %r830;
	add.s32 	%r832, %r831, %r829;
	shf.l.wrap.b32 	%r833, %r831, %r831, 15;
	xor.b32  	%r834, %r832, %r833;
	add.s32 	%r835, %r834, %r832;
	shf.l.wrap.b32 	%r836, %r834, %r834, 26;
	xor.b32  	%r837, %r835, %r836;
	add.s32 	%r838, %r837, %r835;
	add.s32 	%r839, %r838, %r1047;
	shf.l.wrap.b32 	%r840, %r837, %r837, 6;
	xor.b32  	%r841, %r838, %r840;
	add.s32 	%r842, %r180, %r841;
	add.s32 	%r843, %r839, %r842;
	shf.l.wrap.b32 	%r844, %r842, %r842, 17;
	xor.b32  	%r845, %r843, %r844;
	add.s32 	%r846, %r845, %r843;
	shf.l.wrap.b32 	%r847, %r845, %r845, 29;
	xor.b32  	%r848, %r846, %r847;
	add.s32 	%r849, %r848, %r846;
	shf.l.wrap.b32 	%r850, %r848, %r848, 16;
	xor.b32  	%r851, %r849, %r850;
	add.s32 	%r852, %r851, %r849;
	add.s32 	%r853, %r852, %r179;
	shf.l.wrap.b32 	%r854, %r851, %r851, 24;
	xor.b32  	%r855, %r852, %r854;
	add.s32 	%r856, %r195, %r855;
	add.s32 	%r857, %r853, %r856;
	shf.l.wrap.b32 	%r858, %r856, %r856, 13;
	xor.b32  	%r859, %r857, %r858;
	add.s32 	%r860, %r859, %r857;
	shf.l.wrap.b32 	%r861, %r859, %r859, 15;
	xor.b32  	%r862, %r860, %r861;
	add.s32 	%r863, %r862, %r860;
	shf.l.wrap.b32 	%r864, %r862, %r862, 26;
	xor.b32  	%r865, %r863, %r864;
	add.s32 	%r866, %r865, %r863;
	add.s32 	%r867, %r866, %r1;
	shf.l.wrap.b32 	%r868, %r865, %r865, 6;
	xor.b32  	%r869, %r866, %r868;
	add.s32 	%r870, %r210, %r869;
	add.s32 	%r871, %r867, %r870;
	shf.l.wrap.b32 	%r872, %r870, %r870, 17;
	xor.b32  	%r873, %r871, %r872;
	add.s32 	%r874, %r873, %r871;
	shf.l.wrap.b32 	%r875, %r873, %r873, 29;
	xor.b32  	%r876, %r874, %r875;
	add.s32 	%r877, %r876, %r874;
	shf.l.wrap.b32 	%r878, %r876, %r876, 16;
	xor.b32  	%r879, %r877, %r878;
	add.s32 	%r880, %r879, %r877;
	add.s32 	%r881, %r880, %r1047;
	shf.l.wrap.b32 	%r882, %r879, %r879, 24;
	xor.b32  	%r883, %r880, %r882;
	add.s32 	%r884, %r225, %r883;
	add.s32 	%r885, %r881, %r884;
	shf.l.wrap.b32 	%r886, %r884, %r884, 13;
	xor.b32  	%r887, %r885, %r886;
	add.s32 	%r888, %r887, %r885;
	shf.l.wrap.b32 	%r889, %r887, %r887, 15;
	xor.b32  	%r890, %r888, %r889;
	add.s32 	%r891, %r890, %r888;
	shf.l.wrap.b32 	%r892, %r890, %r890, 26;
	xor.b32  	%r893, %r891, %r892;
	add.s32 	%r894, %r893, %r891;
	add.s32 	%r895, %r894, %r179;
	shf.l.wrap.b32 	%r896, %r893, %r893, 6;
	xor.b32  	%r897, %r894, %r896;
	add.s32 	%r898, %r240, %r897;
	xor.b32  	%r899, %r895, %r898;
	xor.b32  	%r900, %r899, 466688986;
	add.s32 	%r901, %r1047, -926125496;
	add.s32 	%r902, %r901, %r1;
	shf.l.wrap.b32 	%r903, %r901, %r901, 13;
	xor.b32  	%r904, %r902, %r903;
	add.s32 	%r905, %r904, %r902;
	shf.l.wrap.b32 	%r906, %r904, %r904, 15;
	xor.b32  	%r907, %r905, %r906;
	add.s32 	%r908, %r907, %r905;
	shf.l.wrap.b32 	%r909, %r907, %r907, 26;
	xor.b32  	%r910, %r908, %r909;
	add.s32 	%r911, %r910, %r908;
	add.s32 	%r912, %r911, %r1047;
	shf.l.wrap.b32 	%r913, %r910, %r910, 6;
	xor.b32  	%r914, %r911, %r913;
	add.s32 	%r915, %r180, %r914;
	add.s32 	%r916, %r912, %r915;
	shf.l.wrap.b32 	%r917, %r915, %r915, 17;
	xor.b32  	%r918, %r916, %r917;
	add.s32 	%r919, %r918, %r916;
	shf.l.wrap.b32 	%r920, %r918, %r918, 29;
	xor.b32  	%r921, %r919, %r920;
	add.s32 	%r922, %r921, %r919;
	shf.l.wrap.b32 	%r923, %r921, %r921, 16;
	xor.b32  	%r924, %r922, %r923;
	add.s32 	%r925, %r924, %r922;
	add.s32 	%r926, %r925, %r179;
	shf.l.wrap.b32 	%r927, %r924, %r924, 24;
	xor.b32  	%r928, %r925, %r927;
	add.s32 	%r929, %r195, %r928;
	add.s32 	%r930, %r926, %r929;
	shf.l.wrap.b32 	%r931, %r929, %r929, 13;
	xor.b32  	%r932, %r930, %r931;
	add.s32 	%r933, %r932, %r930;
	shf.l.wrap.b32 	%r934, %r932, %r932, 15;
	xor.b32  	%r935, %r933, %r934;
	add.s32 	%r936, %r935, %r933;
	shf.l.wrap.b32 	%r937, %r935, %r935, 26;
	xor.b32  	%r938, %r936, %r937;
	add.s32 	%r939, %r938, %r936;
	add.s32 	%r940, %r939, %r1;
	shf.l.wrap.b32 	%r941, %r938, %r938, 6;
	xor.b32  	%r942, %r939, %r941;
	add.s32 	%r943, %r210, %r942;
	add.s32 	%r944, %r940, %r943;
	shf.l.wrap.b32 	%r945, %r943, %r943, 17;
	xor.b32  	%r946, %r944, %r945;
	add.s32 	%r947, %r946, %r944;
	shf.l.wrap.b32 	%r948, %r946, %r946, 29;
	xor.b32  	%r949, %r947, %r948;
	add.s32 	%r950, %r949, %r947;
	shf.l.wrap.b32 	%r951, %r949, %r949, 16;
	xor.b32  	%r952, %r950, %r951;
	add.s32 	%r953, %r952, %r950;
	add.s32 	%r954, %r953, %r1047;
	shf.l.wrap.b32 	%r955, %r952, %r952, 24;
	xor.b32  	%r956, %r953, %r955;
	add.s32 	%r957, %r225, %r956;
	add.s32 	%r958, %r954, %r957;
	shf.l.wrap.b32 	%r959, %r957, %r957, 13;
	xor.b32  	%r960, %r958, %r959;
	add.s32 	%r961, %r960, %r958;
	shf.l.wrap.b32 	%r962, %r960, %r960, 15;
	xor.b32  	%r963, %r961, %r962;
	add.s32 	%r964, %r963, %r961;
	shf.l.wrap.b32 	%r965, %r963, %r963, 26;
	xor.b32  	%r966, %r964, %r965;
	add.s32 	%r967, %r966, %r964;
	add.s32 	%r968, %r967, %r179;
	shf.l.wrap.b32 	%r969, %r966, %r966, 6;
	xor.b32  	%r970, %r967, %r969;
	add.s32 	%r971, %r240, %r970;
	xor.b32  	%r972, %r968, %r971;
	xor.b32  	%r973, %r972, 466688986;
	add.s32 	%r974, %r1047, -1650524457;
	add.s32 	%r975, %r974, %r1;
	shf.l.wrap.b32 	%r976, %r974, %r974, 13;
	xor.b32  	%r977, %r975, %r976;
	add.s32 	%r978, %r977, %r975;
	shf.l.wrap.b32 	%r979, %r977, %r977, 15;
	xor.b32  	%r980, %r978, %r979;
	add.s32 	%r981, %r980, %r978;
	shf.l.wrap.b32 	%r982, %r980, %r980, 26;
	xor.b32  	%r983, %r981, %r982;
	add.s32 	%r984, %r983, %r981;
	add.s32 	%r985, %r984, %r1047;
	shf.l.wrap.b32 	%r986, %r983, %r983, 6;
	xor.b32  	%r987, %r984, %r986;
	add.s32 	%r988, %r180, %r987;
	add.s32 	%r989, %r985, %r988;
	shf.l.wrap.b32 	%r990, %r988, %r988, 17;
	xor.b32  	%r991, %r989, %r990;
	add.s32 	%r992, %r991, %r989;
	shf.l.wrap.b32 	%r993, %r991, %r991, 29;
	xor.b32  	%r994, %r992, %r993;
	add.s32 	%r995, %r994, %r992;
	shf.l.wrap.b32 	%r996, %r994, %r994, 16;
	xor.b32  	%r997, %r995, %r996;
	add.s32 	%r998, %r997, %r995;
	add.s32 	%r999, %r998, %r179;
	shf.l.wrap.b32 	%r1000, %r997, %r997, 24;
	xor.b32  	%r1001, %r998, %r1000;
	add.s32 	%r1002, %r195, %r1001;
	add.s32 	%r1003, %r999, %r1002;
	shf.l.wrap.b32 	%r1004, %r1002, %r1002, 13;
	xor.b32  	%r1005, %r1003, %r1004;
	add.s32 	%r1006, %r1005, %r1003;
	shf.l.wrap.b32 	%r1007, %r1005, %r1005, 15;
	xor.b32  	%r1008, %r1006, %r1007;
	add.s32 	%r1009, %r1008, %r1006;
	shf.l.wrap.b32 	%r1010, %r1008, %r1008, 26;
	xor.b32  	%r1011, %r1009, %r1010;
	add.s32 	%r1012, %r1011, %r1009;
	add.s32 	%r1013, %r1012, %r1;
	shf.l.wrap.b32 	%r1014, %r1011, %r1011, 6;
	xor.b32  	%r1015, %r1012, %r1014;
	add.s32 	%r1016, %r210, %r1015;
	add.s32 	%r1017, %r1013, %r1016;
	shf.l.wrap.b32 	%r1018, %r1016, %r1016, 17;
	xor.b32  	%r1019, %r1017, %r1018;
	add.s32 	%r1020, %r1019, %r1017;
	shf.l.wrap.b32 	%r1021, %r1019, %r1019, 29;
	xor.b32  	%r1022, %r1020, %r1021;
	add.s32 	%r1023, %r1022, %r1020;
	shf.l.wrap.b32 	%r1024, %r1022, %r1022, 16;
	xor.b32  	%r1025, %r1023, %r1024;
	add.s32 	%r1026, %r1025, %r1023;
	add.s32 	%r1027, %r1026, %r1047;
	shf.l.wrap.b32 	%r1028, %r1025, %r1025, 24;
	xor.b32  	%r1029, %r1026, %r1028;
	add.s32 	%r1030, %r225, %r1029;
	add.s32 	%r1031, %r1027, %r1030;
	shf.l.wrap.b32 	%r1032, %r1030, %r1030, 13;
	xor.b32  	%r1033, %r1031, %r1032;
	add.s32 	%r1034, %r1033, %r1031;
	shf.l.wrap.b32 	%r1035, %r1033, %r1033, 15;
	xor.b32  	%r1036, %r1034, %r1035;
	add.s32 	%r1037, %r1036, %r1034;
	shf.l.wrap.b32 	%r1038, %r1036, %r1036, 26;
	xor.b32  	%r1039, %r1037, %r1038;
	add.s32 	%r1040, %r1039, %r1037;
	add.s32 	%r1041, %r1040, %r179;
	shf.l.wrap.b32 	%r1042, %r1039, %r1039, 6;
	xor.b32  	%r1043, %r1040, %r1042;
	add.s32 	%r1044, %r240, %r1043;
	xor.b32  	%r1045, %r1041, %r1044;
	xor.b32  	%r1046, %r1045, 466688986;
	st.global.u32 	[%rd38], %r243;
	shl.b64 	%rd78, %rd37, 2;
	add.s64 	%rd79, %rd35, %rd78;
	st.global.u32 	[%rd79], %r241;
	add.s64 	%rd80, %rd34, %rd78;
	st.global.u32 	[%rd80], %r237;
	add.s64 	%rd81, %rd33, %rd78;
	st.global.u32 	[%rd81], %r316;
	add.s64 	%rd82, %rd32, %rd78;
	st.global.u32 	[%rd82], %r314;
	add.s64 	%rd83, %rd31, %rd78;
	st.global.u32 	[%rd83], %r311;
	add.s64 	%rd84, %rd30, %rd78;
	st.global.u32 	[%rd84], %r389;
	add.s64 	%rd85, %rd29, %rd78;
	st.global.u32 	[%rd85], %r387;
	add.s64 	%rd86, %rd28, %rd78;
	st.global.u32 	[%rd86], %r384;
	add.s64 	%rd87, %rd27, %rd78;
	st.global.u32 	[%rd87], %r462;
	add.s64 	%rd88, %rd26, %rd78;
	st.global.u32 	[%rd88], %r460;
	add.s64 	%rd89, %rd25, %rd78;
	st.global.u32 	[%rd89], %r457;
	add.s64 	%rd90, %rd24, %rd78;
	st.global.u32 	[%rd90], %r535;
	add.s64 	%rd91, %rd23, %rd78;
	st.global.u32 	[%rd91], %r533;
	add.s64 	%rd92, %rd22, %rd78;
	st.global.u32 	[%rd92], %r530;
	add.s64 	%rd93, %rd21, %rd78;
	st.global.u32 	[%rd93], %r608;
	add.s64 	%rd94, %rd20, %rd78;
	st.global.u32 	[%rd94], %r606;
	add.s64 	%rd95, %rd19, %rd78;
	st.global.u32 	[%rd95], %r603;
	add.s64 	%rd96, %rd18, %rd78;
	st.global.u32 	[%rd96], %r681;
	add.s64 	%rd97, %rd17, %rd78;
	st.global.u32 	[%rd97], %r679;
	add.s64 	%rd98, %rd16, %rd78;
	st.global.u32 	[%rd98], %r676;
	add.s64 	%rd99, %rd15, %rd78;
	st.global.u32 	[%rd99], %r754;
	add.s64 	%rd100, %rd14, %rd78;
	st.global.u32 	[%rd100], %r752;
	add.s64 	%rd101, %rd13, %rd78;
	st.global.u32 	[%rd101], %r749;
	add.s64 	%rd102, %rd12, %rd78;
	st.global.u32 	[%rd102], %r827;
	add.s64 	%rd103, %rd11, %rd78;
	st.global.u32 	[%rd103], %r825;
	add.s64 	%rd104, %rd10, %rd78;
	st.global.u32 	[%rd104], %r822;
	add.s64 	%rd105, %rd9, %rd78;
	st.global.u32 	[%rd105], %r900;
	add.s64 	%rd106, %rd8, %rd78;
	st.global.u32 	[%rd106], %r898;
	add.s64 	%rd107, %rd7, %rd78;
	st.global.u32 	[%rd107], %r895;
	add.s64 	%rd108, %rd6, %rd78;
	st.global.u32 	[%rd108], %r973;
	add.s64 	%rd109, %rd5, %rd78;
	st.global.u32 	[%rd109], %r971;
	add.s64 	%rd110, %rd4, %rd78;
	st.global.u32 	[%rd110], %r968;
	add.s64 	%rd111, %rd3, %rd78;
	st.global.u32 	[%rd111], %r1046;
	add.s64 	%rd112, %rd2, %rd78;
	st.global.u32 	[%rd112], %r1044;
	add.s64 	%rd113, %rd1, %rd78;
	st.global.u32 	[%rd113], %r1041;
	ret;

}
	// .globl	loop_add_fusion_304
.visible .entry loop_add_fusion_304(
	.param .u64 loop_add_fusion_304_param_0,
	.param .u64 loop_add_fusion_304_param_1,
	.param .u64 loop_add_fusion_304_param_2,
	.param .u64 loop_add_fusion_304_param_3
)
.reqntid 128, 1, 1
{
	.reg .b32 	%r<83>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [loop_add_fusion_304_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_304_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_304_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_304_param_2];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	shr.u32 	%r5, %r1, 1;
	and.b32  	%r6, %r4, 255;
	mul.wide.u32 	%rd9, %r5, 4;
	add.s64 	%rd10, %rd6, %rd9;
	ld.global.nc.u32 	%r7, [%rd10];
	add.s32 	%r8, %r7, %r6;
	add.s64 	%rd11, %rd8, %rd9;
	ld.global.nc.u32 	%r9, [%rd11];
	add.s32 	%r10, %r9, %r6;
	add.s32 	%r11, %r10, 256;
	add.s32 	%r12, %r8, %r11;
	shf.l.wrap.b32 	%r13, %r11, %r11, 13;
	xor.b32  	%r14, %r12, %r13;
	add.s32 	%r15, %r14, %r12;
	shf.l.wrap.b32 	%r16, %r14, %r14, 15;
	xor.b32  	%r17, %r15, %r16;
	add.s32 	%r18, %r17, %r15;
	shf.l.wrap.b32 	%r19, %r17, %r17, 26;
	xor.b32  	%r20, %r18, %r19;
	add.s32 	%r21, %r20, %r18;
	add.s32 	%r22, %r21, %r9;
	shf.l.wrap.b32 	%r23, %r20, %r20, 6;
	xor.b32  	%r24, %r21, %r23;
	add.s64 	%rd12, %rd7, %rd9;
	ld.global.nc.u32 	%r25, [%rd12];
	add.s32 	%r26, %r25, %r24;
	add.s32 	%r27, %r26, 1;
	add.s32 	%r28, %r22, %r27;
	shf.l.wrap.b32 	%r29, %r27, %r27, 17;
	xor.b32  	%r30, %r28, %r29;
	add.s32 	%r31, %r30, %r28;
	shf.l.wrap.b32 	%r32, %r30, %r30, 29;
	xor.b32  	%r33, %r31, %r32;
	add.s32 	%r34, %r33, %r31;
	shf.l.wrap.b32 	%r35, %r33, %r33, 16;
	xor.b32  	%r36, %r34, %r35;
	add.s32 	%r37, %r36, %r34;
	add.s32 	%r38, %r37, %r25;
	shf.l.wrap.b32 	%r39, %r36, %r36, 24;
	xor.b32  	%r40, %r37, %r39;
	add.s32 	%r41, %r7, %r40;
	add.s32 	%r42, %r41, 2;
	add.s32 	%r43, %r38, %r42;
	shf.l.wrap.b32 	%r44, %r42, %r42, 13;
	xor.b32  	%r45, %r43, %r44;
	add.s32 	%r46, %r45, %r43;
	shf.l.wrap.b32 	%r47, %r45, %r45, 15;
	xor.b32  	%r48, %r46, %r47;
	add.s32 	%r49, %r48, %r46;
	shf.l.wrap.b32 	%r50, %r48, %r48, 26;
	xor.b32  	%r51, %r49, %r50;
	add.s32 	%r52, %r51, %r49;
	add.s32 	%r53, %r52, %r7;
	shf.l.wrap.b32 	%r54, %r51, %r51, 6;
	xor.b32  	%r55, %r52, %r54;
	add.s32 	%r56, %r9, %r55;
	add.s32 	%r57, %r56, 3;
	add.s32 	%r58, %r53, %r57;
	shf.l.wrap.b32 	%r59, %r57, %r57, 17;
	xor.b32  	%r60, %r58, %r59;
	add.s32 	%r61, %r60, %r58;
	shf.l.wrap.b32 	%r62, %r60, %r60, 29;
	xor.b32  	%r63, %r61, %r62;
	add.s32 	%r64, %r63, %r61;
	shf.l.wrap.b32 	%r65, %r63, %r63, 16;
	xor.b32  	%r66, %r64, %r65;
	add.s32 	%r67, %r66, %r64;
	add.s32 	%r68, %r67, %r9;
	shf.l.wrap.b32 	%r69, %r66, %r66, 24;
	xor.b32  	%r70, %r67, %r69;
	add.s32 	%r71, %r25, %r70;
	add.s32 	%r72, %r71, 4;
	add.s32 	%r73, %r68, %r72;
	shf.l.wrap.b32 	%r74, %r72, %r72, 13;
	xor.b32  	%r75, %r73, %r74;
	add.s32 	%r76, %r75, %r73;
	shf.l.wrap.b32 	%r77, %r75, %r75, 15;
	xor.b32  	%r78, %r76, %r77;
	add.s32 	%r79, %r78, %r76;
	shf.l.wrap.b32 	%r80, %r78, %r78, 26;
	xor.b32  	%r81, %r79, %r80;
	add.s32 	%r82, %r81, %r79;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	st.global.u32 	[%rd14], %r82;
	ret;

}
	// .globl	input_concatenate_fusion_202
.visible .entry input_concatenate_fusion_202(
	.param .u64 input_concatenate_fusion_202_param_0,
	.param .u64 input_concatenate_fusion_202_param_1,
	.param .u64 input_concatenate_fusion_202_param_2,
	.param .u64 input_concatenate_fusion_202_param_3,
	.param .u64 input_concatenate_fusion_202_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<92>;
	.reg .f32 	%f<7>;
	.reg .b64 	%rd<21>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_202_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_202_param_4];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [input_concatenate_fusion_202_param_1];
	ld.param.u64 	%rd5, [input_concatenate_fusion_202_param_3];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [input_concatenate_fusion_202_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	cvta.to.global.u64 	%rd9, %rd4;
	cvta.to.global.u64 	%rd10, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r4, 255;
	shr.u32 	%r6, %r1, 1;
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd9, %rd11;
	ld.global.nc.u32 	%r7, [%rd12];
	mul.wide.u32 	%rd13, %r6, 4;
	add.s64 	%rd14, %rd8, %rd13;
	ld.global.nc.u32 	%r8, [%rd14];
	add.s32 	%r9, %r8, %r7;
	shr.u32 	%r10, %r9, 9;
	or.b32  	%r11, %r10, 1065353216;
	mov.b32 	%f1, %r11;
	add.rn.f32 	%f2, %f1, 0fBF800000;
	max.NaN.f32 	%f3, %f2, 0f00000000;
	setp.lt.f32 	%p1, %f3, 0f3F666666;
	selp.u16 	%rs1, 1, 0, %p1;
	cvt.u64.u32 	%rd15, %r5;
	mul.wide.u32 	%rd16, %r6, 512;
	add.s64 	%rd17, %rd3, %rd16;
	add.s64 	%rd18, %rd17, %rd15;
	st.global.u8 	[%rd18], %rs1;
	add.s64 	%rd19, %rd10, %rd13;
	ld.global.nc.u32 	%r12, [%rd19];
	add.s32 	%r13, %r12, %r5;
	add.s64 	%rd20, %rd6, %rd13;
	ld.global.nc.u32 	%r14, [%rd20];
	add.s32 	%r15, %r14, %r5;
	add.s32 	%r16, %r15, 256;
	add.s32 	%r17, %r13, %r16;
	shf.l.wrap.b32 	%r18, %r16, %r16, 13;
	xor.b32  	%r19, %r17, %r18;
	add.s32 	%r20, %r19, %r17;
	shf.l.wrap.b32 	%r21, %r19, %r19, 15;
	xor.b32  	%r22, %r20, %r21;
	add.s32 	%r23, %r22, %r20;
	shf.l.wrap.b32 	%r24, %r22, %r22, 26;
	xor.b32  	%r25, %r23, %r24;
	add.s32 	%r26, %r25, %r23;
	add.s32 	%r27, %r26, %r14;
	shf.l.wrap.b32 	%r28, %r25, %r25, 6;
	xor.b32  	%r29, %r26, %r28;
	add.s32 	%r30, %r8, %r29;
	add.s32 	%r31, %r30, 1;
	add.s32 	%r32, %r27, %r31;
	shf.l.wrap.b32 	%r33, %r31, %r31, 17;
	xor.b32  	%r34, %r32, %r33;
	add.s32 	%r35, %r34, %r32;
	shf.l.wrap.b32 	%r36, %r34, %r34, 29;
	xor.b32  	%r37, %r35, %r36;
	add.s32 	%r38, %r37, %r35;
	shf.l.wrap.b32 	%r39, %r37, %r37, 16;
	xor.b32  	%r40, %r38, %r39;
	add.s32 	%r41, %r40, %r38;
	add.s32 	%r42, %r41, %r8;
	shf.l.wrap.b32 	%r43, %r40, %r40, 24;
	xor.b32  	%r44, %r41, %r43;
	add.s32 	%r45, %r12, %r44;
	add.s32 	%r46, %r45, 2;
	add.s32 	%r47, %r42, %r46;
	shf.l.wrap.b32 	%r48, %r46, %r46, 13;
	xor.b32  	%r49, %r47, %r48;
	add.s32 	%r50, %r49, %r47;
	shf.l.wrap.b32 	%r51, %r49, %r49, 15;
	xor.b32  	%r52, %r50, %r51;
	add.s32 	%r53, %r52, %r50;
	shf.l.wrap.b32 	%r54, %r52, %r52, 26;
	xor.b32  	%r55, %r53, %r54;
	add.s32 	%r56, %r55, %r53;
	add.s32 	%r57, %r56, %r12;
	shf.l.wrap.b32 	%r58, %r55, %r55, 6;
	xor.b32  	%r59, %r56, %r58;
	add.s32 	%r60, %r14, %r59;
	add.s32 	%r61, %r60, 3;
	add.s32 	%r62, %r57, %r61;
	shf.l.wrap.b32 	%r63, %r61, %r61, 17;
	xor.b32  	%r64, %r62, %r63;
	add.s32 	%r65, %r64, %r62;
	shf.l.wrap.b32 	%r66, %r64, %r64, 29;
	xor.b32  	%r67, %r65, %r66;
	add.s32 	%r68, %r67, %r65;
	shf.l.wrap.b32 	%r69, %r67, %r67, 16;
	xor.b32  	%r70, %r68, %r69;
	add.s32 	%r71, %r70, %r68;
	add.s32 	%r72, %r71, %r14;
	shf.l.wrap.b32 	%r73, %r70, %r70, 24;
	xor.b32  	%r74, %r71, %r73;
	add.s32 	%r75, %r8, %r74;
	add.s32 	%r76, %r75, 4;
	add.s32 	%r77, %r72, %r76;
	shf.l.wrap.b32 	%r78, %r76, %r76, 13;
	xor.b32  	%r79, %r77, %r78;
	add.s32 	%r80, %r79, %r77;
	shf.l.wrap.b32 	%r81, %r79, %r79, 15;
	xor.b32  	%r82, %r80, %r81;
	add.s32 	%r83, %r82, %r80;
	shf.l.wrap.b32 	%r84, %r82, %r82, 26;
	xor.b32  	%r85, %r83, %r84;
	shf.l.wrap.b32 	%r86, %r85, %r85, 6;
	xor.b32  	%r87, %r86, %r7;
	add.s32 	%r88, %r12, %r87;
	add.s32 	%r89, %r88, 5;
	shr.u32 	%r90, %r89, 9;
	or.b32  	%r91, %r90, 1065353216;
	mov.b32 	%f4, %r91;
	add.rn.f32 	%f5, %f4, 0fBF800000;
	max.NaN.f32 	%f6, %f5, 0f00000000;
	setp.lt.f32 	%p2, %f6, 0f3F666666;
	selp.u16 	%rs2, 1, 0, %p2;
	st.global.u8 	[%rd18+256], %rs2;
	ret;

}
	// .globl	loop_select_tanh_fusion_6
.visible .entry loop_select_tanh_fusion_6(
	.param .u64 loop_select_tanh_fusion_6_param_0,
	.param .u64 loop_select_tanh_fusion_6_param_1,
	.param .u64 loop_select_tanh_fusion_6_param_2,
	.param .u64 loop_select_tanh_fusion_6_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<25>;
	.reg .b32 	%r<28>;
	.reg .f32 	%f<154>;
	.reg .b64 	%rd<17>;

	ld.param.u64 	%rd1, [loop_select_tanh_fusion_6_param_0];
	ld.param.u64 	%rd2, [loop_select_tanh_fusion_6_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_select_tanh_fusion_6_param_1];
	ld.param.u64 	%rd5, [loop_select_tanh_fusion_6_param_2];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	shr.u32 	%r6, %r1, 10;
	cvt.u64.u32 	%rd9, %r4;
	mul.wide.u32 	%rd10, %r6, 512;
	add.s64 	%rd11, %rd7, %rd10;
	add.s64 	%rd12, %rd11, %rd9;
	ld.global.nc.u32 	%r7, [%rd12];
	bfe.u32 	%r8, %r7, 0, 8;
	bfe.u32 	%r9, %r7, 8, 8;
	bfe.u32 	%r10, %r7, 16, 8;
	bfe.u32 	%r11, %r7, 24, 8;
	mul.wide.u32 	%rd13, %r5, 4;
	add.s64 	%rd14, %rd8, %rd13;
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd14];
	mul.rn.f32 	%f5, %f1, %f1;
	mul.rn.f32 	%f6, %f1, %f5;
	mul.rn.f32 	%f7, %f6, 0f3D372713;
	add.rn.f32 	%f8, %f1, %f7;
	mul.rn.f32 	%f9, %f8, 0f3F4C422A;
	abs.f32 	%f10, %f9;
	setp.lt.f32 	%p1, %f10, 0f39D1B717;
	setp.lt.f32 	%p2, %f9, 0fC0FCF84F;
	selp.f32 	%f11, 0fC0FCF84F, %f9, %p2;
	setp.gt.f32 	%p3, %f11, 0f40FCF84F;
	selp.f32 	%f12, 0f40FCF84F, %f11, %p3;
	mul.rn.f32 	%f13, %f12, %f12;
	mul.rn.f32 	%f14, %f13, 0f259F25C0;
	mov.f32 	%f15, 0f2A61337E;
	sub.rn.f32 	%f16, %f15, %f14;
	mul.rn.f32 	%f17, %f13, %f16;
	add.rn.f32 	%f18, %f17, 0fAEBD37FF;
	mul.rn.f32 	%f19, %f13, %f18;
	add.rn.f32 	%f20, %f19, 0f335C0041;
	mul.rn.f32 	%f21, %f13, %f20;
	add.rn.f32 	%f22, %f21, 0f3779434A;
	mul.rn.f32 	%f23, %f13, %f22;
	add.rn.f32 	%f24, %f23, 0f3A270DED;
	mul.rn.f32 	%f25, %f13, %f24;
	add.rn.f32 	%f26, %f25, 0f3BA059DC;
	mul.rn.f32 	%f27, %f12, %f26;
	mul.rn.f32 	%f28, %f13, 0f35A0D3D8;
	add.rn.f32 	%f29, %f28, 0f38F895D6;
	mul.rn.f32 	%f30, %f13, %f29;
	add.rn.f32 	%f31, %f30, 0f3B14AA05;
	mul.rn.f32 	%f32, %f13, %f31;
	add.rn.f32 	%f33, %f32, 0f3BA059DD;
	div.full.f32 	%f34, %f27, %f33;
	selp.f32 	%f35, %f9, %f34, %p1;
	mov.b32 	%r12, %f9;
	shr.u32 	%r13, %r12, 31;
	and.b32  	%r14, %r13, 1;
	setp.eq.b32 	%p4, %r14, 1;
	selp.f32 	%f36, 0fBF800000, 0f3F800000, %p4;
	setp.ltu.f32 	%p5, %f10, 0f41A00000;
	selp.f32 	%f37, %f35, %f36, %p5;
	add.rn.f32 	%f38, %f37, 0f3F800000;
	mul.rn.f32 	%f39, %f38, 0f3F000000;
	mul.rn.f32 	%f40, %f1, %f39;
	mul.rn.f32 	%f41, %f40, 0f3F8E38E4;
	and.b32  	%r15, %r8, 1;
	setp.eq.b32 	%p6, %r15, 1;
	selp.f32 	%f42, %f41, 0f00000000, %p6;
	add.s64 	%rd15, %rd6, %rd13;
	add.s64 	%rd16, %rd3, %rd13;
	mul.rn.f32 	%f43, %f2, %f2;
	mul.rn.f32 	%f44, %f2, %f43;
	mul.rn.f32 	%f45, %f44, 0f3D372713;
	add.rn.f32 	%f46, %f2, %f45;
	mul.rn.f32 	%f47, %f46, 0f3F4C422A;
	abs.f32 	%f48, %f47;
	setp.lt.f32 	%p7, %f48, 0f39D1B717;
	setp.lt.f32 	%p8, %f47, 0fC0FCF84F;
	selp.f32 	%f49, 0fC0FCF84F, %f47, %p8;
	setp.gt.f32 	%p9, %f49, 0f40FCF84F;
	selp.f32 	%f50, 0f40FCF84F, %f49, %p9;
	mul.rn.f32 	%f51, %f50, %f50;
	mul.rn.f32 	%f52, %f51, 0f259F25C0;
	sub.rn.f32 	%f53, %f15, %f52;
	mul.rn.f32 	%f54, %f51, %f53;
	add.rn.f32 	%f55, %f54, 0fAEBD37FF;
	mul.rn.f32 	%f56, %f51, %f55;
	add.rn.f32 	%f57, %f56, 0f335C0041;
	mul.rn.f32 	%f58, %f51, %f57;
	add.rn.f32 	%f59, %f58, 0f3779434A;
	mul.rn.f32 	%f60, %f51, %f59;
	add.rn.f32 	%f61, %f60, 0f3A270DED;
	mul.rn.f32 	%f62, %f51, %f61;
	add.rn.f32 	%f63, %f62, 0f3BA059DC;
	mul.rn.f32 	%f64, %f50, %f63;
	mul.rn.f32 	%f65, %f51, 0f35A0D3D8;
	add.rn.f32 	%f66, %f65, 0f38F895D6;
	mul.rn.f32 	%f67, %f51, %f66;
	add.rn.f32 	%f68, %f67, 0f3B14AA05;
	mul.rn.f32 	%f69, %f51, %f68;
	add.rn.f32 	%f70, %f69, 0f3BA059DD;
	div.full.f32 	%f71, %f64, %f70;
	selp.f32 	%f72, %f47, %f71, %p7;
	mov.b32 	%r16, %f47;
	shr.u32 	%r17, %r16, 31;
	and.b32  	%r18, %r17, 1;
	setp.eq.b32 	%p10, %r18, 1;
	selp.f32 	%f73, 0fBF800000, 0f3F800000, %p10;
	setp.ltu.f32 	%p11, %f48, 0f41A00000;
	selp.f32 	%f74, %f72, %f73, %p11;
	add.rn.f32 	%f75, %f74, 0f3F800000;
	mul.rn.f32 	%f76, %f75, 0f3F000000;
	mul.rn.f32 	%f77, %f2, %f76;
	mul.rn.f32 	%f78, %f77, 0f3F8E38E4;
	and.b32  	%r19, %r9, 1;
	setp.eq.b32 	%p12, %r19, 1;
	selp.f32 	%f79, %f78, 0f00000000, %p12;
	mul.rn.f32 	%f80, %f3, %f3;
	mul.rn.f32 	%f81, %f3, %f80;
	mul.rn.f32 	%f82, %f81, 0f3D372713;
	add.rn.f32 	%f83, %f3, %f82;
	mul.rn.f32 	%f84, %f83, 0f3F4C422A;
	abs.f32 	%f85, %f84;
	setp.lt.f32 	%p13, %f85, 0f39D1B717;
	setp.lt.f32 	%p14, %f84, 0fC0FCF84F;
	selp.f32 	%f86, 0fC0FCF84F, %f84, %p14;
	setp.gt.f32 	%p15, %f86, 0f40FCF84F;
	selp.f32 	%f87, 0f40FCF84F, %f86, %p15;
	mul.rn.f32 	%f88, %f87, %f87;
	mul.rn.f32 	%f89, %f88, 0f259F25C0;
	sub.rn.f32 	%f90, %f15, %f89;
	mul.rn.f32 	%f91, %f88, %f90;
	add.rn.f32 	%f92, %f91, 0fAEBD37FF;
	mul.rn.f32 	%f93, %f88, %f92;
	add.rn.f32 	%f94, %f93, 0f335C0041;
	mul.rn.f32 	%f95, %f88, %f94;
	add.rn.f32 	%f96, %f95, 0f3779434A;
	mul.rn.f32 	%f97, %f88, %f96;
	add.rn.f32 	%f98, %f97, 0f3A270DED;
	mul.rn.f32 	%f99, %f88, %f98;
	add.rn.f32 	%f100, %f99, 0f3BA059DC;
	mul.rn.f32 	%f101, %f87, %f100;
	mul.rn.f32 	%f102, %f88, 0f35A0D3D8;
	add.rn.f32 	%f103, %f102, 0f38F895D6;
	mul.rn.f32 	%f104, %f88, %f103;
	add.rn.f32 	%f105, %f104, 0f3B14AA05;
	mul.rn.f32 	%f106, %f88, %f105;
	add.rn.f32 	%f107, %f106, 0f3BA059DD;
	div.full.f32 	%f108, %f101, %f107;
	selp.f32 	%f109, %f84, %f108, %p13;
	mov.b32 	%r20, %f84;
	shr.u32 	%r21, %r20, 31;
	and.b32  	%r22, %r21, 1;
	setp.eq.b32 	%p16, %r22, 1;
	selp.f32 	%f110, 0fBF800000, 0f3F800000, %p16;
	setp.ltu.f32 	%p17, %f85, 0f41A00000;
	selp.f32 	%f111, %f109, %f110, %p17;
	add.rn.f32 	%f112, %f111, 0f3F800000;
	mul.rn.f32 	%f113, %f112, 0f3F000000;
	mul.rn.f32 	%f114, %f3, %f113;
	mul.rn.f32 	%f115, %f114, 0f3F8E38E4;
	and.b32  	%r23, %r10, 1;
	setp.eq.b32 	%p18, %r23, 1;
	selp.f32 	%f116, %f115, 0f00000000, %p18;
	mul.rn.f32 	%f117, %f4, %f4;
	mul.rn.f32 	%f118, %f4, %f117;
	mul.rn.f32 	%f119, %f118, 0f3D372713;
	add.rn.f32 	%f120, %f4, %f119;
	mul.rn.f32 	%f121, %f120, 0f3F4C422A;
	abs.f32 	%f122, %f121;
	setp.lt.f32 	%p19, %f122, 0f39D1B717;
	setp.lt.f32 	%p20, %f121, 0fC0FCF84F;
	selp.f32 	%f123, 0fC0FCF84F, %f121, %p20;
	setp.gt.f32 	%p21, %f123, 0f40FCF84F;
	selp.f32 	%f124, 0f40FCF84F, %f123, %p21;
	mul.rn.f32 	%f125, %f124, %f124;
	mul.rn.f32 	%f126, %f125, 0f259F25C0;
	sub.rn.f32 	%f127, %f15, %f126;
	mul.rn.f32 	%f128, %f125, %f127;
	add.rn.f32 	%f129, %f128, 0fAEBD37FF;
	mul.rn.f32 	%f130, %f125, %f129;
	add.rn.f32 	%f131, %f130, 0f335C0041;
	mul.rn.f32 	%f132, %f125, %f131;
	add.rn.f32 	%f133, %f132, 0f3779434A;
	mul.rn.f32 	%f134, %f125, %f133;
	add.rn.f32 	%f135, %f134, 0f3A270DED;
	mul.rn.f32 	%f136, %f125, %f135;
	add.rn.f32 	%f137, %f136, 0f3BA059DC;
	mul.rn.f32 	%f138, %f124, %f137;
	mul.rn.f32 	%f139, %f125, 0f35A0D3D8;
	add.rn.f32 	%f140, %f139, 0f38F895D6;
	mul.rn.f32 	%f141, %f125, %f140;
	add.rn.f32 	%f142, %f141, 0f3B14AA05;
	mul.rn.f32 	%f143, %f125, %f142;
	add.rn.f32 	%f144, %f143, 0f3BA059DD;
	div.full.f32 	%f145, %f138, %f144;
	selp.f32 	%f146, %f121, %f145, %p19;
	mov.b32 	%r24, %f121;
	shr.u32 	%r25, %r24, 31;
	and.b32  	%r26, %r25, 1;
	setp.eq.b32 	%p22, %r26, 1;
	selp.f32 	%f147, 0fBF800000, 0f3F800000, %p22;
	setp.ltu.f32 	%p23, %f122, 0f41A00000;
	selp.f32 	%f148, %f146, %f147, %p23;
	add.rn.f32 	%f149, %f148, 0f3F800000;
	mul.rn.f32 	%f150, %f149, 0f3F000000;
	mul.rn.f32 	%f151, %f4, %f150;
	mul.rn.f32 	%f152, %f151, 0f3F8E38E4;
	and.b32  	%r27, %r11, 1;
	setp.eq.b32 	%p24, %r27, 1;
	selp.f32 	%f153, %f152, 0f00000000, %p24;
	st.global.v4.f32 	[%rd15], {%f42, %f79, %f116, %f153};
	st.global.v4.f32 	[%rd16], {%f37, %f74, %f111, %f148};
	ret;

}
	// .globl	loop_add_fusion_306
.visible .entry loop_add_fusion_306(
	.param .u64 loop_add_fusion_306_param_0,
	.param .u64 loop_add_fusion_306_param_1,
	.param .u64 loop_add_fusion_306_param_2,
	.param .u64 loop_add_fusion_306_param_3,
	.param .u64 loop_add_fusion_306_param_4,
	.param .u64 loop_add_fusion_306_param_5,
	.param .u64 loop_add_fusion_306_param_6,
	.param .u64 loop_add_fusion_306_param_7
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<25>;
	.reg .f32 	%f<100>;
	.reg .b64 	%rd<33>;

	ld.param.u64 	%rd1, [loop_add_fusion_306_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_306_param_7];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_306_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_306_param_6];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_306_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_306_param_5];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_306_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_306_param_4];
	cvta.to.global.u64 	%rd12, %rd11;
	cvta.to.global.u64 	%rd13, %rd10;
	cvta.to.global.u64 	%rd14, %rd7;
	cvta.to.global.u64 	%rd15, %rd4;
	cvta.to.global.u64 	%rd16, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	shr.u32 	%r6, %r1, 10;
	and.b32  	%r7, %r1, 1023;
	mul.wide.u32 	%rd17, %r6, 4096;
	add.s64 	%rd18, %rd13, %rd17;
	mul.wide.u32 	%rd19, %r7, 4;
	add.s64 	%rd20, %rd18, %rd19;
	ld.global.nc.f32 	%f1, [%rd20];
	cvt.u64.u32 	%rd21, %r4;
	mul.wide.u32 	%rd22, %r4, 4;
	add.s64 	%rd23, %rd14, %rd22;
	ld.global.nc.v4.f32 	{%f2, %f3, %f4, %f5}, [%rd23];
	mul.rn.f32 	%f6, %f1, %f2;
	add.s64 	%rd24, %rd15, %rd22;
	ld.global.nc.v4.f32 	{%f7, %f8, %f9, %f10}, [%rd24];
	add.rn.f32 	%f11, %f6, %f7;
	mul.wide.u32 	%rd25, %r6, 512;
	add.s64 	%rd26, %rd6, %rd25;
	add.s64 	%rd27, %rd26, %rd21;
	ld.global.nc.u32 	%r8, [%rd27];
	bfe.u32 	%r9, %r8, 0, 8;
	bfe.u32 	%r10, %r8, 8, 8;
	bfe.u32 	%r11, %r8, 16, 8;
	bfe.u32 	%r12, %r8, 24, 8;
	mul.wide.u32 	%rd28, %r5, 4;
	add.s64 	%rd29, %rd16, %rd28;
	ld.global.nc.v4.f32 	{%f12, %f13, %f14, %f15}, [%rd29];
	add.s64 	%rd30, %rd12, %rd28;
	ld.global.nc.v4.f32 	{%f16, %f17, %f18, %f19}, [%rd30];
	add.s64 	%rd31, %rd9, %rd22;
	ld.global.nc.v4.f32 	{%f20, %f21, %f22, %f23}, [%rd31];
	add.rn.f32 	%f24, %f16, %f20;
	fma.rn.f32 	%f25, %f24, 0fBBBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f26, %f25;
	mov.f32 	%f27, 0f4B400001;
	mov.f32 	%f28, 0f437C0000;
	fma.rm.f32 	%f29, %f26, %f28, %f27;
	add.rn.f32 	%f30, %f29, 0fCB40007F;
	neg.f32 	%f31, %f30;
	fma.rn.f32 	%f32, %f24, 0fBFB8AA3B, %f31;
	fma.rn.f32 	%f33, %f24, 0fB2A57060, %f32;
	mov.b32 	%r13, %f29;
	shl.b32 	%r14, %r13, 23;
	mov.b32 	%f34, %r14;
	ex2.approx.ftz.f32 	%f35, %f33;
	mul.rn.f32 	%f36, %f35, %f34;
	add.rn.f32 	%f37, %f36, 0f3F800000;
	rcp.approx.f32 	%f38, %f37;
	mul.rn.f32 	%f39, %f12, %f38;
	mul.rn.f32 	%f40, %f39, 0f3F8E38E4;
	and.b32  	%r15, %r9, 1;
	setp.eq.b32 	%p1, %r15, 1;
	selp.f32 	%f41, %f40, 0f00000000, %p1;
	add.rn.f32 	%f42, %f11, %f41;
	add.s64 	%rd32, %rd3, %rd28;
	mul.rn.f32 	%f43, %f1, %f3;
	add.rn.f32 	%f44, %f43, %f8;
	add.rn.f32 	%f45, %f17, %f21;
	fma.rn.f32 	%f46, %f45, 0fBBBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f47, %f46;
	fma.rm.f32 	%f48, %f47, %f28, %f27;
	add.rn.f32 	%f49, %f48, 0fCB40007F;
	neg.f32 	%f50, %f49;
	fma.rn.f32 	%f51, %f45, 0fBFB8AA3B, %f50;
	fma.rn.f32 	%f52, %f45, 0fB2A57060, %f51;
	mov.b32 	%r16, %f48;
	shl.b32 	%r17, %r16, 23;
	mov.b32 	%f53, %r17;
	ex2.approx.ftz.f32 	%f54, %f52;
	mul.rn.f32 	%f55, %f54, %f53;
	add.rn.f32 	%f56, %f55, 0f3F800000;
	rcp.approx.f32 	%f57, %f56;
	mul.rn.f32 	%f58, %f13, %f57;
	mul.rn.f32 	%f59, %f58, 0f3F8E38E4;
	and.b32  	%r18, %r10, 1;
	setp.eq.b32 	%p2, %r18, 1;
	selp.f32 	%f60, %f59, 0f00000000, %p2;
	add.rn.f32 	%f61, %f44, %f60;
	mul.rn.f32 	%f62, %f1, %f4;
	add.rn.f32 	%f63, %f62, %f9;
	add.rn.f32 	%f64, %f18, %f22;
	fma.rn.f32 	%f65, %f64, 0fBBBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f66, %f65;
	fma.rm.f32 	%f67, %f66, %f28, %f27;
	add.rn.f32 	%f68, %f67, 0fCB40007F;
	neg.f32 	%f69, %f68;
	fma.rn.f32 	%f70, %f64, 0fBFB8AA3B, %f69;
	fma.rn.f32 	%f71, %f64, 0fB2A57060, %f70;
	mov.b32 	%r19, %f67;
	shl.b32 	%r20, %r19, 23;
	mov.b32 	%f72, %r20;
	ex2.approx.ftz.f32 	%f73, %f71;
	mul.rn.f32 	%f74, %f73, %f72;
	add.rn.f32 	%f75, %f74, 0f3F800000;
	rcp.approx.f32 	%f76, %f75;
	mul.rn.f32 	%f77, %f14, %f76;
	mul.rn.f32 	%f78, %f77, 0f3F8E38E4;
	and.b32  	%r21, %r11, 1;
	setp.eq.b32 	%p3, %r21, 1;
	selp.f32 	%f79, %f78, 0f00000000, %p3;
	add.rn.f32 	%f80, %f63, %f79;
	mul.rn.f32 	%f81, %f1, %f5;
	add.rn.f32 	%f82, %f81, %f10;
	add.rn.f32 	%f83, %f19, %f23;
	fma.rn.f32 	%f84, %f83, 0fBBBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f85, %f84;
	fma.rm.f32 	%f86, %f85, %f28, %f27;
	add.rn.f32 	%f87, %f86, 0fCB40007F;
	neg.f32 	%f88, %f87;
	fma.rn.f32 	%f89, %f83, 0fBFB8AA3B, %f88;
	fma.rn.f32 	%f90, %f83, 0fB2A57060, %f89;
	mov.b32 	%r22, %f86;
	shl.b32 	%r23, %r22, 23;
	mov.b32 	%f91, %r23;
	ex2.approx.ftz.f32 	%f92, %f90;
	mul.rn.f32 	%f93, %f92, %f91;
	add.rn.f32 	%f94, %f93, 0f3F800000;
	rcp.approx.f32 	%f95, %f94;
	mul.rn.f32 	%f96, %f15, %f95;
	mul.rn.f32 	%f97, %f96, 0f3F8E38E4;
	and.b32  	%r24, %r12, 1;
	setp.eq.b32 	%p4, %r24, 1;
	selp.f32 	%f98, %f97, 0f00000000, %p4;
	add.rn.f32 	%f99, %f82, %f98;
	st.global.v4.f32 	[%rd32], {%f42, %f61, %f80, %f99};
	ret;

}
	// .globl	input_reduce_fusion_292
.visible .entry input_reduce_fusion_292(
	.param .u64 input_reduce_fusion_292_param_0,
	.param .u64 input_reduce_fusion_292_param_1,
	.param .u64 input_reduce_fusion_292_param_2
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<60>;
	.reg .b64 	%rd<49>;
	// demoted variable
	.shared .align 4 .b8 shared_cache4[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache5[4224];
	ld.param.u64 	%rd12, [input_reduce_fusion_292_param_0];
	ld.param.u64 	%rd13, [input_reduce_fusion_292_param_2];
	cvta.to.global.u64 	%rd1, %rd13;
	ld.param.u64 	%rd14, [input_reduce_fusion_292_param_1];
	cvta.to.global.u64 	%rd2, %rd14;
	cvta.to.global.u64 	%rd15, %rd12;
	mov.u32 	%r7, %tid.x;
	mov.u32 	%r8, %ctaid.x;
	shr.u32 	%r1, %r7, 5;
	and.b32  	%r2, %r7, 31;
	shr.u32 	%r9, %r8, 4;
	shl.b32 	%r10, %r8, 5;
	and.b32  	%r3, %r10, 480;
	or.b32  	%r11, %r3, %r2;
	cvt.u64.u32 	%rd3, %r9;
	add.s32 	%r13, %r1, -256;
	mul.wide.u32 	%rd16, %r9, 2097152;
	cvt.u64.u32 	%rd17, %r7;
	shl.b64 	%rd18, %rd17, 6;
	and.b64  	%rd19, %rd18, 274877904896;
	add.s64 	%rd20, %rd16, %rd19;
	mul.wide.u32 	%rd21, %r11, 4;
	or.b64  	%rd22, %rd20, %rd21;
	add.s64 	%rd23, %rd22, %rd15;
	add.s64 	%rd48, %rd23, 262144;
	mov.f32 	%f58, 0f00000000;
	mov.f32 	%f59, %f58;
$L__BB90_1:
	ld.global.nc.f32 	%f8, [%rd48+-262144];
	mul.rn.f32 	%f9, %f8, %f8;
	add.rn.f32 	%f10, %f59, %f9;
	add.rn.f32 	%f11, %f58, %f8;
	ld.global.nc.f32 	%f12, [%rd48+-196608];
	mul.rn.f32 	%f13, %f12, %f12;
	add.rn.f32 	%f14, %f10, %f13;
	add.rn.f32 	%f15, %f11, %f12;
	ld.global.nc.f32 	%f16, [%rd48+-131072];
	mul.rn.f32 	%f17, %f16, %f16;
	add.rn.f32 	%f18, %f14, %f17;
	add.rn.f32 	%f19, %f15, %f16;
	ld.global.nc.f32 	%f20, [%rd48+-65536];
	mul.rn.f32 	%f21, %f20, %f20;
	add.rn.f32 	%f22, %f18, %f21;
	add.rn.f32 	%f23, %f19, %f20;
	ld.global.nc.f32 	%f24, [%rd48];
	mul.rn.f32 	%f25, %f24, %f24;
	add.rn.f32 	%f26, %f22, %f25;
	add.rn.f32 	%f27, %f23, %f24;
	ld.global.nc.f32 	%f28, [%rd48+65536];
	mul.rn.f32 	%f29, %f28, %f28;
	add.rn.f32 	%f30, %f26, %f29;
	add.rn.f32 	%f31, %f27, %f28;
	ld.global.nc.f32 	%f32, [%rd48+131072];
	mul.rn.f32 	%f33, %f32, %f32;
	add.rn.f32 	%f34, %f30, %f33;
	add.rn.f32 	%f35, %f31, %f32;
	ld.global.nc.f32 	%f36, [%rd48+196608];
	mul.rn.f32 	%f37, %f36, %f36;
	add.rn.f32 	%f59, %f34, %f37;
	add.rn.f32 	%f58, %f35, %f36;
	add.s32 	%r13, %r13, 256;
	add.s64 	%rd48, %rd48, 524288;
	setp.lt.u32 	%p1, %r13, 768;
	@%p1 bra 	$L__BB90_1;
	cvt.u64.u32 	%rd7, %r2;
	cvt.u64.u32 	%rd8, %r1;
	mul.wide.u32 	%rd24, %r2, 132;
	mov.u64 	%rd25, shared_cache4;
	add.s64 	%rd26, %rd25, %rd24;
	mul.wide.u32 	%rd27, %r1, 4;
	add.s64 	%rd28, %rd26, %rd27;
	st.shared.f32 	[%rd28], %f59;
	bar.sync 	0;
	mul.wide.u32 	%rd29, %r1, 132;
	add.s64 	%rd30, %rd25, %rd29;
	mul.wide.u32 	%rd31, %r2, 4;
	add.s64 	%rd32, %rd30, %rd31;
	ld.shared.f32 	%f38, [%rd32];
	shfl.sync.down.b32	%f39, %f38, 16, 31, -1;
	add.rn.f32 	%f40, %f38, %f39;
	shfl.sync.down.b32	%f41, %f40, 8, 31, -1;
	add.rn.f32 	%f42, %f40, %f41;
	shfl.sync.down.b32	%f43, %f42, 4, 31, -1;
	add.rn.f32 	%f44, %f42, %f43;
	shfl.sync.down.b32	%f45, %f44, 2, 31, -1;
	add.rn.f32 	%f46, %f44, %f45;
	shfl.sync.down.b32	%f47, %f46, 1, 31, -1;
	add.rn.f32 	%f5, %f46, %f47;
	st.shared.f32 	[%rd32], %f5;
	setp.eq.s32 	%p2, %r2, 0;
	or.b32  	%r12, %r3, %r1;
	shl.b64 	%rd33, %rd3, 11;
	@%p2 bra 	$L__BB90_5;
	bra.uni 	$L__BB90_3;
$L__BB90_5:
	add.s64 	%rd34, %rd2, %rd33;
	mul.wide.u32 	%rd35, %r12, 4;
	add.s64 	%rd10, %rd34, %rd35;
	st.global.f32 	[%rd10], %f5;
$L__BB90_3:
	mul.lo.s64 	%rd36, %rd7, 132;
	mov.u64 	%rd37, shared_cache5;
	add.s64 	%rd38, %rd37, %rd36;
	shl.b64 	%rd39, %rd8, 2;
	add.s64 	%rd40, %rd38, %rd39;
	st.shared.f32 	[%rd40], %f58;
	bar.sync 	0;
	mul.lo.s64 	%rd41, %rd8, 132;
	add.s64 	%rd42, %rd37, %rd41;
	shl.b64 	%rd43, %rd7, 2;
	add.s64 	%rd44, %rd42, %rd43;
	ld.shared.f32 	%f48, [%rd44];
	shfl.sync.down.b32	%f49, %f48, 16, 31, -1;
	add.rn.f32 	%f50, %f48, %f49;
	shfl.sync.down.b32	%f51, %f50, 8, 31, -1;
	add.rn.f32 	%f52, %f50, %f51;
	shfl.sync.down.b32	%f53, %f52, 4, 31, -1;
	add.rn.f32 	%f54, %f52, %f53;
	shfl.sync.down.b32	%f55, %f54, 2, 31, -1;
	add.rn.f32 	%f56, %f54, %f55;
	shfl.sync.down.b32	%f57, %f56, 1, 31, -1;
	add.rn.f32 	%f6, %f56, %f57;
	st.shared.f32 	[%rd44], %f6;
	@%p2 bra 	$L__BB90_6;
	bra.uni 	$L__BB90_4;
$L__BB90_6:
	cvt.u64.u32 	%rd9, %r12;
	add.s64 	%rd46, %rd1, %rd33;
	shl.b64 	%rd47, %rd9, 2;
	add.s64 	%rd11, %rd46, %rd47;
	st.global.f32 	[%rd11], %f6;
$L__BB90_4:
	ret;

}
	// .globl	loop_multiply_fusion_80
.visible .entry loop_multiply_fusion_80(
	.param .u64 loop_multiply_fusion_80_param_0,
	.param .u64 loop_multiply_fusion_80_param_1,
	.param .u64 loop_multiply_fusion_80_param_2,
	.param .u64 loop_multiply_fusion_80_param_3,
	.param .u64 loop_multiply_fusion_80_param_4,
	.param .u64 loop_multiply_fusion_80_param_5,
	.param .u64 loop_multiply_fusion_80_param_6
)
.reqntid 128, 1, 1
{
	.reg .b32 	%r<6>;
	.reg .f32 	%f<37>;
	.reg .b64 	%rd<24>;

	ld.param.u64 	%rd1, [loop_multiply_fusion_80_param_0];
	ld.param.u64 	%rd2, [loop_multiply_fusion_80_param_6];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_multiply_fusion_80_param_1];
	ld.param.u64 	%rd5, [loop_multiply_fusion_80_param_5];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_multiply_fusion_80_param_2];
	ld.param.u64 	%rd8, [loop_multiply_fusion_80_param_4];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_multiply_fusion_80_param_3];
	cvta.to.global.u64 	%rd11, %rd10;
	cvta.to.global.u64 	%rd12, %rd7;
	cvta.to.global.u64 	%rd13, %rd4;
	cvta.to.global.u64 	%rd14, %rd1;
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r2, %r1, 2;
	mov.u32 	%r3, %ctaid.x;
	shl.b32 	%r4, %r3, 9;
	or.b32  	%r5, %r4, %r2;
	mul.wide.u32 	%rd15, %r2, 4;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd16];
	mul.wide.u32 	%rd17, %r5, 4;
	add.s64 	%rd18, %rd11, %rd17;
	ld.global.nc.v4.f32 	{%f5, %f6, %f7, %f8}, [%rd18];
	add.s64 	%rd19, %rd9, %rd15;
	ld.global.nc.v4.f32 	{%f9, %f10, %f11, %f12}, [%rd19];
	sub.rn.f32 	%f13, %f5, %f9;
	add.s64 	%rd20, %rd12, %rd15;
	ld.global.nc.v4.f32 	{%f14, %f15, %f16, %f17}, [%rd20];
	mul.rn.f32 	%f18, %f13, %f14;
	add.s64 	%rd21, %rd13, %rd15;
	ld.global.nc.v4.f32 	{%f19, %f20, %f21, %f22}, [%rd21];
	add.rn.f32 	%f23, %f18, %f19;
	mul.rn.f32 	%f24, %f1, %f23;
	add.s64 	%rd22, %rd6, %rd17;
	add.s64 	%rd23, %rd3, %rd17;
	sub.rn.f32 	%f25, %f6, %f10;
	mul.rn.f32 	%f26, %f25, %f15;
	add.rn.f32 	%f27, %f26, %f20;
	mul.rn.f32 	%f28, %f2, %f27;
	sub.rn.f32 	%f29, %f7, %f11;
	mul.rn.f32 	%f30, %f29, %f16;
	add.rn.f32 	%f31, %f30, %f21;
	mul.rn.f32 	%f32, %f3, %f31;
	sub.rn.f32 	%f33, %f8, %f12;
	mul.rn.f32 	%f34, %f33, %f17;
	add.rn.f32 	%f35, %f34, %f22;
	mul.rn.f32 	%f36, %f4, %f35;
	st.global.v4.f32 	[%rd22], {%f24, %f28, %f32, %f36};
	st.global.v4.f32 	[%rd23], {%f18, %f26, %f30, %f34};
	ret;

}
	// .globl	loop_add_fusion_319
.visible .entry loop_add_fusion_319(
	.param .u64 loop_add_fusion_319_param_0,
	.param .u64 loop_add_fusion_319_param_1,
	.param .u64 loop_add_fusion_319_param_2,
	.param .u64 loop_add_fusion_319_param_3,
	.param .u64 loop_add_fusion_319_param_4,
	.param .u64 loop_add_fusion_319_param_5
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<87>;
	.reg .b64 	%rd<24>;

	ld.param.u64 	%rd1, [loop_add_fusion_319_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_319_param_5];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_319_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_319_param_4];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_319_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_319_param_3];
	cvta.to.global.u64 	%rd9, %rd8;
	cvta.to.global.u64 	%rd10, %rd7;
	cvta.to.global.u64 	%rd11, %rd4;
	cvta.to.global.u64 	%rd12, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	shr.u32 	%r6, %r1, 10;
	mul.wide.u32 	%rd13, %r5, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd14];
	cvt.u64.u32 	%rd15, %r4;
	mul.wide.u32 	%rd16, %r6, 512;
	add.s64 	%rd17, %rd6, %rd16;
	add.s64 	%rd18, %rd17, %rd15;
	ld.global.nc.u32 	%r7, [%rd18];
	bfe.u32 	%r8, %r7, 0, 8;
	bfe.u32 	%r9, %r7, 8, 8;
	bfe.u32 	%r10, %r7, 16, 8;
	bfe.u32 	%r11, %r7, 24, 8;
	add.s64 	%rd19, %rd11, %rd13;
	ld.global.nc.v4.f32 	{%f5, %f6, %f7, %f8}, [%rd19];
	add.s64 	%rd20, %rd10, %rd13;
	ld.global.nc.v4.f32 	{%f9, %f10, %f11, %f12}, [%rd20];
	mul.wide.u32 	%rd21, %r4, 4;
	add.s64 	%rd22, %rd9, %rd21;
	ld.global.nc.v4.f32 	{%f13, %f14, %f15, %f16}, [%rd22];
	add.rn.f32 	%f17, %f9, %f13;
	fma.rn.f32 	%f18, %f17, 0fBBBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f19, %f18;
	mov.f32 	%f20, 0f4B400001;
	mov.f32 	%f21, 0f437C0000;
	fma.rm.f32 	%f22, %f19, %f21, %f20;
	add.rn.f32 	%f23, %f22, 0fCB40007F;
	neg.f32 	%f24, %f23;
	fma.rn.f32 	%f25, %f17, 0fBFB8AA3B, %f24;
	fma.rn.f32 	%f26, %f17, 0fB2A57060, %f25;
	mov.b32 	%r12, %f22;
	shl.b32 	%r13, %r12, 23;
	mov.b32 	%f27, %r13;
	ex2.approx.ftz.f32 	%f28, %f26;
	mul.rn.f32 	%f29, %f28, %f27;
	add.rn.f32 	%f30, %f29, 0f3F800000;
	rcp.approx.f32 	%f31, %f30;
	mul.rn.f32 	%f32, %f5, %f31;
	mul.rn.f32 	%f33, %f32, 0f3F8E38E4;
	and.b32  	%r14, %r8, 1;
	setp.eq.b32 	%p1, %r14, 1;
	selp.f32 	%f34, %f33, 0f00000000, %p1;
	add.rn.f32 	%f35, %f1, %f34;
	add.s64 	%rd23, %rd3, %rd13;
	add.rn.f32 	%f36, %f10, %f14;
	fma.rn.f32 	%f37, %f36, 0fBBBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f38, %f37;
	fma.rm.f32 	%f39, %f38, %f21, %f20;
	add.rn.f32 	%f40, %f39, 0fCB40007F;
	neg.f32 	%f41, %f40;
	fma.rn.f32 	%f42, %f36, 0fBFB8AA3B, %f41;
	fma.rn.f32 	%f43, %f36, 0fB2A57060, %f42;
	mov.b32 	%r15, %f39;
	shl.b32 	%r16, %r15, 23;
	mov.b32 	%f44, %r16;
	ex2.approx.ftz.f32 	%f45, %f43;
	mul.rn.f32 	%f46, %f45, %f44;
	add.rn.f32 	%f47, %f46, 0f3F800000;
	rcp.approx.f32 	%f48, %f47;
	mul.rn.f32 	%f49, %f6, %f48;
	mul.rn.f32 	%f50, %f49, 0f3F8E38E4;
	and.b32  	%r17, %r9, 1;
	setp.eq.b32 	%p2, %r17, 1;
	selp.f32 	%f51, %f50, 0f00000000, %p2;
	add.rn.f32 	%f52, %f2, %f51;
	add.rn.f32 	%f53, %f11, %f15;
	fma.rn.f32 	%f54, %f53, 0fBBBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f55, %f54;
	fma.rm.f32 	%f56, %f55, %f21, %f20;
	add.rn.f32 	%f57, %f56, 0fCB40007F;
	neg.f32 	%f58, %f57;
	fma.rn.f32 	%f59, %f53, 0fBFB8AA3B, %f58;
	fma.rn.f32 	%f60, %f53, 0fB2A57060, %f59;
	mov.b32 	%r18, %f56;
	shl.b32 	%r19, %r18, 23;
	mov.b32 	%f61, %r19;
	ex2.approx.ftz.f32 	%f62, %f60;
	mul.rn.f32 	%f63, %f62, %f61;
	add.rn.f32 	%f64, %f63, 0f3F800000;
	rcp.approx.f32 	%f65, %f64;
	mul.rn.f32 	%f66, %f7, %f65;
	mul.rn.f32 	%f67, %f66, 0f3F8E38E4;
	and.b32  	%r20, %r10, 1;
	setp.eq.b32 	%p3, %r20, 1;
	selp.f32 	%f68, %f67, 0f00000000, %p3;
	add.rn.f32 	%f69, %f3, %f68;
	add.rn.f32 	%f70, %f12, %f16;
	fma.rn.f32 	%f71, %f70, 0fBBBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f72, %f71;
	fma.rm.f32 	%f73, %f72, %f21, %f20;
	add.rn.f32 	%f74, %f73, 0fCB40007F;
	neg.f32 	%f75, %f74;
	fma.rn.f32 	%f76, %f70, 0fBFB8AA3B, %f75;
	fma.rn.f32 	%f77, %f70, 0fB2A57060, %f76;
	mov.b32 	%r21, %f73;
	shl.b32 	%r22, %r21, 23;
	mov.b32 	%f78, %r22;
	ex2.approx.ftz.f32 	%f79, %f77;
	mul.rn.f32 	%f80, %f79, %f78;
	add.rn.f32 	%f81, %f80, 0f3F800000;
	rcp.approx.f32 	%f82, %f81;
	mul.rn.f32 	%f83, %f8, %f82;
	mul.rn.f32 	%f84, %f83, 0f3F8E38E4;
	and.b32  	%r23, %r11, 1;
	setp.eq.b32 	%p4, %r23, 1;
	selp.f32 	%f85, %f84, 0f00000000, %p4;
	add.rn.f32 	%f86, %f4, %f85;
	st.global.v4.f32 	[%rd23], {%f35, %f52, %f69, %f86};
	ret;

}
	// .globl	input_concatenate_fusion_322
.visible .entry input_concatenate_fusion_322(
	.param .u64 input_concatenate_fusion_322_param_0,
	.param .u64 input_concatenate_fusion_322_param_1,
	.param .u64 input_concatenate_fusion_322_param_2,
	.param .u64 input_concatenate_fusion_322_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<92>;
	.reg .f32 	%f<7>;
	.reg .b64 	%rd<17>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_322_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_322_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [input_concatenate_fusion_322_param_1];
	ld.param.u64 	%rd5, [input_concatenate_fusion_322_param_2];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	and.b32  	%r4, %r3, 128;
	or.b32  	%r5, %r4, %r2;
	shr.u32 	%r6, %r1, 1;
	mul.wide.u32 	%rd9, %r6, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.u32 	%r7, [%rd10];
	add.s32 	%r8, %r7, %r5;
	add.s64 	%rd11, %rd6, %rd9;
	ld.global.nc.u32 	%r9, [%rd11];
	add.s32 	%r10, %r9, %r5;
	add.s32 	%r11, %r10, 256;
	add.s32 	%r12, %r8, %r11;
	shf.l.wrap.b32 	%r13, %r11, %r11, 13;
	xor.b32  	%r14, %r12, %r13;
	add.s32 	%r15, %r14, %r12;
	shf.l.wrap.b32 	%r16, %r14, %r14, 15;
	xor.b32  	%r17, %r15, %r16;
	add.s32 	%r18, %r17, %r15;
	shf.l.wrap.b32 	%r19, %r17, %r17, 26;
	xor.b32  	%r20, %r18, %r19;
	add.s32 	%r21, %r20, %r18;
	add.s32 	%r22, %r21, %r9;
	shf.l.wrap.b32 	%r23, %r20, %r20, 6;
	xor.b32  	%r24, %r21, %r23;
	add.s64 	%rd12, %rd7, %rd9;
	ld.global.nc.u32 	%r25, [%rd12];
	add.s32 	%r26, %r25, %r24;
	add.s32 	%r27, %r26, 1;
	add.s32 	%r28, %r22, %r27;
	shf.l.wrap.b32 	%r29, %r27, %r27, 17;
	xor.b32  	%r30, %r28, %r29;
	add.s32 	%r31, %r30, %r28;
	shf.l.wrap.b32 	%r32, %r30, %r30, 29;
	xor.b32  	%r33, %r31, %r32;
	add.s32 	%r34, %r33, %r31;
	shf.l.wrap.b32 	%r35, %r33, %r33, 16;
	xor.b32  	%r36, %r34, %r35;
	add.s32 	%r37, %r36, %r34;
	add.s32 	%r38, %r37, %r25;
	shf.l.wrap.b32 	%r39, %r36, %r36, 24;
	xor.b32  	%r40, %r37, %r39;
	add.s32 	%r41, %r7, %r40;
	add.s32 	%r42, %r41, 2;
	add.s32 	%r43, %r38, %r42;
	shf.l.wrap.b32 	%r44, %r42, %r42, 13;
	xor.b32  	%r45, %r43, %r44;
	add.s32 	%r46, %r45, %r43;
	shf.l.wrap.b32 	%r47, %r45, %r45, 15;
	xor.b32  	%r48, %r46, %r47;
	add.s32 	%r49, %r48, %r46;
	shf.l.wrap.b32 	%r50, %r48, %r48, 26;
	xor.b32  	%r51, %r49, %r50;
	add.s32 	%r52, %r51, %r49;
	add.s32 	%r53, %r52, %r7;
	shf.l.wrap.b32 	%r54, %r51, %r51, 6;
	xor.b32  	%r55, %r52, %r54;
	add.s32 	%r56, %r9, %r55;
	add.s32 	%r57, %r56, 3;
	add.s32 	%r58, %r53, %r57;
	shf.l.wrap.b32 	%r59, %r57, %r57, 17;
	xor.b32  	%r60, %r58, %r59;
	add.s32 	%r61, %r60, %r58;
	shf.l.wrap.b32 	%r62, %r60, %r60, 29;
	xor.b32  	%r63, %r61, %r62;
	add.s32 	%r64, %r63, %r61;
	shf.l.wrap.b32 	%r65, %r63, %r63, 16;
	xor.b32  	%r66, %r64, %r65;
	add.s32 	%r67, %r66, %r64;
	add.s32 	%r68, %r67, %r9;
	shf.l.wrap.b32 	%r69, %r66, %r66, 24;
	xor.b32  	%r70, %r67, %r69;
	add.s32 	%r71, %r25, %r70;
	add.s32 	%r72, %r71, 4;
	add.s32 	%r73, %r68, %r72;
	shf.l.wrap.b32 	%r74, %r72, %r72, 13;
	xor.b32  	%r75, %r73, %r74;
	add.s32 	%r76, %r75, %r73;
	shf.l.wrap.b32 	%r77, %r75, %r75, 15;
	xor.b32  	%r78, %r76, %r77;
	add.s32 	%r79, %r78, %r76;
	shf.l.wrap.b32 	%r80, %r78, %r78, 26;
	xor.b32  	%r81, %r79, %r80;
	add.s32 	%r82, %r81, %r79;
	add.s32 	%r83, %r82, %r25;
	shr.u32 	%r84, %r83, 9;
	or.b32  	%r85, %r84, 1065353216;
	mov.b32 	%f1, %r85;
	add.rn.f32 	%f2, %f1, 0fBF800000;
	max.NaN.f32 	%f3, %f2, 0f00000000;
	setp.lt.f32 	%p1, %f3, 0f3F666666;
	selp.u16 	%rs1, 1, 0, %p1;
	cvt.u64.u32 	%rd13, %r5;
	mul.wide.u32 	%rd14, %r6, 512;
	add.s64 	%rd15, %rd3, %rd14;
	add.s64 	%rd16, %rd15, %rd13;
	st.global.u8 	[%rd16], %rs1;
	shf.l.wrap.b32 	%r86, %r81, %r81, 6;
	xor.b32  	%r87, %r82, %r86;
	add.s32 	%r88, %r7, %r87;
	add.s32 	%r89, %r88, 5;
	shr.u32 	%r90, %r89, 9;
	or.b32  	%r91, %r90, 1065353216;
	mov.b32 	%f4, %r91;
	add.rn.f32 	%f5, %f4, 0fBF800000;
	max.NaN.f32 	%f6, %f5, 0f00000000;
	setp.lt.f32 	%p2, %f6, 0f3F666666;
	selp.u16 	%rs2, 1, 0, %p2;
	st.global.u8 	[%rd16+256], %rs2;
	ret;

}
	// .globl	input_reduce_fusion_307
.visible .entry input_reduce_fusion_307(
	.param .u64 input_reduce_fusion_307_param_0,
	.param .u64 input_reduce_fusion_307_param_1,
	.param .u64 input_reduce_fusion_307_param_2,
	.param .u64 input_reduce_fusion_307_param_3,
	.param .u64 input_reduce_fusion_307_param_4,
	.param .u64 input_reduce_fusion_307_param_5
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<18>;
	.reg .f32 	%f<60>;
	.reg .b64 	%rd<52>;
	// demoted variable
	.shared .align 4 .b8 shared_cache6[4224];
	ld.param.u64 	%rd13, [input_reduce_fusion_307_param_0];
	ld.param.u64 	%rd14, [input_reduce_fusion_307_param_5];
	cvta.to.global.u64 	%rd1, %rd14;
	ld.param.u64 	%rd15, [input_reduce_fusion_307_param_1];
	ld.param.u64 	%rd16, [input_reduce_fusion_307_param_4];
	cvta.to.global.u64 	%rd17, %rd16;
	ld.param.u64 	%rd18, [input_reduce_fusion_307_param_2];
	ld.param.u64 	%rd19, [input_reduce_fusion_307_param_3];
	cvta.to.global.u64 	%rd20, %rd19;
	cvta.to.global.u64 	%rd21, %rd18;
	cvta.to.global.u64 	%rd22, %rd15;
	cvta.to.global.u64 	%rd23, %rd13;
	mov.u32 	%r7, %tid.x;
	mov.u32 	%r8, %ctaid.x;
	shr.u32 	%r1, %r7, 5;
	and.b32  	%r2, %r7, 31;
	shr.u32 	%r9, %r8, 4;
	shl.b32 	%r10, %r8, 5;
	and.b32  	%r3, %r10, 480;
	or.b32  	%r11, %r3, %r2;
	cvt.u64.u32 	%rd2, %r9;
	cvt.u64.u32 	%rd24, %r11;
	mul.wide.u32 	%rd25, %r9, 512;
	add.s64 	%rd26, %rd17, %rd25;
	add.s64 	%rd27, %rd26, %rd24;
	ld.global.nc.u8 	%rs1, [%rd27];
	cvt.u16.u8 	%rs2, %rs1;
	mul.wide.u32 	%rd28, %r11, 4;
	add.s64 	%rd29, %rd20, %rd28;
	ld.global.nc.f32 	%f1, [%rd29];
	and.b16  	%rs3, %rs2, 1;
	setp.eq.b16 	%p1, %rs3, 1;
	add.s32 	%r17, %r1, -64;
	mul.wide.u32 	%rd30, %r9, 2097152;
	cvt.u64.u32 	%rd31, %r7;
	shl.b64 	%rd32, %rd31, 6;
	and.b64  	%rd33, %rd32, 274877904896;
	add.s64 	%rd34, %rd30, %rd33;
	or.b64  	%rd35, %rd34, %rd28;
	add.s64 	%rd36, %rd35, 65536;
	add.s64 	%rd51, %rd21, %rd36;
	add.s64 	%rd50, %rd23, %rd36;
	add.s64 	%rd49, %rd22, %rd36;
	mov.f32 	%f59, 0f00000000;
	mov.f32 	%f12, 0f4B400001;
	mov.f32 	%f13, 0f437C0000;
$L__BB94_1:
	ld.global.nc.f32 	%f6, [%rd50+-65536];
	ld.global.nc.f32 	%f7, [%rd49+-65536];
	ld.global.nc.f32 	%f8, [%rd51+-65536];
	add.rn.f32 	%f9, %f8, %f1;
	fma.rn.f32 	%f10, %f9, 0fBBBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f11, %f10;
	fma.rm.f32 	%f14, %f11, %f13, %f12;
	add.rn.f32 	%f15, %f14, 0fCB40007F;
	neg.f32 	%f16, %f15;
	fma.rn.f32 	%f17, %f9, 0fBFB8AA3B, %f16;
	fma.rn.f32 	%f18, %f9, 0fB2A57060, %f17;
	mov.b32 	%r12, %f14;
	shl.b32 	%r13, %r12, 23;
	mov.b32 	%f19, %r13;
	ex2.approx.ftz.f32 	%f20, %f18;
	mul.rn.f32 	%f21, %f20, %f19;
	add.rn.f32 	%f22, %f21, 0f3F800000;
	rcp.approx.f32 	%f23, %f22;
	mul.rn.f32 	%f24, %f7, %f23;
	mul.rn.f32 	%f25, %f24, 0f3F8E38E4;
	selp.f32 	%f26, %f25, 0f00000000, %p1;
	add.rn.f32 	%f27, %f6, %f26;
	add.rn.f32 	%f28, %f59, %f27;
	ld.global.nc.f32 	%f29, [%rd50];
	ld.global.nc.f32 	%f30, [%rd49];
	ld.global.nc.f32 	%f31, [%rd51];
	add.rn.f32 	%f32, %f31, %f1;
	fma.rn.f32 	%f33, %f32, 0fBBBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f34, %f33;
	fma.rm.f32 	%f35, %f34, %f13, %f12;
	add.rn.f32 	%f36, %f35, 0fCB40007F;
	neg.f32 	%f37, %f36;
	fma.rn.f32 	%f38, %f32, 0fBFB8AA3B, %f37;
	fma.rn.f32 	%f39, %f32, 0fB2A57060, %f38;
	mov.b32 	%r14, %f35;
	shl.b32 	%r15, %r14, 23;
	mov.b32 	%f40, %r15;
	ex2.approx.ftz.f32 	%f41, %f39;
	mul.rn.f32 	%f42, %f41, %f40;
	add.rn.f32 	%f43, %f42, 0f3F800000;
	rcp.approx.f32 	%f44, %f43;
	mul.rn.f32 	%f45, %f30, %f44;
	mul.rn.f32 	%f46, %f45, 0f3F8E38E4;
	selp.f32 	%f47, %f46, 0f00000000, %p1;
	add.rn.f32 	%f48, %f29, %f47;
	add.rn.f32 	%f59, %f28, %f48;
	add.s32 	%r17, %r17, 64;
	add.s64 	%rd51, %rd51, 131072;
	add.s64 	%rd50, %rd50, 131072;
	add.s64 	%rd49, %rd49, 131072;
	setp.lt.u32 	%p2, %r17, 960;
	@%p2 bra 	$L__BB94_1;
	mul.wide.u32 	%rd37, %r2, 132;
	mov.u64 	%rd38, shared_cache6;
	add.s64 	%rd39, %rd38, %rd37;
	mul.wide.u32 	%rd40, %r1, 4;
	add.s64 	%rd41, %rd39, %rd40;
	st.shared.f32 	[%rd41], %f59;
	bar.sync 	0;
	mul.wide.u32 	%rd42, %r1, 132;
	add.s64 	%rd43, %rd38, %rd42;
	mul.wide.u32 	%rd44, %r2, 4;
	add.s64 	%rd45, %rd43, %rd44;
	ld.shared.f32 	%f49, [%rd45];
	shfl.sync.down.b32	%f50, %f49, 16, 31, -1;
	add.rn.f32 	%f51, %f49, %f50;
	shfl.sync.down.b32	%f52, %f51, 8, 31, -1;
	add.rn.f32 	%f53, %f51, %f52;
	shfl.sync.down.b32	%f54, %f53, 4, 31, -1;
	add.rn.f32 	%f55, %f53, %f54;
	shfl.sync.down.b32	%f56, %f55, 2, 31, -1;
	add.rn.f32 	%f57, %f55, %f56;
	shfl.sync.down.b32	%f58, %f57, 1, 31, -1;
	add.rn.f32 	%f4, %f57, %f58;
	st.shared.f32 	[%rd45], %f4;
	setp.ne.s32 	%p3, %r2, 0;
	@%p3 bra 	$L__BB94_4;
	or.b32  	%r16, %r3, %r1;
	shl.b64 	%rd46, %rd2, 11;
	add.s64 	%rd47, %rd1, %rd46;
	mul.wide.u32 	%rd48, %r16, 4;
	add.s64 	%rd12, %rd47, %rd48;
	st.global.f32 	[%rd12], %f4;
$L__BB94_4:
	ret;

}
	// .globl	gemm_fusion_dot_16167_1
.visible .entry gemm_fusion_dot_16167_1(
	.param .u64 gemm_fusion_dot_16167_1_param_0,
	.param .u64 gemm_fusion_dot_16167_1_param_1,
	.param .u64 gemm_fusion_dot_16167_1_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<137>;
	.reg .f32 	%f<41>;
	.reg .b64 	%rd<62>;

	ld.param.u64 	%rd5, [gemm_fusion_dot_16167_1_param_0];
	ld.param.u64 	%rd6, [gemm_fusion_dot_16167_1_param_2];
	cvta.to.global.u64 	%rd7, %rd6;
	ld.param.u64 	%rd8, [gemm_fusion_dot_16167_1_param_1];
	cvta.to.global.u64 	%rd9, %rd8;
	cvta.to.global.u64 	%rd10, %rd5;
	// begin inline asm
	mov.u32 %r1, %ctaid.x;
	// end inline asm
	// begin inline asm
	mov.u32 %r2, %ctaid.z;
	// end inline asm
	shr.s32 	%r65, %r1, 31;
	shr.u32 	%r66, %r65, 29;
	add.s32 	%r67, %r1, %r66;
	and.b32  	%r68, %r67, -8;
	mov.b32 	%r69, 4;
	sub.s32 	%r70, %r69, %r68;
	min.s32 	%r71, %r70, 8;
	rem.s32 	%r72, %r1, %r71;
	add.s32 	%r73, %r68, %r72;
	sub.s32 	%r74, %r1, %r68;
	div.s32 	%r75, %r74, %r71;
	shl.b32 	%r76, %r73, 4;
	shl.b32 	%r77, %r2, 5;
	cvt.s64.s32 	%rd11, %r76;
	cvt.s64.s32 	%rd12, %r77;
	shl.b32 	%r78, %r75, 4;
	cvt.s64.s32 	%rd13, %r78;
	mov.u32 	%r79, %tid.x;
	shr.u32 	%r80, %r79, 5;
	shr.u32 	%r81, %r79, 3;
	shl.b32 	%r82, %r79, 1;
	and.b32  	%r83, %r82, 14;
	cvt.u64.u32 	%rd14, %r81;
	cvt.u64.u32 	%rd15, %r83;
	or.b64  	%rd16, %rd11, %rd14;
	shl.b32 	%r84, %r79, 2;
	and.b32  	%r85, %r84, 28;
	or.b32  	%r86, %r81, 16;
	cvt.u64.u32 	%rd17, %r85;
	cvt.u64.u32 	%rd18, %r86;
	or.b64  	%rd19, %rd12, %rd17;
	or.b64  	%rd20, %rd12, %rd14;
	or.b64  	%rd21, %rd12, %rd18;
	shl.b64 	%rd22, %rd16, 11;
	add.s64 	%rd23, %rd10, %rd22;
	shl.b64 	%rd24, %rd19, 2;
	add.s64 	%rd1, %rd23, %rd24;
	setp.lt.u64 	%p1, %rd16, 50;
	mov.b32 	%r7, 0;
	// begin inline asm
	mov.u32 %r3, 0x0;
	mov.u32 %r4, 0x0;
	mov.u32 %r5, 0x0;
	mov.u32 %r6, 0x0;
	@%p1 ld.global.v4.b32 { %r3, %r4, %r5, %r6 }, [ %rd1 + 0 ];
	@!%p1 mov.u32 %r3, %r7;
	@!%p1 mov.u32 %r4, %r7;
	@!%p1 mov.u32 %r5, %r7;
	@!%p1 mov.u32 %r6, %r7;
	// end inline asm
	or.b64  	%rd25, %rd13, %rd15;
	mul.lo.s64 	%rd26, %rd20, 40;
	add.s64 	%rd27, %rd9, %rd26;
	shl.b64 	%rd28, %rd25, 2;
	add.s64 	%rd2, %rd27, %rd28;
	mul.lo.s64 	%rd29, %rd21, 40;
	add.s64 	%rd30, %rd9, %rd29;
	add.s64 	%rd3, %rd30, %rd28;
	setp.lt.u64 	%p6, %rd25, 10;
	// begin inline asm
	mov.u32 %r11, 0x0;
	mov.u32 %r12, 0x0;
	@%p6 ld.global.v2.b32 { %r11, %r12 }, [ %rd2 + 0 ];
	@!%p6 mov.u32 %r11, %r7;
	@!%p6 mov.u32 %r12, %r7;
	// end inline asm
	// begin inline asm
	mov.u32 %r15, 0x0;
	mov.u32 %r16, 0x0;
	@%p6 ld.global.v2.b32 { %r15, %r16 }, [ %rd3 + 0 ];
	@!%p6 mov.u32 %r15, %r7;
	@!%p6 mov.u32 %r16, %r7;
	// end inline asm
	shr.u32 	%r87, %r79, 1;
	and.b32  	%r88, %r87, 8;
	xor.b32  	%r89, %r83, %r88;
	shl.b32 	%r90, %r81, 4;
	or.b32  	%r91, %r89, %r90;
	mul.wide.u32 	%rd31, %r91, 4;
	mov.u64 	%rd32, global_smem;
	add.s64 	%rd33, %rd32, %rd31;
	st.shared.v2.u32 	[%rd33], {%r11, %r12};
	shl.b32 	%r92, %r86, 4;
	or.b32  	%r93, %r92, %r89;
	mul.wide.u32 	%rd34, %r93, 4;
	add.s64 	%rd35, %rd32, %rd34;
	st.shared.v2.u32 	[%rd35], {%r15, %r16};
	mov.b32 	%f33, %r3;
	mov.b32 	%f34, %r4;
	mov.b32 	%f35, %r5;
	mov.b32 	%f36, %r6;
	mul.rn.f32 	%f37, %f36, 0f3A800000;
	mul.rn.f32 	%f38, %f35, 0f3A800000;
	mul.rn.f32 	%f39, %f34, 0f3A800000;
	mul.rn.f32 	%f40, %f33, 0f3A800000;
	xor.b32  	%r94, %r87, %r84;
	and.b32  	%r95, %r94, 28;
	shl.b32 	%r96, %r81, 5;
	or.b32  	%r97, %r95, %r96;
	mul.wide.u32 	%rd36, %r97, 4;
	add.s64 	%rd37, %rd32, 2048;
	add.s64 	%rd38, %rd37, %rd36;
	st.shared.v4.f32 	[%rd38], {%f40, %f39, %f38, %f37};
	bar.sync 	0;
	and.b32  	%r98, %r79, 7;
	bfe.u32 	%r99, %r79, 3, 2;
	bfe.u32 	%r100, %r79, 4, 1;
	xor.b32  	%r101, %r100, %r98;
	shl.b32 	%r102, %r101, 4;
	shl.b32 	%r103, %r79, 7;
	and.b32  	%r104, %r103, 1920;
	or.b32  	%r105, %r102, %r104;
	cvt.u64.u32 	%rd39, %r105;
	add.s64 	%rd40, %rd37, %rd39;
	cvt.u32.u64 	%r23, %rd40;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r39, %r40, %r41, %r42 }, [ %r23 + 0 ];
	// end inline asm
	or.b32  	%r106, %r100, 2;
	xor.b32  	%r107, %r106, %r98;
	shl.b32 	%r108, %r107, 4;
	or.b32  	%r109, %r108, %r104;
	cvt.u64.u32 	%rd41, %r109;
	add.s64 	%rd42, %rd37, %rd41;
	cvt.u32.u64 	%r28, %rd42;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r45, %r46, %r47, %r48 }, [ %r28 + 0 ];
	// end inline asm
	or.b32  	%r110, %r100, 4;
	xor.b32  	%r111, %r110, %r98;
	shl.b32 	%r112, %r111, 4;
	or.b32  	%r113, %r112, %r104;
	cvt.u64.u32 	%rd43, %r113;
	add.s64 	%rd44, %rd37, %rd43;
	cvt.u32.u64 	%r33, %rd44;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r51, %r52, %r53, %r54 }, [ %r33 + 0 ];
	// end inline asm
	or.b32  	%r114, %r100, 6;
	xor.b32  	%r115, %r114, %r98;
	shl.b32 	%r116, %r115, 4;
	or.b32  	%r117, %r116, %r104;
	cvt.u64.u32 	%rd45, %r117;
	add.s64 	%rd46, %rd37, %rd45;
	cvt.u32.u64 	%r38, %rd46;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r57, %r58, %r59, %r60 }, [ %r38 + 0 ];
	// end inline asm
	bfe.u32 	%r118, %r79, 5, 1;
	bfe.u32 	%r119, %r79, 2, 3;
	and.b32  	%r120, %r79, 3;
	bfe.u32 	%r121, %r79, 1, 1;
	xor.b32  	%r122, %r118, %r121;
	shl.b32 	%r123, %r122, 3;
	shl.b32 	%r124, %r120, 4;
	or.b32  	%r125, %r123, %r124;
	or.b32  	%r126, %r125, %r119;
	mul.wide.u32 	%rd47, %r126, 4;
	add.s64 	%rd48, %rd32, %rd47;
	ld.shared.u32 	%r43, [%rd48];
	ld.shared.u32 	%r44, [%rd48+256];
	ld.shared.u32 	%r49, [%rd48+512];
	ld.shared.u32 	%r50, [%rd48+768];
	ld.shared.u32 	%r55, [%rd48+1024];
	ld.shared.u32 	%r56, [%rd48+1280];
	ld.shared.u32 	%r61, [%rd48+1536];
	ld.shared.u32 	%r62, [%rd48+1792];
	mov.f32 	%f9, 0f00000000;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f9;
	mov.f32 	%f12, %f9;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r39, %r40, %r41, %r42 }, { %r43, %r44 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r45, %r46, %r47, %r48 }, { %r49, %r50 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r51, %r52, %r53, %r54 }, { %r55, %r56 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r57, %r58, %r59, %r60 }, { %r61, %r62 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	mul.lo.s32 	%r127, %r2, 500;
	mul.wide.s32 	%rd49, %r127, 4;
	add.s64 	%rd50, %rd7, %rd49;
	mul.lo.s64 	%rd51, %rd16, 40;
	add.s64 	%rd52, %rd50, %rd51;
	add.s64 	%rd4, %rd52, %rd28;
	and.pred  	%p12, %p6, %p1;
	bar.sync 	0;
	shl.b32 	%r128, %r120, 1;
	shl.b32 	%r129, %r118, 3;
	or.b32  	%r130, %r129, %r128;
	mul.lo.s32 	%r131, %r119, 18;
	add.s32 	%r132, %r130, %r131;
	mul.wide.u32 	%rd53, %r132, 4;
	add.s64 	%rd54, %rd32, %rd53;
	st.shared.v2.f32 	[%rd54], {%f9, %f10};
	cvt.u64.u32 	%rd55, %r130;
	cvt.u64.u32 	%rd56, %r131;
	add.s64 	%rd57, %rd56, %rd55;
	shl.b64 	%rd58, %rd57, 2;
	add.s64 	%rd59, %rd32, %rd58;
	st.shared.v2.f32 	[%rd59+576], {%f11, %f12};
	bar.sync 	0;
	shl.b32 	%r133, %r80, 2;
	or.b32  	%r134, %r133, %r99;
	shl.b32 	%r135, %r98, 1;
	mad.lo.s32 	%r136, %r134, 18, %r135;
	mul.wide.u32 	%rd60, %r136, 4;
	add.s64 	%rd61, %rd32, %rd60;
	ld.shared.v2.u32 	{%r63, %r64}, [%rd61];
	// begin inline asm
	@%p12 st.global.v2.b32 [ %rd4 + 0 ], { %r63, %r64 };
	// end inline asm
	ret;

}
	// .globl	loop_add_fusion_370
.visible .entry loop_add_fusion_370(
	.param .u64 loop_add_fusion_370_param_0,
	.param .u64 loop_add_fusion_370_param_1,
	.param .u64 loop_add_fusion_370_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<7>;
	.reg .f32 	%f<35>;
	.reg .b64 	%rd<14>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 7;
	or.b32  	%r1, %r4, %r3;
	setp.gt.u32 	%p1, %r1, 499;
	@%p1 bra 	$L__BB96_2;
	ld.param.u64 	%rd4, [loop_add_fusion_370_param_0];
	ld.param.u64 	%rd5, [loop_add_fusion_370_param_2];
	cvta.to.global.u64 	%rd1, %rd5;
	ld.param.u64 	%rd6, [loop_add_fusion_370_param_1];
	cvta.to.global.u64 	%rd2, %rd6;
	cvta.to.global.u64 	%rd3, %rd4;
	cvt.u16.u32 	%rs1, %r1;
	mul.hi.u16 	%rs2, %rs1, -13107;
	shr.u16 	%rs3, %rs2, 3;
	mul.lo.s16 	%rs4, %rs3, 10;
	sub.s16 	%rs5, %rs1, %rs4;
	cvt.u32.u16 	%r5, %rs3;
	mul.wide.u32 	%rd7, %r5, 40;
	add.s64 	%rd8, %rd3, %rd7;
	cvt.u32.u16 	%r6, %rs5;
	mul.wide.u32 	%rd9, %r6, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	add.rn.f32 	%f2, %f1, 0f00000000;
	ld.global.nc.f32 	%f3, [%rd10+2000];
	add.rn.f32 	%f4, %f2, %f3;
	ld.global.nc.f32 	%f5, [%rd10+4000];
	add.rn.f32 	%f6, %f4, %f5;
	ld.global.nc.f32 	%f7, [%rd10+6000];
	add.rn.f32 	%f8, %f6, %f7;
	ld.global.nc.f32 	%f9, [%rd10+8000];
	add.rn.f32 	%f10, %f8, %f9;
	ld.global.nc.f32 	%f11, [%rd10+10000];
	add.rn.f32 	%f12, %f10, %f11;
	ld.global.nc.f32 	%f13, [%rd10+12000];
	add.rn.f32 	%f14, %f12, %f13;
	ld.global.nc.f32 	%f15, [%rd10+14000];
	add.rn.f32 	%f16, %f14, %f15;
	ld.global.nc.f32 	%f17, [%rd10+16000];
	add.rn.f32 	%f18, %f16, %f17;
	ld.global.nc.f32 	%f19, [%rd10+18000];
	add.rn.f32 	%f20, %f18, %f19;
	ld.global.nc.f32 	%f21, [%rd10+20000];
	add.rn.f32 	%f22, %f20, %f21;
	ld.global.nc.f32 	%f23, [%rd10+22000];
	add.rn.f32 	%f24, %f22, %f23;
	ld.global.nc.f32 	%f25, [%rd10+24000];
	add.rn.f32 	%f26, %f24, %f25;
	ld.global.nc.f32 	%f27, [%rd10+26000];
	add.rn.f32 	%f28, %f26, %f27;
	ld.global.nc.f32 	%f29, [%rd10+28000];
	add.rn.f32 	%f30, %f28, %f29;
	ld.global.nc.f32 	%f31, [%rd10+30000];
	add.rn.f32 	%f32, %f30, %f31;
	add.s64 	%rd11, %rd2, %rd9;
	ld.global.nc.f32 	%f33, [%rd11];
	add.rn.f32 	%f34, %f32, %f33;
	mul.wide.u32 	%rd12, %r1, 4;
	add.s64 	%rd13, %rd1, %rd12;
	st.global.f32 	[%rd13], %f34;
$L__BB96_2:
	ret;

}
	// .globl	loop_reduce_fusion_43
.visible .entry loop_reduce_fusion_43(
	.param .u64 loop_reduce_fusion_43_param_0,
	.param .u64 loop_reduce_fusion_43_param_1,
	.param .u64 loop_reduce_fusion_43_param_2
)
.reqntid 50, 1, 1
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<26>;
	.reg .f32 	%f<163>;
	.reg .b64 	%rd<12>;

	ld.param.u64 	%rd1, [loop_reduce_fusion_43_param_0];
	ld.param.u64 	%rd2, [loop_reduce_fusion_43_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_reduce_fusion_43_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %tid.x;
	mul.wide.u32 	%rd7, %r1, 40;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.nc.v2.f32 	{%f1, %f2}, [%rd8];
	max.NaN.f32 	%f3, %f1, %f2;
	ld.global.nc.v2.f32 	{%f4, %f5}, [%rd8+8];
	max.NaN.f32 	%f6, %f3, %f4;
	max.NaN.f32 	%f7, %f6, %f5;
	ld.global.nc.v2.f32 	{%f8, %f9}, [%rd8+16];
	max.NaN.f32 	%f10, %f7, %f8;
	max.NaN.f32 	%f11, %f10, %f9;
	ld.global.nc.v2.f32 	{%f12, %f13}, [%rd8+24];
	max.NaN.f32 	%f14, %f11, %f12;
	max.NaN.f32 	%f15, %f14, %f13;
	ld.global.nc.v2.f32 	{%f16, %f17}, [%rd8+32];
	max.NaN.f32 	%f18, %f15, %f16;
	max.NaN.f32 	%f19, %f18, %f17;
	sub.rn.f32 	%f20, %f1, %f19;
	fma.rn.f32 	%f21, %f20, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f22, %f21;
	mov.f32 	%f23, 0f4B400001;
	mov.f32 	%f24, 0f437C0000;
	fma.rm.f32 	%f25, %f22, %f24, %f23;
	add.rn.f32 	%f26, %f25, 0fCB40007F;
	neg.f32 	%f27, %f26;
	fma.rn.f32 	%f28, %f20, 0f3FB8AA3B, %f27;
	fma.rn.f32 	%f29, %f20, 0f32A57060, %f28;
	mov.b32 	%r2, %f25;
	shl.b32 	%r3, %r2, 23;
	mov.b32 	%f30, %r3;
	ex2.approx.ftz.f32 	%f31, %f29;
	mul.rn.f32 	%f32, %f31, %f30;
	add.rn.f32 	%f33, %f32, 0f00000000;
	sub.rn.f32 	%f34, %f2, %f19;
	fma.rn.f32 	%f35, %f34, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f36, %f35;
	fma.rm.f32 	%f37, %f36, %f24, %f23;
	add.rn.f32 	%f38, %f37, 0fCB40007F;
	neg.f32 	%f39, %f38;
	fma.rn.f32 	%f40, %f34, 0f3FB8AA3B, %f39;
	fma.rn.f32 	%f41, %f34, 0f32A57060, %f40;
	mov.b32 	%r4, %f37;
	shl.b32 	%r5, %r4, 23;
	mov.b32 	%f42, %r5;
	ex2.approx.ftz.f32 	%f43, %f41;
	mul.rn.f32 	%f44, %f43, %f42;
	add.rn.f32 	%f45, %f33, %f44;
	sub.rn.f32 	%f46, %f4, %f19;
	fma.rn.f32 	%f47, %f46, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f48, %f47;
	fma.rm.f32 	%f49, %f48, %f24, %f23;
	add.rn.f32 	%f50, %f49, 0fCB40007F;
	neg.f32 	%f51, %f50;
	fma.rn.f32 	%f52, %f46, 0f3FB8AA3B, %f51;
	fma.rn.f32 	%f53, %f46, 0f32A57060, %f52;
	mov.b32 	%r6, %f49;
	shl.b32 	%r7, %r6, 23;
	mov.b32 	%f54, %r7;
	ex2.approx.ftz.f32 	%f55, %f53;
	mul.rn.f32 	%f56, %f55, %f54;
	add.rn.f32 	%f57, %f45, %f56;
	sub.rn.f32 	%f58, %f5, %f19;
	fma.rn.f32 	%f59, %f58, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f60, %f59;
	fma.rm.f32 	%f61, %f60, %f24, %f23;
	add.rn.f32 	%f62, %f61, 0fCB40007F;
	neg.f32 	%f63, %f62;
	fma.rn.f32 	%f64, %f58, 0f3FB8AA3B, %f63;
	fma.rn.f32 	%f65, %f58, 0f32A57060, %f64;
	mov.b32 	%r8, %f61;
	shl.b32 	%r9, %r8, 23;
	mov.b32 	%f66, %r9;
	ex2.approx.ftz.f32 	%f67, %f65;
	mul.rn.f32 	%f68, %f67, %f66;
	add.rn.f32 	%f69, %f57, %f68;
	sub.rn.f32 	%f70, %f8, %f19;
	fma.rn.f32 	%f71, %f70, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f72, %f71;
	fma.rm.f32 	%f73, %f72, %f24, %f23;
	add.rn.f32 	%f74, %f73, 0fCB40007F;
	neg.f32 	%f75, %f74;
	fma.rn.f32 	%f76, %f70, 0f3FB8AA3B, %f75;
	fma.rn.f32 	%f77, %f70, 0f32A57060, %f76;
	mov.b32 	%r10, %f73;
	shl.b32 	%r11, %r10, 23;
	mov.b32 	%f78, %r11;
	ex2.approx.ftz.f32 	%f79, %f77;
	mul.rn.f32 	%f80, %f79, %f78;
	add.rn.f32 	%f81, %f69, %f80;
	sub.rn.f32 	%f82, %f9, %f19;
	fma.rn.f32 	%f83, %f82, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f84, %f83;
	fma.rm.f32 	%f85, %f84, %f24, %f23;
	add.rn.f32 	%f86, %f85, 0fCB40007F;
	neg.f32 	%f87, %f86;
	fma.rn.f32 	%f88, %f82, 0f3FB8AA3B, %f87;
	fma.rn.f32 	%f89, %f82, 0f32A57060, %f88;
	mov.b32 	%r12, %f85;
	shl.b32 	%r13, %r12, 23;
	mov.b32 	%f90, %r13;
	ex2.approx.ftz.f32 	%f91, %f89;
	mul.rn.f32 	%f92, %f91, %f90;
	add.rn.f32 	%f93, %f81, %f92;
	sub.rn.f32 	%f94, %f12, %f19;
	fma.rn.f32 	%f95, %f94, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f96, %f95;
	fma.rm.f32 	%f97, %f96, %f24, %f23;
	add.rn.f32 	%f98, %f97, 0fCB40007F;
	neg.f32 	%f99, %f98;
	fma.rn.f32 	%f100, %f94, 0f3FB8AA3B, %f99;
	fma.rn.f32 	%f101, %f94, 0f32A57060, %f100;
	mov.b32 	%r14, %f97;
	shl.b32 	%r15, %r14, 23;
	mov.b32 	%f102, %r15;
	ex2.approx.ftz.f32 	%f103, %f101;
	mul.rn.f32 	%f104, %f103, %f102;
	add.rn.f32 	%f105, %f93, %f104;
	sub.rn.f32 	%f106, %f13, %f19;
	fma.rn.f32 	%f107, %f106, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f108, %f107;
	fma.rm.f32 	%f109, %f108, %f24, %f23;
	add.rn.f32 	%f110, %f109, 0fCB40007F;
	neg.f32 	%f111, %f110;
	fma.rn.f32 	%f112, %f106, 0f3FB8AA3B, %f111;
	fma.rn.f32 	%f113, %f106, 0f32A57060, %f112;
	mov.b32 	%r16, %f109;
	shl.b32 	%r17, %r16, 23;
	mov.b32 	%f114, %r17;
	ex2.approx.ftz.f32 	%f115, %f113;
	mul.rn.f32 	%f116, %f115, %f114;
	add.rn.f32 	%f117, %f105, %f116;
	sub.rn.f32 	%f118, %f16, %f19;
	fma.rn.f32 	%f119, %f118, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f120, %f119;
	fma.rm.f32 	%f121, %f120, %f24, %f23;
	add.rn.f32 	%f122, %f121, 0fCB40007F;
	neg.f32 	%f123, %f122;
	fma.rn.f32 	%f124, %f118, 0f3FB8AA3B, %f123;
	fma.rn.f32 	%f125, %f118, 0f32A57060, %f124;
	mov.b32 	%r18, %f121;
	shl.b32 	%r19, %r18, 23;
	mov.b32 	%f126, %r19;
	ex2.approx.ftz.f32 	%f127, %f125;
	mul.rn.f32 	%f128, %f127, %f126;
	add.rn.f32 	%f129, %f117, %f128;
	sub.rn.f32 	%f130, %f17, %f19;
	fma.rn.f32 	%f131, %f130, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f132, %f131;
	fma.rm.f32 	%f133, %f132, %f24, %f23;
	add.rn.f32 	%f134, %f133, 0fCB40007F;
	neg.f32 	%f135, %f134;
	fma.rn.f32 	%f136, %f130, 0f3FB8AA3B, %f135;
	fma.rn.f32 	%f137, %f130, 0f32A57060, %f136;
	mov.b32 	%r20, %f133;
	shl.b32 	%r21, %r20, 23;
	mov.b32 	%f138, %r21;
	ex2.approx.ftz.f32 	%f139, %f137;
	mul.rn.f32 	%f140, %f139, %f138;
	add.rn.f32 	%f141, %f129, %f140;
	setp.lt.f32 	%p1, %f141, 0f00800000;
	mul.rn.f32 	%f142, %f141, 0f4B000000;
	selp.f32 	%f143, %f142, %f141, %p1;
	setp.eq.f32 	%p2, %f143, 0f00000000;
	mov.b32 	%r22, %f143;
	setp.gt.u32 	%p3, %r22, 2139095039;
	fma.rn.f32 	%f144, %f143, 0f7F800000, 0f7F800000;
	add.s32 	%r23, %r22, -1059760811;
	and.b32  	%r24, %r23, -8388608;
	cvt.rn.f32.s32 	%f145, %r24;
	selp.f32 	%f146, 0fC1B80000, 0f00000000, %p1;
	fma.rn.f32 	%f147, %f145, 0f34000000, %f146;
	sub.s32 	%r25, %r22, %r24;
	mov.b32 	%f148, %r25;
	add.rn.f32 	%f149, %f148, 0fBF800000;
	fma.rn.f32 	%f150, %f149, 0fBE055027, 0f3E1039F6;
	fma.rn.f32 	%f151, %f150, %f149, 0fBDF8CDCC;
	fma.rn.f32 	%f152, %f151, %f149, 0f3E0F2955;
	fma.rn.f32 	%f153, %f152, %f149, 0fBE2AD8B9;
	fma.rn.f32 	%f154, %f153, %f149, 0f3E4CED0B;
	fma.rn.f32 	%f155, %f154, %f149, 0fBE7FFF22;
	fma.rn.f32 	%f156, %f155, %f149, 0f3EAAAA78;
	fma.rn.f32 	%f157, %f156, %f149, 0fBF000000;
	mul.rn.f32 	%f158, %f149, %f157;
	fma.rn.f32 	%f159, %f158, %f149, %f149;
	fma.rn.f32 	%f160, %f147, 0f3F317218, %f159;
	selp.f32 	%f161, %f144, %f160, %p3;
	selp.f32 	%f162, 0fFF800000, %f161, %p2;
	mul.wide.u32 	%rd9, %r1, 4;
	add.s64 	%rd10, %rd5, %rd9;
	st.global.f32 	[%rd10], %f162;
	add.s64 	%rd11, %rd3, %rd9;
	st.global.f32 	[%rd11], %f19;
	ret;

}
	// .globl	input_add_reduce_fusion_38
.visible .entry input_add_reduce_fusion_38(
	.param .u64 input_add_reduce_fusion_38_param_0,
	.param .u64 input_add_reduce_fusion_38_param_1,
	.param .u64 input_add_reduce_fusion_38_param_2,
	.param .u64 input_add_reduce_fusion_38_param_3,
	.param .u64 input_add_reduce_fusion_38_param_4,
	.param .u64 input_add_reduce_fusion_38_param_5
)
.reqntid 32, 1, 1
{
	.reg .pred 	%p<100>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<295>;
	.reg .f32 	%f<1555>;
	.reg .b64 	%rd<117>;
	// demoted variable
	.shared .align 4 .f32 shared_cache7_$_0;
	ld.param.u64 	%rd7, [input_add_reduce_fusion_38_param_0];
	ld.param.u64 	%rd8, [input_add_reduce_fusion_38_param_5];
	cvta.to.global.u64 	%rd1, %rd8;
	ld.param.u64 	%rd9, [input_add_reduce_fusion_38_param_1];
	ld.param.u64 	%rd11, [input_add_reduce_fusion_38_param_2];
	ld.param.u64 	%rd12, [input_add_reduce_fusion_38_param_3];
	cvta.to.global.u64 	%rd3, %rd12;
	cvta.to.global.u64 	%rd4, %rd11;
	cvta.to.global.u64 	%rd5, %rd9;
	cvta.to.global.u64 	%rd6, %rd7;
	mov.u32 	%r1, %tid.x;
	cvt.u16.u32 	%rs1, %r1;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 205;
	shr.u16 	%rs4, %rs3, 10;
	cvt.u32.u16 	%r3, %rs4;
	mul.wide.u32 	%rd13, %r3, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f5, [%rd14];
	setp.eq.f32 	%p1, %f5, 0f00000000;
	selp.f32 	%f6, 0fBCA3D70A, 0f00000000, %p1;
	setp.eq.f32 	%p2, %f5, 0f3F800000;
	selp.f32 	%f7, 0fBCA3D70A, 0f00000000, %p2;
	add.rn.f32 	%f8, %f6, %f7;
	setp.eq.f32 	%p3, %f5, 0f40000000;
	selp.f32 	%f9, 0fBCA3D70A, 0f00000000, %p3;
	add.rn.f32 	%f10, %f8, %f9;
	setp.eq.f32 	%p4, %f5, 0f40400000;
	selp.f32 	%f11, 0fBCA3D70A, 0f00000000, %p4;
	add.rn.f32 	%f12, %f10, %f11;
	setp.eq.f32 	%p5, %f5, 0f40800000;
	selp.f32 	%f13, 0fBCA3D70A, 0f00000000, %p5;
	add.rn.f32 	%f14, %f12, %f13;
	setp.eq.f32 	%p6, %f5, 0f40A00000;
	selp.f32 	%f15, 0fBCA3D70A, 0f00000000, %p6;
	add.rn.f32 	%f16, %f14, %f15;
	setp.eq.f32 	%p7, %f5, 0f40C00000;
	selp.f32 	%f17, 0fBCA3D70A, 0f00000000, %p7;
	add.rn.f32 	%f18, %f16, %f17;
	setp.eq.f32 	%p8, %f5, 0f40E00000;
	selp.f32 	%f19, 0fBCA3D70A, 0f00000000, %p8;
	add.rn.f32 	%f20, %f18, %f19;
	setp.eq.f32 	%p9, %f5, 0f41000000;
	selp.f32 	%f21, 0fBCA3D70A, 0f00000000, %p9;
	add.rn.f32 	%f22, %f20, %f21;
	setp.eq.f32 	%p10, %f5, 0f41100000;
	selp.f32 	%f23, 0fBCA3D70A, 0f00000000, %p10;
	add.rn.f32 	%f24, %f22, %f23;
	neg.f32 	%f25, %f24;
	mul.wide.u32 	%rd15, %r3, 40;
	add.s64 	%rd16, %rd5, %rd15;
	ld.global.nc.v2.f32 	{%f26, %f27}, [%rd16];
	add.s64 	%rd17, %rd4, %rd13;
	ld.global.nc.f32 	%f28, [%rd17];
	sub.rn.f32 	%f29, %f26, %f28;
	fma.rn.f32 	%f30, %f29, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f31, %f30;
	mov.f32 	%f32, 0f4B400001;
	mov.f32 	%f33, 0f437C0000;
	fma.rm.f32 	%f34, %f31, %f33, %f32;
	add.rn.f32 	%f35, %f34, 0fCB40007F;
	neg.f32 	%f36, %f35;
	fma.rn.f32 	%f37, %f29, 0f3FB8AA3B, %f36;
	fma.rn.f32 	%f38, %f29, 0f32A57060, %f37;
	ex2.approx.ftz.f32 	%f39, %f38;
	mov.b32 	%r4, %f34;
	shl.b32 	%r5, %r4, 23;
	mov.b32 	%f40, %r5;
	mul.rn.f32 	%f41, %f39, %f40;
	add.rn.f32 	%f42, %f41, 0f00000000;
	sub.rn.f32 	%f43, %f27, %f28;
	fma.rn.f32 	%f44, %f43, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f45, %f44;
	fma.rm.f32 	%f46, %f45, %f33, %f32;
	add.rn.f32 	%f47, %f46, 0fCB40007F;
	neg.f32 	%f48, %f47;
	fma.rn.f32 	%f49, %f43, 0f3FB8AA3B, %f48;
	fma.rn.f32 	%f50, %f43, 0f32A57060, %f49;
	ex2.approx.ftz.f32 	%f51, %f50;
	mov.b32 	%r6, %f46;
	shl.b32 	%r7, %r6, 23;
	mov.b32 	%f52, %r7;
	mul.rn.f32 	%f53, %f51, %f52;
	add.rn.f32 	%f54, %f42, %f53;
	ld.global.nc.v2.f32 	{%f55, %f56}, [%rd16+8];
	sub.rn.f32 	%f57, %f55, %f28;
	fma.rn.f32 	%f58, %f57, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f59, %f58;
	fma.rm.f32 	%f60, %f59, %f33, %f32;
	add.rn.f32 	%f61, %f60, 0fCB40007F;
	neg.f32 	%f62, %f61;
	fma.rn.f32 	%f63, %f57, 0f3FB8AA3B, %f62;
	fma.rn.f32 	%f64, %f57, 0f32A57060, %f63;
	ex2.approx.ftz.f32 	%f65, %f64;
	mov.b32 	%r8, %f60;
	shl.b32 	%r9, %r8, 23;
	mov.b32 	%f66, %r9;
	mul.rn.f32 	%f67, %f65, %f66;
	add.rn.f32 	%f68, %f54, %f67;
	sub.rn.f32 	%f69, %f56, %f28;
	fma.rn.f32 	%f70, %f69, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f71, %f70;
	fma.rm.f32 	%f72, %f71, %f33, %f32;
	add.rn.f32 	%f73, %f72, 0fCB40007F;
	neg.f32 	%f74, %f73;
	fma.rn.f32 	%f75, %f69, 0f3FB8AA3B, %f74;
	fma.rn.f32 	%f76, %f69, 0f32A57060, %f75;
	ex2.approx.ftz.f32 	%f77, %f76;
	mov.b32 	%r10, %f72;
	shl.b32 	%r11, %r10, 23;
	mov.b32 	%f78, %r11;
	mul.rn.f32 	%f79, %f77, %f78;
	add.rn.f32 	%f80, %f68, %f79;
	ld.global.nc.v2.f32 	{%f81, %f82}, [%rd16+16];
	sub.rn.f32 	%f83, %f81, %f28;
	fma.rn.f32 	%f84, %f83, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f85, %f84;
	fma.rm.f32 	%f86, %f85, %f33, %f32;
	add.rn.f32 	%f87, %f86, 0fCB40007F;
	neg.f32 	%f88, %f87;
	fma.rn.f32 	%f89, %f83, 0f3FB8AA3B, %f88;
	fma.rn.f32 	%f90, %f83, 0f32A57060, %f89;
	ex2.approx.ftz.f32 	%f91, %f90;
	mov.b32 	%r12, %f86;
	shl.b32 	%r13, %r12, 23;
	mov.b32 	%f92, %r13;
	mul.rn.f32 	%f93, %f91, %f92;
	add.rn.f32 	%f94, %f80, %f93;
	sub.rn.f32 	%f95, %f82, %f28;
	fma.rn.f32 	%f96, %f95, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f97, %f96;
	fma.rm.f32 	%f98, %f97, %f33, %f32;
	add.rn.f32 	%f99, %f98, 0fCB40007F;
	neg.f32 	%f100, %f99;
	fma.rn.f32 	%f101, %f95, 0f3FB8AA3B, %f100;
	fma.rn.f32 	%f102, %f95, 0f32A57060, %f101;
	ex2.approx.ftz.f32 	%f103, %f102;
	mov.b32 	%r14, %f98;
	shl.b32 	%r15, %r14, 23;
	mov.b32 	%f104, %r15;
	mul.rn.f32 	%f105, %f103, %f104;
	add.rn.f32 	%f106, %f94, %f105;
	ld.global.nc.v2.f32 	{%f107, %f108}, [%rd16+24];
	sub.rn.f32 	%f109, %f107, %f28;
	fma.rn.f32 	%f110, %f109, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f111, %f110;
	fma.rm.f32 	%f112, %f111, %f33, %f32;
	add.rn.f32 	%f113, %f112, 0fCB40007F;
	neg.f32 	%f114, %f113;
	fma.rn.f32 	%f115, %f109, 0f3FB8AA3B, %f114;
	fma.rn.f32 	%f116, %f109, 0f32A57060, %f115;
	ex2.approx.ftz.f32 	%f117, %f116;
	mov.b32 	%r16, %f112;
	shl.b32 	%r17, %r16, 23;
	mov.b32 	%f118, %r17;
	mul.rn.f32 	%f119, %f117, %f118;
	add.rn.f32 	%f120, %f106, %f119;
	sub.rn.f32 	%f121, %f108, %f28;
	fma.rn.f32 	%f122, %f121, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f123, %f122;
	fma.rm.f32 	%f124, %f123, %f33, %f32;
	add.rn.f32 	%f125, %f124, 0fCB40007F;
	neg.f32 	%f126, %f125;
	fma.rn.f32 	%f127, %f121, 0f3FB8AA3B, %f126;
	fma.rn.f32 	%f128, %f121, 0f32A57060, %f127;
	ex2.approx.ftz.f32 	%f129, %f128;
	mov.b32 	%r18, %f124;
	shl.b32 	%r19, %r18, 23;
	mov.b32 	%f130, %r19;
	mul.rn.f32 	%f131, %f129, %f130;
	add.rn.f32 	%f132, %f120, %f131;
	ld.global.nc.v2.f32 	{%f133, %f134}, [%rd16+32];
	sub.rn.f32 	%f135, %f133, %f28;
	fma.rn.f32 	%f136, %f135, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f137, %f136;
	fma.rm.f32 	%f138, %f137, %f33, %f32;
	add.rn.f32 	%f139, %f138, 0fCB40007F;
	neg.f32 	%f140, %f139;
	fma.rn.f32 	%f141, %f135, 0f3FB8AA3B, %f140;
	fma.rn.f32 	%f142, %f135, 0f32A57060, %f141;
	ex2.approx.ftz.f32 	%f143, %f142;
	mov.b32 	%r20, %f138;
	shl.b32 	%r21, %r20, 23;
	mov.b32 	%f144, %r21;
	mul.rn.f32 	%f145, %f143, %f144;
	add.rn.f32 	%f146, %f132, %f145;
	sub.rn.f32 	%f147, %f134, %f28;
	fma.rn.f32 	%f148, %f147, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f149, %f148;
	fma.rm.f32 	%f150, %f149, %f33, %f32;
	add.rn.f32 	%f151, %f150, 0fCB40007F;
	neg.f32 	%f152, %f151;
	fma.rn.f32 	%f153, %f147, 0f3FB8AA3B, %f152;
	fma.rn.f32 	%f154, %f147, 0f32A57060, %f153;
	ex2.approx.ftz.f32 	%f155, %f154;
	mov.b32 	%r22, %f150;
	shl.b32 	%r23, %r22, 23;
	mov.b32 	%f156, %r23;
	mul.rn.f32 	%f157, %f155, %f156;
	add.rn.f32 	%f158, %f146, %f157;
	div.full.f32 	%f159, %f25, %f158;
	add.s64 	%rd18, %rd6, %rd13;
	ld.global.nc.f32 	%f160, [%rd18];
	shl.b32 	%r24, %r1, 1;
	mul.hi.u32 	%r25, %r24, 1717986919;
	shr.u32 	%r26, %r25, 2;
	mul.lo.s32 	%r27, %r26, 10;
	sub.s32 	%r28, %r24, %r27;
	cvt.rn.f32.u32 	%f161, %r28;
	setp.eq.f32 	%p11, %f5, %f161;
	mul.wide.u32 	%rd19, %r28, 4;
	add.s64 	%rd20, %rd16, %rd19;
	ld.global.nc.f32 	%f162, [%rd20];
	sub.rn.f32 	%f163, %f162, %f28;
	selp.f32 	%f164, 0fBCA3D70A, 0f00000000, %p11;
	fma.rn.f32 	%f165, %f163, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f166, %f165;
	fma.rm.f32 	%f167, %f166, %f33, %f32;
	add.rn.f32 	%f168, %f167, 0fCB40007F;
	neg.f32 	%f169, %f168;
	fma.rn.f32 	%f170, %f163, 0f3FB8AA3B, %f169;
	fma.rn.f32 	%f171, %f163, 0f32A57060, %f170;
	mov.b32 	%r29, %f167;
	shl.b32 	%r30, %r29, 23;
	mov.b32 	%f172, %r30;
	ex2.approx.ftz.f32 	%f173, %f171;
	mul.rn.f32 	%f174, %f173, %f172;
	mul.rn.f32 	%f175, %f159, %f174;
	add.rn.f32 	%f176, %f164, %f175;
	add.s64 	%rd21, %rd1, %rd15;
	add.s64 	%rd22, %rd21, %rd19;
	st.global.f32 	[%rd22], %f176;
	or.b32  	%r31, %r24, 1;
	mul.hi.u32 	%r32, %r31, 1717986919;
	shr.u32 	%r33, %r32, 2;
	mul.lo.s32 	%r34, %r33, 10;
	sub.s32 	%r35, %r31, %r34;
	cvt.rn.f32.u32 	%f177, %r35;
	setp.eq.f32 	%p12, %f5, %f177;
	mul.wide.u32 	%rd23, %r35, 4;
	add.s64 	%rd24, %rd16, %rd23;
	ld.global.nc.f32 	%f178, [%rd24];
	sub.rn.f32 	%f179, %f178, %f28;
	selp.f32 	%f180, 0fBCA3D70A, 0f00000000, %p12;
	fma.rn.f32 	%f181, %f179, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f182, %f181;
	fma.rm.f32 	%f183, %f182, %f33, %f32;
	add.rn.f32 	%f184, %f183, 0fCB40007F;
	neg.f32 	%f185, %f184;
	fma.rn.f32 	%f186, %f179, 0f3FB8AA3B, %f185;
	fma.rn.f32 	%f187, %f179, 0f32A57060, %f186;
	mov.b32 	%r36, %f183;
	shl.b32 	%r37, %r36, 23;
	mov.b32 	%f188, %r37;
	ex2.approx.ftz.f32 	%f189, %f187;
	mul.rn.f32 	%f190, %f189, %f188;
	mul.rn.f32 	%f191, %f159, %f190;
	add.rn.f32 	%f192, %f180, %f191;
	add.s64 	%rd25, %rd21, %rd23;
	st.global.f32 	[%rd25], %f192;
	or.b32  	%r38, %r1, 32;
	mul.hi.u32 	%r39, %r38, -858993459;
	shr.u32 	%r40, %r39, 2;
	mul.wide.u32 	%rd26, %r40, 4;
	add.s64 	%rd27, %rd3, %rd26;
	ld.global.nc.f32 	%f193, [%rd27];
	setp.eq.f32 	%p13, %f193, 0f00000000;
	selp.f32 	%f194, 0fBCA3D70A, 0f00000000, %p13;
	setp.eq.f32 	%p14, %f193, 0f3F800000;
	selp.f32 	%f195, 0fBCA3D70A, 0f00000000, %p14;
	add.rn.f32 	%f196, %f194, %f195;
	setp.eq.f32 	%p15, %f193, 0f40000000;
	selp.f32 	%f197, 0fBCA3D70A, 0f00000000, %p15;
	add.rn.f32 	%f198, %f196, %f197;
	setp.eq.f32 	%p16, %f193, 0f40400000;
	selp.f32 	%f199, 0fBCA3D70A, 0f00000000, %p16;
	add.rn.f32 	%f200, %f198, %f199;
	setp.eq.f32 	%p17, %f193, 0f40800000;
	selp.f32 	%f201, 0fBCA3D70A, 0f00000000, %p17;
	add.rn.f32 	%f202, %f200, %f201;
	setp.eq.f32 	%p18, %f193, 0f40A00000;
	selp.f32 	%f203, 0fBCA3D70A, 0f00000000, %p18;
	add.rn.f32 	%f204, %f202, %f203;
	setp.eq.f32 	%p19, %f193, 0f40C00000;
	selp.f32 	%f205, 0fBCA3D70A, 0f00000000, %p19;
	add.rn.f32 	%f206, %f204, %f205;
	setp.eq.f32 	%p20, %f193, 0f40E00000;
	selp.f32 	%f207, 0fBCA3D70A, 0f00000000, %p20;
	add.rn.f32 	%f208, %f206, %f207;
	setp.eq.f32 	%p21, %f193, 0f41000000;
	selp.f32 	%f209, 0fBCA3D70A, 0f00000000, %p21;
	add.rn.f32 	%f210, %f208, %f209;
	setp.eq.f32 	%p22, %f193, 0f41100000;
	selp.f32 	%f211, 0fBCA3D70A, 0f00000000, %p22;
	add.rn.f32 	%f212, %f210, %f211;
	neg.f32 	%f213, %f212;
	mul.wide.u32 	%rd28, %r40, 40;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.nc.v2.f32 	{%f214, %f215}, [%rd29];
	add.s64 	%rd30, %rd4, %rd26;
	ld.global.nc.f32 	%f216, [%rd30];
	sub.rn.f32 	%f217, %f214, %f216;
	fma.rn.f32 	%f218, %f217, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f219, %f218;
	fma.rm.f32 	%f220, %f219, %f33, %f32;
	add.rn.f32 	%f221, %f220, 0fCB40007F;
	neg.f32 	%f222, %f221;
	fma.rn.f32 	%f223, %f217, 0f3FB8AA3B, %f222;
	fma.rn.f32 	%f224, %f217, 0f32A57060, %f223;
	ex2.approx.ftz.f32 	%f225, %f224;
	mov.b32 	%r41, %f220;
	shl.b32 	%r42, %r41, 23;
	mov.b32 	%f226, %r42;
	mul.rn.f32 	%f227, %f225, %f226;
	add.rn.f32 	%f228, %f227, 0f00000000;
	sub.rn.f32 	%f229, %f215, %f216;
	fma.rn.f32 	%f230, %f229, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f231, %f230;
	fma.rm.f32 	%f232, %f231, %f33, %f32;
	add.rn.f32 	%f233, %f232, 0fCB40007F;
	neg.f32 	%f234, %f233;
	fma.rn.f32 	%f235, %f229, 0f3FB8AA3B, %f234;
	fma.rn.f32 	%f236, %f229, 0f32A57060, %f235;
	ex2.approx.ftz.f32 	%f237, %f236;
	mov.b32 	%r43, %f232;
	shl.b32 	%r44, %r43, 23;
	mov.b32 	%f238, %r44;
	mul.rn.f32 	%f239, %f237, %f238;
	add.rn.f32 	%f240, %f228, %f239;
	ld.global.nc.v2.f32 	{%f241, %f242}, [%rd29+8];
	sub.rn.f32 	%f243, %f241, %f216;
	fma.rn.f32 	%f244, %f243, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f245, %f244;
	fma.rm.f32 	%f246, %f245, %f33, %f32;
	add.rn.f32 	%f247, %f246, 0fCB40007F;
	neg.f32 	%f248, %f247;
	fma.rn.f32 	%f249, %f243, 0f3FB8AA3B, %f248;
	fma.rn.f32 	%f250, %f243, 0f32A57060, %f249;
	ex2.approx.ftz.f32 	%f251, %f250;
	mov.b32 	%r45, %f246;
	shl.b32 	%r46, %r45, 23;
	mov.b32 	%f252, %r46;
	mul.rn.f32 	%f253, %f251, %f252;
	add.rn.f32 	%f254, %f240, %f253;
	sub.rn.f32 	%f255, %f242, %f216;
	fma.rn.f32 	%f256, %f255, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f257, %f256;
	fma.rm.f32 	%f258, %f257, %f33, %f32;
	add.rn.f32 	%f259, %f258, 0fCB40007F;
	neg.f32 	%f260, %f259;
	fma.rn.f32 	%f261, %f255, 0f3FB8AA3B, %f260;
	fma.rn.f32 	%f262, %f255, 0f32A57060, %f261;
	ex2.approx.ftz.f32 	%f263, %f262;
	mov.b32 	%r47, %f258;
	shl.b32 	%r48, %r47, 23;
	mov.b32 	%f264, %r48;
	mul.rn.f32 	%f265, %f263, %f264;
	add.rn.f32 	%f266, %f254, %f265;
	ld.global.nc.v2.f32 	{%f267, %f268}, [%rd29+16];
	sub.rn.f32 	%f269, %f267, %f216;
	fma.rn.f32 	%f270, %f269, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f271, %f270;
	fma.rm.f32 	%f272, %f271, %f33, %f32;
	add.rn.f32 	%f273, %f272, 0fCB40007F;
	neg.f32 	%f274, %f273;
	fma.rn.f32 	%f275, %f269, 0f3FB8AA3B, %f274;
	fma.rn.f32 	%f276, %f269, 0f32A57060, %f275;
	ex2.approx.ftz.f32 	%f277, %f276;
	mov.b32 	%r49, %f272;
	shl.b32 	%r50, %r49, 23;
	mov.b32 	%f278, %r50;
	mul.rn.f32 	%f279, %f277, %f278;
	add.rn.f32 	%f280, %f266, %f279;
	sub.rn.f32 	%f281, %f268, %f216;
	fma.rn.f32 	%f282, %f281, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f283, %f282;
	fma.rm.f32 	%f284, %f283, %f33, %f32;
	add.rn.f32 	%f285, %f284, 0fCB40007F;
	neg.f32 	%f286, %f285;
	fma.rn.f32 	%f287, %f281, 0f3FB8AA3B, %f286;
	fma.rn.f32 	%f288, %f281, 0f32A57060, %f287;
	ex2.approx.ftz.f32 	%f289, %f288;
	mov.b32 	%r51, %f284;
	shl.b32 	%r52, %r51, 23;
	mov.b32 	%f290, %r52;
	mul.rn.f32 	%f291, %f289, %f290;
	add.rn.f32 	%f292, %f280, %f291;
	ld.global.nc.v2.f32 	{%f293, %f294}, [%rd29+24];
	sub.rn.f32 	%f295, %f293, %f216;
	fma.rn.f32 	%f296, %f295, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f297, %f296;
	fma.rm.f32 	%f298, %f297, %f33, %f32;
	add.rn.f32 	%f299, %f298, 0fCB40007F;
	neg.f32 	%f300, %f299;
	fma.rn.f32 	%f301, %f295, 0f3FB8AA3B, %f300;
	fma.rn.f32 	%f302, %f295, 0f32A57060, %f301;
	ex2.approx.ftz.f32 	%f303, %f302;
	mov.b32 	%r53, %f298;
	shl.b32 	%r54, %r53, 23;
	mov.b32 	%f304, %r54;
	mul.rn.f32 	%f305, %f303, %f304;
	add.rn.f32 	%f306, %f292, %f305;
	sub.rn.f32 	%f307, %f294, %f216;
	fma.rn.f32 	%f308, %f307, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f309, %f308;
	fma.rm.f32 	%f310, %f309, %f33, %f32;
	add.rn.f32 	%f311, %f310, 0fCB40007F;
	neg.f32 	%f312, %f311;
	fma.rn.f32 	%f313, %f307, 0f3FB8AA3B, %f312;
	fma.rn.f32 	%f314, %f307, 0f32A57060, %f313;
	ex2.approx.ftz.f32 	%f315, %f314;
	mov.b32 	%r55, %f310;
	shl.b32 	%r56, %r55, 23;
	mov.b32 	%f316, %r56;
	mul.rn.f32 	%f317, %f315, %f316;
	add.rn.f32 	%f318, %f306, %f317;
	ld.global.nc.v2.f32 	{%f319, %f320}, [%rd29+32];
	sub.rn.f32 	%f321, %f319, %f216;
	fma.rn.f32 	%f322, %f321, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f323, %f322;
	fma.rm.f32 	%f324, %f323, %f33, %f32;
	add.rn.f32 	%f325, %f324, 0fCB40007F;
	neg.f32 	%f326, %f325;
	fma.rn.f32 	%f327, %f321, 0f3FB8AA3B, %f326;
	fma.rn.f32 	%f328, %f321, 0f32A57060, %f327;
	ex2.approx.ftz.f32 	%f329, %f328;
	mov.b32 	%r57, %f324;
	shl.b32 	%r58, %r57, 23;
	mov.b32 	%f330, %r58;
	mul.rn.f32 	%f331, %f329, %f330;
	add.rn.f32 	%f332, %f318, %f331;
	sub.rn.f32 	%f333, %f320, %f216;
	fma.rn.f32 	%f334, %f333, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f335, %f334;
	fma.rm.f32 	%f336, %f335, %f33, %f32;
	add.rn.f32 	%f337, %f336, 0fCB40007F;
	neg.f32 	%f338, %f337;
	fma.rn.f32 	%f339, %f333, 0f3FB8AA3B, %f338;
	fma.rn.f32 	%f340, %f333, 0f32A57060, %f339;
	ex2.approx.ftz.f32 	%f341, %f340;
	mov.b32 	%r59, %f336;
	shl.b32 	%r60, %r59, 23;
	mov.b32 	%f342, %r60;
	mul.rn.f32 	%f343, %f341, %f342;
	add.rn.f32 	%f344, %f332, %f343;
	div.full.f32 	%f345, %f213, %f344;
	add.s64 	%rd31, %rd6, %rd26;
	ld.global.nc.f32 	%f346, [%rd31];
	shl.b32 	%r61, %r38, 1;
	mul.hi.u32 	%r62, %r61, 1717986919;
	shr.u32 	%r63, %r62, 2;
	mul.lo.s32 	%r64, %r63, 10;
	sub.s32 	%r65, %r61, %r64;
	cvt.rn.f32.u32 	%f347, %r65;
	setp.eq.f32 	%p23, %f193, %f347;
	mul.wide.u32 	%rd32, %r65, 4;
	add.s64 	%rd33, %rd29, %rd32;
	ld.global.nc.f32 	%f348, [%rd33];
	sub.rn.f32 	%f349, %f348, %f216;
	selp.f32 	%f350, 0fBCA3D70A, 0f00000000, %p23;
	fma.rn.f32 	%f351, %f349, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f352, %f351;
	fma.rm.f32 	%f353, %f352, %f33, %f32;
	add.rn.f32 	%f354, %f353, 0fCB40007F;
	neg.f32 	%f355, %f354;
	fma.rn.f32 	%f356, %f349, 0f3FB8AA3B, %f355;
	fma.rn.f32 	%f357, %f349, 0f32A57060, %f356;
	mov.b32 	%r66, %f353;
	shl.b32 	%r67, %r66, 23;
	mov.b32 	%f358, %r67;
	ex2.approx.ftz.f32 	%f359, %f357;
	mul.rn.f32 	%f360, %f359, %f358;
	mul.rn.f32 	%f361, %f345, %f360;
	add.rn.f32 	%f362, %f350, %f361;
	add.s64 	%rd34, %rd1, %rd28;
	add.s64 	%rd35, %rd34, %rd32;
	st.global.f32 	[%rd35], %f362;
	or.b32  	%r68, %r61, 1;
	mul.hi.u32 	%r69, %r68, 1717986919;
	shr.u32 	%r70, %r69, 2;
	mul.lo.s32 	%r71, %r70, 10;
	sub.s32 	%r72, %r68, %r71;
	cvt.rn.f32.u32 	%f363, %r72;
	setp.eq.f32 	%p24, %f193, %f363;
	mul.wide.u32 	%rd36, %r72, 4;
	add.s64 	%rd37, %rd29, %rd36;
	ld.global.nc.f32 	%f364, [%rd37];
	sub.rn.f32 	%f365, %f364, %f216;
	selp.f32 	%f366, 0fBCA3D70A, 0f00000000, %p24;
	fma.rn.f32 	%f367, %f365, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f368, %f367;
	fma.rm.f32 	%f369, %f368, %f33, %f32;
	add.rn.f32 	%f370, %f369, 0fCB40007F;
	neg.f32 	%f371, %f370;
	fma.rn.f32 	%f372, %f365, 0f3FB8AA3B, %f371;
	fma.rn.f32 	%f373, %f365, 0f32A57060, %f372;
	mov.b32 	%r73, %f369;
	shl.b32 	%r74, %r73, 23;
	mov.b32 	%f374, %r74;
	ex2.approx.ftz.f32 	%f375, %f373;
	mul.rn.f32 	%f376, %f375, %f374;
	mul.rn.f32 	%f377, %f345, %f376;
	add.rn.f32 	%f378, %f366, %f377;
	add.s64 	%rd38, %rd34, %rd36;
	st.global.f32 	[%rd38], %f378;
	or.b32  	%r75, %r1, 64;
	mul.hi.u32 	%r76, %r75, -858993459;
	shr.u32 	%r77, %r76, 2;
	mul.wide.u32 	%rd39, %r77, 4;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.nc.f32 	%f379, [%rd40];
	setp.eq.f32 	%p25, %f379, 0f00000000;
	selp.f32 	%f380, 0fBCA3D70A, 0f00000000, %p25;
	setp.eq.f32 	%p26, %f379, 0f3F800000;
	selp.f32 	%f381, 0fBCA3D70A, 0f00000000, %p26;
	add.rn.f32 	%f382, %f380, %f381;
	setp.eq.f32 	%p27, %f379, 0f40000000;
	selp.f32 	%f383, 0fBCA3D70A, 0f00000000, %p27;
	add.rn.f32 	%f384, %f382, %f383;
	setp.eq.f32 	%p28, %f379, 0f40400000;
	selp.f32 	%f385, 0fBCA3D70A, 0f00000000, %p28;
	add.rn.f32 	%f386, %f384, %f385;
	setp.eq.f32 	%p29, %f379, 0f40800000;
	selp.f32 	%f387, 0fBCA3D70A, 0f00000000, %p29;
	add.rn.f32 	%f388, %f386, %f387;
	setp.eq.f32 	%p30, %f379, 0f40A00000;
	selp.f32 	%f389, 0fBCA3D70A, 0f00000000, %p30;
	add.rn.f32 	%f390, %f388, %f389;
	setp.eq.f32 	%p31, %f379, 0f40C00000;
	selp.f32 	%f391, 0fBCA3D70A, 0f00000000, %p31;
	add.rn.f32 	%f392, %f390, %f391;
	setp.eq.f32 	%p32, %f379, 0f40E00000;
	selp.f32 	%f393, 0fBCA3D70A, 0f00000000, %p32;
	add.rn.f32 	%f394, %f392, %f393;
	setp.eq.f32 	%p33, %f379, 0f41000000;
	selp.f32 	%f395, 0fBCA3D70A, 0f00000000, %p33;
	add.rn.f32 	%f396, %f394, %f395;
	setp.eq.f32 	%p34, %f379, 0f41100000;
	selp.f32 	%f397, 0fBCA3D70A, 0f00000000, %p34;
	add.rn.f32 	%f398, %f396, %f397;
	neg.f32 	%f399, %f398;
	mul.wide.u32 	%rd41, %r77, 40;
	add.s64 	%rd42, %rd5, %rd41;
	ld.global.nc.v2.f32 	{%f400, %f401}, [%rd42];
	add.s64 	%rd43, %rd4, %rd39;
	ld.global.nc.f32 	%f402, [%rd43];
	sub.rn.f32 	%f403, %f400, %f402;
	fma.rn.f32 	%f404, %f403, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f405, %f404;
	fma.rm.f32 	%f406, %f405, %f33, %f32;
	add.rn.f32 	%f407, %f406, 0fCB40007F;
	neg.f32 	%f408, %f407;
	fma.rn.f32 	%f409, %f403, 0f3FB8AA3B, %f408;
	fma.rn.f32 	%f410, %f403, 0f32A57060, %f409;
	ex2.approx.ftz.f32 	%f411, %f410;
	mov.b32 	%r78, %f406;
	shl.b32 	%r79, %r78, 23;
	mov.b32 	%f412, %r79;
	mul.rn.f32 	%f413, %f411, %f412;
	add.rn.f32 	%f414, %f413, 0f00000000;
	sub.rn.f32 	%f415, %f401, %f402;
	fma.rn.f32 	%f416, %f415, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f417, %f416;
	fma.rm.f32 	%f418, %f417, %f33, %f32;
	add.rn.f32 	%f419, %f418, 0fCB40007F;
	neg.f32 	%f420, %f419;
	fma.rn.f32 	%f421, %f415, 0f3FB8AA3B, %f420;
	fma.rn.f32 	%f422, %f415, 0f32A57060, %f421;
	ex2.approx.ftz.f32 	%f423, %f422;
	mov.b32 	%r80, %f418;
	shl.b32 	%r81, %r80, 23;
	mov.b32 	%f424, %r81;
	mul.rn.f32 	%f425, %f423, %f424;
	add.rn.f32 	%f426, %f414, %f425;
	ld.global.nc.v2.f32 	{%f427, %f428}, [%rd42+8];
	sub.rn.f32 	%f429, %f427, %f402;
	fma.rn.f32 	%f430, %f429, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f431, %f430;
	fma.rm.f32 	%f432, %f431, %f33, %f32;
	add.rn.f32 	%f433, %f432, 0fCB40007F;
	neg.f32 	%f434, %f433;
	fma.rn.f32 	%f435, %f429, 0f3FB8AA3B, %f434;
	fma.rn.f32 	%f436, %f429, 0f32A57060, %f435;
	ex2.approx.ftz.f32 	%f437, %f436;
	mov.b32 	%r82, %f432;
	shl.b32 	%r83, %r82, 23;
	mov.b32 	%f438, %r83;
	mul.rn.f32 	%f439, %f437, %f438;
	add.rn.f32 	%f440, %f426, %f439;
	sub.rn.f32 	%f441, %f428, %f402;
	fma.rn.f32 	%f442, %f441, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f443, %f442;
	fma.rm.f32 	%f444, %f443, %f33, %f32;
	add.rn.f32 	%f445, %f444, 0fCB40007F;
	neg.f32 	%f446, %f445;
	fma.rn.f32 	%f447, %f441, 0f3FB8AA3B, %f446;
	fma.rn.f32 	%f448, %f441, 0f32A57060, %f447;
	ex2.approx.ftz.f32 	%f449, %f448;
	mov.b32 	%r84, %f444;
	shl.b32 	%r85, %r84, 23;
	mov.b32 	%f450, %r85;
	mul.rn.f32 	%f451, %f449, %f450;
	add.rn.f32 	%f452, %f440, %f451;
	ld.global.nc.v2.f32 	{%f453, %f454}, [%rd42+16];
	sub.rn.f32 	%f455, %f453, %f402;
	fma.rn.f32 	%f456, %f455, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f457, %f456;
	fma.rm.f32 	%f458, %f457, %f33, %f32;
	add.rn.f32 	%f459, %f458, 0fCB40007F;
	neg.f32 	%f460, %f459;
	fma.rn.f32 	%f461, %f455, 0f3FB8AA3B, %f460;
	fma.rn.f32 	%f462, %f455, 0f32A57060, %f461;
	ex2.approx.ftz.f32 	%f463, %f462;
	mov.b32 	%r86, %f458;
	shl.b32 	%r87, %r86, 23;
	mov.b32 	%f464, %r87;
	mul.rn.f32 	%f465, %f463, %f464;
	add.rn.f32 	%f466, %f452, %f465;
	sub.rn.f32 	%f467, %f454, %f402;
	fma.rn.f32 	%f468, %f467, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f469, %f468;
	fma.rm.f32 	%f470, %f469, %f33, %f32;
	add.rn.f32 	%f471, %f470, 0fCB40007F;
	neg.f32 	%f472, %f471;
	fma.rn.f32 	%f473, %f467, 0f3FB8AA3B, %f472;
	fma.rn.f32 	%f474, %f467, 0f32A57060, %f473;
	ex2.approx.ftz.f32 	%f475, %f474;
	mov.b32 	%r88, %f470;
	shl.b32 	%r89, %r88, 23;
	mov.b32 	%f476, %r89;
	mul.rn.f32 	%f477, %f475, %f476;
	add.rn.f32 	%f478, %f466, %f477;
	ld.global.nc.v2.f32 	{%f479, %f480}, [%rd42+24];
	sub.rn.f32 	%f481, %f479, %f402;
	fma.rn.f32 	%f482, %f481, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f483, %f482;
	fma.rm.f32 	%f484, %f483, %f33, %f32;
	add.rn.f32 	%f485, %f484, 0fCB40007F;
	neg.f32 	%f486, %f485;
	fma.rn.f32 	%f487, %f481, 0f3FB8AA3B, %f486;
	fma.rn.f32 	%f488, %f481, 0f32A57060, %f487;
	ex2.approx.ftz.f32 	%f489, %f488;
	mov.b32 	%r90, %f484;
	shl.b32 	%r91, %r90, 23;
	mov.b32 	%f490, %r91;
	mul.rn.f32 	%f491, %f489, %f490;
	add.rn.f32 	%f492, %f478, %f491;
	sub.rn.f32 	%f493, %f480, %f402;
	fma.rn.f32 	%f494, %f493, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f495, %f494;
	fma.rm.f32 	%f496, %f495, %f33, %f32;
	add.rn.f32 	%f497, %f496, 0fCB40007F;
	neg.f32 	%f498, %f497;
	fma.rn.f32 	%f499, %f493, 0f3FB8AA3B, %f498;
	fma.rn.f32 	%f500, %f493, 0f32A57060, %f499;
	ex2.approx.ftz.f32 	%f501, %f500;
	mov.b32 	%r92, %f496;
	shl.b32 	%r93, %r92, 23;
	mov.b32 	%f502, %r93;
	mul.rn.f32 	%f503, %f501, %f502;
	add.rn.f32 	%f504, %f492, %f503;
	ld.global.nc.v2.f32 	{%f505, %f506}, [%rd42+32];
	sub.rn.f32 	%f507, %f505, %f402;
	fma.rn.f32 	%f508, %f507, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f509, %f508;
	fma.rm.f32 	%f510, %f509, %f33, %f32;
	add.rn.f32 	%f511, %f510, 0fCB40007F;
	neg.f32 	%f512, %f511;
	fma.rn.f32 	%f513, %f507, 0f3FB8AA3B, %f512;
	fma.rn.f32 	%f514, %f507, 0f32A57060, %f513;
	ex2.approx.ftz.f32 	%f515, %f514;
	mov.b32 	%r94, %f510;
	shl.b32 	%r95, %r94, 23;
	mov.b32 	%f516, %r95;
	mul.rn.f32 	%f517, %f515, %f516;
	add.rn.f32 	%f518, %f504, %f517;
	sub.rn.f32 	%f519, %f506, %f402;
	fma.rn.f32 	%f520, %f519, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f521, %f520;
	fma.rm.f32 	%f522, %f521, %f33, %f32;
	add.rn.f32 	%f523, %f522, 0fCB40007F;
	neg.f32 	%f524, %f523;
	fma.rn.f32 	%f525, %f519, 0f3FB8AA3B, %f524;
	fma.rn.f32 	%f526, %f519, 0f32A57060, %f525;
	ex2.approx.ftz.f32 	%f527, %f526;
	mov.b32 	%r96, %f522;
	shl.b32 	%r97, %r96, 23;
	mov.b32 	%f528, %r97;
	mul.rn.f32 	%f529, %f527, %f528;
	add.rn.f32 	%f530, %f518, %f529;
	div.full.f32 	%f531, %f399, %f530;
	add.s64 	%rd44, %rd6, %rd39;
	ld.global.nc.f32 	%f532, [%rd44];
	shl.b32 	%r98, %r75, 1;
	mul.hi.u32 	%r99, %r98, 1717986919;
	shr.u32 	%r100, %r99, 2;
	mul.lo.s32 	%r101, %r100, 10;
	sub.s32 	%r102, %r98, %r101;
	cvt.rn.f32.u32 	%f533, %r102;
	setp.eq.f32 	%p35, %f379, %f533;
	mul.wide.u32 	%rd45, %r102, 4;
	add.s64 	%rd46, %rd42, %rd45;
	ld.global.nc.f32 	%f534, [%rd46];
	sub.rn.f32 	%f535, %f534, %f402;
	selp.f32 	%f536, 0fBCA3D70A, 0f00000000, %p35;
	fma.rn.f32 	%f537, %f535, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f538, %f537;
	fma.rm.f32 	%f539, %f538, %f33, %f32;
	add.rn.f32 	%f540, %f539, 0fCB40007F;
	neg.f32 	%f541, %f540;
	fma.rn.f32 	%f542, %f535, 0f3FB8AA3B, %f541;
	fma.rn.f32 	%f543, %f535, 0f32A57060, %f542;
	mov.b32 	%r103, %f539;
	shl.b32 	%r104, %r103, 23;
	mov.b32 	%f544, %r104;
	ex2.approx.ftz.f32 	%f545, %f543;
	mul.rn.f32 	%f546, %f545, %f544;
	mul.rn.f32 	%f547, %f531, %f546;
	add.rn.f32 	%f548, %f536, %f547;
	add.s64 	%rd47, %rd1, %rd41;
	add.s64 	%rd48, %rd47, %rd45;
	st.global.f32 	[%rd48], %f548;
	or.b32  	%r105, %r98, 1;
	mul.hi.u32 	%r106, %r105, 1717986919;
	shr.u32 	%r107, %r106, 2;
	mul.lo.s32 	%r108, %r107, 10;
	sub.s32 	%r109, %r105, %r108;
	cvt.rn.f32.u32 	%f549, %r109;
	setp.eq.f32 	%p36, %f379, %f549;
	mul.wide.u32 	%rd49, %r109, 4;
	add.s64 	%rd50, %rd42, %rd49;
	ld.global.nc.f32 	%f550, [%rd50];
	sub.rn.f32 	%f551, %f550, %f402;
	selp.f32 	%f552, 0fBCA3D70A, 0f00000000, %p36;
	fma.rn.f32 	%f553, %f551, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f554, %f553;
	fma.rm.f32 	%f555, %f554, %f33, %f32;
	add.rn.f32 	%f556, %f555, 0fCB40007F;
	neg.f32 	%f557, %f556;
	fma.rn.f32 	%f558, %f551, 0f3FB8AA3B, %f557;
	fma.rn.f32 	%f559, %f551, 0f32A57060, %f558;
	mov.b32 	%r110, %f555;
	shl.b32 	%r111, %r110, 23;
	mov.b32 	%f560, %r111;
	ex2.approx.ftz.f32 	%f561, %f559;
	mul.rn.f32 	%f562, %f561, %f560;
	mul.rn.f32 	%f563, %f531, %f562;
	add.rn.f32 	%f564, %f552, %f563;
	add.s64 	%rd51, %rd47, %rd49;
	st.global.f32 	[%rd51], %f564;
	or.b32  	%r112, %r1, 96;
	mul.hi.u32 	%r113, %r112, -858993459;
	shr.u32 	%r114, %r113, 2;
	mul.wide.u32 	%rd52, %r114, 4;
	add.s64 	%rd53, %rd3, %rd52;
	ld.global.nc.f32 	%f565, [%rd53];
	setp.eq.f32 	%p37, %f565, 0f00000000;
	selp.f32 	%f566, 0fBCA3D70A, 0f00000000, %p37;
	setp.eq.f32 	%p38, %f565, 0f3F800000;
	selp.f32 	%f567, 0fBCA3D70A, 0f00000000, %p38;
	add.rn.f32 	%f568, %f566, %f567;
	setp.eq.f32 	%p39, %f565, 0f40000000;
	selp.f32 	%f569, 0fBCA3D70A, 0f00000000, %p39;
	add.rn.f32 	%f570, %f568, %f569;
	setp.eq.f32 	%p40, %f565, 0f40400000;
	selp.f32 	%f571, 0fBCA3D70A, 0f00000000, %p40;
	add.rn.f32 	%f572, %f570, %f571;
	setp.eq.f32 	%p41, %f565, 0f40800000;
	selp.f32 	%f573, 0fBCA3D70A, 0f00000000, %p41;
	add.rn.f32 	%f574, %f572, %f573;
	setp.eq.f32 	%p42, %f565, 0f40A00000;
	selp.f32 	%f575, 0fBCA3D70A, 0f00000000, %p42;
	add.rn.f32 	%f576, %f574, %f575;
	setp.eq.f32 	%p43, %f565, 0f40C00000;
	selp.f32 	%f577, 0fBCA3D70A, 0f00000000, %p43;
	add.rn.f32 	%f578, %f576, %f577;
	setp.eq.f32 	%p44, %f565, 0f40E00000;
	selp.f32 	%f579, 0fBCA3D70A, 0f00000000, %p44;
	add.rn.f32 	%f580, %f578, %f579;
	setp.eq.f32 	%p45, %f565, 0f41000000;
	selp.f32 	%f581, 0fBCA3D70A, 0f00000000, %p45;
	add.rn.f32 	%f582, %f580, %f581;
	setp.eq.f32 	%p46, %f565, 0f41100000;
	selp.f32 	%f583, 0fBCA3D70A, 0f00000000, %p46;
	add.rn.f32 	%f584, %f582, %f583;
	neg.f32 	%f585, %f584;
	mul.wide.u32 	%rd54, %r114, 40;
	add.s64 	%rd55, %rd5, %rd54;
	ld.global.nc.v2.f32 	{%f586, %f587}, [%rd55];
	add.s64 	%rd56, %rd4, %rd52;
	ld.global.nc.f32 	%f588, [%rd56];
	sub.rn.f32 	%f589, %f586, %f588;
	fma.rn.f32 	%f590, %f589, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f591, %f590;
	fma.rm.f32 	%f592, %f591, %f33, %f32;
	add.rn.f32 	%f593, %f592, 0fCB40007F;
	neg.f32 	%f594, %f593;
	fma.rn.f32 	%f595, %f589, 0f3FB8AA3B, %f594;
	fma.rn.f32 	%f596, %f589, 0f32A57060, %f595;
	ex2.approx.ftz.f32 	%f597, %f596;
	mov.b32 	%r115, %f592;
	shl.b32 	%r116, %r115, 23;
	mov.b32 	%f598, %r116;
	mul.rn.f32 	%f599, %f597, %f598;
	add.rn.f32 	%f600, %f599, 0f00000000;
	sub.rn.f32 	%f601, %f587, %f588;
	fma.rn.f32 	%f602, %f601, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f603, %f602;
	fma.rm.f32 	%f604, %f603, %f33, %f32;
	add.rn.f32 	%f605, %f604, 0fCB40007F;
	neg.f32 	%f606, %f605;
	fma.rn.f32 	%f607, %f601, 0f3FB8AA3B, %f606;
	fma.rn.f32 	%f608, %f601, 0f32A57060, %f607;
	ex2.approx.ftz.f32 	%f609, %f608;
	mov.b32 	%r117, %f604;
	shl.b32 	%r118, %r117, 23;
	mov.b32 	%f610, %r118;
	mul.rn.f32 	%f611, %f609, %f610;
	add.rn.f32 	%f612, %f600, %f611;
	ld.global.nc.v2.f32 	{%f613, %f614}, [%rd55+8];
	sub.rn.f32 	%f615, %f613, %f588;
	fma.rn.f32 	%f616, %f615, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f617, %f616;
	fma.rm.f32 	%f618, %f617, %f33, %f32;
	add.rn.f32 	%f619, %f618, 0fCB40007F;
	neg.f32 	%f620, %f619;
	fma.rn.f32 	%f621, %f615, 0f3FB8AA3B, %f620;
	fma.rn.f32 	%f622, %f615, 0f32A57060, %f621;
	ex2.approx.ftz.f32 	%f623, %f622;
	mov.b32 	%r119, %f618;
	shl.b32 	%r120, %r119, 23;
	mov.b32 	%f624, %r120;
	mul.rn.f32 	%f625, %f623, %f624;
	add.rn.f32 	%f626, %f612, %f625;
	sub.rn.f32 	%f627, %f614, %f588;
	fma.rn.f32 	%f628, %f627, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f629, %f628;
	fma.rm.f32 	%f630, %f629, %f33, %f32;
	add.rn.f32 	%f631, %f630, 0fCB40007F;
	neg.f32 	%f632, %f631;
	fma.rn.f32 	%f633, %f627, 0f3FB8AA3B, %f632;
	fma.rn.f32 	%f634, %f627, 0f32A57060, %f633;
	ex2.approx.ftz.f32 	%f635, %f634;
	mov.b32 	%r121, %f630;
	shl.b32 	%r122, %r121, 23;
	mov.b32 	%f636, %r122;
	mul.rn.f32 	%f637, %f635, %f636;
	add.rn.f32 	%f638, %f626, %f637;
	ld.global.nc.v2.f32 	{%f639, %f640}, [%rd55+16];
	sub.rn.f32 	%f641, %f639, %f588;
	fma.rn.f32 	%f642, %f641, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f643, %f642;
	fma.rm.f32 	%f644, %f643, %f33, %f32;
	add.rn.f32 	%f645, %f644, 0fCB40007F;
	neg.f32 	%f646, %f645;
	fma.rn.f32 	%f647, %f641, 0f3FB8AA3B, %f646;
	fma.rn.f32 	%f648, %f641, 0f32A57060, %f647;
	ex2.approx.ftz.f32 	%f649, %f648;
	mov.b32 	%r123, %f644;
	shl.b32 	%r124, %r123, 23;
	mov.b32 	%f650, %r124;
	mul.rn.f32 	%f651, %f649, %f650;
	add.rn.f32 	%f652, %f638, %f651;
	sub.rn.f32 	%f653, %f640, %f588;
	fma.rn.f32 	%f654, %f653, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f655, %f654;
	fma.rm.f32 	%f656, %f655, %f33, %f32;
	add.rn.f32 	%f657, %f656, 0fCB40007F;
	neg.f32 	%f658, %f657;
	fma.rn.f32 	%f659, %f653, 0f3FB8AA3B, %f658;
	fma.rn.f32 	%f660, %f653, 0f32A57060, %f659;
	ex2.approx.ftz.f32 	%f661, %f660;
	mov.b32 	%r125, %f656;
	shl.b32 	%r126, %r125, 23;
	mov.b32 	%f662, %r126;
	mul.rn.f32 	%f663, %f661, %f662;
	add.rn.f32 	%f664, %f652, %f663;
	ld.global.nc.v2.f32 	{%f665, %f666}, [%rd55+24];
	sub.rn.f32 	%f667, %f665, %f588;
	fma.rn.f32 	%f668, %f667, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f669, %f668;
	fma.rm.f32 	%f670, %f669, %f33, %f32;
	add.rn.f32 	%f671, %f670, 0fCB40007F;
	neg.f32 	%f672, %f671;
	fma.rn.f32 	%f673, %f667, 0f3FB8AA3B, %f672;
	fma.rn.f32 	%f674, %f667, 0f32A57060, %f673;
	ex2.approx.ftz.f32 	%f675, %f674;
	mov.b32 	%r127, %f670;
	shl.b32 	%r128, %r127, 23;
	mov.b32 	%f676, %r128;
	mul.rn.f32 	%f677, %f675, %f676;
	add.rn.f32 	%f678, %f664, %f677;
	sub.rn.f32 	%f679, %f666, %f588;
	fma.rn.f32 	%f680, %f679, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f681, %f680;
	fma.rm.f32 	%f682, %f681, %f33, %f32;
	add.rn.f32 	%f683, %f682, 0fCB40007F;
	neg.f32 	%f684, %f683;
	fma.rn.f32 	%f685, %f679, 0f3FB8AA3B, %f684;
	fma.rn.f32 	%f686, %f679, 0f32A57060, %f685;
	ex2.approx.ftz.f32 	%f687, %f686;
	mov.b32 	%r129, %f682;
	shl.b32 	%r130, %r129, 23;
	mov.b32 	%f688, %r130;
	mul.rn.f32 	%f689, %f687, %f688;
	add.rn.f32 	%f690, %f678, %f689;
	ld.global.nc.v2.f32 	{%f691, %f692}, [%rd55+32];
	sub.rn.f32 	%f693, %f691, %f588;
	fma.rn.f32 	%f694, %f693, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f695, %f694;
	fma.rm.f32 	%f696, %f695, %f33, %f32;
	add.rn.f32 	%f697, %f696, 0fCB40007F;
	neg.f32 	%f698, %f697;
	fma.rn.f32 	%f699, %f693, 0f3FB8AA3B, %f698;
	fma.rn.f32 	%f700, %f693, 0f32A57060, %f699;
	ex2.approx.ftz.f32 	%f701, %f700;
	mov.b32 	%r131, %f696;
	shl.b32 	%r132, %r131, 23;
	mov.b32 	%f702, %r132;
	mul.rn.f32 	%f703, %f701, %f702;
	add.rn.f32 	%f704, %f690, %f703;
	sub.rn.f32 	%f705, %f692, %f588;
	fma.rn.f32 	%f706, %f705, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f707, %f706;
	fma.rm.f32 	%f708, %f707, %f33, %f32;
	add.rn.f32 	%f709, %f708, 0fCB40007F;
	neg.f32 	%f710, %f709;
	fma.rn.f32 	%f711, %f705, 0f3FB8AA3B, %f710;
	fma.rn.f32 	%f712, %f705, 0f32A57060, %f711;
	ex2.approx.ftz.f32 	%f713, %f712;
	mov.b32 	%r133, %f708;
	shl.b32 	%r134, %r133, 23;
	mov.b32 	%f714, %r134;
	mul.rn.f32 	%f715, %f713, %f714;
	add.rn.f32 	%f716, %f704, %f715;
	div.full.f32 	%f717, %f585, %f716;
	add.s64 	%rd57, %rd6, %rd52;
	ld.global.nc.f32 	%f718, [%rd57];
	shl.b32 	%r135, %r112, 1;
	mul.hi.u32 	%r136, %r135, 1717986919;
	shr.u32 	%r137, %r136, 2;
	mul.lo.s32 	%r138, %r137, 10;
	sub.s32 	%r139, %r135, %r138;
	cvt.rn.f32.u32 	%f719, %r139;
	setp.eq.f32 	%p47, %f565, %f719;
	mul.wide.u32 	%rd58, %r139, 4;
	add.s64 	%rd59, %rd55, %rd58;
	ld.global.nc.f32 	%f720, [%rd59];
	sub.rn.f32 	%f721, %f720, %f588;
	selp.f32 	%f722, 0fBCA3D70A, 0f00000000, %p47;
	fma.rn.f32 	%f723, %f721, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f724, %f723;
	fma.rm.f32 	%f725, %f724, %f33, %f32;
	add.rn.f32 	%f726, %f725, 0fCB40007F;
	neg.f32 	%f727, %f726;
	fma.rn.f32 	%f728, %f721, 0f3FB8AA3B, %f727;
	fma.rn.f32 	%f729, %f721, 0f32A57060, %f728;
	mov.b32 	%r140, %f725;
	shl.b32 	%r141, %r140, 23;
	mov.b32 	%f730, %r141;
	ex2.approx.ftz.f32 	%f731, %f729;
	mul.rn.f32 	%f732, %f731, %f730;
	mul.rn.f32 	%f733, %f717, %f732;
	add.rn.f32 	%f734, %f722, %f733;
	add.s64 	%rd60, %rd1, %rd54;
	add.s64 	%rd61, %rd60, %rd58;
	st.global.f32 	[%rd61], %f734;
	or.b32  	%r142, %r135, 1;
	mul.hi.u32 	%r143, %r142, 1717986919;
	shr.u32 	%r144, %r143, 2;
	mul.lo.s32 	%r145, %r144, 10;
	sub.s32 	%r146, %r142, %r145;
	cvt.rn.f32.u32 	%f735, %r146;
	setp.eq.f32 	%p48, %f565, %f735;
	mul.wide.u32 	%rd62, %r146, 4;
	add.s64 	%rd63, %rd55, %rd62;
	ld.global.nc.f32 	%f736, [%rd63];
	sub.rn.f32 	%f737, %f736, %f588;
	selp.f32 	%f738, 0fBCA3D70A, 0f00000000, %p48;
	fma.rn.f32 	%f739, %f737, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f740, %f739;
	fma.rm.f32 	%f741, %f740, %f33, %f32;
	add.rn.f32 	%f742, %f741, 0fCB40007F;
	neg.f32 	%f743, %f742;
	fma.rn.f32 	%f744, %f737, 0f3FB8AA3B, %f743;
	fma.rn.f32 	%f745, %f737, 0f32A57060, %f744;
	mov.b32 	%r147, %f741;
	shl.b32 	%r148, %r147, 23;
	mov.b32 	%f746, %r148;
	ex2.approx.ftz.f32 	%f747, %f745;
	mul.rn.f32 	%f748, %f747, %f746;
	mul.rn.f32 	%f749, %f717, %f748;
	add.rn.f32 	%f750, %f738, %f749;
	add.s64 	%rd64, %rd60, %rd62;
	st.global.f32 	[%rd64], %f750;
	or.b32  	%r149, %r1, 128;
	mul.hi.u32 	%r150, %r149, -858993459;
	shr.u32 	%r151, %r150, 2;
	mul.wide.u32 	%rd65, %r151, 4;
	add.s64 	%rd66, %rd3, %rd65;
	ld.global.nc.f32 	%f751, [%rd66];
	setp.eq.f32 	%p49, %f751, 0f00000000;
	selp.f32 	%f752, 0fBCA3D70A, 0f00000000, %p49;
	setp.eq.f32 	%p50, %f751, 0f3F800000;
	selp.f32 	%f753, 0fBCA3D70A, 0f00000000, %p50;
	add.rn.f32 	%f754, %f752, %f753;
	setp.eq.f32 	%p51, %f751, 0f40000000;
	selp.f32 	%f755, 0fBCA3D70A, 0f00000000, %p51;
	add.rn.f32 	%f756, %f754, %f755;
	setp.eq.f32 	%p52, %f751, 0f40400000;
	selp.f32 	%f757, 0fBCA3D70A, 0f00000000, %p52;
	add.rn.f32 	%f758, %f756, %f757;
	setp.eq.f32 	%p53, %f751, 0f40800000;
	selp.f32 	%f759, 0fBCA3D70A, 0f00000000, %p53;
	add.rn.f32 	%f760, %f758, %f759;
	setp.eq.f32 	%p54, %f751, 0f40A00000;
	selp.f32 	%f761, 0fBCA3D70A, 0f00000000, %p54;
	add.rn.f32 	%f762, %f760, %f761;
	setp.eq.f32 	%p55, %f751, 0f40C00000;
	selp.f32 	%f763, 0fBCA3D70A, 0f00000000, %p55;
	add.rn.f32 	%f764, %f762, %f763;
	setp.eq.f32 	%p56, %f751, 0f40E00000;
	selp.f32 	%f765, 0fBCA3D70A, 0f00000000, %p56;
	add.rn.f32 	%f766, %f764, %f765;
	setp.eq.f32 	%p57, %f751, 0f41000000;
	selp.f32 	%f767, 0fBCA3D70A, 0f00000000, %p57;
	add.rn.f32 	%f768, %f766, %f767;
	setp.eq.f32 	%p58, %f751, 0f41100000;
	selp.f32 	%f769, 0fBCA3D70A, 0f00000000, %p58;
	add.rn.f32 	%f770, %f768, %f769;
	neg.f32 	%f771, %f770;
	mul.wide.u32 	%rd67, %r151, 40;
	add.s64 	%rd68, %rd5, %rd67;
	ld.global.nc.v2.f32 	{%f772, %f773}, [%rd68];
	add.s64 	%rd69, %rd4, %rd65;
	ld.global.nc.f32 	%f774, [%rd69];
	sub.rn.f32 	%f775, %f772, %f774;
	fma.rn.f32 	%f776, %f775, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f777, %f776;
	fma.rm.f32 	%f778, %f777, %f33, %f32;
	add.rn.f32 	%f779, %f778, 0fCB40007F;
	neg.f32 	%f780, %f779;
	fma.rn.f32 	%f781, %f775, 0f3FB8AA3B, %f780;
	fma.rn.f32 	%f782, %f775, 0f32A57060, %f781;
	ex2.approx.ftz.f32 	%f783, %f782;
	mov.b32 	%r152, %f778;
	shl.b32 	%r153, %r152, 23;
	mov.b32 	%f784, %r153;
	mul.rn.f32 	%f785, %f783, %f784;
	add.rn.f32 	%f786, %f785, 0f00000000;
	sub.rn.f32 	%f787, %f773, %f774;
	fma.rn.f32 	%f788, %f787, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f789, %f788;
	fma.rm.f32 	%f790, %f789, %f33, %f32;
	add.rn.f32 	%f791, %f790, 0fCB40007F;
	neg.f32 	%f792, %f791;
	fma.rn.f32 	%f793, %f787, 0f3FB8AA3B, %f792;
	fma.rn.f32 	%f794, %f787, 0f32A57060, %f793;
	ex2.approx.ftz.f32 	%f795, %f794;
	mov.b32 	%r154, %f790;
	shl.b32 	%r155, %r154, 23;
	mov.b32 	%f796, %r155;
	mul.rn.f32 	%f797, %f795, %f796;
	add.rn.f32 	%f798, %f786, %f797;
	ld.global.nc.v2.f32 	{%f799, %f800}, [%rd68+8];
	sub.rn.f32 	%f801, %f799, %f774;
	fma.rn.f32 	%f802, %f801, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f803, %f802;
	fma.rm.f32 	%f804, %f803, %f33, %f32;
	add.rn.f32 	%f805, %f804, 0fCB40007F;
	neg.f32 	%f806, %f805;
	fma.rn.f32 	%f807, %f801, 0f3FB8AA3B, %f806;
	fma.rn.f32 	%f808, %f801, 0f32A57060, %f807;
	ex2.approx.ftz.f32 	%f809, %f808;
	mov.b32 	%r156, %f804;
	shl.b32 	%r157, %r156, 23;
	mov.b32 	%f810, %r157;
	mul.rn.f32 	%f811, %f809, %f810;
	add.rn.f32 	%f812, %f798, %f811;
	sub.rn.f32 	%f813, %f800, %f774;
	fma.rn.f32 	%f814, %f813, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f815, %f814;
	fma.rm.f32 	%f816, %f815, %f33, %f32;
	add.rn.f32 	%f817, %f816, 0fCB40007F;
	neg.f32 	%f818, %f817;
	fma.rn.f32 	%f819, %f813, 0f3FB8AA3B, %f818;
	fma.rn.f32 	%f820, %f813, 0f32A57060, %f819;
	ex2.approx.ftz.f32 	%f821, %f820;
	mov.b32 	%r158, %f816;
	shl.b32 	%r159, %r158, 23;
	mov.b32 	%f822, %r159;
	mul.rn.f32 	%f823, %f821, %f822;
	add.rn.f32 	%f824, %f812, %f823;
	ld.global.nc.v2.f32 	{%f825, %f826}, [%rd68+16];
	sub.rn.f32 	%f827, %f825, %f774;
	fma.rn.f32 	%f828, %f827, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f829, %f828;
	fma.rm.f32 	%f830, %f829, %f33, %f32;
	add.rn.f32 	%f831, %f830, 0fCB40007F;
	neg.f32 	%f832, %f831;
	fma.rn.f32 	%f833, %f827, 0f3FB8AA3B, %f832;
	fma.rn.f32 	%f834, %f827, 0f32A57060, %f833;
	ex2.approx.ftz.f32 	%f835, %f834;
	mov.b32 	%r160, %f830;
	shl.b32 	%r161, %r160, 23;
	mov.b32 	%f836, %r161;
	mul.rn.f32 	%f837, %f835, %f836;
	add.rn.f32 	%f838, %f824, %f837;
	sub.rn.f32 	%f839, %f826, %f774;
	fma.rn.f32 	%f840, %f839, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f841, %f840;
	fma.rm.f32 	%f842, %f841, %f33, %f32;
	add.rn.f32 	%f843, %f842, 0fCB40007F;
	neg.f32 	%f844, %f843;
	fma.rn.f32 	%f845, %f839, 0f3FB8AA3B, %f844;
	fma.rn.f32 	%f846, %f839, 0f32A57060, %f845;
	ex2.approx.ftz.f32 	%f847, %f846;
	mov.b32 	%r162, %f842;
	shl.b32 	%r163, %r162, 23;
	mov.b32 	%f848, %r163;
	mul.rn.f32 	%f849, %f847, %f848;
	add.rn.f32 	%f850, %f838, %f849;
	ld.global.nc.v2.f32 	{%f851, %f852}, [%rd68+24];
	sub.rn.f32 	%f853, %f851, %f774;
	fma.rn.f32 	%f854, %f853, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f855, %f854;
	fma.rm.f32 	%f856, %f855, %f33, %f32;
	add.rn.f32 	%f857, %f856, 0fCB40007F;
	neg.f32 	%f858, %f857;
	fma.rn.f32 	%f859, %f853, 0f3FB8AA3B, %f858;
	fma.rn.f32 	%f860, %f853, 0f32A57060, %f859;
	ex2.approx.ftz.f32 	%f861, %f860;
	mov.b32 	%r164, %f856;
	shl.b32 	%r165, %r164, 23;
	mov.b32 	%f862, %r165;
	mul.rn.f32 	%f863, %f861, %f862;
	add.rn.f32 	%f864, %f850, %f863;
	sub.rn.f32 	%f865, %f852, %f774;
	fma.rn.f32 	%f866, %f865, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f867, %f866;
	fma.rm.f32 	%f868, %f867, %f33, %f32;
	add.rn.f32 	%f869, %f868, 0fCB40007F;
	neg.f32 	%f870, %f869;
	fma.rn.f32 	%f871, %f865, 0f3FB8AA3B, %f870;
	fma.rn.f32 	%f872, %f865, 0f32A57060, %f871;
	ex2.approx.ftz.f32 	%f873, %f872;
	mov.b32 	%r166, %f868;
	shl.b32 	%r167, %r166, 23;
	mov.b32 	%f874, %r167;
	mul.rn.f32 	%f875, %f873, %f874;
	add.rn.f32 	%f876, %f864, %f875;
	ld.global.nc.v2.f32 	{%f877, %f878}, [%rd68+32];
	sub.rn.f32 	%f879, %f877, %f774;
	fma.rn.f32 	%f880, %f879, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f881, %f880;
	fma.rm.f32 	%f882, %f881, %f33, %f32;
	add.rn.f32 	%f883, %f882, 0fCB40007F;
	neg.f32 	%f884, %f883;
	fma.rn.f32 	%f885, %f879, 0f3FB8AA3B, %f884;
	fma.rn.f32 	%f886, %f879, 0f32A57060, %f885;
	ex2.approx.ftz.f32 	%f887, %f886;
	mov.b32 	%r168, %f882;
	shl.b32 	%r169, %r168, 23;
	mov.b32 	%f888, %r169;
	mul.rn.f32 	%f889, %f887, %f888;
	add.rn.f32 	%f890, %f876, %f889;
	sub.rn.f32 	%f891, %f878, %f774;
	fma.rn.f32 	%f892, %f891, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f893, %f892;
	fma.rm.f32 	%f894, %f893, %f33, %f32;
	add.rn.f32 	%f895, %f894, 0fCB40007F;
	neg.f32 	%f896, %f895;
	fma.rn.f32 	%f897, %f891, 0f3FB8AA3B, %f896;
	fma.rn.f32 	%f898, %f891, 0f32A57060, %f897;
	ex2.approx.ftz.f32 	%f899, %f898;
	mov.b32 	%r170, %f894;
	shl.b32 	%r171, %r170, 23;
	mov.b32 	%f900, %r171;
	mul.rn.f32 	%f901, %f899, %f900;
	add.rn.f32 	%f902, %f890, %f901;
	div.full.f32 	%f903, %f771, %f902;
	add.s64 	%rd70, %rd6, %rd65;
	ld.global.nc.f32 	%f904, [%rd70];
	shl.b32 	%r172, %r149, 1;
	mul.hi.u32 	%r173, %r172, 1717986919;
	shr.u32 	%r174, %r173, 2;
	mul.lo.s32 	%r175, %r174, 10;
	sub.s32 	%r176, %r172, %r175;
	cvt.rn.f32.u32 	%f905, %r176;
	setp.eq.f32 	%p59, %f751, %f905;
	mul.wide.u32 	%rd71, %r176, 4;
	add.s64 	%rd72, %rd68, %rd71;
	ld.global.nc.f32 	%f906, [%rd72];
	sub.rn.f32 	%f907, %f906, %f774;
	selp.f32 	%f908, 0fBCA3D70A, 0f00000000, %p59;
	fma.rn.f32 	%f909, %f907, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f910, %f909;
	fma.rm.f32 	%f911, %f910, %f33, %f32;
	add.rn.f32 	%f912, %f911, 0fCB40007F;
	neg.f32 	%f913, %f912;
	fma.rn.f32 	%f914, %f907, 0f3FB8AA3B, %f913;
	fma.rn.f32 	%f915, %f907, 0f32A57060, %f914;
	mov.b32 	%r177, %f911;
	shl.b32 	%r178, %r177, 23;
	mov.b32 	%f916, %r178;
	ex2.approx.ftz.f32 	%f917, %f915;
	mul.rn.f32 	%f918, %f917, %f916;
	mul.rn.f32 	%f919, %f903, %f918;
	add.rn.f32 	%f920, %f908, %f919;
	add.s64 	%rd73, %rd1, %rd67;
	add.s64 	%rd74, %rd73, %rd71;
	st.global.f32 	[%rd74], %f920;
	or.b32  	%r179, %r172, 1;
	mul.hi.u32 	%r180, %r179, 1717986919;
	shr.u32 	%r181, %r180, 2;
	mul.lo.s32 	%r182, %r181, 10;
	sub.s32 	%r183, %r179, %r182;
	cvt.rn.f32.u32 	%f921, %r183;
	setp.eq.f32 	%p60, %f751, %f921;
	mul.wide.u32 	%rd75, %r183, 4;
	add.s64 	%rd76, %rd68, %rd75;
	ld.global.nc.f32 	%f922, [%rd76];
	sub.rn.f32 	%f923, %f922, %f774;
	selp.f32 	%f924, 0fBCA3D70A, 0f00000000, %p60;
	fma.rn.f32 	%f925, %f923, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f926, %f925;
	fma.rm.f32 	%f927, %f926, %f33, %f32;
	add.rn.f32 	%f928, %f927, 0fCB40007F;
	neg.f32 	%f929, %f928;
	fma.rn.f32 	%f930, %f923, 0f3FB8AA3B, %f929;
	fma.rn.f32 	%f931, %f923, 0f32A57060, %f930;
	mov.b32 	%r184, %f927;
	shl.b32 	%r185, %r184, 23;
	mov.b32 	%f932, %r185;
	ex2.approx.ftz.f32 	%f933, %f931;
	mul.rn.f32 	%f934, %f933, %f932;
	mul.rn.f32 	%f935, %f903, %f934;
	add.rn.f32 	%f936, %f924, %f935;
	add.s64 	%rd77, %rd73, %rd75;
	st.global.f32 	[%rd77], %f936;
	or.b32  	%r186, %r1, 160;
	mul.hi.u32 	%r187, %r186, -858993459;
	shr.u32 	%r188, %r187, 2;
	mul.wide.u32 	%rd78, %r188, 4;
	add.s64 	%rd79, %rd3, %rd78;
	ld.global.nc.f32 	%f937, [%rd79];
	setp.eq.f32 	%p61, %f937, 0f00000000;
	selp.f32 	%f938, 0fBCA3D70A, 0f00000000, %p61;
	setp.eq.f32 	%p62, %f937, 0f3F800000;
	selp.f32 	%f939, 0fBCA3D70A, 0f00000000, %p62;
	add.rn.f32 	%f940, %f938, %f939;
	setp.eq.f32 	%p63, %f937, 0f40000000;
	selp.f32 	%f941, 0fBCA3D70A, 0f00000000, %p63;
	add.rn.f32 	%f942, %f940, %f941;
	setp.eq.f32 	%p64, %f937, 0f40400000;
	selp.f32 	%f943, 0fBCA3D70A, 0f00000000, %p64;
	add.rn.f32 	%f944, %f942, %f943;
	setp.eq.f32 	%p65, %f937, 0f40800000;
	selp.f32 	%f945, 0fBCA3D70A, 0f00000000, %p65;
	add.rn.f32 	%f946, %f944, %f945;
	setp.eq.f32 	%p66, %f937, 0f40A00000;
	selp.f32 	%f947, 0fBCA3D70A, 0f00000000, %p66;
	add.rn.f32 	%f948, %f946, %f947;
	setp.eq.f32 	%p67, %f937, 0f40C00000;
	selp.f32 	%f949, 0fBCA3D70A, 0f00000000, %p67;
	add.rn.f32 	%f950, %f948, %f949;
	setp.eq.f32 	%p68, %f937, 0f40E00000;
	selp.f32 	%f951, 0fBCA3D70A, 0f00000000, %p68;
	add.rn.f32 	%f952, %f950, %f951;
	setp.eq.f32 	%p69, %f937, 0f41000000;
	selp.f32 	%f953, 0fBCA3D70A, 0f00000000, %p69;
	add.rn.f32 	%f954, %f952, %f953;
	setp.eq.f32 	%p70, %f937, 0f41100000;
	selp.f32 	%f955, 0fBCA3D70A, 0f00000000, %p70;
	add.rn.f32 	%f956, %f954, %f955;
	neg.f32 	%f957, %f956;
	mul.wide.u32 	%rd80, %r188, 40;
	add.s64 	%rd81, %rd5, %rd80;
	ld.global.nc.v2.f32 	{%f958, %f959}, [%rd81];
	add.s64 	%rd82, %rd4, %rd78;
	ld.global.nc.f32 	%f960, [%rd82];
	sub.rn.f32 	%f961, %f958, %f960;
	fma.rn.f32 	%f962, %f961, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f963, %f962;
	fma.rm.f32 	%f964, %f963, %f33, %f32;
	add.rn.f32 	%f965, %f964, 0fCB40007F;
	neg.f32 	%f966, %f965;
	fma.rn.f32 	%f967, %f961, 0f3FB8AA3B, %f966;
	fma.rn.f32 	%f968, %f961, 0f32A57060, %f967;
	ex2.approx.ftz.f32 	%f969, %f968;
	mov.b32 	%r189, %f964;
	shl.b32 	%r190, %r189, 23;
	mov.b32 	%f970, %r190;
	mul.rn.f32 	%f971, %f969, %f970;
	add.rn.f32 	%f972, %f971, 0f00000000;
	sub.rn.f32 	%f973, %f959, %f960;
	fma.rn.f32 	%f974, %f973, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f975, %f974;
	fma.rm.f32 	%f976, %f975, %f33, %f32;
	add.rn.f32 	%f977, %f976, 0fCB40007F;
	neg.f32 	%f978, %f977;
	fma.rn.f32 	%f979, %f973, 0f3FB8AA3B, %f978;
	fma.rn.f32 	%f980, %f973, 0f32A57060, %f979;
	ex2.approx.ftz.f32 	%f981, %f980;
	mov.b32 	%r191, %f976;
	shl.b32 	%r192, %r191, 23;
	mov.b32 	%f982, %r192;
	mul.rn.f32 	%f983, %f981, %f982;
	add.rn.f32 	%f984, %f972, %f983;
	ld.global.nc.v2.f32 	{%f985, %f986}, [%rd81+8];
	sub.rn.f32 	%f987, %f985, %f960;
	fma.rn.f32 	%f988, %f987, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f989, %f988;
	fma.rm.f32 	%f990, %f989, %f33, %f32;
	add.rn.f32 	%f991, %f990, 0fCB40007F;
	neg.f32 	%f992, %f991;
	fma.rn.f32 	%f993, %f987, 0f3FB8AA3B, %f992;
	fma.rn.f32 	%f994, %f987, 0f32A57060, %f993;
	ex2.approx.ftz.f32 	%f995, %f994;
	mov.b32 	%r193, %f990;
	shl.b32 	%r194, %r193, 23;
	mov.b32 	%f996, %r194;
	mul.rn.f32 	%f997, %f995, %f996;
	add.rn.f32 	%f998, %f984, %f997;
	sub.rn.f32 	%f999, %f986, %f960;
	fma.rn.f32 	%f1000, %f999, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1001, %f1000;
	fma.rm.f32 	%f1002, %f1001, %f33, %f32;
	add.rn.f32 	%f1003, %f1002, 0fCB40007F;
	neg.f32 	%f1004, %f1003;
	fma.rn.f32 	%f1005, %f999, 0f3FB8AA3B, %f1004;
	fma.rn.f32 	%f1006, %f999, 0f32A57060, %f1005;
	ex2.approx.ftz.f32 	%f1007, %f1006;
	mov.b32 	%r195, %f1002;
	shl.b32 	%r196, %r195, 23;
	mov.b32 	%f1008, %r196;
	mul.rn.f32 	%f1009, %f1007, %f1008;
	add.rn.f32 	%f1010, %f998, %f1009;
	ld.global.nc.v2.f32 	{%f1011, %f1012}, [%rd81+16];
	sub.rn.f32 	%f1013, %f1011, %f960;
	fma.rn.f32 	%f1014, %f1013, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1015, %f1014;
	fma.rm.f32 	%f1016, %f1015, %f33, %f32;
	add.rn.f32 	%f1017, %f1016, 0fCB40007F;
	neg.f32 	%f1018, %f1017;
	fma.rn.f32 	%f1019, %f1013, 0f3FB8AA3B, %f1018;
	fma.rn.f32 	%f1020, %f1013, 0f32A57060, %f1019;
	ex2.approx.ftz.f32 	%f1021, %f1020;
	mov.b32 	%r197, %f1016;
	shl.b32 	%r198, %r197, 23;
	mov.b32 	%f1022, %r198;
	mul.rn.f32 	%f1023, %f1021, %f1022;
	add.rn.f32 	%f1024, %f1010, %f1023;
	sub.rn.f32 	%f1025, %f1012, %f960;
	fma.rn.f32 	%f1026, %f1025, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1027, %f1026;
	fma.rm.f32 	%f1028, %f1027, %f33, %f32;
	add.rn.f32 	%f1029, %f1028, 0fCB40007F;
	neg.f32 	%f1030, %f1029;
	fma.rn.f32 	%f1031, %f1025, 0f3FB8AA3B, %f1030;
	fma.rn.f32 	%f1032, %f1025, 0f32A57060, %f1031;
	ex2.approx.ftz.f32 	%f1033, %f1032;
	mov.b32 	%r199, %f1028;
	shl.b32 	%r200, %r199, 23;
	mov.b32 	%f1034, %r200;
	mul.rn.f32 	%f1035, %f1033, %f1034;
	add.rn.f32 	%f1036, %f1024, %f1035;
	ld.global.nc.v2.f32 	{%f1037, %f1038}, [%rd81+24];
	sub.rn.f32 	%f1039, %f1037, %f960;
	fma.rn.f32 	%f1040, %f1039, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1041, %f1040;
	fma.rm.f32 	%f1042, %f1041, %f33, %f32;
	add.rn.f32 	%f1043, %f1042, 0fCB40007F;
	neg.f32 	%f1044, %f1043;
	fma.rn.f32 	%f1045, %f1039, 0f3FB8AA3B, %f1044;
	fma.rn.f32 	%f1046, %f1039, 0f32A57060, %f1045;
	ex2.approx.ftz.f32 	%f1047, %f1046;
	mov.b32 	%r201, %f1042;
	shl.b32 	%r202, %r201, 23;
	mov.b32 	%f1048, %r202;
	mul.rn.f32 	%f1049, %f1047, %f1048;
	add.rn.f32 	%f1050, %f1036, %f1049;
	sub.rn.f32 	%f1051, %f1038, %f960;
	fma.rn.f32 	%f1052, %f1051, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1053, %f1052;
	fma.rm.f32 	%f1054, %f1053, %f33, %f32;
	add.rn.f32 	%f1055, %f1054, 0fCB40007F;
	neg.f32 	%f1056, %f1055;
	fma.rn.f32 	%f1057, %f1051, 0f3FB8AA3B, %f1056;
	fma.rn.f32 	%f1058, %f1051, 0f32A57060, %f1057;
	ex2.approx.ftz.f32 	%f1059, %f1058;
	mov.b32 	%r203, %f1054;
	shl.b32 	%r204, %r203, 23;
	mov.b32 	%f1060, %r204;
	mul.rn.f32 	%f1061, %f1059, %f1060;
	add.rn.f32 	%f1062, %f1050, %f1061;
	ld.global.nc.v2.f32 	{%f1063, %f1064}, [%rd81+32];
	sub.rn.f32 	%f1065, %f1063, %f960;
	fma.rn.f32 	%f1066, %f1065, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1067, %f1066;
	fma.rm.f32 	%f1068, %f1067, %f33, %f32;
	add.rn.f32 	%f1069, %f1068, 0fCB40007F;
	neg.f32 	%f1070, %f1069;
	fma.rn.f32 	%f1071, %f1065, 0f3FB8AA3B, %f1070;
	fma.rn.f32 	%f1072, %f1065, 0f32A57060, %f1071;
	ex2.approx.ftz.f32 	%f1073, %f1072;
	mov.b32 	%r205, %f1068;
	shl.b32 	%r206, %r205, 23;
	mov.b32 	%f1074, %r206;
	mul.rn.f32 	%f1075, %f1073, %f1074;
	add.rn.f32 	%f1076, %f1062, %f1075;
	sub.rn.f32 	%f1077, %f1064, %f960;
	fma.rn.f32 	%f1078, %f1077, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1079, %f1078;
	fma.rm.f32 	%f1080, %f1079, %f33, %f32;
	add.rn.f32 	%f1081, %f1080, 0fCB40007F;
	neg.f32 	%f1082, %f1081;
	fma.rn.f32 	%f1083, %f1077, 0f3FB8AA3B, %f1082;
	fma.rn.f32 	%f1084, %f1077, 0f32A57060, %f1083;
	ex2.approx.ftz.f32 	%f1085, %f1084;
	mov.b32 	%r207, %f1080;
	shl.b32 	%r208, %r207, 23;
	mov.b32 	%f1086, %r208;
	mul.rn.f32 	%f1087, %f1085, %f1086;
	add.rn.f32 	%f1088, %f1076, %f1087;
	div.full.f32 	%f1089, %f957, %f1088;
	add.s64 	%rd83, %rd6, %rd78;
	ld.global.nc.f32 	%f1090, [%rd83];
	shl.b32 	%r209, %r186, 1;
	mul.hi.u32 	%r210, %r209, 1717986919;
	shr.u32 	%r211, %r210, 2;
	mul.lo.s32 	%r212, %r211, 10;
	sub.s32 	%r213, %r209, %r212;
	cvt.rn.f32.u32 	%f1091, %r213;
	setp.eq.f32 	%p71, %f937, %f1091;
	mul.wide.u32 	%rd84, %r213, 4;
	add.s64 	%rd85, %rd81, %rd84;
	ld.global.nc.f32 	%f1092, [%rd85];
	sub.rn.f32 	%f1093, %f1092, %f960;
	selp.f32 	%f1094, 0fBCA3D70A, 0f00000000, %p71;
	fma.rn.f32 	%f1095, %f1093, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1096, %f1095;
	fma.rm.f32 	%f1097, %f1096, %f33, %f32;
	add.rn.f32 	%f1098, %f1097, 0fCB40007F;
	neg.f32 	%f1099, %f1098;
	fma.rn.f32 	%f1100, %f1093, 0f3FB8AA3B, %f1099;
	fma.rn.f32 	%f1101, %f1093, 0f32A57060, %f1100;
	mov.b32 	%r214, %f1097;
	shl.b32 	%r215, %r214, 23;
	mov.b32 	%f1102, %r215;
	ex2.approx.ftz.f32 	%f1103, %f1101;
	mul.rn.f32 	%f1104, %f1103, %f1102;
	mul.rn.f32 	%f1105, %f1089, %f1104;
	add.rn.f32 	%f1106, %f1094, %f1105;
	add.s64 	%rd86, %rd1, %rd80;
	add.s64 	%rd87, %rd86, %rd84;
	st.global.f32 	[%rd87], %f1106;
	or.b32  	%r216, %r209, 1;
	mul.hi.u32 	%r217, %r216, 1717986919;
	shr.u32 	%r218, %r217, 2;
	mul.lo.s32 	%r219, %r218, 10;
	sub.s32 	%r220, %r216, %r219;
	cvt.rn.f32.u32 	%f1107, %r220;
	setp.eq.f32 	%p72, %f937, %f1107;
	mul.wide.u32 	%rd88, %r220, 4;
	add.s64 	%rd89, %rd81, %rd88;
	ld.global.nc.f32 	%f1108, [%rd89];
	sub.rn.f32 	%f1109, %f1108, %f960;
	selp.f32 	%f1110, 0fBCA3D70A, 0f00000000, %p72;
	fma.rn.f32 	%f1111, %f1109, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1112, %f1111;
	fma.rm.f32 	%f1113, %f1112, %f33, %f32;
	add.rn.f32 	%f1114, %f1113, 0fCB40007F;
	neg.f32 	%f1115, %f1114;
	fma.rn.f32 	%f1116, %f1109, 0f3FB8AA3B, %f1115;
	fma.rn.f32 	%f1117, %f1109, 0f32A57060, %f1116;
	mov.b32 	%r221, %f1113;
	shl.b32 	%r222, %r221, 23;
	mov.b32 	%f1118, %r222;
	ex2.approx.ftz.f32 	%f1119, %f1117;
	mul.rn.f32 	%f1120, %f1119, %f1118;
	mul.rn.f32 	%f1121, %f1089, %f1120;
	add.rn.f32 	%f1122, %f1110, %f1121;
	add.s64 	%rd90, %rd86, %rd88;
	st.global.f32 	[%rd90], %f1122;
	or.b32  	%r223, %r1, 192;
	mul.hi.u32 	%r224, %r223, -858993459;
	shr.u32 	%r225, %r224, 2;
	mul.wide.u32 	%rd91, %r225, 4;
	add.s64 	%rd92, %rd3, %rd91;
	ld.global.nc.f32 	%f1123, [%rd92];
	setp.eq.f32 	%p73, %f1123, 0f00000000;
	selp.f32 	%f1124, 0fBCA3D70A, 0f00000000, %p73;
	setp.eq.f32 	%p74, %f1123, 0f3F800000;
	selp.f32 	%f1125, 0fBCA3D70A, 0f00000000, %p74;
	add.rn.f32 	%f1126, %f1124, %f1125;
	setp.eq.f32 	%p75, %f1123, 0f40000000;
	selp.f32 	%f1127, 0fBCA3D70A, 0f00000000, %p75;
	add.rn.f32 	%f1128, %f1126, %f1127;
	setp.eq.f32 	%p76, %f1123, 0f40400000;
	selp.f32 	%f1129, 0fBCA3D70A, 0f00000000, %p76;
	add.rn.f32 	%f1130, %f1128, %f1129;
	setp.eq.f32 	%p77, %f1123, 0f40800000;
	selp.f32 	%f1131, 0fBCA3D70A, 0f00000000, %p77;
	add.rn.f32 	%f1132, %f1130, %f1131;
	setp.eq.f32 	%p78, %f1123, 0f40A00000;
	selp.f32 	%f1133, 0fBCA3D70A, 0f00000000, %p78;
	add.rn.f32 	%f1134, %f1132, %f1133;
	setp.eq.f32 	%p79, %f1123, 0f40C00000;
	selp.f32 	%f1135, 0fBCA3D70A, 0f00000000, %p79;
	add.rn.f32 	%f1136, %f1134, %f1135;
	setp.eq.f32 	%p80, %f1123, 0f40E00000;
	selp.f32 	%f1137, 0fBCA3D70A, 0f00000000, %p80;
	add.rn.f32 	%f1138, %f1136, %f1137;
	setp.eq.f32 	%p81, %f1123, 0f41000000;
	selp.f32 	%f1139, 0fBCA3D70A, 0f00000000, %p81;
	add.rn.f32 	%f1140, %f1138, %f1139;
	setp.eq.f32 	%p82, %f1123, 0f41100000;
	selp.f32 	%f1141, 0fBCA3D70A, 0f00000000, %p82;
	add.rn.f32 	%f1142, %f1140, %f1141;
	neg.f32 	%f1143, %f1142;
	mul.wide.u32 	%rd93, %r225, 40;
	add.s64 	%rd94, %rd5, %rd93;
	ld.global.nc.v2.f32 	{%f1144, %f1145}, [%rd94];
	add.s64 	%rd95, %rd4, %rd91;
	ld.global.nc.f32 	%f1146, [%rd95];
	sub.rn.f32 	%f1147, %f1144, %f1146;
	fma.rn.f32 	%f1148, %f1147, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1149, %f1148;
	fma.rm.f32 	%f1150, %f1149, %f33, %f32;
	add.rn.f32 	%f1151, %f1150, 0fCB40007F;
	neg.f32 	%f1152, %f1151;
	fma.rn.f32 	%f1153, %f1147, 0f3FB8AA3B, %f1152;
	fma.rn.f32 	%f1154, %f1147, 0f32A57060, %f1153;
	ex2.approx.ftz.f32 	%f1155, %f1154;
	mov.b32 	%r226, %f1150;
	shl.b32 	%r227, %r226, 23;
	mov.b32 	%f1156, %r227;
	mul.rn.f32 	%f1157, %f1155, %f1156;
	add.rn.f32 	%f1158, %f1157, 0f00000000;
	sub.rn.f32 	%f1159, %f1145, %f1146;
	fma.rn.f32 	%f1160, %f1159, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1161, %f1160;
	fma.rm.f32 	%f1162, %f1161, %f33, %f32;
	add.rn.f32 	%f1163, %f1162, 0fCB40007F;
	neg.f32 	%f1164, %f1163;
	fma.rn.f32 	%f1165, %f1159, 0f3FB8AA3B, %f1164;
	fma.rn.f32 	%f1166, %f1159, 0f32A57060, %f1165;
	ex2.approx.ftz.f32 	%f1167, %f1166;
	mov.b32 	%r228, %f1162;
	shl.b32 	%r229, %r228, 23;
	mov.b32 	%f1168, %r229;
	mul.rn.f32 	%f1169, %f1167, %f1168;
	add.rn.f32 	%f1170, %f1158, %f1169;
	ld.global.nc.v2.f32 	{%f1171, %f1172}, [%rd94+8];
	sub.rn.f32 	%f1173, %f1171, %f1146;
	fma.rn.f32 	%f1174, %f1173, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1175, %f1174;
	fma.rm.f32 	%f1176, %f1175, %f33, %f32;
	add.rn.f32 	%f1177, %f1176, 0fCB40007F;
	neg.f32 	%f1178, %f1177;
	fma.rn.f32 	%f1179, %f1173, 0f3FB8AA3B, %f1178;
	fma.rn.f32 	%f1180, %f1173, 0f32A57060, %f1179;
	ex2.approx.ftz.f32 	%f1181, %f1180;
	mov.b32 	%r230, %f1176;
	shl.b32 	%r231, %r230, 23;
	mov.b32 	%f1182, %r231;
	mul.rn.f32 	%f1183, %f1181, %f1182;
	add.rn.f32 	%f1184, %f1170, %f1183;
	sub.rn.f32 	%f1185, %f1172, %f1146;
	fma.rn.f32 	%f1186, %f1185, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1187, %f1186;
	fma.rm.f32 	%f1188, %f1187, %f33, %f32;
	add.rn.f32 	%f1189, %f1188, 0fCB40007F;
	neg.f32 	%f1190, %f1189;
	fma.rn.f32 	%f1191, %f1185, 0f3FB8AA3B, %f1190;
	fma.rn.f32 	%f1192, %f1185, 0f32A57060, %f1191;
	ex2.approx.ftz.f32 	%f1193, %f1192;
	mov.b32 	%r232, %f1188;
	shl.b32 	%r233, %r232, 23;
	mov.b32 	%f1194, %r233;
	mul.rn.f32 	%f1195, %f1193, %f1194;
	add.rn.f32 	%f1196, %f1184, %f1195;
	ld.global.nc.v2.f32 	{%f1197, %f1198}, [%rd94+16];
	sub.rn.f32 	%f1199, %f1197, %f1146;
	fma.rn.f32 	%f1200, %f1199, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1201, %f1200;
	fma.rm.f32 	%f1202, %f1201, %f33, %f32;
	add.rn.f32 	%f1203, %f1202, 0fCB40007F;
	neg.f32 	%f1204, %f1203;
	fma.rn.f32 	%f1205, %f1199, 0f3FB8AA3B, %f1204;
	fma.rn.f32 	%f1206, %f1199, 0f32A57060, %f1205;
	ex2.approx.ftz.f32 	%f1207, %f1206;
	mov.b32 	%r234, %f1202;
	shl.b32 	%r235, %r234, 23;
	mov.b32 	%f1208, %r235;
	mul.rn.f32 	%f1209, %f1207, %f1208;
	add.rn.f32 	%f1210, %f1196, %f1209;
	sub.rn.f32 	%f1211, %f1198, %f1146;
	fma.rn.f32 	%f1212, %f1211, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1213, %f1212;
	fma.rm.f32 	%f1214, %f1213, %f33, %f32;
	add.rn.f32 	%f1215, %f1214, 0fCB40007F;
	neg.f32 	%f1216, %f1215;
	fma.rn.f32 	%f1217, %f1211, 0f3FB8AA3B, %f1216;
	fma.rn.f32 	%f1218, %f1211, 0f32A57060, %f1217;
	ex2.approx.ftz.f32 	%f1219, %f1218;
	mov.b32 	%r236, %f1214;
	shl.b32 	%r237, %r236, 23;
	mov.b32 	%f1220, %r237;
	mul.rn.f32 	%f1221, %f1219, %f1220;
	add.rn.f32 	%f1222, %f1210, %f1221;
	ld.global.nc.v2.f32 	{%f1223, %f1224}, [%rd94+24];
	sub.rn.f32 	%f1225, %f1223, %f1146;
	fma.rn.f32 	%f1226, %f1225, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1227, %f1226;
	fma.rm.f32 	%f1228, %f1227, %f33, %f32;
	add.rn.f32 	%f1229, %f1228, 0fCB40007F;
	neg.f32 	%f1230, %f1229;
	fma.rn.f32 	%f1231, %f1225, 0f3FB8AA3B, %f1230;
	fma.rn.f32 	%f1232, %f1225, 0f32A57060, %f1231;
	ex2.approx.ftz.f32 	%f1233, %f1232;
	mov.b32 	%r238, %f1228;
	shl.b32 	%r239, %r238, 23;
	mov.b32 	%f1234, %r239;
	mul.rn.f32 	%f1235, %f1233, %f1234;
	add.rn.f32 	%f1236, %f1222, %f1235;
	sub.rn.f32 	%f1237, %f1224, %f1146;
	fma.rn.f32 	%f1238, %f1237, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1239, %f1238;
	fma.rm.f32 	%f1240, %f1239, %f33, %f32;
	add.rn.f32 	%f1241, %f1240, 0fCB40007F;
	neg.f32 	%f1242, %f1241;
	fma.rn.f32 	%f1243, %f1237, 0f3FB8AA3B, %f1242;
	fma.rn.f32 	%f1244, %f1237, 0f32A57060, %f1243;
	ex2.approx.ftz.f32 	%f1245, %f1244;
	mov.b32 	%r240, %f1240;
	shl.b32 	%r241, %r240, 23;
	mov.b32 	%f1246, %r241;
	mul.rn.f32 	%f1247, %f1245, %f1246;
	add.rn.f32 	%f1248, %f1236, %f1247;
	ld.global.nc.v2.f32 	{%f1249, %f1250}, [%rd94+32];
	sub.rn.f32 	%f1251, %f1249, %f1146;
	fma.rn.f32 	%f1252, %f1251, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1253, %f1252;
	fma.rm.f32 	%f1254, %f1253, %f33, %f32;
	add.rn.f32 	%f1255, %f1254, 0fCB40007F;
	neg.f32 	%f1256, %f1255;
	fma.rn.f32 	%f1257, %f1251, 0f3FB8AA3B, %f1256;
	fma.rn.f32 	%f1258, %f1251, 0f32A57060, %f1257;
	ex2.approx.ftz.f32 	%f1259, %f1258;
	mov.b32 	%r242, %f1254;
	shl.b32 	%r243, %r242, 23;
	mov.b32 	%f1260, %r243;
	mul.rn.f32 	%f1261, %f1259, %f1260;
	add.rn.f32 	%f1262, %f1248, %f1261;
	sub.rn.f32 	%f1263, %f1250, %f1146;
	fma.rn.f32 	%f1264, %f1263, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1265, %f1264;
	fma.rm.f32 	%f1266, %f1265, %f33, %f32;
	add.rn.f32 	%f1267, %f1266, 0fCB40007F;
	neg.f32 	%f1268, %f1267;
	fma.rn.f32 	%f1269, %f1263, 0f3FB8AA3B, %f1268;
	fma.rn.f32 	%f1270, %f1263, 0f32A57060, %f1269;
	ex2.approx.ftz.f32 	%f1271, %f1270;
	mov.b32 	%r244, %f1266;
	shl.b32 	%r245, %r244, 23;
	mov.b32 	%f1272, %r245;
	mul.rn.f32 	%f1273, %f1271, %f1272;
	add.rn.f32 	%f1274, %f1262, %f1273;
	div.full.f32 	%f1275, %f1143, %f1274;
	add.s64 	%rd96, %rd6, %rd91;
	ld.global.nc.f32 	%f1276, [%rd96];
	shl.b32 	%r246, %r223, 1;
	sub.rn.f32 	%f1277, %f163, %f160;
	add.rn.f32 	%f1278, %f1277, 0f00000000;
	selp.f32 	%f1279, %f1278, 0f00000000, %p11;
	sub.rn.f32 	%f1280, %f179, %f160;
	selp.f32 	%f1281, %f1280, 0f00000000, %p12;
	add.rn.f32 	%f1282, %f1279, %f1281;
	sub.rn.f32 	%f1283, %f349, %f346;
	selp.f32 	%f1284, %f1283, 0f00000000, %p23;
	add.rn.f32 	%f1285, %f1282, %f1284;
	sub.rn.f32 	%f1286, %f365, %f346;
	selp.f32 	%f1287, %f1286, 0f00000000, %p24;
	add.rn.f32 	%f1288, %f1285, %f1287;
	sub.rn.f32 	%f1289, %f535, %f532;
	selp.f32 	%f1290, %f1289, 0f00000000, %p35;
	add.rn.f32 	%f1291, %f1288, %f1290;
	sub.rn.f32 	%f1292, %f551, %f532;
	selp.f32 	%f1293, %f1292, 0f00000000, %p36;
	add.rn.f32 	%f1294, %f1291, %f1293;
	sub.rn.f32 	%f1295, %f721, %f718;
	selp.f32 	%f1296, %f1295, 0f00000000, %p47;
	add.rn.f32 	%f1297, %f1294, %f1296;
	sub.rn.f32 	%f1298, %f737, %f718;
	selp.f32 	%f1299, %f1298, 0f00000000, %p48;
	add.rn.f32 	%f1300, %f1297, %f1299;
	sub.rn.f32 	%f1301, %f907, %f904;
	selp.f32 	%f1302, %f1301, 0f00000000, %p59;
	add.rn.f32 	%f1303, %f1300, %f1302;
	sub.rn.f32 	%f1304, %f923, %f904;
	selp.f32 	%f1305, %f1304, 0f00000000, %p60;
	add.rn.f32 	%f1306, %f1303, %f1305;
	sub.rn.f32 	%f1307, %f1093, %f1090;
	selp.f32 	%f1308, %f1307, 0f00000000, %p71;
	add.rn.f32 	%f1309, %f1306, %f1308;
	sub.rn.f32 	%f1310, %f1109, %f1090;
	selp.f32 	%f1311, %f1310, 0f00000000, %p72;
	add.rn.f32 	%f1312, %f1309, %f1311;
	mul.hi.u32 	%r247, %r246, 1717986919;
	shr.u32 	%r248, %r247, 2;
	mul.lo.s32 	%r249, %r248, 10;
	sub.s32 	%r250, %r246, %r249;
	cvt.rn.f32.u32 	%f1313, %r250;
	setp.eq.f32 	%p83, %f1123, %f1313;
	mul.wide.u32 	%rd97, %r250, 4;
	add.s64 	%rd98, %rd94, %rd97;
	ld.global.nc.f32 	%f1314, [%rd98];
	sub.rn.f32 	%f1315, %f1314, %f1146;
	sub.rn.f32 	%f1316, %f1315, %f1276;
	selp.f32 	%f1317, %f1316, 0f00000000, %p83;
	add.rn.f32 	%f1318, %f1312, %f1317;
	selp.f32 	%f1319, 0fBCA3D70A, 0f00000000, %p83;
	fma.rn.f32 	%f1320, %f1315, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1321, %f1320;
	fma.rm.f32 	%f1322, %f1321, %f33, %f32;
	add.rn.f32 	%f1323, %f1322, 0fCB40007F;
	neg.f32 	%f1324, %f1323;
	fma.rn.f32 	%f1325, %f1315, 0f3FB8AA3B, %f1324;
	fma.rn.f32 	%f1326, %f1315, 0f32A57060, %f1325;
	mov.b32 	%r251, %f1322;
	shl.b32 	%r252, %r251, 23;
	mov.b32 	%f1327, %r252;
	ex2.approx.ftz.f32 	%f1328, %f1326;
	mul.rn.f32 	%f1329, %f1328, %f1327;
	mul.rn.f32 	%f1330, %f1275, %f1329;
	add.rn.f32 	%f1331, %f1319, %f1330;
	add.s64 	%rd99, %rd1, %rd93;
	add.s64 	%rd100, %rd99, %rd97;
	st.global.f32 	[%rd100], %f1331;
	or.b32  	%r253, %r246, 1;
	mul.hi.u32 	%r254, %r253, 1717986919;
	shr.u32 	%r255, %r254, 2;
	mul.lo.s32 	%r256, %r255, 10;
	sub.s32 	%r257, %r253, %r256;
	cvt.rn.f32.u32 	%f1332, %r257;
	setp.eq.f32 	%p84, %f1123, %f1332;
	mul.wide.u32 	%rd101, %r257, 4;
	add.s64 	%rd102, %rd94, %rd101;
	ld.global.nc.f32 	%f1333, [%rd102];
	sub.rn.f32 	%f1334, %f1333, %f1146;
	sub.rn.f32 	%f1335, %f1334, %f1276;
	selp.f32 	%f1336, %f1335, 0f00000000, %p84;
	add.rn.f32 	%f1554, %f1318, %f1336;
	selp.f32 	%f1337, 0fBCA3D70A, 0f00000000, %p84;
	fma.rn.f32 	%f1338, %f1334, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1339, %f1338;
	fma.rm.f32 	%f1340, %f1339, %f33, %f32;
	add.rn.f32 	%f1341, %f1340, 0fCB40007F;
	neg.f32 	%f1342, %f1341;
	fma.rn.f32 	%f1343, %f1334, 0f3FB8AA3B, %f1342;
	fma.rn.f32 	%f1344, %f1334, 0f32A57060, %f1343;
	mov.b32 	%r258, %f1340;
	shl.b32 	%r259, %r258, 23;
	mov.b32 	%f1345, %r259;
	ex2.approx.ftz.f32 	%f1346, %f1344;
	mul.rn.f32 	%f1347, %f1346, %f1345;
	mul.rn.f32 	%f1348, %f1275, %f1347;
	add.rn.f32 	%f1349, %f1337, %f1348;
	add.s64 	%rd103, %rd99, %rd101;
	st.global.f32 	[%rd103], %f1349;
	or.b32  	%r2, %r1, 224;
	setp.lt.u32 	%p85, %r2, 250;
	@%p85 bra 	$L__BB98_1;
	bra.uni 	$L__BB98_2;
$L__BB98_1:
	cvt.u16.u32 	%rs5, %r2;
	and.b16  	%rs6, %rs5, 255;
	mul.lo.s16 	%rs7, %rs6, 205;
	shr.u16 	%rs8, %rs7, 10;
	cvt.u32.u16 	%r260, %rs8;
	mul.wide.u32 	%rd104, %r260, 4;
	add.s64 	%rd105, %rd3, %rd104;
	ld.global.nc.f32 	%f1350, [%rd105];
	setp.eq.f32 	%p86, %f1350, 0f00000000;
	selp.f32 	%f1351, 0fBCA3D70A, 0f00000000, %p86;
	setp.eq.f32 	%p87, %f1350, 0f3F800000;
	selp.f32 	%f1352, 0fBCA3D70A, 0f00000000, %p87;
	add.rn.f32 	%f1353, %f1351, %f1352;
	setp.eq.f32 	%p88, %f1350, 0f40000000;
	selp.f32 	%f1354, 0fBCA3D70A, 0f00000000, %p88;
	add.rn.f32 	%f1355, %f1353, %f1354;
	setp.eq.f32 	%p89, %f1350, 0f40400000;
	selp.f32 	%f1356, 0fBCA3D70A, 0f00000000, %p89;
	add.rn.f32 	%f1357, %f1355, %f1356;
	setp.eq.f32 	%p90, %f1350, 0f40800000;
	selp.f32 	%f1358, 0fBCA3D70A, 0f00000000, %p90;
	add.rn.f32 	%f1359, %f1357, %f1358;
	setp.eq.f32 	%p91, %f1350, 0f40A00000;
	selp.f32 	%f1360, 0fBCA3D70A, 0f00000000, %p91;
	add.rn.f32 	%f1361, %f1359, %f1360;
	setp.eq.f32 	%p92, %f1350, 0f40C00000;
	selp.f32 	%f1362, 0fBCA3D70A, 0f00000000, %p92;
	add.rn.f32 	%f1363, %f1361, %f1362;
	setp.eq.f32 	%p93, %f1350, 0f40E00000;
	selp.f32 	%f1364, 0fBCA3D70A, 0f00000000, %p93;
	add.rn.f32 	%f1365, %f1363, %f1364;
	setp.eq.f32 	%p94, %f1350, 0f41000000;
	selp.f32 	%f1366, 0fBCA3D70A, 0f00000000, %p94;
	add.rn.f32 	%f1367, %f1365, %f1366;
	setp.eq.f32 	%p95, %f1350, 0f41100000;
	selp.f32 	%f1368, 0fBCA3D70A, 0f00000000, %p95;
	add.rn.f32 	%f1369, %f1367, %f1368;
	neg.f32 	%f1370, %f1369;
	mul.wide.u32 	%rd106, %r260, 40;
	add.s64 	%rd107, %rd5, %rd106;
	ld.global.nc.v2.f32 	{%f1371, %f1372}, [%rd107];
	add.s64 	%rd108, %rd4, %rd104;
	ld.global.nc.f32 	%f1373, [%rd108];
	sub.rn.f32 	%f1374, %f1371, %f1373;
	fma.rn.f32 	%f1375, %f1374, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1376, %f1375;
	fma.rm.f32 	%f1379, %f1376, %f33, %f32;
	add.rn.f32 	%f1380, %f1379, 0fCB40007F;
	neg.f32 	%f1381, %f1380;
	fma.rn.f32 	%f1382, %f1374, 0f3FB8AA3B, %f1381;
	fma.rn.f32 	%f1383, %f1374, 0f32A57060, %f1382;
	ex2.approx.ftz.f32 	%f1384, %f1383;
	mov.b32 	%r261, %f1379;
	shl.b32 	%r262, %r261, 23;
	mov.b32 	%f1385, %r262;
	mul.rn.f32 	%f1386, %f1384, %f1385;
	add.rn.f32 	%f1387, %f1386, 0f00000000;
	sub.rn.f32 	%f1388, %f1372, %f1373;
	fma.rn.f32 	%f1389, %f1388, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1390, %f1389;
	fma.rm.f32 	%f1391, %f1390, %f33, %f32;
	add.rn.f32 	%f1392, %f1391, 0fCB40007F;
	neg.f32 	%f1393, %f1392;
	fma.rn.f32 	%f1394, %f1388, 0f3FB8AA3B, %f1393;
	fma.rn.f32 	%f1395, %f1388, 0f32A57060, %f1394;
	ex2.approx.ftz.f32 	%f1396, %f1395;
	mov.b32 	%r263, %f1391;
	shl.b32 	%r264, %r263, 23;
	mov.b32 	%f1397, %r264;
	mul.rn.f32 	%f1398, %f1396, %f1397;
	add.rn.f32 	%f1399, %f1387, %f1398;
	ld.global.nc.v2.f32 	{%f1400, %f1401}, [%rd107+8];
	sub.rn.f32 	%f1402, %f1400, %f1373;
	fma.rn.f32 	%f1403, %f1402, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1404, %f1403;
	fma.rm.f32 	%f1405, %f1404, %f33, %f32;
	add.rn.f32 	%f1406, %f1405, 0fCB40007F;
	neg.f32 	%f1407, %f1406;
	fma.rn.f32 	%f1408, %f1402, 0f3FB8AA3B, %f1407;
	fma.rn.f32 	%f1409, %f1402, 0f32A57060, %f1408;
	ex2.approx.ftz.f32 	%f1410, %f1409;
	mov.b32 	%r265, %f1405;
	shl.b32 	%r266, %r265, 23;
	mov.b32 	%f1411, %r266;
	mul.rn.f32 	%f1412, %f1410, %f1411;
	add.rn.f32 	%f1413, %f1399, %f1412;
	sub.rn.f32 	%f1414, %f1401, %f1373;
	fma.rn.f32 	%f1415, %f1414, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1416, %f1415;
	fma.rm.f32 	%f1417, %f1416, %f33, %f32;
	add.rn.f32 	%f1418, %f1417, 0fCB40007F;
	neg.f32 	%f1419, %f1418;
	fma.rn.f32 	%f1420, %f1414, 0f3FB8AA3B, %f1419;
	fma.rn.f32 	%f1421, %f1414, 0f32A57060, %f1420;
	ex2.approx.ftz.f32 	%f1422, %f1421;
	mov.b32 	%r267, %f1417;
	shl.b32 	%r268, %r267, 23;
	mov.b32 	%f1423, %r268;
	mul.rn.f32 	%f1424, %f1422, %f1423;
	add.rn.f32 	%f1425, %f1413, %f1424;
	ld.global.nc.v2.f32 	{%f1426, %f1427}, [%rd107+16];
	sub.rn.f32 	%f1428, %f1426, %f1373;
	fma.rn.f32 	%f1429, %f1428, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1430, %f1429;
	fma.rm.f32 	%f1431, %f1430, %f33, %f32;
	add.rn.f32 	%f1432, %f1431, 0fCB40007F;
	neg.f32 	%f1433, %f1432;
	fma.rn.f32 	%f1434, %f1428, 0f3FB8AA3B, %f1433;
	fma.rn.f32 	%f1435, %f1428, 0f32A57060, %f1434;
	ex2.approx.ftz.f32 	%f1436, %f1435;
	mov.b32 	%r269, %f1431;
	shl.b32 	%r270, %r269, 23;
	mov.b32 	%f1437, %r270;
	mul.rn.f32 	%f1438, %f1436, %f1437;
	add.rn.f32 	%f1439, %f1425, %f1438;
	sub.rn.f32 	%f1440, %f1427, %f1373;
	fma.rn.f32 	%f1441, %f1440, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1442, %f1441;
	fma.rm.f32 	%f1443, %f1442, %f33, %f32;
	add.rn.f32 	%f1444, %f1443, 0fCB40007F;
	neg.f32 	%f1445, %f1444;
	fma.rn.f32 	%f1446, %f1440, 0f3FB8AA3B, %f1445;
	fma.rn.f32 	%f1447, %f1440, 0f32A57060, %f1446;
	ex2.approx.ftz.f32 	%f1448, %f1447;
	mov.b32 	%r271, %f1443;
	shl.b32 	%r272, %r271, 23;
	mov.b32 	%f1449, %r272;
	mul.rn.f32 	%f1450, %f1448, %f1449;
	add.rn.f32 	%f1451, %f1439, %f1450;
	ld.global.nc.v2.f32 	{%f1452, %f1453}, [%rd107+24];
	sub.rn.f32 	%f1454, %f1452, %f1373;
	fma.rn.f32 	%f1455, %f1454, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1456, %f1455;
	fma.rm.f32 	%f1457, %f1456, %f33, %f32;
	add.rn.f32 	%f1458, %f1457, 0fCB40007F;
	neg.f32 	%f1459, %f1458;
	fma.rn.f32 	%f1460, %f1454, 0f3FB8AA3B, %f1459;
	fma.rn.f32 	%f1461, %f1454, 0f32A57060, %f1460;
	ex2.approx.ftz.f32 	%f1462, %f1461;
	mov.b32 	%r273, %f1457;
	shl.b32 	%r274, %r273, 23;
	mov.b32 	%f1463, %r274;
	mul.rn.f32 	%f1464, %f1462, %f1463;
	add.rn.f32 	%f1465, %f1451, %f1464;
	sub.rn.f32 	%f1466, %f1453, %f1373;
	fma.rn.f32 	%f1467, %f1466, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1468, %f1467;
	fma.rm.f32 	%f1469, %f1468, %f33, %f32;
	add.rn.f32 	%f1470, %f1469, 0fCB40007F;
	neg.f32 	%f1471, %f1470;
	fma.rn.f32 	%f1472, %f1466, 0f3FB8AA3B, %f1471;
	fma.rn.f32 	%f1473, %f1466, 0f32A57060, %f1472;
	ex2.approx.ftz.f32 	%f1474, %f1473;
	mov.b32 	%r275, %f1469;
	shl.b32 	%r276, %r275, 23;
	mov.b32 	%f1475, %r276;
	mul.rn.f32 	%f1476, %f1474, %f1475;
	add.rn.f32 	%f1477, %f1465, %f1476;
	ld.global.nc.v2.f32 	{%f1478, %f1479}, [%rd107+32];
	sub.rn.f32 	%f1480, %f1478, %f1373;
	fma.rn.f32 	%f1481, %f1480, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1482, %f1481;
	fma.rm.f32 	%f1483, %f1482, %f33, %f32;
	add.rn.f32 	%f1484, %f1483, 0fCB40007F;
	neg.f32 	%f1485, %f1484;
	fma.rn.f32 	%f1486, %f1480, 0f3FB8AA3B, %f1485;
	fma.rn.f32 	%f1487, %f1480, 0f32A57060, %f1486;
	ex2.approx.ftz.f32 	%f1488, %f1487;
	mov.b32 	%r277, %f1483;
	shl.b32 	%r278, %r277, 23;
	mov.b32 	%f1489, %r278;
	mul.rn.f32 	%f1490, %f1488, %f1489;
	add.rn.f32 	%f1491, %f1477, %f1490;
	sub.rn.f32 	%f1492, %f1479, %f1373;
	fma.rn.f32 	%f1493, %f1492, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1494, %f1493;
	fma.rm.f32 	%f1495, %f1494, %f33, %f32;
	add.rn.f32 	%f1496, %f1495, 0fCB40007F;
	neg.f32 	%f1497, %f1496;
	fma.rn.f32 	%f1498, %f1492, 0f3FB8AA3B, %f1497;
	fma.rn.f32 	%f1499, %f1492, 0f32A57060, %f1498;
	ex2.approx.ftz.f32 	%f1500, %f1499;
	mov.b32 	%r279, %f1495;
	shl.b32 	%r280, %r279, 23;
	mov.b32 	%f1501, %r280;
	mul.rn.f32 	%f1502, %f1500, %f1501;
	add.rn.f32 	%f1503, %f1491, %f1502;
	div.full.f32 	%f1504, %f1370, %f1503;
	add.s64 	%rd109, %rd6, %rd104;
	ld.global.nc.f32 	%f1505, [%rd109];
	shl.b32 	%r281, %r2, 1;
	mul.hi.u32 	%r282, %r281, 1717986919;
	shr.u32 	%r283, %r282, 2;
	mul.lo.s32 	%r284, %r283, 10;
	sub.s32 	%r285, %r281, %r284;
	cvt.rn.f32.u32 	%f1506, %r285;
	setp.eq.f32 	%p96, %f1350, %f1506;
	mul.wide.u32 	%rd110, %r285, 4;
	add.s64 	%rd111, %rd107, %rd110;
	ld.global.nc.f32 	%f1507, [%rd111];
	sub.rn.f32 	%f1508, %f1507, %f1373;
	sub.rn.f32 	%f1509, %f1508, %f1505;
	selp.f32 	%f1510, %f1509, 0f00000000, %p96;
	add.rn.f32 	%f1511, %f1554, %f1510;
	selp.f32 	%f1512, 0fBCA3D70A, 0f00000000, %p96;
	fma.rn.f32 	%f1513, %f1508, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1514, %f1513;
	fma.rm.f32 	%f1515, %f1514, %f33, %f32;
	add.rn.f32 	%f1516, %f1515, 0fCB40007F;
	neg.f32 	%f1517, %f1516;
	fma.rn.f32 	%f1518, %f1508, 0f3FB8AA3B, %f1517;
	fma.rn.f32 	%f1519, %f1508, 0f32A57060, %f1518;
	mov.b32 	%r286, %f1515;
	shl.b32 	%r287, %r286, 23;
	mov.b32 	%f1520, %r287;
	ex2.approx.ftz.f32 	%f1521, %f1519;
	mul.rn.f32 	%f1522, %f1521, %f1520;
	mul.rn.f32 	%f1523, %f1504, %f1522;
	add.rn.f32 	%f1524, %f1512, %f1523;
	add.s64 	%rd112, %rd1, %rd106;
	add.s64 	%rd113, %rd112, %rd110;
	st.global.f32 	[%rd113], %f1524;
	or.b32  	%r288, %r281, 1;
	mul.hi.u32 	%r289, %r288, 1717986919;
	shr.u32 	%r290, %r289, 2;
	mul.lo.s32 	%r291, %r290, 10;
	sub.s32 	%r292, %r288, %r291;
	cvt.rn.f32.u32 	%f1525, %r292;
	setp.eq.f32 	%p97, %f1350, %f1525;
	mul.wide.u32 	%rd114, %r292, 4;
	add.s64 	%rd115, %rd107, %rd114;
	ld.global.nc.f32 	%f1526, [%rd115];
	sub.rn.f32 	%f1527, %f1526, %f1373;
	sub.rn.f32 	%f1528, %f1527, %f1505;
	selp.f32 	%f1529, %f1528, 0f00000000, %p97;
	add.rn.f32 	%f1554, %f1511, %f1529;
	selp.f32 	%f1530, 0fBCA3D70A, 0f00000000, %p97;
	fma.rn.f32 	%f1531, %f1527, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f1532, %f1531;
	fma.rm.f32 	%f1533, %f1532, %f33, %f32;
	add.rn.f32 	%f1534, %f1533, 0fCB40007F;
	neg.f32 	%f1535, %f1534;
	fma.rn.f32 	%f1536, %f1527, 0f3FB8AA3B, %f1535;
	fma.rn.f32 	%f1537, %f1527, 0f32A57060, %f1536;
	mov.b32 	%r293, %f1533;
	shl.b32 	%r294, %r293, 23;
	mov.b32 	%f1538, %r294;
	ex2.approx.ftz.f32 	%f1539, %f1537;
	mul.rn.f32 	%f1540, %f1539, %f1538;
	mul.rn.f32 	%f1541, %f1504, %f1540;
	add.rn.f32 	%f1542, %f1530, %f1541;
	add.s64 	%rd116, %rd112, %rd114;
	st.global.f32 	[%rd116], %f1542;
$L__BB98_2:
	shfl.sync.down.b32	%f1543, %f1554, 16, 31, -1;
	add.rn.f32 	%f1544, %f1554, %f1543;
	shfl.sync.down.b32	%f1545, %f1544, 8, 31, -1;
	add.rn.f32 	%f1546, %f1544, %f1545;
	shfl.sync.down.b32	%f1547, %f1546, 4, 31, -1;
	add.rn.f32 	%f1548, %f1546, %f1547;
	shfl.sync.down.b32	%f1549, %f1548, 2, 31, -1;
	add.rn.f32 	%f1550, %f1548, %f1549;
	shfl.sync.down.b32	%f1551, %f1550, 1, 31, -1;
	setp.eq.s32 	%p98, %r1, 0;
	@%p98 bra 	$L__BB98_5;
	bra.uni 	$L__BB98_3;
$L__BB98_5:
	add.rn.f32 	%f4, %f1550, %f1551;
	st.shared.f32 	[shared_cache7_$_0], %f4;
$L__BB98_3:
	bar.sync 	0;
	@%p98 bra 	$L__BB98_6;
	bra.uni 	$L__BB98_4;
$L__BB98_6:
	ld.param.u64 	%rd10, [input_add_reduce_fusion_38_param_4];
	cvta.to.global.u64 	%rd2, %rd10;
	ld.shared.f32 	%f1552, [shared_cache7_$_0];
	neg.f32 	%f1553, %f1552;
	st.global.f32 	[%rd2], %f1553;
$L__BB98_4:
	ret;

}
	// .globl	gemm_fusion_dot_16270_1
.visible .entry gemm_fusion_dot_16270_1(
	.param .u64 gemm_fusion_dot_16270_1_param_0,
	.param .u64 gemm_fusion_dot_16270_1_param_1,
	.param .u64 gemm_fusion_dot_16270_1_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<119>;
	.reg .f32 	%f<37>;
	.reg .b64 	%rd<51>;

	ld.param.u64 	%rd5, [gemm_fusion_dot_16270_1_param_0];
	ld.param.u64 	%rd6, [gemm_fusion_dot_16270_1_param_2];
	cvta.to.global.u64 	%rd7, %rd6;
	ld.param.u64 	%rd8, [gemm_fusion_dot_16270_1_param_1];
	cvta.to.global.u64 	%rd9, %rd8;
	cvta.to.global.u64 	%rd10, %rd5;
	// begin inline asm
	mov.u32 %r1, %ctaid.x;
	// end inline asm
	shr.s32 	%r50, %r1, 31;
	shr.u32 	%r51, %r50, 24;
	add.s32 	%r52, %r1, %r51;
	shr.s32 	%r53, %r52, 8;
	shl.b32 	%r54, %r53, 3;
	mov.b32 	%r55, 2;
	sub.s32 	%r56, %r55, %r54;
	min.s32 	%r57, %r56, 8;
	rem.s32 	%r58, %r1, %r57;
	add.s32 	%r59, %r54, %r58;
	and.b32  	%r60, %r52, -256;
	sub.s32 	%r61, %r1, %r60;
	div.s32 	%r62, %r61, %r57;
	shl.b32 	%r63, %r59, 5;
	cvt.s64.s32 	%rd11, %r63;
	shl.b32 	%r64, %r62, 4;
	cvt.s64.s32 	%rd12, %r64;
	mov.u32 	%r65, %tid.x;
	shr.u32 	%r66, %r65, 2;
	cvt.u64.u32 	%rd13, %r66;
	or.b64  	%rd14, %rd11, %rd13;
	shl.b32 	%r67, %r65, 2;
	shl.b32 	%r68, %r65, 1;
	and.b32  	%r69, %r68, 14;
	shr.u32 	%r70, %r65, 3;
	cvt.u64.u32 	%rd15, %r70;
	mul.lo.s64 	%rd16, %rd14, 40;
	add.s64 	%rd17, %rd10, %rd16;
	setp.lt.u64 	%p10, %rd14, 50;
	or.b64  	%rd18, %rd12, %rd15;
	mul.lo.s64 	%rd19, %rd18, 40;
	add.s64 	%rd20, %rd9, %rd19;
	mul.wide.u32 	%rd21, %r69, 4;
	add.s64 	%rd3, %rd20, %rd21;
	setp.lt.u32 	%p7, %r69, 10;
	and.b32  	%r71, %r67, 12;
	or.b32  	%r72, %r71, 2;
	cvt.u64.u32 	%rd22, %r71;
	mul.wide.u32 	%rd23, %r71, 4;
	add.s64 	%rd1, %rd17, %rd23;
	add.s64 	%rd2, %rd1, 8;
	setp.lt.u32 	%p11, %r72, 10;
	setp.lt.u32 	%p12, %r71, 10;
	and.pred  	%p1, %p12, %p10;
	and.pred  	%p4, %p11, %p10;
	mov.b32 	%r4, 0;
	// begin inline asm
	mov.u32 %r2, 0x0;
	mov.u32 %r3, 0x0;
	@%p1 ld.global.v2.b32 { %r2, %r3 }, [ %rd1 + 0 ];
	@!%p1 mov.u32 %r2, %r4;
	@!%p1 mov.u32 %r3, %r4;
	// end inline asm
	// begin inline asm
	mov.u32 %r6, 0x0;
	mov.u32 %r7, 0x0;
	@%p4 ld.global.v2.b32 { %r6, %r7 }, [ %rd2 + 0 ];
	@!%p4 mov.u32 %r6, %r4;
	@!%p4 mov.u32 %r7, %r4;
	// end inline asm
	mov.b32 	%f17, %r6;
	mov.b32 	%f18, %r7;
	mov.b32 	%f19, %r2;
	mov.b32 	%f20, %r3;
	or.b64  	%rd24, %rd12, %rd22;
	// begin inline asm
	mov.u32 %r10, 0x0;
	mov.u32 %r11, 0x0;
	@%p7 ld.global.v2.b32 { %r10, %r11 }, [ %rd3 + 0 ];
	@!%p7 mov.u32 %r10, %r4;
	@!%p7 mov.u32 %r11, %r4;
	// end inline asm
	mov.b32 	%f21, %r10;
	mov.b32 	%f22, %r11;
	selp.f32 	%f23, %f20, 0f00000000, %p12;
	selp.f32 	%f24, %f19, 0f00000000, %p12;
	selp.f32 	%f25, %f18, 0f00000000, %p11;
	selp.f32 	%f26, %f17, 0f00000000, %p11;
	shr.u32 	%r73, %r65, 1;
	xor.b32  	%r74, %r73, %r67;
	and.b32  	%r75, %r74, 12;
	shl.b32 	%r76, %r66, 4;
	or.b32  	%r77, %r75, %r76;
	mul.wide.u32 	%rd25, %r77, 4;
	mov.u64 	%rd26, global_smem;
	add.s64 	%rd27, %rd26, %rd25;
	st.shared.v4.f32 	[%rd27], {%f24, %f23, %f26, %f25};
	selp.f32 	%f27, %f21, 0f00000000, %p7;
	selp.f32 	%f28, %f22, 0f00000000, %p7;
	and.b32  	%r78, %r66, 12;
	xor.b32  	%r79, %r78, %r69;
	shl.b32 	%r80, %r70, 4;
	or.b32  	%r81, %r79, %r80;
	mul.wide.u32 	%rd28, %r81, 4;
	add.s64 	%rd29, %rd26, 2048;
	add.s64 	%rd30, %rd29, %rd28;
	st.shared.v2.f32 	[%rd30], {%f27, %f28};
	bar.sync 	0;
	and.b32  	%r82, %r65, 7;
	bfe.u32 	%r83, %r65, 3, 1;
	bfe.u32 	%r84, %r65, 4, 1;
	bfe.u32 	%r85, %r65, 1, 2;
	and.b32  	%r86, %r66, 16;
	shl.b32 	%r87, %r83, 3;
	or.b32  	%r88, %r87, %r86;
	or.b32  	%r89, %r88, %r82;
	xor.b32  	%r90, %r84, %r85;
	shl.b32 	%r91, %r90, 4;
	shl.b32 	%r92, %r89, 6;
	or.b32  	%r93, %r92, %r91;
	cvt.u64.u32 	%rd31, %r93;
	add.s64 	%rd32, %rd26, %rd31;
	cvt.u32.u64 	%r18, %rd32;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r34, %r35, %r36, %r37 }, [ %r18 + 0 ];
	// end inline asm
	or.b32  	%r94, %r84, 2;
	xor.b32  	%r95, %r94, %r85;
	shl.b32 	%r96, %r95, 4;
	or.b32  	%r97, %r96, %r92;
	cvt.u64.u32 	%rd33, %r97;
	add.s64 	%rd34, %rd26, %rd33;
	cvt.u32.u64 	%r23, %rd34;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r40, %r41, %r42, %r43 }, [ %r23 + 0 ];
	// end inline asm
	and.b32  	%r98, %r66, 8;
	or.b32  	%r99, %r98, %r82;
	xor.b32  	%r100, %r83, %r85;
	shl.b32 	%r101, %r100, 4;
	shl.b32 	%r102, %r99, 6;
	or.b32  	%r103, %r101, %r102;
	cvt.u64.u32 	%rd35, %r103;
	add.s64 	%rd36, %rd29, %rd35;
	cvt.u32.u64 	%r28, %rd36;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r38, %r39, %r26, %r27 }, [ %r28 + 0 ];
	// end inline asm
	or.b32  	%r104, %r83, 2;
	xor.b32  	%r105, %r104, %r85;
	shl.b32 	%r106, %r105, 4;
	or.b32  	%r107, %r106, %r102;
	cvt.u64.u32 	%rd37, %r107;
	add.s64 	%rd38, %rd29, %rd37;
	cvt.u32.u64 	%r33, %rd38;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r44, %r45, %r31, %r32 }, [ %r33 + 0 ];
	// end inline asm
	mov.f32 	%f12, 0f00000000;
	mov.f32 	%f9, %f12;
	mov.f32 	%f10, %f12;
	mov.f32 	%f11, %f12;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r34, %r35, %r36, %r37 }, { %r38, %r39 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r40, %r41, %r42, %r43 }, { %r44, %r45 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	bar.sync 	0;
	bfe.u32 	%r108, %r65, 2, 3;
	and.b32  	%r109, %r65, 3;
	shl.b32 	%r110, %r109, 1;
	or.b32  	%r111, %r108, %r86;
	or.b32  	%r112, %r110, %r98;
	mul.lo.s32 	%r113, %r111, 20;
	add.s32 	%r114, %r113, %r112;
	mul.wide.u32 	%rd39, %r114, 4;
	add.s64 	%rd40, %rd26, %rd39;
	st.shared.v2.f32 	[%rd40], {%f9, %f10};
	cvt.u64.u32 	%rd41, %r113;
	cvt.u64.u32 	%rd42, %r112;
	add.s64 	%rd43, %rd42, %rd41;
	shl.b64 	%rd44, %rd43, 2;
	add.s64 	%rd45, %rd26, %rd44;
	st.shared.v2.f32 	[%rd45+640], {%f11, %f12};
	bar.sync 	0;
	and.b32  	%r115, %r66, 24;
	or.b32  	%r116, %r108, %r115;
	shl.b32 	%r117, %r109, 2;
	mad.lo.s32 	%r118, %r116, 20, %r117;
	mul.wide.u32 	%rd46, %r118, 4;
	add.s64 	%rd47, %rd26, %rd46;
	ld.shared.v4.f32 	{%f29, %f30, %f31, %f32}, [%rd47];
	mul.rn.f32 	%f33, %f29, 0f3A800000;
	mul.rn.f32 	%f34, %f30, 0f3A800000;
	mul.rn.f32 	%f35, %f31, 0f3A800000;
	mul.rn.f32 	%f36, %f32, 0f3A800000;
	shl.b64 	%rd48, %rd14, 11;
	add.s64 	%rd49, %rd7, %rd48;
	shl.b64 	%rd50, %rd24, 2;
	add.s64 	%rd4, %rd49, %rd50;
	mov.b32 	%r46, %f33;
	mov.b32 	%r47, %f34;
	mov.b32 	%r48, %f35;
	mov.b32 	%r49, %f36;
	// begin inline asm
	@%p10 st.global.v4.b32 [ %rd4 + 0 ], { %r46, %r47, %r48, %r49 };
	// end inline asm
	ret;

}
	// .globl	input_multiply_reduce_fusion_12
.visible .entry input_multiply_reduce_fusion_12(
	.param .u64 input_multiply_reduce_fusion_12_param_0,
	.param .u64 input_multiply_reduce_fusion_12_param_1,
	.param .u64 input_multiply_reduce_fusion_12_param_2,
	.param .u64 input_multiply_reduce_fusion_12_param_3,
	.param .u64 input_multiply_reduce_fusion_12_param_4,
	.param .u64 input_multiply_reduce_fusion_12_param_5,
	.param .u64 input_multiply_reduce_fusion_12_param_6,
	.param .u64 input_multiply_reduce_fusion_12_param_7
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<19>;
	.reg .f32 	%f<43>;
	.reg .b64 	%rd<63>;
	// demoted variable
	.shared .align 4 .b8 shared_cache8[4224];
	ld.param.u64 	%rd12, [input_multiply_reduce_fusion_12_param_0];
	ld.param.u64 	%rd13, [input_multiply_reduce_fusion_12_param_7];
	cvta.to.global.u64 	%rd1, %rd13;
	ld.param.u64 	%rd14, [input_multiply_reduce_fusion_12_param_1];
	ld.param.u64 	%rd15, [input_multiply_reduce_fusion_12_param_6];
	cvta.to.global.u64 	%rd2, %rd15;
	ld.param.u64 	%rd16, [input_multiply_reduce_fusion_12_param_2];
	ld.param.u64 	%rd17, [input_multiply_reduce_fusion_12_param_5];
	cvta.to.global.u64 	%rd3, %rd17;
	ld.param.u64 	%rd18, [input_multiply_reduce_fusion_12_param_3];
	ld.param.u64 	%rd19, [input_multiply_reduce_fusion_12_param_4];
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvta.to.global.u64 	%rd6, %rd16;
	cvta.to.global.u64 	%rd20, %rd14;
	cvta.to.global.u64 	%rd21, %rd12;
	mov.u32 	%r8, %tid.x;
	mov.u32 	%r9, %ctaid.x;
	shr.u32 	%r1, %r8, 5;
	and.b32  	%r2, %r8, 31;
	shr.u32 	%r3, %r9, 4;
	shl.b32 	%r10, %r9, 5;
	and.b32  	%r4, %r10, 480;
	or.b32  	%r11, %r4, %r2;
	mul.lo.s32 	%r5, %r3, 400;
	cvt.u64.u32 	%rd7, %r11;
	mul.wide.u32 	%rd22, %r11, 4;
	add.s64 	%rd23, %rd20, %rd22;
	ld.global.nc.f32 	%f1, [%rd23];
	cvt.u64.u32 	%rd24, %r9;
	shr.u64 	%rd25, %rd24, 4;
	mul.lo.s64 	%rd26, %rd25, 819200;
	cvt.u64.u32 	%rd27, %r8;
	shl.b64 	%rd28, %rd27, 6;
	and.b64  	%rd29, %rd28, 274877904896;
	add.s64 	%rd30, %rd26, %rd29;
	or.b64  	%rd31, %rd30, %rd22;
	add.s64 	%rd62, %rd21, %rd31;
	mov.f32 	%f42, 0f00000000;
	mov.f32 	%f15, 0f4B400001;
	mov.f32 	%f16, 0f437C0000;
	mov.u32 	%r18, %r1;
$L__BB100_1:
	add.s32 	%r7, %r18, 32;
	add.s32 	%r12, %r5, %r18;
	and.b32  	%r13, %r12, 1023;
	shr.u32 	%r14, %r12, 10;
	mul.wide.u32 	%rd32, %r14, 2097152;
	add.s64 	%rd33, %rd6, %rd32;
	mul.wide.u32 	%rd34, %r13, 2048;
	add.s64 	%rd35, %rd33, %rd34;
	shl.b64 	%rd36, %rd7, 2;
	add.s64 	%rd37, %rd35, %rd36;
	ld.global.nc.f32 	%f6, [%rd37];
	mul.wide.u32 	%rd38, %r14, 512;
	add.s64 	%rd39, %rd4, %rd38;
	add.s64 	%rd40, %rd39, %rd7;
	ld.global.nc.u8 	%rs1, [%rd40];
	cvt.u16.u8 	%rs2, %rs1;
	mul.wide.u32 	%rd41, %r14, 2048;
	add.s64 	%rd42, %rd5, %rd41;
	add.s64 	%rd43, %rd42, %rd36;
	ld.global.nc.f32 	%f7, [%rd43];
	and.b16  	%rs3, %rs2, 1;
	setp.eq.b16 	%p1, %rs3, 1;
	mul.rn.f32 	%f8, %f7, 0f3F8E38E4;
	selp.f32 	%f9, %f8, 0f00000000, %p1;
	mul.rn.f32 	%f10, %f6, %f9;
	ld.global.nc.f32 	%f11, [%rd62];
	add.rn.f32 	%f12, %f11, %f1;
	fma.rn.f32 	%f13, %f12, 0fBBBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f14, %f13;
	fma.rm.f32 	%f17, %f14, %f16, %f15;
	add.rn.f32 	%f18, %f17, 0fCB40007F;
	neg.f32 	%f19, %f18;
	fma.rn.f32 	%f20, %f12, 0fBFB8AA3B, %f19;
	fma.rn.f32 	%f21, %f12, 0fB2A57060, %f20;
	mov.b32 	%r15, %f17;
	shl.b32 	%r16, %r15, 23;
	mov.b32 	%f22, %r16;
	ex2.approx.ftz.f32 	%f23, %f21;
	mul.rn.f32 	%f24, %f23, %f22;
	add.rn.f32 	%f25, %f24, 0f3F800000;
	rcp.approx.f32 	%f26, %f25;
	mov.f32 	%f27, 0f3F800000;
	sub.rn.f32 	%f28, %f27, %f26;
	mul.rn.f32 	%f29, %f26, %f28;
	mul.rn.f32 	%f30, %f10, %f29;
	add.rn.f32 	%f42, %f42, %f30;
	mul.rn.f32 	%f31, %f9, %f26;
	add.s64 	%rd44, %rd2, %rd32;
	add.s64 	%rd45, %rd44, %rd34;
	add.s64 	%rd46, %rd45, %rd36;
	st.global.f32 	[%rd46], %f30;
	add.s64 	%rd47, %rd1, %rd32;
	add.s64 	%rd48, %rd47, %rd34;
	add.s64 	%rd49, %rd48, %rd36;
	st.global.f32 	[%rd49], %f31;
	add.s64 	%rd62, %rd62, 65536;
	setp.lt.u32 	%p2, %r18, 368;
	mov.u32 	%r18, %r7;
	@%p2 bra 	$L__BB100_1;
	mul.wide.u32 	%rd50, %r2, 132;
	mov.u64 	%rd51, shared_cache8;
	add.s64 	%rd52, %rd51, %rd50;
	mul.wide.u32 	%rd53, %r1, 4;
	add.s64 	%rd54, %rd52, %rd53;
	st.shared.f32 	[%rd54], %f42;
	bar.sync 	0;
	mul.wide.u32 	%rd55, %r1, 132;
	add.s64 	%rd56, %rd51, %rd55;
	mul.wide.u32 	%rd57, %r2, 4;
	add.s64 	%rd58, %rd56, %rd57;
	ld.shared.f32 	%f32, [%rd58];
	shfl.sync.down.b32	%f33, %f32, 16, 31, -1;
	add.rn.f32 	%f34, %f32, %f33;
	shfl.sync.down.b32	%f35, %f34, 8, 31, -1;
	add.rn.f32 	%f36, %f34, %f35;
	shfl.sync.down.b32	%f37, %f36, 4, 31, -1;
	add.rn.f32 	%f38, %f36, %f37;
	shfl.sync.down.b32	%f39, %f38, 2, 31, -1;
	add.rn.f32 	%f40, %f38, %f39;
	shfl.sync.down.b32	%f41, %f40, 1, 31, -1;
	add.rn.f32 	%f4, %f40, %f41;
	st.shared.f32 	[%rd58], %f4;
	setp.ne.s32 	%p3, %r2, 0;
	@%p3 bra 	$L__BB100_4;
	or.b32  	%r17, %r4, %r1;
	mul.wide.u32 	%rd59, %r3, 2048;
	add.s64 	%rd60, %rd3, %rd59;
	mul.wide.u32 	%rd61, %r17, 4;
	add.s64 	%rd11, %rd60, %rd61;
	st.global.f32 	[%rd11], %f4;
$L__BB100_4:
	ret;

}
	// .globl	loop_add_fusion_371
.visible .entry loop_add_fusion_371(
	.param .u64 loop_add_fusion_371_param_0,
	.param .u64 loop_add_fusion_371_param_1,
	.param .u64 loop_add_fusion_371_param_2,
	.param .u64 loop_add_fusion_371_param_3,
	.param .u64 loop_add_fusion_371_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<16>;
	.reg .f32 	%f<86>;
	.reg .b64 	%rd<20>;

	ld.param.u64 	%rd1, [loop_add_fusion_371_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_371_param_4];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_371_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_371_param_3];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_371_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	cvta.to.global.u64 	%rd9, %rd4;
	cvta.to.global.u64 	%rd10, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	shr.u32 	%r6, %r1, 10;
	cvt.u64.u32 	%rd11, %r4;
	mul.wide.u32 	%rd12, %r6, 512;
	add.s64 	%rd13, %rd6, %rd12;
	add.s64 	%rd14, %rd13, %rd11;
	ld.global.nc.u32 	%r7, [%rd14];
	bfe.u32 	%r8, %r7, 0, 8;
	bfe.u32 	%r9, %r7, 8, 8;
	bfe.u32 	%r10, %r7, 16, 8;
	bfe.u32 	%r11, %r7, 24, 8;
	mul.wide.u32 	%rd15, %r5, 4;
	add.s64 	%rd16, %rd8, %rd15;
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd16];
	and.b32  	%r12, %r8, 1;
	setp.eq.b32 	%p1, %r12, 1;
	mul.rn.f32 	%f5, %f1, 0f3F8E38E4;
	selp.f32 	%f6, %f5, 0f00000000, %p1;
	add.s64 	%rd17, %rd10, %rd15;
	ld.global.nc.v4.f32 	{%f7, %f8, %f9, %f10}, [%rd17];
	add.rn.f32 	%f11, %f7, 0f3F800000;
	mul.rn.f32 	%f12, %f11, 0f3F000000;
	mul.rn.f32 	%f13, %f6, %f12;
	add.s64 	%rd18, %rd9, %rd15;
	ld.global.nc.v4.f32 	{%f14, %f15, %f16, %f17}, [%rd18];
	mul.rn.f32 	%f18, %f14, %f6;
	mul.rn.f32 	%f19, %f18, 0f3F000000;
	mov.f32 	%f20, 0f3F800000;
	sub.rn.f32 	%f21, %f20, %f7;
	mul.rn.f32 	%f22, %f21, %f19;
	mul.rn.f32 	%f23, %f7, %f22;
	add.rn.f32 	%f24, %f22, %f23;
	mul.rn.f32 	%f25, %f24, 0f3F4C422A;
	add.rn.f32 	%f26, %f13, %f25;
	mul.rn.f32 	%f27, %f24, 0f3D122279;
	mul.rn.f32 	%f28, %f14, %f14;
	mul.rn.f32 	%f29, %f28, 0f40400000;
	mul.rn.f32 	%f30, %f29, %f27;
	add.rn.f32 	%f31, %f26, %f30;
	add.s64 	%rd19, %rd3, %rd15;
	and.b32  	%r13, %r9, 1;
	setp.eq.b32 	%p2, %r13, 1;
	mul.rn.f32 	%f32, %f2, 0f3F8E38E4;
	selp.f32 	%f33, %f32, 0f00000000, %p2;
	add.rn.f32 	%f34, %f8, 0f3F800000;
	mul.rn.f32 	%f35, %f34, 0f3F000000;
	mul.rn.f32 	%f36, %f33, %f35;
	mul.rn.f32 	%f37, %f15, %f33;
	mul.rn.f32 	%f38, %f37, 0f3F000000;
	sub.rn.f32 	%f39, %f20, %f8;
	mul.rn.f32 	%f40, %f39, %f38;
	mul.rn.f32 	%f41, %f8, %f40;
	add.rn.f32 	%f42, %f40, %f41;
	mul.rn.f32 	%f43, %f42, 0f3F4C422A;
	add.rn.f32 	%f44, %f36, %f43;
	mul.rn.f32 	%f45, %f42, 0f3D122279;
	mul.rn.f32 	%f46, %f15, %f15;
	mul.rn.f32 	%f47, %f46, 0f40400000;
	mul.rn.f32 	%f48, %f47, %f45;
	add.rn.f32 	%f49, %f44, %f48;
	and.b32  	%r14, %r10, 1;
	setp.eq.b32 	%p3, %r14, 1;
	mul.rn.f32 	%f50, %f3, 0f3F8E38E4;
	selp.f32 	%f51, %f50, 0f00000000, %p3;
	add.rn.f32 	%f52, %f9, 0f3F800000;
	mul.rn.f32 	%f53, %f52, 0f3F000000;
	mul.rn.f32 	%f54, %f51, %f53;
	mul.rn.f32 	%f55, %f16, %f51;
	mul.rn.f32 	%f56, %f55, 0f3F000000;
	sub.rn.f32 	%f57, %f20, %f9;
	mul.rn.f32 	%f58, %f57, %f56;
	mul.rn.f32 	%f59, %f9, %f58;
	add.rn.f32 	%f60, %f58, %f59;
	mul.rn.f32 	%f61, %f60, 0f3F4C422A;
	add.rn.f32 	%f62, %f54, %f61;
	mul.rn.f32 	%f63, %f60, 0f3D122279;
	mul.rn.f32 	%f64, %f16, %f16;
	mul.rn.f32 	%f65, %f64, 0f40400000;
	mul.rn.f32 	%f66, %f65, %f63;
	add.rn.f32 	%f67, %f62, %f66;
	and.b32  	%r15, %r11, 1;
	setp.eq.b32 	%p4, %r15, 1;
	mul.rn.f32 	%f68, %f4, 0f3F8E38E4;
	selp.f32 	%f69, %f68, 0f00000000, %p4;
	add.rn.f32 	%f70, %f10, 0f3F800000;
	mul.rn.f32 	%f71, %f70, 0f3F000000;
	mul.rn.f32 	%f72, %f69, %f71;
	mul.rn.f32 	%f73, %f17, %f69;
	mul.rn.f32 	%f74, %f73, 0f3F000000;
	sub.rn.f32 	%f75, %f20, %f10;
	mul.rn.f32 	%f76, %f75, %f74;
	mul.rn.f32 	%f77, %f10, %f76;
	add.rn.f32 	%f78, %f76, %f77;
	mul.rn.f32 	%f79, %f78, 0f3F4C422A;
	add.rn.f32 	%f80, %f72, %f79;
	mul.rn.f32 	%f81, %f78, 0f3D122279;
	mul.rn.f32 	%f82, %f17, %f17;
	mul.rn.f32 	%f83, %f82, 0f40400000;
	mul.rn.f32 	%f84, %f83, %f81;
	add.rn.f32 	%f85, %f80, %f84;
	st.global.v4.f32 	[%rd19], {%f31, %f49, %f67, %f85};
	ret;

}
	// .globl	gemm_fusion_dot_565_1
.visible .entry gemm_fusion_dot_565_1(
	.param .u64 gemm_fusion_dot_565_1_param_0,
	.param .u64 gemm_fusion_dot_565_1_param_1,
	.param .u64 gemm_fusion_dot_565_1_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<69>;
	.reg .b32 	%r<346>;
	.reg .f32 	%f<197>;
	.reg .b64 	%rd<222>;

	ld.param.u64 	%rd34, [gemm_fusion_dot_565_1_param_0];
	ld.param.u64 	%rd35, [gemm_fusion_dot_565_1_param_2];
	cvta.to.global.u64 	%rd36, %rd35;
	ld.param.u64 	%rd37, [gemm_fusion_dot_565_1_param_1];
	cvta.to.global.u64 	%rd38, %rd37;
	cvta.to.global.u64 	%rd39, %rd34;
	// begin inline asm
	mov.u32 %r1, %ctaid.x;
	// end inline asm
	shr.s32 	%r239, %r1, 31;
	shr.u32 	%r240, %r239, 29;
	add.s32 	%r241, %r1, %r240;
	and.b32  	%r242, %r241, -8;
	mov.b32 	%r243, 200;
	sub.s32 	%r244, %r243, %r242;
	min.s32 	%r245, %r244, 8;
	rem.s32 	%r246, %r1, %r245;
	add.s32 	%r247, %r242, %r246;
	sub.s32 	%r248, %r1, %r242;
	div.s32 	%r249, %r248, %r245;
	shl.b32 	%r250, %r247, 8;
	// begin inline asm
	mov.u32 %r2, %ctaid.y;
	// end inline asm
	mul.lo.s32 	%r251, %r2, 6;
	mul.wide.s32 	%rd40, %r251, 4;
	add.s64 	%rd41, %rd39, %rd40;
	cvt.s64.s32 	%rd42, %r250;
	shl.b32 	%r252, %r249, 4;
	mul.lo.s32 	%r253, %r2, 36;
	mul.wide.s32 	%rd43, %r253, 4;
	add.s64 	%rd44, %rd38, %rd43;
	cvt.s64.s32 	%rd45, %r252;
	mov.u32 	%r254, %tid.x;
	shr.u32 	%r255, %r254, 5;
	shr.u32 	%r256, %r254, 3;
	or.b32  	%r257, %r256, 16;
	or.b32  	%r258, %r256, 32;
	or.b32  	%r259, %r256, 48;
	or.b32  	%r260, %r256, 64;
	or.b32  	%r261, %r256, 80;
	or.b32  	%r262, %r256, 96;
	or.b32  	%r263, %r256, 112;
	or.b32  	%r264, %r256, 128;
	or.b32  	%r265, %r256, 144;
	or.b32  	%r266, %r256, 160;
	or.b32  	%r267, %r256, 176;
	or.b32  	%r268, %r256, 192;
	or.b32  	%r269, %r256, 208;
	or.b32  	%r270, %r256, 224;
	or.b32  	%r271, %r256, 240;
	cvt.u64.u32 	%rd46, %r256;
	cvt.u64.u32 	%rd47, %r257;
	cvt.u64.u32 	%rd48, %r258;
	cvt.u64.u32 	%rd49, %r259;
	cvt.u64.u32 	%rd50, %r260;
	cvt.u64.u32 	%rd51, %r261;
	cvt.u64.u32 	%rd52, %r262;
	cvt.u64.u32 	%rd53, %r263;
	cvt.u64.u32 	%rd54, %r264;
	cvt.u64.u32 	%rd55, %r265;
	cvt.u64.u32 	%rd56, %r266;
	cvt.u64.u32 	%rd57, %r267;
	cvt.u64.u32 	%rd58, %r268;
	cvt.u64.u32 	%rd59, %r269;
	cvt.u64.u32 	%rd60, %r270;
	cvt.u64.u32 	%rd61, %r271;
	or.b64  	%rd62, %rd42, %rd46;
	or.b64  	%rd63, %rd42, %rd47;
	or.b64  	%rd64, %rd42, %rd48;
	or.b64  	%rd65, %rd42, %rd49;
	or.b64  	%rd66, %rd42, %rd50;
	or.b64  	%rd67, %rd42, %rd51;
	or.b64  	%rd68, %rd42, %rd52;
	or.b64  	%rd69, %rd42, %rd53;
	or.b64  	%rd70, %rd42, %rd54;
	or.b64  	%rd71, %rd42, %rd55;
	or.b64  	%rd72, %rd42, %rd56;
	or.b64  	%rd73, %rd42, %rd57;
	or.b64  	%rd74, %rd42, %rd58;
	or.b64  	%rd75, %rd42, %rd59;
	or.b64  	%rd76, %rd42, %rd60;
	or.b64  	%rd77, %rd42, %rd61;
	mul.lo.s64 	%rd78, %rd62, 384;
	mul.lo.s64 	%rd79, %rd63, 384;
	mul.lo.s64 	%rd80, %rd64, 384;
	mul.lo.s64 	%rd81, %rd65, 384;
	mul.lo.s64 	%rd82, %rd66, 384;
	mul.lo.s64 	%rd83, %rd67, 384;
	mul.lo.s64 	%rd84, %rd68, 384;
	mul.lo.s64 	%rd85, %rd69, 384;
	mul.lo.s64 	%rd86, %rd70, 384;
	mul.lo.s64 	%rd87, %rd71, 384;
	mul.lo.s64 	%rd88, %rd72, 384;
	mul.lo.s64 	%rd89, %rd73, 384;
	mul.lo.s64 	%rd90, %rd74, 384;
	mul.lo.s64 	%rd91, %rd75, 384;
	mul.lo.s64 	%rd92, %rd76, 384;
	mul.lo.s64 	%rd93, %rd77, 384;
	shl.b32 	%r272, %r254, 1;
	and.b32  	%r273, %r272, 14;
	cvt.u64.u32 	%rd94, %r273;
	or.b64  	%rd95, %rd78, %rd94;
	or.b64  	%rd96, %rd79, %rd94;
	or.b64  	%rd97, %rd80, %rd94;
	or.b64  	%rd98, %rd81, %rd94;
	or.b64  	%rd99, %rd82, %rd94;
	or.b64  	%rd100, %rd83, %rd94;
	or.b64  	%rd101, %rd84, %rd94;
	or.b64  	%rd102, %rd85, %rd94;
	or.b64  	%rd103, %rd86, %rd94;
	or.b64  	%rd104, %rd87, %rd94;
	or.b64  	%rd105, %rd88, %rd94;
	or.b64  	%rd106, %rd89, %rd94;
	or.b64  	%rd107, %rd90, %rd94;
	or.b64  	%rd108, %rd91, %rd94;
	or.b64  	%rd109, %rd92, %rd94;
	or.b64  	%rd110, %rd93, %rd94;
	shl.b64 	%rd111, %rd95, 2;
	add.s64 	%rd1, %rd41, %rd111;
	shl.b64 	%rd112, %rd96, 2;
	add.s64 	%rd2, %rd41, %rd112;
	shl.b64 	%rd113, %rd97, 2;
	add.s64 	%rd3, %rd41, %rd113;
	shl.b64 	%rd114, %rd98, 2;
	add.s64 	%rd4, %rd41, %rd114;
	shl.b64 	%rd115, %rd99, 2;
	add.s64 	%rd5, %rd41, %rd115;
	shl.b64 	%rd116, %rd100, 2;
	add.s64 	%rd6, %rd41, %rd116;
	shl.b64 	%rd117, %rd101, 2;
	add.s64 	%rd7, %rd41, %rd117;
	shl.b64 	%rd118, %rd102, 2;
	add.s64 	%rd8, %rd41, %rd118;
	shl.b64 	%rd119, %rd103, 2;
	add.s64 	%rd9, %rd41, %rd119;
	shl.b64 	%rd120, %rd104, 2;
	add.s64 	%rd10, %rd41, %rd120;
	shl.b64 	%rd121, %rd105, 2;
	add.s64 	%rd11, %rd41, %rd121;
	shl.b64 	%rd122, %rd106, 2;
	add.s64 	%rd12, %rd41, %rd122;
	shl.b64 	%rd123, %rd107, 2;
	add.s64 	%rd13, %rd41, %rd123;
	shl.b64 	%rd124, %rd108, 2;
	add.s64 	%rd14, %rd41, %rd124;
	shl.b64 	%rd125, %rd109, 2;
	add.s64 	%rd15, %rd41, %rd125;
	shl.b64 	%rd126, %rd110, 2;
	add.s64 	%rd16, %rd41, %rd126;
	setp.lt.u32 	%p1, %r273, 6;
	mov.b32 	%r5, 0;
	// begin inline asm
	mov.u32 %r3, 0x0;
	mov.u32 %r4, 0x0;
	@%p1 ld.global.v2.b32 { %r3, %r4 }, [ %rd1 + 0 ];
	@!%p1 mov.u32 %r3, %r5;
	@!%p1 mov.u32 %r4, %r5;
	// end inline asm
	mov.b32 	%f129, %r3;
	mov.b32 	%f130, %r4;
	// begin inline asm
	mov.u32 %r7, 0x0;
	mov.u32 %r8, 0x0;
	@%p1 ld.global.v2.b32 { %r7, %r8 }, [ %rd2 + 0 ];
	@!%p1 mov.u32 %r7, %r5;
	@!%p1 mov.u32 %r8, %r5;
	// end inline asm
	mov.b32 	%f131, %r7;
	mov.b32 	%f132, %r8;
	// begin inline asm
	mov.u32 %r11, 0x0;
	mov.u32 %r12, 0x0;
	@%p1 ld.global.v2.b32 { %r11, %r12 }, [ %rd3 + 0 ];
	@!%p1 mov.u32 %r11, %r5;
	@!%p1 mov.u32 %r12, %r5;
	// end inline asm
	mov.b32 	%f133, %r11;
	mov.b32 	%f134, %r12;
	// begin inline asm
	mov.u32 %r15, 0x0;
	mov.u32 %r16, 0x0;
	@%p1 ld.global.v2.b32 { %r15, %r16 }, [ %rd4 + 0 ];
	@!%p1 mov.u32 %r15, %r5;
	@!%p1 mov.u32 %r16, %r5;
	// end inline asm
	mov.b32 	%f135, %r15;
	mov.b32 	%f136, %r16;
	// begin inline asm
	mov.u32 %r19, 0x0;
	mov.u32 %r20, 0x0;
	@%p1 ld.global.v2.b32 { %r19, %r20 }, [ %rd5 + 0 ];
	@!%p1 mov.u32 %r19, %r5;
	@!%p1 mov.u32 %r20, %r5;
	// end inline asm
	mov.b32 	%f137, %r19;
	mov.b32 	%f138, %r20;
	// begin inline asm
	mov.u32 %r23, 0x0;
	mov.u32 %r24, 0x0;
	@%p1 ld.global.v2.b32 { %r23, %r24 }, [ %rd6 + 0 ];
	@!%p1 mov.u32 %r23, %r5;
	@!%p1 mov.u32 %r24, %r5;
	// end inline asm
	mov.b32 	%f139, %r23;
	mov.b32 	%f140, %r24;
	// begin inline asm
	mov.u32 %r27, 0x0;
	mov.u32 %r28, 0x0;
	@%p1 ld.global.v2.b32 { %r27, %r28 }, [ %rd7 + 0 ];
	@!%p1 mov.u32 %r27, %r5;
	@!%p1 mov.u32 %r28, %r5;
	// end inline asm
	mov.b32 	%f141, %r27;
	mov.b32 	%f142, %r28;
	// begin inline asm
	mov.u32 %r31, 0x0;
	mov.u32 %r32, 0x0;
	@%p1 ld.global.v2.b32 { %r31, %r32 }, [ %rd8 + 0 ];
	@!%p1 mov.u32 %r31, %r5;
	@!%p1 mov.u32 %r32, %r5;
	// end inline asm
	mov.b32 	%f143, %r31;
	mov.b32 	%f144, %r32;
	// begin inline asm
	mov.u32 %r35, 0x0;
	mov.u32 %r36, 0x0;
	@%p1 ld.global.v2.b32 { %r35, %r36 }, [ %rd9 + 0 ];
	@!%p1 mov.u32 %r35, %r5;
	@!%p1 mov.u32 %r36, %r5;
	// end inline asm
	mov.b32 	%f145, %r35;
	mov.b32 	%f146, %r36;
	// begin inline asm
	mov.u32 %r39, 0x0;
	mov.u32 %r40, 0x0;
	@%p1 ld.global.v2.b32 { %r39, %r40 }, [ %rd10 + 0 ];
	@!%p1 mov.u32 %r39, %r5;
	@!%p1 mov.u32 %r40, %r5;
	// end inline asm
	mov.b32 	%f147, %r39;
	mov.b32 	%f148, %r40;
	// begin inline asm
	mov.u32 %r43, 0x0;
	mov.u32 %r44, 0x0;
	@%p1 ld.global.v2.b32 { %r43, %r44 }, [ %rd11 + 0 ];
	@!%p1 mov.u32 %r43, %r5;
	@!%p1 mov.u32 %r44, %r5;
	// end inline asm
	mov.b32 	%f149, %r43;
	mov.b32 	%f150, %r44;
	// begin inline asm
	mov.u32 %r47, 0x0;
	mov.u32 %r48, 0x0;
	@%p1 ld.global.v2.b32 { %r47, %r48 }, [ %rd12 + 0 ];
	@!%p1 mov.u32 %r47, %r5;
	@!%p1 mov.u32 %r48, %r5;
	// end inline asm
	mov.b32 	%f151, %r47;
	mov.b32 	%f152, %r48;
	// begin inline asm
	mov.u32 %r51, 0x0;
	mov.u32 %r52, 0x0;
	@%p1 ld.global.v2.b32 { %r51, %r52 }, [ %rd13 + 0 ];
	@!%p1 mov.u32 %r51, %r5;
	@!%p1 mov.u32 %r52, %r5;
	// end inline asm
	mov.b32 	%f153, %r51;
	mov.b32 	%f154, %r52;
	// begin inline asm
	mov.u32 %r55, 0x0;
	mov.u32 %r56, 0x0;
	@%p1 ld.global.v2.b32 { %r55, %r56 }, [ %rd14 + 0 ];
	@!%p1 mov.u32 %r55, %r5;
	@!%p1 mov.u32 %r56, %r5;
	// end inline asm
	mov.b32 	%f155, %r55;
	mov.b32 	%f156, %r56;
	// begin inline asm
	mov.u32 %r59, 0x0;
	mov.u32 %r60, 0x0;
	@%p1 ld.global.v2.b32 { %r59, %r60 }, [ %rd15 + 0 ];
	@!%p1 mov.u32 %r59, %r5;
	@!%p1 mov.u32 %r60, %r5;
	// end inline asm
	mov.b32 	%f157, %r59;
	mov.b32 	%f158, %r60;
	// begin inline asm
	mov.u32 %r63, 0x0;
	mov.u32 %r64, 0x0;
	@%p1 ld.global.v2.b32 { %r63, %r64 }, [ %rd16 + 0 ];
	@!%p1 mov.u32 %r63, %r5;
	@!%p1 mov.u32 %r64, %r5;
	// end inline asm
	mov.b32 	%f159, %r63;
	mov.b32 	%f160, %r64;
	or.b64  	%rd127, %rd45, %rd94;
	mul.wide.u32 	%rd128, %r256, 24;
	add.s64 	%rd129, %rd44, %rd128;
	shl.b64 	%rd130, %rd127, 2;
	add.s64 	%rd17, %rd129, %rd130;
	setp.lt.u32 	%p68, %r254, 48;
	setp.lt.u64 	%p52, %rd127, 6;
	and.pred  	%p49, %p68, %p52;
	// begin inline asm
	mov.u32 %r67, 0x0;
	mov.u32 %r68, 0x0;
	@%p49 ld.global.v2.b32 { %r67, %r68 }, [ %rd17 + 0 ];
	@!%p49 mov.u32 %r67, %r5;
	@!%p49 mov.u32 %r68, %r5;
	// end inline asm
	mov.b32 	%f161, %r67;
	mov.b32 	%f162, %r68;
	selp.f32 	%f163, %f129, 0f00000000, %p1;
	selp.f32 	%f164, %f130, 0f00000000, %p1;
	selp.f32 	%f165, %f131, 0f00000000, %p1;
	selp.f32 	%f166, %f132, 0f00000000, %p1;
	selp.f32 	%f167, %f133, 0f00000000, %p1;
	selp.f32 	%f168, %f134, 0f00000000, %p1;
	selp.f32 	%f169, %f135, 0f00000000, %p1;
	selp.f32 	%f170, %f136, 0f00000000, %p1;
	selp.f32 	%f171, %f137, 0f00000000, %p1;
	selp.f32 	%f172, %f138, 0f00000000, %p1;
	selp.f32 	%f173, %f139, 0f00000000, %p1;
	selp.f32 	%f174, %f140, 0f00000000, %p1;
	selp.f32 	%f175, %f141, 0f00000000, %p1;
	selp.f32 	%f176, %f142, 0f00000000, %p1;
	selp.f32 	%f177, %f143, 0f00000000, %p1;
	selp.f32 	%f178, %f144, 0f00000000, %p1;
	selp.f32 	%f179, %f145, 0f00000000, %p1;
	selp.f32 	%f180, %f146, 0f00000000, %p1;
	selp.f32 	%f181, %f147, 0f00000000, %p1;
	selp.f32 	%f182, %f148, 0f00000000, %p1;
	selp.f32 	%f183, %f149, 0f00000000, %p1;
	selp.f32 	%f184, %f150, 0f00000000, %p1;
	selp.f32 	%f185, %f151, 0f00000000, %p1;
	selp.f32 	%f186, %f152, 0f00000000, %p1;
	selp.f32 	%f187, %f153, 0f00000000, %p1;
	selp.f32 	%f188, %f154, 0f00000000, %p1;
	selp.f32 	%f189, %f155, 0f00000000, %p1;
	selp.f32 	%f190, %f156, 0f00000000, %p1;
	selp.f32 	%f191, %f157, 0f00000000, %p1;
	selp.f32 	%f192, %f158, 0f00000000, %p1;
	selp.f32 	%f193, %f159, 0f00000000, %p1;
	selp.f32 	%f194, %f160, 0f00000000, %p1;
	shr.u32 	%r274, %r254, 2;
	and.b32  	%r275, %r274, 12;
	xor.b32  	%r276, %r275, %r273;
	shl.b32 	%r277, %r256, 4;
	or.b32  	%r278, %r276, %r277;
	mul.wide.u32 	%rd131, %r278, 4;
	mov.u64 	%rd132, global_smem;
	add.s64 	%rd133, %rd132, %rd131;
	st.shared.v2.f32 	[%rd133], {%f163, %f164};
	shl.b32 	%r279, %r257, 4;
	or.b32  	%r280, %r279, %r276;
	mul.wide.u32 	%rd134, %r280, 4;
	add.s64 	%rd135, %rd132, %rd134;
	st.shared.v2.f32 	[%rd135], {%f165, %f166};
	shl.b32 	%r281, %r258, 4;
	or.b32  	%r282, %r281, %r276;
	mul.wide.u32 	%rd136, %r282, 4;
	add.s64 	%rd137, %rd132, %rd136;
	st.shared.v2.f32 	[%rd137], {%f167, %f168};
	shl.b32 	%r283, %r259, 4;
	or.b32  	%r284, %r283, %r276;
	mul.wide.u32 	%rd138, %r284, 4;
	add.s64 	%rd139, %rd132, %rd138;
	st.shared.v2.f32 	[%rd139], {%f169, %f170};
	shl.b32 	%r285, %r260, 4;
	or.b32  	%r286, %r285, %r276;
	mul.wide.u32 	%rd140, %r286, 4;
	add.s64 	%rd141, %rd132, %rd140;
	st.shared.v2.f32 	[%rd141], {%f171, %f172};
	shl.b32 	%r287, %r261, 4;
	or.b32  	%r288, %r287, %r276;
	mul.wide.u32 	%rd142, %r288, 4;
	add.s64 	%rd143, %rd132, %rd142;
	st.shared.v2.f32 	[%rd143], {%f173, %f174};
	shl.b32 	%r289, %r262, 4;
	or.b32  	%r290, %r289, %r276;
	mul.wide.u32 	%rd144, %r290, 4;
	add.s64 	%rd145, %rd132, %rd144;
	st.shared.v2.f32 	[%rd145], {%f175, %f176};
	shl.b32 	%r291, %r263, 4;
	or.b32  	%r292, %r291, %r276;
	mul.wide.u32 	%rd146, %r292, 4;
	add.s64 	%rd147, %rd132, %rd146;
	st.shared.v2.f32 	[%rd147], {%f177, %f178};
	shl.b32 	%r293, %r264, 4;
	or.b32  	%r294, %r293, %r276;
	mul.wide.u32 	%rd148, %r294, 4;
	add.s64 	%rd149, %rd132, %rd148;
	st.shared.v2.f32 	[%rd149], {%f179, %f180};
	shl.b32 	%r295, %r265, 4;
	or.b32  	%r296, %r295, %r276;
	mul.wide.u32 	%rd150, %r296, 4;
	add.s64 	%rd151, %rd132, %rd150;
	st.shared.v2.f32 	[%rd151], {%f181, %f182};
	shl.b32 	%r297, %r266, 4;
	or.b32  	%r298, %r297, %r276;
	mul.wide.u32 	%rd152, %r298, 4;
	add.s64 	%rd153, %rd132, %rd152;
	st.shared.v2.f32 	[%rd153], {%f183, %f184};
	shl.b32 	%r299, %r267, 4;
	or.b32  	%r300, %r299, %r276;
	mul.wide.u32 	%rd154, %r300, 4;
	add.s64 	%rd155, %rd132, %rd154;
	st.shared.v2.f32 	[%rd155], {%f185, %f186};
	shl.b32 	%r301, %r268, 4;
	or.b32  	%r302, %r301, %r276;
	mul.wide.u32 	%rd156, %r302, 4;
	add.s64 	%rd157, %rd132, %rd156;
	st.shared.v2.f32 	[%rd157], {%f187, %f188};
	shl.b32 	%r303, %r269, 4;
	or.b32  	%r304, %r303, %r276;
	mul.wide.u32 	%rd158, %r304, 4;
	add.s64 	%rd159, %rd132, %rd158;
	st.shared.v2.f32 	[%rd159], {%f189, %f190};
	shl.b32 	%r305, %r270, 4;
	or.b32  	%r306, %r305, %r276;
	mul.wide.u32 	%rd160, %r306, 4;
	add.s64 	%rd161, %rd132, %rd160;
	st.shared.v2.f32 	[%rd161], {%f191, %f192};
	shl.b32 	%r307, %r271, 4;
	or.b32  	%r308, %r307, %r276;
	mul.wide.u32 	%rd162, %r308, 4;
	add.s64 	%rd163, %rd132, %rd162;
	st.shared.v2.f32 	[%rd163], {%f193, %f194};
	selp.f32 	%f195, %f161, 0f00000000, %p68;
	selp.f32 	%f196, %f162, 0f00000000, %p68;
	shr.u32 	%r309, %r254, 1;
	and.b32  	%r310, %r309, 8;
	xor.b32  	%r311, %r273, %r310;
	or.b32  	%r312, %r311, %r277;
	mul.wide.u32 	%rd164, %r312, 4;
	add.s64 	%rd165, %rd132, 16384;
	add.s64 	%rd166, %rd165, %rd164;
	st.shared.v2.f32 	[%rd166], {%f195, %f196};
	bar.sync 	0;
	and.b32  	%r313, %r254, 7;
	bfe.u32 	%r314, %r254, 3, 2;
	bfe.u32 	%r315, %r254, 4, 1;
	bfe.u32 	%r316, %r254, 1, 2;
	shl.b32 	%r317, %r255, 4;
	and.b32  	%r318, %r254, 15;
	or.b32  	%r319, %r317, %r318;
	xor.b32  	%r320, %r315, %r316;
	shl.b32 	%r321, %r320, 4;
	shl.b32 	%r322, %r319, 6;
	or.b32  	%r323, %r322, %r321;
	cvt.u64.u32 	%rd167, %r323;
	add.s64 	%rd168, %rd132, %rd167;
	cvt.u32.u64 	%r75, %rd168;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r111, %r112, %r113, %r114 }, [ %r75 + 0 ];
	// end inline asm
	or.b32  	%r324, %r315, 2;
	xor.b32  	%r325, %r324, %r316;
	shl.b32 	%r326, %r325, 4;
	or.b32  	%r327, %r326, %r322;
	cvt.u64.u32 	%rd169, %r327;
	add.s64 	%rd170, %rd132, %rd169;
	cvt.u32.u64 	%r80, %rd170;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r159, %r160, %r161, %r162 }, [ %r80 + 0 ];
	// end inline asm
	add.s32 	%r85, %r75, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r123, %r124, %r125, %r126 }, [ %r85 + 0 ];
	// end inline asm
	add.s32 	%r90, %r80, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r171, %r172, %r173, %r174 }, [ %r90 + 0 ];
	// end inline asm
	add.s32 	%r95, %r75, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r135, %r136, %r137, %r138 }, [ %r95 + 0 ];
	// end inline asm
	add.s32 	%r100, %r80, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r183, %r184, %r185, %r186 }, [ %r100 + 0 ];
	// end inline asm
	add.s32 	%r105, %r75, 12288;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r147, %r148, %r149, %r150 }, [ %r105 + 0 ];
	// end inline asm
	add.s32 	%r110, %r80, 12288;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r195, %r196, %r197, %r198 }, [ %r110 + 0 ];
	// end inline asm
	bfe.u32 	%r328, %r254, 2, 3;
	and.b32  	%r329, %r254, 3;
	shl.b32 	%r330, %r254, 2;
	and.b32  	%r331, %r330, 8;
	shl.b32 	%r332, %r329, 4;
	or.b32  	%r333, %r331, %r332;
	or.b32  	%r334, %r333, %r328;
	xor.b32  	%r335, %r334, 8;
	mul.wide.u32 	%rd171, %r334, 4;
	add.s64 	%rd172, %rd165, %rd171;
	mul.wide.u32 	%rd173, %r335, 4;
	add.s64 	%rd174, %rd165, %rd173;
	ld.shared.u32 	%r115, [%rd172];
	ld.shared.u32 	%r121, [%rd174];
	ld.shared.u32 	%r116, [%rd172+256];
	ld.shared.u32 	%r122, [%rd174+256];
	ld.shared.u32 	%r163, [%rd172+512];
	ld.shared.u32 	%r169, [%rd174+512];
	ld.shared.u32 	%r164, [%rd172+768];
	ld.shared.u32 	%r170, [%rd174+768];
	mov.f32 	%f121, 0f00000000;
	mov.f32 	%f65, %f121;
	mov.f32 	%f66, %f121;
	mov.f32 	%f67, %f121;
	mov.f32 	%f68, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f65, %f66, %f67, %f68 }, { %r111, %r112, %r113, %r114 }, { %r115, %r116 }, { %f65, %f66, %f67, %f68 };
	// end inline asm
	mov.f32 	%f73, %f121;
	mov.f32 	%f74, %f121;
	mov.f32 	%f75, %f121;
	mov.f32 	%f76, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f73, %f74, %f75, %f76 }, { %r111, %r112, %r113, %r114 }, { %r121, %r122 }, { %f73, %f74, %f75, %f76 };
	// end inline asm
	mov.f32 	%f81, %f121;
	mov.f32 	%f82, %f121;
	mov.f32 	%f83, %f121;
	mov.f32 	%f84, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f81, %f82, %f83, %f84 }, { %r123, %r124, %r125, %r126 }, { %r115, %r116 }, { %f81, %f82, %f83, %f84 };
	// end inline asm
	mov.f32 	%f89, %f121;
	mov.f32 	%f90, %f121;
	mov.f32 	%f91, %f121;
	mov.f32 	%f92, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f89, %f90, %f91, %f92 }, { %r123, %r124, %r125, %r126 }, { %r121, %r122 }, { %f89, %f90, %f91, %f92 };
	// end inline asm
	mov.f32 	%f97, %f121;
	mov.f32 	%f98, %f121;
	mov.f32 	%f99, %f121;
	mov.f32 	%f100, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f97, %f98, %f99, %f100 }, { %r135, %r136, %r137, %r138 }, { %r115, %r116 }, { %f97, %f98, %f99, %f100 };
	// end inline asm
	mov.f32 	%f105, %f121;
	mov.f32 	%f106, %f121;
	mov.f32 	%f107, %f121;
	mov.f32 	%f108, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f105, %f106, %f107, %f108 }, { %r135, %r136, %r137, %r138 }, { %r121, %r122 }, { %f105, %f106, %f107, %f108 };
	// end inline asm
	mov.f32 	%f113, %f121;
	mov.f32 	%f114, %f121;
	mov.f32 	%f115, %f121;
	mov.f32 	%f116, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f113, %f114, %f115, %f116 }, { %r147, %r148, %r149, %r150 }, { %r115, %r116 }, { %f113, %f114, %f115, %f116 };
	// end inline asm
	mov.f32 	%f122, %f121;
	mov.f32 	%f123, %f121;
	mov.f32 	%f124, %f121;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f121, %f122, %f123, %f124 }, { %r147, %r148, %r149, %r150 }, { %r121, %r122 }, { %f121, %f122, %f123, %f124 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f65, %f66, %f67, %f68 }, { %r159, %r160, %r161, %r162 }, { %r163, %r164 }, { %f65, %f66, %f67, %f68 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f73, %f74, %f75, %f76 }, { %r159, %r160, %r161, %r162 }, { %r169, %r170 }, { %f73, %f74, %f75, %f76 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f81, %f82, %f83, %f84 }, { %r171, %r172, %r173, %r174 }, { %r163, %r164 }, { %f81, %f82, %f83, %f84 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f89, %f90, %f91, %f92 }, { %r171, %r172, %r173, %r174 }, { %r169, %r170 }, { %f89, %f90, %f91, %f92 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f97, %f98, %f99, %f100 }, { %r183, %r184, %r185, %r186 }, { %r163, %r164 }, { %f97, %f98, %f99, %f100 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f105, %f106, %f107, %f108 }, { %r183, %r184, %r185, %r186 }, { %r169, %r170 }, { %f105, %f106, %f107, %f108 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f113, %f114, %f115, %f116 }, { %r195, %r196, %r197, %r198 }, { %r163, %r164 }, { %f113, %f114, %f115, %f116 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f121, %f122, %f123, %f124 }, { %r195, %r196, %r197, %r198 }, { %r169, %r170 }, { %f121, %f122, %f123, %f124 };
	// end inline asm
	mul.lo.s32 	%r336, %r2, 307200;
	mul.wide.s32 	%rd175, %r336, 4;
	add.s64 	%rd176, %rd36, %rd175;
	mul.lo.s64 	%rd177, %rd62, 24;
	add.s64 	%rd178, %rd176, %rd177;
	add.s64 	%rd18, %rd178, %rd130;
	mul.lo.s64 	%rd179, %rd63, 24;
	add.s64 	%rd180, %rd176, %rd179;
	add.s64 	%rd19, %rd180, %rd130;
	mul.lo.s64 	%rd181, %rd64, 24;
	add.s64 	%rd182, %rd176, %rd181;
	add.s64 	%rd20, %rd182, %rd130;
	mul.lo.s64 	%rd183, %rd65, 24;
	add.s64 	%rd184, %rd176, %rd183;
	add.s64 	%rd21, %rd184, %rd130;
	mul.lo.s64 	%rd185, %rd66, 24;
	add.s64 	%rd186, %rd176, %rd185;
	add.s64 	%rd22, %rd186, %rd130;
	mul.lo.s64 	%rd187, %rd67, 24;
	add.s64 	%rd188, %rd176, %rd187;
	add.s64 	%rd23, %rd188, %rd130;
	mul.lo.s64 	%rd189, %rd68, 24;
	add.s64 	%rd190, %rd176, %rd189;
	add.s64 	%rd24, %rd190, %rd130;
	mul.lo.s64 	%rd191, %rd69, 24;
	add.s64 	%rd192, %rd176, %rd191;
	add.s64 	%rd25, %rd192, %rd130;
	mul.lo.s64 	%rd193, %rd70, 24;
	add.s64 	%rd194, %rd176, %rd193;
	add.s64 	%rd26, %rd194, %rd130;
	mul.lo.s64 	%rd195, %rd71, 24;
	add.s64 	%rd196, %rd176, %rd195;
	add.s64 	%rd27, %rd196, %rd130;
	mul.lo.s64 	%rd197, %rd72, 24;
	add.s64 	%rd198, %rd176, %rd197;
	add.s64 	%rd28, %rd198, %rd130;
	mul.lo.s64 	%rd199, %rd73, 24;
	add.s64 	%rd200, %rd176, %rd199;
	add.s64 	%rd29, %rd200, %rd130;
	mul.lo.s64 	%rd201, %rd74, 24;
	add.s64 	%rd202, %rd176, %rd201;
	add.s64 	%rd30, %rd202, %rd130;
	mul.lo.s64 	%rd203, %rd75, 24;
	add.s64 	%rd204, %rd176, %rd203;
	add.s64 	%rd31, %rd204, %rd130;
	mul.lo.s64 	%rd205, %rd76, 24;
	add.s64 	%rd206, %rd176, %rd205;
	add.s64 	%rd32, %rd206, %rd130;
	mul.lo.s64 	%rd207, %rd77, 24;
	add.s64 	%rd208, %rd176, %rd207;
	add.s64 	%rd33, %rd208, %rd130;
	bar.sync 	0;
	shl.b32 	%r337, %r329, 1;
	or.b32  	%r338, %r317, %r328;
	mul.lo.s32 	%r339, %r338, 18;
	add.s32 	%r340, %r339, %r337;
	mul.wide.u32 	%rd209, %r340, 4;
	add.s64 	%rd210, %rd132, %rd209;
	st.shared.v2.f32 	[%rd210], {%f65, %f66};
	cvt.u64.u32 	%rd211, %r337;
	cvt.u64.u32 	%rd212, %r339;
	add.s64 	%rd213, %rd212, %rd211;
	shl.b64 	%rd214, %rd213, 2;
	add.s64 	%rd215, %rd132, %rd214;
	st.shared.v2.f32 	[%rd215+576], {%f67, %f68};
	or.b32  	%r341, %r337, 8;
	st.shared.v2.f32 	[%rd215+32], {%f73, %f74};
	cvt.u64.u32 	%rd216, %r341;
	add.s64 	%rd217, %rd212, %rd216;
	shl.b64 	%rd218, %rd217, 2;
	add.s64 	%rd219, %rd132, %rd218;
	st.shared.v2.f32 	[%rd219+576], {%f75, %f76};
	bar.sync 	0;
	shl.b32 	%r342, %r255, 2;
	or.b32  	%r343, %r342, %r314;
	shl.b32 	%r344, %r313, 1;
	mad.lo.s32 	%r345, %r343, 18, %r344;
	mul.wide.u32 	%rd220, %r345, 4;
	add.s64 	%rd221, %rd132, %rd220;
	ld.shared.v2.u32 	{%r207, %r208}, [%rd221];
	ld.shared.v2.u32 	{%r209, %r210}, [%rd221+1152];
	ld.shared.v2.u32 	{%r211, %r212}, [%rd221+2304];
	ld.shared.v2.u32 	{%r213, %r214}, [%rd221+3456];
	bar.sync 	0;
	st.shared.v2.f32 	[%rd210], {%f81, %f82};
	st.shared.v2.f32 	[%rd215+576], {%f83, %f84};
	st.shared.v2.f32 	[%rd215+32], {%f89, %f90};
	st.shared.v2.f32 	[%rd219+576], {%f91, %f92};
	bar.sync 	0;
	ld.shared.v2.u32 	{%r215, %r216}, [%rd221];
	ld.shared.v2.u32 	{%r217, %r218}, [%rd221+1152];
	ld.shared.v2.u32 	{%r219, %r220}, [%rd221+2304];
	ld.shared.v2.u32 	{%r221, %r222}, [%rd221+3456];
	bar.sync 	0;
	st.shared.v2.f32 	[%rd210], {%f97, %f98};
	st.shared.v2.f32 	[%rd215+576], {%f99, %f100};
	st.shared.v2.f32 	[%rd215+32], {%f105, %f106};
	st.shared.v2.f32 	[%rd219+576], {%f107, %f108};
	bar.sync 	0;
	ld.shared.v2.u32 	{%r223, %r224}, [%rd221];
	ld.shared.v2.u32 	{%r225, %r226}, [%rd221+1152];
	ld.shared.v2.u32 	{%r227, %r228}, [%rd221+2304];
	ld.shared.v2.u32 	{%r229, %r230}, [%rd221+3456];
	bar.sync 	0;
	st.shared.v2.f32 	[%rd210], {%f113, %f114};
	st.shared.v2.f32 	[%rd215+576], {%f115, %f116};
	st.shared.v2.f32 	[%rd215+32], {%f121, %f122};
	st.shared.v2.f32 	[%rd219+576], {%f123, %f124};
	bar.sync 	0;
	ld.shared.v2.u32 	{%r231, %r232}, [%rd221];
	ld.shared.v2.u32 	{%r233, %r234}, [%rd221+1152];
	ld.shared.v2.u32 	{%r235, %r236}, [%rd221+2304];
	ld.shared.v2.u32 	{%r237, %r238}, [%rd221+3456];
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd18 + 0 ], { %r207, %r208 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd19 + 0 ], { %r209, %r210 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd20 + 0 ], { %r211, %r212 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd21 + 0 ], { %r213, %r214 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd22 + 0 ], { %r215, %r216 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd23 + 0 ], { %r217, %r218 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd24 + 0 ], { %r219, %r220 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd25 + 0 ], { %r221, %r222 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd26 + 0 ], { %r223, %r224 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd27 + 0 ], { %r225, %r226 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd28 + 0 ], { %r227, %r228 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd29 + 0 ], { %r229, %r230 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd30 + 0 ], { %r231, %r232 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd31 + 0 ], { %r233, %r234 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd32 + 0 ], { %r235, %r236 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v2.b32 [ %rd33 + 0 ], { %r237, %r238 };
	// end inline asm
	ret;

}
	// .globl	loop_transpose_fusion_103
.visible .entry loop_transpose_fusion_103(
	.param .u64 loop_transpose_fusion_103_param_0,
	.param .u64 loop_transpose_fusion_103_param_1,
	.param .u64 loop_transpose_fusion_103_param_2,
	.param .u64 loop_transpose_fusion_103_param_3,
	.param .u64 loop_transpose_fusion_103_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<29>;
	.reg .b32 	%r<37>;
	.reg .f32 	%f<34>;
	.reg .b64 	%rd<61>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 9;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	setp.lt.u32 	%p1, %r1, 4905600;
	@%p1 bra 	$L__BB103_2;
	bra.uni 	$L__BB103_1;
$L__BB103_2:
	ld.param.u64 	%rd6, [loop_transpose_fusion_103_param_0];
	ld.param.u64 	%rd7, [loop_transpose_fusion_103_param_4];
	cvta.to.global.u64 	%rd1, %rd7;
	ld.param.u64 	%rd8, [loop_transpose_fusion_103_param_1];
	ld.param.u64 	%rd9, [loop_transpose_fusion_103_param_3];
	cvta.to.global.u64 	%rd2, %rd9;
	ld.param.u64 	%rd10, [loop_transpose_fusion_103_param_2];
	cvta.to.global.u64 	%rd3, %rd10;
	cvta.to.global.u64 	%rd4, %rd8;
	cvta.to.global.u64 	%rd5, %rd6;
	or.b32  	%r6, %r1, 3;
	mul.hi.u32 	%r7, %r1, 1377079143;
	shr.u32 	%r8, %r7, 19;
	mul.hi.u32 	%r9, %r6, 1377079143;
	bfe.u32 	%r10, %r9, 13, 6;
	mul.hi.u32 	%r11, %r6, -2143281135;
	shr.u32 	%r12, %r11, 8;
	cvt.u16.u32 	%rs1, %r12;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.lo.s32 	%r13, %r12, 511;
	sub.s32 	%r14, %r6, %r13;
	or.b32  	%r15, %r1, 2;
	mul.hi.u32 	%r16, %r15, 1377079143;
	bfe.u32 	%r17, %r16, 13, 6;
	mul.hi.u32 	%r18, %r15, -2143281135;
	shr.u32 	%r19, %r18, 8;
	cvt.u16.u32 	%rs7, %r19;
	shr.u16 	%rs8, %rs7, 1;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	mul.lo.s16 	%rs11, %rs10, 50;
	sub.s16 	%rs12, %rs7, %rs11;
	mul.lo.s32 	%r20, %r19, 511;
	sub.s32 	%r21, %r15, %r20;
	or.b32  	%r22, %r1, 1;
	bfe.u32 	%r23, %r7, 13, 6;
	mul.hi.u32 	%r24, %r22, -2143281135;
	shr.u32 	%r25, %r24, 8;
	cvt.u16.u32 	%rs13, %r25;
	shr.u16 	%rs14, %rs13, 1;
	mul.hi.u16 	%rs15, %rs14, 5243;
	shr.u16 	%rs16, %rs15, 1;
	mul.lo.s16 	%rs17, %rs16, 50;
	sub.s16 	%rs18, %rs13, %rs17;
	mul.lo.s32 	%r26, %r25, 511;
	sub.s32 	%r27, %r22, %r26;
	mul.hi.u32 	%r28, %r1, -2143281135;
	shr.u32 	%r29, %r28, 8;
	cvt.u16.u32 	%rs19, %r29;
	shr.u16 	%rs20, %rs19, 1;
	mul.hi.u16 	%rs21, %rs20, 5243;
	shr.u16 	%rs22, %rs21, 1;
	mul.lo.s16 	%rs23, %rs22, 50;
	sub.s16 	%rs24, %rs19, %rs23;
	mul.lo.s32 	%r30, %r29, 511;
	sub.s32 	%r31, %r1, %r30;
	shl.b32 	%r32, %r8, 1;
	mul.wide.u32 	%rd11, %r23, 12;
	add.s64 	%rd12, %rd3, %rd11;
	mul.wide.u32 	%rd13, %r8, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	mul.wide.u32 	%rd15, %r23, 4;
	add.s64 	%rd16, %rd4, %rd15;
	ld.global.nc.f32 	%f2, [%rd16];
	shl.b32 	%r33, %r31, 1;
	shl.b16 	%rs25, %rs24, 10;
	cvt.u64.u16 	%rd17, %rs25;
	cvt.u64.u32 	%rd18, %r33;
	add.s64 	%rd19, %rd18, %rd17;
	mul.lo.s64 	%rd20, %rd19, 24;
	mul.wide.u32 	%rd21, %r23, 1228800;
	add.s64 	%rd22, %rd5, %rd21;
	add.s64 	%rd23, %rd22, %rd20;
	mul.wide.u32 	%rd24, %r32, 4;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.nc.v2.f32 	{%f3, %f4}, [%rd25+48];
	mul.rn.f32 	%f5, %f2, %f4;
	mul.rn.f32 	%f6, %f1, %f5;
	mul.rn.f32 	%f7, %f2, %f3;
	neg.f32 	%f8, %f1;
	mul.rn.f32 	%f9, %f7, %f8;
	mul.wide.u32 	%rd26, %r1, 4;
	add.s64 	%rd27, %rd2, %rd26;
	add.s64 	%rd28, %rd1, %rd26;
	shl.b32 	%r34, %r27, 1;
	shl.b16 	%rs26, %rs18, 10;
	cvt.u64.u16 	%rd29, %rs26;
	cvt.u64.u32 	%rd30, %r34;
	add.s64 	%rd31, %rd30, %rd29;
	mul.lo.s64 	%rd32, %rd31, 24;
	add.s64 	%rd33, %rd22, %rd32;
	add.s64 	%rd34, %rd33, %rd24;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd34+48];
	mul.rn.f32 	%f12, %f2, %f11;
	mul.rn.f32 	%f13, %f1, %f12;
	mul.rn.f32 	%f14, %f2, %f10;
	mul.rn.f32 	%f15, %f14, %f8;
	mul.wide.u32 	%rd35, %r17, 12;
	add.s64 	%rd36, %rd3, %rd35;
	add.s64 	%rd37, %rd36, %rd13;
	ld.global.nc.f32 	%f16, [%rd37];
	mul.wide.u32 	%rd38, %r17, 4;
	add.s64 	%rd39, %rd4, %rd38;
	ld.global.nc.f32 	%f17, [%rd39];
	shl.b32 	%r35, %r21, 1;
	shl.b16 	%rs27, %rs12, 10;
	cvt.u64.u16 	%rd40, %rs27;
	cvt.u64.u32 	%rd41, %r35;
	add.s64 	%rd42, %rd41, %rd40;
	mul.lo.s64 	%rd43, %rd42, 24;
	mul.wide.u32 	%rd44, %r17, 1228800;
	add.s64 	%rd45, %rd5, %rd44;
	add.s64 	%rd46, %rd45, %rd43;
	add.s64 	%rd47, %rd46, %rd24;
	ld.global.nc.v2.f32 	{%f18, %f19}, [%rd47+48];
	mul.rn.f32 	%f20, %f17, %f19;
	mul.rn.f32 	%f21, %f16, %f20;
	mul.rn.f32 	%f22, %f17, %f18;
	neg.f32 	%f23, %f16;
	mul.rn.f32 	%f24, %f22, %f23;
	mul.wide.u32 	%rd48, %r10, 12;
	add.s64 	%rd49, %rd3, %rd48;
	add.s64 	%rd50, %rd49, %rd13;
	ld.global.nc.f32 	%f25, [%rd50];
	mul.wide.u32 	%rd51, %r10, 4;
	add.s64 	%rd52, %rd4, %rd51;
	ld.global.nc.f32 	%f26, [%rd52];
	shl.b32 	%r36, %r14, 1;
	shl.b16 	%rs28, %rs6, 10;
	cvt.u64.u16 	%rd53, %rs28;
	cvt.u64.u32 	%rd54, %r36;
	add.s64 	%rd55, %rd54, %rd53;
	mul.lo.s64 	%rd56, %rd55, 24;
	mul.wide.u32 	%rd57, %r10, 1228800;
	add.s64 	%rd58, %rd5, %rd57;
	add.s64 	%rd59, %rd58, %rd56;
	add.s64 	%rd60, %rd59, %rd24;
	ld.global.nc.v2.f32 	{%f27, %f28}, [%rd60+48];
	mul.rn.f32 	%f29, %f26, %f28;
	mul.rn.f32 	%f30, %f25, %f29;
	mul.rn.f32 	%f31, %f26, %f27;
	neg.f32 	%f32, %f25;
	mul.rn.f32 	%f33, %f31, %f32;
	st.global.v4.f32 	[%rd27], {%f6, %f13, %f21, %f30};
	st.global.v4.f32 	[%rd28], {%f9, %f15, %f24, %f33};
$L__BB103_1:
	ret;

}
	// .globl	loop_broadcast_fusion_28
.visible .entry loop_broadcast_fusion_28(
	.param .u64 loop_broadcast_fusion_28_param_0
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd2, [loop_broadcast_fusion_28_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 9;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	mul.wide.u32 	%rd4, %r1, 4;
	add.s64 	%rd1, %rd3, %rd4;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd1], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+3538944], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+7077888], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+10616832], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+14155776], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+17694720], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+21233664], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+24772608], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+28311552], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+31850496], {%f1, %f1, %f1, %f1};
	setp.gt.u32 	%p1, %r1, 963839;
	@%p1 bra 	$L__BB104_2;
	st.global.v4.f32 	[%rd1+35389440], {%f1, %f1, %f1, %f1};
$L__BB104_2:
	setp.gt.u32 	%p2, %r1, 79103;
	@%p2 bra 	$L__BB104_4;
	st.global.v4.f32 	[%rd1+38928384], {%f1, %f1, %f1, %f1};
$L__BB104_4:
	ret;

}
	// .globl	input_scatter_fusion_228
.visible .entry input_scatter_fusion_228(
	.param .u64 input_scatter_fusion_228_param_0,
	.param .u64 input_scatter_fusion_228_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<16>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_228_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_228_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, 8405025;
	sub.s32 	%r6, %r4, %r5;
	shr.u32 	%r7, %r6, 1;
	add.s32 	%r8, %r7, %r5;
	shr.u32 	%r9, %r8, 8;
	mul.lo.s32 	%r10, %r9, 511;
	sub.s32 	%r11, %r4, %r10;
	cvt.u16.u32 	%rs1, %r9;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r12, %r4, -1540809011;
	bfe.u32 	%r13, %r12, 14, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, 18515;
	sub.s16 	%rs9, %rs7, %rs8;
	shr.u16 	%rs10, %rs9, 1;
	add.s16 	%rs11, %rs10, %rs8;
	shr.u16 	%rs12, %rs11, 12;
	and.b16  	%rs13, %rs12, 14;
	cvt.u32.u16 	%r14, %rs6;
	mul.wide.u32 	%rd5, %r14, 2044;
	cvt.u32.u16 	%r15, %rs13;
	mul.wide.u32 	%rd6, %r15, 6540800;
	add.s64 	%rd7, %rd4, %rd6;
	mul.wide.u32 	%rd8, %r13, 102200;
	add.s64 	%rd9, %rd7, %rd8;
	add.s64 	%rd10, %rd9, %rd5;
	mul.wide.u32 	%rd11, %r11, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+6540800];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+6540800], %f3;
	ret;

}
	// .globl	wrapped_transpose_234
.visible .entry wrapped_transpose_234(
	.param .u64 wrapped_transpose_234_param_0,
	.param .u64 wrapped_transpose_234_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<44>;
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<34>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 9;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	setp.lt.u32 	%p1, %r1, 9811200;
	@%p1 bra 	$L__BB106_2;
	bra.uni 	$L__BB106_1;
$L__BB106_2:
	ld.param.u64 	%rd3, [wrapped_transpose_234_param_0];
	ld.param.u64 	%rd4, [wrapped_transpose_234_param_1];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd3;
	mul.hi.u32 	%r6, %r1, 459026381;
	shr.u32 	%r7, %r6, 14;
	or.b32  	%r8, %r1, 3;
	mul.hi.u32 	%r9, %r8, -1426052415;
	shr.u32 	%r10, %r9, 11;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r8, 715827883;
	mul.hi.u32 	%r12, %r11, 537921541;
	shr.u32 	%r13, %r12, 6;
	mul.lo.s32 	%r14, %r13, 511;
	sub.s32 	%r15, %r11, %r14;
	mul.lo.s32 	%r16, %r11, 6;
	sub.s32 	%r17, %r8, %r16;
	or.b32  	%r18, %r1, 2;
	mul.hi.u32 	%r19, %r18, -1426052415;
	shr.u32 	%r20, %r19, 11;
	cvt.u16.u32 	%rs7, %r20;
	shr.u16 	%rs8, %rs7, 1;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	mul.lo.s16 	%rs11, %rs10, 50;
	sub.s16 	%rs12, %rs7, %rs11;
	mul.hi.u32 	%r21, %r18, 715827883;
	mul.hi.u32 	%r22, %r21, 537921541;
	shr.u32 	%r23, %r22, 6;
	mul.lo.s32 	%r24, %r23, 511;
	sub.s32 	%r25, %r21, %r24;
	mul.lo.s32 	%r26, %r21, 6;
	sub.s32 	%r27, %r18, %r26;
	or.b32  	%r28, %r1, 1;
	mul.hi.u32 	%r29, %r1, -1426052415;
	shr.u32 	%r30, %r29, 11;
	cvt.u16.u32 	%rs13, %r30;
	shr.u16 	%rs14, %rs13, 1;
	mul.hi.u16 	%rs15, %rs14, 5243;
	shr.u16 	%rs16, %rs15, 1;
	mul.lo.s16 	%rs17, %rs16, 50;
	sub.s16 	%rs18, %rs13, %rs17;
	mul.hi.u32 	%r31, %r1, 715827883;
	mul.hi.u32 	%r32, %r31, 537921541;
	shr.u32 	%r33, %r32, 6;
	mul.lo.s32 	%r34, %r33, 511;
	sub.s32 	%r35, %r31, %r34;
	mul.hi.u32 	%r36, %r28, 715827883;
	mul.lo.s32 	%r37, %r36, 6;
	sub.s32 	%r38, %r28, %r37;
	mul.lo.s32 	%r39, %r31, 6;
	sub.s32 	%r40, %r1, %r39;
	mul.wide.u32 	%rd5, %r40, 6540800;
	add.s64 	%rd6, %rd2, %rd5;
	mul.wide.u32 	%rd7, %r7, 102200;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r41, %rs18;
	mul.wide.u32 	%rd9, %r41, 2044;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r35, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r1, 4;
	add.s64 	%rd14, %rd1, %rd13;
	mul.wide.u32 	%rd15, %r38, 6540800;
	add.s64 	%rd16, %rd2, %rd15;
	add.s64 	%rd17, %rd16, %rd7;
	add.s64 	%rd18, %rd17, %rd9;
	add.s64 	%rd19, %rd18, %rd11;
	ld.global.nc.f32 	%f2, [%rd19];
	mul.wide.u32 	%rd20, %r27, 6540800;
	add.s64 	%rd21, %rd2, %rd20;
	add.s64 	%rd22, %rd21, %rd7;
	cvt.u32.u16 	%r42, %rs12;
	mul.wide.u32 	%rd23, %r42, 2044;
	add.s64 	%rd24, %rd22, %rd23;
	mul.wide.u32 	%rd25, %r25, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f3, [%rd26];
	mul.wide.u32 	%rd27, %r17, 6540800;
	add.s64 	%rd28, %rd2, %rd27;
	add.s64 	%rd29, %rd28, %rd7;
	cvt.u32.u16 	%r43, %rs6;
	mul.wide.u32 	%rd30, %r43, 2044;
	add.s64 	%rd31, %rd29, %rd30;
	mul.wide.u32 	%rd32, %r15, 4;
	add.s64 	%rd33, %rd31, %rd32;
	ld.global.nc.f32 	%f4, [%rd33];
	st.global.v4.f32 	[%rd14], {%f1, %f2, %f3, %f4};
$L__BB106_1:
	ret;

}
	// .globl	input_scatter_fusion_229
.visible .entry input_scatter_fusion_229(
	.param .u64 input_scatter_fusion_229_param_0,
	.param .u64 input_scatter_fusion_229_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<16>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_229_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_229_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, 8405025;
	sub.s32 	%r6, %r4, %r5;
	shr.u32 	%r7, %r6, 1;
	add.s32 	%r8, %r7, %r5;
	shr.u32 	%r9, %r8, 8;
	mul.lo.s32 	%r10, %r9, 511;
	sub.s32 	%r11, %r4, %r10;
	cvt.u16.u32 	%rs1, %r9;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r12, %r4, -1540809011;
	bfe.u32 	%r13, %r12, 14, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, 18515;
	sub.s16 	%rs9, %rs7, %rs8;
	shr.u16 	%rs10, %rs9, 1;
	add.s16 	%rs11, %rs10, %rs8;
	shr.u16 	%rs12, %rs11, 12;
	and.b16  	%rs13, %rs12, 14;
	cvt.u32.u16 	%r14, %rs6;
	mul.wide.u32 	%rd5, %r14, 2044;
	cvt.u32.u16 	%r15, %rs13;
	mul.wide.u32 	%rd6, %r15, 6540800;
	add.s64 	%rd7, %rd4, %rd6;
	mul.wide.u32 	%rd8, %r13, 102200;
	add.s64 	%rd9, %rd7, %rd8;
	add.s64 	%rd10, %rd9, %rd5;
	mul.wide.u32 	%rd11, %r11, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	input_reduce_slice_fusion_12
.visible .entry input_reduce_slice_fusion_12(
	.param .u64 input_reduce_slice_fusion_12_param_0,
	.param .u64 input_reduce_slice_fusion_12_param_1,
	.param .u64 input_reduce_slice_fusion_12_param_2,
	.param .u64 input_reduce_slice_fusion_12_param_3,
	.param .u64 input_reduce_slice_fusion_12_param_4,
	.param .u64 input_reduce_slice_fusion_12_param_5,
	.param .u64 input_reduce_slice_fusion_12_param_6,
	.param .u64 input_reduce_slice_fusion_12_param_7,
	.param .u64 input_reduce_slice_fusion_12_param_8,
	.param .u64 input_reduce_slice_fusion_12_param_9,
	.param .u64 input_reduce_slice_fusion_12_param_10,
	.param .u64 input_reduce_slice_fusion_12_param_11,
	.param .u64 input_reduce_slice_fusion_12_param_12
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<22>;
	.reg .b32 	%r<32>;
	.reg .f32 	%f<72>;
	.reg .b64 	%rd<133>;
	// demoted variable
	.shared .align 4 .b8 shared_cache9[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache10[4224];
	ld.param.u64 	%rd31, [input_reduce_slice_fusion_12_param_0];
	ld.param.u64 	%rd32, [input_reduce_slice_fusion_12_param_12];
	cvta.to.global.u64 	%rd33, %rd32;
	ld.param.u64 	%rd34, [input_reduce_slice_fusion_12_param_1];
	ld.param.u64 	%rd35, [input_reduce_slice_fusion_12_param_11];
	cvta.to.global.u64 	%rd1, %rd35;
	ld.param.u64 	%rd36, [input_reduce_slice_fusion_12_param_2];
	ld.param.u64 	%rd37, [input_reduce_slice_fusion_12_param_10];
	cvta.to.global.u64 	%rd2, %rd37;
	ld.param.u64 	%rd38, [input_reduce_slice_fusion_12_param_3];
	ld.param.u64 	%rd39, [input_reduce_slice_fusion_12_param_9];
	cvta.to.global.u64 	%rd40, %rd39;
	ld.param.u64 	%rd41, [input_reduce_slice_fusion_12_param_4];
	ld.param.u64 	%rd42, [input_reduce_slice_fusion_12_param_8];
	cvta.to.global.u64 	%rd43, %rd42;
	ld.param.u64 	%rd44, [input_reduce_slice_fusion_12_param_5];
	ld.param.u64 	%rd45, [input_reduce_slice_fusion_12_param_7];
	cvta.to.global.u64 	%rd46, %rd45;
	ld.param.u64 	%rd47, [input_reduce_slice_fusion_12_param_6];
	cvta.to.global.u64 	%rd48, %rd47;
	cvta.to.global.u64 	%rd49, %rd44;
	cvta.to.global.u64 	%rd50, %rd41;
	cvta.to.global.u64 	%rd51, %rd38;
	cvta.to.global.u64 	%rd52, %rd36;
	cvta.to.global.u64 	%rd53, %rd34;
	cvta.to.global.u64 	%rd54, %rd31;
	mov.u32 	%r9, %tid.x;
	mov.u32 	%r10, %ctaid.x;
	shr.u32 	%r1, %r9, 5;
	and.b32  	%r2, %r9, 31;
	cvt.u16.u32 	%rs1, %r10;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 5;
	mul.lo.s16 	%rs4, %rs3, 48;
	sub.s16 	%rs5, %rs1, %rs4;
	setp.eq.s16 	%p2, %rs5, 47;
	selp.b32 	%r3, 26, 32, %p2;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r4, %rs6;
	or.b32  	%r5, %r2, %r4;
	cvt.u16.u32 	%rs7, %r5;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r11, %rs10;
	cvt.u64.u16 	%rd3, %rs3;
	shr.u32 	%r12, %r11, 1;
	mul.wide.u32 	%rd55, %r12, 4;
	cvt.u32.u16 	%r13, %rs3;
	mul.wide.u32 	%rd56, %r13, 12;
	add.s64 	%rd57, %rd48, %rd56;
	add.s64 	%rd4, %rd57, %rd55;
	mul.wide.u32 	%rd58, %r13, 4;
	add.s64 	%rd5, %rd49, %rd58;
	add.s64 	%rd59, %rd52, %rd56;
	add.s64 	%rd6, %rd59, %rd55;
	add.s64 	%rd60, %rd51, %rd56;
	add.s64 	%rd7, %rd60, %rd55;
	add.s64 	%rd8, %rd50, %rd58;
	add.s32 	%r31, %r1, -32;
	shl.b16 	%rs11, %rs1, 5;
	cvt.u16.u32 	%rs12, %r9;
	and.b16  	%rs13, %rs12, 31;
	or.b16  	%rs14, %rs11, %rs13;
	mul.lo.s16 	%rs15, %rs3, 1536;
	sub.s16 	%rs16, %rs14, %rs15;
	mul.hi.u16 	%rs17, %rs16, -21845;
	shr.u16 	%rs18, %rs17, 2;
	mul.lo.s16 	%rs19, %rs18, 6;
	sub.s16 	%rs20, %rs14, %rs19;
	sub.s16 	%rs21, %rs20, %rs15;
	cvt.u32.u16 	%r14, %rs21;
	mul.wide.u32 	%rd9, %r14, 4;
	mul.wide.u32 	%rd61, %r13, 306000;
	cvt.u64.u32 	%rd62, %r9;
	shr.u64 	%rd63, %rd62, 5;
	mul.lo.s64 	%rd64, %rd63, 6120;
	add.s64 	%rd65, %rd61, %rd64;
	cvt.u32.u16 	%r15, %rs16;
	mul.hi.u32 	%r16, %r15, 715827883;
	mul.wide.u32 	%rd66, %r16, 24;
	add.s64 	%rd67, %rd65, %rd66;
	add.s64 	%rd132, %rd33, %rd67;
	mul.wide.u32 	%rd68, %r13, 1228800;
	mul.lo.s64 	%rd69, %rd63, 24576;
	add.s64 	%rd70, %rd68, %rd69;
	mul.wide.u32 	%rd71, %r16, 96;
	add.s64 	%rd72, %rd70, %rd71;
	add.s64 	%rd73, %rd72, %rd40;
	add.s64 	%rd131, %rd73, 120;
	mul.wide.u32 	%rd74, %r13, 613200;
	mul.lo.s64 	%rd75, %rd63, 12264;
	add.s64 	%rd76, %rd74, %rd75;
	mul.wide.u32 	%rd77, %r16, 48;
	add.s64 	%rd78, %rd76, %rd77;
	add.s64 	%rd79, %rd78, 48;
	add.s64 	%rd130, %rd43, %rd79;
	add.s64 	%rd129, %rd46, %rd79;
	mul.wide.u32 	%rd80, %r13, 307200;
	mul.lo.s64 	%rd81, %rd63, 6144;
	add.s64 	%rd82, %rd80, %rd81;
	add.s64 	%rd83, %rd82, %rd66;
	add.s64 	%rd128, %rd53, %rd83;
	and.b64  	%rd84, %rd9, 262136;
	add.s64 	%rd85, %rd67, %rd84;
	and.b32  	%r17, %r9, 1;
	mul.wide.u32 	%rd86, %r17, 4;
	or.b64  	%rd87, %rd85, %rd86;
	add.s64 	%rd127, %rd54, %rd87;
	mov.f32 	%f16, 0f00000000;
	setp.lt.u32 	%p3, %r2, %r3;
	setp.lt.u32 	%p4, %r5, 1530;
	mov.f32 	%f1, %f16;
	mov.f32 	%f2, %f16;
	bra.uni 	$L__BB108_1;
$L__BB108_8:
	add.rn.f32 	%f1, %f1, %f34;
	add.rn.f32 	%f43, %f7, %f71;
	mul.rn.f32 	%f44, %f11, %f43;
	mul.rn.f32 	%f45, %f9, %f44;
	add.rn.f32 	%f2, %f2, %f45;
	add.s64 	%rd93, %rd132, %rd9;
	st.global.f32 	[%rd93], %f43;
$L__BB108_2:
	add.s32 	%r31, %r31, 32;
	add.s64 	%rd132, %rd132, 195840;
	add.s64 	%rd131, %rd131, 786432;
	add.s64 	%rd130, %rd130, 392448;
	add.s64 	%rd129, %rd129, 392448;
	add.s64 	%rd128, %rd128, 196608;
	add.s64 	%rd127, %rd127, 195840;
	setp.lt.u32 	%p6, %r31, 18;
	@%p6 bra 	$L__BB108_1;
	bra.uni 	$L__BB108_3;
$L__BB108_1:
	@%p3 bra 	$L__BB108_6;
	bra.uni 	$L__BB108_2;
$L__BB108_6:
	add.s64 	%rd30, %rd131, %rd9;
	ld.global.nc.f32 	%f7, [%rd30];
	add.s64 	%rd125, %rd129, %rd9;
	add.s64 	%rd126, %rd130, %rd9;
	mov.f32 	%f70, %f16;
	@%p4 bra 	$L__BB108_9;
	bra.uni 	$L__BB108_7;
$L__BB108_9:
	ld.global.nc.f32 	%f18, [%rd125];
	ld.global.nc.f32 	%f19, [%rd126];
	add.rn.f32 	%f20, %f18, %f19;
	ld.global.nc.f32 	%f21, [%rd4];
	ld.global.nc.f32 	%f22, [%rd5];
	ld.global.nc.f32 	%f23, [%rd30+24];
	mul.rn.f32 	%f24, %f22, %f23;
	mul.rn.f32 	%f25, %f21, %f24;
	add.rn.f32 	%f70, %f20, %f25;
$L__BB108_7:
	add.rn.f32 	%f27, %f7, %f70;
	ld.global.nc.f32 	%f28, [%rd6];
	add.s64 	%rd90, %rd128, %rd9;
	ld.global.nc.f32 	%f29, [%rd90];
	mul.rn.f32 	%f30, %f28, %f29;
	ld.global.nc.f32 	%f31, [%rd7];
	ld.global.nc.f32 	%f9, [%rd127];
	mul.rn.f32 	%f32, %f31, %f9;
	add.rn.f32 	%f33, %f30, %f32;
	mul.rn.f32 	%f34, %f27, %f33;
	ld.global.nc.f32 	%f11, [%rd8];
	mov.f32 	%f71, %f16;
	@%p4 bra 	$L__BB108_10;
	bra.uni 	$L__BB108_8;
$L__BB108_10:
	ld.global.nc.f32 	%f35, [%rd125];
	ld.global.nc.f32 	%f36, [%rd126];
	add.rn.f32 	%f37, %f35, %f36;
	ld.global.nc.f32 	%f38, [%rd4];
	ld.global.nc.f32 	%f39, [%rd5];
	ld.global.nc.f32 	%f40, [%rd30+24];
	mul.rn.f32 	%f41, %f39, %f40;
	mul.rn.f32 	%f42, %f38, %f41;
	add.rn.f32 	%f71, %f37, %f42;
	bra.uni 	$L__BB108_8;
$L__BB108_3:
	cvt.u64.u32 	%rd28, %r2;
	cvt.u64.u32 	%rd29, %r1;
	mul.wide.u32 	%rd94, %r2, 132;
	mov.u64 	%rd95, shared_cache9;
	add.s64 	%rd96, %rd95, %rd94;
	mul.wide.u32 	%rd97, %r1, 4;
	add.s64 	%rd98, %rd96, %rd97;
	st.shared.f32 	[%rd98], %f1;
	bar.sync 	0;
	mul.wide.u32 	%rd99, %r1, 132;
	add.s64 	%rd100, %rd95, %rd99;
	mul.wide.u32 	%rd101, %r2, 4;
	add.s64 	%rd102, %rd100, %rd101;
	ld.shared.f32 	%f46, [%rd102];
	shfl.sync.down.b32	%f47, %f46, 16, 31, -1;
	add.rn.f32 	%f48, %f46, %f47;
	shfl.sync.down.b32	%f49, %f48, 8, 31, -1;
	add.rn.f32 	%f50, %f48, %f49;
	shfl.sync.down.b32	%f51, %f50, 4, 31, -1;
	add.rn.f32 	%f52, %f50, %f51;
	shfl.sync.down.b32	%f53, %f52, 2, 31, -1;
	add.rn.f32 	%f54, %f52, %f53;
	shfl.sync.down.b32	%f55, %f54, 1, 31, -1;
	add.rn.f32 	%f5, %f54, %f55;
	st.shared.f32 	[%rd102], %f5;
	setp.lt.u32 	%p7, %r1, %r3;
	setp.eq.s32 	%p8, %r2, 0;
	and.pred  	%p1, %p8, %p7;
	or.b32  	%r30, %r1, %r4;
	mul.lo.s64 	%rd124, %rd3, 6120;
	@%p1 bra 	$L__BB108_11;
	bra.uni 	$L__BB108_4;
$L__BB108_11:
	mul.hi.u32 	%r20, %r30, -1431655765;
	shr.u32 	%r21, %r20, 2;
	mul.lo.s32 	%r22, %r21, 6;
	sub.s32 	%r23, %r30, %r22;
	add.s64 	%rd104, %rd2, %rd124;
	mul.wide.u32 	%rd105, %r21, 24;
	add.s64 	%rd106, %rd104, %rd105;
	mul.wide.u32 	%rd107, %r23, 4;
	add.s64 	%rd108, %rd106, %rd107;
	st.global.f32 	[%rd108], %f5;
$L__BB108_4:
	mul.lo.s64 	%rd109, %rd28, 132;
	mov.u64 	%rd110, shared_cache10;
	add.s64 	%rd111, %rd110, %rd109;
	shl.b64 	%rd112, %rd29, 2;
	add.s64 	%rd113, %rd111, %rd112;
	st.shared.f32 	[%rd113], %f2;
	bar.sync 	0;
	mul.lo.s64 	%rd114, %rd29, 132;
	add.s64 	%rd115, %rd110, %rd114;
	shl.b64 	%rd116, %rd28, 2;
	add.s64 	%rd117, %rd115, %rd116;
	ld.shared.f32 	%f56, [%rd117];
	shfl.sync.down.b32	%f57, %f56, 16, 31, -1;
	add.rn.f32 	%f58, %f56, %f57;
	shfl.sync.down.b32	%f59, %f58, 8, 31, -1;
	add.rn.f32 	%f60, %f58, %f59;
	shfl.sync.down.b32	%f61, %f60, 4, 31, -1;
	add.rn.f32 	%f62, %f60, %f61;
	shfl.sync.down.b32	%f63, %f62, 2, 31, -1;
	add.rn.f32 	%f64, %f62, %f63;
	shfl.sync.down.b32	%f65, %f64, 1, 31, -1;
	add.rn.f32 	%f6, %f64, %f65;
	st.shared.f32 	[%rd117], %f6;
	@%p1 bra 	$L__BB108_12;
	bra.uni 	$L__BB108_5;
$L__BB108_12:
	mul.hi.u32 	%r26, %r30, -1431655765;
	shr.u32 	%r27, %r26, 2;
	mul.lo.s32 	%r28, %r27, 6;
	sub.s32 	%r29, %r30, %r28;
	add.s64 	%rd119, %rd1, %rd124;
	mul.wide.u32 	%rd120, %r27, 24;
	add.s64 	%rd121, %rd119, %rd120;
	mul.wide.u32 	%rd122, %r29, 4;
	add.s64 	%rd123, %rd121, %rd122;
	st.global.f32 	[%rd123], %f6;
$L__BB108_5:
	ret;

}
	// .globl	loop_transpose_fusion_104
.visible .entry loop_transpose_fusion_104(
	.param .u64 loop_transpose_fusion_104_param_0,
	.param .u64 loop_transpose_fusion_104_param_1,
	.param .u64 loop_transpose_fusion_104_param_2,
	.param .u64 loop_transpose_fusion_104_param_3,
	.param .u64 loop_transpose_fusion_104_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<25>;
	.reg .b32 	%r<37>;
	.reg .f32 	%f<34>;
	.reg .b64 	%rd<57>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 9;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	setp.lt.u32 	%p1, %r1, 2448000;
	@%p1 bra 	$L__BB109_2;
	bra.uni 	$L__BB109_1;
$L__BB109_2:
	ld.param.u64 	%rd6, [loop_transpose_fusion_104_param_0];
	ld.param.u64 	%rd7, [loop_transpose_fusion_104_param_4];
	cvta.to.global.u64 	%rd1, %rd7;
	ld.param.u64 	%rd8, [loop_transpose_fusion_104_param_1];
	ld.param.u64 	%rd9, [loop_transpose_fusion_104_param_3];
	cvta.to.global.u64 	%rd2, %rd9;
	ld.param.u64 	%rd10, [loop_transpose_fusion_104_param_2];
	cvta.to.global.u64 	%rd3, %rd10;
	cvta.to.global.u64 	%rd4, %rd8;
	cvta.to.global.u64 	%rd5, %rd6;
	or.b32  	%r6, %r1, 3;
	mul.hi.u32 	%r7, %r1, 689889649;
	shr.u32 	%r8, %r7, 17;
	mul.hi.u32 	%r9, %r6, 689889649;
	bfe.u32 	%r10, %r9, 11, 6;
	mul.hi.u32 	%r11, %r6, -2139062143;
	shr.u32 	%r12, %r11, 7;
	cvt.u16.u32 	%rs1, %r12;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.lo.s32 	%r13, %r12, 255;
	sub.s32 	%r14, %r6, %r13;
	or.b32  	%r15, %r1, 2;
	mul.hi.u32 	%r16, %r15, 689889649;
	bfe.u32 	%r17, %r16, 11, 6;
	mul.hi.u32 	%r18, %r15, -2139062143;
	shr.u32 	%r19, %r18, 7;
	cvt.u16.u32 	%rs7, %r19;
	shr.u16 	%rs8, %rs7, 1;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	mul.lo.s16 	%rs11, %rs10, 50;
	sub.s16 	%rs12, %rs7, %rs11;
	mul.lo.s32 	%r20, %r19, 255;
	sub.s32 	%r21, %r15, %r20;
	or.b32  	%r22, %r1, 1;
	bfe.u32 	%r23, %r7, 11, 6;
	mul.hi.u32 	%r24, %r22, -2139062143;
	shr.u32 	%r25, %r24, 7;
	cvt.u16.u32 	%rs13, %r25;
	shr.u16 	%rs14, %rs13, 1;
	mul.hi.u16 	%rs15, %rs14, 5243;
	shr.u16 	%rs16, %rs15, 1;
	mul.lo.s16 	%rs17, %rs16, 50;
	sub.s16 	%rs18, %rs13, %rs17;
	mul.lo.s32 	%r26, %r25, 255;
	sub.s32 	%r27, %r22, %r26;
	mul.hi.u32 	%r28, %r1, -2139062143;
	shr.u32 	%r29, %r28, 7;
	cvt.u16.u32 	%rs19, %r29;
	shr.u16 	%rs20, %rs19, 1;
	mul.hi.u16 	%rs21, %rs20, 5243;
	shr.u16 	%rs22, %rs21, 1;
	mul.lo.s16 	%rs23, %rs22, 50;
	sub.s16 	%rs24, %rs19, %rs23;
	mul.lo.s32 	%r30, %r29, 255;
	sub.s32 	%r31, %r1, %r30;
	shl.b32 	%r32, %r8, 1;
	mul.wide.u32 	%rd11, %r23, 12;
	add.s64 	%rd12, %rd3, %rd11;
	mul.wide.u32 	%rd13, %r8, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	mul.wide.u32 	%rd15, %r23, 4;
	add.s64 	%rd16, %rd4, %rd15;
	ld.global.nc.f32 	%f2, [%rd16];
	mul.wide.u32 	%rd17, %r23, 306000;
	add.s64 	%rd18, %rd5, %rd17;
	cvt.u32.u16 	%r33, %rs24;
	mul.wide.u32 	%rd19, %r33, 6120;
	add.s64 	%rd20, %rd18, %rd19;
	mul.wide.u32 	%rd21, %r31, 24;
	add.s64 	%rd22, %rd20, %rd21;
	mul.wide.u32 	%rd23, %r32, 4;
	add.s64 	%rd24, %rd22, %rd23;
	ld.global.nc.v2.f32 	{%f3, %f4}, [%rd24];
	mul.rn.f32 	%f5, %f2, %f4;
	mul.rn.f32 	%f6, %f1, %f5;
	mul.rn.f32 	%f7, %f2, %f3;
	neg.f32 	%f8, %f1;
	mul.rn.f32 	%f9, %f7, %f8;
	mul.wide.u32 	%rd25, %r1, 4;
	add.s64 	%rd26, %rd2, %rd25;
	add.s64 	%rd27, %rd1, %rd25;
	cvt.u32.u16 	%r34, %rs18;
	mul.wide.u32 	%rd28, %r34, 6120;
	add.s64 	%rd29, %rd18, %rd28;
	mul.wide.u32 	%rd30, %r27, 24;
	add.s64 	%rd31, %rd29, %rd30;
	add.s64 	%rd32, %rd31, %rd23;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd32];
	mul.rn.f32 	%f12, %f2, %f11;
	mul.rn.f32 	%f13, %f1, %f12;
	mul.rn.f32 	%f14, %f2, %f10;
	mul.rn.f32 	%f15, %f14, %f8;
	mul.wide.u32 	%rd33, %r17, 12;
	add.s64 	%rd34, %rd3, %rd33;
	add.s64 	%rd35, %rd34, %rd13;
	ld.global.nc.f32 	%f16, [%rd35];
	mul.wide.u32 	%rd36, %r17, 4;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.nc.f32 	%f17, [%rd37];
	mul.wide.u32 	%rd38, %r17, 306000;
	add.s64 	%rd39, %rd5, %rd38;
	cvt.u32.u16 	%r35, %rs12;
	mul.wide.u32 	%rd40, %r35, 6120;
	add.s64 	%rd41, %rd39, %rd40;
	mul.wide.u32 	%rd42, %r21, 24;
	add.s64 	%rd43, %rd41, %rd42;
	add.s64 	%rd44, %rd43, %rd23;
	ld.global.nc.v2.f32 	{%f18, %f19}, [%rd44];
	mul.rn.f32 	%f20, %f17, %f19;
	mul.rn.f32 	%f21, %f16, %f20;
	mul.rn.f32 	%f22, %f17, %f18;
	neg.f32 	%f23, %f16;
	mul.rn.f32 	%f24, %f22, %f23;
	mul.wide.u32 	%rd45, %r10, 12;
	add.s64 	%rd46, %rd3, %rd45;
	add.s64 	%rd47, %rd46, %rd13;
	ld.global.nc.f32 	%f25, [%rd47];
	mul.wide.u32 	%rd48, %r10, 4;
	add.s64 	%rd49, %rd4, %rd48;
	ld.global.nc.f32 	%f26, [%rd49];
	mul.wide.u32 	%rd50, %r10, 306000;
	add.s64 	%rd51, %rd5, %rd50;
	cvt.u32.u16 	%r36, %rs6;
	mul.wide.u32 	%rd52, %r36, 6120;
	add.s64 	%rd53, %rd51, %rd52;
	mul.wide.u32 	%rd54, %r14, 24;
	add.s64 	%rd55, %rd53, %rd54;
	add.s64 	%rd56, %rd55, %rd23;
	ld.global.nc.v2.f32 	{%f27, %f28}, [%rd56];
	mul.rn.f32 	%f29, %f26, %f28;
	mul.rn.f32 	%f30, %f25, %f29;
	mul.rn.f32 	%f31, %f26, %f27;
	neg.f32 	%f32, %f25;
	mul.rn.f32 	%f33, %f31, %f32;
	st.global.v4.f32 	[%rd26], {%f6, %f13, %f21, %f30};
	st.global.v4.f32 	[%rd27], {%f9, %f15, %f24, %f33};
$L__BB109_1:
	ret;

}
	// .globl	loop_broadcast_fusion_29
.visible .entry loop_broadcast_fusion_29(
	.param .u64 loop_broadcast_fusion_29_param_0
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd2, [loop_broadcast_fusion_29_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 9;
	shl.b32 	%r4, %r2, 2;
	or.b32  	%r5, %r3, %r4;
	mul.wide.u32 	%rd4, %r5, 4;
	add.s64 	%rd1, %rd3, %rd4;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd1], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+3538944], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+7077888], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+10616832], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+14155776], {%f1, %f1, %f1, %f1};
	setp.gt.u32 	%p1, %r5, 472319;
	@%p1 bra 	$L__BB110_2;
	st.global.v4.f32 	[%rd1+17694720], {%f1, %f1, %f1, %f1};
$L__BB110_2:
	ret;

}
	// .globl	input_scatter_fusion_230
.visible .entry input_scatter_fusion_230(
	.param .u64 input_scatter_fusion_230_param_0,
	.param .u64 input_scatter_fusion_230_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_230_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_230_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -2139062143;
	shr.u32 	%r6, %r5, 7;
	mul.lo.s32 	%r7, %r6, 255;
	sub.s32 	%r8, %r4, %r7;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	shr.u32 	%r9, %r4, 1;
	mul.hi.u32 	%r10, %r9, 689889649;
	bfe.u32 	%r11, %r10, 10, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, 10527;
	shr.u16 	%rs9, %rs8, 9;
	and.b16  	%rs10, %rs9, 30;
	cvt.u32.u16 	%r12, %rs10;
	mul.wide.u32 	%rd5, %r12, 3264000;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r11, 51000;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r13, %rs6;
	mul.wide.u32 	%rd9, %r13, 1020;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r8, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+3264000];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+3264000], %f3;
	ret;

}
	// .globl	wrapped_transpose_236
.visible .entry wrapped_transpose_236(
	.param .u64 wrapped_transpose_236_param_0,
	.param .u64 wrapped_transpose_236_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<44>;
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<34>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 9;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	setp.lt.u32 	%p1, %r1, 4896000;
	@%p1 bra 	$L__BB112_2;
	bra.uni 	$L__BB112_1;
$L__BB112_2:
	ld.param.u64 	%rd3, [wrapped_transpose_236_param_0];
	ld.param.u64 	%rd4, [wrapped_transpose_236_param_1];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd3;
	mul.hi.u32 	%r6, %r1, -615555835;
	shr.u32 	%r7, %r6, 16;
	or.b32  	%r8, %r1, 3;
	mul.hi.u32 	%r9, %r8, 718635051;
	shr.u32 	%r10, %r9, 8;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r8, 715827883;
	mul.hi.u32 	%r12, %r11, 538976289;
	shr.u32 	%r13, %r12, 5;
	mul.lo.s32 	%r14, %r13, 255;
	sub.s32 	%r15, %r11, %r14;
	mul.lo.s32 	%r16, %r11, 6;
	sub.s32 	%r17, %r8, %r16;
	or.b32  	%r18, %r1, 2;
	mul.hi.u32 	%r19, %r18, 718635051;
	shr.u32 	%r20, %r19, 8;
	cvt.u16.u32 	%rs7, %r20;
	shr.u16 	%rs8, %rs7, 1;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	mul.lo.s16 	%rs11, %rs10, 50;
	sub.s16 	%rs12, %rs7, %rs11;
	mul.hi.u32 	%r21, %r18, 715827883;
	mul.hi.u32 	%r22, %r21, 538976289;
	shr.u32 	%r23, %r22, 5;
	mul.lo.s32 	%r24, %r23, 255;
	sub.s32 	%r25, %r21, %r24;
	mul.lo.s32 	%r26, %r21, 6;
	sub.s32 	%r27, %r18, %r26;
	or.b32  	%r28, %r1, 1;
	mul.hi.u32 	%r29, %r1, 718635051;
	shr.u32 	%r30, %r29, 8;
	cvt.u16.u32 	%rs13, %r30;
	shr.u16 	%rs14, %rs13, 1;
	mul.hi.u16 	%rs15, %rs14, 5243;
	shr.u16 	%rs16, %rs15, 1;
	mul.lo.s16 	%rs17, %rs16, 50;
	sub.s16 	%rs18, %rs13, %rs17;
	mul.hi.u32 	%r31, %r1, 715827883;
	mul.hi.u32 	%r32, %r31, 538976289;
	shr.u32 	%r33, %r32, 5;
	mul.lo.s32 	%r34, %r33, 255;
	sub.s32 	%r35, %r31, %r34;
	mul.hi.u32 	%r36, %r28, 715827883;
	mul.lo.s32 	%r37, %r36, 6;
	sub.s32 	%r38, %r28, %r37;
	mul.lo.s32 	%r39, %r31, 6;
	sub.s32 	%r40, %r1, %r39;
	mul.wide.u32 	%rd5, %r40, 3264000;
	add.s64 	%rd6, %rd2, %rd5;
	mul.wide.u32 	%rd7, %r7, 51000;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r41, %rs18;
	mul.wide.u32 	%rd9, %r41, 1020;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r35, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r1, 4;
	add.s64 	%rd14, %rd1, %rd13;
	mul.wide.u32 	%rd15, %r38, 3264000;
	add.s64 	%rd16, %rd2, %rd15;
	add.s64 	%rd17, %rd16, %rd7;
	add.s64 	%rd18, %rd17, %rd9;
	add.s64 	%rd19, %rd18, %rd11;
	ld.global.nc.f32 	%f2, [%rd19];
	mul.wide.u32 	%rd20, %r27, 3264000;
	add.s64 	%rd21, %rd2, %rd20;
	add.s64 	%rd22, %rd21, %rd7;
	cvt.u32.u16 	%r42, %rs12;
	mul.wide.u32 	%rd23, %r42, 1020;
	add.s64 	%rd24, %rd22, %rd23;
	mul.wide.u32 	%rd25, %r25, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f3, [%rd26];
	mul.wide.u32 	%rd27, %r17, 3264000;
	add.s64 	%rd28, %rd2, %rd27;
	add.s64 	%rd29, %rd28, %rd7;
	cvt.u32.u16 	%r43, %rs6;
	mul.wide.u32 	%rd30, %r43, 1020;
	add.s64 	%rd31, %rd29, %rd30;
	mul.wide.u32 	%rd32, %r15, 4;
	add.s64 	%rd33, %rd31, %rd32;
	ld.global.nc.f32 	%f4, [%rd33];
	st.global.v4.f32 	[%rd14], {%f1, %f2, %f3, %f4};
$L__BB112_1:
	ret;

}
	// .globl	input_scatter_fusion_231
.visible .entry input_scatter_fusion_231(
	.param .u64 input_scatter_fusion_231_param_0,
	.param .u64 input_scatter_fusion_231_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_231_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_231_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -2139062143;
	shr.u32 	%r6, %r5, 7;
	mul.lo.s32 	%r7, %r6, 255;
	sub.s32 	%r8, %r4, %r7;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	shr.u32 	%r9, %r4, 1;
	mul.hi.u32 	%r10, %r9, 689889649;
	bfe.u32 	%r11, %r10, 10, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, 10527;
	shr.u16 	%rs9, %rs8, 9;
	and.b16  	%rs10, %rs9, 30;
	cvt.u32.u16 	%r12, %rs10;
	mul.wide.u32 	%rd5, %r12, 3264000;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r11, 51000;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r13, %rs6;
	mul.wide.u32 	%rd9, %r13, 1020;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r8, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	input_reduce_slice_fusion_13
.visible .entry input_reduce_slice_fusion_13(
	.param .u64 input_reduce_slice_fusion_13_param_0,
	.param .u64 input_reduce_slice_fusion_13_param_1,
	.param .u64 input_reduce_slice_fusion_13_param_2,
	.param .u64 input_reduce_slice_fusion_13_param_3,
	.param .u64 input_reduce_slice_fusion_13_param_4,
	.param .u64 input_reduce_slice_fusion_13_param_5,
	.param .u64 input_reduce_slice_fusion_13_param_6,
	.param .u64 input_reduce_slice_fusion_13_param_7,
	.param .u64 input_reduce_slice_fusion_13_param_8,
	.param .u64 input_reduce_slice_fusion_13_param_9,
	.param .u64 input_reduce_slice_fusion_13_param_10,
	.param .u64 input_reduce_slice_fusion_13_param_11,
	.param .u64 input_reduce_slice_fusion_13_param_12,
	.param .u64 input_reduce_slice_fusion_13_param_13,
	.param .u64 input_reduce_slice_fusion_13_param_14
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<24>;
	.reg .b32 	%r<33>;
	.reg .f32 	%f<84>;
	.reg .b64 	%rd<170>;
	// demoted variable
	.shared .align 4 .b8 shared_cache11[4224];
	ld.param.u64 	%rd47, [input_reduce_slice_fusion_13_param_0];
	ld.param.u64 	%rd48, [input_reduce_slice_fusion_13_param_14];
	cvta.to.global.u64 	%rd1, %rd48;
	ld.param.u64 	%rd49, [input_reduce_slice_fusion_13_param_1];
	ld.param.u64 	%rd50, [input_reduce_slice_fusion_13_param_13];
	cvta.to.global.u64 	%rd2, %rd50;
	ld.param.u64 	%rd51, [input_reduce_slice_fusion_13_param_2];
	ld.param.u64 	%rd52, [input_reduce_slice_fusion_13_param_12];
	cvta.to.global.u64 	%rd53, %rd52;
	ld.param.u64 	%rd54, [input_reduce_slice_fusion_13_param_3];
	ld.param.u64 	%rd55, [input_reduce_slice_fusion_13_param_11];
	cvta.to.global.u64 	%rd3, %rd55;
	ld.param.u64 	%rd56, [input_reduce_slice_fusion_13_param_4];
	ld.param.u64 	%rd57, [input_reduce_slice_fusion_13_param_10];
	cvta.to.global.u64 	%rd4, %rd57;
	ld.param.u64 	%rd58, [input_reduce_slice_fusion_13_param_5];
	ld.param.u64 	%rd59, [input_reduce_slice_fusion_13_param_9];
	cvta.to.global.u64 	%rd60, %rd59;
	ld.param.u64 	%rd61, [input_reduce_slice_fusion_13_param_6];
	ld.param.u64 	%rd62, [input_reduce_slice_fusion_13_param_8];
	cvta.to.global.u64 	%rd63, %rd62;
	ld.param.u64 	%rd64, [input_reduce_slice_fusion_13_param_7];
	cvta.to.global.u64 	%rd5, %rd64;
	cvta.to.global.u64 	%rd6, %rd61;
	cvta.to.global.u64 	%rd65, %rd58;
	cvta.to.global.u64 	%rd66, %rd56;
	cvta.to.global.u64 	%rd7, %rd54;
	cvta.to.global.u64 	%rd67, %rd51;
	cvta.to.global.u64 	%rd8, %rd49;
	cvta.to.global.u64 	%rd9, %rd47;
	mov.u32 	%r12, %tid.x;
	mov.u32 	%r13, %ctaid.x;
	shr.u32 	%r1, %r12, 5;
	and.b32  	%r2, %r12, 31;
	cvt.u16.u32 	%rs1, %r13;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 4;
	mul.lo.s16 	%rs4, %rs3, 24;
	sub.s16 	%rs5, %rs1, %rs4;
	setp.eq.s16 	%p2, %rs5, 23;
	selp.b32 	%r3, 26, 32, %p2;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r4, %rs6;
	or.b32  	%r5, %r2, %r4;
	cvt.u16.u32 	%rs7, %r5;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r14, %rs8;
	cvt.u64.u16 	%rd10, %rs3;
	cvt.u32.u16 	%r15, %rs3;
	mul.wide.u32 	%rd68, %r15, 4;
	add.s64 	%rd11, %rd67, %rd68;
	mul.wide.u16 	%r6, %rs8, 2;
	mul.wide.u16 	%r16, %rs8, 4;
	add.s32 	%r7, %r16, 4;
	add.s32 	%r8, %r16, 5;
	cvt.u64.u16 	%rd12, %rs10;
	shr.u16 	%rs11, %rs10, 1;
	cvt.u32.u16 	%r17, %rs11;
	mul.wide.u32 	%rd69, %r17, 4;
	mul.wide.u32 	%rd70, %r15, 12;
	add.s64 	%rd71, %rd60, %rd70;
	add.s64 	%rd13, %rd71, %rd69;
	add.s64 	%rd14, %rd63, %rd68;
	add.s64 	%rd72, %rd65, %rd70;
	add.s64 	%rd15, %rd72, %rd69;
	add.s64 	%rd16, %rd66, %rd68;
	and.b32  	%r9, %r14, 1;
	shr.u16 	%rs12, %rs8, 1;
	cvt.u64.u16 	%rd17, %rs12;
	add.s32 	%r18, %r14, -1;
	setp.gt.u32 	%p3, %r5, 5;
	and.b32  	%r19, %r18, 1;
	setp.eq.b32 	%p4, %r19, 1;
	not.pred 	%p5, %p4;
	and.pred  	%p1, %p3, %p5;
	shr.u32 	%r20, %r18, 1;
	cvt.u64.u32 	%rd18, %r20;
	cvt.u64.u16 	%rd19, %rs8;
	cvt.u64.u32 	%rd73, %r12;
	shr.u64 	%rd168, %rd73, 5;
	shl.b16 	%rs13, %rs1, 5;
	cvt.u16.u32 	%rs14, %r12;
	and.b16  	%rs15, %rs14, 31;
	or.b16  	%rs16, %rs13, %rs15;
	mul.lo.s16 	%rs17, %rs3, 768;
	sub.s16 	%rs18, %rs16, %rs17;
	mul.hi.u16 	%rs19, %rs18, -21845;
	shr.u16 	%rs20, %rs19, 2;
	mul.lo.s16 	%rs21, %rs20, 6;
	sub.s16 	%rs22, %rs16, %rs21;
	sub.s16 	%rs23, %rs22, %rs17;
	cvt.u32.u16 	%r21, %rs23;
	mul.wide.u32 	%rd21, %r21, 4;
	mul.wide.u32 	%rd74, %r15, 306000;
	mul.lo.s64 	%rd75, %rd168, 6120;
	add.s64 	%rd76, %rd74, %rd75;
	cvt.u32.u16 	%r22, %rs18;
	mul.hi.u32 	%r23, %r22, 715827883;
	mul.wide.u32 	%rd77, %r23, 48;
	add.s64 	%rd78, %rd76, %rd77;
	add.s64 	%rd79, %rd78, 48;
	add.s64 	%rd167, %rd6, %rd79;
	mul.wide.u32 	%rd80, %r15, 1228800;
	mul.lo.s64 	%rd81, %rd168, 24576;
	add.s64 	%rd82, %rd80, %rd81;
	mul.wide.u32 	%rd83, %r23, 192;
	add.s64 	%rd84, %rd82, %rd83;
	add.s64 	%rd85, %rd84, %rd53;
	add.s64 	%rd166, %rd85, 264;
	mul.wide.u32 	%rd86, %r15, 613200;
	mul.lo.s64 	%rd87, %rd168, 12264;
	add.s64 	%rd88, %rd86, %rd87;
	mul.wide.u32 	%rd89, %r23, 96;
	add.s64 	%rd90, %rd88, %rd89;
	add.s64 	%rd91, %rd90, 120;
	add.s64 	%rd165, %rd3, %rd91;
	add.s64 	%rd164, %rd4, %rd91;
	add.s64 	%rd163, %rd7, %rd79;
	add.s64 	%rd162, %rd5, %rd79;
	mov.f32 	%f22, 0f00000000;
	setp.lt.u32 	%p6, %r2, %r3;
	setp.lt.u32 	%p7, %r8, 511;
	setp.lt.u32 	%p8, %r5, 762;
	mul.lo.s64 	%rd101, %rd17, 24;
	mul.lo.s64 	%rd108, %rd18, 24;
	mul.lo.s64 	%rd143, %rd19, 24;
	mov.u32 	%r32, %r1;
	mov.f32 	%f1, %f22;
	bra.uni 	$L__BB114_1;
$L__BB114_11:
	add.rn.f32 	%f1, %f1, %f46;
	add.rn.f32 	%f14, %f5, %f82;
	add.rn.f32 	%f64, %f14, %f83;
	mul.lo.s64 	%rd139, %rd10, 152400;
	add.s64 	%rd140, %rd1, %rd139;
	mul.lo.s64 	%rd141, %rd169, 3048;
	add.s64 	%rd142, %rd140, %rd141;
	add.s64 	%rd144, %rd142, %rd143;
	add.s64 	%rd146, %rd144, %rd103;
	st.global.f32 	[%rd146], %f64;
$L__BB114_2:
	add.s64 	%rd168, %rd168, 32;
	cvt.u32.u64 	%r24, %rd168;
	add.s32 	%r25, %r24, -32;
	add.s64 	%rd167, %rd167, 195840;
	add.s64 	%rd166, %rd166, 786432;
	add.s64 	%rd165, %rd165, 392448;
	add.s64 	%rd164, %rd164, 392448;
	add.s64 	%rd163, %rd163, 195840;
	add.s64 	%rd162, %rd162, 195840;
	add.s32 	%r32, %r32, 32;
	setp.lt.u32 	%p12, %r25, 18;
	@%p12 bra 	$L__BB114_1;
	bra.uni 	$L__BB114_3;
$L__BB114_1:
	@%p6 bra 	$L__BB114_5;
	bra.uni 	$L__BB114_2;
$L__BB114_5:
	ld.global.nc.f32 	%f4, [%rd11];
	add.s64 	%rd42, %rd166, %rd21;
	ld.global.nc.f32 	%f5, [%rd42];
	mov.f32 	%f78, %f22;
	@%p7 bra 	$L__BB114_12;
	bra.uni 	$L__BB114_6;
$L__BB114_12:
	add.s64 	%rd92, %rd164, %rd21;
	ld.global.nc.f32 	%f24, [%rd92];
	add.s64 	%rd93, %rd165, %rd21;
	ld.global.nc.f32 	%f25, [%rd93];
	add.rn.f32 	%f26, %f24, %f25;
	ld.global.nc.f32 	%f27, [%rd13];
	ld.global.nc.f32 	%f28, [%rd14];
	ld.global.nc.f32 	%f29, [%rd42+24];
	mul.rn.f32 	%f30, %f28, %f29;
	mul.rn.f32 	%f31, %f27, %f30;
	add.rn.f32 	%f78, %f26, %f31;
$L__BB114_6:
	mov.u64 	%rd169, %rd168;
	mov.f32 	%f79, %f22;
	@%p8 bra 	$L__BB114_13;
	bra.uni 	$L__BB114_7;
$L__BB114_13:
	cvt.u64.u32 	%rd169, %r32;
	add.s64 	%rd94, %rd167, %rd21;
	ld.global.nc.f32 	%f33, [%rd94];
	add.s64 	%rd95, %rd162, %rd21;
	ld.global.nc.f32 	%f34, [%rd95];
	add.rn.f32 	%f35, %f33, %f34;
	ld.global.nc.f32 	%f36, [%rd15];
	ld.global.nc.f32 	%f37, [%rd16];
	add.s64 	%rd96, %rd163, %rd21;
	ld.global.nc.f32 	%f38, [%rd96];
	mul.rn.f32 	%f39, %f37, %f38;
	mul.rn.f32 	%f40, %f36, %f39;
	add.rn.f32 	%f79, %f35, %f40;
$L__BB114_7:
	add.rn.f32 	%f7, %f5, %f78;
	setp.eq.s32 	%p9, %r9, 0;
	mul.lo.s64 	%rd97, %rd10, 76800;
	mul.lo.s64 	%rd99, %rd169, 1536;
	shl.b64 	%rd103, %rd12, 2;
	mov.f32 	%f80, %f22;
	@%p9 bra 	$L__BB114_14;
	bra.uni 	$L__BB114_8;
$L__BB114_14:
	add.s64 	%rd98, %rd8, %rd97;
	add.s64 	%rd100, %rd98, %rd99;
	add.s64 	%rd102, %rd100, %rd101;
	add.s64 	%rd44, %rd102, %rd103;
	ld.global.nc.f32 	%f80, [%rd44];
$L__BB114_8:
	add.rn.f32 	%f42, %f7, %f79;
	mov.f32 	%f81, %f22;
	@%p1 bra 	$L__BB114_15;
	bra.uni 	$L__BB114_9;
$L__BB114_15:
	add.s64 	%rd105, %rd9, %rd97;
	add.s64 	%rd107, %rd105, %rd99;
	add.s64 	%rd109, %rd107, %rd108;
	add.s64 	%rd45, %rd109, %rd103;
	ld.global.nc.f32 	%f81, [%rd45];
$L__BB114_9:
	mul.rn.f32 	%f9, %f4, %f42;
	add.rn.f32 	%f45, %f80, %f81;
	mov.f32 	%f82, %f22;
	@%p7 bra 	$L__BB114_16;
	bra.uni 	$L__BB114_10;
$L__BB114_16:
	mul.lo.s64 	%rd111, %rd10, 613200;
	add.s64 	%rd112, %rd4, %rd111;
	mul.lo.s64 	%rd113, %rd169, 12264;
	add.s64 	%rd114, %rd112, %rd113;
	mul.wide.u32 	%rd115, %r7, 24;
	add.s64 	%rd116, %rd114, %rd115;
	add.s64 	%rd118, %rd116, %rd103;
	ld.global.nc.f32 	%f47, [%rd118+24];
	add.s64 	%rd119, %rd3, %rd111;
	add.s64 	%rd120, %rd119, %rd113;
	add.s64 	%rd121, %rd120, %rd115;
	add.s64 	%rd122, %rd121, %rd103;
	ld.global.nc.f32 	%f48, [%rd122+24];
	add.rn.f32 	%f49, %f47, %f48;
	ld.global.nc.f32 	%f50, [%rd13];
	ld.global.nc.f32 	%f51, [%rd14];
	ld.global.nc.f32 	%f52, [%rd42+24];
	mul.rn.f32 	%f53, %f51, %f52;
	mul.rn.f32 	%f54, %f50, %f53;
	add.rn.f32 	%f82, %f49, %f54;
$L__BB114_10:
	mul.rn.f32 	%f46, %f9, %f45;
	mov.f32 	%f83, %f22;
	@%p8 bra 	$L__BB114_17;
	bra.uni 	$L__BB114_11;
$L__BB114_17:
	mul.lo.s64 	%rd123, %rd10, 306000;
	add.s64 	%rd124, %rd6, %rd123;
	mul.lo.s64 	%rd125, %rd169, 6120;
	add.s64 	%rd126, %rd124, %rd125;
	mul.wide.u32 	%rd127, %r6, 24;
	add.s64 	%rd128, %rd126, %rd127;
	add.s64 	%rd130, %rd128, %rd103;
	ld.global.nc.f32 	%f56, [%rd130+48];
	add.s64 	%rd131, %rd5, %rd123;
	add.s64 	%rd132, %rd131, %rd125;
	add.s64 	%rd133, %rd132, %rd127;
	add.s64 	%rd134, %rd133, %rd103;
	ld.global.nc.f32 	%f57, [%rd134+48];
	add.rn.f32 	%f58, %f56, %f57;
	ld.global.nc.f32 	%f59, [%rd15];
	ld.global.nc.f32 	%f60, [%rd16];
	add.s64 	%rd135, %rd7, %rd123;
	add.s64 	%rd136, %rd135, %rd125;
	add.s64 	%rd137, %rd136, %rd127;
	add.s64 	%rd138, %rd137, %rd103;
	ld.global.nc.f32 	%f61, [%rd138+48];
	mul.rn.f32 	%f62, %f60, %f61;
	mul.rn.f32 	%f63, %f59, %f62;
	add.rn.f32 	%f83, %f58, %f63;
	bra.uni 	$L__BB114_11;
$L__BB114_3:
	mul.wide.u32 	%rd147, %r2, 132;
	mov.u64 	%rd148, shared_cache11;
	add.s64 	%rd149, %rd148, %rd147;
	mul.wide.u32 	%rd150, %r1, 4;
	add.s64 	%rd151, %rd149, %rd150;
	st.shared.f32 	[%rd151], %f1;
	bar.sync 	0;
	mul.wide.u32 	%rd152, %r1, 132;
	add.s64 	%rd153, %rd148, %rd152;
	mul.wide.u32 	%rd154, %r2, 4;
	add.s64 	%rd155, %rd153, %rd154;
	ld.shared.f32 	%f65, [%rd155];
	shfl.sync.down.b32	%f66, %f65, 16, 31, -1;
	add.rn.f32 	%f67, %f65, %f66;
	shfl.sync.down.b32	%f68, %f67, 8, 31, -1;
	add.rn.f32 	%f69, %f67, %f68;
	shfl.sync.down.b32	%f70, %f69, 4, 31, -1;
	add.rn.f32 	%f71, %f69, %f70;
	shfl.sync.down.b32	%f72, %f71, 2, 31, -1;
	add.rn.f32 	%f73, %f71, %f72;
	shfl.sync.down.b32	%f74, %f73, 1, 31, -1;
	add.rn.f32 	%f3, %f73, %f74;
	st.shared.f32 	[%rd155], %f3;
	setp.lt.u32 	%p13, %r1, %r3;
	setp.eq.s32 	%p14, %r2, 0;
	and.pred  	%p15, %p14, %p13;
	@%p15 bra 	$L__BB114_18;
	bra.uni 	$L__BB114_4;
$L__BB114_18:
	or.b32  	%r26, %r1, %r4;
	mul.hi.u32 	%r28, %r26, -1431655765;
	shr.u32 	%r29, %r28, 2;
	mul.lo.s32 	%r30, %r29, 6;
	sub.s32 	%r31, %r26, %r30;
	mul.lo.s64 	%rd156, %rd10, 3048;
	add.s64 	%rd157, %rd2, %rd156;
	mul.wide.u32 	%rd158, %r29, 24;
	add.s64 	%rd159, %rd157, %rd158;
	mul.wide.u32 	%rd160, %r31, 4;
	add.s64 	%rd161, %rd159, %rd160;
	neg.f32 	%f75, %f3;
	st.global.f32 	[%rd161], %f75;
$L__BB114_4:
	ret;

}
	// .globl	loop_transpose_fusion_105
.visible .entry loop_transpose_fusion_105(
	.param .u64 loop_transpose_fusion_105_param_0,
	.param .u64 loop_transpose_fusion_105_param_1,
	.param .u64 loop_transpose_fusion_105_param_2,
	.param .u64 loop_transpose_fusion_105_param_3,
	.param .u64 loop_transpose_fusion_105_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<25>;
	.reg .b32 	%r<37>;
	.reg .f32 	%f<34>;
	.reg .b64 	%rd<57>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 9;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	setp.lt.u32 	%p1, %r1, 1219200;
	@%p1 bra 	$L__BB115_2;
	bra.uni 	$L__BB115_1;
$L__BB115_2:
	ld.param.u64 	%rd6, [loop_transpose_fusion_105_param_0];
	ld.param.u64 	%rd7, [loop_transpose_fusion_105_param_4];
	cvta.to.global.u64 	%rd1, %rd7;
	ld.param.u64 	%rd8, [loop_transpose_fusion_105_param_1];
	ld.param.u64 	%rd9, [loop_transpose_fusion_105_param_3];
	cvta.to.global.u64 	%rd2, %rd9;
	ld.param.u64 	%rd10, [loop_transpose_fusion_105_param_2];
	cvta.to.global.u64 	%rd3, %rd10;
	cvta.to.global.u64 	%rd4, %rd8;
	cvta.to.global.u64 	%rd5, %rd6;
	or.b32  	%r6, %r1, 3;
	mul.hi.u32 	%r7, %r1, 346302875;
	shr.u32 	%r8, %r7, 15;
	mul.hi.u32 	%r9, %r6, 346302875;
	bfe.u32 	%r10, %r9, 9, 6;
	mul.hi.u32 	%r11, %r6, -2130574327;
	shr.u32 	%r12, %r11, 6;
	cvt.u16.u32 	%rs1, %r12;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.lo.s32 	%r13, %r12, 127;
	sub.s32 	%r14, %r6, %r13;
	or.b32  	%r15, %r1, 2;
	mul.hi.u32 	%r16, %r15, 346302875;
	bfe.u32 	%r17, %r16, 9, 6;
	mul.hi.u32 	%r18, %r15, -2130574327;
	shr.u32 	%r19, %r18, 6;
	cvt.u16.u32 	%rs7, %r19;
	shr.u16 	%rs8, %rs7, 1;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	mul.lo.s16 	%rs11, %rs10, 50;
	sub.s16 	%rs12, %rs7, %rs11;
	mul.lo.s32 	%r20, %r19, 127;
	sub.s32 	%r21, %r15, %r20;
	or.b32  	%r22, %r1, 1;
	bfe.u32 	%r23, %r7, 9, 6;
	mul.hi.u32 	%r24, %r22, -2130574327;
	shr.u32 	%r25, %r24, 6;
	cvt.u16.u32 	%rs13, %r25;
	shr.u16 	%rs14, %rs13, 1;
	mul.hi.u16 	%rs15, %rs14, 5243;
	shr.u16 	%rs16, %rs15, 1;
	mul.lo.s16 	%rs17, %rs16, 50;
	sub.s16 	%rs18, %rs13, %rs17;
	mul.lo.s32 	%r26, %r25, 127;
	sub.s32 	%r27, %r22, %r26;
	mul.hi.u32 	%r28, %r1, -2130574327;
	shr.u32 	%r29, %r28, 6;
	cvt.u16.u32 	%rs19, %r29;
	shr.u16 	%rs20, %rs19, 1;
	mul.hi.u16 	%rs21, %rs20, 5243;
	shr.u16 	%rs22, %rs21, 1;
	mul.lo.s16 	%rs23, %rs22, 50;
	sub.s16 	%rs24, %rs19, %rs23;
	mul.lo.s32 	%r30, %r29, 127;
	sub.s32 	%r31, %r1, %r30;
	shl.b32 	%r32, %r8, 1;
	mul.wide.u32 	%rd11, %r23, 12;
	add.s64 	%rd12, %rd3, %rd11;
	mul.wide.u32 	%rd13, %r8, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	mul.wide.u32 	%rd15, %r23, 4;
	add.s64 	%rd16, %rd4, %rd15;
	ld.global.nc.f32 	%f2, [%rd16];
	mul.wide.u32 	%rd17, %r23, 152400;
	add.s64 	%rd18, %rd5, %rd17;
	cvt.u32.u16 	%r33, %rs24;
	mul.wide.u32 	%rd19, %r33, 3048;
	add.s64 	%rd20, %rd18, %rd19;
	mul.wide.u32 	%rd21, %r31, 24;
	add.s64 	%rd22, %rd20, %rd21;
	mul.wide.u32 	%rd23, %r32, 4;
	add.s64 	%rd24, %rd22, %rd23;
	ld.global.nc.v2.f32 	{%f3, %f4}, [%rd24];
	mul.rn.f32 	%f5, %f2, %f4;
	mul.rn.f32 	%f6, %f1, %f5;
	mul.rn.f32 	%f7, %f2, %f3;
	neg.f32 	%f8, %f1;
	mul.rn.f32 	%f9, %f7, %f8;
	mul.wide.u32 	%rd25, %r1, 4;
	add.s64 	%rd26, %rd2, %rd25;
	add.s64 	%rd27, %rd1, %rd25;
	cvt.u32.u16 	%r34, %rs18;
	mul.wide.u32 	%rd28, %r34, 3048;
	add.s64 	%rd29, %rd18, %rd28;
	mul.wide.u32 	%rd30, %r27, 24;
	add.s64 	%rd31, %rd29, %rd30;
	add.s64 	%rd32, %rd31, %rd23;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd32];
	mul.rn.f32 	%f12, %f2, %f11;
	mul.rn.f32 	%f13, %f1, %f12;
	mul.rn.f32 	%f14, %f2, %f10;
	mul.rn.f32 	%f15, %f14, %f8;
	mul.wide.u32 	%rd33, %r17, 12;
	add.s64 	%rd34, %rd3, %rd33;
	add.s64 	%rd35, %rd34, %rd13;
	ld.global.nc.f32 	%f16, [%rd35];
	mul.wide.u32 	%rd36, %r17, 4;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.nc.f32 	%f17, [%rd37];
	mul.wide.u32 	%rd38, %r17, 152400;
	add.s64 	%rd39, %rd5, %rd38;
	cvt.u32.u16 	%r35, %rs12;
	mul.wide.u32 	%rd40, %r35, 3048;
	add.s64 	%rd41, %rd39, %rd40;
	mul.wide.u32 	%rd42, %r21, 24;
	add.s64 	%rd43, %rd41, %rd42;
	add.s64 	%rd44, %rd43, %rd23;
	ld.global.nc.v2.f32 	{%f18, %f19}, [%rd44];
	mul.rn.f32 	%f20, %f17, %f19;
	mul.rn.f32 	%f21, %f16, %f20;
	mul.rn.f32 	%f22, %f17, %f18;
	neg.f32 	%f23, %f16;
	mul.rn.f32 	%f24, %f22, %f23;
	mul.wide.u32 	%rd45, %r10, 12;
	add.s64 	%rd46, %rd3, %rd45;
	add.s64 	%rd47, %rd46, %rd13;
	ld.global.nc.f32 	%f25, [%rd47];
	mul.wide.u32 	%rd48, %r10, 4;
	add.s64 	%rd49, %rd4, %rd48;
	ld.global.nc.f32 	%f26, [%rd49];
	mul.wide.u32 	%rd50, %r10, 152400;
	add.s64 	%rd51, %rd5, %rd50;
	cvt.u32.u16 	%r36, %rs6;
	mul.wide.u32 	%rd52, %r36, 3048;
	add.s64 	%rd53, %rd51, %rd52;
	mul.wide.u32 	%rd54, %r14, 24;
	add.s64 	%rd55, %rd53, %rd54;
	add.s64 	%rd56, %rd55, %rd23;
	ld.global.nc.v2.f32 	{%f27, %f28}, [%rd56];
	mul.rn.f32 	%f29, %f26, %f28;
	mul.rn.f32 	%f30, %f25, %f29;
	mul.rn.f32 	%f31, %f26, %f27;
	neg.f32 	%f32, %f25;
	mul.rn.f32 	%f33, %f31, %f32;
	st.global.v4.f32 	[%rd26], {%f6, %f13, %f21, %f30};
	st.global.v4.f32 	[%rd27], {%f9, %f15, %f24, %f33};
$L__BB115_1:
	ret;

}
	// .globl	loop_broadcast_fusion_30
.visible .entry loop_broadcast_fusion_30(
	.param .u64 loop_broadcast_fusion_30_param_0
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd2, [loop_broadcast_fusion_30_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 9;
	shl.b32 	%r4, %r2, 2;
	or.b32  	%r5, %r3, %r4;
	mul.wide.u32 	%rd4, %r5, 4;
	add.s64 	%rd1, %rd3, %rd4;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd1], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+3538944], {%f1, %f1, %f1, %f1};
	setp.gt.u32 	%p1, %r5, 668927;
	@%p1 bra 	$L__BB116_2;
	st.global.v4.f32 	[%rd1+7077888], {%f1, %f1, %f1, %f1};
$L__BB116_2:
	ret;

}
	// .globl	input_scatter_fusion_232
.visible .entry input_scatter_fusion_232(
	.param .u64 input_scatter_fusion_232_param_0,
	.param .u64 input_scatter_fusion_232_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_232_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_232_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, 33818641;
	sub.s32 	%r6, %r4, %r5;
	shr.u32 	%r7, %r6, 1;
	add.s32 	%r8, %r7, %r5;
	shr.u32 	%r9, %r8, 6;
	mul.lo.s32 	%r10, %r9, 127;
	sub.s32 	%r11, %r4, %r10;
	cvt.u16.u32 	%rs1, %r9;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	shr.u32 	%r12, %r4, 1;
	mul.hi.u32 	%r13, %r12, 346302875;
	bfe.u32 	%r14, %r13, 8, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, 19011;
	sub.s16 	%rs9, %rs7, %rs8;
	shr.u16 	%rs10, %rs9, 1;
	add.s16 	%rs11, %rs10, %rs8;
	shr.u16 	%rs12, %rs11, 10;
	and.b16  	%rs13, %rs12, 62;
	cvt.u32.u16 	%r15, %rs6;
	mul.wide.u32 	%rd5, %r15, 508;
	cvt.u32.u16 	%r16, %rs13;
	mul.wide.u32 	%rd6, %r16, 1625600;
	add.s64 	%rd7, %rd4, %rd6;
	mul.wide.u32 	%rd8, %r14, 25400;
	add.s64 	%rd9, %rd7, %rd8;
	add.s64 	%rd10, %rd9, %rd5;
	mul.wide.u32 	%rd11, %r11, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+1625600];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+1625600], %f3;
	ret;

}
	// .globl	wrapped_transpose_238
.visible .entry wrapped_transpose_238(
	.param .u64 wrapped_transpose_238_param_0,
	.param .u64 wrapped_transpose_238_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<44>;
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<34>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 9;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	setp.lt.u32 	%p1, %r1, 2438400;
	@%p1 bra 	$L__BB118_2;
	bra.uni 	$L__BB118_1;
$L__BB118_2:
	ld.param.u64 	%rd3, [wrapped_transpose_238_param_0];
	ld.param.u64 	%rd4, [wrapped_transpose_238_param_1];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd3;
	mul.hi.u32 	%r6, %r1, -601069963;
	shr.u32 	%r7, %r6, 15;
	or.b32  	%r8, %r1, 3;
	mul.hi.u32 	%r9, %r8, 721464323;
	shr.u32 	%r10, %r9, 7;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r8, 715827883;
	mul.hi.u32 	%r12, %r11, 541098243;
	shr.u32 	%r13, %r12, 4;
	mul.lo.s32 	%r14, %r13, 127;
	sub.s32 	%r15, %r11, %r14;
	mul.lo.s32 	%r16, %r11, 6;
	sub.s32 	%r17, %r8, %r16;
	or.b32  	%r18, %r1, 2;
	mul.hi.u32 	%r19, %r18, 721464323;
	shr.u32 	%r20, %r19, 7;
	cvt.u16.u32 	%rs7, %r20;
	shr.u16 	%rs8, %rs7, 1;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	mul.lo.s16 	%rs11, %rs10, 50;
	sub.s16 	%rs12, %rs7, %rs11;
	mul.hi.u32 	%r21, %r18, 715827883;
	mul.hi.u32 	%r22, %r21, 541098243;
	shr.u32 	%r23, %r22, 4;
	mul.lo.s32 	%r24, %r23, 127;
	sub.s32 	%r25, %r21, %r24;
	mul.lo.s32 	%r26, %r21, 6;
	sub.s32 	%r27, %r18, %r26;
	or.b32  	%r28, %r1, 1;
	mul.hi.u32 	%r29, %r1, 721464323;
	shr.u32 	%r30, %r29, 7;
	cvt.u16.u32 	%rs13, %r30;
	shr.u16 	%rs14, %rs13, 1;
	mul.hi.u16 	%rs15, %rs14, 5243;
	shr.u16 	%rs16, %rs15, 1;
	mul.lo.s16 	%rs17, %rs16, 50;
	sub.s16 	%rs18, %rs13, %rs17;
	mul.hi.u32 	%r31, %r1, 715827883;
	mul.hi.u32 	%r32, %r31, 541098243;
	shr.u32 	%r33, %r32, 4;
	mul.lo.s32 	%r34, %r33, 127;
	sub.s32 	%r35, %r31, %r34;
	mul.hi.u32 	%r36, %r28, 715827883;
	mul.lo.s32 	%r37, %r36, 6;
	sub.s32 	%r38, %r28, %r37;
	mul.lo.s32 	%r39, %r31, 6;
	sub.s32 	%r40, %r1, %r39;
	mul.wide.u32 	%rd5, %r40, 1625600;
	add.s64 	%rd6, %rd2, %rd5;
	mul.wide.u32 	%rd7, %r7, 25400;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r41, %rs18;
	mul.wide.u32 	%rd9, %r41, 508;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r35, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r1, 4;
	add.s64 	%rd14, %rd1, %rd13;
	mul.wide.u32 	%rd15, %r38, 1625600;
	add.s64 	%rd16, %rd2, %rd15;
	add.s64 	%rd17, %rd16, %rd7;
	add.s64 	%rd18, %rd17, %rd9;
	add.s64 	%rd19, %rd18, %rd11;
	ld.global.nc.f32 	%f2, [%rd19];
	mul.wide.u32 	%rd20, %r27, 1625600;
	add.s64 	%rd21, %rd2, %rd20;
	add.s64 	%rd22, %rd21, %rd7;
	cvt.u32.u16 	%r42, %rs12;
	mul.wide.u32 	%rd23, %r42, 508;
	add.s64 	%rd24, %rd22, %rd23;
	mul.wide.u32 	%rd25, %r25, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f3, [%rd26];
	mul.wide.u32 	%rd27, %r17, 1625600;
	add.s64 	%rd28, %rd2, %rd27;
	add.s64 	%rd29, %rd28, %rd7;
	cvt.u32.u16 	%r43, %rs6;
	mul.wide.u32 	%rd30, %r43, 508;
	add.s64 	%rd31, %rd29, %rd30;
	mul.wide.u32 	%rd32, %r15, 4;
	add.s64 	%rd33, %rd31, %rd32;
	ld.global.nc.f32 	%f4, [%rd33];
	st.global.v4.f32 	[%rd14], {%f1, %f2, %f3, %f4};
$L__BB118_1:
	ret;

}
	// .globl	input_scatter_fusion_233
.visible .entry input_scatter_fusion_233(
	.param .u64 input_scatter_fusion_233_param_0,
	.param .u64 input_scatter_fusion_233_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_233_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_233_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, 33818641;
	sub.s32 	%r6, %r4, %r5;
	shr.u32 	%r7, %r6, 1;
	add.s32 	%r8, %r7, %r5;
	shr.u32 	%r9, %r8, 6;
	mul.lo.s32 	%r10, %r9, 127;
	sub.s32 	%r11, %r4, %r10;
	cvt.u16.u32 	%rs1, %r9;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	shr.u32 	%r12, %r4, 1;
	mul.hi.u32 	%r13, %r12, 346302875;
	bfe.u32 	%r14, %r13, 8, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, 19011;
	sub.s16 	%rs9, %rs7, %rs8;
	shr.u16 	%rs10, %rs9, 1;
	add.s16 	%rs11, %rs10, %rs8;
	shr.u16 	%rs12, %rs11, 10;
	and.b16  	%rs13, %rs12, 62;
	cvt.u32.u16 	%r15, %rs6;
	mul.wide.u32 	%rd5, %r15, 508;
	cvt.u32.u16 	%r16, %rs13;
	mul.wide.u32 	%rd6, %r16, 1625600;
	add.s64 	%rd7, %rd4, %rd6;
	mul.wide.u32 	%rd8, %r14, 25400;
	add.s64 	%rd9, %rd7, %rd8;
	add.s64 	%rd10, %rd9, %rd5;
	mul.wide.u32 	%rd11, %r11, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	loop_slice_fusion_74
.visible .entry loop_slice_fusion_74(
	.param .u64 loop_slice_fusion_74_param_0,
	.param .u64 loop_slice_fusion_74_param_1,
	.param .u64 loop_slice_fusion_74_param_2,
	.param .u64 loop_slice_fusion_74_param_3,
	.param .u64 loop_slice_fusion_74_param_4,
	.param .u64 loop_slice_fusion_74_param_5,
	.param .u64 loop_slice_fusion_74_param_6,
	.param .u64 loop_slice_fusion_74_param_7,
	.param .u64 loop_slice_fusion_74_param_8,
	.param .u64 loop_slice_fusion_74_param_9,
	.param .u64 loop_slice_fusion_74_param_10,
	.param .u64 loop_slice_fusion_74_param_11,
	.param .u64 loop_slice_fusion_74_param_12,
	.param .u64 loop_slice_fusion_74_param_13,
	.param .u64 loop_slice_fusion_74_param_14,
	.param .u64 loop_slice_fusion_74_param_15
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<54>;
	.reg .f32 	%f<116>;
	.reg .b64 	%rd<179>;

	ld.param.u64 	%rd1, [loop_slice_fusion_74_param_0];
	ld.param.u64 	%rd2, [loop_slice_fusion_74_param_15];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_slice_fusion_74_param_1];
	ld.param.u64 	%rd5, [loop_slice_fusion_74_param_14];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_slice_fusion_74_param_2];
	ld.param.u64 	%rd8, [loop_slice_fusion_74_param_13];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_slice_fusion_74_param_3];
	ld.param.u64 	%rd11, [loop_slice_fusion_74_param_12];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_slice_fusion_74_param_4];
	ld.param.u64 	%rd14, [loop_slice_fusion_74_param_11];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_slice_fusion_74_param_5];
	ld.param.u64 	%rd17, [loop_slice_fusion_74_param_10];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_slice_fusion_74_param_6];
	ld.param.u64 	%rd20, [loop_slice_fusion_74_param_9];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_slice_fusion_74_param_7];
	ld.param.u64 	%rd23, [loop_slice_fusion_74_param_8];
	cvta.to.global.u64 	%rd24, %rd23;
	cvta.to.global.u64 	%rd25, %rd22;
	cvta.to.global.u64 	%rd26, %rd19;
	cvta.to.global.u64 	%rd27, %rd16;
	cvta.to.global.u64 	%rd28, %rd13;
	cvta.to.global.u64 	%rd29, %rd10;
	cvta.to.global.u64 	%rd30, %rd7;
	cvta.to.global.u64 	%rd31, %rd4;
	cvta.to.global.u64 	%rd32, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 9;
	shl.b32 	%r4, %r2, 2;
	or.b32  	%r5, %r3, %r4;
	mul.hi.u32 	%r6, %r5, 715827883;
	mul.lo.s32 	%r7, %r6, 6;
	sub.s32 	%r8, %r5, %r7;
	shr.u32 	%r9, %r6, 6;
	cvt.u16.u32 	%rs1, %r9;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r10, %r5, 458129845;
	bfe.u32 	%r11, %r10, 11, 6;
	or.b32  	%r12, %r5, 1;
	mul.hi.u32 	%r13, %r12, 715827883;
	mul.lo.s32 	%r14, %r13, 6;
	sub.s32 	%r15, %r12, %r14;
	or.b32  	%r16, %r5, 2;
	mul.hi.u32 	%r17, %r16, 715827883;
	mul.lo.s32 	%r18, %r17, 6;
	sub.s32 	%r19, %r16, %r18;
	or.b32  	%r20, %r5, 3;
	mul.hi.u32 	%r21, %r20, 715827883;
	mul.lo.s32 	%r22, %r21, 6;
	sub.s32 	%r23, %r20, %r22;
	shl.b32 	%r24, %r6, 1;
	and.b32  	%r25, %r24, 126;
	shl.b32 	%r26, %r25, 1;
	or.b32  	%r27, %r26, 1;
	shl.b32 	%r28, %r27, 1;
	shl.b16 	%rs7, %rs6, 10;
	cvt.u32.u16 	%r29, %rs7;
	shl.b32 	%r30, %r27, 2;
	or.b32  	%r31, %r30, %r29;
	or.b32  	%r32, %r31, 2;
	mul.wide.u32 	%rd33, %r32, 24;
	mul.wide.u32 	%rd34, %r11, 1228800;
	add.s64 	%rd35, %rd26, %rd34;
	add.s64 	%rd36, %rd35, %rd33;
	mul.wide.u32 	%rd37, %r8, 4;
	add.s64 	%rd38, %rd36, %rd37;
	ld.global.nc.f32 	%f1, [%rd38+24];
	cvt.u32.u16 	%r33, %rs6;
	mul.wide.u32 	%rd39, %r33, 12264;
	mul.wide.u32 	%rd40, %r11, 613200;
	add.s64 	%rd41, %rd21, %rd40;
	add.s64 	%rd42, %rd41, %rd39;
	mul.wide.u32 	%rd43, %r28, 24;
	add.s64 	%rd44, %rd42, %rd43;
	add.s64 	%rd45, %rd44, %rd37;
	ld.global.nc.f32 	%f2, [%rd45+24];
	add.s64 	%rd46, %rd18, %rd40;
	add.s64 	%rd47, %rd46, %rd39;
	add.s64 	%rd48, %rd47, %rd43;
	add.s64 	%rd49, %rd48, %rd37;
	ld.global.nc.f32 	%f3, [%rd49+24];
	add.rn.f32 	%f4, %f2, %f3;
	shr.u32 	%r34, %r8, 1;
	mul.wide.u32 	%rd50, %r34, 4;
	mul.wide.u32 	%rd51, %r11, 12;
	add.s64 	%rd52, %rd24, %rd51;
	add.s64 	%rd53, %rd52, %rd50;
	ld.global.nc.f32 	%f5, [%rd53];
	mul.wide.u32 	%rd54, %r11, 4;
	add.s64 	%rd55, %rd25, %rd54;
	ld.global.nc.f32 	%f6, [%rd55];
	cvt.u64.u16 	%rd56, %rs7;
	cvt.u64.u32 	%rd57, %r30;
	or.b64  	%rd58, %rd57, %rd56;
	mul.lo.s64 	%rd59, %rd58, 24;
	add.s64 	%rd60, %rd35, %rd59;
	add.s64 	%rd61, %rd60, %rd37;
	ld.global.nc.f32 	%f7, [%rd61+96];
	mul.rn.f32 	%f8, %f6, %f7;
	mul.rn.f32 	%f9, %f5, %f8;
	add.rn.f32 	%f10, %f4, %f9;
	add.rn.f32 	%f11, %f1, %f10;
	mul.wide.u32 	%rd62, %r33, 6120;
	mul.wide.u32 	%rd63, %r11, 306000;
	add.s64 	%rd64, %rd28, %rd63;
	add.s64 	%rd65, %rd64, %rd62;
	mul.wide.u32 	%rd66, %r26, 24;
	add.s64 	%rd67, %rd65, %rd66;
	add.s64 	%rd68, %rd67, %rd37;
	ld.global.nc.f32 	%f12, [%rd68+24];
	add.s64 	%rd69, %rd27, %rd63;
	add.s64 	%rd70, %rd69, %rd62;
	add.s64 	%rd71, %rd70, %rd66;
	add.s64 	%rd72, %rd71, %rd37;
	ld.global.nc.f32 	%f13, [%rd72+24];
	add.rn.f32 	%f14, %f12, %f13;
	add.s64 	%rd73, %rd9, %rd51;
	add.s64 	%rd74, %rd73, %rd50;
	ld.global.nc.f32 	%f15, [%rd74];
	add.s64 	%rd75, %rd29, %rd54;
	ld.global.nc.f32 	%f16, [%rd75];
	add.s64 	%rd76, %rd30, %rd63;
	add.s64 	%rd77, %rd76, %rd62;
	add.s64 	%rd78, %rd77, %rd66;
	add.s64 	%rd79, %rd78, %rd37;
	ld.global.nc.f32 	%f17, [%rd79+24];
	mul.rn.f32 	%f18, %f16, %f17;
	mul.rn.f32 	%f19, %f15, %f18;
	add.rn.f32 	%f20, %f14, %f19;
	add.rn.f32 	%f21, %f11, %f20;
	mul.wide.u32 	%rd80, %r33, 3048;
	mul.wide.u32 	%rd81, %r11, 152400;
	add.s64 	%rd82, %rd32, %rd81;
	add.s64 	%rd83, %rd82, %rd80;
	mul.wide.u32 	%rd84, %r25, 24;
	add.s64 	%rd85, %rd83, %rd84;
	add.s64 	%rd86, %rd85, %rd37;
	ld.global.nc.f32 	%f22, [%rd86];
	add.s64 	%rd87, %rd31, %rd81;
	add.s64 	%rd88, %rd87, %rd80;
	add.s64 	%rd89, %rd88, %rd84;
	add.s64 	%rd90, %rd89, %rd37;
	ld.global.nc.f32 	%f23, [%rd90];
	add.rn.f32 	%f24, %f22, %f23;
	add.s64 	%rd91, %rd6, %rd51;
	add.s64 	%rd92, %rd91, %rd50;
	ld.global.nc.f32 	%f25, [%rd92];
	add.s64 	%rd93, %rd12, %rd54;
	ld.global.nc.f32 	%f26, [%rd93];
	add.s64 	%rd94, %rd15, %rd81;
	add.s64 	%rd95, %rd94, %rd80;
	add.s64 	%rd96, %rd95, %rd84;
	add.s64 	%rd97, %rd96, %rd37;
	ld.global.nc.f32 	%f27, [%rd97];
	mul.rn.f32 	%f28, %f26, %f27;
	mul.rn.f32 	%f29, %f25, %f28;
	add.rn.f32 	%f30, %f24, %f29;
	add.rn.f32 	%f31, %f21, %f30;
	mul.wide.u32 	%rd98, %r5, 4;
	add.s64 	%rd99, %rd3, %rd98;
	mul.wide.u32 	%rd100, %r15, 4;
	add.s64 	%rd101, %rd36, %rd100;
	ld.global.nc.f32 	%f32, [%rd101+24];
	add.s64 	%rd102, %rd44, %rd100;
	ld.global.nc.f32 	%f33, [%rd102+24];
	add.s64 	%rd103, %rd48, %rd100;
	ld.global.nc.f32 	%f34, [%rd103+24];
	add.rn.f32 	%f35, %f33, %f34;
	shr.u32 	%r35, %r15, 1;
	mul.wide.u32 	%rd104, %r35, 4;
	add.s64 	%rd105, %rd52, %rd104;
	ld.global.nc.f32 	%f36, [%rd105];
	add.s64 	%rd106, %rd60, %rd100;
	ld.global.nc.f32 	%f37, [%rd106+96];
	mul.rn.f32 	%f38, %f6, %f37;
	mul.rn.f32 	%f39, %f36, %f38;
	add.rn.f32 	%f40, %f35, %f39;
	add.rn.f32 	%f41, %f32, %f40;
	add.s64 	%rd107, %rd67, %rd100;
	ld.global.nc.f32 	%f42, [%rd107+24];
	add.s64 	%rd108, %rd71, %rd100;
	ld.global.nc.f32 	%f43, [%rd108+24];
	add.rn.f32 	%f44, %f42, %f43;
	add.s64 	%rd109, %rd73, %rd104;
	ld.global.nc.f32 	%f45, [%rd109];
	add.s64 	%rd110, %rd78, %rd100;
	ld.global.nc.f32 	%f46, [%rd110+24];
	mul.rn.f32 	%f47, %f16, %f46;
	mul.rn.f32 	%f48, %f45, %f47;
	add.rn.f32 	%f49, %f44, %f48;
	add.rn.f32 	%f50, %f41, %f49;
	add.s64 	%rd111, %rd85, %rd100;
	ld.global.nc.f32 	%f51, [%rd111];
	add.s64 	%rd112, %rd89, %rd100;
	ld.global.nc.f32 	%f52, [%rd112];
	add.rn.f32 	%f53, %f51, %f52;
	add.s64 	%rd113, %rd91, %rd104;
	ld.global.nc.f32 	%f54, [%rd113];
	add.s64 	%rd114, %rd96, %rd100;
	ld.global.nc.f32 	%f55, [%rd114];
	mul.rn.f32 	%f56, %f26, %f55;
	mul.rn.f32 	%f57, %f54, %f56;
	add.rn.f32 	%f58, %f53, %f57;
	add.rn.f32 	%f59, %f50, %f58;
	shl.b32 	%r36, %r17, 1;
	and.b32  	%r37, %r36, 126;
	shl.b32 	%r38, %r37, 1;
	or.b32  	%r39, %r38, 1;
	shl.b32 	%r40, %r39, 1;
	shl.b32 	%r41, %r39, 2;
	or.b32  	%r42, %r41, %r29;
	or.b32  	%r43, %r42, 2;
	mul.wide.u32 	%rd115, %r43, 24;
	add.s64 	%rd116, %rd35, %rd115;
	mul.wide.u32 	%rd117, %r19, 4;
	add.s64 	%rd118, %rd116, %rd117;
	ld.global.nc.f32 	%f60, [%rd118+24];
	mul.wide.u32 	%rd119, %r40, 24;
	add.s64 	%rd120, %rd42, %rd119;
	add.s64 	%rd121, %rd120, %rd117;
	ld.global.nc.f32 	%f61, [%rd121+24];
	add.s64 	%rd122, %rd47, %rd119;
	add.s64 	%rd123, %rd122, %rd117;
	ld.global.nc.f32 	%f62, [%rd123+24];
	add.rn.f32 	%f63, %f61, %f62;
	shr.u32 	%r44, %r19, 1;
	mul.wide.u32 	%rd124, %r44, 4;
	add.s64 	%rd125, %rd52, %rd124;
	ld.global.nc.f32 	%f64, [%rd125];
	cvt.u64.u32 	%rd126, %r41;
	or.b64  	%rd127, %rd126, %rd56;
	mul.lo.s64 	%rd128, %rd127, 24;
	add.s64 	%rd129, %rd35, %rd128;
	add.s64 	%rd130, %rd129, %rd117;
	ld.global.nc.f32 	%f65, [%rd130+96];
	mul.rn.f32 	%f66, %f6, %f65;
	mul.rn.f32 	%f67, %f64, %f66;
	add.rn.f32 	%f68, %f63, %f67;
	add.rn.f32 	%f69, %f60, %f68;
	mul.wide.u32 	%rd131, %r38, 24;
	add.s64 	%rd132, %rd65, %rd131;
	add.s64 	%rd133, %rd132, %rd117;
	ld.global.nc.f32 	%f70, [%rd133+24];
	add.s64 	%rd134, %rd70, %rd131;
	add.s64 	%rd135, %rd134, %rd117;
	ld.global.nc.f32 	%f71, [%rd135+24];
	add.rn.f32 	%f72, %f70, %f71;
	add.s64 	%rd136, %rd73, %rd124;
	ld.global.nc.f32 	%f73, [%rd136];
	add.s64 	%rd137, %rd77, %rd131;
	add.s64 	%rd138, %rd137, %rd117;
	ld.global.nc.f32 	%f74, [%rd138+24];
	mul.rn.f32 	%f75, %f16, %f74;
	mul.rn.f32 	%f76, %f73, %f75;
	add.rn.f32 	%f77, %f72, %f76;
	add.rn.f32 	%f78, %f69, %f77;
	mul.wide.u32 	%rd139, %r37, 24;
	add.s64 	%rd140, %rd83, %rd139;
	add.s64 	%rd141, %rd140, %rd117;
	ld.global.nc.f32 	%f79, [%rd141];
	add.s64 	%rd142, %rd88, %rd139;
	add.s64 	%rd143, %rd142, %rd117;
	ld.global.nc.f32 	%f80, [%rd143];
	add.rn.f32 	%f81, %f79, %f80;
	add.s64 	%rd144, %rd91, %rd124;
	ld.global.nc.f32 	%f82, [%rd144];
	add.s64 	%rd145, %rd95, %rd139;
	add.s64 	%rd146, %rd145, %rd117;
	ld.global.nc.f32 	%f83, [%rd146];
	mul.rn.f32 	%f84, %f26, %f83;
	mul.rn.f32 	%f85, %f82, %f84;
	add.rn.f32 	%f86, %f81, %f85;
	add.rn.f32 	%f87, %f78, %f86;
	shl.b32 	%r45, %r21, 1;
	and.b32  	%r46, %r45, 126;
	shl.b32 	%r47, %r46, 1;
	or.b32  	%r48, %r47, 1;
	shl.b32 	%r49, %r48, 1;
	shl.b32 	%r50, %r48, 2;
	or.b32  	%r51, %r50, %r29;
	or.b32  	%r52, %r51, 2;
	mul.wide.u32 	%rd147, %r52, 24;
	add.s64 	%rd148, %rd35, %rd147;
	mul.wide.u32 	%rd149, %r23, 4;
	add.s64 	%rd150, %rd148, %rd149;
	ld.global.nc.f32 	%f88, [%rd150+24];
	mul.wide.u32 	%rd151, %r49, 24;
	add.s64 	%rd152, %rd42, %rd151;
	add.s64 	%rd153, %rd152, %rd149;
	ld.global.nc.f32 	%f89, [%rd153+24];
	add.s64 	%rd154, %rd47, %rd151;
	add.s64 	%rd155, %rd154, %rd149;
	ld.global.nc.f32 	%f90, [%rd155+24];
	add.rn.f32 	%f91, %f89, %f90;
	shr.u32 	%r53, %r23, 1;
	mul.wide.u32 	%rd156, %r53, 4;
	add.s64 	%rd157, %rd52, %rd156;
	ld.global.nc.f32 	%f92, [%rd157];
	cvt.u64.u32 	%rd158, %r50;
	or.b64  	%rd159, %rd158, %rd56;
	mul.lo.s64 	%rd160, %rd159, 24;
	add.s64 	%rd161, %rd35, %rd160;
	add.s64 	%rd162, %rd161, %rd149;
	ld.global.nc.f32 	%f93, [%rd162+96];
	mul.rn.f32 	%f94, %f6, %f93;
	mul.rn.f32 	%f95, %f92, %f94;
	add.rn.f32 	%f96, %f91, %f95;
	add.rn.f32 	%f97, %f88, %f96;
	mul.wide.u32 	%rd163, %r47, 24;
	add.s64 	%rd164, %rd65, %rd163;
	add.s64 	%rd165, %rd164, %rd149;
	ld.global.nc.f32 	%f98, [%rd165+24];
	add.s64 	%rd166, %rd70, %rd163;
	add.s64 	%rd167, %rd166, %rd149;
	ld.global.nc.f32 	%f99, [%rd167+24];
	add.rn.f32 	%f100, %f98, %f99;
	add.s64 	%rd168, %rd73, %rd156;
	ld.global.nc.f32 	%f101, [%rd168];
	add.s64 	%rd169, %rd77, %rd163;
	add.s64 	%rd170, %rd169, %rd149;
	ld.global.nc.f32 	%f102, [%rd170+24];
	mul.rn.f32 	%f103, %f16, %f102;
	mul.rn.f32 	%f104, %f101, %f103;
	add.rn.f32 	%f105, %f100, %f104;
	add.rn.f32 	%f106, %f97, %f105;
	mul.wide.u32 	%rd171, %r46, 24;
	add.s64 	%rd172, %rd83, %rd171;
	add.s64 	%rd173, %rd172, %rd149;
	ld.global.nc.f32 	%f107, [%rd173];
	add.s64 	%rd174, %rd88, %rd171;
	add.s64 	%rd175, %rd174, %rd149;
	ld.global.nc.f32 	%f108, [%rd175];
	add.rn.f32 	%f109, %f107, %f108;
	add.s64 	%rd176, %rd91, %rd156;
	ld.global.nc.f32 	%f110, [%rd176];
	add.s64 	%rd177, %rd95, %rd171;
	add.s64 	%rd178, %rd177, %rd149;
	ld.global.nc.f32 	%f111, [%rd178];
	mul.rn.f32 	%f112, %f26, %f111;
	mul.rn.f32 	%f113, %f110, %f112;
	add.rn.f32 	%f114, %f109, %f113;
	add.rn.f32 	%f115, %f106, %f114;
	st.global.v4.f32 	[%rd99], {%f31, %f59, %f87, %f115};
	ret;

}
	// .globl	loop_transpose_fusion_106
.visible .entry loop_transpose_fusion_106(
	.param .u64 loop_transpose_fusion_106_param_0,
	.param .u64 loop_transpose_fusion_106_param_1,
	.param .u64 loop_transpose_fusion_106_param_2,
	.param .u64 loop_transpose_fusion_106_param_3,
	.param .u64 loop_transpose_fusion_106_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<25>;
	.reg .b32 	%r<37>;
	.reg .f32 	%f<34>;
	.reg .b64 	%rd<57>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 9;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	setp.lt.u32 	%p1, %r1, 604800;
	@%p1 bra 	$L__BB121_2;
	bra.uni 	$L__BB121_1;
$L__BB121_2:
	ld.param.u64 	%rd6, [loop_transpose_fusion_106_param_0];
	ld.param.u64 	%rd7, [loop_transpose_fusion_106_param_4];
	cvta.to.global.u64 	%rd1, %rd7;
	ld.param.u64 	%rd8, [loop_transpose_fusion_106_param_1];
	ld.param.u64 	%rd9, [loop_transpose_fusion_106_param_3];
	cvta.to.global.u64 	%rd2, %rd9;
	ld.param.u64 	%rd10, [loop_transpose_fusion_106_param_2];
	cvta.to.global.u64 	%rd3, %rd10;
	cvta.to.global.u64 	%rd4, %rd8;
	cvta.to.global.u64 	%rd5, %rd6;
	or.b32  	%r6, %r1, 3;
	mul.hi.u32 	%r7, %r1, 698102621;
	shr.u32 	%r8, %r7, 15;
	mul.hi.u32 	%r9, %r6, 698102621;
	bfe.u32 	%r10, %r9, 9, 6;
	mul.hi.u32 	%r11, %r6, -2113396605;
	shr.u32 	%r12, %r11, 5;
	cvt.u16.u32 	%rs1, %r12;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.lo.s32 	%r13, %r12, 63;
	sub.s32 	%r14, %r6, %r13;
	or.b32  	%r15, %r1, 2;
	mul.hi.u32 	%r16, %r15, 698102621;
	bfe.u32 	%r17, %r16, 9, 6;
	mul.hi.u32 	%r18, %r15, -2113396605;
	shr.u32 	%r19, %r18, 5;
	cvt.u16.u32 	%rs7, %r19;
	shr.u16 	%rs8, %rs7, 1;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	mul.lo.s16 	%rs11, %rs10, 50;
	sub.s16 	%rs12, %rs7, %rs11;
	mul.lo.s32 	%r20, %r19, 63;
	sub.s32 	%r21, %r15, %r20;
	or.b32  	%r22, %r1, 1;
	bfe.u32 	%r23, %r7, 9, 6;
	mul.hi.u32 	%r24, %r22, -2113396605;
	shr.u32 	%r25, %r24, 5;
	cvt.u16.u32 	%rs13, %r25;
	shr.u16 	%rs14, %rs13, 1;
	mul.hi.u16 	%rs15, %rs14, 5243;
	shr.u16 	%rs16, %rs15, 1;
	mul.lo.s16 	%rs17, %rs16, 50;
	sub.s16 	%rs18, %rs13, %rs17;
	mul.lo.s32 	%r26, %r25, 63;
	sub.s32 	%r27, %r22, %r26;
	mul.hi.u32 	%r28, %r1, -2113396605;
	shr.u32 	%r29, %r28, 5;
	cvt.u16.u32 	%rs19, %r29;
	shr.u16 	%rs20, %rs19, 1;
	mul.hi.u16 	%rs21, %rs20, 5243;
	shr.u16 	%rs22, %rs21, 1;
	mul.lo.s16 	%rs23, %rs22, 50;
	sub.s16 	%rs24, %rs19, %rs23;
	mul.lo.s32 	%r30, %r29, 63;
	sub.s32 	%r31, %r1, %r30;
	shl.b32 	%r32, %r8, 1;
	mul.wide.u32 	%rd11, %r23, 12;
	add.s64 	%rd12, %rd3, %rd11;
	mul.wide.u32 	%rd13, %r8, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	mul.wide.u32 	%rd15, %r23, 4;
	add.s64 	%rd16, %rd4, %rd15;
	ld.global.nc.f32 	%f2, [%rd16];
	mul.wide.u32 	%rd17, %r23, 76800;
	add.s64 	%rd18, %rd5, %rd17;
	cvt.u32.u16 	%r33, %rs24;
	mul.wide.u32 	%rd19, %r33, 1536;
	add.s64 	%rd20, %rd18, %rd19;
	mul.wide.u32 	%rd21, %r31, 24;
	add.s64 	%rd22, %rd20, %rd21;
	mul.wide.u32 	%rd23, %r32, 4;
	add.s64 	%rd24, %rd22, %rd23;
	ld.global.nc.v2.f32 	{%f3, %f4}, [%rd24+24];
	mul.rn.f32 	%f5, %f2, %f4;
	mul.rn.f32 	%f6, %f1, %f5;
	mul.rn.f32 	%f7, %f2, %f3;
	neg.f32 	%f8, %f1;
	mul.rn.f32 	%f9, %f7, %f8;
	mul.wide.u32 	%rd25, %r1, 4;
	add.s64 	%rd26, %rd2, %rd25;
	add.s64 	%rd27, %rd1, %rd25;
	cvt.u32.u16 	%r34, %rs18;
	mul.wide.u32 	%rd28, %r34, 1536;
	add.s64 	%rd29, %rd18, %rd28;
	mul.wide.u32 	%rd30, %r27, 24;
	add.s64 	%rd31, %rd29, %rd30;
	add.s64 	%rd32, %rd31, %rd23;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd32+24];
	mul.rn.f32 	%f12, %f2, %f11;
	mul.rn.f32 	%f13, %f1, %f12;
	mul.rn.f32 	%f14, %f2, %f10;
	mul.rn.f32 	%f15, %f14, %f8;
	mul.wide.u32 	%rd33, %r17, 12;
	add.s64 	%rd34, %rd3, %rd33;
	add.s64 	%rd35, %rd34, %rd13;
	ld.global.nc.f32 	%f16, [%rd35];
	mul.wide.u32 	%rd36, %r17, 4;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.nc.f32 	%f17, [%rd37];
	mul.wide.u32 	%rd38, %r17, 76800;
	add.s64 	%rd39, %rd5, %rd38;
	cvt.u32.u16 	%r35, %rs12;
	mul.wide.u32 	%rd40, %r35, 1536;
	add.s64 	%rd41, %rd39, %rd40;
	mul.wide.u32 	%rd42, %r21, 24;
	add.s64 	%rd43, %rd41, %rd42;
	add.s64 	%rd44, %rd43, %rd23;
	ld.global.nc.v2.f32 	{%f18, %f19}, [%rd44+24];
	mul.rn.f32 	%f20, %f17, %f19;
	mul.rn.f32 	%f21, %f16, %f20;
	mul.rn.f32 	%f22, %f17, %f18;
	neg.f32 	%f23, %f16;
	mul.rn.f32 	%f24, %f22, %f23;
	mul.wide.u32 	%rd45, %r10, 12;
	add.s64 	%rd46, %rd3, %rd45;
	add.s64 	%rd47, %rd46, %rd13;
	ld.global.nc.f32 	%f25, [%rd47];
	mul.wide.u32 	%rd48, %r10, 4;
	add.s64 	%rd49, %rd4, %rd48;
	ld.global.nc.f32 	%f26, [%rd49];
	mul.wide.u32 	%rd50, %r10, 76800;
	add.s64 	%rd51, %rd5, %rd50;
	cvt.u32.u16 	%r36, %rs6;
	mul.wide.u32 	%rd52, %r36, 1536;
	add.s64 	%rd53, %rd51, %rd52;
	mul.wide.u32 	%rd54, %r14, 24;
	add.s64 	%rd55, %rd53, %rd54;
	add.s64 	%rd56, %rd55, %rd23;
	ld.global.nc.v2.f32 	{%f27, %f28}, [%rd56+24];
	mul.rn.f32 	%f29, %f26, %f28;
	mul.rn.f32 	%f30, %f25, %f29;
	mul.rn.f32 	%f31, %f26, %f27;
	neg.f32 	%f32, %f25;
	mul.rn.f32 	%f33, %f31, %f32;
	st.global.v4.f32 	[%rd26], {%f6, %f13, %f21, %f30};
	st.global.v4.f32 	[%rd27], {%f9, %f15, %f24, %f33};
$L__BB121_1:
	ret;

}
	// .globl	loop_broadcast_fusion_31
.visible .entry loop_broadcast_fusion_31(
	.param .u64 loop_broadcast_fusion_31_param_0
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<5>;

	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 10;
	shl.b32 	%r4, %r2, 2;
	or.b32  	%r5, %r3, %r4;
	setp.lt.u32 	%p1, %r5, 1209600;
	@%p1 bra 	$L__BB122_2;
	bra.uni 	$L__BB122_1;
$L__BB122_2:
	ld.param.u64 	%rd2, [loop_broadcast_fusion_31_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.u32 	%rd4, %r5, 4;
	add.s64 	%rd1, %rd3, %rd4;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd1], {%f1, %f1, %f1, %f1};
$L__BB122_1:
	ret;

}
	// .globl	input_scatter_fusion_234
.visible .entry input_scatter_fusion_234(
	.param .u64 input_scatter_fusion_234_param_0,
	.param .u64 input_scatter_fusion_234_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_234_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_234_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, 68174085;
	sub.s32 	%r6, %r4, %r5;
	shr.u32 	%r7, %r6, 1;
	add.s32 	%r8, %r7, %r5;
	shr.u32 	%r9, %r8, 5;
	mul.lo.s32 	%r10, %r9, 63;
	sub.s32 	%r11, %r4, %r10;
	cvt.u16.u32 	%rs1, %r9;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	shr.u32 	%r12, %r4, 1;
	mul.hi.u32 	%r13, %r12, 698102621;
	bfe.u32 	%r14, %r13, 8, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, -22927;
	shr.u16 	%rs9, %rs8, 9;
	and.b16  	%rs10, %rs9, 126;
	cvt.u32.u16 	%r15, %rs6;
	mul.wide.u32 	%rd5, %r15, 252;
	cvt.u32.u16 	%r16, %rs10;
	mul.wide.u32 	%rd6, %r16, 806400;
	add.s64 	%rd7, %rd4, %rd6;
	mul.wide.u32 	%rd8, %r14, 12600;
	add.s64 	%rd9, %rd7, %rd8;
	add.s64 	%rd10, %rd9, %rd5;
	mul.wide.u32 	%rd11, %r11, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+806400];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+806400], %f3;
	ret;

}
	// .globl	wrapped_transpose_240
.visible .entry wrapped_transpose_240(
	.param .u64 wrapped_transpose_240_param_0,
	.param .u64 wrapped_transpose_240_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<44>;
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<34>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 9;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	setp.lt.u32 	%p1, %r1, 1209600;
	@%p1 bra 	$L__BB124_2;
	bra.uni 	$L__BB124_1;
$L__BB124_2:
	ld.param.u64 	%rd3, [wrapped_transpose_240_param_0];
	ld.param.u64 	%rd4, [wrapped_transpose_240_param_1];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd3;
	mul.hi.u32 	%r6, %r1, 1861606989;
	shr.u32 	%r7, %r6, 13;
	or.b32  	%r8, %r1, 3;
	mul.hi.u32 	%r9, %r8, -1386206375;
	shr.u32 	%r10, %r9, 8;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r8, 715827883;
	mul.hi.u32 	%r12, %r11, 545392673;
	shr.u32 	%r13, %r12, 3;
	mul.lo.s32 	%r14, %r13, 63;
	sub.s32 	%r15, %r11, %r14;
	mul.lo.s32 	%r16, %r11, 6;
	sub.s32 	%r17, %r8, %r16;
	or.b32  	%r18, %r1, 2;
	mul.hi.u32 	%r19, %r18, -1386206375;
	shr.u32 	%r20, %r19, 8;
	cvt.u16.u32 	%rs7, %r20;
	shr.u16 	%rs8, %rs7, 1;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	mul.lo.s16 	%rs11, %rs10, 50;
	sub.s16 	%rs12, %rs7, %rs11;
	mul.hi.u32 	%r21, %r18, 715827883;
	mul.hi.u32 	%r22, %r21, 545392673;
	shr.u32 	%r23, %r22, 3;
	mul.lo.s32 	%r24, %r23, 63;
	sub.s32 	%r25, %r21, %r24;
	mul.lo.s32 	%r26, %r21, 6;
	sub.s32 	%r27, %r18, %r26;
	or.b32  	%r28, %r1, 1;
	mul.hi.u32 	%r29, %r1, -1386206375;
	shr.u32 	%r30, %r29, 8;
	cvt.u16.u32 	%rs13, %r30;
	shr.u16 	%rs14, %rs13, 1;
	mul.hi.u16 	%rs15, %rs14, 5243;
	shr.u16 	%rs16, %rs15, 1;
	mul.lo.s16 	%rs17, %rs16, 50;
	sub.s16 	%rs18, %rs13, %rs17;
	mul.hi.u32 	%r31, %r1, 715827883;
	mul.hi.u32 	%r32, %r31, 545392673;
	shr.u32 	%r33, %r32, 3;
	mul.lo.s32 	%r34, %r33, 63;
	sub.s32 	%r35, %r31, %r34;
	mul.hi.u32 	%r36, %r28, 715827883;
	mul.lo.s32 	%r37, %r36, 6;
	sub.s32 	%r38, %r28, %r37;
	mul.lo.s32 	%r39, %r31, 6;
	sub.s32 	%r40, %r1, %r39;
	mul.wide.u32 	%rd5, %r40, 806400;
	add.s64 	%rd6, %rd2, %rd5;
	mul.wide.u32 	%rd7, %r7, 12600;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r41, %rs18;
	mul.wide.u32 	%rd9, %r41, 252;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r35, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r1, 4;
	add.s64 	%rd14, %rd1, %rd13;
	mul.wide.u32 	%rd15, %r38, 806400;
	add.s64 	%rd16, %rd2, %rd15;
	add.s64 	%rd17, %rd16, %rd7;
	add.s64 	%rd18, %rd17, %rd9;
	add.s64 	%rd19, %rd18, %rd11;
	ld.global.nc.f32 	%f2, [%rd19];
	mul.wide.u32 	%rd20, %r27, 806400;
	add.s64 	%rd21, %rd2, %rd20;
	add.s64 	%rd22, %rd21, %rd7;
	cvt.u32.u16 	%r42, %rs12;
	mul.wide.u32 	%rd23, %r42, 252;
	add.s64 	%rd24, %rd22, %rd23;
	mul.wide.u32 	%rd25, %r25, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f3, [%rd26];
	mul.wide.u32 	%rd27, %r17, 806400;
	add.s64 	%rd28, %rd2, %rd27;
	add.s64 	%rd29, %rd28, %rd7;
	cvt.u32.u16 	%r43, %rs6;
	mul.wide.u32 	%rd30, %r43, 252;
	add.s64 	%rd31, %rd29, %rd30;
	mul.wide.u32 	%rd32, %r15, 4;
	add.s64 	%rd33, %rd31, %rd32;
	ld.global.nc.f32 	%f4, [%rd33];
	st.global.v4.f32 	[%rd14], {%f1, %f2, %f3, %f4};
$L__BB124_1:
	ret;

}
	// .globl	input_scatter_fusion_235
.visible .entry input_scatter_fusion_235(
	.param .u64 input_scatter_fusion_235_param_0,
	.param .u64 input_scatter_fusion_235_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_235_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_235_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, 68174085;
	sub.s32 	%r6, %r4, %r5;
	shr.u32 	%r7, %r6, 1;
	add.s32 	%r8, %r7, %r5;
	shr.u32 	%r9, %r8, 5;
	mul.lo.s32 	%r10, %r9, 63;
	sub.s32 	%r11, %r4, %r10;
	cvt.u16.u32 	%rs1, %r9;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	shr.u32 	%r12, %r4, 1;
	mul.hi.u32 	%r13, %r12, 698102621;
	bfe.u32 	%r14, %r13, 8, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, -22927;
	shr.u16 	%rs9, %rs8, 9;
	and.b16  	%rs10, %rs9, 126;
	cvt.u32.u16 	%r15, %rs6;
	mul.wide.u32 	%rd5, %r15, 252;
	cvt.u32.u16 	%r16, %rs10;
	mul.wide.u32 	%rd6, %r16, 806400;
	add.s64 	%rd7, %rd4, %rd6;
	mul.wide.u32 	%rd8, %r14, 12600;
	add.s64 	%rd9, %rd7, %rd8;
	add.s64 	%rd10, %rd9, %rd5;
	mul.wide.u32 	%rd11, %r11, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	loop_slice_fusion_75
.visible .entry loop_slice_fusion_75(
	.param .u64 loop_slice_fusion_75_param_0,
	.param .u64 loop_slice_fusion_75_param_1,
	.param .u64 loop_slice_fusion_75_param_2,
	.param .u64 loop_slice_fusion_75_param_3,
	.param .u64 loop_slice_fusion_75_param_4,
	.param .u64 loop_slice_fusion_75_param_5,
	.param .u64 loop_slice_fusion_75_param_6,
	.param .u64 loop_slice_fusion_75_param_7,
	.param .u64 loop_slice_fusion_75_param_8,
	.param .u64 loop_slice_fusion_75_param_9,
	.param .u64 loop_slice_fusion_75_param_10,
	.param .u64 loop_slice_fusion_75_param_11,
	.param .u64 loop_slice_fusion_75_param_12,
	.param .u64 loop_slice_fusion_75_param_13,
	.param .u64 loop_slice_fusion_75_param_14,
	.param .u64 loop_slice_fusion_75_param_15,
	.param .u64 loop_slice_fusion_75_param_16,
	.param .u64 loop_slice_fusion_75_param_17,
	.param .u64 loop_slice_fusion_75_param_18,
	.param .u64 loop_slice_fusion_75_param_19,
	.param .u64 loop_slice_fusion_75_param_20
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<56>;
	.reg .f32 	%f<153>;
	.reg .b64 	%rd<235>;

	ld.param.u64 	%rd1, [loop_slice_fusion_75_param_0];
	ld.param.u64 	%rd2, [loop_slice_fusion_75_param_20];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_slice_fusion_75_param_1];
	ld.param.u64 	%rd5, [loop_slice_fusion_75_param_19];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_slice_fusion_75_param_2];
	ld.param.u64 	%rd8, [loop_slice_fusion_75_param_18];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_slice_fusion_75_param_3];
	ld.param.u64 	%rd11, [loop_slice_fusion_75_param_17];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_slice_fusion_75_param_4];
	ld.param.u64 	%rd14, [loop_slice_fusion_75_param_16];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_slice_fusion_75_param_5];
	ld.param.u64 	%rd17, [loop_slice_fusion_75_param_15];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_slice_fusion_75_param_6];
	ld.param.u64 	%rd20, [loop_slice_fusion_75_param_14];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_slice_fusion_75_param_7];
	ld.param.u64 	%rd23, [loop_slice_fusion_75_param_13];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_slice_fusion_75_param_8];
	ld.param.u64 	%rd26, [loop_slice_fusion_75_param_12];
	cvta.to.global.u64 	%rd27, %rd26;
	ld.param.u64 	%rd28, [loop_slice_fusion_75_param_9];
	ld.param.u64 	%rd29, [loop_slice_fusion_75_param_11];
	cvta.to.global.u64 	%rd30, %rd29;
	ld.param.u64 	%rd31, [loop_slice_fusion_75_param_10];
	cvta.to.global.u64 	%rd32, %rd31;
	cvta.to.global.u64 	%rd33, %rd28;
	cvta.to.global.u64 	%rd34, %rd25;
	cvta.to.global.u64 	%rd35, %rd22;
	cvta.to.global.u64 	%rd36, %rd19;
	cvta.to.global.u64 	%rd37, %rd16;
	cvta.to.global.u64 	%rd38, %rd13;
	cvta.to.global.u64 	%rd39, %rd10;
	cvta.to.global.u64 	%rd40, %rd7;
	cvta.to.global.u64 	%rd41, %rd4;
	cvta.to.global.u64 	%rd42, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 9;
	shl.b32 	%r4, %r2, 2;
	or.b32  	%r5, %r3, %r4;
	mul.hi.u32 	%r6, %r5, 715827883;
	mul.lo.s32 	%r7, %r6, 6;
	sub.s32 	%r8, %r5, %r7;
	shr.u32 	%r9, %r6, 5;
	cvt.u16.u32 	%rs1, %r9;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r10, %r5, 458129845;
	bfe.u32 	%r11, %r10, 10, 6;
	or.b32  	%r12, %r5, 1;
	mul.hi.u32 	%r13, %r12, 715827883;
	mul.lo.s32 	%r14, %r13, 6;
	sub.s32 	%r15, %r12, %r14;
	or.b32  	%r16, %r5, 2;
	mul.hi.u32 	%r17, %r16, 715827883;
	mul.lo.s32 	%r18, %r17, 6;
	sub.s32 	%r19, %r16, %r18;
	or.b32  	%r20, %r5, 3;
	mul.hi.u32 	%r21, %r20, 715827883;
	mul.lo.s32 	%r22, %r21, 6;
	sub.s32 	%r23, %r20, %r22;
	shl.b32 	%r24, %r6, 1;
	and.b32  	%r25, %r24, 62;
	shl.b32 	%r26, %r25, 1;
	shl.b32 	%r27, %r25, 2;
	or.b32  	%r28, %r27, 2;
	or.b32  	%r29, %r27, 3;
	shl.b32 	%r30, %r29, 1;
	shl.b32 	%r31, %r29, 2;
	or.b32  	%r32, %r31, 2;
	shl.b16 	%rs7, %rs6, 10;
	cvt.u64.u32 	%rd43, %r32;
	cvt.u64.u16 	%rd44, %rs7;
	or.b64  	%rd45, %rd44, %rd43;
	mul.lo.s64 	%rd46, %rd45, 24;
	mul.wide.u32 	%rd47, %r11, 1228800;
	add.s64 	%rd48, %rd30, %rd47;
	add.s64 	%rd49, %rd48, %rd46;
	mul.wide.u32 	%rd50, %r8, 4;
	add.s64 	%rd51, %rd49, %rd50;
	ld.global.nc.f32 	%f1, [%rd51+24];
	cvt.u32.u16 	%r33, %rs6;
	mul.wide.u32 	%rd52, %r33, 12264;
	mul.wide.u32 	%rd53, %r11, 613200;
	add.s64 	%rd54, %rd21, %rd53;
	add.s64 	%rd55, %rd54, %rd52;
	mul.wide.u32 	%rd56, %r30, 24;
	add.s64 	%rd57, %rd55, %rd56;
	add.s64 	%rd58, %rd57, %rd50;
	ld.global.nc.f32 	%f2, [%rd58+24];
	add.s64 	%rd59, %rd18, %rd53;
	add.s64 	%rd60, %rd59, %rd52;
	add.s64 	%rd61, %rd60, %rd56;
	add.s64 	%rd62, %rd61, %rd50;
	ld.global.nc.f32 	%f3, [%rd62+24];
	add.rn.f32 	%f4, %f2, %f3;
	shr.u32 	%r34, %r8, 1;
	mul.wide.u32 	%rd63, %r34, 4;
	mul.wide.u32 	%rd64, %r11, 12;
	add.s64 	%rd65, %rd24, %rd64;
	add.s64 	%rd66, %rd65, %rd63;
	ld.global.nc.f32 	%f5, [%rd66];
	mul.wide.u32 	%rd67, %r11, 4;
	add.s64 	%rd68, %rd27, %rd67;
	ld.global.nc.f32 	%f6, [%rd68];
	cvt.u64.u32 	%rd69, %r31;
	or.b64  	%rd70, %rd44, %rd69;
	mul.lo.s64 	%rd71, %rd70, 24;
	add.s64 	%rd72, %rd48, %rd71;
	add.s64 	%rd73, %rd72, %rd50;
	ld.global.nc.f32 	%f7, [%rd73+96];
	mul.rn.f32 	%f8, %f6, %f7;
	mul.rn.f32 	%f9, %f5, %f8;
	add.rn.f32 	%f10, %f4, %f9;
	add.rn.f32 	%f11, %f1, %f10;
	mul.wide.u32 	%rd74, %r33, 6120;
	mul.wide.u32 	%rd75, %r11, 306000;
	add.s64 	%rd76, %rd33, %rd75;
	add.s64 	%rd77, %rd76, %rd74;
	mul.wide.u32 	%rd78, %r28, 24;
	add.s64 	%rd79, %rd77, %rd78;
	add.s64 	%rd80, %rd79, %rd50;
	ld.global.nc.f32 	%f12, [%rd80+24];
	add.s64 	%rd81, %rd32, %rd75;
	add.s64 	%rd82, %rd81, %rd74;
	add.s64 	%rd83, %rd82, %rd78;
	add.s64 	%rd84, %rd83, %rd50;
	ld.global.nc.f32 	%f13, [%rd84+24];
	add.rn.f32 	%f14, %f12, %f13;
	add.s64 	%rd85, %rd34, %rd64;
	add.s64 	%rd86, %rd85, %rd63;
	ld.global.nc.f32 	%f15, [%rd86];
	add.s64 	%rd87, %rd35, %rd67;
	ld.global.nc.f32 	%f16, [%rd87];
	add.s64 	%rd88, %rd36, %rd75;
	add.s64 	%rd89, %rd88, %rd74;
	add.s64 	%rd90, %rd89, %rd78;
	add.s64 	%rd91, %rd90, %rd50;
	ld.global.nc.f32 	%f17, [%rd91+24];
	mul.rn.f32 	%f18, %f16, %f17;
	mul.rn.f32 	%f19, %f15, %f18;
	add.rn.f32 	%f20, %f14, %f19;
	add.rn.f32 	%f21, %f11, %f20;
	mul.wide.u32 	%rd92, %r33, 3048;
	mul.wide.u32 	%rd93, %r11, 152400;
	add.s64 	%rd94, %rd38, %rd93;
	add.s64 	%rd95, %rd94, %rd92;
	mul.wide.u32 	%rd96, %r26, 24;
	add.s64 	%rd97, %rd95, %rd96;
	add.s64 	%rd98, %rd97, %rd50;
	ld.global.nc.f32 	%f22, [%rd98+24];
	add.s64 	%rd99, %rd37, %rd93;
	add.s64 	%rd100, %rd99, %rd92;
	add.s64 	%rd101, %rd100, %rd96;
	add.s64 	%rd102, %rd101, %rd50;
	ld.global.nc.f32 	%f23, [%rd102+24];
	add.rn.f32 	%f24, %f22, %f23;
	add.s64 	%rd103, %rd9, %rd64;
	add.s64 	%rd104, %rd103, %rd63;
	ld.global.nc.f32 	%f25, [%rd104];
	add.s64 	%rd105, %rd39, %rd67;
	ld.global.nc.f32 	%f26, [%rd105];
	add.s64 	%rd106, %rd40, %rd93;
	add.s64 	%rd107, %rd106, %rd92;
	add.s64 	%rd108, %rd107, %rd96;
	add.s64 	%rd109, %rd108, %rd50;
	ld.global.nc.f32 	%f27, [%rd109+24];
	mul.rn.f32 	%f28, %f26, %f27;
	mul.rn.f32 	%f29, %f25, %f28;
	add.rn.f32 	%f30, %f24, %f29;
	add.rn.f32 	%f31, %f21, %f30;
	mul.wide.u32 	%rd110, %r33, 1512;
	mul.wide.u32 	%rd111, %r11, 75600;
	add.s64 	%rd112, %rd42, %rd111;
	add.s64 	%rd113, %rd112, %rd110;
	mul.wide.u32 	%rd114, %r25, 24;
	add.s64 	%rd115, %rd113, %rd114;
	add.s64 	%rd116, %rd115, %rd50;
	ld.global.nc.f32 	%f32, [%rd116];
	add.s64 	%rd117, %rd41, %rd111;
	add.s64 	%rd118, %rd117, %rd110;
	add.s64 	%rd119, %rd118, %rd114;
	add.s64 	%rd120, %rd119, %rd50;
	ld.global.nc.f32 	%f33, [%rd120];
	add.rn.f32 	%f34, %f32, %f33;
	add.s64 	%rd121, %rd6, %rd64;
	add.s64 	%rd122, %rd121, %rd63;
	ld.global.nc.f32 	%f35, [%rd122];
	add.s64 	%rd123, %rd12, %rd67;
	ld.global.nc.f32 	%f36, [%rd123];
	mul.wide.u32 	%rd124, %r33, 1536;
	mul.wide.u32 	%rd125, %r11, 76800;
	add.s64 	%rd126, %rd15, %rd125;
	add.s64 	%rd127, %rd126, %rd124;
	add.s64 	%rd128, %rd127, %rd114;
	add.s64 	%rd129, %rd128, %rd50;
	ld.global.nc.f32 	%f37, [%rd129+24];
	mul.rn.f32 	%f38, %f36, %f37;
	mul.rn.f32 	%f39, %f35, %f38;
	add.rn.f32 	%f40, %f34, %f39;
	add.rn.f32 	%f41, %f31, %f40;
	mul.wide.u32 	%rd130, %r5, 4;
	add.s64 	%rd131, %rd3, %rd130;
	mul.wide.u32 	%rd132, %r15, 4;
	add.s64 	%rd133, %rd49, %rd132;
	ld.global.nc.f32 	%f42, [%rd133+24];
	add.s64 	%rd134, %rd57, %rd132;
	ld.global.nc.f32 	%f43, [%rd134+24];
	add.s64 	%rd135, %rd61, %rd132;
	ld.global.nc.f32 	%f44, [%rd135+24];
	add.rn.f32 	%f45, %f43, %f44;
	shr.u32 	%r35, %r15, 1;
	mul.wide.u32 	%rd136, %r35, 4;
	add.s64 	%rd137, %rd65, %rd136;
	ld.global.nc.f32 	%f46, [%rd137];
	add.s64 	%rd138, %rd72, %rd132;
	ld.global.nc.f32 	%f47, [%rd138+96];
	mul.rn.f32 	%f48, %f6, %f47;
	mul.rn.f32 	%f49, %f46, %f48;
	add.rn.f32 	%f50, %f45, %f49;
	add.rn.f32 	%f51, %f42, %f50;
	add.s64 	%rd139, %rd79, %rd132;
	ld.global.nc.f32 	%f52, [%rd139+24];
	add.s64 	%rd140, %rd83, %rd132;
	ld.global.nc.f32 	%f53, [%rd140+24];
	add.rn.f32 	%f54, %f52, %f53;
	add.s64 	%rd141, %rd85, %rd136;
	ld.global.nc.f32 	%f55, [%rd141];
	add.s64 	%rd142, %rd90, %rd132;
	ld.global.nc.f32 	%f56, [%rd142+24];
	mul.rn.f32 	%f57, %f16, %f56;
	mul.rn.f32 	%f58, %f55, %f57;
	add.rn.f32 	%f59, %f54, %f58;
	add.rn.f32 	%f60, %f51, %f59;
	add.s64 	%rd143, %rd97, %rd132;
	ld.global.nc.f32 	%f61, [%rd143+24];
	add.s64 	%rd144, %rd101, %rd132;
	ld.global.nc.f32 	%f62, [%rd144+24];
	add.rn.f32 	%f63, %f61, %f62;
	add.s64 	%rd145, %rd103, %rd136;
	ld.global.nc.f32 	%f64, [%rd145];
	add.s64 	%rd146, %rd108, %rd132;
	ld.global.nc.f32 	%f65, [%rd146+24];
	mul.rn.f32 	%f66, %f26, %f65;
	mul.rn.f32 	%f67, %f64, %f66;
	add.rn.f32 	%f68, %f63, %f67;
	add.rn.f32 	%f69, %f60, %f68;
	add.s64 	%rd147, %rd115, %rd132;
	ld.global.nc.f32 	%f70, [%rd147];
	add.s64 	%rd148, %rd119, %rd132;
	ld.global.nc.f32 	%f71, [%rd148];
	add.rn.f32 	%f72, %f70, %f71;
	add.s64 	%rd149, %rd121, %rd136;
	ld.global.nc.f32 	%f73, [%rd149];
	add.s64 	%rd150, %rd128, %rd132;
	ld.global.nc.f32 	%f74, [%rd150+24];
	mul.rn.f32 	%f75, %f36, %f74;
	mul.rn.f32 	%f76, %f73, %f75;
	add.rn.f32 	%f77, %f72, %f76;
	add.rn.f32 	%f78, %f69, %f77;
	shl.b32 	%r36, %r17, 1;
	and.b32  	%r37, %r36, 62;
	shl.b32 	%r38, %r37, 1;
	shl.b32 	%r39, %r37, 2;
	or.b32  	%r40, %r39, 2;
	or.b32  	%r41, %r39, 3;
	shl.b32 	%r42, %r41, 1;
	shl.b32 	%r43, %r41, 2;
	or.b32  	%r44, %r43, 2;
	cvt.u64.u32 	%rd151, %r44;
	or.b64  	%rd152, %rd44, %rd151;
	mul.lo.s64 	%rd153, %rd152, 24;
	add.s64 	%rd154, %rd48, %rd153;
	mul.wide.u32 	%rd155, %r19, 4;
	add.s64 	%rd156, %rd154, %rd155;
	ld.global.nc.f32 	%f79, [%rd156+24];
	mul.wide.u32 	%rd157, %r42, 24;
	add.s64 	%rd158, %rd55, %rd157;
	add.s64 	%rd159, %rd158, %rd155;
	ld.global.nc.f32 	%f80, [%rd159+24];
	add.s64 	%rd160, %rd60, %rd157;
	add.s64 	%rd161, %rd160, %rd155;
	ld.global.nc.f32 	%f81, [%rd161+24];
	add.rn.f32 	%f82, %f80, %f81;
	shr.u32 	%r45, %r19, 1;
	mul.wide.u32 	%rd162, %r45, 4;
	add.s64 	%rd163, %rd65, %rd162;
	ld.global.nc.f32 	%f83, [%rd163];
	cvt.u64.u32 	%rd164, %r43;
	or.b64  	%rd165, %rd44, %rd164;
	mul.lo.s64 	%rd166, %rd165, 24;
	add.s64 	%rd167, %rd48, %rd166;
	add.s64 	%rd168, %rd167, %rd155;
	ld.global.nc.f32 	%f84, [%rd168+96];
	mul.rn.f32 	%f85, %f6, %f84;
	mul.rn.f32 	%f86, %f83, %f85;
	add.rn.f32 	%f87, %f82, %f86;
	add.rn.f32 	%f88, %f79, %f87;
	mul.wide.u32 	%rd169, %r40, 24;
	add.s64 	%rd170, %rd77, %rd169;
	add.s64 	%rd171, %rd170, %rd155;
	ld.global.nc.f32 	%f89, [%rd171+24];
	add.s64 	%rd172, %rd82, %rd169;
	add.s64 	%rd173, %rd172, %rd155;
	ld.global.nc.f32 	%f90, [%rd173+24];
	add.rn.f32 	%f91, %f89, %f90;
	add.s64 	%rd174, %rd85, %rd162;
	ld.global.nc.f32 	%f92, [%rd174];
	add.s64 	%rd175, %rd89, %rd169;
	add.s64 	%rd176, %rd175, %rd155;
	ld.global.nc.f32 	%f93, [%rd176+24];
	mul.rn.f32 	%f94, %f16, %f93;
	mul.rn.f32 	%f95, %f92, %f94;
	add.rn.f32 	%f96, %f91, %f95;
	add.rn.f32 	%f97, %f88, %f96;
	mul.wide.u32 	%rd177, %r38, 24;
	add.s64 	%rd178, %rd95, %rd177;
	add.s64 	%rd179, %rd178, %rd155;
	ld.global.nc.f32 	%f98, [%rd179+24];
	add.s64 	%rd180, %rd100, %rd177;
	add.s64 	%rd181, %rd180, %rd155;
	ld.global.nc.f32 	%f99, [%rd181+24];
	add.rn.f32 	%f100, %f98, %f99;
	add.s64 	%rd182, %rd103, %rd162;
	ld.global.nc.f32 	%f101, [%rd182];
	add.s64 	%rd183, %rd107, %rd177;
	add.s64 	%rd184, %rd183, %rd155;
	ld.global.nc.f32 	%f102, [%rd184+24];
	mul.rn.f32 	%f103, %f26, %f102;
	mul.rn.f32 	%f104, %f101, %f103;
	add.rn.f32 	%f105, %f100, %f104;
	add.rn.f32 	%f106, %f97, %f105;
	mul.wide.u32 	%rd185, %r37, 24;
	add.s64 	%rd186, %rd113, %rd185;
	add.s64 	%rd187, %rd186, %rd155;
	ld.global.nc.f32 	%f107, [%rd187];
	add.s64 	%rd188, %rd118, %rd185;
	add.s64 	%rd189, %rd188, %rd155;
	ld.global.nc.f32 	%f108, [%rd189];
	add.rn.f32 	%f109, %f107, %f108;
	add.s64 	%rd190, %rd121, %rd162;
	ld.global.nc.f32 	%f110, [%rd190];
	add.s64 	%rd191, %rd127, %rd185;
	add.s64 	%rd192, %rd191, %rd155;
	ld.global.nc.f32 	%f111, [%rd192+24];
	mul.rn.f32 	%f112, %f36, %f111;
	mul.rn.f32 	%f113, %f110, %f112;
	add.rn.f32 	%f114, %f109, %f113;
	add.rn.f32 	%f115, %f106, %f114;
	shl.b32 	%r46, %r21, 1;
	and.b32  	%r47, %r46, 62;
	shl.b32 	%r48, %r47, 1;
	shl.b32 	%r49, %r47, 2;
	or.b32  	%r50, %r49, 2;
	or.b32  	%r51, %r49, 3;
	shl.b32 	%r52, %r51, 1;
	shl.b32 	%r53, %r51, 2;
	or.b32  	%r54, %r53, 2;
	cvt.u64.u32 	%rd193, %r54;
	or.b64  	%rd194, %rd44, %rd193;
	mul.lo.s64 	%rd195, %rd194, 24;
	add.s64 	%rd196, %rd48, %rd195;
	mul.wide.u32 	%rd197, %r23, 4;
	add.s64 	%rd198, %rd196, %rd197;
	ld.global.nc.f32 	%f116, [%rd198+24];
	mul.wide.u32 	%rd199, %r52, 24;
	add.s64 	%rd200, %rd55, %rd199;
	add.s64 	%rd201, %rd200, %rd197;
	ld.global.nc.f32 	%f117, [%rd201+24];
	add.s64 	%rd202, %rd60, %rd199;
	add.s64 	%rd203, %rd202, %rd197;
	ld.global.nc.f32 	%f118, [%rd203+24];
	add.rn.f32 	%f119, %f117, %f118;
	shr.u32 	%r55, %r23, 1;
	mul.wide.u32 	%rd204, %r55, 4;
	add.s64 	%rd205, %rd65, %rd204;
	ld.global.nc.f32 	%f120, [%rd205];
	cvt.u64.u32 	%rd206, %r53;
	or.b64  	%rd207, %rd44, %rd206;
	mul.lo.s64 	%rd208, %rd207, 24;
	add.s64 	%rd209, %rd48, %rd208;
	add.s64 	%rd210, %rd209, %rd197;
	ld.global.nc.f32 	%f121, [%rd210+96];
	mul.rn.f32 	%f122, %f6, %f121;
	mul.rn.f32 	%f123, %f120, %f122;
	add.rn.f32 	%f124, %f119, %f123;
	add.rn.f32 	%f125, %f116, %f124;
	mul.wide.u32 	%rd211, %r50, 24;
	add.s64 	%rd212, %rd77, %rd211;
	add.s64 	%rd213, %rd212, %rd197;
	ld.global.nc.f32 	%f126, [%rd213+24];
	add.s64 	%rd214, %rd82, %rd211;
	add.s64 	%rd215, %rd214, %rd197;
	ld.global.nc.f32 	%f127, [%rd215+24];
	add.rn.f32 	%f128, %f126, %f127;
	add.s64 	%rd216, %rd85, %rd204;
	ld.global.nc.f32 	%f129, [%rd216];
	add.s64 	%rd217, %rd89, %rd211;
	add.s64 	%rd218, %rd217, %rd197;
	ld.global.nc.f32 	%f130, [%rd218+24];
	mul.rn.f32 	%f131, %f16, %f130;
	mul.rn.f32 	%f132, %f129, %f131;
	add.rn.f32 	%f133, %f128, %f132;
	add.rn.f32 	%f134, %f125, %f133;
	mul.wide.u32 	%rd219, %r48, 24;
	add.s64 	%rd220, %rd95, %rd219;
	add.s64 	%rd221, %rd220, %rd197;
	ld.global.nc.f32 	%f135, [%rd221+24];
	add.s64 	%rd222, %rd100, %rd219;
	add.s64 	%rd223, %rd222, %rd197;
	ld.global.nc.f32 	%f136, [%rd223+24];
	add.rn.f32 	%f137, %f135, %f136;
	add.s64 	%rd224, %rd103, %rd204;
	ld.global.nc.f32 	%f138, [%rd224];
	add.s64 	%rd225, %rd107, %rd219;
	add.s64 	%rd226, %rd225, %rd197;
	ld.global.nc.f32 	%f139, [%rd226+24];
	mul.rn.f32 	%f140, %f26, %f139;
	mul.rn.f32 	%f141, %f138, %f140;
	add.rn.f32 	%f142, %f137, %f141;
	add.rn.f32 	%f143, %f134, %f142;
	mul.wide.u32 	%rd227, %r47, 24;
	add.s64 	%rd228, %rd113, %rd227;
	add.s64 	%rd229, %rd228, %rd197;
	ld.global.nc.f32 	%f144, [%rd229];
	add.s64 	%rd230, %rd118, %rd227;
	add.s64 	%rd231, %rd230, %rd197;
	ld.global.nc.f32 	%f145, [%rd231];
	add.rn.f32 	%f146, %f144, %f145;
	add.s64 	%rd232, %rd121, %rd204;
	ld.global.nc.f32 	%f147, [%rd232];
	add.s64 	%rd233, %rd127, %rd227;
	add.s64 	%rd234, %rd233, %rd197;
	ld.global.nc.f32 	%f148, [%rd234+24];
	mul.rn.f32 	%f149, %f36, %f148;
	mul.rn.f32 	%f150, %f147, %f149;
	add.rn.f32 	%f151, %f146, %f150;
	add.rn.f32 	%f152, %f143, %f151;
	st.global.v4.f32 	[%rd131], {%f41, %f78, %f115, %f152};
	ret;

}
	// .globl	loop_transpose_fusion_107
.visible .entry loop_transpose_fusion_107(
	.param .u64 loop_transpose_fusion_107_param_0,
	.param .u64 loop_transpose_fusion_107_param_1,
	.param .u64 loop_transpose_fusion_107_param_2,
	.param .u64 loop_transpose_fusion_107_param_3,
	.param .u64 loop_transpose_fusion_107_param_4
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot127[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<121>;
	.reg .f32 	%f<56>;
	.reg .b64 	%rd<59>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot127;
	ld.param.u64 	%rd15, [loop_transpose_fusion_107_param_0];
	ld.param.u64 	%rd16, [loop_transpose_fusion_107_param_4];
	ld.param.u64 	%rd17, [loop_transpose_fusion_107_param_1];
	ld.param.u64 	%rd18, [loop_transpose_fusion_107_param_3];
	ld.param.u64 	%rd19, [loop_transpose_fusion_107_param_2];
	cvta.to.global.u64 	%rd20, %rd19;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd15;
	add.u64 	%rd5, %SPL, 0;
	mov.u32 	%r34, %ctaid.x;
	shl.b32 	%r35, %r34, 7;
	mov.u32 	%r36, %tid.x;
	or.b32  	%r1, %r35, %r36;
	cvt.u16.u32 	%rs3, %r34;
	mul.hi.u16 	%rs4, %rs3, 21057;
	sub.s16 	%rs5, %rs3, %rs4;
	shr.u16 	%rs6, %rs5, 1;
	add.s16 	%rs7, %rs6, %rs4;
	shr.u16 	%rs8, %rs7, 9;
	shr.u32 	%r37, %r1, 1;
	mul.hi.u32 	%r38, %r37, -1457517933;
	bfe.u32 	%r39, %r38, 9, 6;
	mul.hi.u32 	%r40, %r1, 138547333;
	sub.s32 	%r41, %r1, %r40;
	shr.u32 	%r42, %r41, 1;
	add.s32 	%r43, %r42, %r40;
	shr.u32 	%r44, %r43, 4;
	cvt.u16.u32 	%rs9, %r44;
	shr.u16 	%rs10, %rs9, 1;
	mul.hi.u16 	%rs11, %rs10, 5243;
	shr.u16 	%rs12, %rs11, 1;
	mul.lo.s16 	%rs13, %rs12, 50;
	sub.s16 	%rs1, %rs9, %rs13;
	mul.lo.s32 	%r45, %r44, 31;
	sub.s32 	%r2, %r1, %r45;
	shl.b16 	%rs2, %rs8, 1;
	cvt.u64.u32 	%rd7, %r39;
	mul.wide.u32 	%rd23, %r39, 12;
	add.s64 	%rd24, %rd20, %rd23;
	cvt.u32.u16 	%r46, %rs8;
	mul.wide.u32 	%rd25, %r46, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f1, [%rd26];
	mul.rn.f32 	%f12, %f1, 0f3F22F983;
	cvt.rni.s32.f32 	%r120, %f12;
	cvt.rn.f32.s32 	%f13, %r120;
	fma.rn.f32 	%f14, %f13, 0fBFC90FDA, %f1;
	fma.rn.f32 	%f15, %f13, 0fB3A22168, %f14;
	fma.rn.f32 	%f55, %f13, 0fA7C234C5, %f15;
	abs.f32 	%f3, %f1;
	setp.ltu.f32 	%p1, %f3, 0f47CE4780;
	setp.neu.f32 	%p17, %f3, 0f7F800000;
	mov.f32 	%f53, 0f00000000;
	mov.u32 	%r116, %r120;
	mov.f32 	%f54, %f55;
	@%p1 bra 	$L__BB127_8;
	@%p17 bra 	$L__BB127_3;
	mul.rn.f32 	%f54, %f1, %f53;
	mov.b32 	%r116, 0;
	bra.uni 	$L__BB127_8;
$L__BB127_3:
	mov.b32 	%r4, %f1;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r48, %r5, 224;
	add.s32 	%r49, %r48, -128;
	shl.b32 	%r50, %r4, 8;
	or.b32  	%r54, %r50, -2147483648;
	shr.u32 	%r7, %r49, 5;
	mov.b32 	%r113, 0;
	mov.u64 	%rd57, 0;
	mov.u64 	%rd28, __cudart_i2opi_f;
$L__BB127_4:
	.pragma "nounroll";
	add.s64 	%rd29, %rd28, %rd57;
	ld.global.nc.u32 	%r53, [%rd29];
	// begin inline asm
	{
	mad.lo.cc.u32   %r51, %r53, %r54, %r113;
	madc.hi.u32     %r113, %r53, %r54,  0;
	}
	// end inline asm
	add.s64 	%rd30, %rd5, %rd57;
	st.local.u32 	[%rd30], %r51;
	add.s64 	%rd57, %rd57, 4;
	cvt.u32.u64 	%r56, %rd57;
	setp.ne.s32 	%p3, %r56, 24;
	@%p3 bra 	$L__BB127_4;
	st.local.u32 	[%rd5+24], %r113;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd31, %r7, 4;
	sub.s64 	%rd10, %rd5, %rd31;
	ld.local.u32 	%r114, [%rd10+24];
	ld.local.u32 	%r115, [%rd10+20];
	setp.eq.s32 	%p4, %r10, 0;
	@%p4 bra 	$L__BB127_7;
	shl.b32 	%r57, %r115, %r10;
	shl.b32 	%r58, %r114, %r10;
	mov.b32 	%r59, 32;
	sub.s32 	%r60, %r59, %r10;
	shr.u32 	%r61, %r115, %r60;
	add.s32 	%r114, %r61, %r58;
	ld.local.u32 	%r62, [%rd10+16];
	shr.u32 	%r63, %r62, %r60;
	add.s32 	%r115, %r63, %r57;
$L__BB127_7:
	shr.u32 	%r64, %r114, 30;
	shr.u32 	%r65, %r115, 30;
	shl.b32 	%r66, %r114, 2;
	or.b32  	%r67, %r66, %r65;
	shl.b32 	%r68, %r115, 2;
	bfe.u32 	%r69, %r114, 29, 1;
	add.s32 	%r70, %r69, %r64;
	neg.s32 	%r71, %r70;
	setp.lt.s32 	%p5, %r4, 0;
	selp.b32 	%r116, %r71, %r70, %p5;
	xor.b32  	%r72, %r67, %r4;
	bfe.s32 	%r73, %r114, 29, 1;
	xor.b32  	%r74, %r73, %r67;
	xor.b32  	%r75, %r73, %r68;
	cvt.u64.u32 	%rd32, %r74;
	shl.b64 	%rd33, %rd32, 32;
	cvt.u64.u32 	%rd34, %r75;
	or.b64  	%rd35, %rd33, %rd34;
	cvt.rn.f64.s64 	%fd1, %rd35;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f16, %fd2;
	neg.f32 	%f17, %f16;
	setp.lt.s32 	%p6, %r72, 0;
	selp.f32 	%f54, %f17, %f16, %p6;
$L__BB127_8:
	cvta.to.global.u64 	%rd1, %rd16;
	cvta.to.global.u64 	%rd2, %rd18;
	shl.b64 	%rd36, %rd7, 2;
	add.s64 	%rd37, %rd3, %rd36;
	ld.global.nc.f32 	%f7, [%rd37];
	mul.lo.s64 	%rd38, %rd7, 38400;
	add.s64 	%rd39, %rd4, %rd38;
	cvt.u32.u16 	%r77, %rs1;
	mul.wide.u32 	%rd40, %r77, 768;
	add.s64 	%rd41, %rd39, %rd40;
	mul.wide.u32 	%rd42, %r2, 24;
	add.s64 	%rd43, %rd41, %rd42;
	cvt.u32.u16 	%r78, %rs2;
	mul.wide.u32 	%rd44, %r78, 4;
	add.s64 	%rd11, %rd43, %rd44;
	ld.global.nc.f32 	%f8, [%rd11+28];
	@%p1 bra 	$L__BB127_16;
	@%p17 bra 	$L__BB127_11;
	mul.rn.f32 	%f55, %f1, %f53;
	mov.b32 	%r120, 0;
	bra.uni 	$L__BB127_16;
$L__BB127_11:
	mov.b32 	%r19, %f1;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r80, %r20, 224;
	add.s32 	%r81, %r80, -128;
	shl.b32 	%r82, %r19, 8;
	or.b32  	%r86, %r82, -2147483648;
	shr.u32 	%r22, %r81, 5;
	mov.b32 	%r117, 0;
	mov.u64 	%rd58, 0;
	mov.u64 	%rd46, __cudart_i2opi_f;
$L__BB127_12:
	.pragma "nounroll";
	add.s64 	%rd47, %rd46, %rd58;
	ld.global.nc.u32 	%r85, [%rd47];
	// begin inline asm
	{
	mad.lo.cc.u32   %r83, %r85, %r86, %r117;
	madc.hi.u32     %r117, %r85, %r86,  0;
	}
	// end inline asm
	add.s64 	%rd48, %rd5, %rd58;
	st.local.u32 	[%rd48], %r83;
	add.s64 	%rd58, %rd58, 4;
	cvt.u32.u64 	%r88, %rd58;
	setp.ne.s32 	%p9, %r88, 24;
	@%p9 bra 	$L__BB127_12;
	st.local.u32 	[%rd5+24], %r117;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd49, %r22, 4;
	sub.s64 	%rd14, %rd5, %rd49;
	ld.local.u32 	%r118, [%rd14+24];
	ld.local.u32 	%r119, [%rd14+20];
	setp.eq.s32 	%p10, %r25, 0;
	@%p10 bra 	$L__BB127_15;
	shl.b32 	%r89, %r119, %r25;
	shl.b32 	%r90, %r118, %r25;
	mov.b32 	%r91, 32;
	sub.s32 	%r92, %r91, %r25;
	shr.u32 	%r93, %r119, %r92;
	add.s32 	%r118, %r93, %r90;
	ld.local.u32 	%r94, [%rd14+16];
	shr.u32 	%r95, %r94, %r92;
	add.s32 	%r119, %r95, %r89;
$L__BB127_15:
	shr.u32 	%r96, %r118, 30;
	shr.u32 	%r97, %r119, 30;
	shl.b32 	%r98, %r118, 2;
	or.b32  	%r99, %r98, %r97;
	shl.b32 	%r100, %r119, 2;
	bfe.u32 	%r101, %r118, 29, 1;
	add.s32 	%r102, %r101, %r96;
	neg.s32 	%r103, %r102;
	setp.lt.s32 	%p11, %r19, 0;
	selp.b32 	%r120, %r103, %r102, %p11;
	xor.b32  	%r104, %r99, %r19;
	bfe.s32 	%r105, %r118, 29, 1;
	xor.b32  	%r106, %r105, %r99;
	xor.b32  	%r107, %r105, %r100;
	cvt.u64.u32 	%rd50, %r106;
	shl.b64 	%rd51, %rd50, 32;
	cvt.u64.u32 	%rd52, %r107;
	or.b64  	%rd53, %rd51, %rd52;
	cvt.rn.f64.s64 	%fd3, %rd53;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f19, %fd4;
	neg.f32 	%f20, %f19;
	setp.lt.s32 	%p12, %r104, 0;
	selp.f32 	%f55, %f20, %f19, %p12;
$L__BB127_16:
	and.b32  	%r109, %r116, 2;
	setp.eq.s32 	%p13, %r109, 0;
	and.b32  	%r110, %r116, 1;
	setp.eq.b32 	%p14, %r110, 1;
	mul.rn.f32 	%f22, %f54, %f54;
	fma.rn.f32 	%f23, %f22, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f24, %f23, 0fB94D4153, %p14;
	selp.f32 	%f25, 0f3D2AAABB, 0f3C0885E4, %p14;
	fma.rn.f32 	%f26, %f24, %f22, %f25;
	selp.f32 	%f27, 0fBEFFFFFF, 0fBE2AAAA8, %p14;
	fma.rn.f32 	%f28, %f26, %f22, %f27;
	selp.f32 	%f29, 0f3F800000, %f54, %p14;
	fma.rn.f32 	%f30, %f22, %f29, 0f00000000;
	fma.rn.f32 	%f31, %f28, %f30, %f29;
	sub.rn.f32 	%f33, %f53, %f31;
	selp.f32 	%f34, %f31, %f33, %p13;
	mul.rn.f32 	%f35, %f7, %f8;
	mul.rn.f32 	%f36, %f35, %f34;
	mul.rn.f32 	%f37, %f55, %f55;
	and.b32  	%r111, %r120, 1;
	setp.eq.b32 	%p15, %r111, 1;
	selp.f32 	%f38, 0f3F800000, %f55, %p15;
	fma.rn.f32 	%f39, %f37, %f38, 0f00000000;
	fma.rn.f32 	%f40, %f37, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f41, %f40, 0fB94D4153, %p15;
	selp.f32 	%f42, 0f3D2AAABB, 0f3C0885E4, %p15;
	fma.rn.f32 	%f43, %f41, %f37, %f42;
	selp.f32 	%f44, 0fBEFFFFFF, 0fBE2AAAA8, %p15;
	fma.rn.f32 	%f45, %f43, %f37, %f44;
	fma.rn.f32 	%f46, %f45, %f39, %f38;
	and.b32  	%r112, %r120, 2;
	setp.eq.s32 	%p16, %r112, 0;
	sub.rn.f32 	%f47, %f53, %f46;
	selp.f32 	%f48, %f46, %f47, %p16;
	ld.global.nc.f32 	%f49, [%rd11+24];
	mul.rn.f32 	%f50, %f7, %f49;
	neg.f32 	%f51, %f48;
	mul.rn.f32 	%f52, %f50, %f51;
	mul.wide.u32 	%rd54, %r1, 4;
	add.s64 	%rd55, %rd2, %rd54;
	st.global.f32 	[%rd55], %f36;
	add.s64 	%rd56, %rd1, %rd54;
	st.global.f32 	[%rd56], %f52;
	ret;

}
	// .globl	loop_broadcast_fusion_32
.visible .entry loop_broadcast_fusion_32(
	.param .u64 loop_broadcast_fusion_32_param_0
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<5>;

	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 10;
	shl.b32 	%r4, %r2, 2;
	or.b32  	%r5, %r3, %r4;
	setp.lt.u32 	%p1, %r5, 595200;
	@%p1 bra 	$L__BB128_2;
	bra.uni 	$L__BB128_1;
$L__BB128_2:
	ld.param.u64 	%rd2, [loop_broadcast_fusion_32_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.u32 	%rd4, %r5, 4;
	add.s64 	%rd1, %rd3, %rd4;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd1], {%f1, %f1, %f1, %f1};
$L__BB128_1:
	ret;

}
	// .globl	input_scatter_fusion_236
.visible .entry input_scatter_fusion_236(
	.param .u64 input_scatter_fusion_236_param_0,
	.param .u64 input_scatter_fusion_236_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_236_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_236_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, 138547333;
	sub.s32 	%r6, %r4, %r5;
	shr.u32 	%r7, %r6, 1;
	add.s32 	%r8, %r7, %r5;
	shr.u32 	%r9, %r8, 4;
	mul.lo.s32 	%r10, %r9, 31;
	sub.s32 	%r11, %r4, %r10;
	cvt.u16.u32 	%rs1, %r9;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	shr.u32 	%r12, %r4, 1;
	mul.hi.u32 	%r13, %r12, -1457517933;
	bfe.u32 	%r14, %r13, 9, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, 21057;
	sub.s16 	%rs9, %rs7, %rs8;
	shr.u16 	%rs10, %rs9, 1;
	add.s16 	%rs11, %rs10, %rs8;
	shr.u16 	%rs12, %rs11, 8;
	and.b16  	%rs13, %rs12, 254;
	cvt.u32.u16 	%r15, %rs6;
	mul.wide.u32 	%rd5, %r15, 124;
	cvt.u32.u16 	%r16, %rs13;
	mul.wide.u32 	%rd6, %r16, 396800;
	add.s64 	%rd7, %rd4, %rd6;
	mul.wide.u32 	%rd8, %r14, 6200;
	add.s64 	%rd9, %rd7, %rd8;
	add.s64 	%rd10, %rd9, %rd5;
	mul.wide.u32 	%rd11, %r11, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+396800];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+396800], %f3;
	ret;

}
	// .globl	wrapped_transpose_242
.visible .entry wrapped_transpose_242(
	.param .u64 wrapped_transpose_242_param_0,
	.param .u64 wrapped_transpose_242_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<44>;
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<34>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 9;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	setp.lt.u32 	%p1, %r1, 595200;
	@%p1 bra 	$L__BB130_2;
	bra.uni 	$L__BB130_1;
$L__BB130_2:
	ld.param.u64 	%rd3, [wrapped_transpose_242_param_0];
	ld.param.u64 	%rd4, [wrapped_transpose_242_param_1];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd3;
	mul.hi.u32 	%r6, %r1, -511701479;
	shr.u32 	%r7, %r6, 13;
	or.b32  	%r8, %r1, 3;
	mul.hi.u32 	%r9, %r8, 738919105;
	shr.u32 	%r10, %r9, 5;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r8, 715827883;
	mul.hi.u32 	%r12, %r11, 554189329;
	shr.u32 	%r13, %r12, 2;
	mul.lo.s32 	%r14, %r13, 31;
	sub.s32 	%r15, %r11, %r14;
	mul.lo.s32 	%r16, %r11, 6;
	sub.s32 	%r17, %r8, %r16;
	or.b32  	%r18, %r1, 2;
	mul.hi.u32 	%r19, %r18, 738919105;
	shr.u32 	%r20, %r19, 5;
	cvt.u16.u32 	%rs7, %r20;
	shr.u16 	%rs8, %rs7, 1;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	mul.lo.s16 	%rs11, %rs10, 50;
	sub.s16 	%rs12, %rs7, %rs11;
	mul.hi.u32 	%r21, %r18, 715827883;
	mul.hi.u32 	%r22, %r21, 554189329;
	shr.u32 	%r23, %r22, 2;
	mul.lo.s32 	%r24, %r23, 31;
	sub.s32 	%r25, %r21, %r24;
	mul.lo.s32 	%r26, %r21, 6;
	sub.s32 	%r27, %r18, %r26;
	or.b32  	%r28, %r1, 1;
	mul.hi.u32 	%r29, %r1, 738919105;
	shr.u32 	%r30, %r29, 5;
	cvt.u16.u32 	%rs13, %r30;
	shr.u16 	%rs14, %rs13, 1;
	mul.hi.u16 	%rs15, %rs14, 5243;
	shr.u16 	%rs16, %rs15, 1;
	mul.lo.s16 	%rs17, %rs16, 50;
	sub.s16 	%rs18, %rs13, %rs17;
	mul.hi.u32 	%r31, %r1, 715827883;
	mul.hi.u32 	%r32, %r31, 554189329;
	shr.u32 	%r33, %r32, 2;
	mul.lo.s32 	%r34, %r33, 31;
	sub.s32 	%r35, %r31, %r34;
	mul.hi.u32 	%r36, %r28, 715827883;
	mul.lo.s32 	%r37, %r36, 6;
	sub.s32 	%r38, %r28, %r37;
	mul.lo.s32 	%r39, %r31, 6;
	sub.s32 	%r40, %r1, %r39;
	mul.wide.u32 	%rd5, %r40, 396800;
	add.s64 	%rd6, %rd2, %rd5;
	mul.wide.u32 	%rd7, %r7, 6200;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r41, %rs18;
	mul.wide.u32 	%rd9, %r41, 124;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r35, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r1, 4;
	add.s64 	%rd14, %rd1, %rd13;
	mul.wide.u32 	%rd15, %r38, 396800;
	add.s64 	%rd16, %rd2, %rd15;
	add.s64 	%rd17, %rd16, %rd7;
	add.s64 	%rd18, %rd17, %rd9;
	add.s64 	%rd19, %rd18, %rd11;
	ld.global.nc.f32 	%f2, [%rd19];
	mul.wide.u32 	%rd20, %r27, 396800;
	add.s64 	%rd21, %rd2, %rd20;
	add.s64 	%rd22, %rd21, %rd7;
	cvt.u32.u16 	%r42, %rs12;
	mul.wide.u32 	%rd23, %r42, 124;
	add.s64 	%rd24, %rd22, %rd23;
	mul.wide.u32 	%rd25, %r25, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f3, [%rd26];
	mul.wide.u32 	%rd27, %r17, 396800;
	add.s64 	%rd28, %rd2, %rd27;
	add.s64 	%rd29, %rd28, %rd7;
	cvt.u32.u16 	%r43, %rs6;
	mul.wide.u32 	%rd30, %r43, 124;
	add.s64 	%rd31, %rd29, %rd30;
	mul.wide.u32 	%rd32, %r15, 4;
	add.s64 	%rd33, %rd31, %rd32;
	ld.global.nc.f32 	%f4, [%rd33];
	st.global.v4.f32 	[%rd14], {%f1, %f2, %f3, %f4};
$L__BB130_1:
	ret;

}
	// .globl	input_scatter_fusion_237
.visible .entry input_scatter_fusion_237(
	.param .u64 input_scatter_fusion_237_param_0,
	.param .u64 input_scatter_fusion_237_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_237_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_237_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, 138547333;
	sub.s32 	%r6, %r4, %r5;
	shr.u32 	%r7, %r6, 1;
	add.s32 	%r8, %r7, %r5;
	shr.u32 	%r9, %r8, 4;
	mul.lo.s32 	%r10, %r9, 31;
	sub.s32 	%r11, %r4, %r10;
	cvt.u16.u32 	%rs1, %r9;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	shr.u32 	%r12, %r4, 1;
	mul.hi.u32 	%r13, %r12, -1457517933;
	bfe.u32 	%r14, %r13, 9, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, 21057;
	sub.s16 	%rs9, %rs7, %rs8;
	shr.u16 	%rs10, %rs9, 1;
	add.s16 	%rs11, %rs10, %rs8;
	shr.u16 	%rs12, %rs11, 8;
	and.b16  	%rs13, %rs12, 254;
	cvt.u32.u16 	%r15, %rs6;
	mul.wide.u32 	%rd5, %r15, 124;
	cvt.u32.u16 	%r16, %rs13;
	mul.wide.u32 	%rd6, %r16, 396800;
	add.s64 	%rd7, %rd4, %rd6;
	mul.wide.u32 	%rd8, %r14, 6200;
	add.s64 	%rd9, %rd7, %rd8;
	add.s64 	%rd10, %rd9, %rd5;
	mul.wide.u32 	%rd11, %r11, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	loop_slice_fusion_76
.visible .entry loop_slice_fusion_76(
	.param .u64 loop_slice_fusion_76_param_0,
	.param .u64 loop_slice_fusion_76_param_1,
	.param .u64 loop_slice_fusion_76_param_2,
	.param .u64 loop_slice_fusion_76_param_3,
	.param .u64 loop_slice_fusion_76_param_4,
	.param .u64 loop_slice_fusion_76_param_5,
	.param .u64 loop_slice_fusion_76_param_6,
	.param .u64 loop_slice_fusion_76_param_7,
	.param .u64 loop_slice_fusion_76_param_8,
	.param .u64 loop_slice_fusion_76_param_9,
	.param .u64 loop_slice_fusion_76_param_10,
	.param .u64 loop_slice_fusion_76_param_11,
	.param .u64 loop_slice_fusion_76_param_12,
	.param .u64 loop_slice_fusion_76_param_13,
	.param .u64 loop_slice_fusion_76_param_14,
	.param .u64 loop_slice_fusion_76_param_15,
	.param .u64 loop_slice_fusion_76_param_16,
	.param .u64 loop_slice_fusion_76_param_17,
	.param .u64 loop_slice_fusion_76_param_18,
	.param .u64 loop_slice_fusion_76_param_19,
	.param .u64 loop_slice_fusion_76_param_20,
	.param .u64 loop_slice_fusion_76_param_21,
	.param .u64 loop_slice_fusion_76_param_22,
	.param .u64 loop_slice_fusion_76_param_23,
	.param .u64 loop_slice_fusion_76_param_24,
	.param .u64 loop_slice_fusion_76_param_25
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot132[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<78>;
	.reg .f32 	%f<79>;
	.reg .b64 	%rd<184>;
	.reg .f64 	%fd<3>;

	mov.u64 	%SPL, __local_depot132;
	ld.param.u64 	%rd12, [loop_slice_fusion_76_param_0];
	ld.param.u64 	%rd13, [loop_slice_fusion_76_param_25];
	cvta.to.global.u64 	%rd1, %rd13;
	ld.param.u64 	%rd14, [loop_slice_fusion_76_param_1];
	ld.param.u64 	%rd15, [loop_slice_fusion_76_param_24];
	cvta.to.global.u64 	%rd16, %rd15;
	ld.param.u64 	%rd17, [loop_slice_fusion_76_param_2];
	ld.param.u64 	%rd18, [loop_slice_fusion_76_param_23];
	cvta.to.global.u64 	%rd19, %rd18;
	ld.param.u64 	%rd20, [loop_slice_fusion_76_param_3];
	ld.param.u64 	%rd21, [loop_slice_fusion_76_param_22];
	cvta.to.global.u64 	%rd22, %rd21;
	ld.param.u64 	%rd23, [loop_slice_fusion_76_param_4];
	ld.param.u64 	%rd24, [loop_slice_fusion_76_param_21];
	cvta.to.global.u64 	%rd2, %rd24;
	ld.param.u64 	%rd25, [loop_slice_fusion_76_param_5];
	ld.param.u64 	%rd26, [loop_slice_fusion_76_param_20];
	cvta.to.global.u64 	%rd3, %rd26;
	ld.param.u64 	%rd27, [loop_slice_fusion_76_param_6];
	ld.param.u64 	%rd28, [loop_slice_fusion_76_param_19];
	cvta.to.global.u64 	%rd29, %rd28;
	ld.param.u64 	%rd30, [loop_slice_fusion_76_param_7];
	ld.param.u64 	%rd31, [loop_slice_fusion_76_param_18];
	cvta.to.global.u64 	%rd32, %rd31;
	ld.param.u64 	%rd33, [loop_slice_fusion_76_param_8];
	ld.param.u64 	%rd34, [loop_slice_fusion_76_param_17];
	cvta.to.global.u64 	%rd35, %rd34;
	ld.param.u64 	%rd36, [loop_slice_fusion_76_param_9];
	ld.param.u64 	%rd37, [loop_slice_fusion_76_param_16];
	cvta.to.global.u64 	%rd38, %rd37;
	ld.param.u64 	%rd39, [loop_slice_fusion_76_param_10];
	ld.param.u64 	%rd40, [loop_slice_fusion_76_param_15];
	cvta.to.global.u64 	%rd41, %rd40;
	ld.param.u64 	%rd42, [loop_slice_fusion_76_param_11];
	ld.param.u64 	%rd43, [loop_slice_fusion_76_param_14];
	cvta.to.global.u64 	%rd44, %rd43;
	ld.param.u64 	%rd45, [loop_slice_fusion_76_param_12];
	ld.param.u64 	%rd46, [loop_slice_fusion_76_param_13];
	cvta.to.global.u64 	%rd47, %rd46;
	cvta.to.global.u64 	%rd48, %rd45;
	cvta.to.global.u64 	%rd49, %rd42;
	cvta.to.global.u64 	%rd50, %rd39;
	cvta.to.global.u64 	%rd51, %rd36;
	cvta.to.global.u64 	%rd52, %rd33;
	cvta.to.global.u64 	%rd53, %rd30;
	cvta.to.global.u64 	%rd54, %rd27;
	cvta.to.global.u64 	%rd55, %rd25;
	cvta.to.global.u64 	%rd56, %rd23;
	cvta.to.global.u64 	%rd57, %rd20;
	cvta.to.global.u64 	%rd58, %rd17;
	cvta.to.global.u64 	%rd59, %rd14;
	cvta.to.global.u64 	%rd60, %rd12;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %tid.x;
	shl.b32 	%r20, %r18, 7;
	or.b32  	%r1, %r20, %r19;
	mul.hi.u32 	%r21, %r1, -1431655765;
	shr.u32 	%r22, %r21, 2;
	mul.lo.s32 	%r23, %r22, 6;
	sub.s32 	%r24, %r1, %r23;
	shr.u32 	%r25, %r21, 6;
	cvt.u16.u32 	%rs1, %r25;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r26, %r1, 458129845;
	bfe.u32 	%r27, %r26, 9, 6;
	shr.u32 	%r28, %r21, 1;
	and.b32  	%r29, %r28, 30;
	shl.b32 	%r30, %r29, 1;
	or.b32  	%r31, %r30, 1;
	shl.b32 	%r32, %r31, 1;
	shl.b32 	%r33, %r31, 2;
	or.b32  	%r34, %r33, 2;
	or.b32  	%r35, %r33, 3;
	shl.b32 	%r36, %r35, 1;
	shl.b32 	%r37, %r35, 2;
	or.b32  	%r38, %r37, 2;
	shl.b16 	%rs7, %rs6, 10;
	cvt.u64.u32 	%rd5, %r27;
	cvt.u64.u32 	%rd6, %r24;
	cvt.u64.u32 	%rd62, %r38;
	cvt.u64.u16 	%rd63, %rs7;
	add.s64 	%rd64, %rd63, %rd62;
	mul.lo.s64 	%rd65, %rd64, 24;
	mul.wide.u32 	%rd66, %r27, 1228800;
	add.s64 	%rd67, %rd41, %rd66;
	add.s64 	%rd68, %rd67, %rd65;
	mul.wide.u32 	%rd69, %r24, 4;
	add.s64 	%rd70, %rd68, %rd69;
	ld.global.nc.f32 	%f1, [%rd70+24];
	cvt.u64.u16 	%rd7, %rs6;
	cvt.u32.u16 	%r39, %rs6;
	mul.wide.u32 	%rd71, %r39, 12264;
	mul.wide.u32 	%rd72, %r27, 613200;
	add.s64 	%rd73, %rd32, %rd72;
	add.s64 	%rd74, %rd73, %rd71;
	mul.wide.u32 	%rd75, %r36, 24;
	add.s64 	%rd76, %rd74, %rd75;
	add.s64 	%rd77, %rd76, %rd69;
	ld.global.nc.f32 	%f2, [%rd77+24];
	add.s64 	%rd78, %rd29, %rd72;
	add.s64 	%rd79, %rd78, %rd71;
	add.s64 	%rd80, %rd79, %rd75;
	add.s64 	%rd81, %rd80, %rd69;
	ld.global.nc.f32 	%f3, [%rd81+24];
	shr.u32 	%r40, %r24, 1;
	mul.wide.u32 	%rd82, %r40, 4;
	mul.wide.u32 	%rd83, %r27, 12;
	add.s64 	%rd84, %rd35, %rd83;
	add.s64 	%rd85, %rd84, %rd82;
	ld.global.nc.f32 	%f4, [%rd85];
	mul.wide.u32 	%rd86, %r27, 4;
	add.s64 	%rd87, %rd38, %rd86;
	ld.global.nc.f32 	%f5, [%rd87];
	cvt.u64.u32 	%rd88, %r37;
	add.s64 	%rd89, %rd63, %rd88;
	mul.lo.s64 	%rd90, %rd89, 24;
	add.s64 	%rd91, %rd67, %rd90;
	add.s64 	%rd92, %rd91, %rd69;
	ld.global.nc.f32 	%f6, [%rd92+96];
	mul.wide.u32 	%rd93, %r39, 6120;
	mul.wide.u32 	%rd94, %r27, 306000;
	add.s64 	%rd95, %rd47, %rd94;
	add.s64 	%rd96, %rd95, %rd93;
	mul.wide.u32 	%rd97, %r34, 24;
	add.s64 	%rd98, %rd96, %rd97;
	add.s64 	%rd99, %rd98, %rd69;
	ld.global.nc.f32 	%f7, [%rd99+24];
	add.s64 	%rd100, %rd44, %rd94;
	add.s64 	%rd101, %rd100, %rd93;
	add.s64 	%rd102, %rd101, %rd97;
	add.s64 	%rd103, %rd102, %rd69;
	ld.global.nc.f32 	%f8, [%rd103+24];
	add.s64 	%rd104, %rd48, %rd83;
	add.s64 	%rd105, %rd104, %rd82;
	ld.global.nc.f32 	%f9, [%rd105];
	add.s64 	%rd106, %rd49, %rd86;
	ld.global.nc.f32 	%f10, [%rd106];
	add.s64 	%rd107, %rd50, %rd94;
	add.s64 	%rd108, %rd107, %rd93;
	add.s64 	%rd109, %rd108, %rd97;
	add.s64 	%rd110, %rd109, %rd69;
	ld.global.nc.f32 	%f11, [%rd110+24];
	mul.wide.u32 	%rd111, %r39, 3048;
	mul.wide.u32 	%rd112, %r27, 152400;
	add.s64 	%rd113, %rd52, %rd112;
	add.s64 	%rd114, %rd113, %rd111;
	mul.wide.u32 	%rd115, %r32, 24;
	add.s64 	%rd116, %rd114, %rd115;
	add.s64 	%rd117, %rd116, %rd69;
	ld.global.nc.f32 	%f12, [%rd117+24];
	add.s64 	%rd118, %rd51, %rd112;
	add.s64 	%rd119, %rd118, %rd111;
	add.s64 	%rd120, %rd119, %rd115;
	add.s64 	%rd121, %rd120, %rd69;
	ld.global.nc.f32 	%f13, [%rd121+24];
	add.s64 	%rd122, %rd22, %rd83;
	add.s64 	%rd123, %rd122, %rd82;
	ld.global.nc.f32 	%f14, [%rd123];
	add.s64 	%rd124, %rd53, %rd86;
	ld.global.nc.f32 	%f15, [%rd124];
	add.s64 	%rd125, %rd54, %rd112;
	add.s64 	%rd126, %rd125, %rd111;
	add.s64 	%rd127, %rd126, %rd115;
	add.s64 	%rd128, %rd127, %rd69;
	ld.global.nc.f32 	%f16, [%rd128+24];
	mul.wide.u32 	%rd129, %r39, 1512;
	mul.wide.u32 	%rd130, %r27, 75600;
	add.s64 	%rd131, %rd56, %rd130;
	add.s64 	%rd132, %rd131, %rd129;
	mul.wide.u32 	%rd133, %r30, 24;
	add.s64 	%rd134, %rd132, %rd133;
	add.s64 	%rd135, %rd134, %rd69;
	ld.global.nc.f32 	%f17, [%rd135+24];
	add.s64 	%rd136, %rd55, %rd130;
	add.s64 	%rd137, %rd136, %rd129;
	add.s64 	%rd138, %rd137, %rd133;
	add.s64 	%rd139, %rd138, %rd69;
	ld.global.nc.f32 	%f18, [%rd139+24];
	add.s64 	%rd140, %rd19, %rd83;
	add.s64 	%rd141, %rd140, %rd82;
	ld.global.nc.f32 	%f19, [%rd141];
	add.s64 	%rd142, %rd57, %rd86;
	ld.global.nc.f32 	%f20, [%rd142];
	mul.wide.u32 	%rd143, %r39, 1536;
	mul.wide.u32 	%rd144, %r27, 76800;
	add.s64 	%rd145, %rd58, %rd144;
	add.s64 	%rd146, %rd145, %rd143;
	add.s64 	%rd147, %rd146, %rd133;
	add.s64 	%rd148, %rd147, %rd69;
	ld.global.nc.f32 	%f21, [%rd148+48];
	cvt.u64.u32 	%rd8, %r29;
	mul.wide.u32 	%rd149, %r39, 744;
	mul.wide.u32 	%rd150, %r27, 37200;
	add.s64 	%rd151, %rd60, %rd150;
	add.s64 	%rd152, %rd151, %rd149;
	mul.wide.u32 	%rd153, %r29, 24;
	add.s64 	%rd154, %rd152, %rd153;
	add.s64 	%rd155, %rd154, %rd69;
	ld.global.nc.f32 	%f22, [%rd155];
	add.s64 	%rd156, %rd59, %rd150;
	add.s64 	%rd157, %rd156, %rd149;
	add.s64 	%rd158, %rd157, %rd153;
	add.s64 	%rd159, %rd158, %rd69;
	ld.global.nc.f32 	%f23, [%rd159];
	add.s64 	%rd160, %rd16, %rd83;
	add.s64 	%rd161, %rd160, %rd82;
	ld.global.nc.f32 	%f24, [%rd161];
	mul.rn.f32 	%f30, %f24, 0f3F22F983;
	cvt.rni.s32.f32 	%r77, %f30;
	cvt.rn.f32.s32 	%f31, %r77;
	fma.rn.f32 	%f32, %f31, 0fBFC90FDA, %f24;
	fma.rn.f32 	%f33, %f31, 0fB3A22168, %f32;
	fma.rn.f32 	%f78, %f31, 0fA7C234C5, %f33;
	abs.f32 	%f26, %f24;
	setp.ltu.f32 	%p1, %f26, 0f47CE4780;
	mov.f32 	%f77, 0f00000000;
	@%p1 bra 	$L__BB132_8;
	setp.neu.f32 	%p2, %f26, 0f7F800000;
	@%p2 bra 	$L__BB132_3;
	mul.rn.f32 	%f78, %f24, %f77;
	mov.b32 	%r77, 0;
	bra.uni 	$L__BB132_8;
$L__BB132_3:
	add.u64 	%rd4, %SPL, 0;
	mov.b32 	%r3, %f24;
	shr.u32 	%r4, %r3, 23;
	and.b32  	%r42, %r4, 224;
	add.s32 	%r43, %r42, -128;
	shl.b32 	%r44, %r3, 8;
	or.b32  	%r48, %r44, -2147483648;
	shr.u32 	%r6, %r43, 5;
	mov.b32 	%r74, 0;
	mov.u64 	%rd183, 0;
	mov.u64 	%rd163, __cudart_i2opi_f;
$L__BB132_4:
	.pragma "nounroll";
	add.s64 	%rd164, %rd163, %rd183;
	ld.global.nc.u32 	%r47, [%rd164];
	// begin inline asm
	{
	mad.lo.cc.u32   %r45, %r47, %r48, %r74;
	madc.hi.u32     %r74, %r47, %r48,  0;
	}
	// end inline asm
	add.s64 	%rd165, %rd4, %rd183;
	st.local.u32 	[%rd165], %r45;
	add.s64 	%rd183, %rd183, 4;
	cvt.u32.u64 	%r50, %rd183;
	setp.ne.s32 	%p3, %r50, 24;
	@%p3 bra 	$L__BB132_4;
	st.local.u32 	[%rd4+24], %r74;
	and.b32  	%r9, %r4, 31;
	mul.wide.u32 	%rd166, %r6, 4;
	sub.s64 	%rd11, %rd4, %rd166;
	ld.local.u32 	%r75, [%rd11+24];
	ld.local.u32 	%r76, [%rd11+20];
	setp.eq.s32 	%p4, %r9, 0;
	@%p4 bra 	$L__BB132_7;
	shl.b32 	%r51, %r76, %r9;
	shl.b32 	%r52, %r75, %r9;
	mov.b32 	%r53, 32;
	sub.s32 	%r54, %r53, %r9;
	shr.u32 	%r55, %r76, %r54;
	add.s32 	%r75, %r55, %r52;
	ld.local.u32 	%r56, [%rd11+16];
	shr.u32 	%r57, %r56, %r54;
	add.s32 	%r76, %r57, %r51;
$L__BB132_7:
	shr.u32 	%r58, %r75, 30;
	shr.u32 	%r59, %r76, 30;
	shl.b32 	%r60, %r75, 2;
	or.b32  	%r61, %r60, %r59;
	shl.b32 	%r62, %r76, 2;
	bfe.u32 	%r63, %r75, 29, 1;
	add.s32 	%r64, %r63, %r58;
	neg.s32 	%r65, %r64;
	setp.lt.s32 	%p5, %r3, 0;
	selp.b32 	%r77, %r65, %r64, %p5;
	xor.b32  	%r66, %r61, %r3;
	bfe.s32 	%r67, %r75, 29, 1;
	xor.b32  	%r68, %r67, %r61;
	xor.b32  	%r69, %r67, %r62;
	cvt.u64.u32 	%rd167, %r68;
	shl.b64 	%rd168, %rd167, 32;
	cvt.u64.u32 	%rd169, %r69;
	or.b64  	%rd170, %rd168, %rd169;
	cvt.rn.f64.s64 	%fd1, %rd170;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f34, %fd2;
	neg.f32 	%f35, %f34;
	setp.lt.s32 	%p6, %r66, 0;
	selp.f32 	%f78, %f35, %f34, %p6;
$L__BB132_8:
	add.rn.f32 	%f37, %f2, %f3;
	mul.rn.f32 	%f38, %f5, %f6;
	mul.rn.f32 	%f39, %f4, %f38;
	add.rn.f32 	%f40, %f37, %f39;
	add.rn.f32 	%f41, %f1, %f40;
	add.rn.f32 	%f42, %f7, %f8;
	mul.rn.f32 	%f43, %f10, %f11;
	mul.rn.f32 	%f44, %f9, %f43;
	add.rn.f32 	%f45, %f42, %f44;
	add.rn.f32 	%f46, %f41, %f45;
	add.rn.f32 	%f47, %f12, %f13;
	mul.rn.f32 	%f48, %f15, %f16;
	mul.rn.f32 	%f49, %f14, %f48;
	add.rn.f32 	%f50, %f47, %f49;
	add.rn.f32 	%f51, %f46, %f50;
	add.rn.f32 	%f52, %f17, %f18;
	mul.rn.f32 	%f53, %f20, %f21;
	mul.rn.f32 	%f54, %f19, %f53;
	add.rn.f32 	%f55, %f52, %f54;
	add.rn.f32 	%f56, %f51, %f55;
	add.s32 	%r71, %r77, 1;
	mul.rn.f32 	%f57, %f78, %f78;
	and.b32  	%r72, %r77, 1;
	setp.eq.b32 	%p7, %r72, 1;
	selp.f32 	%f58, %f78, 0f3F800000, %p7;
	fma.rn.f32 	%f59, %f57, %f58, 0f00000000;
	fma.rn.f32 	%f60, %f57, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f61, 0fB94D4153, %f60, %p7;
	selp.f32 	%f62, 0f3C0885E4, 0f3D2AAABB, %p7;
	fma.rn.f32 	%f63, %f61, %f57, %f62;
	selp.f32 	%f64, 0fBE2AAAA8, 0fBEFFFFFF, %p7;
	fma.rn.f32 	%f65, %f63, %f57, %f64;
	fma.rn.f32 	%f66, %f65, %f59, %f58;
	and.b32  	%r73, %r71, 2;
	setp.eq.s32 	%p8, %r73, 0;
	sub.rn.f32 	%f68, %f77, %f66;
	selp.f32 	%f69, %f66, %f68, %p8;
	add.rn.f32 	%f70, %f22, %f23;
	shl.b64 	%rd171, %rd5, 2;
	add.s64 	%rd172, %rd2, %rd171;
	ld.global.nc.f32 	%f71, [%rd172];
	mul.lo.s64 	%rd173, %rd5, 38400;
	add.s64 	%rd174, %rd3, %rd173;
	mul.lo.s64 	%rd175, %rd7, 768;
	add.s64 	%rd176, %rd174, %rd175;
	mul.lo.s64 	%rd177, %rd8, 24;
	add.s64 	%rd178, %rd176, %rd177;
	shl.b64 	%rd179, %rd6, 2;
	add.s64 	%rd180, %rd178, %rd179;
	ld.global.nc.f32 	%f72, [%rd180+24];
	mul.rn.f32 	%f73, %f71, %f72;
	mul.rn.f32 	%f74, %f73, %f69;
	add.rn.f32 	%f75, %f70, %f74;
	add.rn.f32 	%f76, %f56, %f75;
	mul.wide.u32 	%rd181, %r1, 4;
	add.s64 	%rd182, %rd1, %rd181;
	st.global.f32 	[%rd182], %f76;
	ret;

}
	// .globl	loop_transpose_fusion_108
.visible .entry loop_transpose_fusion_108(
	.param .u64 loop_transpose_fusion_108_param_0,
	.param .u64 loop_transpose_fusion_108_param_1,
	.param .u64 loop_transpose_fusion_108_param_2,
	.param .u64 loop_transpose_fusion_108_param_3,
	.param .u64 loop_transpose_fusion_108_param_4
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot133[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<121>;
	.reg .f32 	%f<85>;
	.reg .b64 	%rd<59>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot133;
	ld.param.u64 	%rd15, [loop_transpose_fusion_108_param_0];
	ld.param.u64 	%rd16, [loop_transpose_fusion_108_param_4];
	ld.param.u64 	%rd17, [loop_transpose_fusion_108_param_1];
	ld.param.u64 	%rd18, [loop_transpose_fusion_108_param_3];
	ld.param.u64 	%rd19, [loop_transpose_fusion_108_param_2];
	cvta.to.global.u64 	%rd3, %rd19;
	cvta.to.global.u64 	%rd20, %rd17;
	cvta.to.global.u64 	%rd4, %rd15;
	add.u64 	%rd5, %SPL, 0;
	mov.u32 	%r34, %ctaid.x;
	shl.b32 	%r35, %r34, 7;
	mov.u32 	%r36, %tid.x;
	or.b32  	%r1, %r35, %r36;
	cvt.u16.u32 	%rs3, %r34;
	mul.hi.u16 	%rs4, %rs3, 23943;
	sub.s16 	%rs5, %rs3, %rs4;
	shr.u16 	%rs6, %rs5, 1;
	add.s16 	%rs7, %rs6, %rs4;
	shr.u16 	%rs8, %rs7, 8;
	mul.hi.u32 	%r37, %r1, 91625969;
	bfe.u32 	%r38, %r37, 4, 6;
	mul.hi.u32 	%r39, %r1, -2004318071;
	shr.u32 	%r40, %r39, 3;
	cvt.u16.u32 	%rs9, %r40;
	shr.u16 	%rs10, %rs9, 1;
	mul.hi.u16 	%rs11, %rs10, 5243;
	shr.u16 	%rs12, %rs11, 1;
	mul.lo.s16 	%rs13, %rs12, 50;
	sub.s16 	%rs1, %rs9, %rs13;
	mul.lo.s32 	%r41, %r40, 15;
	sub.s32 	%r2, %r1, %r41;
	shl.b16 	%rs2, %rs8, 1;
	cvt.u64.u32 	%rd7, %r38;
	mul.wide.u32 	%rd23, %r38, 12;
	add.s64 	%rd24, %rd20, %rd23;
	cvt.u32.u16 	%r42, %rs8;
	mul.wide.u32 	%rd25, %r42, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f12, [%rd26];
	add.rn.f32 	%f1, %f12, %f12;
	mul.rn.f32 	%f13, %f1, 0f3F22F983;
	cvt.rni.s32.f32 	%r120, %f13;
	cvt.rn.f32.s32 	%f14, %r120;
	fma.rn.f32 	%f15, %f14, 0fBFC90FDA, %f1;
	fma.rn.f32 	%f16, %f14, 0fB3A22168, %f15;
	fma.rn.f32 	%f84, %f14, 0fA7C234C5, %f16;
	abs.f32 	%f3, %f1;
	setp.ltu.f32 	%p1, %f3, 0f47CE4780;
	setp.neu.f32 	%p17, %f3, 0f7F800000;
	mov.f32 	%f82, 0f00000000;
	mov.u32 	%r116, %r120;
	mov.f32 	%f83, %f84;
	@%p1 bra 	$L__BB133_8;
	@%p17 bra 	$L__BB133_3;
	mul.rn.f32 	%f83, %f1, %f82;
	mov.b32 	%r116, 0;
	bra.uni 	$L__BB133_8;
$L__BB133_3:
	mov.b32 	%r4, %f1;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r44, %r5, 224;
	add.s32 	%r45, %r44, -128;
	shl.b32 	%r46, %r4, 8;
	or.b32  	%r50, %r46, -2147483648;
	shr.u32 	%r7, %r45, 5;
	mov.b32 	%r113, 0;
	mov.u64 	%rd57, 0;
	mov.u64 	%rd28, __cudart_i2opi_f;
$L__BB133_4:
	.pragma "nounroll";
	add.s64 	%rd29, %rd28, %rd57;
	ld.global.nc.u32 	%r49, [%rd29];
	// begin inline asm
	{
	mad.lo.cc.u32   %r47, %r49, %r50, %r113;
	madc.hi.u32     %r113, %r49, %r50,  0;
	}
	// end inline asm
	add.s64 	%rd30, %rd5, %rd57;
	st.local.u32 	[%rd30], %r47;
	add.s64 	%rd57, %rd57, 4;
	cvt.u32.u64 	%r52, %rd57;
	setp.ne.s32 	%p3, %r52, 24;
	@%p3 bra 	$L__BB133_4;
	st.local.u32 	[%rd5+24], %r113;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd31, %r7, 4;
	sub.s64 	%rd10, %rd5, %rd31;
	ld.local.u32 	%r114, [%rd10+24];
	ld.local.u32 	%r115, [%rd10+20];
	setp.eq.s32 	%p4, %r10, 0;
	@%p4 bra 	$L__BB133_7;
	shl.b32 	%r53, %r115, %r10;
	shl.b32 	%r54, %r114, %r10;
	mov.b32 	%r55, 32;
	sub.s32 	%r56, %r55, %r10;
	shr.u32 	%r57, %r115, %r56;
	add.s32 	%r114, %r57, %r54;
	ld.local.u32 	%r58, [%rd10+16];
	shr.u32 	%r59, %r58, %r56;
	add.s32 	%r115, %r59, %r53;
$L__BB133_7:
	shr.u32 	%r60, %r114, 30;
	shr.u32 	%r61, %r115, 30;
	shl.b32 	%r62, %r114, 2;
	or.b32  	%r63, %r62, %r61;
	shl.b32 	%r64, %r115, 2;
	bfe.u32 	%r65, %r114, 29, 1;
	add.s32 	%r66, %r65, %r60;
	neg.s32 	%r67, %r66;
	setp.lt.s32 	%p5, %r4, 0;
	selp.b32 	%r116, %r67, %r66, %p5;
	xor.b32  	%r68, %r63, %r4;
	bfe.s32 	%r69, %r114, 29, 1;
	xor.b32  	%r70, %r69, %r63;
	xor.b32  	%r71, %r69, %r64;
	cvt.u64.u32 	%rd32, %r70;
	shl.b64 	%rd33, %rd32, 32;
	cvt.u64.u32 	%rd34, %r71;
	or.b64  	%rd35, %rd33, %rd34;
	cvt.rn.f64.s64 	%fd1, %rd35;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f17, %fd2;
	neg.f32 	%f18, %f17;
	setp.lt.s32 	%p6, %r68, 0;
	selp.f32 	%f83, %f18, %f17, %p6;
$L__BB133_8:
	cvta.to.global.u64 	%rd1, %rd16;
	cvta.to.global.u64 	%rd2, %rd18;
	shl.b64 	%rd36, %rd7, 2;
	add.s64 	%rd37, %rd3, %rd36;
	ld.global.nc.f32 	%f7, [%rd37];
	mul.lo.s64 	%rd38, %rd7, 19200;
	add.s64 	%rd39, %rd4, %rd38;
	cvt.u32.u16 	%r73, %rs1;
	mul.wide.u32 	%rd40, %r73, 384;
	add.s64 	%rd41, %rd39, %rd40;
	mul.wide.u32 	%rd42, %r2, 24;
	add.s64 	%rd43, %rd41, %rd42;
	cvt.u32.u16 	%r74, %rs2;
	mul.wide.u32 	%rd44, %r74, 4;
	add.s64 	%rd11, %rd43, %rd44;
	ld.global.nc.f32 	%f8, [%rd11+28];
	@%p1 bra 	$L__BB133_16;
	@%p17 bra 	$L__BB133_11;
	mul.rn.f32 	%f84, %f1, %f82;
	mov.b32 	%r120, 0;
	bra.uni 	$L__BB133_16;
$L__BB133_11:
	mov.b32 	%r19, %f1;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r76, %r20, 224;
	add.s32 	%r77, %r76, -128;
	shl.b32 	%r78, %r19, 8;
	or.b32  	%r82, %r78, -2147483648;
	shr.u32 	%r22, %r77, 5;
	mov.b32 	%r117, 0;
	mov.u64 	%rd58, 0;
	mov.u64 	%rd46, __cudart_i2opi_f;
$L__BB133_12:
	.pragma "nounroll";
	add.s64 	%rd47, %rd46, %rd58;
	ld.global.nc.u32 	%r81, [%rd47];
	// begin inline asm
	{
	mad.lo.cc.u32   %r79, %r81, %r82, %r117;
	madc.hi.u32     %r117, %r81, %r82,  0;
	}
	// end inline asm
	add.s64 	%rd48, %rd5, %rd58;
	st.local.u32 	[%rd48], %r79;
	add.s64 	%rd58, %rd58, 4;
	cvt.u32.u64 	%r84, %rd58;
	setp.ne.s32 	%p9, %r84, 24;
	@%p9 bra 	$L__BB133_12;
	st.local.u32 	[%rd5+24], %r117;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd49, %r22, 4;
	sub.s64 	%rd14, %rd5, %rd49;
	ld.local.u32 	%r118, [%rd14+24];
	ld.local.u32 	%r119, [%rd14+20];
	setp.eq.s32 	%p10, %r25, 0;
	@%p10 bra 	$L__BB133_15;
	shl.b32 	%r85, %r119, %r25;
	shl.b32 	%r86, %r118, %r25;
	mov.b32 	%r87, 32;
	sub.s32 	%r88, %r87, %r25;
	shr.u32 	%r89, %r119, %r88;
	add.s32 	%r118, %r89, %r86;
	ld.local.u32 	%r90, [%rd14+16];
	shr.u32 	%r91, %r90, %r88;
	add.s32 	%r119, %r91, %r85;
$L__BB133_15:
	shr.u32 	%r92, %r118, 30;
	shr.u32 	%r93, %r119, 30;
	shl.b32 	%r94, %r118, 2;
	or.b32  	%r95, %r94, %r93;
	shl.b32 	%r96, %r119, 2;
	bfe.u32 	%r97, %r118, 29, 1;
	add.s32 	%r98, %r97, %r92;
	neg.s32 	%r99, %r98;
	setp.lt.s32 	%p11, %r19, 0;
	selp.b32 	%r120, %r99, %r98, %p11;
	xor.b32  	%r100, %r95, %r19;
	bfe.s32 	%r101, %r118, 29, 1;
	xor.b32  	%r102, %r101, %r95;
	xor.b32  	%r103, %r101, %r96;
	cvt.u64.u32 	%rd50, %r102;
	shl.b64 	%rd51, %rd50, 32;
	cvt.u64.u32 	%rd52, %r103;
	or.b64  	%rd53, %rd51, %rd52;
	cvt.rn.f64.s64 	%fd3, %rd53;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f20, %fd4;
	neg.f32 	%f21, %f20;
	setp.lt.s32 	%p12, %r100, 0;
	selp.f32 	%f84, %f21, %f20, %p12;
$L__BB133_16:
	and.b32  	%r105, %r116, 2;
	setp.eq.s32 	%p13, %r105, 0;
	and.b32  	%r106, %r116, 1;
	setp.eq.b32 	%p14, %r106, 1;
	mul.rn.f32 	%f23, %f83, %f83;
	fma.rn.f32 	%f24, %f23, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f25, %f24, 0fB94D4153, %p14;
	selp.f32 	%f26, 0f3D2AAABB, 0f3C0885E4, %p14;
	fma.rn.f32 	%f27, %f25, %f23, %f26;
	selp.f32 	%f28, 0fBEFFFFFF, 0fBE2AAAA8, %p14;
	fma.rn.f32 	%f29, %f27, %f23, %f28;
	selp.f32 	%f30, 0f3F800000, %f83, %p14;
	fma.rn.f32 	%f31, %f23, %f30, 0f00000000;
	fma.rn.f32 	%f32, %f29, %f31, %f30;
	sub.rn.f32 	%f34, %f82, %f32;
	selp.f32 	%f35, %f32, %f34, %p13;
	fma.rn.f32 	%f36, %f7, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f37, %f36;
	mov.f32 	%f38, 0f4B400001;
	mov.f32 	%f39, 0f437C0000;
	fma.rm.f32 	%f40, %f37, %f39, %f38;
	add.rn.f32 	%f41, %f40, 0fCB40007F;
	neg.f32 	%f42, %f41;
	fma.rn.f32 	%f43, %f7, 0f3FB8AA3B, %f42;
	fma.rn.f32 	%f44, %f7, 0f32A57060, %f43;
	ex2.approx.ftz.f32 	%f45, %f44;
	mov.b32 	%r107, %f40;
	shl.b32 	%r108, %r107, 23;
	mov.b32 	%f46, %r108;
	mul.rn.f32 	%f47, %f45, %f46;
	neg.f32 	%f48, %f47;
	sub.rn.f32 	%f49, %f48, %f47;
	add.rn.f32 	%f50, %f49, %f49;
	add.rn.f32 	%f51, %f50, %f50;
	add.rn.f32 	%f52, %f51, %f51;
	add.rn.f32 	%f53, %f52, %f52;
	fma.rn.f32 	%f54, %f53, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f55, %f54;
	fma.rm.f32 	%f56, %f55, %f39, %f38;
	add.rn.f32 	%f57, %f56, 0fCB40007F;
	neg.f32 	%f58, %f57;
	fma.rn.f32 	%f59, %f53, 0f3FB8AA3B, %f58;
	fma.rn.f32 	%f60, %f53, 0f32A57060, %f59;
	ex2.approx.ftz.f32 	%f61, %f60;
	mov.b32 	%r109, %f56;
	shl.b32 	%r110, %r109, 23;
	mov.b32 	%f62, %r110;
	mul.rn.f32 	%f63, %f61, %f62;
	mul.rn.f32 	%f64, %f8, %f63;
	mul.rn.f32 	%f65, %f35, %f64;
	mul.rn.f32 	%f66, %f84, %f84;
	and.b32  	%r111, %r120, 1;
	setp.eq.b32 	%p15, %r111, 1;
	selp.f32 	%f67, 0f3F800000, %f84, %p15;
	fma.rn.f32 	%f68, %f66, %f67, 0f00000000;
	fma.rn.f32 	%f69, %f66, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f70, %f69, 0fB94D4153, %p15;
	selp.f32 	%f71, 0f3D2AAABB, 0f3C0885E4, %p15;
	fma.rn.f32 	%f72, %f70, %f66, %f71;
	selp.f32 	%f73, 0fBEFFFFFF, 0fBE2AAAA8, %p15;
	fma.rn.f32 	%f74, %f72, %f66, %f73;
	fma.rn.f32 	%f75, %f74, %f68, %f67;
	and.b32  	%r112, %r120, 2;
	setp.eq.s32 	%p16, %r112, 0;
	sub.rn.f32 	%f76, %f82, %f75;
	selp.f32 	%f77, %f75, %f76, %p16;
	ld.global.nc.f32 	%f78, [%rd11+24];
	mul.rn.f32 	%f79, %f78, %f63;
	neg.f32 	%f80, %f77;
	mul.rn.f32 	%f81, %f79, %f80;
	mul.wide.u32 	%rd54, %r1, 4;
	add.s64 	%rd55, %rd2, %rd54;
	st.global.f32 	[%rd55], %f65;
	add.s64 	%rd56, %rd1, %rd54;
	st.global.f32 	[%rd56], %f81;
	ret;

}
	// .globl	loop_broadcast_fusion_33
.visible .entry loop_broadcast_fusion_33(
	.param .u64 loop_broadcast_fusion_33_param_0
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<5>;

	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 10;
	shl.b32 	%r4, %r2, 2;
	or.b32  	%r5, %r3, %r4;
	setp.lt.u32 	%p1, %r5, 288000;
	@%p1 bra 	$L__BB134_2;
	bra.uni 	$L__BB134_1;
$L__BB134_2:
	ld.param.u64 	%rd2, [loop_broadcast_fusion_33_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.u32 	%rd4, %r5, 4;
	add.s64 	%rd1, %rd3, %rd4;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd1], {%f1, %f1, %f1, %f1};
$L__BB134_1:
	ret;

}
	// .globl	input_scatter_fusion_238
.visible .entry input_scatter_fusion_238(
	.param .u64 input_scatter_fusion_238_param_0,
	.param .u64 input_scatter_fusion_238_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<13>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_238_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_238_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -2004318071;
	shr.u32 	%r6, %r5, 3;
	mul.lo.s32 	%r7, %r6, 15;
	sub.s32 	%r8, %r4, %r7;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r9, %r4, 91625969;
	bfe.u32 	%r10, %r9, 4, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, 23943;
	sub.s16 	%rs9, %rs7, %rs8;
	shr.u16 	%rs10, %rs9, 1;
	add.s16 	%rs11, %rs10, %rs8;
	shr.u16 	%rs12, %rs11, 7;
	and.b16  	%rs13, %rs12, 510;
	cvt.u32.u16 	%r11, %rs13;
	mul.wide.u32 	%rd5, %r11, 192000;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r10, 3000;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r12, %rs6;
	mul.wide.u32 	%rd9, %r12, 60;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r8, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+192000];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+192000], %f3;
	ret;

}
	// .globl	wrapped_transpose_244
.visible .entry wrapped_transpose_244(
	.param .u64 wrapped_transpose_244_param_0,
	.param .u64 wrapped_transpose_244_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<24>;
	.reg .b32 	%r<41>;
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<34>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 9;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	setp.lt.u32 	%p1, %r1, 288000;
	@%p1 bra 	$L__BB136_2;
	bra.uni 	$L__BB136_1;
$L__BB136_2:
	ld.param.u64 	%rd3, [wrapped_transpose_244_param_0];
	ld.param.u64 	%rd4, [wrapped_transpose_244_param_1];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd3;
	mul.hi.u32 	%r6, %r1, 1954687339;
	shr.u32 	%r7, %r6, 11;
	or.b32  	%r8, %r1, 3;
	mul.hi.u32 	%r9, %r8, -1240768329;
	shr.u32 	%r10, %r9, 6;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r8, 715827883;
	mul.hi.u32 	%r12, %r11, 572662307;
	shr.u32 	%r13, %r12, 1;
	mul.lo.s32 	%r14, %r13, 15;
	sub.s32 	%r15, %r11, %r14;
	mul.lo.s32 	%r16, %r11, 6;
	sub.s32 	%r17, %r8, %r16;
	or.b32  	%r18, %r1, 2;
	mul.hi.u32 	%r19, %r18, -1240768329;
	shr.u32 	%r20, %r19, 6;
	cvt.u16.u32 	%rs7, %r20;
	shr.u16 	%rs8, %rs7, 1;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	mul.lo.s16 	%rs11, %rs10, 50;
	sub.s16 	%rs12, %rs7, %rs11;
	mul.hi.u32 	%r21, %r18, 715827883;
	mul.hi.u32 	%r22, %r21, 572662307;
	shr.u32 	%r23, %r22, 1;
	mul.lo.s32 	%r24, %r23, 15;
	sub.s32 	%r25, %r21, %r24;
	mul.lo.s32 	%r26, %r21, 6;
	sub.s32 	%r27, %r18, %r26;
	or.b32  	%r28, %r1, 1;
	mul.hi.u32 	%r29, %r1, -1240768329;
	shr.u32 	%r30, %r29, 6;
	cvt.u16.u32 	%rs13, %r30;
	shr.u16 	%rs14, %rs13, 1;
	mul.hi.u16 	%rs15, %rs14, 5243;
	shr.u16 	%rs16, %rs15, 1;
	mul.lo.s16 	%rs17, %rs16, 50;
	sub.s16 	%rs18, %rs13, %rs17;
	mul.hi.u32 	%r31, %r1, 715827883;
	cvt.u16.u32 	%rs19, %r31;
	mul.hi.u16 	%rs20, %rs19, -30583;
	shr.u16 	%rs21, %rs20, 3;
	mul.lo.s16 	%rs22, %rs21, 15;
	sub.s16 	%rs23, %rs19, %rs22;
	mul.hi.u32 	%r32, %r28, 715827883;
	mul.lo.s32 	%r33, %r32, 6;
	sub.s32 	%r34, %r28, %r33;
	mul.lo.s32 	%r35, %r31, 6;
	sub.s32 	%r36, %r1, %r35;
	mul.wide.u32 	%rd5, %r36, 192000;
	add.s64 	%rd6, %rd2, %rd5;
	mul.wide.u32 	%rd7, %r7, 3000;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r37, %rs18;
	mul.wide.u32 	%rd9, %r37, 60;
	add.s64 	%rd10, %rd8, %rd9;
	cvt.u32.u16 	%r38, %rs23;
	mul.wide.u32 	%rd11, %r38, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r1, 4;
	add.s64 	%rd14, %rd1, %rd13;
	mul.wide.u32 	%rd15, %r34, 192000;
	add.s64 	%rd16, %rd2, %rd15;
	add.s64 	%rd17, %rd16, %rd7;
	add.s64 	%rd18, %rd17, %rd9;
	add.s64 	%rd19, %rd18, %rd11;
	ld.global.nc.f32 	%f2, [%rd19];
	mul.wide.u32 	%rd20, %r27, 192000;
	add.s64 	%rd21, %rd2, %rd20;
	add.s64 	%rd22, %rd21, %rd7;
	cvt.u32.u16 	%r39, %rs12;
	mul.wide.u32 	%rd23, %r39, 60;
	add.s64 	%rd24, %rd22, %rd23;
	mul.wide.u32 	%rd25, %r25, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f3, [%rd26];
	mul.wide.u32 	%rd27, %r17, 192000;
	add.s64 	%rd28, %rd2, %rd27;
	add.s64 	%rd29, %rd28, %rd7;
	cvt.u32.u16 	%r40, %rs6;
	mul.wide.u32 	%rd30, %r40, 60;
	add.s64 	%rd31, %rd29, %rd30;
	mul.wide.u32 	%rd32, %r15, 4;
	add.s64 	%rd33, %rd31, %rd32;
	ld.global.nc.f32 	%f4, [%rd33];
	st.global.v4.f32 	[%rd14], {%f1, %f2, %f3, %f4};
$L__BB136_1:
	ret;

}
	// .globl	input_scatter_fusion_239
.visible .entry input_scatter_fusion_239(
	.param .u64 input_scatter_fusion_239_param_0,
	.param .u64 input_scatter_fusion_239_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<13>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_239_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_239_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, -2004318071;
	shr.u32 	%r6, %r5, 3;
	mul.lo.s32 	%r7, %r6, 15;
	sub.s32 	%r8, %r4, %r7;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r9, %r4, 91625969;
	bfe.u32 	%r10, %r9, 4, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, 23943;
	sub.s16 	%rs9, %rs7, %rs8;
	shr.u16 	%rs10, %rs9, 1;
	add.s16 	%rs11, %rs10, %rs8;
	shr.u16 	%rs12, %rs11, 7;
	and.b16  	%rs13, %rs12, 510;
	cvt.u32.u16 	%r11, %rs13;
	mul.wide.u32 	%rd5, %r11, 192000;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r10, 3000;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r12, %rs6;
	mul.wide.u32 	%rd9, %r12, 60;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r8, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	loop_slice_fusion_77
.visible .entry loop_slice_fusion_77(
	.param .u64 loop_slice_fusion_77_param_0,
	.param .u64 loop_slice_fusion_77_param_1,
	.param .u64 loop_slice_fusion_77_param_2,
	.param .u64 loop_slice_fusion_77_param_3,
	.param .u64 loop_slice_fusion_77_param_4,
	.param .u64 loop_slice_fusion_77_param_5,
	.param .u64 loop_slice_fusion_77_param_6,
	.param .u64 loop_slice_fusion_77_param_7,
	.param .u64 loop_slice_fusion_77_param_8,
	.param .u64 loop_slice_fusion_77_param_9,
	.param .u64 loop_slice_fusion_77_param_10,
	.param .u64 loop_slice_fusion_77_param_11,
	.param .u64 loop_slice_fusion_77_param_12,
	.param .u64 loop_slice_fusion_77_param_13,
	.param .u64 loop_slice_fusion_77_param_14,
	.param .u64 loop_slice_fusion_77_param_15,
	.param .u64 loop_slice_fusion_77_param_16,
	.param .u64 loop_slice_fusion_77_param_17,
	.param .u64 loop_slice_fusion_77_param_18,
	.param .u64 loop_slice_fusion_77_param_19,
	.param .u64 loop_slice_fusion_77_param_20,
	.param .u64 loop_slice_fusion_77_param_21,
	.param .u64 loop_slice_fusion_77_param_22,
	.param .u64 loop_slice_fusion_77_param_23,
	.param .u64 loop_slice_fusion_77_param_24,
	.param .u64 loop_slice_fusion_77_param_25,
	.param .u64 loop_slice_fusion_77_param_26,
	.param .u64 loop_slice_fusion_77_param_27,
	.param .u64 loop_slice_fusion_77_param_28,
	.param .u64 loop_slice_fusion_77_param_29
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot138[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<137>;
	.reg .f32 	%f<142>;
	.reg .b64 	%rd<229>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot138;
	ld.param.u64 	%rd21, [loop_slice_fusion_77_param_0];
	ld.param.u64 	%rd22, [loop_slice_fusion_77_param_29];
	ld.param.u64 	%rd23, [loop_slice_fusion_77_param_1];
	ld.param.u64 	%rd24, [loop_slice_fusion_77_param_28];
	ld.param.u64 	%rd25, [loop_slice_fusion_77_param_2];
	ld.param.u64 	%rd26, [loop_slice_fusion_77_param_27];
	cvta.to.global.u64 	%rd27, %rd26;
	ld.param.u64 	%rd28, [loop_slice_fusion_77_param_3];
	ld.param.u64 	%rd29, [loop_slice_fusion_77_param_26];
	cvta.to.global.u64 	%rd30, %rd29;
	ld.param.u64 	%rd31, [loop_slice_fusion_77_param_4];
	ld.param.u64 	%rd32, [loop_slice_fusion_77_param_25];
	cvta.to.global.u64 	%rd33, %rd32;
	ld.param.u64 	%rd34, [loop_slice_fusion_77_param_5];
	ld.param.u64 	%rd35, [loop_slice_fusion_77_param_24];
	ld.param.u64 	%rd36, [loop_slice_fusion_77_param_6];
	ld.param.u64 	%rd37, [loop_slice_fusion_77_param_23];
	cvta.to.global.u64 	%rd4, %rd37;
	ld.param.u64 	%rd38, [loop_slice_fusion_77_param_7];
	ld.param.u64 	%rd39, [loop_slice_fusion_77_param_22];
	cvta.to.global.u64 	%rd5, %rd39;
	ld.param.u64 	%rd40, [loop_slice_fusion_77_param_8];
	ld.param.u64 	%rd41, [loop_slice_fusion_77_param_21];
	cvta.to.global.u64 	%rd42, %rd41;
	ld.param.u64 	%rd43, [loop_slice_fusion_77_param_9];
	ld.param.u64 	%rd44, [loop_slice_fusion_77_param_20];
	cvta.to.global.u64 	%rd45, %rd44;
	ld.param.u64 	%rd46, [loop_slice_fusion_77_param_10];
	ld.param.u64 	%rd47, [loop_slice_fusion_77_param_19];
	cvta.to.global.u64 	%rd48, %rd47;
	ld.param.u64 	%rd49, [loop_slice_fusion_77_param_11];
	ld.param.u64 	%rd50, [loop_slice_fusion_77_param_18];
	cvta.to.global.u64 	%rd51, %rd50;
	ld.param.u64 	%rd52, [loop_slice_fusion_77_param_12];
	ld.param.u64 	%rd53, [loop_slice_fusion_77_param_17];
	cvta.to.global.u64 	%rd54, %rd53;
	ld.param.u64 	%rd55, [loop_slice_fusion_77_param_13];
	ld.param.u64 	%rd56, [loop_slice_fusion_77_param_16];
	cvta.to.global.u64 	%rd57, %rd56;
	ld.param.u64 	%rd58, [loop_slice_fusion_77_param_14];
	ld.param.u64 	%rd59, [loop_slice_fusion_77_param_15];
	cvta.to.global.u64 	%rd60, %rd59;
	cvta.to.global.u64 	%rd61, %rd58;
	cvta.to.global.u64 	%rd62, %rd55;
	cvta.to.global.u64 	%rd63, %rd52;
	cvta.to.global.u64 	%rd64, %rd49;
	cvta.to.global.u64 	%rd65, %rd46;
	cvta.to.global.u64 	%rd66, %rd43;
	cvta.to.global.u64 	%rd67, %rd40;
	cvta.to.global.u64 	%rd68, %rd38;
	cvta.to.global.u64 	%rd69, %rd36;
	cvta.to.global.u64 	%rd70, %rd34;
	cvta.to.global.u64 	%rd71, %rd31;
	cvta.to.global.u64 	%rd72, %rd28;
	cvta.to.global.u64 	%rd73, %rd25;
	cvta.to.global.u64 	%rd6, %rd23;
	cvta.to.global.u64 	%rd7, %rd21;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r35, %ctaid.x;
	mov.u32 	%r36, %tid.x;
	shl.b32 	%r37, %r35, 7;
	or.b32  	%r1, %r37, %r36;
	mul.hi.u32 	%r38, %r1, -1431655765;
	shr.u32 	%r39, %r38, 2;
	mul.lo.s32 	%r40, %r39, 6;
	sub.s32 	%r41, %r1, %r40;
	shr.u32 	%r42, %r38, 5;
	cvt.u16.u32 	%rs1, %r42;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r43, %r1, 458129845;
	bfe.u32 	%r44, %r43, 8, 6;
	shr.u32 	%r45, %r38, 1;
	and.b32  	%r2, %r45, 14;
	shl.b32 	%r46, %r2, 1;
	shl.b32 	%r47, %r2, 2;
	or.b32  	%r48, %r47, 2;
	or.b32  	%r49, %r47, 3;
	shl.b32 	%r50, %r49, 1;
	shl.b32 	%r51, %r49, 2;
	or.b32  	%r52, %r51, 2;
	or.b32  	%r53, %r51, 3;
	shl.b32 	%r54, %r53, 1;
	shl.b32 	%r55, %r53, 2;
	or.b32  	%r56, %r55, 2;
	shl.b16 	%rs7, %rs6, 10;
	cvt.u64.u32 	%rd10, %r44;
	cvt.u64.u32 	%rd11, %r41;
	cvt.u64.u32 	%rd76, %r56;
	cvt.u64.u16 	%rd77, %rs7;
	add.s64 	%rd78, %rd77, %rd76;
	mul.lo.s64 	%rd79, %rd78, 24;
	mul.wide.u32 	%rd80, %r44, 1228800;
	add.s64 	%rd81, %rd54, %rd80;
	add.s64 	%rd82, %rd81, %rd79;
	mul.wide.u32 	%rd83, %r41, 4;
	add.s64 	%rd84, %rd82, %rd83;
	ld.global.nc.f32 	%f1, [%rd84+24];
	cvt.u64.u16 	%rd12, %rs6;
	cvt.u32.u16 	%r57, %rs6;
	mul.wide.u32 	%rd85, %r57, 12264;
	mul.wide.u32 	%rd86, %r44, 613200;
	add.s64 	%rd87, %rd45, %rd86;
	add.s64 	%rd88, %rd87, %rd85;
	mul.wide.u32 	%rd89, %r54, 24;
	add.s64 	%rd90, %rd88, %rd89;
	add.s64 	%rd91, %rd90, %rd83;
	ld.global.nc.f32 	%f2, [%rd91+24];
	add.s64 	%rd92, %rd42, %rd86;
	add.s64 	%rd93, %rd92, %rd85;
	add.s64 	%rd94, %rd93, %rd89;
	add.s64 	%rd95, %rd94, %rd83;
	ld.global.nc.f32 	%f3, [%rd95+24];
	shr.u32 	%r58, %r41, 1;
	mul.wide.u32 	%rd96, %r58, 4;
	mul.wide.u32 	%rd97, %r44, 12;
	add.s64 	%rd98, %rd48, %rd97;
	add.s64 	%rd99, %rd98, %rd96;
	ld.global.nc.f32 	%f4, [%rd99];
	mul.wide.u32 	%rd100, %r44, 4;
	add.s64 	%rd101, %rd51, %rd100;
	ld.global.nc.f32 	%f5, [%rd101];
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd77, %rd102;
	mul.lo.s64 	%rd104, %rd103, 24;
	add.s64 	%rd105, %rd81, %rd104;
	add.s64 	%rd106, %rd105, %rd83;
	ld.global.nc.f32 	%f6, [%rd106+96];
	mul.wide.u32 	%rd107, %r57, 6120;
	mul.wide.u32 	%rd108, %r44, 306000;
	add.s64 	%rd109, %rd60, %rd108;
	add.s64 	%rd110, %rd109, %rd107;
	mul.wide.u32 	%rd111, %r52, 24;
	add.s64 	%rd112, %rd110, %rd111;
	add.s64 	%rd113, %rd112, %rd83;
	ld.global.nc.f32 	%f7, [%rd113+24];
	add.s64 	%rd114, %rd57, %rd108;
	add.s64 	%rd115, %rd114, %rd107;
	add.s64 	%rd116, %rd115, %rd111;
	add.s64 	%rd117, %rd116, %rd83;
	ld.global.nc.f32 	%f8, [%rd117+24];
	add.s64 	%rd118, %rd61, %rd97;
	add.s64 	%rd119, %rd118, %rd96;
	ld.global.nc.f32 	%f9, [%rd119];
	add.s64 	%rd120, %rd62, %rd100;
	ld.global.nc.f32 	%f10, [%rd120];
	add.s64 	%rd121, %rd63, %rd108;
	add.s64 	%rd122, %rd121, %rd107;
	add.s64 	%rd123, %rd122, %rd111;
	add.s64 	%rd124, %rd123, %rd83;
	ld.global.nc.f32 	%f11, [%rd124+24];
	mul.wide.u32 	%rd125, %r57, 3048;
	mul.wide.u32 	%rd126, %r44, 152400;
	add.s64 	%rd127, %rd65, %rd126;
	add.s64 	%rd128, %rd127, %rd125;
	mul.wide.u32 	%rd129, %r50, 24;
	add.s64 	%rd130, %rd128, %rd129;
	add.s64 	%rd131, %rd130, %rd83;
	ld.global.nc.f32 	%f12, [%rd131+24];
	add.s64 	%rd132, %rd64, %rd126;
	add.s64 	%rd133, %rd132, %rd125;
	add.s64 	%rd134, %rd133, %rd129;
	add.s64 	%rd135, %rd134, %rd83;
	ld.global.nc.f32 	%f13, [%rd135+24];
	add.s64 	%rd136, %rd33, %rd97;
	add.s64 	%rd137, %rd136, %rd96;
	ld.global.nc.f32 	%f14, [%rd137];
	add.s64 	%rd138, %rd66, %rd100;
	ld.global.nc.f32 	%f15, [%rd138];
	add.s64 	%rd139, %rd67, %rd126;
	add.s64 	%rd140, %rd139, %rd125;
	add.s64 	%rd141, %rd140, %rd129;
	add.s64 	%rd142, %rd141, %rd83;
	ld.global.nc.f32 	%f16, [%rd142+24];
	mul.wide.u32 	%rd143, %r57, 1512;
	mul.wide.u32 	%rd144, %r44, 75600;
	add.s64 	%rd145, %rd69, %rd144;
	add.s64 	%rd146, %rd145, %rd143;
	mul.wide.u32 	%rd147, %r48, 24;
	add.s64 	%rd148, %rd146, %rd147;
	add.s64 	%rd149, %rd148, %rd83;
	ld.global.nc.f32 	%f17, [%rd149+24];
	add.s64 	%rd150, %rd68, %rd144;
	add.s64 	%rd151, %rd150, %rd143;
	add.s64 	%rd152, %rd151, %rd147;
	add.s64 	%rd153, %rd152, %rd83;
	ld.global.nc.f32 	%f18, [%rd153+24];
	add.s64 	%rd154, %rd30, %rd97;
	add.s64 	%rd155, %rd154, %rd96;
	ld.global.nc.f32 	%f19, [%rd155];
	add.s64 	%rd156, %rd70, %rd100;
	ld.global.nc.f32 	%f20, [%rd156];
	mul.wide.u32 	%rd157, %r57, 1536;
	mul.wide.u32 	%rd158, %r44, 76800;
	add.s64 	%rd159, %rd71, %rd158;
	add.s64 	%rd160, %rd159, %rd157;
	add.s64 	%rd161, %rd160, %rd147;
	add.s64 	%rd162, %rd161, %rd83;
	ld.global.nc.f32 	%f21, [%rd162+48];
	cvt.u64.u32 	%rd13, %r46;
	mul.wide.u32 	%rd163, %r57, 744;
	mul.wide.u32 	%rd164, %r44, 37200;
	add.s64 	%rd165, %rd73, %rd164;
	add.s64 	%rd166, %rd165, %rd163;
	mul.wide.u32 	%rd167, %r46, 24;
	add.s64 	%rd168, %rd166, %rd167;
	add.s64 	%rd169, %rd168, %rd83;
	ld.global.nc.f32 	%f22, [%rd169+24];
	add.s64 	%rd170, %rd72, %rd164;
	add.s64 	%rd171, %rd170, %rd163;
	add.s64 	%rd172, %rd171, %rd167;
	add.s64 	%rd173, %rd172, %rd83;
	ld.global.nc.f32 	%f23, [%rd173+24];
	add.s64 	%rd174, %rd27, %rd97;
	add.s64 	%rd175, %rd174, %rd96;
	ld.global.nc.f32 	%f24, [%rd175];
	mul.rn.f32 	%f40, %f24, 0f3F22F983;
	cvt.rni.s32.f32 	%r132, %f40;
	cvt.rn.f32.s32 	%f41, %r132;
	fma.rn.f32 	%f42, %f41, 0fBFC90FDA, %f24;
	fma.rn.f32 	%f43, %f41, 0fB3A22168, %f42;
	fma.rn.f32 	%f140, %f41, 0fA7C234C5, %f43;
	abs.f32 	%f26, %f24;
	setp.ltu.f32 	%p1, %f26, 0f47CE4780;
	mov.f32 	%f139, 0f00000000;
	@%p1 bra 	$L__BB138_8;
	setp.neu.f32 	%p2, %f26, 0f7F800000;
	@%p2 bra 	$L__BB138_3;
	mul.rn.f32 	%f140, %f24, %f139;
	mov.b32 	%r132, 0;
	bra.uni 	$L__BB138_8;
$L__BB138_3:
	mov.b32 	%r4, %f24;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r60, %r5, 224;
	add.s32 	%r61, %r60, -128;
	shl.b32 	%r62, %r4, 8;
	or.b32  	%r66, %r62, -2147483648;
	shr.u32 	%r7, %r61, 5;
	mov.b32 	%r129, 0;
	mov.u64 	%rd227, 0;
	mov.u64 	%rd177, __cudart_i2opi_f;
$L__BB138_4:
	.pragma "nounroll";
	add.s64 	%rd178, %rd177, %rd227;
	ld.global.nc.u32 	%r65, [%rd178];
	// begin inline asm
	{
	mad.lo.cc.u32   %r63, %r65, %r66, %r129;
	madc.hi.u32     %r129, %r65, %r66,  0;
	}
	// end inline asm
	add.s64 	%rd179, %rd8, %rd227;
	st.local.u32 	[%rd179], %r63;
	add.s64 	%rd227, %rd227, 4;
	cvt.u32.u64 	%r68, %rd227;
	setp.ne.s32 	%p3, %r68, 24;
	@%p3 bra 	$L__BB138_4;
	st.local.u32 	[%rd8+24], %r129;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd180, %r7, 4;
	sub.s64 	%rd16, %rd8, %rd180;
	ld.local.u32 	%r130, [%rd16+24];
	ld.local.u32 	%r131, [%rd16+20];
	setp.eq.s32 	%p4, %r10, 0;
	@%p4 bra 	$L__BB138_7;
	shl.b32 	%r69, %r131, %r10;
	shl.b32 	%r70, %r130, %r10;
	mov.b32 	%r71, 32;
	sub.s32 	%r72, %r71, %r10;
	shr.u32 	%r73, %r131, %r72;
	add.s32 	%r130, %r73, %r70;
	ld.local.u32 	%r74, [%rd16+16];
	shr.u32 	%r75, %r74, %r72;
	add.s32 	%r131, %r75, %r69;
$L__BB138_7:
	shr.u32 	%r76, %r130, 30;
	shr.u32 	%r77, %r131, 30;
	shl.b32 	%r78, %r130, 2;
	or.b32  	%r79, %r78, %r77;
	shl.b32 	%r80, %r131, 2;
	bfe.u32 	%r81, %r130, 29, 1;
	add.s32 	%r82, %r81, %r76;
	neg.s32 	%r83, %r82;
	setp.lt.s32 	%p5, %r4, 0;
	selp.b32 	%r132, %r83, %r82, %p5;
	xor.b32  	%r84, %r79, %r4;
	bfe.s32 	%r85, %r130, 29, 1;
	xor.b32  	%r86, %r85, %r79;
	xor.b32  	%r87, %r85, %r80;
	cvt.u64.u32 	%rd181, %r86;
	shl.b64 	%rd182, %rd181, 32;
	cvt.u64.u32 	%rd183, %r87;
	or.b64  	%rd184, %rd182, %rd183;
	cvt.rn.f64.s64 	%fd1, %rd184;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f44, %fd2;
	neg.f32 	%f45, %f44;
	setp.lt.s32 	%p6, %r84, 0;
	selp.f32 	%f140, %f45, %f44, %p6;
$L__BB138_8:
	cvta.to.global.u64 	%rd1, %rd22;
	cvta.to.global.u64 	%rd2, %rd24;
	cvta.to.global.u64 	%rd3, %rd35;
	shl.b64 	%rd185, %rd10, 2;
	add.s64 	%rd186, %rd6, %rd185;
	ld.global.nc.f32 	%f30, [%rd186];
	mul.lo.s64 	%rd187, %rd10, 38400;
	add.s64 	%rd188, %rd7, %rd187;
	mul.lo.s64 	%rd189, %rd12, 768;
	add.s64 	%rd190, %rd188, %rd189;
	mul.lo.s64 	%rd191, %rd13, 24;
	add.s64 	%rd192, %rd190, %rd191;
	shl.b64 	%rd193, %rd11, 2;
	add.s64 	%rd194, %rd192, %rd193;
	ld.global.nc.f32 	%f31, [%rd194+48];
	cvt.u64.u32 	%rd17, %r2;
	mul.lo.s64 	%rd195, %rd10, 18000;
	add.s64 	%rd196, %rd5, %rd195;
	mul.lo.s64 	%rd197, %rd12, 360;
	add.s64 	%rd198, %rd196, %rd197;
	mul.wide.u32 	%rd199, %r2, 24;
	add.s64 	%rd200, %rd198, %rd199;
	add.s64 	%rd201, %rd200, %rd193;
	ld.global.nc.f32 	%f32, [%rd201];
	add.s64 	%rd202, %rd4, %rd195;
	add.s64 	%rd203, %rd202, %rd197;
	add.s64 	%rd204, %rd203, %rd199;
	add.s64 	%rd205, %rd204, %rd193;
	ld.global.nc.f32 	%f33, [%rd205];
	add.rn.f32 	%f34, %f24, %f24;
	mul.rn.f32 	%f47, %f34, 0f3F22F983;
	cvt.rni.s32.f32 	%r136, %f47;
	cvt.rn.f32.s32 	%f48, %r136;
	fma.rn.f32 	%f49, %f48, 0fBFC90FDA, %f34;
	fma.rn.f32 	%f50, %f48, 0fB3A22168, %f49;
	fma.rn.f32 	%f141, %f48, 0fA7C234C5, %f50;
	abs.f32 	%f36, %f34;
	setp.ltu.f32 	%p7, %f36, 0f47CE4780;
	@%p7 bra 	$L__BB138_16;
	setp.neu.f32 	%p8, %f36, 0f7F800000;
	@%p8 bra 	$L__BB138_11;
	mul.rn.f32 	%f141, %f34, %f139;
	mov.b32 	%r136, 0;
	bra.uni 	$L__BB138_16;
$L__BB138_11:
	mov.b32 	%r20, %f34;
	shr.u32 	%r21, %r20, 23;
	and.b32  	%r90, %r21, 224;
	add.s32 	%r91, %r90, -128;
	shl.b32 	%r92, %r20, 8;
	or.b32  	%r96, %r92, -2147483648;
	shr.u32 	%r23, %r91, 5;
	mov.b32 	%r133, 0;
	mov.u64 	%rd228, 0;
	mov.u64 	%rd207, __cudart_i2opi_f;
$L__BB138_12:
	.pragma "nounroll";
	add.s64 	%rd208, %rd207, %rd228;
	ld.global.nc.u32 	%r95, [%rd208];
	// begin inline asm
	{
	mad.lo.cc.u32   %r93, %r95, %r96, %r133;
	madc.hi.u32     %r133, %r95, %r96,  0;
	}
	// end inline asm
	add.s64 	%rd209, %rd8, %rd228;
	st.local.u32 	[%rd209], %r93;
	add.s64 	%rd228, %rd228, 4;
	cvt.u32.u64 	%r98, %rd228;
	setp.ne.s32 	%p9, %r98, 24;
	@%p9 bra 	$L__BB138_12;
	st.local.u32 	[%rd8+24], %r133;
	and.b32  	%r26, %r21, 31;
	mul.wide.u32 	%rd210, %r23, 4;
	sub.s64 	%rd20, %rd8, %rd210;
	ld.local.u32 	%r134, [%rd20+24];
	ld.local.u32 	%r135, [%rd20+20];
	setp.eq.s32 	%p10, %r26, 0;
	@%p10 bra 	$L__BB138_15;
	shl.b32 	%r99, %r135, %r26;
	shl.b32 	%r100, %r134, %r26;
	mov.b32 	%r101, 32;
	sub.s32 	%r102, %r101, %r26;
	shr.u32 	%r103, %r135, %r102;
	add.s32 	%r134, %r103, %r100;
	ld.local.u32 	%r104, [%rd20+16];
	shr.u32 	%r105, %r104, %r102;
	add.s32 	%r135, %r105, %r99;
$L__BB138_15:
	shr.u32 	%r106, %r134, 30;
	shr.u32 	%r107, %r135, 30;
	shl.b32 	%r108, %r134, 2;
	or.b32  	%r109, %r108, %r107;
	shl.b32 	%r110, %r135, 2;
	bfe.u32 	%r111, %r134, 29, 1;
	add.s32 	%r112, %r111, %r106;
	neg.s32 	%r113, %r112;
	setp.lt.s32 	%p11, %r20, 0;
	selp.b32 	%r136, %r113, %r112, %p11;
	xor.b32  	%r114, %r109, %r20;
	bfe.s32 	%r115, %r134, 29, 1;
	xor.b32  	%r116, %r115, %r109;
	xor.b32  	%r117, %r115, %r110;
	cvt.u64.u32 	%rd211, %r116;
	shl.b64 	%rd212, %rd211, 32;
	cvt.u64.u32 	%rd213, %r117;
	or.b64  	%rd214, %rd212, %rd213;
	cvt.rn.f64.s64 	%fd3, %rd214;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f51, %fd4;
	neg.f32 	%f52, %f51;
	setp.lt.s32 	%p12, %r114, 0;
	selp.f32 	%f141, %f52, %f51, %p12;
$L__BB138_16:
	add.rn.f32 	%f54, %f2, %f3;
	mul.rn.f32 	%f55, %f5, %f6;
	mul.rn.f32 	%f56, %f4, %f55;
	add.rn.f32 	%f57, %f54, %f56;
	add.rn.f32 	%f58, %f1, %f57;
	add.rn.f32 	%f59, %f7, %f8;
	mul.rn.f32 	%f60, %f10, %f11;
	mul.rn.f32 	%f61, %f9, %f60;
	add.rn.f32 	%f62, %f59, %f61;
	add.rn.f32 	%f63, %f58, %f62;
	add.rn.f32 	%f64, %f12, %f13;
	mul.rn.f32 	%f65, %f15, %f16;
	mul.rn.f32 	%f66, %f14, %f65;
	add.rn.f32 	%f67, %f64, %f66;
	add.rn.f32 	%f68, %f63, %f67;
	add.rn.f32 	%f69, %f17, %f18;
	mul.rn.f32 	%f70, %f20, %f21;
	mul.rn.f32 	%f71, %f19, %f70;
	add.rn.f32 	%f72, %f69, %f71;
	add.rn.f32 	%f73, %f68, %f72;
	add.rn.f32 	%f74, %f22, %f23;
	add.s32 	%r119, %r132, 1;
	and.b32  	%r120, %r119, 2;
	setp.eq.s32 	%p13, %r120, 0;
	and.b32  	%r121, %r132, 1;
	setp.eq.b32 	%p14, %r121, 1;
	mul.rn.f32 	%f75, %f140, %f140;
	fma.rn.f32 	%f76, %f75, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f77, 0fB94D4153, %f76, %p14;
	selp.f32 	%f78, 0f3C0885E4, 0f3D2AAABB, %p14;
	fma.rn.f32 	%f79, %f77, %f75, %f78;
	selp.f32 	%f80, 0fBE2AAAA8, 0fBEFFFFFF, %p14;
	fma.rn.f32 	%f81, %f79, %f75, %f80;
	selp.f32 	%f82, %f140, 0f3F800000, %p14;
	fma.rn.f32 	%f83, %f75, %f82, 0f00000000;
	fma.rn.f32 	%f84, %f81, %f83, %f82;
	sub.rn.f32 	%f86, %f139, %f84;
	selp.f32 	%f87, %f84, %f86, %p13;
	mul.rn.f32 	%f88, %f30, %f31;
	mul.rn.f32 	%f89, %f88, %f87;
	add.rn.f32 	%f90, %f74, %f89;
	add.rn.f32 	%f91, %f73, %f90;
	add.s32 	%r122, %r136, 1;
	mul.rn.f32 	%f92, %f141, %f141;
	and.b32  	%r123, %r136, 1;
	setp.eq.b32 	%p15, %r123, 1;
	selp.f32 	%f93, %f141, 0f3F800000, %p15;
	fma.rn.f32 	%f94, %f92, %f93, 0f00000000;
	fma.rn.f32 	%f95, %f92, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f96, 0fB94D4153, %f95, %p15;
	selp.f32 	%f97, 0f3C0885E4, 0f3D2AAABB, %p15;
	fma.rn.f32 	%f98, %f96, %f92, %f97;
	selp.f32 	%f99, 0fBE2AAAA8, 0fBEFFFFFF, %p15;
	fma.rn.f32 	%f100, %f98, %f92, %f99;
	fma.rn.f32 	%f101, %f100, %f94, %f93;
	and.b32  	%r124, %r122, 2;
	setp.eq.s32 	%p16, %r124, 0;
	sub.rn.f32 	%f102, %f139, %f101;
	selp.f32 	%f103, %f101, %f102, %p16;
	add.s64 	%rd216, %rd2, %rd185;
	ld.global.nc.f32 	%f104, [%rd216];
	fma.rn.f32 	%f105, %f104, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f106, %f105;
	mov.f32 	%f107, 0f4B400001;
	mov.f32 	%f108, 0f437C0000;
	fma.rm.f32 	%f109, %f106, %f108, %f107;
	add.rn.f32 	%f110, %f109, 0fCB40007F;
	neg.f32 	%f111, %f110;
	fma.rn.f32 	%f112, %f104, 0f3FB8AA3B, %f111;
	fma.rn.f32 	%f113, %f104, 0f32A57060, %f112;
	mov.b32 	%r125, %f109;
	shl.b32 	%r126, %r125, 23;
	mov.b32 	%f114, %r126;
	ex2.approx.ftz.f32 	%f115, %f113;
	mul.rn.f32 	%f116, %f115, %f114;
	neg.f32 	%f117, %f116;
	sub.rn.f32 	%f118, %f117, %f116;
	add.rn.f32 	%f119, %f118, %f118;
	add.rn.f32 	%f120, %f119, %f119;
	add.rn.f32 	%f121, %f120, %f120;
	add.rn.f32 	%f122, %f121, %f121;
	fma.rn.f32 	%f123, %f122, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f124, %f123;
	fma.rm.f32 	%f125, %f124, %f108, %f107;
	add.rn.f32 	%f126, %f125, 0fCB40007F;
	neg.f32 	%f127, %f126;
	fma.rn.f32 	%f128, %f122, 0f3FB8AA3B, %f127;
	fma.rn.f32 	%f129, %f122, 0f32A57060, %f128;
	mov.b32 	%r127, %f125;
	shl.b32 	%r128, %r127, 23;
	mov.b32 	%f130, %r128;
	ex2.approx.ftz.f32 	%f131, %f129;
	mul.rn.f32 	%f132, %f131, %f130;
	add.rn.f32 	%f133, %f32, %f33;
	mul.lo.s64 	%rd217, %rd10, 19200;
	add.s64 	%rd218, %rd3, %rd217;
	mul.lo.s64 	%rd219, %rd12, 384;
	add.s64 	%rd220, %rd218, %rd219;
	mul.lo.s64 	%rd221, %rd17, 24;
	add.s64 	%rd222, %rd220, %rd221;
	add.s64 	%rd224, %rd222, %rd193;
	ld.global.nc.f32 	%f134, [%rd224+24];
	mul.rn.f32 	%f135, %f134, %f132;
	mul.rn.f32 	%f136, %f103, %f135;
	add.rn.f32 	%f137, %f133, %f136;
	add.rn.f32 	%f138, %f91, %f137;
	mul.wide.u32 	%rd225, %r1, 4;
	add.s64 	%rd226, %rd1, %rd225;
	st.global.f32 	[%rd226], %f138;
	ret;

}
	// .globl	loop_transpose_fusion_109
.visible .entry loop_transpose_fusion_109(
	.param .u64 loop_transpose_fusion_109_param_0,
	.param .u64 loop_transpose_fusion_109_param_1,
	.param .u64 loop_transpose_fusion_109_param_2,
	.param .u64 loop_transpose_fusion_109_param_3,
	.param .u64 loop_transpose_fusion_109_param_4
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot139[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<124>;
	.reg .f32 	%f<87>;
	.reg .b64 	%rd<59>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot139;
	ld.param.u64 	%rd15, [loop_transpose_fusion_109_param_0];
	ld.param.u64 	%rd16, [loop_transpose_fusion_109_param_4];
	ld.param.u64 	%rd17, [loop_transpose_fusion_109_param_1];
	ld.param.u64 	%rd18, [loop_transpose_fusion_109_param_3];
	ld.param.u64 	%rd19, [loop_transpose_fusion_109_param_2];
	cvta.to.global.u64 	%rd3, %rd19;
	cvta.to.global.u64 	%rd20, %rd17;
	cvta.to.global.u64 	%rd4, %rd15;
	add.u64 	%rd5, %SPL, 0;
	mov.u32 	%r34, %ctaid.x;
	shl.b32 	%r35, %r34, 7;
	mov.u32 	%r36, %tid.x;
	or.b32  	%r1, %r35, %r36;
	cvt.u16.u32 	%rs3, %r34;
	mul.hi.u16 	%rs4, %rs3, -17601;
	shr.u16 	%rs5, %rs4, 7;
	mul.hi.u32 	%r37, %r1, 1570730897;
	bfe.u32 	%r38, %r37, 7, 6;
	mul.hi.u32 	%r39, %r1, 613566757;
	sub.s32 	%r40, %r1, %r39;
	shr.u32 	%r41, %r40, 1;
	add.s32 	%r42, %r41, %r39;
	shr.u32 	%r43, %r42, 2;
	cvt.u16.u32 	%rs6, %r43;
	shr.u16 	%rs7, %rs6, 1;
	mul.hi.u16 	%rs8, %rs7, 5243;
	shr.u16 	%rs9, %rs8, 1;
	mul.lo.s16 	%rs10, %rs9, 50;
	sub.s16 	%rs1, %rs6, %rs10;
	mul.lo.s32 	%r44, %r43, 7;
	sub.s32 	%r2, %r1, %r44;
	shl.b16 	%rs2, %rs5, 1;
	cvt.u64.u32 	%rd7, %r38;
	mul.wide.u32 	%rd23, %r38, 12;
	add.s64 	%rd24, %rd20, %rd23;
	cvt.u32.u16 	%r45, %rs5;
	mul.wide.u32 	%rd25, %r45, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f12, [%rd26];
	add.rn.f32 	%f13, %f12, %f12;
	add.rn.f32 	%f1, %f13, %f13;
	mul.rn.f32 	%f14, %f1, 0f3F22F983;
	cvt.rni.s32.f32 	%r123, %f14;
	cvt.rn.f32.s32 	%f15, %r123;
	fma.rn.f32 	%f16, %f15, 0fBFC90FDA, %f1;
	fma.rn.f32 	%f17, %f15, 0fB3A22168, %f16;
	fma.rn.f32 	%f86, %f15, 0fA7C234C5, %f17;
	abs.f32 	%f3, %f1;
	setp.ltu.f32 	%p1, %f3, 0f47CE4780;
	setp.neu.f32 	%p17, %f3, 0f7F800000;
	mov.f32 	%f84, 0f00000000;
	mov.u32 	%r119, %r123;
	mov.f32 	%f85, %f86;
	@%p1 bra 	$L__BB139_8;
	@%p17 bra 	$L__BB139_3;
	mul.rn.f32 	%f85, %f1, %f84;
	mov.b32 	%r119, 0;
	bra.uni 	$L__BB139_8;
$L__BB139_3:
	mov.b32 	%r4, %f1;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r47, %r5, 224;
	add.s32 	%r48, %r47, -128;
	shl.b32 	%r49, %r4, 8;
	or.b32  	%r53, %r49, -2147483648;
	shr.u32 	%r7, %r48, 5;
	mov.b32 	%r116, 0;
	mov.u64 	%rd57, 0;
	mov.u64 	%rd28, __cudart_i2opi_f;
$L__BB139_4:
	.pragma "nounroll";
	add.s64 	%rd29, %rd28, %rd57;
	ld.global.nc.u32 	%r52, [%rd29];
	// begin inline asm
	{
	mad.lo.cc.u32   %r50, %r52, %r53, %r116;
	madc.hi.u32     %r116, %r52, %r53,  0;
	}
	// end inline asm
	add.s64 	%rd30, %rd5, %rd57;
	st.local.u32 	[%rd30], %r50;
	add.s64 	%rd57, %rd57, 4;
	cvt.u32.u64 	%r55, %rd57;
	setp.ne.s32 	%p3, %r55, 24;
	@%p3 bra 	$L__BB139_4;
	st.local.u32 	[%rd5+24], %r116;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd31, %r7, 4;
	sub.s64 	%rd10, %rd5, %rd31;
	ld.local.u32 	%r117, [%rd10+24];
	ld.local.u32 	%r118, [%rd10+20];
	setp.eq.s32 	%p4, %r10, 0;
	@%p4 bra 	$L__BB139_7;
	shl.b32 	%r56, %r118, %r10;
	shl.b32 	%r57, %r117, %r10;
	mov.b32 	%r58, 32;
	sub.s32 	%r59, %r58, %r10;
	shr.u32 	%r60, %r118, %r59;
	add.s32 	%r117, %r60, %r57;
	ld.local.u32 	%r61, [%rd10+16];
	shr.u32 	%r62, %r61, %r59;
	add.s32 	%r118, %r62, %r56;
$L__BB139_7:
	shr.u32 	%r63, %r117, 30;
	shr.u32 	%r64, %r118, 30;
	shl.b32 	%r65, %r117, 2;
	or.b32  	%r66, %r65, %r64;
	shl.b32 	%r67, %r118, 2;
	bfe.u32 	%r68, %r117, 29, 1;
	add.s32 	%r69, %r68, %r63;
	neg.s32 	%r70, %r69;
	setp.lt.s32 	%p5, %r4, 0;
	selp.b32 	%r119, %r70, %r69, %p5;
	xor.b32  	%r71, %r66, %r4;
	bfe.s32 	%r72, %r117, 29, 1;
	xor.b32  	%r73, %r72, %r66;
	xor.b32  	%r74, %r72, %r67;
	cvt.u64.u32 	%rd32, %r73;
	shl.b64 	%rd33, %rd32, 32;
	cvt.u64.u32 	%rd34, %r74;
	or.b64  	%rd35, %rd33, %rd34;
	cvt.rn.f64.s64 	%fd1, %rd35;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f18, %fd2;
	neg.f32 	%f19, %f18;
	setp.lt.s32 	%p6, %r71, 0;
	selp.f32 	%f85, %f19, %f18, %p6;
$L__BB139_8:
	cvta.to.global.u64 	%rd1, %rd16;
	cvta.to.global.u64 	%rd2, %rd18;
	shl.b64 	%rd36, %rd7, 2;
	add.s64 	%rd37, %rd3, %rd36;
	ld.global.nc.f32 	%f7, [%rd37];
	mul.lo.s64 	%rd38, %rd7, 9600;
	add.s64 	%rd39, %rd4, %rd38;
	cvt.u32.u16 	%r76, %rs1;
	mul.wide.u32 	%rd40, %r76, 192;
	add.s64 	%rd41, %rd39, %rd40;
	mul.wide.u32 	%rd42, %r2, 24;
	add.s64 	%rd43, %rd41, %rd42;
	cvt.u32.u16 	%r77, %rs2;
	mul.wide.u32 	%rd44, %r77, 4;
	add.s64 	%rd11, %rd43, %rd44;
	ld.global.nc.f32 	%f8, [%rd11+24];
	@%p1 bra 	$L__BB139_16;
	@%p17 bra 	$L__BB139_11;
	mul.rn.f32 	%f86, %f1, %f84;
	mov.b32 	%r123, 0;
	bra.uni 	$L__BB139_16;
$L__BB139_11:
	mov.b32 	%r19, %f1;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r79, %r20, 224;
	add.s32 	%r80, %r79, -128;
	shl.b32 	%r81, %r19, 8;
	or.b32  	%r85, %r81, -2147483648;
	shr.u32 	%r22, %r80, 5;
	mov.b32 	%r120, 0;
	mov.u64 	%rd58, 0;
	mov.u64 	%rd46, __cudart_i2opi_f;
$L__BB139_12:
	.pragma "nounroll";
	add.s64 	%rd47, %rd46, %rd58;
	ld.global.nc.u32 	%r84, [%rd47];
	// begin inline asm
	{
	mad.lo.cc.u32   %r82, %r84, %r85, %r120;
	madc.hi.u32     %r120, %r84, %r85,  0;
	}
	// end inline asm
	add.s64 	%rd48, %rd5, %rd58;
	st.local.u32 	[%rd48], %r82;
	add.s64 	%rd58, %rd58, 4;
	cvt.u32.u64 	%r87, %rd58;
	setp.ne.s32 	%p9, %r87, 24;
	@%p9 bra 	$L__BB139_12;
	st.local.u32 	[%rd5+24], %r120;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd49, %r22, 4;
	sub.s64 	%rd14, %rd5, %rd49;
	ld.local.u32 	%r121, [%rd14+24];
	ld.local.u32 	%r122, [%rd14+20];
	setp.eq.s32 	%p10, %r25, 0;
	@%p10 bra 	$L__BB139_15;
	shl.b32 	%r88, %r122, %r25;
	shl.b32 	%r89, %r121, %r25;
	mov.b32 	%r90, 32;
	sub.s32 	%r91, %r90, %r25;
	shr.u32 	%r92, %r122, %r91;
	add.s32 	%r121, %r92, %r89;
	ld.local.u32 	%r93, [%rd14+16];
	shr.u32 	%r94, %r93, %r91;
	add.s32 	%r122, %r94, %r88;
$L__BB139_15:
	shr.u32 	%r95, %r121, 30;
	shr.u32 	%r96, %r122, 30;
	shl.b32 	%r97, %r121, 2;
	or.b32  	%r98, %r97, %r96;
	shl.b32 	%r99, %r122, 2;
	bfe.u32 	%r100, %r121, 29, 1;
	add.s32 	%r101, %r100, %r95;
	neg.s32 	%r102, %r101;
	setp.lt.s32 	%p11, %r19, 0;
	selp.b32 	%r123, %r102, %r101, %p11;
	xor.b32  	%r103, %r98, %r19;
	bfe.s32 	%r104, %r121, 29, 1;
	xor.b32  	%r105, %r104, %r98;
	xor.b32  	%r106, %r104, %r99;
	cvt.u64.u32 	%rd50, %r105;
	shl.b64 	%rd51, %rd50, 32;
	cvt.u64.u32 	%rd52, %r106;
	or.b64  	%rd53, %rd51, %rd52;
	cvt.rn.f64.s64 	%fd3, %rd53;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f21, %fd4;
	neg.f32 	%f22, %f21;
	setp.lt.s32 	%p12, %r103, 0;
	selp.f32 	%f86, %f22, %f21, %p12;
$L__BB139_16:
	fma.rn.f32 	%f24, %f7, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f25, %f24;
	mov.f32 	%f26, 0f4B400001;
	mov.f32 	%f27, 0f437C0000;
	fma.rm.f32 	%f28, %f25, %f27, %f26;
	add.rn.f32 	%f29, %f28, 0fCB40007F;
	neg.f32 	%f30, %f29;
	fma.rn.f32 	%f31, %f7, 0f3FB8AA3B, %f30;
	fma.rn.f32 	%f32, %f7, 0f32A57060, %f31;
	ex2.approx.ftz.f32 	%f33, %f32;
	mov.b32 	%r108, %f28;
	shl.b32 	%r109, %r108, 23;
	mov.b32 	%f34, %r109;
	mul.rn.f32 	%f35, %f33, %f34;
	neg.f32 	%f36, %f35;
	sub.rn.f32 	%f37, %f36, %f35;
	add.rn.f32 	%f38, %f37, %f37;
	add.rn.f32 	%f39, %f38, %f38;
	add.rn.f32 	%f40, %f39, %f39;
	add.rn.f32 	%f41, %f40, %f40;
	add.rn.f32 	%f42, %f41, %f41;
	fma.rn.f32 	%f43, %f42, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f44, %f43;
	fma.rm.f32 	%f45, %f44, %f27, %f26;
	add.rn.f32 	%f46, %f45, 0fCB40007F;
	neg.f32 	%f47, %f46;
	fma.rn.f32 	%f48, %f42, 0f3FB8AA3B, %f47;
	fma.rn.f32 	%f49, %f42, 0f32A57060, %f48;
	ex2.approx.ftz.f32 	%f50, %f49;
	mov.b32 	%r110, %f45;
	shl.b32 	%r111, %r110, 23;
	mov.b32 	%f51, %r111;
	mul.rn.f32 	%f52, %f50, %f51;
	mul.rn.f32 	%f53, %f8, %f52;
	and.b32  	%r112, %r119, 2;
	setp.eq.s32 	%p13, %r112, 0;
	and.b32  	%r113, %r119, 1;
	setp.eq.b32 	%p14, %r113, 1;
	mul.rn.f32 	%f54, %f85, %f85;
	fma.rn.f32 	%f55, %f54, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f56, %f55, 0fB94D4153, %p14;
	selp.f32 	%f57, 0f3D2AAABB, 0f3C0885E4, %p14;
	fma.rn.f32 	%f58, %f56, %f54, %f57;
	selp.f32 	%f59, 0fBEFFFFFF, 0fBE2AAAA8, %p14;
	fma.rn.f32 	%f60, %f58, %f54, %f59;
	selp.f32 	%f61, 0f3F800000, %f85, %p14;
	fma.rn.f32 	%f62, %f54, %f61, 0f00000000;
	fma.rn.f32 	%f63, %f60, %f62, %f61;
	sub.rn.f32 	%f65, %f84, %f63;
	selp.f32 	%f66, %f63, %f65, %p13;
	neg.f32 	%f67, %f66;
	mul.rn.f32 	%f68, %f53, %f67;
	mul.rn.f32 	%f69, %f86, %f86;
	and.b32  	%r114, %r123, 1;
	setp.eq.b32 	%p15, %r114, 1;
	selp.f32 	%f70, 0f3F800000, %f86, %p15;
	fma.rn.f32 	%f71, %f69, %f70, 0f00000000;
	fma.rn.f32 	%f72, %f69, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f73, %f72, 0fB94D4153, %p15;
	selp.f32 	%f74, 0f3D2AAABB, 0f3C0885E4, %p15;
	fma.rn.f32 	%f75, %f73, %f69, %f74;
	selp.f32 	%f76, 0fBEFFFFFF, 0fBE2AAAA8, %p15;
	fma.rn.f32 	%f77, %f75, %f69, %f76;
	fma.rn.f32 	%f78, %f77, %f71, %f70;
	and.b32  	%r115, %r123, 2;
	setp.eq.s32 	%p16, %r115, 0;
	sub.rn.f32 	%f79, %f84, %f78;
	selp.f32 	%f80, %f78, %f79, %p16;
	ld.global.nc.f32 	%f81, [%rd11+28];
	mul.rn.f32 	%f82, %f81, %f52;
	mul.rn.f32 	%f83, %f80, %f82;
	mul.wide.u32 	%rd54, %r1, 4;
	add.s64 	%rd55, %rd2, %rd54;
	st.global.f32 	[%rd55], %f68;
	add.s64 	%rd56, %rd1, %rd54;
	st.global.f32 	[%rd56], %f83;
	ret;

}
	// .globl	loop_broadcast_fusion_34
.visible .entry loop_broadcast_fusion_34(
	.param .u64 loop_broadcast_fusion_34_param_0
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<5>;

	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 10;
	or.b32  	%r4, %r3, %r2;
	setp.lt.u32 	%p1, %r4, 134400;
	@%p1 bra 	$L__BB140_2;
	bra.uni 	$L__BB140_1;
$L__BB140_2:
	ld.param.u64 	%rd2, [loop_broadcast_fusion_34_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.u32 	%rd4, %r4, 4;
	add.s64 	%rd1, %rd3, %rd4;
	mov.b32 	%r5, 0;
	st.global.u32 	[%rd1], %r5;
$L__BB140_1:
	ret;

}
	// .globl	input_scatter_fusion_240
.visible .entry input_scatter_fusion_240(
	.param .u64 input_scatter_fusion_240_param_0,
	.param .u64 input_scatter_fusion_240_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<16>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_240_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_240_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, 613566757;
	sub.s32 	%r6, %r4, %r5;
	shr.u32 	%r7, %r6, 1;
	add.s32 	%r8, %r7, %r5;
	shr.u32 	%r9, %r8, 2;
	mul.lo.s32 	%r10, %r9, 7;
	sub.s32 	%r11, %r4, %r10;
	cvt.u16.u32 	%rs1, %r9;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r12, %r4, 1570730897;
	bfe.u32 	%r13, %r12, 7, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, -17601;
	shr.u16 	%rs9, %rs8, 6;
	and.b16  	%rs10, %rs9, 1022;
	cvt.u32.u16 	%r14, %rs6;
	mul.wide.u32 	%rd5, %r14, 28;
	cvt.u32.u16 	%r15, %rs10;
	mul.wide.u32 	%rd6, %r15, 89600;
	add.s64 	%rd7, %rd4, %rd6;
	mul.wide.u32 	%rd8, %r13, 1400;
	add.s64 	%rd9, %rd7, %rd8;
	add.s64 	%rd10, %rd9, %rd5;
	mul.wide.u32 	%rd11, %r11, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+89600];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+89600], %f3;
	ret;

}
	// .globl	wrapped_transpose_246
.visible .entry wrapped_transpose_246(
	.param .u64 wrapped_transpose_246_param_0,
	.param .u64 wrapped_transpose_246_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<15>;
	.reg .b32 	%r<16>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [wrapped_transpose_246_param_0];
	ld.param.u64 	%rd2, [wrapped_transpose_246_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.hi.u32 	%r5, %r4, -106351571;
	bfe.u32 	%r6, %r5, 11, 6;
	shr.u32 	%r7, %r4, 1;
	mul.hi.u32 	%r8, %r7, 818089009;
	shr.u32 	%r9, %r8, 2;
	cvt.u16.u32 	%rs1, %r9;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r10, %r4, -1431655765;
	shr.u32 	%r11, %r10, 2;
	cvt.u16.u32 	%rs7, %r11;
	mul.hi.u16 	%rs8, %rs7, 9363;
	sub.s16 	%rs9, %rs7, %rs8;
	shr.u16 	%rs10, %rs9, 1;
	add.s16 	%rs11, %rs10, %rs8;
	shr.u16 	%rs12, %rs11, 2;
	mul.lo.s16 	%rs13, %rs12, 7;
	sub.s16 	%rs14, %rs7, %rs13;
	mul.lo.s32 	%r12, %r11, 6;
	sub.s32 	%r13, %r4, %r12;
	mul.wide.u32 	%rd5, %r13, 89600;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r6, 1400;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r14, %rs6;
	mul.wide.u32 	%rd9, %r14, 28;
	add.s64 	%rd10, %rd8, %rd9;
	cvt.u32.u16 	%r15, %rs14;
	mul.wide.u32 	%rd11, %r15, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	st.global.f32 	[%rd14], %f1;
	ret;

}
	// .globl	input_scatter_fusion_241
.visible .entry input_scatter_fusion_241(
	.param .u64 input_scatter_fusion_241_param_0,
	.param .u64 input_scatter_fusion_241_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<16>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_241_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_241_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.hi.u32 	%r5, %r4, 613566757;
	sub.s32 	%r6, %r4, %r5;
	shr.u32 	%r7, %r6, 1;
	add.s32 	%r8, %r7, %r5;
	shr.u32 	%r9, %r8, 2;
	mul.lo.s32 	%r10, %r9, 7;
	sub.s32 	%r11, %r4, %r10;
	cvt.u16.u32 	%rs1, %r9;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r12, %r4, 1570730897;
	bfe.u32 	%r13, %r12, 7, 6;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, -17601;
	shr.u16 	%rs9, %rs8, 6;
	and.b16  	%rs10, %rs9, 1022;
	cvt.u32.u16 	%r14, %rs6;
	mul.wide.u32 	%rd5, %r14, 28;
	cvt.u32.u16 	%r15, %rs10;
	mul.wide.u32 	%rd6, %r15, 89600;
	add.s64 	%rd7, %rd4, %rd6;
	mul.wide.u32 	%rd8, %r13, 1400;
	add.s64 	%rd9, %rd7, %rd8;
	add.s64 	%rd10, %rd9, %rd5;
	mul.wide.u32 	%rd11, %r11, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	loop_pad_fusion_24
.visible .entry loop_pad_fusion_24(
	.param .u64 loop_pad_fusion_24_param_0,
	.param .u64 loop_pad_fusion_24_param_1,
	.param .u64 loop_pad_fusion_24_param_2,
	.param .u64 loop_pad_fusion_24_param_3,
	.param .u64 loop_pad_fusion_24_param_4,
	.param .u64 loop_pad_fusion_24_param_5
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot144[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<73>;
	.reg .f32 	%f<70>;
	.reg .b64 	%rd<60>;
	.reg .f64 	%fd<3>;

	mov.u64 	%SPL, __local_depot144;
	ld.param.u64 	%rd16, [loop_pad_fusion_24_param_5];
	cvta.to.global.u64 	%rd1, %rd16;
	mov.u32 	%r20, %ctaid.x;
	mov.u32 	%r21, %tid.x;
	shl.b32 	%r22, %r20, 7;
	or.b32  	%r1, %r22, %r21;
	mul.hi.u32 	%r23, %r1, -1431655765;
	bfe.u32 	%r3, %r23, 2, 3;
	setp.ne.s32 	%p1, %r3, 7;
	mov.f32 	%f68, 0f00000000;
	@%p1 bra 	$L__BB144_2;
	bra.uni 	$L__BB144_1;
$L__BB144_2:
	ld.param.u64 	%rd15, [loop_pad_fusion_24_param_0];
	ld.param.u64 	%rd17, [loop_pad_fusion_24_param_1];
	ld.param.u64 	%rd18, [loop_pad_fusion_24_param_4];
	cvta.to.global.u64 	%rd2, %rd18;
	ld.param.u64 	%rd19, [loop_pad_fusion_24_param_2];
	ld.param.u64 	%rd20, [loop_pad_fusion_24_param_3];
	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd17;
	cvta.to.global.u64 	%rd6, %rd15;
	shr.u32 	%r2, %r23, 2;
	mul.hi.u32 	%r24, %r1, 458129845;
	bfe.u32 	%r25, %r24, 8, 6;
	shr.u32 	%r27, %r23, 5;
	cvt.u16.u32 	%rs1, %r27;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.lo.s32 	%r28, %r2, 6;
	sub.s32 	%r29, %r1, %r28;
	cvt.u64.u32 	%rd8, %r25;
	cvt.u64.u16 	%rd9, %rs6;
	cvt.u64.u32 	%rd10, %r3;
	cvt.u64.u32 	%rd11, %r29;
	mul.wide.u32 	%rd22, %r25, 8400;
	add.s64 	%rd23, %rd6, %rd22;
	cvt.u32.u16 	%r30, %rs6;
	mul.wide.u32 	%rd24, %r30, 168;
	add.s64 	%rd25, %rd23, %rd24;
	mul.wide.u32 	%rd26, %r3, 24;
	add.s64 	%rd27, %rd25, %rd26;
	mul.wide.u32 	%rd28, %r29, 4;
	add.s64 	%rd29, %rd27, %rd28;
	ld.global.nc.f32 	%f11, [%rd29];
	add.s64 	%rd30, %rd5, %rd22;
	add.s64 	%rd31, %rd30, %rd24;
	add.s64 	%rd32, %rd31, %rd26;
	add.s64 	%rd33, %rd32, %rd28;
	ld.global.nc.f32 	%f12, [%rd33];
	add.rn.f32 	%f2, %f11, %f12;
	shr.u32 	%r31, %r29, 1;
	mul.wide.u32 	%rd34, %r25, 12;
	add.s64 	%rd35, %rd3, %rd34;
	mul.wide.u32 	%rd36, %r31, 4;
	add.s64 	%rd37, %rd35, %rd36;
	ld.global.nc.f32 	%f13, [%rd37];
	add.rn.f32 	%f14, %f13, %f13;
	add.rn.f32 	%f3, %f14, %f14;
	mul.rn.f32 	%f15, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r72, %f15;
	cvt.rn.f32.s32 	%f16, %r72;
	fma.rn.f32 	%f17, %f16, 0fBFC90FDA, %f3;
	fma.rn.f32 	%f18, %f16, 0fB3A22168, %f17;
	fma.rn.f32 	%f69, %f16, 0fA7C234C5, %f18;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p2, %f5, 0f47CE4780;
	@%p2 bra 	$L__BB144_10;
	setp.neu.f32 	%p3, %f5, 0f7F800000;
	@%p3 bra 	$L__BB144_5;
	mov.f32 	%f21, 0f00000000;
	mul.rn.f32 	%f69, %f3, %f21;
	mov.b32 	%r72, 0;
	bra.uni 	$L__BB144_10;
$L__BB144_5:
	add.u64 	%rd7, %SPL, 0;
	mov.b32 	%r5, %f3;
	shr.u32 	%r6, %r5, 23;
	and.b32  	%r33, %r6, 224;
	add.s32 	%r34, %r33, -128;
	shl.b32 	%r35, %r5, 8;
	or.b32  	%r39, %r35, -2147483648;
	shr.u32 	%r8, %r34, 5;
	mov.b32 	%r69, 0;
	mov.u64 	%rd59, 0;
	mov.u64 	%rd39, __cudart_i2opi_f;
$L__BB144_6:
	.pragma "nounroll";
	add.s64 	%rd40, %rd39, %rd59;
	ld.global.nc.u32 	%r38, [%rd40];
	// begin inline asm
	{
	mad.lo.cc.u32   %r36, %r38, %r39, %r69;
	madc.hi.u32     %r69, %r38, %r39,  0;
	}
	// end inline asm
	add.s64 	%rd41, %rd7, %rd59;
	st.local.u32 	[%rd41], %r36;
	add.s64 	%rd59, %rd59, 4;
	cvt.u32.u64 	%r41, %rd59;
	setp.ne.s32 	%p4, %r41, 24;
	@%p4 bra 	$L__BB144_6;
	st.local.u32 	[%rd7+24], %r69;
	and.b32  	%r11, %r6, 31;
	mul.wide.u32 	%rd42, %r8, 4;
	sub.s64 	%rd14, %rd7, %rd42;
	ld.local.u32 	%r70, [%rd14+24];
	ld.local.u32 	%r71, [%rd14+20];
	setp.eq.s32 	%p5, %r11, 0;
	@%p5 bra 	$L__BB144_9;
	shl.b32 	%r42, %r71, %r11;
	shl.b32 	%r43, %r70, %r11;
	mov.b32 	%r44, 32;
	sub.s32 	%r45, %r44, %r11;
	shr.u32 	%r46, %r71, %r45;
	add.s32 	%r70, %r46, %r43;
	ld.local.u32 	%r47, [%rd14+16];
	shr.u32 	%r48, %r47, %r45;
	add.s32 	%r71, %r48, %r42;
$L__BB144_9:
	shr.u32 	%r49, %r70, 30;
	shr.u32 	%r50, %r71, 30;
	shl.b32 	%r51, %r70, 2;
	or.b32  	%r52, %r51, %r50;
	shl.b32 	%r53, %r71, 2;
	bfe.u32 	%r54, %r70, 29, 1;
	add.s32 	%r55, %r54, %r49;
	neg.s32 	%r56, %r55;
	setp.lt.s32 	%p6, %r5, 0;
	selp.b32 	%r72, %r56, %r55, %p6;
	xor.b32  	%r57, %r52, %r5;
	bfe.s32 	%r58, %r70, 29, 1;
	xor.b32  	%r59, %r58, %r52;
	xor.b32  	%r60, %r58, %r53;
	cvt.u64.u32 	%rd43, %r59;
	shl.b64 	%rd44, %rd43, 32;
	cvt.u64.u32 	%rd45, %r60;
	or.b64  	%rd46, %rd44, %rd45;
	cvt.rn.f64.s64 	%fd1, %rd46;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f19, %fd2;
	neg.f32 	%f20, %f19;
	setp.lt.s32 	%p7, %r57, 0;
	selp.f32 	%f69, %f20, %f19, %p7;
$L__BB144_10:
	add.s32 	%r62, %r72, 1;
	mul.rn.f32 	%f22, %f69, %f69;
	and.b32  	%r63, %r72, 1;
	setp.eq.b32 	%p8, %r63, 1;
	selp.f32 	%f23, %f69, 0f3F800000, %p8;
	fma.rn.f32 	%f24, %f22, %f23, 0f00000000;
	fma.rn.f32 	%f25, %f22, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f26, 0fB94D4153, %f25, %p8;
	selp.f32 	%f27, 0f3C0885E4, 0f3D2AAABB, %p8;
	fma.rn.f32 	%f28, %f26, %f22, %f27;
	selp.f32 	%f29, 0fBE2AAAA8, 0fBEFFFFFF, %p8;
	fma.rn.f32 	%f30, %f28, %f22, %f29;
	fma.rn.f32 	%f31, %f30, %f24, %f23;
	and.b32  	%r64, %r62, 2;
	setp.eq.s32 	%p9, %r64, 0;
	mov.f32 	%f32, 0f00000000;
	sub.rn.f32 	%f33, %f32, %f31;
	selp.f32 	%f34, %f31, %f33, %p9;
	shl.b64 	%rd47, %rd8, 2;
	add.s64 	%rd48, %rd2, %rd47;
	ld.global.nc.f32 	%f35, [%rd48];
	fma.rn.f32 	%f36, %f35, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f37, %f36;
	mov.f32 	%f38, 0f4B400001;
	mov.f32 	%f39, 0f437C0000;
	fma.rm.f32 	%f40, %f37, %f39, %f38;
	add.rn.f32 	%f41, %f40, 0fCB40007F;
	neg.f32 	%f42, %f41;
	fma.rn.f32 	%f43, %f35, 0f3FB8AA3B, %f42;
	fma.rn.f32 	%f44, %f35, 0f32A57060, %f43;
	mov.b32 	%r65, %f40;
	shl.b32 	%r66, %r65, 23;
	mov.b32 	%f45, %r66;
	ex2.approx.ftz.f32 	%f46, %f44;
	mul.rn.f32 	%f47, %f46, %f45;
	neg.f32 	%f48, %f47;
	sub.rn.f32 	%f49, %f48, %f47;
	add.rn.f32 	%f50, %f49, %f49;
	add.rn.f32 	%f51, %f50, %f50;
	add.rn.f32 	%f52, %f51, %f51;
	add.rn.f32 	%f53, %f52, %f52;
	add.rn.f32 	%f54, %f53, %f53;
	fma.rn.f32 	%f55, %f54, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f56, %f55;
	fma.rm.f32 	%f57, %f56, %f39, %f38;
	add.rn.f32 	%f58, %f57, 0fCB40007F;
	neg.f32 	%f59, %f58;
	fma.rn.f32 	%f60, %f54, 0f3FB8AA3B, %f59;
	fma.rn.f32 	%f61, %f54, 0f32A57060, %f60;
	mov.b32 	%r67, %f57;
	shl.b32 	%r68, %r67, 23;
	mov.b32 	%f62, %r68;
	ex2.approx.ftz.f32 	%f63, %f61;
	mul.rn.f32 	%f64, %f63, %f62;
	mul.lo.s64 	%rd49, %rd8, 9600;
	add.s64 	%rd50, %rd4, %rd49;
	mul.lo.s64 	%rd51, %rd9, 192;
	add.s64 	%rd52, %rd50, %rd51;
	mul.lo.s64 	%rd53, %rd10, 24;
	add.s64 	%rd54, %rd52, %rd53;
	shl.b64 	%rd55, %rd11, 2;
	add.s64 	%rd56, %rd54, %rd55;
	ld.global.nc.f32 	%f65, [%rd56+24];
	mul.rn.f32 	%f66, %f65, %f64;
	mul.rn.f32 	%f67, %f34, %f66;
	add.rn.f32 	%f68, %f2, %f67;
$L__BB144_1:
	mul.wide.u32 	%rd57, %r1, 4;
	add.s64 	%rd58, %rd1, %rd57;
	st.global.f32 	[%rd58], %f68;
	ret;

}
	// .globl	loop_slice_fusion_78
.visible .entry loop_slice_fusion_78(
	.param .u64 loop_slice_fusion_78_param_0,
	.param .u64 loop_slice_fusion_78_param_1,
	.param .u64 loop_slice_fusion_78_param_2,
	.param .u64 loop_slice_fusion_78_param_3,
	.param .u64 loop_slice_fusion_78_param_4,
	.param .u64 loop_slice_fusion_78_param_5,
	.param .u64 loop_slice_fusion_78_param_6,
	.param .u64 loop_slice_fusion_78_param_7,
	.param .u64 loop_slice_fusion_78_param_8,
	.param .u64 loop_slice_fusion_78_param_9,
	.param .u64 loop_slice_fusion_78_param_10,
	.param .u64 loop_slice_fusion_78_param_11,
	.param .u64 loop_slice_fusion_78_param_12,
	.param .u64 loop_slice_fusion_78_param_13,
	.param .u64 loop_slice_fusion_78_param_14,
	.param .u64 loop_slice_fusion_78_param_15,
	.param .u64 loop_slice_fusion_78_param_16,
	.param .u64 loop_slice_fusion_78_param_17,
	.param .u64 loop_slice_fusion_78_param_18,
	.param .u64 loop_slice_fusion_78_param_19,
	.param .u64 loop_slice_fusion_78_param_20,
	.param .u64 loop_slice_fusion_78_param_21,
	.param .u64 loop_slice_fusion_78_param_22,
	.param .u64 loop_slice_fusion_78_param_23,
	.param .u64 loop_slice_fusion_78_param_24,
	.param .u64 loop_slice_fusion_78_param_25,
	.param .u64 loop_slice_fusion_78_param_26,
	.param .u64 loop_slice_fusion_78_param_27,
	.param .u64 loop_slice_fusion_78_param_28,
	.param .u64 loop_slice_fusion_78_param_29,
	.param .u64 loop_slice_fusion_78_param_30
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot145[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<139>;
	.reg .f32 	%f<144>;
	.reg .b64 	%rd<238>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot145;
	ld.param.u64 	%rd22, [loop_slice_fusion_78_param_0];
	ld.param.u64 	%rd23, [loop_slice_fusion_78_param_30];
	ld.param.u64 	%rd24, [loop_slice_fusion_78_param_1];
	ld.param.u64 	%rd25, [loop_slice_fusion_78_param_29];
	ld.param.u64 	%rd26, [loop_slice_fusion_78_param_2];
	ld.param.u64 	%rd27, [loop_slice_fusion_78_param_28];
	cvta.to.global.u64 	%rd28, %rd27;
	ld.param.u64 	%rd29, [loop_slice_fusion_78_param_3];
	ld.param.u64 	%rd30, [loop_slice_fusion_78_param_27];
	cvta.to.global.u64 	%rd31, %rd30;
	ld.param.u64 	%rd32, [loop_slice_fusion_78_param_4];
	ld.param.u64 	%rd33, [loop_slice_fusion_78_param_26];
	cvta.to.global.u64 	%rd34, %rd33;
	ld.param.u64 	%rd35, [loop_slice_fusion_78_param_5];
	ld.param.u64 	%rd36, [loop_slice_fusion_78_param_25];
	cvta.to.global.u64 	%rd37, %rd36;
	ld.param.u64 	%rd38, [loop_slice_fusion_78_param_6];
	ld.param.u64 	%rd39, [loop_slice_fusion_78_param_24];
	cvta.to.global.u64 	%rd40, %rd39;
	ld.param.u64 	%rd41, [loop_slice_fusion_78_param_7];
	ld.param.u64 	%rd42, [loop_slice_fusion_78_param_23];
	cvta.to.global.u64 	%rd43, %rd42;
	ld.param.u64 	%rd44, [loop_slice_fusion_78_param_8];
	ld.param.u64 	%rd45, [loop_slice_fusion_78_param_22];
	cvta.to.global.u64 	%rd46, %rd45;
	ld.param.u64 	%rd47, [loop_slice_fusion_78_param_9];
	ld.param.u64 	%rd48, [loop_slice_fusion_78_param_21];
	cvta.to.global.u64 	%rd49, %rd48;
	ld.param.u64 	%rd50, [loop_slice_fusion_78_param_10];
	ld.param.u64 	%rd51, [loop_slice_fusion_78_param_20];
	cvta.to.global.u64 	%rd52, %rd51;
	ld.param.u64 	%rd53, [loop_slice_fusion_78_param_11];
	ld.param.u64 	%rd54, [loop_slice_fusion_78_param_19];
	cvta.to.global.u64 	%rd55, %rd54;
	ld.param.u64 	%rd56, [loop_slice_fusion_78_param_12];
	ld.param.u64 	%rd57, [loop_slice_fusion_78_param_18];
	cvta.to.global.u64 	%rd58, %rd57;
	ld.param.u64 	%rd59, [loop_slice_fusion_78_param_13];
	ld.param.u64 	%rd60, [loop_slice_fusion_78_param_17];
	cvta.to.global.u64 	%rd61, %rd60;
	ld.param.u64 	%rd62, [loop_slice_fusion_78_param_14];
	ld.param.u64 	%rd63, [loop_slice_fusion_78_param_16];
	cvta.to.global.u64 	%rd64, %rd63;
	ld.param.u64 	%rd65, [loop_slice_fusion_78_param_15];
	cvta.to.global.u64 	%rd66, %rd65;
	cvta.to.global.u64 	%rd67, %rd62;
	cvta.to.global.u64 	%rd68, %rd59;
	cvta.to.global.u64 	%rd69, %rd56;
	cvta.to.global.u64 	%rd70, %rd53;
	cvta.to.global.u64 	%rd71, %rd50;
	cvta.to.global.u64 	%rd72, %rd47;
	cvta.to.global.u64 	%rd73, %rd44;
	cvta.to.global.u64 	%rd74, %rd41;
	cvta.to.global.u64 	%rd75, %rd38;
	cvta.to.global.u64 	%rd3, %rd35;
	cvta.to.global.u64 	%rd4, %rd32;
	cvta.to.global.u64 	%rd5, %rd29;
	cvta.to.global.u64 	%rd6, %rd26;
	add.u64 	%rd9, %SPL, 0;
	mov.u32 	%r36, %ctaid.x;
	mov.u32 	%r37, %tid.x;
	shl.b32 	%r38, %r36, 7;
	or.b32  	%r1, %r38, %r37;
	mul.hi.u32 	%r39, %r1, -1431655765;
	shr.u32 	%r40, %r39, 2;
	mul.lo.s32 	%r41, %r40, 6;
	sub.s32 	%r42, %r1, %r41;
	shr.u32 	%r43, %r39, 4;
	cvt.u16.u32 	%rs1, %r43;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r44, %r1, 458129845;
	bfe.u32 	%r45, %r44, 7, 6;
	shr.u32 	%r46, %r39, 1;
	and.b32  	%r2, %r46, 6;
	shl.b32 	%r3, %r2, 1;
	or.b32  	%r47, %r3, 1;
	shl.b32 	%r48, %r47, 1;
	shl.b32 	%r49, %r47, 2;
	or.b32  	%r50, %r49, 2;
	or.b32  	%r51, %r49, 3;
	shl.b32 	%r52, %r51, 1;
	shl.b32 	%r53, %r51, 2;
	or.b32  	%r54, %r53, 2;
	or.b32  	%r55, %r53, 3;
	shl.b32 	%r56, %r55, 1;
	shl.b32 	%r57, %r55, 2;
	or.b32  	%r58, %r57, 2;
	shl.b16 	%rs7, %rs6, 10;
	cvt.u64.u32 	%rd11, %r45;
	cvt.u64.u32 	%rd12, %r42;
	cvt.u64.u32 	%rd78, %r58;
	cvt.u64.u16 	%rd79, %rs7;
	add.s64 	%rd80, %rd79, %rd78;
	mul.lo.s64 	%rd81, %rd80, 24;
	mul.wide.u32 	%rd82, %r45, 1228800;
	add.s64 	%rd83, %rd46, %rd82;
	add.s64 	%rd84, %rd83, %rd81;
	mul.wide.u32 	%rd85, %r42, 4;
	add.s64 	%rd86, %rd84, %rd85;
	ld.global.nc.f32 	%f1, [%rd86+24];
	cvt.u64.u16 	%rd13, %rs6;
	cvt.u32.u16 	%r59, %rs6;
	mul.wide.u32 	%rd87, %r59, 12264;
	mul.wide.u32 	%rd88, %r45, 613200;
	add.s64 	%rd89, %rd37, %rd88;
	add.s64 	%rd90, %rd89, %rd87;
	mul.wide.u32 	%rd91, %r56, 24;
	add.s64 	%rd92, %rd90, %rd91;
	add.s64 	%rd93, %rd92, %rd85;
	ld.global.nc.f32 	%f2, [%rd93+24];
	add.s64 	%rd94, %rd34, %rd88;
	add.s64 	%rd95, %rd94, %rd87;
	add.s64 	%rd96, %rd95, %rd91;
	add.s64 	%rd97, %rd96, %rd85;
	ld.global.nc.f32 	%f3, [%rd97+24];
	shr.u32 	%r60, %r42, 1;
	mul.wide.u32 	%rd98, %r60, 4;
	mul.wide.u32 	%rd99, %r45, 12;
	add.s64 	%rd100, %rd40, %rd99;
	add.s64 	%rd101, %rd100, %rd98;
	ld.global.nc.f32 	%f4, [%rd101];
	mul.wide.u32 	%rd102, %r45, 4;
	add.s64 	%rd103, %rd43, %rd102;
	ld.global.nc.f32 	%f5, [%rd103];
	cvt.u64.u32 	%rd104, %r57;
	add.s64 	%rd105, %rd79, %rd104;
	mul.lo.s64 	%rd106, %rd105, 24;
	add.s64 	%rd107, %rd83, %rd106;
	add.s64 	%rd108, %rd107, %rd85;
	ld.global.nc.f32 	%f6, [%rd108+96];
	mul.wide.u32 	%rd109, %r59, 6120;
	mul.wide.u32 	%rd110, %r45, 306000;
	add.s64 	%rd111, %rd52, %rd110;
	add.s64 	%rd112, %rd111, %rd109;
	mul.wide.u32 	%rd113, %r54, 24;
	add.s64 	%rd114, %rd112, %rd113;
	add.s64 	%rd115, %rd114, %rd85;
	ld.global.nc.f32 	%f7, [%rd115+24];
	add.s64 	%rd116, %rd49, %rd110;
	add.s64 	%rd117, %rd116, %rd109;
	add.s64 	%rd118, %rd117, %rd113;
	add.s64 	%rd119, %rd118, %rd85;
	ld.global.nc.f32 	%f8, [%rd119+24];
	add.s64 	%rd120, %rd55, %rd99;
	add.s64 	%rd121, %rd120, %rd98;
	ld.global.nc.f32 	%f9, [%rd121];
	add.s64 	%rd122, %rd58, %rd102;
	ld.global.nc.f32 	%f10, [%rd122];
	add.s64 	%rd123, %rd61, %rd110;
	add.s64 	%rd124, %rd123, %rd109;
	add.s64 	%rd125, %rd124, %rd113;
	add.s64 	%rd126, %rd125, %rd85;
	ld.global.nc.f32 	%f11, [%rd126+24];
	mul.wide.u32 	%rd127, %r59, 3048;
	mul.wide.u32 	%rd128, %r45, 152400;
	add.s64 	%rd129, %rd66, %rd128;
	add.s64 	%rd130, %rd129, %rd127;
	mul.wide.u32 	%rd131, %r52, 24;
	add.s64 	%rd132, %rd130, %rd131;
	add.s64 	%rd133, %rd132, %rd85;
	ld.global.nc.f32 	%f12, [%rd133+24];
	add.s64 	%rd134, %rd64, %rd128;
	add.s64 	%rd135, %rd134, %rd127;
	add.s64 	%rd136, %rd135, %rd131;
	add.s64 	%rd137, %rd136, %rd85;
	ld.global.nc.f32 	%f13, [%rd137+24];
	add.s64 	%rd138, %rd67, %rd99;
	add.s64 	%rd139, %rd138, %rd98;
	ld.global.nc.f32 	%f14, [%rd139];
	add.s64 	%rd140, %rd68, %rd102;
	ld.global.nc.f32 	%f15, [%rd140];
	add.s64 	%rd141, %rd69, %rd128;
	add.s64 	%rd142, %rd141, %rd127;
	add.s64 	%rd143, %rd142, %rd131;
	add.s64 	%rd144, %rd143, %rd85;
	ld.global.nc.f32 	%f16, [%rd144+24];
	mul.wide.u32 	%rd145, %r59, 1512;
	mul.wide.u32 	%rd146, %r45, 75600;
	add.s64 	%rd147, %rd71, %rd146;
	add.s64 	%rd148, %rd147, %rd145;
	mul.wide.u32 	%rd149, %r50, 24;
	add.s64 	%rd150, %rd148, %rd149;
	add.s64 	%rd151, %rd150, %rd85;
	ld.global.nc.f32 	%f17, [%rd151+24];
	add.s64 	%rd152, %rd70, %rd146;
	add.s64 	%rd153, %rd152, %rd145;
	add.s64 	%rd154, %rd153, %rd149;
	add.s64 	%rd155, %rd154, %rd85;
	ld.global.nc.f32 	%f18, [%rd155+24];
	add.s64 	%rd156, %rd31, %rd99;
	add.s64 	%rd157, %rd156, %rd98;
	ld.global.nc.f32 	%f19, [%rd157];
	add.s64 	%rd158, %rd72, %rd102;
	ld.global.nc.f32 	%f20, [%rd158];
	mul.wide.u32 	%rd159, %r59, 1536;
	mul.wide.u32 	%rd160, %r45, 76800;
	add.s64 	%rd161, %rd73, %rd160;
	add.s64 	%rd162, %rd161, %rd159;
	add.s64 	%rd163, %rd162, %rd149;
	add.s64 	%rd164, %rd163, %rd85;
	ld.global.nc.f32 	%f21, [%rd164+48];
	cvt.u64.u32 	%rd14, %r48;
	mul.wide.u32 	%rd165, %r59, 744;
	mul.wide.u32 	%rd166, %r45, 37200;
	add.s64 	%rd167, %rd75, %rd166;
	add.s64 	%rd168, %rd167, %rd165;
	mul.wide.u32 	%rd169, %r48, 24;
	add.s64 	%rd170, %rd168, %rd169;
	add.s64 	%rd171, %rd170, %rd85;
	ld.global.nc.f32 	%f22, [%rd171+24];
	add.s64 	%rd172, %rd74, %rd166;
	add.s64 	%rd173, %rd172, %rd165;
	add.s64 	%rd174, %rd173, %rd169;
	add.s64 	%rd175, %rd174, %rd85;
	ld.global.nc.f32 	%f23, [%rd175+24];
	add.s64 	%rd176, %rd28, %rd99;
	add.s64 	%rd177, %rd176, %rd98;
	ld.global.nc.f32 	%f24, [%rd177];
	mul.rn.f32 	%f40, %f24, 0f3F22F983;
	cvt.rni.s32.f32 	%r134, %f40;
	cvt.rn.f32.s32 	%f41, %r134;
	fma.rn.f32 	%f42, %f41, 0fBFC90FDA, %f24;
	fma.rn.f32 	%f43, %f41, 0fB3A22168, %f42;
	fma.rn.f32 	%f142, %f41, 0fA7C234C5, %f43;
	abs.f32 	%f26, %f24;
	setp.ltu.f32 	%p1, %f26, 0f47CE4780;
	mov.f32 	%f141, 0f00000000;
	@%p1 bra 	$L__BB145_8;
	setp.neu.f32 	%p2, %f26, 0f7F800000;
	@%p2 bra 	$L__BB145_3;
	mul.rn.f32 	%f142, %f24, %f141;
	mov.b32 	%r134, 0;
	bra.uni 	$L__BB145_8;
$L__BB145_3:
	mov.b32 	%r5, %f24;
	shr.u32 	%r6, %r5, 23;
	and.b32  	%r62, %r6, 224;
	add.s32 	%r63, %r62, -128;
	shl.b32 	%r64, %r5, 8;
	or.b32  	%r68, %r64, -2147483648;
	shr.u32 	%r8, %r63, 5;
	mov.b32 	%r131, 0;
	mov.u64 	%rd236, 0;
	mov.u64 	%rd179, __cudart_i2opi_f;
$L__BB145_4:
	.pragma "nounroll";
	add.s64 	%rd180, %rd179, %rd236;
	ld.global.nc.u32 	%r67, [%rd180];
	// begin inline asm
	{
	mad.lo.cc.u32   %r65, %r67, %r68, %r131;
	madc.hi.u32     %r131, %r67, %r68,  0;
	}
	// end inline asm
	add.s64 	%rd181, %rd9, %rd236;
	st.local.u32 	[%rd181], %r65;
	add.s64 	%rd236, %rd236, 4;
	cvt.u32.u64 	%r70, %rd236;
	setp.ne.s32 	%p3, %r70, 24;
	@%p3 bra 	$L__BB145_4;
	st.local.u32 	[%rd9+24], %r131;
	and.b32  	%r11, %r6, 31;
	mul.wide.u32 	%rd182, %r8, 4;
	sub.s64 	%rd17, %rd9, %rd182;
	ld.local.u32 	%r132, [%rd17+24];
	ld.local.u32 	%r133, [%rd17+20];
	setp.eq.s32 	%p4, %r11, 0;
	@%p4 bra 	$L__BB145_7;
	shl.b32 	%r71, %r133, %r11;
	shl.b32 	%r72, %r132, %r11;
	mov.b32 	%r73, 32;
	sub.s32 	%r74, %r73, %r11;
	shr.u32 	%r75, %r133, %r74;
	add.s32 	%r132, %r75, %r72;
	ld.local.u32 	%r76, [%rd17+16];
	shr.u32 	%r77, %r76, %r74;
	add.s32 	%r133, %r77, %r71;
$L__BB145_7:
	shr.u32 	%r78, %r132, 30;
	shr.u32 	%r79, %r133, 30;
	shl.b32 	%r80, %r132, 2;
	or.b32  	%r81, %r80, %r79;
	shl.b32 	%r82, %r133, 2;
	bfe.u32 	%r83, %r132, 29, 1;
	add.s32 	%r84, %r83, %r78;
	neg.s32 	%r85, %r84;
	setp.lt.s32 	%p5, %r5, 0;
	selp.b32 	%r134, %r85, %r84, %p5;
	xor.b32  	%r86, %r81, %r5;
	bfe.s32 	%r87, %r132, 29, 1;
	xor.b32  	%r88, %r87, %r81;
	xor.b32  	%r89, %r87, %r82;
	cvt.u64.u32 	%rd183, %r88;
	shl.b64 	%rd184, %rd183, 32;
	cvt.u64.u32 	%rd185, %r89;
	or.b64  	%rd186, %rd184, %rd185;
	cvt.rn.f64.s64 	%fd1, %rd186;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f44, %fd2;
	neg.f32 	%f45, %f44;
	setp.lt.s32 	%p6, %r86, 0;
	selp.f32 	%f142, %f45, %f44, %p6;
$L__BB145_8:
	cvta.to.global.u64 	%rd1, %rd23;
	cvta.to.global.u64 	%rd2, %rd25;
	cvta.to.global.u64 	%rd7, %rd24;
	cvta.to.global.u64 	%rd8, %rd22;
	shl.b64 	%rd187, %rd11, 2;
	add.s64 	%rd188, %rd3, %rd187;
	ld.global.nc.f32 	%f30, [%rd188];
	mul.lo.s64 	%rd189, %rd11, 38400;
	add.s64 	%rd190, %rd4, %rd189;
	mul.lo.s64 	%rd191, %rd13, 768;
	add.s64 	%rd192, %rd190, %rd191;
	mul.lo.s64 	%rd193, %rd14, 24;
	add.s64 	%rd194, %rd192, %rd193;
	shl.b64 	%rd195, %rd12, 2;
	add.s64 	%rd196, %rd194, %rd195;
	ld.global.nc.f32 	%f31, [%rd196+48];
	cvt.u64.u32 	%rd18, %r3;
	mul.lo.s64 	%rd197, %rd11, 18000;
	add.s64 	%rd198, %rd6, %rd197;
	mul.lo.s64 	%rd199, %rd13, 360;
	add.s64 	%rd200, %rd198, %rd199;
	mul.wide.u32 	%rd201, %r3, 24;
	add.s64 	%rd202, %rd200, %rd201;
	add.s64 	%rd203, %rd202, %rd195;
	ld.global.nc.f32 	%f32, [%rd203+24];
	add.s64 	%rd204, %rd5, %rd197;
	add.s64 	%rd205, %rd204, %rd199;
	add.s64 	%rd206, %rd205, %rd201;
	add.s64 	%rd207, %rd206, %rd195;
	ld.global.nc.f32 	%f33, [%rd207+24];
	add.rn.f32 	%f34, %f24, %f24;
	mul.rn.f32 	%f47, %f34, 0f3F22F983;
	cvt.rni.s32.f32 	%r138, %f47;
	cvt.rn.f32.s32 	%f48, %r138;
	fma.rn.f32 	%f49, %f48, 0fBFC90FDA, %f34;
	fma.rn.f32 	%f50, %f48, 0fB3A22168, %f49;
	fma.rn.f32 	%f143, %f48, 0fA7C234C5, %f50;
	abs.f32 	%f36, %f34;
	setp.ltu.f32 	%p7, %f36, 0f47CE4780;
	@%p7 bra 	$L__BB145_16;
	setp.neu.f32 	%p8, %f36, 0f7F800000;
	@%p8 bra 	$L__BB145_11;
	mul.rn.f32 	%f143, %f34, %f141;
	mov.b32 	%r138, 0;
	bra.uni 	$L__BB145_16;
$L__BB145_11:
	mov.b32 	%r21, %f34;
	shr.u32 	%r22, %r21, 23;
	and.b32  	%r92, %r22, 224;
	add.s32 	%r93, %r92, -128;
	shl.b32 	%r94, %r21, 8;
	or.b32  	%r98, %r94, -2147483648;
	shr.u32 	%r24, %r93, 5;
	mov.b32 	%r135, 0;
	mov.u64 	%rd237, 0;
	mov.u64 	%rd209, __cudart_i2opi_f;
$L__BB145_12:
	.pragma "nounroll";
	add.s64 	%rd210, %rd209, %rd237;
	ld.global.nc.u32 	%r97, [%rd210];
	// begin inline asm
	{
	mad.lo.cc.u32   %r95, %r97, %r98, %r135;
	madc.hi.u32     %r135, %r97, %r98,  0;
	}
	// end inline asm
	add.s64 	%rd211, %rd9, %rd237;
	st.local.u32 	[%rd211], %r95;
	add.s64 	%rd237, %rd237, 4;
	cvt.u32.u64 	%r100, %rd237;
	setp.ne.s32 	%p9, %r100, 24;
	@%p9 bra 	$L__BB145_12;
	st.local.u32 	[%rd9+24], %r135;
	and.b32  	%r27, %r22, 31;
	mul.wide.u32 	%rd212, %r24, 4;
	sub.s64 	%rd21, %rd9, %rd212;
	ld.local.u32 	%r136, [%rd21+24];
	ld.local.u32 	%r137, [%rd21+20];
	setp.eq.s32 	%p10, %r27, 0;
	@%p10 bra 	$L__BB145_15;
	shl.b32 	%r101, %r137, %r27;
	shl.b32 	%r102, %r136, %r27;
	mov.b32 	%r103, 32;
	sub.s32 	%r104, %r103, %r27;
	shr.u32 	%r105, %r137, %r104;
	add.s32 	%r136, %r105, %r102;
	ld.local.u32 	%r106, [%rd21+16];
	shr.u32 	%r107, %r106, %r104;
	add.s32 	%r137, %r107, %r101;
$L__BB145_15:
	shr.u32 	%r108, %r136, 30;
	shr.u32 	%r109, %r137, 30;
	shl.b32 	%r110, %r136, 2;
	or.b32  	%r111, %r110, %r109;
	shl.b32 	%r112, %r137, 2;
	bfe.u32 	%r113, %r136, 29, 1;
	add.s32 	%r114, %r113, %r108;
	neg.s32 	%r115, %r114;
	setp.lt.s32 	%p11, %r21, 0;
	selp.b32 	%r138, %r115, %r114, %p11;
	xor.b32  	%r116, %r111, %r21;
	bfe.s32 	%r117, %r136, 29, 1;
	xor.b32  	%r118, %r117, %r111;
	xor.b32  	%r119, %r117, %r112;
	cvt.u64.u32 	%rd213, %r118;
	shl.b64 	%rd214, %rd213, 32;
	cvt.u64.u32 	%rd215, %r119;
	or.b64  	%rd216, %rd214, %rd215;
	cvt.rn.f64.s64 	%fd3, %rd216;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f51, %fd4;
	neg.f32 	%f52, %f51;
	setp.lt.s32 	%p12, %r116, 0;
	selp.f32 	%f143, %f52, %f51, %p12;
$L__BB145_16:
	add.rn.f32 	%f54, %f2, %f3;
	mul.rn.f32 	%f55, %f5, %f6;
	mul.rn.f32 	%f56, %f4, %f55;
	add.rn.f32 	%f57, %f54, %f56;
	add.rn.f32 	%f58, %f1, %f57;
	add.rn.f32 	%f59, %f7, %f8;
	mul.rn.f32 	%f60, %f10, %f11;
	mul.rn.f32 	%f61, %f9, %f60;
	add.rn.f32 	%f62, %f59, %f61;
	add.rn.f32 	%f63, %f58, %f62;
	add.rn.f32 	%f64, %f12, %f13;
	mul.rn.f32 	%f65, %f15, %f16;
	mul.rn.f32 	%f66, %f14, %f65;
	add.rn.f32 	%f67, %f64, %f66;
	add.rn.f32 	%f68, %f63, %f67;
	add.rn.f32 	%f69, %f17, %f18;
	mul.rn.f32 	%f70, %f20, %f21;
	mul.rn.f32 	%f71, %f19, %f70;
	add.rn.f32 	%f72, %f69, %f71;
	add.rn.f32 	%f73, %f68, %f72;
	add.rn.f32 	%f74, %f22, %f23;
	add.s32 	%r121, %r134, 1;
	and.b32  	%r122, %r121, 2;
	setp.eq.s32 	%p13, %r122, 0;
	and.b32  	%r123, %r134, 1;
	setp.eq.b32 	%p14, %r123, 1;
	mul.rn.f32 	%f75, %f142, %f142;
	fma.rn.f32 	%f76, %f75, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f77, 0fB94D4153, %f76, %p14;
	selp.f32 	%f78, 0f3C0885E4, 0f3D2AAABB, %p14;
	fma.rn.f32 	%f79, %f77, %f75, %f78;
	selp.f32 	%f80, 0fBE2AAAA8, 0fBEFFFFFF, %p14;
	fma.rn.f32 	%f81, %f79, %f75, %f80;
	selp.f32 	%f82, %f142, 0f3F800000, %p14;
	fma.rn.f32 	%f83, %f75, %f82, 0f00000000;
	fma.rn.f32 	%f84, %f81, %f83, %f82;
	sub.rn.f32 	%f86, %f141, %f84;
	selp.f32 	%f87, %f84, %f86, %p13;
	mul.rn.f32 	%f88, %f30, %f31;
	mul.rn.f32 	%f89, %f88, %f87;
	add.rn.f32 	%f90, %f74, %f89;
	add.rn.f32 	%f91, %f73, %f90;
	add.s32 	%r124, %r138, 1;
	mul.rn.f32 	%f92, %f143, %f143;
	and.b32  	%r125, %r138, 1;
	setp.eq.b32 	%p15, %r125, 1;
	selp.f32 	%f93, %f143, 0f3F800000, %p15;
	fma.rn.f32 	%f94, %f92, %f93, 0f00000000;
	fma.rn.f32 	%f95, %f92, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f96, 0fB94D4153, %f95, %p15;
	selp.f32 	%f97, 0f3C0885E4, 0f3D2AAABB, %p15;
	fma.rn.f32 	%f98, %f96, %f92, %f97;
	selp.f32 	%f99, 0fBE2AAAA8, 0fBEFFFFFF, %p15;
	fma.rn.f32 	%f100, %f98, %f92, %f99;
	fma.rn.f32 	%f101, %f100, %f94, %f93;
	and.b32  	%r126, %r124, 2;
	setp.eq.s32 	%p16, %r126, 0;
	sub.rn.f32 	%f102, %f141, %f101;
	selp.f32 	%f103, %f101, %f102, %p16;
	add.s64 	%rd218, %rd2, %rd187;
	ld.global.nc.f32 	%f104, [%rd218];
	fma.rn.f32 	%f105, %f104, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f106, %f105;
	mov.f32 	%f107, 0f4B400001;
	mov.f32 	%f108, 0f437C0000;
	fma.rm.f32 	%f109, %f106, %f108, %f107;
	add.rn.f32 	%f110, %f109, 0fCB40007F;
	neg.f32 	%f111, %f110;
	fma.rn.f32 	%f112, %f104, 0f3FB8AA3B, %f111;
	fma.rn.f32 	%f113, %f104, 0f32A57060, %f112;
	mov.b32 	%r127, %f109;
	shl.b32 	%r128, %r127, 23;
	mov.b32 	%f114, %r128;
	ex2.approx.ftz.f32 	%f115, %f113;
	mul.rn.f32 	%f116, %f115, %f114;
	neg.f32 	%f117, %f116;
	sub.rn.f32 	%f118, %f117, %f116;
	add.rn.f32 	%f119, %f118, %f118;
	add.rn.f32 	%f120, %f119, %f119;
	add.rn.f32 	%f121, %f120, %f120;
	add.rn.f32 	%f122, %f121, %f121;
	fma.rn.f32 	%f123, %f122, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f124, %f123;
	fma.rm.f32 	%f125, %f124, %f108, %f107;
	add.rn.f32 	%f126, %f125, 0fCB40007F;
	neg.f32 	%f127, %f126;
	fma.rn.f32 	%f128, %f122, 0f3FB8AA3B, %f127;
	fma.rn.f32 	%f129, %f122, 0f32A57060, %f128;
	mov.b32 	%r129, %f125;
	shl.b32 	%r130, %r129, 23;
	mov.b32 	%f130, %r130;
	ex2.approx.ftz.f32 	%f131, %f129;
	mul.rn.f32 	%f132, %f131, %f130;
	add.rn.f32 	%f133, %f32, %f33;
	mul.lo.s64 	%rd219, %rd11, 19200;
	add.s64 	%rd220, %rd7, %rd219;
	mul.lo.s64 	%rd221, %rd13, 384;
	add.s64 	%rd222, %rd220, %rd221;
	mul.lo.s64 	%rd223, %rd18, 24;
	add.s64 	%rd224, %rd222, %rd223;
	add.s64 	%rd226, %rd224, %rd195;
	ld.global.nc.f32 	%f134, [%rd226+48];
	mul.rn.f32 	%f135, %f134, %f132;
	mul.rn.f32 	%f136, %f103, %f135;
	add.rn.f32 	%f137, %f133, %f136;
	add.rn.f32 	%f138, %f91, %f137;
	mul.lo.s64 	%rd227, %rd11, 9600;
	add.s64 	%rd228, %rd8, %rd227;
	mul.lo.s64 	%rd229, %rd13, 192;
	add.s64 	%rd230, %rd228, %rd229;
	mul.wide.u32 	%rd231, %r2, 24;
	add.s64 	%rd232, %rd230, %rd231;
	add.s64 	%rd233, %rd232, %rd195;
	ld.global.nc.f32 	%f139, [%rd233];
	add.rn.f32 	%f140, %f139, %f138;
	mul.wide.u32 	%rd234, %r1, 4;
	add.s64 	%rd235, %rd1, %rd234;
	st.global.f32 	[%rd235], %f140;
	ret;

}
	// .globl	loop_transpose_fusion_110
.visible .entry loop_transpose_fusion_110(
	.param .u64 loop_transpose_fusion_110_param_0,
	.param .u64 loop_transpose_fusion_110_param_1,
	.param .u64 loop_transpose_fusion_110_param_2,
	.param .u64 loop_transpose_fusion_110_param_3,
	.param .u64 loop_transpose_fusion_110_param_4
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot146[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<117>;
	.reg .f32 	%f<89>;
	.reg .b64 	%rd<59>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot146;
	ld.param.u64 	%rd15, [loop_transpose_fusion_110_param_0];
	ld.param.u64 	%rd16, [loop_transpose_fusion_110_param_4];
	ld.param.u64 	%rd17, [loop_transpose_fusion_110_param_1];
	ld.param.u64 	%rd18, [loop_transpose_fusion_110_param_3];
	ld.param.u64 	%rd19, [loop_transpose_fusion_110_param_2];
	cvta.to.global.u64 	%rd3, %rd19;
	cvta.to.global.u64 	%rd20, %rd17;
	cvta.to.global.u64 	%rd4, %rd15;
	add.u64 	%rd5, %SPL, 0;
	mov.u32 	%r33, %ctaid.x;
	shl.b32 	%r34, %r33, 7;
	mov.u32 	%r35, %tid.x;
	or.b32  	%r1, %r34, %r35;
	cvt.u16.u32 	%rs4, %r33;
	and.b16  	%rs5, %rs4, 255;
	mul.lo.s16 	%rs6, %rs5, 219;
	shr.u16 	%rs7, %rs6, 14;
	cvt.u16.u32 	%rs8, %r1;
	shr.u16 	%rs9, %rs8, 1;
	mul.hi.u16 	%rs10, %rs9, -9611;
	shr.u16 	%rs11, %rs10, 6;
	and.b16  	%rs12, %rs11, 63;
	mul.hi.u16 	%rs13, %rs8, -21845;
	shr.u16 	%rs14, %rs13, 1;
	mul.hi.u16 	%rs15, %rs14, 5243;
	shr.u16 	%rs16, %rs15, 2;
	mul.lo.s16 	%rs17, %rs16, 50;
	sub.s16 	%rs1, %rs14, %rs17;
	mul.lo.s16 	%rs18, %rs14, 3;
	sub.s16 	%rs2, %rs8, %rs18;
	shl.b16 	%rs3, %rs7, 1;
	cvt.u64.u16 	%rd7, %rs12;
	cvt.u32.u16 	%r36, %rs12;
	mul.wide.u32 	%rd23, %r36, 12;
	add.s64 	%rd24, %rd20, %rd23;
	cvt.u32.u16 	%r37, %rs7;
	mul.wide.u32 	%rd25, %r37, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f12, [%rd26];
	add.rn.f32 	%f13, %f12, %f12;
	add.rn.f32 	%f14, %f13, %f13;
	add.rn.f32 	%f1, %f14, %f14;
	mul.rn.f32 	%f15, %f1, 0f3F22F983;
	cvt.rni.s32.f32 	%r116, %f15;
	cvt.rn.f32.s32 	%f16, %r116;
	fma.rn.f32 	%f17, %f16, 0fBFC90FDA, %f1;
	fma.rn.f32 	%f18, %f16, 0fB3A22168, %f17;
	fma.rn.f32 	%f88, %f16, 0fA7C234C5, %f18;
	abs.f32 	%f3, %f1;
	setp.ltu.f32 	%p1, %f3, 0f47CE4780;
	setp.neu.f32 	%p17, %f3, 0f7F800000;
	mov.f32 	%f86, 0f00000000;
	mov.u32 	%r112, %r116;
	mov.f32 	%f87, %f88;
	@%p1 bra 	$L__BB146_8;
	@%p17 bra 	$L__BB146_3;
	mul.rn.f32 	%f87, %f1, %f86;
	mov.b32 	%r112, 0;
	bra.uni 	$L__BB146_8;
$L__BB146_3:
	mov.b32 	%r3, %f1;
	shr.u32 	%r4, %r3, 23;
	and.b32  	%r39, %r4, 224;
	add.s32 	%r40, %r39, -128;
	shl.b32 	%r41, %r3, 8;
	or.b32  	%r45, %r41, -2147483648;
	shr.u32 	%r6, %r40, 5;
	mov.b32 	%r109, 0;
	mov.u64 	%rd57, 0;
	mov.u64 	%rd28, __cudart_i2opi_f;
$L__BB146_4:
	.pragma "nounroll";
	add.s64 	%rd29, %rd28, %rd57;
	ld.global.nc.u32 	%r44, [%rd29];
	// begin inline asm
	{
	mad.lo.cc.u32   %r42, %r44, %r45, %r109;
	madc.hi.u32     %r109, %r44, %r45,  0;
	}
	// end inline asm
	add.s64 	%rd30, %rd5, %rd57;
	st.local.u32 	[%rd30], %r42;
	add.s64 	%rd57, %rd57, 4;
	cvt.u32.u64 	%r47, %rd57;
	setp.ne.s32 	%p3, %r47, 24;
	@%p3 bra 	$L__BB146_4;
	st.local.u32 	[%rd5+24], %r109;
	and.b32  	%r9, %r4, 31;
	mul.wide.u32 	%rd31, %r6, 4;
	sub.s64 	%rd10, %rd5, %rd31;
	ld.local.u32 	%r110, [%rd10+24];
	ld.local.u32 	%r111, [%rd10+20];
	setp.eq.s32 	%p4, %r9, 0;
	@%p4 bra 	$L__BB146_7;
	shl.b32 	%r48, %r111, %r9;
	shl.b32 	%r49, %r110, %r9;
	mov.b32 	%r50, 32;
	sub.s32 	%r51, %r50, %r9;
	shr.u32 	%r52, %r111, %r51;
	add.s32 	%r110, %r52, %r49;
	ld.local.u32 	%r53, [%rd10+16];
	shr.u32 	%r54, %r53, %r51;
	add.s32 	%r111, %r54, %r48;
$L__BB146_7:
	shr.u32 	%r55, %r110, 30;
	shr.u32 	%r56, %r111, 30;
	shl.b32 	%r57, %r110, 2;
	or.b32  	%r58, %r57, %r56;
	shl.b32 	%r59, %r111, 2;
	bfe.u32 	%r60, %r110, 29, 1;
	add.s32 	%r61, %r60, %r55;
	neg.s32 	%r62, %r61;
	setp.lt.s32 	%p5, %r3, 0;
	selp.b32 	%r112, %r62, %r61, %p5;
	xor.b32  	%r63, %r58, %r3;
	bfe.s32 	%r64, %r110, 29, 1;
	xor.b32  	%r65, %r64, %r58;
	xor.b32  	%r66, %r64, %r59;
	cvt.u64.u32 	%rd32, %r65;
	shl.b64 	%rd33, %rd32, 32;
	cvt.u64.u32 	%rd34, %r66;
	or.b64  	%rd35, %rd33, %rd34;
	cvt.rn.f64.s64 	%fd1, %rd35;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f19, %fd2;
	neg.f32 	%f20, %f19;
	setp.lt.s32 	%p6, %r63, 0;
	selp.f32 	%f87, %f20, %f19, %p6;
$L__BB146_8:
	cvta.to.global.u64 	%rd1, %rd16;
	cvta.to.global.u64 	%rd2, %rd18;
	shl.b64 	%rd36, %rd7, 2;
	add.s64 	%rd37, %rd3, %rd36;
	ld.global.nc.f32 	%f7, [%rd37];
	mul.lo.s64 	%rd38, %rd7, 4800;
	add.s64 	%rd39, %rd4, %rd38;
	cvt.u32.u16 	%r68, %rs1;
	mul.wide.u32 	%rd40, %r68, 96;
	add.s64 	%rd41, %rd39, %rd40;
	cvt.u32.u16 	%r69, %rs2;
	mul.wide.u32 	%rd42, %r69, 24;
	add.s64 	%rd43, %rd41, %rd42;
	cvt.u32.u16 	%r70, %rs3;
	mul.wide.u32 	%rd44, %r70, 4;
	add.s64 	%rd11, %rd43, %rd44;
	ld.global.nc.f32 	%f8, [%rd11+24];
	@%p1 bra 	$L__BB146_16;
	@%p17 bra 	$L__BB146_11;
	mul.rn.f32 	%f88, %f1, %f86;
	mov.b32 	%r116, 0;
	bra.uni 	$L__BB146_16;
$L__BB146_11:
	mov.b32 	%r18, %f1;
	shr.u32 	%r19, %r18, 23;
	and.b32  	%r72, %r19, 224;
	add.s32 	%r73, %r72, -128;
	shl.b32 	%r74, %r18, 8;
	or.b32  	%r78, %r74, -2147483648;
	shr.u32 	%r21, %r73, 5;
	mov.b32 	%r113, 0;
	mov.u64 	%rd58, 0;
	mov.u64 	%rd46, __cudart_i2opi_f;
$L__BB146_12:
	.pragma "nounroll";
	add.s64 	%rd47, %rd46, %rd58;
	ld.global.nc.u32 	%r77, [%rd47];
	// begin inline asm
	{
	mad.lo.cc.u32   %r75, %r77, %r78, %r113;
	madc.hi.u32     %r113, %r77, %r78,  0;
	}
	// end inline asm
	add.s64 	%rd48, %rd5, %rd58;
	st.local.u32 	[%rd48], %r75;
	add.s64 	%rd58, %rd58, 4;
	cvt.u32.u64 	%r80, %rd58;
	setp.ne.s32 	%p9, %r80, 24;
	@%p9 bra 	$L__BB146_12;
	st.local.u32 	[%rd5+24], %r113;
	and.b32  	%r24, %r19, 31;
	mul.wide.u32 	%rd49, %r21, 4;
	sub.s64 	%rd14, %rd5, %rd49;
	ld.local.u32 	%r114, [%rd14+24];
	ld.local.u32 	%r115, [%rd14+20];
	setp.eq.s32 	%p10, %r24, 0;
	@%p10 bra 	$L__BB146_15;
	shl.b32 	%r81, %r115, %r24;
	shl.b32 	%r82, %r114, %r24;
	mov.b32 	%r83, 32;
	sub.s32 	%r84, %r83, %r24;
	shr.u32 	%r85, %r115, %r84;
	add.s32 	%r114, %r85, %r82;
	ld.local.u32 	%r86, [%rd14+16];
	shr.u32 	%r87, %r86, %r84;
	add.s32 	%r115, %r87, %r81;
$L__BB146_15:
	shr.u32 	%r88, %r114, 30;
	shr.u32 	%r89, %r115, 30;
	shl.b32 	%r90, %r114, 2;
	or.b32  	%r91, %r90, %r89;
	shl.b32 	%r92, %r115, 2;
	bfe.u32 	%r93, %r114, 29, 1;
	add.s32 	%r94, %r93, %r88;
	neg.s32 	%r95, %r94;
	setp.lt.s32 	%p11, %r18, 0;
	selp.b32 	%r116, %r95, %r94, %p11;
	xor.b32  	%r96, %r91, %r18;
	bfe.s32 	%r97, %r114, 29, 1;
	xor.b32  	%r98, %r97, %r91;
	xor.b32  	%r99, %r97, %r92;
	cvt.u64.u32 	%rd50, %r98;
	shl.b64 	%rd51, %rd50, 32;
	cvt.u64.u32 	%rd52, %r99;
	or.b64  	%rd53, %rd51, %rd52;
	cvt.rn.f64.s64 	%fd3, %rd53;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f22, %fd4;
	neg.f32 	%f23, %f22;
	setp.lt.s32 	%p12, %r96, 0;
	selp.f32 	%f88, %f23, %f22, %p12;
$L__BB146_16:
	fma.rn.f32 	%f25, %f7, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f26, %f25;
	mov.f32 	%f27, 0f4B400001;
	mov.f32 	%f28, 0f437C0000;
	fma.rm.f32 	%f29, %f26, %f28, %f27;
	add.rn.f32 	%f30, %f29, 0fCB40007F;
	neg.f32 	%f31, %f30;
	fma.rn.f32 	%f32, %f7, 0f3FB8AA3B, %f31;
	fma.rn.f32 	%f33, %f7, 0f32A57060, %f32;
	ex2.approx.ftz.f32 	%f34, %f33;
	mov.b32 	%r101, %f29;
	shl.b32 	%r102, %r101, 23;
	mov.b32 	%f35, %r102;
	mul.rn.f32 	%f36, %f34, %f35;
	neg.f32 	%f37, %f36;
	sub.rn.f32 	%f38, %f37, %f36;
	add.rn.f32 	%f39, %f38, %f38;
	add.rn.f32 	%f40, %f39, %f39;
	add.rn.f32 	%f41, %f40, %f40;
	add.rn.f32 	%f42, %f41, %f41;
	add.rn.f32 	%f43, %f42, %f42;
	add.rn.f32 	%f44, %f43, %f43;
	fma.rn.f32 	%f45, %f44, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f46, %f45;
	fma.rm.f32 	%f47, %f46, %f28, %f27;
	add.rn.f32 	%f48, %f47, 0fCB40007F;
	neg.f32 	%f49, %f48;
	fma.rn.f32 	%f50, %f44, 0f3FB8AA3B, %f49;
	fma.rn.f32 	%f51, %f44, 0f32A57060, %f50;
	ex2.approx.ftz.f32 	%f52, %f51;
	mov.b32 	%r103, %f47;
	shl.b32 	%r104, %r103, 23;
	mov.b32 	%f53, %r104;
	mul.rn.f32 	%f54, %f52, %f53;
	mul.rn.f32 	%f55, %f8, %f54;
	and.b32  	%r105, %r112, 2;
	setp.eq.s32 	%p13, %r105, 0;
	and.b32  	%r106, %r112, 1;
	setp.eq.b32 	%p14, %r106, 1;
	mul.rn.f32 	%f56, %f87, %f87;
	fma.rn.f32 	%f57, %f56, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f58, %f57, 0fB94D4153, %p14;
	selp.f32 	%f59, 0f3D2AAABB, 0f3C0885E4, %p14;
	fma.rn.f32 	%f60, %f58, %f56, %f59;
	selp.f32 	%f61, 0fBEFFFFFF, 0fBE2AAAA8, %p14;
	fma.rn.f32 	%f62, %f60, %f56, %f61;
	selp.f32 	%f63, 0f3F800000, %f87, %p14;
	fma.rn.f32 	%f64, %f56, %f63, 0f00000000;
	fma.rn.f32 	%f65, %f62, %f64, %f63;
	sub.rn.f32 	%f67, %f86, %f65;
	selp.f32 	%f68, %f65, %f67, %p13;
	neg.f32 	%f69, %f68;
	mul.rn.f32 	%f70, %f55, %f69;
	mul.rn.f32 	%f71, %f88, %f88;
	and.b32  	%r107, %r116, 1;
	setp.eq.b32 	%p15, %r107, 1;
	selp.f32 	%f72, 0f3F800000, %f88, %p15;
	fma.rn.f32 	%f73, %f71, %f72, 0f00000000;
	fma.rn.f32 	%f74, %f71, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f75, %f74, 0fB94D4153, %p15;
	selp.f32 	%f76, 0f3D2AAABB, 0f3C0885E4, %p15;
	fma.rn.f32 	%f77, %f75, %f71, %f76;
	selp.f32 	%f78, 0fBEFFFFFF, 0fBE2AAAA8, %p15;
	fma.rn.f32 	%f79, %f77, %f71, %f78;
	fma.rn.f32 	%f80, %f79, %f73, %f72;
	and.b32  	%r108, %r116, 2;
	setp.eq.s32 	%p16, %r108, 0;
	sub.rn.f32 	%f81, %f86, %f80;
	selp.f32 	%f82, %f80, %f81, %p16;
	ld.global.nc.f32 	%f83, [%rd11+28];
	mul.rn.f32 	%f84, %f83, %f54;
	mul.rn.f32 	%f85, %f82, %f84;
	mul.wide.u32 	%rd54, %r1, 4;
	add.s64 	%rd55, %rd2, %rd54;
	st.global.f32 	[%rd55], %f70;
	add.s64 	%rd56, %rd1, %rd54;
	st.global.f32 	[%rd56], %f85;
	ret;

}
	// .globl	loop_broadcast_fusion_35
.visible .entry loop_broadcast_fusion_35(
	.param .u64 loop_broadcast_fusion_35_param_0
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<5>;

	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 10;
	or.b32  	%r4, %r3, %r2;
	setp.lt.u32 	%p1, %r4, 57600;
	@%p1 bra 	$L__BB147_2;
	bra.uni 	$L__BB147_1;
$L__BB147_2:
	ld.param.u64 	%rd2, [loop_broadcast_fusion_35_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.u32 	%rd4, %r4, 4;
	add.s64 	%rd1, %rd3, %rd4;
	mov.b32 	%r5, 0;
	st.global.u32 	[%rd1], %r5;
$L__BB147_1:
	ret;

}
	// .globl	input_scatter_fusion_242
.visible .entry input_scatter_fusion_242(
	.param .u64 input_scatter_fusion_242_param_0,
	.param .u64 input_scatter_fusion_242_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<18>;
	.reg .b32 	%r<10>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_242_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_242_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 5243;
	shr.u16 	%rs7, %rs6, 2;
	mul.lo.s16 	%rs8, %rs7, 50;
	sub.s16 	%rs9, %rs3, %rs8;
	shr.u16 	%rs10, %rs1, 1;
	mul.hi.u16 	%rs11, %rs10, -9611;
	shr.u16 	%rs12, %rs11, 6;
	and.b16  	%rs13, %rs12, 63;
	cvt.u16.u32 	%rs14, %r1;
	and.b16  	%rs15, %rs14, 255;
	mul.lo.s16 	%rs16, %rs15, 219;
	shr.u16 	%rs17, %rs16, 13;
	cvt.u32.u16 	%r5, %rs17;
	and.b32  	%r6, %r5, 6;
	mul.wide.u32 	%rd5, %r6, 38400;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r7, %rs13;
	mul.wide.u32 	%rd7, %r7, 600;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r8, %rs9;
	mul.wide.u32 	%rd9, %r8, 12;
	add.s64 	%rd10, %rd8, %rd9;
	cvt.u32.u16 	%r9, %rs5;
	mul.wide.u32 	%rd11, %r9, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+38400];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+38400], %f3;
	ret;

}
	// .globl	wrapped_transpose_248
.visible .entry wrapped_transpose_248(
	.param .u64 wrapped_transpose_248_param_0,
	.param .u64 wrapped_transpose_248_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<17>;
	.reg .b32 	%r<9>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [wrapped_transpose_248_param_0];
	ld.param.u64 	%rd2, [wrapped_transpose_248_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -28253;
	shr.u16 	%rs3, %rs2, 9;
	and.b16  	%rs4, %rs3, 63;
	mul.hi.u16 	%rs5, %rs1, -7281;
	shr.u16 	%rs6, %rs5, 4;
	mul.hi.u16 	%rs7, %rs6, 1311;
	mul.lo.s16 	%rs8, %rs7, 50;
	sub.s16 	%rs9, %rs6, %rs8;
	mul.hi.u16 	%rs10, %rs1, -21845;
	shr.u16 	%rs11, %rs10, 2;
	mul.hi.u16 	%rs12, %rs11, 21846;
	mul.lo.s16 	%rs13, %rs12, 3;
	sub.s16 	%rs14, %rs11, %rs13;
	mul.lo.s16 	%rs15, %rs11, 6;
	sub.s16 	%rs16, %rs1, %rs15;
	cvt.u32.u16 	%r5, %rs16;
	mul.wide.u32 	%rd5, %r5, 38400;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r6, %rs4;
	mul.wide.u32 	%rd7, %r6, 600;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r7, %rs9;
	mul.wide.u32 	%rd9, %r7, 12;
	add.s64 	%rd10, %rd8, %rd9;
	cvt.u32.u16 	%r8, %rs14;
	mul.wide.u32 	%rd11, %r8, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	st.global.f32 	[%rd14], %f1;
	ret;

}
	// .globl	input_scatter_fusion_243
.visible .entry input_scatter_fusion_243(
	.param .u64 input_scatter_fusion_243_param_0,
	.param .u64 input_scatter_fusion_243_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<18>;
	.reg .b32 	%r<10>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_243_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_243_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 5243;
	shr.u16 	%rs7, %rs6, 2;
	mul.lo.s16 	%rs8, %rs7, 50;
	sub.s16 	%rs9, %rs3, %rs8;
	shr.u16 	%rs10, %rs1, 1;
	mul.hi.u16 	%rs11, %rs10, -9611;
	shr.u16 	%rs12, %rs11, 6;
	and.b16  	%rs13, %rs12, 63;
	cvt.u16.u32 	%rs14, %r1;
	and.b16  	%rs15, %rs14, 255;
	mul.lo.s16 	%rs16, %rs15, 219;
	shr.u16 	%rs17, %rs16, 13;
	cvt.u32.u16 	%r5, %rs17;
	and.b32  	%r6, %r5, 6;
	mul.wide.u32 	%rd5, %r6, 38400;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r7, %rs13;
	mul.wide.u32 	%rd7, %r7, 600;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r8, %rs9;
	mul.wide.u32 	%rd9, %r8, 12;
	add.s64 	%rd10, %rd8, %rd9;
	cvt.u32.u16 	%r9, %rs5;
	mul.wide.u32 	%rd11, %r9, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	loop_pad_fusion_25
.visible .entry loop_pad_fusion_25(
	.param .u64 loop_pad_fusion_25_param_0,
	.param .u64 loop_pad_fusion_25_param_1,
	.param .u64 loop_pad_fusion_25_param_2,
	.param .u64 loop_pad_fusion_25_param_3,
	.param .u64 loop_pad_fusion_25_param_4,
	.param .u64 loop_pad_fusion_25_param_5
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot151[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<73>;
	.reg .f32 	%f<72>;
	.reg .b64 	%rd<60>;
	.reg .f64 	%fd<3>;

	mov.u64 	%SPL, __local_depot151;
	ld.param.u64 	%rd16, [loop_pad_fusion_25_param_5];
	cvta.to.global.u64 	%rd1, %rd16;
	mov.u32 	%r20, %ctaid.x;
	mov.u32 	%r21, %tid.x;
	shl.b32 	%r22, %r20, 7;
	or.b32  	%r1, %r22, %r21;
	mul.hi.u32 	%r23, %r1, -1431655765;
	bfe.u32 	%r3, %r23, 2, 2;
	setp.ne.s32 	%p1, %r3, 3;
	mov.f32 	%f70, 0f00000000;
	@%p1 bra 	$L__BB151_2;
	bra.uni 	$L__BB151_1;
$L__BB151_2:
	ld.param.u64 	%rd15, [loop_pad_fusion_25_param_0];
	ld.param.u64 	%rd17, [loop_pad_fusion_25_param_1];
	ld.param.u64 	%rd18, [loop_pad_fusion_25_param_4];
	cvta.to.global.u64 	%rd2, %rd18;
	ld.param.u64 	%rd19, [loop_pad_fusion_25_param_2];
	ld.param.u64 	%rd20, [loop_pad_fusion_25_param_3];
	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd17;
	cvta.to.global.u64 	%rd6, %rd15;
	shr.u32 	%r2, %r23, 2;
	mul.hi.u32 	%r24, %r1, 458129845;
	bfe.u32 	%r25, %r24, 7, 6;
	shr.u32 	%r27, %r23, 4;
	cvt.u16.u32 	%rs1, %r27;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.lo.s32 	%r28, %r2, 6;
	sub.s32 	%r29, %r1, %r28;
	cvt.u64.u32 	%rd8, %r25;
	cvt.u64.u16 	%rd9, %rs6;
	cvt.u64.u32 	%rd10, %r3;
	cvt.u64.u32 	%rd11, %r29;
	mul.wide.u32 	%rd22, %r25, 3600;
	add.s64 	%rd23, %rd6, %rd22;
	cvt.u32.u16 	%r30, %rs6;
	mul.wide.u32 	%rd24, %r30, 72;
	add.s64 	%rd25, %rd23, %rd24;
	mul.wide.u32 	%rd26, %r3, 24;
	add.s64 	%rd27, %rd25, %rd26;
	mul.wide.u32 	%rd28, %r29, 4;
	add.s64 	%rd29, %rd27, %rd28;
	ld.global.nc.f32 	%f11, [%rd29];
	add.s64 	%rd30, %rd5, %rd22;
	add.s64 	%rd31, %rd30, %rd24;
	add.s64 	%rd32, %rd31, %rd26;
	add.s64 	%rd33, %rd32, %rd28;
	ld.global.nc.f32 	%f12, [%rd33];
	add.rn.f32 	%f2, %f11, %f12;
	shr.u32 	%r31, %r29, 1;
	mul.wide.u32 	%rd34, %r25, 12;
	add.s64 	%rd35, %rd3, %rd34;
	mul.wide.u32 	%rd36, %r31, 4;
	add.s64 	%rd37, %rd35, %rd36;
	ld.global.nc.f32 	%f13, [%rd37];
	add.rn.f32 	%f14, %f13, %f13;
	add.rn.f32 	%f15, %f14, %f14;
	add.rn.f32 	%f3, %f15, %f15;
	mul.rn.f32 	%f16, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r72, %f16;
	cvt.rn.f32.s32 	%f17, %r72;
	fma.rn.f32 	%f18, %f17, 0fBFC90FDA, %f3;
	fma.rn.f32 	%f19, %f17, 0fB3A22168, %f18;
	fma.rn.f32 	%f71, %f17, 0fA7C234C5, %f19;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p2, %f5, 0f47CE4780;
	@%p2 bra 	$L__BB151_10;
	setp.neu.f32 	%p3, %f5, 0f7F800000;
	@%p3 bra 	$L__BB151_5;
	mov.f32 	%f22, 0f00000000;
	mul.rn.f32 	%f71, %f3, %f22;
	mov.b32 	%r72, 0;
	bra.uni 	$L__BB151_10;
$L__BB151_5:
	add.u64 	%rd7, %SPL, 0;
	mov.b32 	%r5, %f3;
	shr.u32 	%r6, %r5, 23;
	and.b32  	%r33, %r6, 224;
	add.s32 	%r34, %r33, -128;
	shl.b32 	%r35, %r5, 8;
	or.b32  	%r39, %r35, -2147483648;
	shr.u32 	%r8, %r34, 5;
	mov.b32 	%r69, 0;
	mov.u64 	%rd59, 0;
	mov.u64 	%rd39, __cudart_i2opi_f;
$L__BB151_6:
	.pragma "nounroll";
	add.s64 	%rd40, %rd39, %rd59;
	ld.global.nc.u32 	%r38, [%rd40];
	// begin inline asm
	{
	mad.lo.cc.u32   %r36, %r38, %r39, %r69;
	madc.hi.u32     %r69, %r38, %r39,  0;
	}
	// end inline asm
	add.s64 	%rd41, %rd7, %rd59;
	st.local.u32 	[%rd41], %r36;
	add.s64 	%rd59, %rd59, 4;
	cvt.u32.u64 	%r41, %rd59;
	setp.ne.s32 	%p4, %r41, 24;
	@%p4 bra 	$L__BB151_6;
	st.local.u32 	[%rd7+24], %r69;
	and.b32  	%r11, %r6, 31;
	mul.wide.u32 	%rd42, %r8, 4;
	sub.s64 	%rd14, %rd7, %rd42;
	ld.local.u32 	%r70, [%rd14+24];
	ld.local.u32 	%r71, [%rd14+20];
	setp.eq.s32 	%p5, %r11, 0;
	@%p5 bra 	$L__BB151_9;
	shl.b32 	%r42, %r71, %r11;
	shl.b32 	%r43, %r70, %r11;
	mov.b32 	%r44, 32;
	sub.s32 	%r45, %r44, %r11;
	shr.u32 	%r46, %r71, %r45;
	add.s32 	%r70, %r46, %r43;
	ld.local.u32 	%r47, [%rd14+16];
	shr.u32 	%r48, %r47, %r45;
	add.s32 	%r71, %r48, %r42;
$L__BB151_9:
	shr.u32 	%r49, %r70, 30;
	shr.u32 	%r50, %r71, 30;
	shl.b32 	%r51, %r70, 2;
	or.b32  	%r52, %r51, %r50;
	shl.b32 	%r53, %r71, 2;
	bfe.u32 	%r54, %r70, 29, 1;
	add.s32 	%r55, %r54, %r49;
	neg.s32 	%r56, %r55;
	setp.lt.s32 	%p6, %r5, 0;
	selp.b32 	%r72, %r56, %r55, %p6;
	xor.b32  	%r57, %r52, %r5;
	bfe.s32 	%r58, %r70, 29, 1;
	xor.b32  	%r59, %r58, %r52;
	xor.b32  	%r60, %r58, %r53;
	cvt.u64.u32 	%rd43, %r59;
	shl.b64 	%rd44, %rd43, 32;
	cvt.u64.u32 	%rd45, %r60;
	or.b64  	%rd46, %rd44, %rd45;
	cvt.rn.f64.s64 	%fd1, %rd46;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f20, %fd2;
	neg.f32 	%f21, %f20;
	setp.lt.s32 	%p7, %r57, 0;
	selp.f32 	%f71, %f21, %f20, %p7;
$L__BB151_10:
	add.s32 	%r62, %r72, 1;
	mul.rn.f32 	%f23, %f71, %f71;
	and.b32  	%r63, %r72, 1;
	setp.eq.b32 	%p8, %r63, 1;
	selp.f32 	%f24, %f71, 0f3F800000, %p8;
	fma.rn.f32 	%f25, %f23, %f24, 0f00000000;
	fma.rn.f32 	%f26, %f23, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f27, 0fB94D4153, %f26, %p8;
	selp.f32 	%f28, 0f3C0885E4, 0f3D2AAABB, %p8;
	fma.rn.f32 	%f29, %f27, %f23, %f28;
	selp.f32 	%f30, 0fBE2AAAA8, 0fBEFFFFFF, %p8;
	fma.rn.f32 	%f31, %f29, %f23, %f30;
	fma.rn.f32 	%f32, %f31, %f25, %f24;
	and.b32  	%r64, %r62, 2;
	setp.eq.s32 	%p9, %r64, 0;
	mov.f32 	%f33, 0f00000000;
	sub.rn.f32 	%f34, %f33, %f32;
	selp.f32 	%f35, %f32, %f34, %p9;
	shl.b64 	%rd47, %rd8, 2;
	add.s64 	%rd48, %rd2, %rd47;
	ld.global.nc.f32 	%f36, [%rd48];
	fma.rn.f32 	%f37, %f36, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f38, %f37;
	mov.f32 	%f39, 0f4B400001;
	mov.f32 	%f40, 0f437C0000;
	fma.rm.f32 	%f41, %f38, %f40, %f39;
	add.rn.f32 	%f42, %f41, 0fCB40007F;
	neg.f32 	%f43, %f42;
	fma.rn.f32 	%f44, %f36, 0f3FB8AA3B, %f43;
	fma.rn.f32 	%f45, %f36, 0f32A57060, %f44;
	mov.b32 	%r65, %f41;
	shl.b32 	%r66, %r65, 23;
	mov.b32 	%f46, %r66;
	ex2.approx.ftz.f32 	%f47, %f45;
	mul.rn.f32 	%f48, %f47, %f46;
	neg.f32 	%f49, %f48;
	sub.rn.f32 	%f50, %f49, %f48;
	add.rn.f32 	%f51, %f50, %f50;
	add.rn.f32 	%f52, %f51, %f51;
	add.rn.f32 	%f53, %f52, %f52;
	add.rn.f32 	%f54, %f53, %f53;
	add.rn.f32 	%f55, %f54, %f54;
	add.rn.f32 	%f56, %f55, %f55;
	fma.rn.f32 	%f57, %f56, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f58, %f57;
	fma.rm.f32 	%f59, %f58, %f40, %f39;
	add.rn.f32 	%f60, %f59, 0fCB40007F;
	neg.f32 	%f61, %f60;
	fma.rn.f32 	%f62, %f56, 0f3FB8AA3B, %f61;
	fma.rn.f32 	%f63, %f56, 0f32A57060, %f62;
	mov.b32 	%r67, %f59;
	shl.b32 	%r68, %r67, 23;
	mov.b32 	%f64, %r68;
	ex2.approx.ftz.f32 	%f65, %f63;
	mul.rn.f32 	%f66, %f65, %f64;
	mul.lo.s64 	%rd49, %rd8, 4800;
	add.s64 	%rd50, %rd4, %rd49;
	mul.lo.s64 	%rd51, %rd9, 96;
	add.s64 	%rd52, %rd50, %rd51;
	mul.lo.s64 	%rd53, %rd10, 24;
	add.s64 	%rd54, %rd52, %rd53;
	shl.b64 	%rd55, %rd11, 2;
	add.s64 	%rd56, %rd54, %rd55;
	ld.global.nc.f32 	%f67, [%rd56+24];
	mul.rn.f32 	%f68, %f67, %f66;
	mul.rn.f32 	%f69, %f35, %f68;
	add.rn.f32 	%f70, %f2, %f69;
$L__BB151_1:
	mul.wide.u32 	%rd57, %r1, 4;
	add.s64 	%rd58, %rd1, %rd57;
	st.global.f32 	[%rd58], %f70;
	ret;

}
	// .globl	loop_slice_fusion_79
.visible .entry loop_slice_fusion_79(
	.param .u64 loop_slice_fusion_79_param_0,
	.param .u64 loop_slice_fusion_79_param_1,
	.param .u64 loop_slice_fusion_79_param_2,
	.param .u64 loop_slice_fusion_79_param_3,
	.param .u64 loop_slice_fusion_79_param_4,
	.param .u64 loop_slice_fusion_79_param_5,
	.param .u64 loop_slice_fusion_79_param_6,
	.param .u64 loop_slice_fusion_79_param_7,
	.param .u64 loop_slice_fusion_79_param_8,
	.param .u64 loop_slice_fusion_79_param_9,
	.param .u64 loop_slice_fusion_79_param_10,
	.param .u64 loop_slice_fusion_79_param_11,
	.param .u64 loop_slice_fusion_79_param_12,
	.param .u64 loop_slice_fusion_79_param_13,
	.param .u64 loop_slice_fusion_79_param_14,
	.param .u64 loop_slice_fusion_79_param_15,
	.param .u64 loop_slice_fusion_79_param_16,
	.param .u64 loop_slice_fusion_79_param_17,
	.param .u64 loop_slice_fusion_79_param_18,
	.param .u64 loop_slice_fusion_79_param_19,
	.param .u64 loop_slice_fusion_79_param_20,
	.param .u64 loop_slice_fusion_79_param_21,
	.param .u64 loop_slice_fusion_79_param_22,
	.param .u64 loop_slice_fusion_79_param_23,
	.param .u64 loop_slice_fusion_79_param_24,
	.param .u64 loop_slice_fusion_79_param_25,
	.param .u64 loop_slice_fusion_79_param_26,
	.param .u64 loop_slice_fusion_79_param_27,
	.param .u64 loop_slice_fusion_79_param_28,
	.param .u64 loop_slice_fusion_79_param_29,
	.param .u64 loop_slice_fusion_79_param_30,
	.param .u64 loop_slice_fusion_79_param_31
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot152[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<22>;
	.reg .b32 	%r<134>;
	.reg .f32 	%f<146>;
	.reg .b64 	%rd<247>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot152;
	ld.param.u64 	%rd23, [loop_slice_fusion_79_param_0];
	ld.param.u64 	%rd24, [loop_slice_fusion_79_param_31];
	ld.param.u64 	%rd25, [loop_slice_fusion_79_param_1];
	ld.param.u64 	%rd26, [loop_slice_fusion_79_param_30];
	ld.param.u64 	%rd27, [loop_slice_fusion_79_param_2];
	ld.param.u64 	%rd28, [loop_slice_fusion_79_param_29];
	cvta.to.global.u64 	%rd29, %rd28;
	ld.param.u64 	%rd30, [loop_slice_fusion_79_param_3];
	ld.param.u64 	%rd31, [loop_slice_fusion_79_param_28];
	cvta.to.global.u64 	%rd32, %rd31;
	ld.param.u64 	%rd33, [loop_slice_fusion_79_param_4];
	ld.param.u64 	%rd34, [loop_slice_fusion_79_param_27];
	cvta.to.global.u64 	%rd35, %rd34;
	ld.param.u64 	%rd36, [loop_slice_fusion_79_param_5];
	ld.param.u64 	%rd37, [loop_slice_fusion_79_param_26];
	cvta.to.global.u64 	%rd38, %rd37;
	ld.param.u64 	%rd39, [loop_slice_fusion_79_param_6];
	ld.param.u64 	%rd40, [loop_slice_fusion_79_param_25];
	cvta.to.global.u64 	%rd41, %rd40;
	ld.param.u64 	%rd42, [loop_slice_fusion_79_param_7];
	ld.param.u64 	%rd43, [loop_slice_fusion_79_param_24];
	cvta.to.global.u64 	%rd44, %rd43;
	ld.param.u64 	%rd45, [loop_slice_fusion_79_param_8];
	ld.param.u64 	%rd46, [loop_slice_fusion_79_param_23];
	cvta.to.global.u64 	%rd47, %rd46;
	ld.param.u64 	%rd48, [loop_slice_fusion_79_param_9];
	ld.param.u64 	%rd49, [loop_slice_fusion_79_param_22];
	cvta.to.global.u64 	%rd50, %rd49;
	ld.param.u64 	%rd51, [loop_slice_fusion_79_param_10];
	ld.param.u64 	%rd52, [loop_slice_fusion_79_param_21];
	cvta.to.global.u64 	%rd53, %rd52;
	ld.param.u64 	%rd54, [loop_slice_fusion_79_param_11];
	ld.param.u64 	%rd55, [loop_slice_fusion_79_param_20];
	cvta.to.global.u64 	%rd56, %rd55;
	ld.param.u64 	%rd57, [loop_slice_fusion_79_param_12];
	ld.param.u64 	%rd58, [loop_slice_fusion_79_param_19];
	cvta.to.global.u64 	%rd59, %rd58;
	ld.param.u64 	%rd60, [loop_slice_fusion_79_param_13];
	ld.param.u64 	%rd61, [loop_slice_fusion_79_param_18];
	cvta.to.global.u64 	%rd62, %rd61;
	ld.param.u64 	%rd63, [loop_slice_fusion_79_param_14];
	ld.param.u64 	%rd64, [loop_slice_fusion_79_param_17];
	cvta.to.global.u64 	%rd65, %rd64;
	ld.param.u64 	%rd66, [loop_slice_fusion_79_param_15];
	ld.param.u64 	%rd67, [loop_slice_fusion_79_param_16];
	cvta.to.global.u64 	%rd68, %rd67;
	cvta.to.global.u64 	%rd69, %rd66;
	cvta.to.global.u64 	%rd70, %rd63;
	cvta.to.global.u64 	%rd71, %rd60;
	cvta.to.global.u64 	%rd72, %rd57;
	cvta.to.global.u64 	%rd73, %rd54;
	cvta.to.global.u64 	%rd74, %rd51;
	cvta.to.global.u64 	%rd75, %rd48;
	cvta.to.global.u64 	%rd76, %rd45;
	cvta.to.global.u64 	%rd77, %rd42;
	cvta.to.global.u64 	%rd3, %rd39;
	cvta.to.global.u64 	%rd4, %rd36;
	cvta.to.global.u64 	%rd5, %rd33;
	cvta.to.global.u64 	%rd6, %rd30;
	add.u64 	%rd10, %SPL, 0;
	mov.u32 	%r35, %ctaid.x;
	mov.u32 	%r36, %tid.x;
	shl.b32 	%r37, %r35, 7;
	or.b32  	%r1, %r37, %r36;
	cvt.u16.u32 	%rs3, %r1;
	mul.hi.u16 	%rs4, %rs3, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.lo.s16 	%rs6, %rs5, 6;
	sub.s16 	%rs7, %rs3, %rs6;
	shr.u16 	%rs8, %rs4, 3;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 2;
	mul.lo.s16 	%rs11, %rs10, 50;
	sub.s16 	%rs12, %rs8, %rs11;
	shr.u16 	%rs13, %rs3, 3;
	mul.hi.u16 	%rs14, %rs13, 6991;
	shr.u16 	%rs15, %rs14, 3;
	and.b16  	%rs16, %rs15, 63;
	shr.u16 	%rs17, %rs4, 1;
	and.b16  	%rs1, %rs17, 2;
	shl.b16 	%rs18, %rs1, 2;
	or.b16  	%rs19, %rs18, 2;
	cvt.u32.u16 	%r2, %rs19;
	or.b32  	%r38, %r2, 1;
	shl.b32 	%r39, %r38, 1;
	shl.b32 	%r40, %r38, 2;
	or.b32  	%r41, %r40, 2;
	or.b32  	%r42, %r40, 3;
	shl.b32 	%r43, %r42, 1;
	shl.b32 	%r44, %r42, 2;
	or.b32  	%r45, %r44, 2;
	or.b32  	%r46, %r44, 3;
	shl.b32 	%r47, %r46, 1;
	shl.b32 	%r48, %r46, 2;
	or.b32  	%r49, %r48, 2;
	shl.b16 	%rs20, %rs12, 10;
	cvt.u64.u16 	%rd12, %rs16;
	cvt.u64.u16 	%rd13, %rs7;
	cvt.u64.u32 	%rd80, %r49;
	cvt.u64.u16 	%rd81, %rs20;
	add.s64 	%rd82, %rd81, %rd80;
	mul.lo.s64 	%rd83, %rd82, 24;
	cvt.u32.u16 	%r50, %rs16;
	mul.wide.u32 	%rd84, %r50, 1228800;
	add.s64 	%rd85, %rd44, %rd84;
	add.s64 	%rd86, %rd85, %rd83;
	cvt.u32.u16 	%r51, %rs7;
	mul.wide.u32 	%rd87, %r51, 4;
	add.s64 	%rd88, %rd86, %rd87;
	ld.global.nc.f32 	%f1, [%rd88+24];
	cvt.u64.u16 	%rd14, %rs12;
	cvt.u32.u16 	%r52, %rs12;
	mul.wide.u32 	%rd89, %r52, 12264;
	mul.wide.u32 	%rd90, %r50, 613200;
	add.s64 	%rd91, %rd35, %rd90;
	add.s64 	%rd92, %rd91, %rd89;
	mul.wide.u32 	%rd93, %r47, 24;
	add.s64 	%rd94, %rd92, %rd93;
	add.s64 	%rd95, %rd94, %rd87;
	ld.global.nc.f32 	%f2, [%rd95+24];
	add.s64 	%rd96, %rd32, %rd90;
	add.s64 	%rd97, %rd96, %rd89;
	add.s64 	%rd98, %rd97, %rd93;
	add.s64 	%rd99, %rd98, %rd87;
	ld.global.nc.f32 	%f3, [%rd99+24];
	shr.u16 	%rs21, %rs7, 1;
	cvt.u32.u16 	%r53, %rs21;
	mul.wide.u32 	%rd100, %r53, 4;
	mul.wide.u32 	%rd101, %r50, 12;
	add.s64 	%rd102, %rd38, %rd101;
	add.s64 	%rd103, %rd102, %rd100;
	ld.global.nc.f32 	%f4, [%rd103];
	mul.wide.u32 	%rd104, %r50, 4;
	add.s64 	%rd105, %rd41, %rd104;
	ld.global.nc.f32 	%f5, [%rd105];
	cvt.u64.u32 	%rd106, %r48;
	add.s64 	%rd107, %rd81, %rd106;
	mul.lo.s64 	%rd108, %rd107, 24;
	add.s64 	%rd109, %rd85, %rd108;
	add.s64 	%rd110, %rd109, %rd87;
	ld.global.nc.f32 	%f6, [%rd110+96];
	mul.wide.u32 	%rd111, %r52, 6120;
	mul.wide.u32 	%rd112, %r50, 306000;
	add.s64 	%rd113, %rd50, %rd112;
	add.s64 	%rd114, %rd113, %rd111;
	mul.wide.u32 	%rd115, %r45, 24;
	add.s64 	%rd116, %rd114, %rd115;
	add.s64 	%rd117, %rd116, %rd87;
	ld.global.nc.f32 	%f7, [%rd117+24];
	add.s64 	%rd118, %rd47, %rd112;
	add.s64 	%rd119, %rd118, %rd111;
	add.s64 	%rd120, %rd119, %rd115;
	add.s64 	%rd121, %rd120, %rd87;
	ld.global.nc.f32 	%f8, [%rd121+24];
	add.s64 	%rd122, %rd53, %rd101;
	add.s64 	%rd123, %rd122, %rd100;
	ld.global.nc.f32 	%f9, [%rd123];
	add.s64 	%rd124, %rd56, %rd104;
	ld.global.nc.f32 	%f10, [%rd124];
	add.s64 	%rd125, %rd59, %rd112;
	add.s64 	%rd126, %rd125, %rd111;
	add.s64 	%rd127, %rd126, %rd115;
	add.s64 	%rd128, %rd127, %rd87;
	ld.global.nc.f32 	%f11, [%rd128+24];
	mul.wide.u32 	%rd129, %r52, 3048;
	mul.wide.u32 	%rd130, %r50, 152400;
	add.s64 	%rd131, %rd65, %rd130;
	add.s64 	%rd132, %rd131, %rd129;
	mul.wide.u32 	%rd133, %r43, 24;
	add.s64 	%rd134, %rd132, %rd133;
	add.s64 	%rd135, %rd134, %rd87;
	ld.global.nc.f32 	%f12, [%rd135+24];
	add.s64 	%rd136, %rd62, %rd130;
	add.s64 	%rd137, %rd136, %rd129;
	add.s64 	%rd138, %rd137, %rd133;
	add.s64 	%rd139, %rd138, %rd87;
	ld.global.nc.f32 	%f13, [%rd139+24];
	add.s64 	%rd140, %rd68, %rd101;
	add.s64 	%rd141, %rd140, %rd100;
	ld.global.nc.f32 	%f14, [%rd141];
	add.s64 	%rd142, %rd69, %rd104;
	ld.global.nc.f32 	%f15, [%rd142];
	add.s64 	%rd143, %rd70, %rd130;
	add.s64 	%rd144, %rd143, %rd129;
	add.s64 	%rd145, %rd144, %rd133;
	add.s64 	%rd146, %rd145, %rd87;
	ld.global.nc.f32 	%f16, [%rd146+24];
	mul.wide.u32 	%rd147, %r52, 1512;
	mul.wide.u32 	%rd148, %r50, 75600;
	add.s64 	%rd149, %rd72, %rd148;
	add.s64 	%rd150, %rd149, %rd147;
	mul.wide.u32 	%rd151, %r41, 24;
	add.s64 	%rd152, %rd150, %rd151;
	add.s64 	%rd153, %rd152, %rd87;
	ld.global.nc.f32 	%f17, [%rd153+24];
	add.s64 	%rd154, %rd71, %rd148;
	add.s64 	%rd155, %rd154, %rd147;
	add.s64 	%rd156, %rd155, %rd151;
	add.s64 	%rd157, %rd156, %rd87;
	ld.global.nc.f32 	%f18, [%rd157+24];
	add.s64 	%rd158, %rd73, %rd101;
	add.s64 	%rd159, %rd158, %rd100;
	ld.global.nc.f32 	%f19, [%rd159];
	add.s64 	%rd160, %rd74, %rd104;
	ld.global.nc.f32 	%f20, [%rd160];
	mul.wide.u32 	%rd161, %r52, 1536;
	mul.wide.u32 	%rd162, %r50, 76800;
	add.s64 	%rd163, %rd75, %rd162;
	add.s64 	%rd164, %rd163, %rd161;
	add.s64 	%rd165, %rd164, %rd151;
	add.s64 	%rd166, %rd165, %rd87;
	ld.global.nc.f32 	%f21, [%rd166+48];
	cvt.u64.u32 	%rd15, %r39;
	mul.wide.u32 	%rd167, %r52, 744;
	mul.wide.u32 	%rd168, %r50, 37200;
	add.s64 	%rd169, %rd77, %rd168;
	add.s64 	%rd170, %rd169, %rd167;
	mul.wide.u32 	%rd171, %r39, 24;
	add.s64 	%rd172, %rd170, %rd171;
	add.s64 	%rd173, %rd172, %rd87;
	ld.global.nc.f32 	%f22, [%rd173+24];
	add.s64 	%rd174, %rd76, %rd168;
	add.s64 	%rd175, %rd174, %rd167;
	add.s64 	%rd176, %rd175, %rd171;
	add.s64 	%rd177, %rd176, %rd87;
	ld.global.nc.f32 	%f23, [%rd177+24];
	add.s64 	%rd178, %rd29, %rd101;
	add.s64 	%rd179, %rd178, %rd100;
	ld.global.nc.f32 	%f24, [%rd179];
	mul.rn.f32 	%f40, %f24, 0f3F22F983;
	cvt.rni.s32.f32 	%r129, %f40;
	cvt.rn.f32.s32 	%f41, %r129;
	fma.rn.f32 	%f42, %f41, 0fBFC90FDA, %f24;
	fma.rn.f32 	%f43, %f41, 0fB3A22168, %f42;
	fma.rn.f32 	%f144, %f41, 0fA7C234C5, %f43;
	abs.f32 	%f26, %f24;
	setp.ltu.f32 	%p1, %f26, 0f47CE4780;
	mov.f32 	%f143, 0f00000000;
	@%p1 bra 	$L__BB152_8;
	setp.neu.f32 	%p2, %f26, 0f7F800000;
	@%p2 bra 	$L__BB152_3;
	mul.rn.f32 	%f144, %f24, %f143;
	mov.b32 	%r129, 0;
	bra.uni 	$L__BB152_8;
$L__BB152_3:
	mov.b32 	%r4, %f24;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r55, %r5, 224;
	add.s32 	%r56, %r55, -128;
	shl.b32 	%r57, %r4, 8;
	or.b32  	%r61, %r57, -2147483648;
	shr.u32 	%r7, %r56, 5;
	mov.b32 	%r126, 0;
	mov.u64 	%rd245, 0;
	mov.u64 	%rd181, __cudart_i2opi_f;
$L__BB152_4:
	.pragma "nounroll";
	add.s64 	%rd182, %rd181, %rd245;
	ld.global.nc.u32 	%r60, [%rd182];
	// begin inline asm
	{
	mad.lo.cc.u32   %r58, %r60, %r61, %r126;
	madc.hi.u32     %r126, %r60, %r61,  0;
	}
	// end inline asm
	add.s64 	%rd183, %rd10, %rd245;
	st.local.u32 	[%rd183], %r58;
	add.s64 	%rd245, %rd245, 4;
	cvt.u32.u64 	%r63, %rd245;
	setp.ne.s32 	%p3, %r63, 24;
	@%p3 bra 	$L__BB152_4;
	st.local.u32 	[%rd10+24], %r126;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd184, %r7, 4;
	sub.s64 	%rd18, %rd10, %rd184;
	ld.local.u32 	%r127, [%rd18+24];
	ld.local.u32 	%r128, [%rd18+20];
	setp.eq.s32 	%p4, %r10, 0;
	@%p4 bra 	$L__BB152_7;
	shl.b32 	%r64, %r128, %r10;
	shl.b32 	%r65, %r127, %r10;
	mov.b32 	%r66, 32;
	sub.s32 	%r67, %r66, %r10;
	shr.u32 	%r68, %r128, %r67;
	add.s32 	%r127, %r68, %r65;
	ld.local.u32 	%r69, [%rd18+16];
	shr.u32 	%r70, %r69, %r67;
	add.s32 	%r128, %r70, %r64;
$L__BB152_7:
	shr.u32 	%r71, %r127, 30;
	shr.u32 	%r72, %r128, 30;
	shl.b32 	%r73, %r127, 2;
	or.b32  	%r74, %r73, %r72;
	shl.b32 	%r75, %r128, 2;
	bfe.u32 	%r76, %r127, 29, 1;
	add.s32 	%r77, %r76, %r71;
	neg.s32 	%r78, %r77;
	setp.lt.s32 	%p5, %r4, 0;
	selp.b32 	%r129, %r78, %r77, %p5;
	xor.b32  	%r79, %r74, %r4;
	bfe.s32 	%r80, %r127, 29, 1;
	xor.b32  	%r81, %r80, %r74;
	xor.b32  	%r82, %r80, %r75;
	cvt.u64.u32 	%rd185, %r81;
	shl.b64 	%rd186, %rd185, 32;
	cvt.u64.u32 	%rd187, %r82;
	or.b64  	%rd188, %rd186, %rd187;
	cvt.rn.f64.s64 	%fd1, %rd188;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f44, %fd2;
	neg.f32 	%f45, %f44;
	setp.lt.s32 	%p6, %r79, 0;
	selp.f32 	%f144, %f45, %f44, %p6;
$L__BB152_8:
	cvta.to.global.u64 	%rd1, %rd24;
	cvta.to.global.u64 	%rd2, %rd26;
	cvta.to.global.u64 	%rd7, %rd27;
	cvta.to.global.u64 	%rd8, %rd25;
	cvta.to.global.u64 	%rd9, %rd23;
	shl.b16 	%rs2, %rs1, 1;
	shl.b64 	%rd189, %rd12, 2;
	add.s64 	%rd190, %rd3, %rd189;
	ld.global.nc.f32 	%f30, [%rd190];
	mul.lo.s64 	%rd191, %rd12, 38400;
	add.s64 	%rd192, %rd4, %rd191;
	mul.lo.s64 	%rd193, %rd14, 768;
	add.s64 	%rd194, %rd192, %rd193;
	mul.lo.s64 	%rd195, %rd15, 24;
	add.s64 	%rd196, %rd194, %rd195;
	shl.b64 	%rd197, %rd13, 2;
	add.s64 	%rd198, %rd196, %rd197;
	ld.global.nc.f32 	%f31, [%rd198+48];
	cvt.u64.u32 	%rd19, %r2;
	mul.lo.s64 	%rd199, %rd12, 18000;
	add.s64 	%rd200, %rd6, %rd199;
	mul.lo.s64 	%rd201, %rd14, 360;
	add.s64 	%rd202, %rd200, %rd201;
	mul.wide.u32 	%rd203, %r2, 24;
	add.s64 	%rd204, %rd202, %rd203;
	add.s64 	%rd205, %rd204, %rd197;
	ld.global.nc.f32 	%f32, [%rd205+24];
	add.s64 	%rd206, %rd5, %rd199;
	add.s64 	%rd207, %rd206, %rd201;
	add.s64 	%rd208, %rd207, %rd203;
	add.s64 	%rd209, %rd208, %rd197;
	ld.global.nc.f32 	%f33, [%rd209+24];
	add.rn.f32 	%f34, %f24, %f24;
	mul.rn.f32 	%f47, %f34, 0f3F22F983;
	cvt.rni.s32.f32 	%r133, %f47;
	cvt.rn.f32.s32 	%f48, %r133;
	fma.rn.f32 	%f49, %f48, 0fBFC90FDA, %f34;
	fma.rn.f32 	%f50, %f48, 0fB3A22168, %f49;
	fma.rn.f32 	%f145, %f48, 0fA7C234C5, %f50;
	abs.f32 	%f36, %f34;
	setp.ltu.f32 	%p7, %f36, 0f47CE4780;
	@%p7 bra 	$L__BB152_16;
	setp.neu.f32 	%p8, %f36, 0f7F800000;
	@%p8 bra 	$L__BB152_11;
	mul.rn.f32 	%f145, %f34, %f143;
	mov.b32 	%r133, 0;
	bra.uni 	$L__BB152_16;
$L__BB152_11:
	mov.b32 	%r20, %f34;
	shr.u32 	%r21, %r20, 23;
	and.b32  	%r85, %r21, 224;
	add.s32 	%r86, %r85, -128;
	shl.b32 	%r87, %r20, 8;
	or.b32  	%r91, %r87, -2147483648;
	shr.u32 	%r23, %r86, 5;
	mov.b32 	%r130, 0;
	mov.u64 	%rd246, 0;
	mov.u64 	%rd211, __cudart_i2opi_f;
$L__BB152_12:
	.pragma "nounroll";
	add.s64 	%rd212, %rd211, %rd246;
	ld.global.nc.u32 	%r90, [%rd212];
	// begin inline asm
	{
	mad.lo.cc.u32   %r88, %r90, %r91, %r130;
	madc.hi.u32     %r130, %r90, %r91,  0;
	}
	// end inline asm
	add.s64 	%rd213, %rd10, %rd246;
	st.local.u32 	[%rd213], %r88;
	add.s64 	%rd246, %rd246, 4;
	cvt.u32.u64 	%r93, %rd246;
	setp.ne.s32 	%p9, %r93, 24;
	@%p9 bra 	$L__BB152_12;
	st.local.u32 	[%rd10+24], %r130;
	and.b32  	%r26, %r21, 31;
	mul.wide.u32 	%rd214, %r23, 4;
	sub.s64 	%rd22, %rd10, %rd214;
	ld.local.u32 	%r131, [%rd22+24];
	ld.local.u32 	%r132, [%rd22+20];
	setp.eq.s32 	%p10, %r26, 0;
	@%p10 bra 	$L__BB152_15;
	shl.b32 	%r94, %r132, %r26;
	shl.b32 	%r95, %r131, %r26;
	mov.b32 	%r96, 32;
	sub.s32 	%r97, %r96, %r26;
	shr.u32 	%r98, %r132, %r97;
	add.s32 	%r131, %r98, %r95;
	ld.local.u32 	%r99, [%rd22+16];
	shr.u32 	%r100, %r99, %r97;
	add.s32 	%r132, %r100, %r94;
$L__BB152_15:
	shr.u32 	%r101, %r131, 30;
	shr.u32 	%r102, %r132, 30;
	shl.b32 	%r103, %r131, 2;
	or.b32  	%r104, %r103, %r102;
	shl.b32 	%r105, %r132, 2;
	bfe.u32 	%r106, %r131, 29, 1;
	add.s32 	%r107, %r106, %r101;
	neg.s32 	%r108, %r107;
	setp.lt.s32 	%p11, %r20, 0;
	selp.b32 	%r133, %r108, %r107, %p11;
	xor.b32  	%r109, %r104, %r20;
	bfe.s32 	%r110, %r131, 29, 1;
	xor.b32  	%r111, %r110, %r104;
	xor.b32  	%r112, %r110, %r105;
	cvt.u64.u32 	%rd215, %r111;
	shl.b64 	%rd216, %rd215, 32;
	cvt.u64.u32 	%rd217, %r112;
	or.b64  	%rd218, %rd216, %rd217;
	cvt.rn.f64.s64 	%fd3, %rd218;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f51, %fd4;
	neg.f32 	%f52, %f51;
	setp.lt.s32 	%p12, %r109, 0;
	selp.f32 	%f145, %f52, %f51, %p12;
$L__BB152_16:
	add.rn.f32 	%f54, %f2, %f3;
	mul.rn.f32 	%f55, %f5, %f6;
	mul.rn.f32 	%f56, %f4, %f55;
	add.rn.f32 	%f57, %f54, %f56;
	add.rn.f32 	%f58, %f1, %f57;
	add.rn.f32 	%f59, %f7, %f8;
	mul.rn.f32 	%f60, %f10, %f11;
	mul.rn.f32 	%f61, %f9, %f60;
	add.rn.f32 	%f62, %f59, %f61;
	add.rn.f32 	%f63, %f58, %f62;
	add.rn.f32 	%f64, %f12, %f13;
	mul.rn.f32 	%f65, %f15, %f16;
	mul.rn.f32 	%f66, %f14, %f65;
	add.rn.f32 	%f67, %f64, %f66;
	add.rn.f32 	%f68, %f63, %f67;
	add.rn.f32 	%f69, %f17, %f18;
	mul.rn.f32 	%f70, %f20, %f21;
	mul.rn.f32 	%f71, %f19, %f70;
	add.rn.f32 	%f72, %f69, %f71;
	add.rn.f32 	%f73, %f68, %f72;
	add.rn.f32 	%f74, %f22, %f23;
	add.s32 	%r114, %r129, 1;
	and.b32  	%r115, %r114, 2;
	setp.eq.s32 	%p13, %r115, 0;
	and.b32  	%r116, %r129, 1;
	setp.eq.b32 	%p14, %r116, 1;
	mul.rn.f32 	%f75, %f144, %f144;
	fma.rn.f32 	%f76, %f75, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f77, 0fB94D4153, %f76, %p14;
	selp.f32 	%f78, 0f3C0885E4, 0f3D2AAABB, %p14;
	fma.rn.f32 	%f79, %f77, %f75, %f78;
	selp.f32 	%f80, 0fBE2AAAA8, 0fBEFFFFFF, %p14;
	fma.rn.f32 	%f81, %f79, %f75, %f80;
	selp.f32 	%f82, %f144, 0f3F800000, %p14;
	fma.rn.f32 	%f83, %f75, %f82, 0f00000000;
	fma.rn.f32 	%f84, %f81, %f83, %f82;
	sub.rn.f32 	%f86, %f143, %f84;
	selp.f32 	%f87, %f84, %f86, %p13;
	mul.rn.f32 	%f88, %f30, %f31;
	mul.rn.f32 	%f89, %f88, %f87;
	add.rn.f32 	%f90, %f74, %f89;
	add.rn.f32 	%f91, %f73, %f90;
	add.s32 	%r117, %r133, 1;
	mul.rn.f32 	%f92, %f145, %f145;
	and.b32  	%r118, %r133, 1;
	setp.eq.b32 	%p15, %r118, 1;
	selp.f32 	%f93, %f145, 0f3F800000, %p15;
	fma.rn.f32 	%f94, %f92, %f93, 0f00000000;
	fma.rn.f32 	%f95, %f92, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f96, 0fB94D4153, %f95, %p15;
	selp.f32 	%f97, 0f3C0885E4, 0f3D2AAABB, %p15;
	fma.rn.f32 	%f98, %f96, %f92, %f97;
	selp.f32 	%f99, 0fBE2AAAA8, 0fBEFFFFFF, %p15;
	fma.rn.f32 	%f100, %f98, %f92, %f99;
	fma.rn.f32 	%f101, %f100, %f94, %f93;
	and.b32  	%r119, %r117, 2;
	setp.eq.s32 	%p16, %r119, 0;
	sub.rn.f32 	%f102, %f143, %f101;
	selp.f32 	%f103, %f101, %f102, %p16;
	add.s64 	%rd220, %rd2, %rd189;
	ld.global.nc.f32 	%f104, [%rd220];
	fma.rn.f32 	%f105, %f104, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f106, %f105;
	mov.f32 	%f107, 0f4B400001;
	mov.f32 	%f108, 0f437C0000;
	fma.rm.f32 	%f109, %f106, %f108, %f107;
	add.rn.f32 	%f110, %f109, 0fCB40007F;
	neg.f32 	%f111, %f110;
	fma.rn.f32 	%f112, %f104, 0f3FB8AA3B, %f111;
	fma.rn.f32 	%f113, %f104, 0f32A57060, %f112;
	mov.b32 	%r120, %f109;
	shl.b32 	%r121, %r120, 23;
	mov.b32 	%f114, %r121;
	ex2.approx.ftz.f32 	%f115, %f113;
	mul.rn.f32 	%f116, %f115, %f114;
	neg.f32 	%f117, %f116;
	sub.rn.f32 	%f118, %f117, %f116;
	add.rn.f32 	%f119, %f118, %f118;
	add.rn.f32 	%f120, %f119, %f119;
	add.rn.f32 	%f121, %f120, %f120;
	add.rn.f32 	%f122, %f121, %f121;
	fma.rn.f32 	%f123, %f122, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f124, %f123;
	fma.rm.f32 	%f125, %f124, %f108, %f107;
	add.rn.f32 	%f126, %f125, 0fCB40007F;
	neg.f32 	%f127, %f126;
	fma.rn.f32 	%f128, %f122, 0f3FB8AA3B, %f127;
	fma.rn.f32 	%f129, %f122, 0f32A57060, %f128;
	mov.b32 	%r122, %f125;
	shl.b32 	%r123, %r122, 23;
	mov.b32 	%f130, %r123;
	ex2.approx.ftz.f32 	%f131, %f129;
	mul.rn.f32 	%f132, %f131, %f130;
	add.rn.f32 	%f133, %f32, %f33;
	mul.lo.s64 	%rd221, %rd12, 19200;
	add.s64 	%rd222, %rd7, %rd221;
	mul.lo.s64 	%rd223, %rd14, 384;
	add.s64 	%rd224, %rd222, %rd223;
	mul.lo.s64 	%rd225, %rd19, 24;
	add.s64 	%rd226, %rd224, %rd225;
	add.s64 	%rd228, %rd226, %rd197;
	ld.global.nc.f32 	%f134, [%rd228+48];
	mul.rn.f32 	%f135, %f134, %f132;
	mul.rn.f32 	%f136, %f103, %f135;
	add.rn.f32 	%f137, %f133, %f136;
	add.rn.f32 	%f138, %f91, %f137;
	mul.lo.s64 	%rd229, %rd12, 9600;
	add.s64 	%rd230, %rd8, %rd229;
	mul.lo.s64 	%rd231, %rd14, 192;
	add.s64 	%rd232, %rd230, %rd231;
	cvt.u32.u16 	%r124, %rs2;
	mul.wide.u32 	%rd233, %r124, 24;
	add.s64 	%rd234, %rd232, %rd233;
	add.s64 	%rd235, %rd234, %rd197;
	ld.global.nc.f32 	%f139, [%rd235+24];
	add.rn.f32 	%f140, %f139, %f138;
	mul.lo.s64 	%rd236, %rd12, 4800;
	add.s64 	%rd237, %rd9, %rd236;
	mul.lo.s64 	%rd238, %rd14, 96;
	add.s64 	%rd239, %rd237, %rd238;
	cvt.u32.u16 	%r125, %rs1;
	mul.wide.u32 	%rd240, %r125, 24;
	add.s64 	%rd241, %rd239, %rd240;
	add.s64 	%rd242, %rd241, %rd197;
	ld.global.nc.f32 	%f141, [%rd242];
	add.rn.f32 	%f142, %f141, %f140;
	mul.wide.u32 	%rd243, %r1, 4;
	add.s64 	%rd244, %rd1, %rd243;
	st.global.f32 	[%rd244], %f142;
	ret;

}
	// .globl	loop_broadcast_fusion_36
.visible .entry loop_broadcast_fusion_36(
	.param .u64 loop_broadcast_fusion_36_param_0
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<5>;

	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 10;
	or.b32  	%r4, %r3, %r2;
	setp.lt.u32 	%p1, %r4, 19200;
	@%p1 bra 	$L__BB153_2;
	bra.uni 	$L__BB153_1;
$L__BB153_2:
	ld.param.u64 	%rd2, [loop_broadcast_fusion_36_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.u32 	%rd4, %r4, 4;
	add.s64 	%rd1, %rd3, %rd4;
	mov.b32 	%r5, 0;
	st.global.u32 	[%rd1], %r5;
$L__BB153_1:
	ret;

}
	// .globl	input_scatter_fusion_244
.visible .entry input_scatter_fusion_244(
	.param .u64 input_scatter_fusion_244_param_0,
	.param .u64 input_scatter_fusion_244_param_1,
	.param .u64 input_scatter_fusion_244_param_2,
	.param .u64 input_scatter_fusion_244_param_3
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot154[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<65>;
	.reg .f32 	%f<70>;
	.reg .b64 	%rd<43>;
	.reg .f64 	%fd<3>;

	mov.u64 	%SPL, __local_depot154;
	ld.param.u64 	%rd9, [input_scatter_fusion_244_param_0];
	ld.param.u64 	%rd10, [input_scatter_fusion_244_param_3];
	cvta.to.global.u64 	%rd11, %rd10;
	ld.param.u64 	%rd12, [input_scatter_fusion_244_param_1];
	ld.param.u64 	%rd13, [input_scatter_fusion_244_param_2];
	cvta.to.global.u64 	%rd1, %rd13;
	cvta.to.global.u64 	%rd2, %rd12;
	cvta.to.global.u64 	%rd3, %rd9;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	shl.b32 	%r19, %r17, 7;
	or.b32  	%r20, %r19, %r18;
	cvt.u16.u32 	%rs1, %r20;
	shr.u16 	%rs4, %rs1, 1;
	mul.hi.u16 	%rs5, %rs4, 5243;
	shr.u16 	%rs2, %rs5, 1;
	and.b16  	%rs6, %rs2, 63;
	cvt.u16.u32 	%rs7, %r17;
	and.b16  	%rs8, %rs7, 255;
	mul.lo.s16 	%rs9, %rs8, 41;
	shr.u16 	%rs3, %rs9, 10;
	cvt.u64.u16 	%rd5, %rs6;
	cvt.u32.u16 	%r21, %rs6;
	mul.wide.u32 	%rd15, %r21, 12;
	add.s64 	%rd16, %rd11, %rd15;
	cvt.u32.u16 	%r22, %rs3;
	mul.wide.u32 	%rd17, %r22, 4;
	add.s64 	%rd18, %rd16, %rd17;
	ld.global.nc.f32 	%f7, [%rd18];
	add.rn.f32 	%f8, %f7, %f7;
	add.rn.f32 	%f9, %f8, %f8;
	add.rn.f32 	%f10, %f9, %f9;
	add.rn.f32 	%f1, %f10, %f10;
	mul.rn.f32 	%f11, %f1, 0f3F22F983;
	cvt.rni.s32.f32 	%r64, %f11;
	cvt.rn.f32.s32 	%f12, %r64;
	fma.rn.f32 	%f13, %f12, 0fBFC90FDA, %f1;
	fma.rn.f32 	%f14, %f12, 0fB3A22168, %f13;
	fma.rn.f32 	%f69, %f12, 0fA7C234C5, %f14;
	abs.f32 	%f3, %f1;
	setp.ltu.f32 	%p1, %f3, 0f47CE4780;
	mov.f32 	%f68, 0f00000000;
	@%p1 bra 	$L__BB154_8;
	setp.neu.f32 	%p2, %f3, 0f7F800000;
	@%p2 bra 	$L__BB154_3;
	mul.rn.f32 	%f69, %f1, %f68;
	mov.b32 	%r64, 0;
	bra.uni 	$L__BB154_8;
$L__BB154_3:
	add.u64 	%rd4, %SPL, 0;
	mov.b32 	%r2, %f1;
	shr.u32 	%r3, %r2, 23;
	and.b32  	%r24, %r3, 224;
	add.s32 	%r25, %r24, -128;
	shl.b32 	%r26, %r2, 8;
	or.b32  	%r30, %r26, -2147483648;
	shr.u32 	%r5, %r25, 5;
	mov.b32 	%r61, 0;
	mov.u64 	%rd42, 0;
	mov.u64 	%rd20, __cudart_i2opi_f;
$L__BB154_4:
	.pragma "nounroll";
	add.s64 	%rd21, %rd20, %rd42;
	ld.global.nc.u32 	%r29, [%rd21];
	// begin inline asm
	{
	mad.lo.cc.u32   %r27, %r29, %r30, %r61;
	madc.hi.u32     %r61, %r29, %r30,  0;
	}
	// end inline asm
	add.s64 	%rd22, %rd4, %rd42;
	st.local.u32 	[%rd22], %r27;
	add.s64 	%rd42, %rd42, 4;
	cvt.u32.u64 	%r32, %rd42;
	setp.ne.s32 	%p3, %r32, 24;
	@%p3 bra 	$L__BB154_4;
	st.local.u32 	[%rd4+24], %r61;
	and.b32  	%r8, %r3, 31;
	mul.wide.u32 	%rd23, %r5, 4;
	sub.s64 	%rd8, %rd4, %rd23;
	ld.local.u32 	%r62, [%rd8+24];
	ld.local.u32 	%r63, [%rd8+20];
	setp.eq.s32 	%p4, %r8, 0;
	@%p4 bra 	$L__BB154_7;
	shl.b32 	%r33, %r63, %r8;
	shl.b32 	%r34, %r62, %r8;
	mov.b32 	%r35, 32;
	sub.s32 	%r36, %r35, %r8;
	shr.u32 	%r37, %r63, %r36;
	add.s32 	%r62, %r37, %r34;
	ld.local.u32 	%r38, [%rd8+16];
	shr.u32 	%r39, %r38, %r36;
	add.s32 	%r63, %r39, %r33;
$L__BB154_7:
	shr.u32 	%r40, %r62, 30;
	shr.u32 	%r41, %r63, 30;
	shl.b32 	%r42, %r62, 2;
	or.b32  	%r43, %r42, %r41;
	shl.b32 	%r44, %r63, 2;
	bfe.u32 	%r45, %r62, 29, 1;
	add.s32 	%r46, %r45, %r40;
	neg.s32 	%r47, %r46;
	setp.lt.s32 	%p5, %r2, 0;
	selp.b32 	%r64, %r47, %r46, %p5;
	xor.b32  	%r48, %r43, %r2;
	bfe.s32 	%r49, %r62, 29, 1;
	xor.b32  	%r50, %r49, %r43;
	xor.b32  	%r51, %r49, %r44;
	cvt.u64.u32 	%rd24, %r50;
	shl.b64 	%rd25, %rd24, 32;
	cvt.u64.u32 	%rd26, %r51;
	or.b64  	%rd27, %rd25, %rd26;
	cvt.rn.f64.s64 	%fd1, %rd27;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f15, %fd2;
	neg.f32 	%f16, %f15;
	setp.lt.s32 	%p6, %r48, 0;
	selp.f32 	%f69, %f16, %f15, %p6;
$L__BB154_8:
	shl.b16 	%rs10, %rs3, 1;
	mul.lo.s16 	%rs11, %rs2, 50;
	sub.s16 	%rs12, %rs1, %rs11;
	cvt.u32.u16 	%r53, %rs10;
	mul.wide.u32 	%rd28, %r53, 12800;
	add.s64 	%rd29, %rd3, %rd28;
	mul.lo.s64 	%rd30, %rd5, 200;
	add.s64 	%rd31, %rd29, %rd30;
	cvt.u32.u16 	%r54, %rs12;
	mul.wide.u32 	%rd32, %r54, 4;
	add.s64 	%rd33, %rd31, %rd32;
	mul.rn.f32 	%f18, %f69, %f69;
	and.b32  	%r55, %r64, 1;
	setp.eq.b32 	%p7, %r55, 1;
	selp.f32 	%f19, 0f3F800000, %f69, %p7;
	fma.rn.f32 	%f20, %f18, %f19, 0f00000000;
	fma.rn.f32 	%f21, %f18, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f22, %f21, 0fB94D4153, %p7;
	selp.f32 	%f23, 0f3D2AAABB, 0f3C0885E4, %p7;
	fma.rn.f32 	%f24, %f22, %f18, %f23;
	selp.f32 	%f25, 0fBEFFFFFF, 0fBE2AAAA8, %p7;
	fma.rn.f32 	%f26, %f24, %f18, %f25;
	fma.rn.f32 	%f27, %f26, %f20, %f19;
	and.b32  	%r56, %r64, 2;
	setp.eq.s32 	%p8, %r56, 0;
	sub.rn.f32 	%f29, %f68, %f27;
	selp.f32 	%f30, %f27, %f29, %p8;
	shl.b64 	%rd34, %rd5, 2;
	add.s64 	%rd35, %rd1, %rd34;
	ld.global.nc.f32 	%f31, [%rd35];
	fma.rn.f32 	%f32, %f31, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f33, %f32;
	mov.f32 	%f34, 0f4B400001;
	mov.f32 	%f35, 0f437C0000;
	fma.rm.f32 	%f36, %f33, %f35, %f34;
	add.rn.f32 	%f37, %f36, 0fCB40007F;
	neg.f32 	%f38, %f37;
	fma.rn.f32 	%f39, %f31, 0f3FB8AA3B, %f38;
	fma.rn.f32 	%f40, %f31, 0f32A57060, %f39;
	mov.b32 	%r57, %f36;
	shl.b32 	%r58, %r57, 23;
	mov.b32 	%f41, %r58;
	ex2.approx.ftz.f32 	%f42, %f40;
	mul.rn.f32 	%f43, %f42, %f41;
	neg.f32 	%f44, %f43;
	sub.rn.f32 	%f45, %f44, %f43;
	add.rn.f32 	%f46, %f45, %f45;
	add.rn.f32 	%f47, %f46, %f46;
	add.rn.f32 	%f48, %f47, %f47;
	add.rn.f32 	%f49, %f48, %f48;
	add.rn.f32 	%f50, %f49, %f49;
	add.rn.f32 	%f51, %f50, %f50;
	add.rn.f32 	%f52, %f51, %f51;
	fma.rn.f32 	%f53, %f52, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f54, %f53;
	fma.rm.f32 	%f55, %f54, %f35, %f34;
	add.rn.f32 	%f56, %f55, 0fCB40007F;
	neg.f32 	%f57, %f56;
	fma.rn.f32 	%f58, %f52, 0f3FB8AA3B, %f57;
	fma.rn.f32 	%f59, %f52, 0f32A57060, %f58;
	mov.b32 	%r59, %f55;
	shl.b32 	%r60, %r59, 23;
	mov.b32 	%f60, %r60;
	ex2.approx.ftz.f32 	%f61, %f59;
	mul.rn.f32 	%f62, %f61, %f60;
	mul.lo.s64 	%rd36, %rd5, 2400;
	add.s64 	%rd37, %rd2, %rd36;
	mul.wide.u32 	%rd38, %r54, 48;
	add.s64 	%rd39, %rd37, %rd38;
	mul.wide.u32 	%rd40, %r53, 4;
	add.s64 	%rd41, %rd39, %rd40;
	ld.global.nc.f32 	%f63, [%rd41+24];
	mul.rn.f32 	%f64, %f63, %f62;
	ld.global.f32 	%f65, [%rd33+12800];
	mul.rn.f32 	%f66, %f30, %f64;
	sub.rn.f32 	%f67, %f65, %f66;
	st.global.f32 	[%rd33+12800], %f67;
	ret;

}
	// .globl	wrapped_transpose_250
.visible .entry wrapped_transpose_250(
	.param .u64 wrapped_transpose_250_param_0,
	.param .u64 wrapped_transpose_250_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd1, [wrapped_transpose_250_param_0];
	ld.param.u64 	%rd2, [wrapped_transpose_250_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	shr.u16 	%rs2, %rs1, 2;
	mul.hi.u16 	%rs3, %rs2, 27963;
	shr.u16 	%rs4, %rs3, 5;
	and.b16  	%rs5, %rs4, 63;
	mul.hi.u16 	%rs6, %rs1, -21845;
	shr.u16 	%rs7, %rs6, 2;
	mul.hi.u16 	%rs8, %rs7, 5243;
	shr.u16 	%rs9, %rs8, 2;
	mul.lo.s16 	%rs10, %rs9, 50;
	sub.s16 	%rs11, %rs7, %rs10;
	mul.lo.s16 	%rs12, %rs7, 6;
	sub.s16 	%rs13, %rs1, %rs12;
	cvt.u32.u16 	%r5, %rs13;
	mul.wide.u32 	%rd5, %r5, 12800;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r6, %rs5;
	mul.wide.u32 	%rd7, %r6, 200;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r7, %rs11;
	mul.wide.u32 	%rd9, %r7, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd3, %rd11;
	st.global.f32 	[%rd12], %f1;
	ret;

}
	// .globl	input_scatter_fusion_245
.visible .entry input_scatter_fusion_245(
	.param .u64 input_scatter_fusion_245_param_0,
	.param .u64 input_scatter_fusion_245_param_1,
	.param .u64 input_scatter_fusion_245_param_2,
	.param .u64 input_scatter_fusion_245_param_3
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot156[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<65>;
	.reg .f32 	%f<70>;
	.reg .b64 	%rd<43>;
	.reg .f64 	%fd<3>;

	mov.u64 	%SPL, __local_depot156;
	ld.param.u64 	%rd9, [input_scatter_fusion_245_param_0];
	ld.param.u64 	%rd10, [input_scatter_fusion_245_param_3];
	cvta.to.global.u64 	%rd11, %rd10;
	ld.param.u64 	%rd12, [input_scatter_fusion_245_param_1];
	ld.param.u64 	%rd13, [input_scatter_fusion_245_param_2];
	cvta.to.global.u64 	%rd1, %rd13;
	cvta.to.global.u64 	%rd2, %rd12;
	cvta.to.global.u64 	%rd3, %rd9;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	shl.b32 	%r19, %r17, 7;
	or.b32  	%r20, %r19, %r18;
	cvt.u16.u32 	%rs1, %r20;
	shr.u16 	%rs4, %rs1, 1;
	mul.hi.u16 	%rs5, %rs4, 5243;
	shr.u16 	%rs2, %rs5, 1;
	and.b16  	%rs6, %rs2, 63;
	cvt.u16.u32 	%rs7, %r17;
	and.b16  	%rs8, %rs7, 255;
	mul.lo.s16 	%rs9, %rs8, 41;
	shr.u16 	%rs3, %rs9, 10;
	cvt.u64.u16 	%rd5, %rs6;
	cvt.u32.u16 	%r21, %rs6;
	mul.wide.u32 	%rd15, %r21, 12;
	add.s64 	%rd16, %rd11, %rd15;
	cvt.u32.u16 	%r22, %rs3;
	mul.wide.u32 	%rd17, %r22, 4;
	add.s64 	%rd18, %rd16, %rd17;
	ld.global.nc.f32 	%f7, [%rd18];
	add.rn.f32 	%f8, %f7, %f7;
	add.rn.f32 	%f9, %f8, %f8;
	add.rn.f32 	%f10, %f9, %f9;
	add.rn.f32 	%f1, %f10, %f10;
	mul.rn.f32 	%f11, %f1, 0f3F22F983;
	cvt.rni.s32.f32 	%r64, %f11;
	cvt.rn.f32.s32 	%f12, %r64;
	fma.rn.f32 	%f13, %f12, 0fBFC90FDA, %f1;
	fma.rn.f32 	%f14, %f12, 0fB3A22168, %f13;
	fma.rn.f32 	%f69, %f12, 0fA7C234C5, %f14;
	abs.f32 	%f3, %f1;
	setp.ltu.f32 	%p1, %f3, 0f47CE4780;
	mov.f32 	%f68, 0f00000000;
	@%p1 bra 	$L__BB156_8;
	setp.neu.f32 	%p2, %f3, 0f7F800000;
	@%p2 bra 	$L__BB156_3;
	mul.rn.f32 	%f69, %f1, %f68;
	mov.b32 	%r64, 0;
	bra.uni 	$L__BB156_8;
$L__BB156_3:
	add.u64 	%rd4, %SPL, 0;
	mov.b32 	%r2, %f1;
	shr.u32 	%r3, %r2, 23;
	and.b32  	%r24, %r3, 224;
	add.s32 	%r25, %r24, -128;
	shl.b32 	%r26, %r2, 8;
	or.b32  	%r30, %r26, -2147483648;
	shr.u32 	%r5, %r25, 5;
	mov.b32 	%r61, 0;
	mov.u64 	%rd42, 0;
	mov.u64 	%rd20, __cudart_i2opi_f;
$L__BB156_4:
	.pragma "nounroll";
	add.s64 	%rd21, %rd20, %rd42;
	ld.global.nc.u32 	%r29, [%rd21];
	// begin inline asm
	{
	mad.lo.cc.u32   %r27, %r29, %r30, %r61;
	madc.hi.u32     %r61, %r29, %r30,  0;
	}
	// end inline asm
	add.s64 	%rd22, %rd4, %rd42;
	st.local.u32 	[%rd22], %r27;
	add.s64 	%rd42, %rd42, 4;
	cvt.u32.u64 	%r32, %rd42;
	setp.ne.s32 	%p3, %r32, 24;
	@%p3 bra 	$L__BB156_4;
	st.local.u32 	[%rd4+24], %r61;
	and.b32  	%r8, %r3, 31;
	mul.wide.u32 	%rd23, %r5, 4;
	sub.s64 	%rd8, %rd4, %rd23;
	ld.local.u32 	%r62, [%rd8+24];
	ld.local.u32 	%r63, [%rd8+20];
	setp.eq.s32 	%p4, %r8, 0;
	@%p4 bra 	$L__BB156_7;
	shl.b32 	%r33, %r63, %r8;
	shl.b32 	%r34, %r62, %r8;
	mov.b32 	%r35, 32;
	sub.s32 	%r36, %r35, %r8;
	shr.u32 	%r37, %r63, %r36;
	add.s32 	%r62, %r37, %r34;
	ld.local.u32 	%r38, [%rd8+16];
	shr.u32 	%r39, %r38, %r36;
	add.s32 	%r63, %r39, %r33;
$L__BB156_7:
	shr.u32 	%r40, %r62, 30;
	shr.u32 	%r41, %r63, 30;
	shl.b32 	%r42, %r62, 2;
	or.b32  	%r43, %r42, %r41;
	shl.b32 	%r44, %r63, 2;
	bfe.u32 	%r45, %r62, 29, 1;
	add.s32 	%r46, %r45, %r40;
	neg.s32 	%r47, %r46;
	setp.lt.s32 	%p5, %r2, 0;
	selp.b32 	%r64, %r47, %r46, %p5;
	xor.b32  	%r48, %r43, %r2;
	bfe.s32 	%r49, %r62, 29, 1;
	xor.b32  	%r50, %r49, %r43;
	xor.b32  	%r51, %r49, %r44;
	cvt.u64.u32 	%rd24, %r50;
	shl.b64 	%rd25, %rd24, 32;
	cvt.u64.u32 	%rd26, %r51;
	or.b64  	%rd27, %rd25, %rd26;
	cvt.rn.f64.s64 	%fd1, %rd27;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f15, %fd2;
	neg.f32 	%f16, %f15;
	setp.lt.s32 	%p6, %r48, 0;
	selp.f32 	%f69, %f16, %f15, %p6;
$L__BB156_8:
	shl.b16 	%rs10, %rs3, 1;
	mul.lo.s16 	%rs11, %rs2, 50;
	sub.s16 	%rs12, %rs1, %rs11;
	cvt.u32.u16 	%r53, %rs10;
	mul.wide.u32 	%rd28, %r53, 12800;
	add.s64 	%rd29, %rd3, %rd28;
	mul.lo.s64 	%rd30, %rd5, 200;
	add.s64 	%rd31, %rd29, %rd30;
	cvt.u32.u16 	%r54, %rs12;
	mul.wide.u32 	%rd32, %r54, 4;
	add.s64 	%rd33, %rd31, %rd32;
	mul.rn.f32 	%f18, %f69, %f69;
	and.b32  	%r55, %r64, 1;
	setp.eq.b32 	%p7, %r55, 1;
	selp.f32 	%f19, 0f3F800000, %f69, %p7;
	fma.rn.f32 	%f20, %f18, %f19, 0f00000000;
	fma.rn.f32 	%f21, %f18, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f22, %f21, 0fB94D4153, %p7;
	selp.f32 	%f23, 0f3D2AAABB, 0f3C0885E4, %p7;
	fma.rn.f32 	%f24, %f22, %f18, %f23;
	selp.f32 	%f25, 0fBEFFFFFF, 0fBE2AAAA8, %p7;
	fma.rn.f32 	%f26, %f24, %f18, %f25;
	fma.rn.f32 	%f27, %f26, %f20, %f19;
	and.b32  	%r56, %r64, 2;
	setp.eq.s32 	%p8, %r56, 0;
	sub.rn.f32 	%f29, %f68, %f27;
	selp.f32 	%f30, %f27, %f29, %p8;
	shl.b64 	%rd34, %rd5, 2;
	add.s64 	%rd35, %rd1, %rd34;
	ld.global.nc.f32 	%f31, [%rd35];
	fma.rn.f32 	%f32, %f31, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f33, %f32;
	mov.f32 	%f34, 0f4B400001;
	mov.f32 	%f35, 0f437C0000;
	fma.rm.f32 	%f36, %f33, %f35, %f34;
	add.rn.f32 	%f37, %f36, 0fCB40007F;
	neg.f32 	%f38, %f37;
	fma.rn.f32 	%f39, %f31, 0f3FB8AA3B, %f38;
	fma.rn.f32 	%f40, %f31, 0f32A57060, %f39;
	mov.b32 	%r57, %f36;
	shl.b32 	%r58, %r57, 23;
	mov.b32 	%f41, %r58;
	ex2.approx.ftz.f32 	%f42, %f40;
	mul.rn.f32 	%f43, %f42, %f41;
	neg.f32 	%f44, %f43;
	sub.rn.f32 	%f45, %f44, %f43;
	add.rn.f32 	%f46, %f45, %f45;
	add.rn.f32 	%f47, %f46, %f46;
	add.rn.f32 	%f48, %f47, %f47;
	add.rn.f32 	%f49, %f48, %f48;
	add.rn.f32 	%f50, %f49, %f49;
	add.rn.f32 	%f51, %f50, %f50;
	add.rn.f32 	%f52, %f51, %f51;
	fma.rn.f32 	%f53, %f52, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f54, %f53;
	fma.rm.f32 	%f55, %f54, %f35, %f34;
	add.rn.f32 	%f56, %f55, 0fCB40007F;
	neg.f32 	%f57, %f56;
	fma.rn.f32 	%f58, %f52, 0f3FB8AA3B, %f57;
	fma.rn.f32 	%f59, %f52, 0f32A57060, %f58;
	mov.b32 	%r59, %f55;
	shl.b32 	%r60, %r59, 23;
	mov.b32 	%f60, %r60;
	ex2.approx.ftz.f32 	%f61, %f59;
	mul.rn.f32 	%f62, %f61, %f60;
	mul.lo.s64 	%rd36, %rd5, 2400;
	add.s64 	%rd37, %rd2, %rd36;
	mul.wide.u32 	%rd38, %r54, 48;
	add.s64 	%rd39, %rd37, %rd38;
	mul.wide.u32 	%rd40, %r53, 4;
	add.s64 	%rd41, %rd39, %rd40;
	ld.global.nc.f32 	%f63, [%rd41+28];
	mul.rn.f32 	%f64, %f63, %f62;
	mul.rn.f32 	%f65, %f30, %f64;
	ld.global.f32 	%f66, [%rd33];
	add.rn.f32 	%f67, %f66, %f65;
	st.global.f32 	[%rd33], %f67;
	ret;

}
	// .globl	loop_pad_fusion_26
.visible .entry loop_pad_fusion_26(
	.param .u64 loop_pad_fusion_26_param_0,
	.param .u64 loop_pad_fusion_26_param_1,
	.param .u64 loop_pad_fusion_26_param_2,
	.param .u64 loop_pad_fusion_26_param_3,
	.param .u64 loop_pad_fusion_26_param_4,
	.param .u64 loop_pad_fusion_26_param_5
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot157[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<18>;
	.reg .b32 	%r<66>;
	.reg .f32 	%f<74>;
	.reg .b64 	%rd<54>;
	.reg .f64 	%fd<3>;

	mov.u64 	%SPL, __local_depot157;
	ld.param.u64 	%rd15, [loop_pad_fusion_26_param_5];
	cvta.to.global.u64 	%rd1, %rd15;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %tid.x;
	shl.b32 	%r20, %r18, 7;
	or.b32  	%r1, %r20, %r19;
	cvt.u16.u32 	%rs1, %r1;
	mul.hi.u16 	%rs3, %rs1, -21845;
	shr.u16 	%rs2, %rs3, 2;
	and.b16  	%rs4, %rs2, 1;
	setp.eq.b16 	%p1, %rs4, 1;
	mov.pred 	%p2, 0;
	xor.pred  	%p3, %p1, %p2;
	not.pred 	%p4, %p3;
	mov.f32 	%f72, 0f00000000;
	@%p4 bra 	$L__BB157_2;
	bra.uni 	$L__BB157_1;
$L__BB157_2:
	ld.param.u64 	%rd14, [loop_pad_fusion_26_param_0];
	ld.param.u64 	%rd16, [loop_pad_fusion_26_param_1];
	ld.param.u64 	%rd17, [loop_pad_fusion_26_param_4];
	cvta.to.global.u64 	%rd2, %rd17;
	ld.param.u64 	%rd18, [loop_pad_fusion_26_param_2];
	ld.param.u64 	%rd19, [loop_pad_fusion_26_param_3];
	cvta.to.global.u64 	%rd3, %rd19;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd16;
	cvta.to.global.u64 	%rd6, %rd14;
	shr.u16 	%rs5, %rs1, 3;
	mul.hi.u16 	%rs6, %rs5, 6991;
	shr.u16 	%rs7, %rs6, 3;
	and.b16  	%rs8, %rs7, 63;
	shr.u16 	%rs10, %rs3, 3;
	mul.hi.u16 	%rs11, %rs10, 5243;
	shr.u16 	%rs12, %rs11, 2;
	mul.lo.s16 	%rs13, %rs12, 50;
	sub.s16 	%rs14, %rs10, %rs13;
	mul.lo.s16 	%rs15, %rs2, 6;
	sub.s16 	%rs16, %rs1, %rs15;
	cvt.u64.u16 	%rd8, %rs8;
	cvt.u64.u16 	%rd9, %rs14;
	cvt.u64.u16 	%rd10, %rs16;
	cvt.u32.u16 	%r21, %rs8;
	mul.wide.u32 	%rd21, %r21, 1200;
	add.s64 	%rd22, %rd5, %rd21;
	cvt.u32.u16 	%r22, %rs14;
	mul.wide.u32 	%rd23, %r22, 24;
	add.s64 	%rd24, %rd22, %rd23;
	cvt.u32.u16 	%r23, %rs16;
	mul.wide.u32 	%rd25, %r23, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f11, [%rd26];
	add.s64 	%rd27, %rd4, %rd21;
	add.s64 	%rd28, %rd27, %rd23;
	add.s64 	%rd29, %rd28, %rd25;
	ld.global.nc.f32 	%f12, [%rd29];
	add.rn.f32 	%f2, %f11, %f12;
	shr.u16 	%rs17, %rs16, 1;
	mul.wide.u32 	%rd30, %r21, 12;
	add.s64 	%rd31, %rd2, %rd30;
	cvt.u32.u16 	%r24, %rs17;
	mul.wide.u32 	%rd32, %r24, 4;
	add.s64 	%rd33, %rd31, %rd32;
	ld.global.nc.f32 	%f13, [%rd33];
	add.rn.f32 	%f14, %f13, %f13;
	add.rn.f32 	%f15, %f14, %f14;
	add.rn.f32 	%f16, %f15, %f15;
	add.rn.f32 	%f3, %f16, %f16;
	mul.rn.f32 	%f17, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r65, %f17;
	cvt.rn.f32.s32 	%f18, %r65;
	fma.rn.f32 	%f19, %f18, 0fBFC90FDA, %f3;
	fma.rn.f32 	%f20, %f18, 0fB3A22168, %f19;
	fma.rn.f32 	%f73, %f18, 0fA7C234C5, %f20;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p5, %f5, 0f47CE4780;
	@%p5 bra 	$L__BB157_10;
	setp.neu.f32 	%p6, %f5, 0f7F800000;
	@%p6 bra 	$L__BB157_5;
	mov.f32 	%f23, 0f00000000;
	mul.rn.f32 	%f73, %f3, %f23;
	mov.b32 	%r65, 0;
	bra.uni 	$L__BB157_10;
$L__BB157_5:
	add.u64 	%rd7, %SPL, 0;
	mov.b32 	%r3, %f3;
	shr.u32 	%r4, %r3, 23;
	and.b32  	%r26, %r4, 224;
	add.s32 	%r27, %r26, -128;
	shl.b32 	%r28, %r3, 8;
	or.b32  	%r32, %r28, -2147483648;
	shr.u32 	%r6, %r27, 5;
	mov.b32 	%r62, 0;
	mov.u64 	%rd53, 0;
	mov.u64 	%rd35, __cudart_i2opi_f;
$L__BB157_6:
	.pragma "nounroll";
	add.s64 	%rd36, %rd35, %rd53;
	ld.global.nc.u32 	%r31, [%rd36];
	// begin inline asm
	{
	mad.lo.cc.u32   %r29, %r31, %r32, %r62;
	madc.hi.u32     %r62, %r31, %r32,  0;
	}
	// end inline asm
	add.s64 	%rd37, %rd7, %rd53;
	st.local.u32 	[%rd37], %r29;
	add.s64 	%rd53, %rd53, 4;
	cvt.u32.u64 	%r34, %rd53;
	setp.ne.s32 	%p7, %r34, 24;
	@%p7 bra 	$L__BB157_6;
	st.local.u32 	[%rd7+24], %r62;
	and.b32  	%r9, %r4, 31;
	mul.wide.u32 	%rd38, %r6, 4;
	sub.s64 	%rd13, %rd7, %rd38;
	ld.local.u32 	%r63, [%rd13+24];
	ld.local.u32 	%r64, [%rd13+20];
	setp.eq.s32 	%p8, %r9, 0;
	@%p8 bra 	$L__BB157_9;
	shl.b32 	%r35, %r64, %r9;
	shl.b32 	%r36, %r63, %r9;
	mov.b32 	%r37, 32;
	sub.s32 	%r38, %r37, %r9;
	shr.u32 	%r39, %r64, %r38;
	add.s32 	%r63, %r39, %r36;
	ld.local.u32 	%r40, [%rd13+16];
	shr.u32 	%r41, %r40, %r38;
	add.s32 	%r64, %r41, %r35;
$L__BB157_9:
	shr.u32 	%r42, %r63, 30;
	shr.u32 	%r43, %r64, 30;
	shl.b32 	%r44, %r63, 2;
	or.b32  	%r45, %r44, %r43;
	shl.b32 	%r46, %r64, 2;
	bfe.u32 	%r47, %r63, 29, 1;
	add.s32 	%r48, %r47, %r42;
	neg.s32 	%r49, %r48;
	setp.lt.s32 	%p9, %r3, 0;
	selp.b32 	%r65, %r49, %r48, %p9;
	xor.b32  	%r50, %r45, %r3;
	bfe.s32 	%r51, %r63, 29, 1;
	xor.b32  	%r52, %r51, %r45;
	xor.b32  	%r53, %r51, %r46;
	cvt.u64.u32 	%rd39, %r52;
	shl.b64 	%rd40, %rd39, 32;
	cvt.u64.u32 	%rd41, %r53;
	or.b64  	%rd42, %rd40, %rd41;
	cvt.rn.f64.s64 	%fd1, %rd42;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f21, %fd2;
	neg.f32 	%f22, %f21;
	setp.lt.s32 	%p10, %r50, 0;
	selp.f32 	%f73, %f22, %f21, %p10;
$L__BB157_10:
	add.s32 	%r55, %r65, 1;
	mul.rn.f32 	%f24, %f73, %f73;
	and.b32  	%r56, %r65, 1;
	setp.eq.b32 	%p11, %r56, 1;
	selp.f32 	%f25, %f73, 0f3F800000, %p11;
	fma.rn.f32 	%f26, %f24, %f25, 0f00000000;
	fma.rn.f32 	%f27, %f24, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f28, 0fB94D4153, %f27, %p11;
	selp.f32 	%f29, 0f3C0885E4, 0f3D2AAABB, %p11;
	fma.rn.f32 	%f30, %f28, %f24, %f29;
	selp.f32 	%f31, 0fBE2AAAA8, 0fBEFFFFFF, %p11;
	fma.rn.f32 	%f32, %f30, %f24, %f31;
	fma.rn.f32 	%f33, %f32, %f26, %f25;
	and.b32  	%r57, %r55, 2;
	setp.eq.s32 	%p12, %r57, 0;
	mov.f32 	%f34, 0f00000000;
	sub.rn.f32 	%f35, %f34, %f33;
	selp.f32 	%f36, %f33, %f35, %p12;
	shl.b64 	%rd43, %rd8, 2;
	add.s64 	%rd44, %rd3, %rd43;
	ld.global.nc.f32 	%f37, [%rd44];
	fma.rn.f32 	%f38, %f37, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f39, %f38;
	mov.f32 	%f40, 0f4B400001;
	mov.f32 	%f41, 0f437C0000;
	fma.rm.f32 	%f42, %f39, %f41, %f40;
	add.rn.f32 	%f43, %f42, 0fCB40007F;
	neg.f32 	%f44, %f43;
	fma.rn.f32 	%f45, %f37, 0f3FB8AA3B, %f44;
	fma.rn.f32 	%f46, %f37, 0f32A57060, %f45;
	mov.b32 	%r58, %f42;
	shl.b32 	%r59, %r58, 23;
	mov.b32 	%f47, %r59;
	ex2.approx.ftz.f32 	%f48, %f46;
	mul.rn.f32 	%f49, %f48, %f47;
	neg.f32 	%f50, %f49;
	sub.rn.f32 	%f51, %f50, %f49;
	add.rn.f32 	%f52, %f51, %f51;
	add.rn.f32 	%f53, %f52, %f52;
	add.rn.f32 	%f54, %f53, %f53;
	add.rn.f32 	%f55, %f54, %f54;
	add.rn.f32 	%f56, %f55, %f55;
	add.rn.f32 	%f57, %f56, %f56;
	add.rn.f32 	%f58, %f57, %f57;
	fma.rn.f32 	%f59, %f58, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f60, %f59;
	fma.rm.f32 	%f61, %f60, %f41, %f40;
	add.rn.f32 	%f62, %f61, 0fCB40007F;
	neg.f32 	%f63, %f62;
	fma.rn.f32 	%f64, %f58, 0f3FB8AA3B, %f63;
	fma.rn.f32 	%f65, %f58, 0f32A57060, %f64;
	mov.b32 	%r60, %f61;
	shl.b32 	%r61, %r60, 23;
	mov.b32 	%f66, %r61;
	ex2.approx.ftz.f32 	%f67, %f65;
	mul.rn.f32 	%f68, %f67, %f66;
	mul.lo.s64 	%rd45, %rd8, 2400;
	add.s64 	%rd46, %rd6, %rd45;
	mul.lo.s64 	%rd47, %rd9, 48;
	add.s64 	%rd48, %rd46, %rd47;
	shl.b64 	%rd49, %rd10, 2;
	add.s64 	%rd50, %rd48, %rd49;
	ld.global.nc.f32 	%f69, [%rd50+24];
	mul.rn.f32 	%f70, %f69, %f68;
	mul.rn.f32 	%f71, %f36, %f70;
	add.rn.f32 	%f72, %f2, %f71;
$L__BB157_1:
	mul.wide.u32 	%rd51, %r1, 4;
	add.s64 	%rd52, %rd1, %rd51;
	st.global.f32 	[%rd52], %f72;
	ret;

}
	// .globl	loop_add_fusion_372
.visible .entry loop_add_fusion_372(
	.param .u64 loop_add_fusion_372_param_0,
	.param .u64 loop_add_fusion_372_param_1,
	.param .u64 loop_add_fusion_372_param_2,
	.param .u64 loop_add_fusion_372_param_3,
	.param .u64 loop_add_fusion_372_param_4,
	.param .u64 loop_add_fusion_372_param_5,
	.param .u64 loop_add_fusion_372_param_6,
	.param .u64 loop_add_fusion_372_param_7,
	.param .u64 loop_add_fusion_372_param_8,
	.param .u64 loop_add_fusion_372_param_9,
	.param .u64 loop_add_fusion_372_param_10,
	.param .u64 loop_add_fusion_372_param_11,
	.param .u64 loop_add_fusion_372_param_12,
	.param .u64 loop_add_fusion_372_param_13,
	.param .u64 loop_add_fusion_372_param_14,
	.param .u64 loop_add_fusion_372_param_15,
	.param .u64 loop_add_fusion_372_param_16,
	.param .u64 loop_add_fusion_372_param_17,
	.param .u64 loop_add_fusion_372_param_18,
	.param .u64 loop_add_fusion_372_param_19,
	.param .u64 loop_add_fusion_372_param_20,
	.param .u64 loop_add_fusion_372_param_21,
	.param .u64 loop_add_fusion_372_param_22,
	.param .u64 loop_add_fusion_372_param_23,
	.param .u64 loop_add_fusion_372_param_24,
	.param .u64 loop_add_fusion_372_param_25,
	.param .u64 loop_add_fusion_372_param_26,
	.param .u64 loop_add_fusion_372_param_27,
	.param .u64 loop_add_fusion_372_param_28,
	.param .u64 loop_add_fusion_372_param_29,
	.param .u64 loop_add_fusion_372_param_30,
	.param .u64 loop_add_fusion_372_param_31,
	.param .u64 loop_add_fusion_372_param_32
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot158[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<23>;
	.reg .b16 	%rs<22>;
	.reg .b32 	%r<144>;
	.reg .f32 	%f<167>;
	.reg .b64 	%rd<283>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot158;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd65, [loop_add_fusion_372_param_25];
	cvta.to.global.u64 	%rd8, %rd65;
	mov.u32 	%r45, %ctaid.x;
	mov.u32 	%r46, %tid.x;
	shl.b32 	%r47, %r45, 7;
	or.b32  	%r1, %r47, %r46;
	cvt.u16.u32 	%rs4, %r1;
	mul.hi.u16 	%rs5, %rs4, -21845;
	shr.u16 	%rs6, %rs5, 2;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs4, %rs7;
	cvt.u32.u16 	%r2, %rs8;
	shr.u16 	%rs9, %rs5, 3;
	mul.hi.u16 	%rs10, %rs9, 5243;
	shr.u16 	%rs11, %rs10, 2;
	mul.lo.s16 	%rs12, %rs11, 50;
	sub.s16 	%rs1, %rs9, %rs12;
	shr.u16 	%rs13, %rs4, 3;
	mul.hi.u16 	%rs14, %rs13, 6991;
	shr.u16 	%rs15, %rs14, 3;
	and.b16  	%rs16, %rs15, 63;
	shr.u16 	%rs17, %rs5, 1;
	and.b16  	%rs2, %rs17, 2;
	or.b16  	%rs18, %rs2, 1;
	shl.b16 	%rs19, %rs18, 2;
	or.b16  	%rs20, %rs19, 2;
	mul.wide.u16 	%r48, %rs20, 2;
	or.b32  	%r5, %r48, 3;
	shl.b32 	%r6, %r5, 1;
	or.b32  	%r7, %r6, 1;
	shl.b32 	%r8, %r7, 1;
	or.b32  	%r9, %r8, 1;
	shl.b32 	%r10, %r9, 1;
	or.b32  	%r11, %r10, 1;
	shl.b32 	%r12, %r11, 1;
	or.b32  	%r49, %r12, 1;
	shl.b32 	%r50, %r49, 1;
	shl.b16 	%rs21, %rs1, 10;
	cvt.u64.u16 	%rd36, %rs16;
	cvt.u64.u16 	%rd37, %rs8;
	cvt.u64.u32 	%rd85, %r50;
	cvt.u64.u16 	%rd38, %rs21;
	add.s64 	%rd86, %rd38, %rd85;
	mul.lo.s64 	%rd87, %rd86, 24;
	cvt.u32.u16 	%r51, %rs16;
	mul.wide.u32 	%rd88, %r51, 1228800;
	add.s64 	%rd89, %rd8, %rd88;
	add.s64 	%rd90, %rd89, %rd87;
	mul.wide.u32 	%rd91, %r2, 4;
	add.s64 	%rd92, %rd90, %rd91;
	ld.global.nc.f32 	%f1, [%rd92+24];
	setp.lt.u32 	%p1, %r49, 511;
	mov.f32 	%f162, 0f00000000;
	shl.b64 	%rd279, %rd37, 2;
	mov.f32 	%f159, %f162;
	@%p1 bra 	$L__BB158_8;
	bra.uni 	$L__BB158_1;
$L__BB158_8:
	ld.param.u64 	%rd57, [loop_add_fusion_372_param_29];
	cvta.to.global.u64 	%rd4, %rd57;
	ld.param.u64 	%rd59, [loop_add_fusion_372_param_28];
	cvta.to.global.u64 	%rd5, %rd59;
	ld.param.u64 	%rd61, [loop_add_fusion_372_param_27];
	cvta.to.global.u64 	%rd6, %rd61;
	ld.param.u64 	%rd63, [loop_add_fusion_372_param_26];
	cvta.to.global.u64 	%rd7, %rd63;
	mul.lo.s64 	%rd93, %rd36, 613200;
	add.s64 	%rd94, %rd5, %rd93;
	cvt.u32.u16 	%r52, %rs1;
	mul.wide.u32 	%rd95, %r52, 12264;
	add.s64 	%rd96, %rd94, %rd95;
	mul.wide.u32 	%rd97, %r12, 24;
	add.s64 	%rd98, %rd96, %rd97;
	add.s64 	%rd100, %rd98, %rd279;
	ld.global.nc.f32 	%f29, [%rd100+24];
	add.s64 	%rd101, %rd4, %rd93;
	add.s64 	%rd102, %rd101, %rd95;
	add.s64 	%rd103, %rd102, %rd97;
	add.s64 	%rd104, %rd103, %rd279;
	ld.global.nc.f32 	%f30, [%rd104+24];
	add.rn.f32 	%f31, %f29, %f30;
	shr.u32 	%r53, %r2, 1;
	mul.lo.s64 	%rd105, %rd36, 12;
	add.s64 	%rd106, %rd6, %rd105;
	mul.wide.u32 	%rd107, %r53, 4;
	add.s64 	%rd108, %rd106, %rd107;
	ld.global.nc.f32 	%f32, [%rd108];
	shl.b64 	%rd109, %rd36, 2;
	add.s64 	%rd110, %rd7, %rd109;
	ld.global.nc.f32 	%f33, [%rd110];
	shl.b32 	%r54, %r11, 2;
	cvt.u64.u32 	%rd111, %r54;
	add.s64 	%rd112, %rd38, %rd111;
	mul.lo.s64 	%rd113, %rd36, 1228800;
	add.s64 	%rd114, %rd8, %rd113;
	mul.lo.s64 	%rd115, %rd112, 24;
	add.s64 	%rd116, %rd114, %rd115;
	add.s64 	%rd117, %rd116, %rd279;
	ld.global.nc.f32 	%f34, [%rd117+96];
	mul.rn.f32 	%f35, %f33, %f34;
	mul.rn.f32 	%f36, %f32, %f35;
	add.rn.f32 	%f159, %f31, %f36;
$L__BB158_1:
	setp.lt.u32 	%p2, %r11, 255;
	mov.f32 	%f160, %f162;
	@%p2 bra 	$L__BB158_9;
	bra.uni 	$L__BB158_2;
$L__BB158_9:
	ld.param.u64 	%rd67, [loop_add_fusion_372_param_24];
	ld.param.u64 	%rd69, [loop_add_fusion_372_param_23];
	ld.param.u64 	%rd71, [loop_add_fusion_372_param_22];
	ld.param.u64 	%rd73, [loop_add_fusion_372_param_21];
	ld.param.u64 	%rd75, [loop_add_fusion_372_param_20];
	cvta.to.global.u64 	%rd9, %rd67;
	cvta.to.global.u64 	%rd10, %rd69;
	cvta.to.global.u64 	%rd11, %rd71;
	cvta.to.global.u64 	%rd12, %rd73;
	cvta.to.global.u64 	%rd13, %rd75;
	mul.lo.s64 	%rd118, %rd36, 306000;
	add.s64 	%rd119, %rd10, %rd118;
	cvt.u32.u16 	%r55, %rs1;
	mul.wide.u32 	%rd120, %r55, 6120;
	add.s64 	%rd121, %rd119, %rd120;
	mul.wide.u32 	%rd122, %r10, 24;
	add.s64 	%rd123, %rd121, %rd122;
	add.s64 	%rd125, %rd123, %rd279;
	ld.global.nc.f32 	%f38, [%rd125+24];
	add.s64 	%rd126, %rd9, %rd118;
	add.s64 	%rd127, %rd126, %rd120;
	add.s64 	%rd128, %rd127, %rd122;
	add.s64 	%rd129, %rd128, %rd279;
	ld.global.nc.f32 	%f39, [%rd129+24];
	add.rn.f32 	%f40, %f38, %f39;
	shr.u32 	%r56, %r2, 1;
	mul.lo.s64 	%rd130, %rd36, 12;
	add.s64 	%rd131, %rd11, %rd130;
	mul.wide.u32 	%rd132, %r56, 4;
	add.s64 	%rd133, %rd131, %rd132;
	ld.global.nc.f32 	%f41, [%rd133];
	shl.b64 	%rd134, %rd36, 2;
	add.s64 	%rd135, %rd12, %rd134;
	ld.global.nc.f32 	%f42, [%rd135];
	add.s64 	%rd136, %rd13, %rd118;
	add.s64 	%rd137, %rd136, %rd120;
	add.s64 	%rd138, %rd137, %rd122;
	add.s64 	%rd139, %rd138, %rd279;
	ld.global.nc.f32 	%f43, [%rd139+24];
	mul.rn.f32 	%f44, %f42, %f43;
	mul.rn.f32 	%f45, %f41, %f44;
	add.rn.f32 	%f160, %f40, %f45;
$L__BB158_2:
	setp.lt.u32 	%p3, %r9, 127;
	mov.f32 	%f161, %f162;
	@%p3 bra 	$L__BB158_10;
	bra.uni 	$L__BB158_3;
$L__BB158_10:
	ld.param.u64 	%rd77, [loop_add_fusion_372_param_19];
	ld.param.u64 	%rd79, [loop_add_fusion_372_param_18];
	ld.param.u64 	%rd80, [loop_add_fusion_372_param_15];
	ld.param.u64 	%rd81, [loop_add_fusion_372_param_17];
	ld.param.u64 	%rd82, [loop_add_fusion_372_param_16];
	cvta.to.global.u64 	%rd14, %rd77;
	cvta.to.global.u64 	%rd15, %rd79;
	cvta.to.global.u64 	%rd16, %rd81;
	cvta.to.global.u64 	%rd17, %rd82;
	cvta.to.global.u64 	%rd18, %rd80;
	mul.lo.s64 	%rd140, %rd36, 152400;
	add.s64 	%rd141, %rd15, %rd140;
	cvt.u32.u16 	%r57, %rs1;
	mul.wide.u32 	%rd142, %r57, 3048;
	add.s64 	%rd143, %rd141, %rd142;
	mul.wide.u32 	%rd144, %r8, 24;
	add.s64 	%rd145, %rd143, %rd144;
	add.s64 	%rd147, %rd145, %rd279;
	ld.global.nc.f32 	%f47, [%rd147+24];
	add.s64 	%rd148, %rd14, %rd140;
	add.s64 	%rd149, %rd148, %rd142;
	add.s64 	%rd150, %rd149, %rd144;
	add.s64 	%rd151, %rd150, %rd279;
	ld.global.nc.f32 	%f48, [%rd151+24];
	add.rn.f32 	%f49, %f47, %f48;
	shr.u32 	%r58, %r2, 1;
	mul.lo.s64 	%rd152, %rd36, 12;
	add.s64 	%rd153, %rd16, %rd152;
	mul.wide.u32 	%rd154, %r58, 4;
	add.s64 	%rd155, %rd153, %rd154;
	ld.global.nc.f32 	%f50, [%rd155];
	shl.b64 	%rd156, %rd36, 2;
	add.s64 	%rd157, %rd17, %rd156;
	ld.global.nc.f32 	%f51, [%rd157];
	add.s64 	%rd158, %rd18, %rd140;
	add.s64 	%rd159, %rd158, %rd142;
	add.s64 	%rd160, %rd159, %rd144;
	add.s64 	%rd161, %rd160, %rd279;
	ld.global.nc.f32 	%f52, [%rd161+24];
	mul.rn.f32 	%f53, %f51, %f52;
	mul.rn.f32 	%f54, %f50, %f53;
	add.rn.f32 	%f161, %f49, %f54;
$L__BB158_3:
	ld.param.u64 	%rd55, [loop_add_fusion_372_param_30];
	add.u64 	%rd83, %SP, 0;
	setp.lt.u32 	%p4, %r7, 63;
	@%p4 bra 	$L__BB158_11;
	bra.uni 	$L__BB158_4;
$L__BB158_11:
	ld.param.u64 	%rd70, [loop_add_fusion_372_param_10];
	ld.param.u64 	%rd72, [loop_add_fusion_372_param_11];
	ld.param.u64 	%rd74, [loop_add_fusion_372_param_12];
	ld.param.u64 	%rd76, [loop_add_fusion_372_param_13];
	ld.param.u64 	%rd78, [loop_add_fusion_372_param_14];
	cvta.to.global.u64 	%rd19, %rd78;
	cvta.to.global.u64 	%rd20, %rd76;
	cvta.to.global.u64 	%rd21, %rd74;
	cvta.to.global.u64 	%rd22, %rd72;
	cvta.to.global.u64 	%rd23, %rd70;
	mul.lo.s64 	%rd162, %rd36, 75600;
	add.s64 	%rd163, %rd20, %rd162;
	cvt.u32.u16 	%r59, %rs1;
	mul.wide.u32 	%rd164, %r59, 1512;
	add.s64 	%rd165, %rd163, %rd164;
	mul.wide.u32 	%rd166, %r6, 24;
	add.s64 	%rd167, %rd165, %rd166;
	add.s64 	%rd169, %rd167, %rd279;
	ld.global.nc.f32 	%f56, [%rd169+24];
	add.s64 	%rd170, %rd19, %rd162;
	add.s64 	%rd171, %rd170, %rd164;
	add.s64 	%rd172, %rd171, %rd166;
	add.s64 	%rd173, %rd172, %rd279;
	ld.global.nc.f32 	%f57, [%rd173+24];
	add.rn.f32 	%f58, %f56, %f57;
	shr.u32 	%r60, %r2, 1;
	mul.lo.s64 	%rd174, %rd36, 12;
	add.s64 	%rd175, %rd21, %rd174;
	mul.wide.u32 	%rd176, %r60, 4;
	add.s64 	%rd177, %rd175, %rd176;
	ld.global.nc.f32 	%f59, [%rd177];
	shl.b64 	%rd178, %rd36, 2;
	add.s64 	%rd179, %rd22, %rd178;
	ld.global.nc.f32 	%f60, [%rd179];
	mul.lo.s64 	%rd180, %rd36, 76800;
	add.s64 	%rd181, %rd23, %rd180;
	mul.wide.u32 	%rd182, %r59, 1536;
	add.s64 	%rd183, %rd181, %rd182;
	add.s64 	%rd184, %rd183, %rd166;
	add.s64 	%rd185, %rd184, %rd279;
	ld.global.nc.f32 	%f61, [%rd185+48];
	mul.rn.f32 	%f62, %f60, %f61;
	mul.rn.f32 	%f63, %f59, %f62;
	add.rn.f32 	%f162, %f58, %f63;
$L__BB158_4:
	ld.param.u64 	%rd50, [loop_add_fusion_372_param_0];
	ld.param.u64 	%rd51, [loop_add_fusion_372_param_32];
	ld.param.u64 	%rd52, [loop_add_fusion_372_param_1];
	ld.param.u64 	%rd54, [loop_add_fusion_372_param_2];
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.local.u64 	%rd34, %rd83;
	setp.lt.u32 	%p5, %r5, 31;
	@%p5 bra 	$L__BB158_12;
	bra.uni 	$L__BB158_5;
$L__BB158_12:
	ld.param.u64 	%rd62, [loop_add_fusion_372_param_6];
	ld.param.u64 	%rd64, [loop_add_fusion_372_param_7];
	ld.param.u64 	%rd66, [loop_add_fusion_372_param_8];
	ld.param.u64 	%rd68, [loop_add_fusion_372_param_9];
	cvta.to.global.u64 	%rd24, %rd68;
	cvta.to.global.u64 	%rd25, %rd66;
	cvta.to.global.u64 	%rd26, %rd64;
	cvta.to.global.u64 	%rd27, %rd62;
	or.b32  	%r4, %r48, 2;
	cvt.u64.u16 	%rd280, %rs1;
	cvt.u64.u32 	%rd42, %r4;
	mul.lo.s64 	%rd186, %rd36, 37200;
	add.s64 	%rd187, %rd25, %rd186;
	cvt.u32.u16 	%r61, %rs1;
	mul.wide.u32 	%rd188, %r61, 744;
	add.s64 	%rd189, %rd187, %rd188;
	mul.wide.u32 	%rd190, %r4, 24;
	add.s64 	%rd191, %rd189, %rd190;
	add.s64 	%rd193, %rd191, %rd279;
	ld.global.nc.f32 	%f65, [%rd193+24];
	add.s64 	%rd194, %rd24, %rd186;
	add.s64 	%rd195, %rd194, %rd188;
	add.s64 	%rd196, %rd195, %rd190;
	add.s64 	%rd197, %rd196, %rd279;
	ld.global.nc.f32 	%f66, [%rd197+24];
	add.rn.f32 	%f12, %f65, %f66;
	shr.u32 	%r62, %r2, 1;
	mul.lo.s64 	%rd198, %rd36, 12;
	add.s64 	%rd199, %rd3, %rd198;
	mul.wide.u32 	%rd200, %r62, 4;
	add.s64 	%rd201, %rd199, %rd200;
	ld.global.nc.f32 	%f13, [%rd201];
	mul.rn.f32 	%f67, %f13, 0f3F22F983;
	cvt.rni.s32.f32 	%r139, %f67;
	cvt.rn.f32.s32 	%f68, %r139;
	fma.rn.f32 	%f69, %f68, 0fBFC90FDA, %f13;
	fma.rn.f32 	%f70, %f68, 0fB3A22168, %f69;
	fma.rn.f32 	%f165, %f68, 0fA7C234C5, %f70;
	abs.f32 	%f15, %f13;
	setp.ltu.f32 	%p6, %f15, 0f47CE4780;
	@%p6 bra 	$L__BB158_20;
	setp.neu.f32 	%p7, %f15, 0f7F800000;
	@%p7 bra 	$L__BB158_15;
	mov.f32 	%f73, 0f00000000;
	mul.rn.f32 	%f165, %f13, %f73;
	mov.b32 	%r139, 0;
	bra.uni 	$L__BB158_20;
$L__BB158_5:
	cvt.u64.u16 	%rd280, %rs1;
	mov.f32 	%f163, 0f00000000;
	bra.uni 	$L__BB158_6;
$L__BB158_15:
	mov.b32 	%r14, %f13;
	shr.u32 	%r15, %r14, 23;
	and.b32  	%r64, %r15, 224;
	add.s32 	%r65, %r64, -128;
	shl.b32 	%r66, %r14, 8;
	or.b32  	%r70, %r66, -2147483648;
	shr.u32 	%r17, %r65, 5;
	mov.b32 	%r136, 0;
	mov.u64 	%rd281, 0;
	mov.u64 	%rd203, __cudart_i2opi_f;
$L__BB158_16:
	.pragma "nounroll";
	add.s64 	%rd204, %rd203, %rd281;
	ld.global.nc.u32 	%r69, [%rd204];
	// begin inline asm
	{
	mad.lo.cc.u32   %r67, %r69, %r70, %r136;
	madc.hi.u32     %r136, %r69, %r70,  0;
	}
	// end inline asm
	add.s64 	%rd205, %rd34, %rd281;
	st.local.u32 	[%rd205], %r67;
	add.s64 	%rd281, %rd281, 4;
	cvt.u32.u64 	%r72, %rd281;
	setp.ne.s32 	%p8, %r72, 24;
	@%p8 bra 	$L__BB158_16;
	st.local.u32 	[%rd34+24], %r136;
	and.b32  	%r20, %r15, 31;
	mul.wide.u32 	%rd206, %r17, 4;
	sub.s64 	%rd45, %rd34, %rd206;
	ld.local.u32 	%r137, [%rd45+24];
	ld.local.u32 	%r138, [%rd45+20];
	setp.eq.s32 	%p9, %r20, 0;
	@%p9 bra 	$L__BB158_19;
	shl.b32 	%r73, %r138, %r20;
	shl.b32 	%r74, %r137, %r20;
	mov.b32 	%r75, 32;
	sub.s32 	%r76, %r75, %r20;
	shr.u32 	%r77, %r138, %r76;
	add.s32 	%r137, %r77, %r74;
	ld.local.u32 	%r78, [%rd45+16];
	shr.u32 	%r79, %r78, %r76;
	add.s32 	%r138, %r79, %r73;
$L__BB158_19:
	shr.u32 	%r80, %r137, 30;
	shr.u32 	%r81, %r138, 30;
	shl.b32 	%r82, %r137, 2;
	or.b32  	%r83, %r82, %r81;
	shl.b32 	%r84, %r138, 2;
	bfe.u32 	%r85, %r137, 29, 1;
	add.s32 	%r86, %r85, %r80;
	neg.s32 	%r87, %r86;
	setp.lt.s32 	%p10, %r14, 0;
	selp.b32 	%r139, %r87, %r86, %p10;
	xor.b32  	%r88, %r83, %r14;
	bfe.s32 	%r89, %r137, 29, 1;
	xor.b32  	%r90, %r89, %r83;
	xor.b32  	%r91, %r89, %r84;
	cvt.u64.u32 	%rd207, %r90;
	shl.b64 	%rd208, %rd207, 32;
	cvt.u64.u32 	%rd209, %r91;
	or.b64  	%rd210, %rd208, %rd209;
	cvt.rn.f64.s64 	%fd1, %rd210;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f71, %fd2;
	neg.f32 	%f72, %f71;
	setp.lt.s32 	%p11, %r88, 0;
	selp.f32 	%f165, %f72, %f71, %p11;
$L__BB158_20:
	add.s32 	%r93, %r139, 1;
	mul.rn.f32 	%f74, %f165, %f165;
	and.b32  	%r94, %r139, 1;
	setp.eq.b32 	%p12, %r94, 1;
	selp.f32 	%f75, %f165, 0f3F800000, %p12;
	fma.rn.f32 	%f76, %f74, %f75, 0f00000000;
	fma.rn.f32 	%f77, %f74, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f78, 0fB94D4153, %f77, %p12;
	selp.f32 	%f79, 0f3C0885E4, 0f3D2AAABB, %p12;
	fma.rn.f32 	%f80, %f78, %f74, %f79;
	selp.f32 	%f81, 0fBE2AAAA8, 0fBEFFFFFF, %p12;
	fma.rn.f32 	%f82, %f80, %f74, %f81;
	fma.rn.f32 	%f83, %f82, %f76, %f75;
	and.b32  	%r95, %r93, 2;
	setp.eq.s32 	%p13, %r95, 0;
	mov.f32 	%f84, 0f00000000;
	sub.rn.f32 	%f85, %f84, %f83;
	selp.f32 	%f86, %f83, %f85, %p13;
	shl.b64 	%rd211, %rd36, 2;
	add.s64 	%rd212, %rd26, %rd211;
	ld.global.nc.f32 	%f87, [%rd212];
	mul.lo.s64 	%rd213, %rd36, 38400;
	add.s64 	%rd214, %rd27, %rd213;
	mul.lo.s64 	%rd215, %rd280, 768;
	add.s64 	%rd216, %rd214, %rd215;
	mul.lo.s64 	%rd217, %rd42, 24;
	add.s64 	%rd218, %rd216, %rd217;
	add.s64 	%rd220, %rd218, %rd279;
	ld.global.nc.f32 	%f88, [%rd220+48];
	mul.rn.f32 	%f89, %f87, %f88;
	mul.rn.f32 	%f90, %f89, %f86;
	add.rn.f32 	%f163, %f12, %f90;
$L__BB158_6:
	cvta.to.global.u64 	%rd1, %rd51;
	cvta.to.global.u64 	%rd31, %rd54;
	cvta.to.global.u64 	%rd32, %rd52;
	cvta.to.global.u64 	%rd33, %rd50;
	shl.b16 	%rs3, %rs18, 1;
	setp.eq.s16 	%p14, %rs2, 0;
	mov.f32 	%f164, 0f00000000;
	@%p14 bra 	$L__BB158_21;
	bra.uni 	$L__BB158_7;
$L__BB158_21:
	ld.param.u64 	%rd53, [loop_add_fusion_372_param_31];
	ld.param.u64 	%rd56, [loop_add_fusion_372_param_3];
	ld.param.u64 	%rd58, [loop_add_fusion_372_param_4];
	ld.param.u64 	%rd60, [loop_add_fusion_372_param_5];
	cvta.to.global.u64 	%rd2, %rd53;
	cvta.to.global.u64 	%rd28, %rd60;
	cvta.to.global.u64 	%rd29, %rd58;
	cvta.to.global.u64 	%rd30, %rd56;
	cvt.u32.u16 	%r3, %rs20;
	cvt.u64.u32 	%rd46, %r3;
	mul.lo.s64 	%rd221, %rd36, 18000;
	add.s64 	%rd222, %rd29, %rd221;
	mul.lo.s64 	%rd223, %rd280, 360;
	add.s64 	%rd224, %rd222, %rd223;
	mul.wide.u32 	%rd225, %r3, 24;
	add.s64 	%rd226, %rd224, %rd225;
	add.s64 	%rd228, %rd226, %rd279;
	ld.global.nc.f32 	%f92, [%rd228+24];
	add.s64 	%rd229, %rd28, %rd221;
	add.s64 	%rd230, %rd229, %rd223;
	add.s64 	%rd231, %rd230, %rd225;
	add.s64 	%rd232, %rd231, %rd279;
	ld.global.nc.f32 	%f93, [%rd232+24];
	add.rn.f32 	%f20, %f92, %f93;
	shr.u32 	%r96, %r2, 1;
	mul.lo.s64 	%rd233, %rd36, 12;
	add.s64 	%rd234, %rd3, %rd233;
	mul.wide.u32 	%rd235, %r96, 4;
	add.s64 	%rd236, %rd234, %rd235;
	ld.global.nc.f32 	%f94, [%rd236];
	add.rn.f32 	%f21, %f94, %f94;
	mul.rn.f32 	%f95, %f21, 0f3F22F983;
	cvt.rni.s32.f32 	%r143, %f95;
	cvt.rn.f32.s32 	%f96, %r143;
	fma.rn.f32 	%f97, %f96, 0fBFC90FDA, %f21;
	fma.rn.f32 	%f98, %f96, 0fB3A22168, %f97;
	fma.rn.f32 	%f166, %f96, 0fA7C234C5, %f98;
	abs.f32 	%f23, %f21;
	setp.ltu.f32 	%p15, %f23, 0f47CE4780;
	@%p15 bra 	$L__BB158_29;
	setp.neu.f32 	%p16, %f23, 0f7F800000;
	@%p16 bra 	$L__BB158_24;
	mov.f32 	%f101, 0f00000000;
	mul.rn.f32 	%f166, %f21, %f101;
	mov.b32 	%r143, 0;
	bra.uni 	$L__BB158_29;
$L__BB158_24:
	mov.b32 	%r30, %f21;
	shr.u32 	%r31, %r30, 23;
	and.b32  	%r98, %r31, 224;
	add.s32 	%r99, %r98, -128;
	shl.b32 	%r100, %r30, 8;
	or.b32  	%r104, %r100, -2147483648;
	shr.u32 	%r33, %r99, 5;
	mov.b32 	%r140, 0;
	mov.u64 	%rd282, 0;
	mov.u64 	%rd238, __cudart_i2opi_f;
$L__BB158_25:
	.pragma "nounroll";
	add.s64 	%rd239, %rd238, %rd282;
	ld.global.nc.u32 	%r103, [%rd239];
	// begin inline asm
	{
	mad.lo.cc.u32   %r101, %r103, %r104, %r140;
	madc.hi.u32     %r140, %r103, %r104,  0;
	}
	// end inline asm
	add.s64 	%rd240, %rd34, %rd282;
	st.local.u32 	[%rd240], %r101;
	add.s64 	%rd282, %rd282, 4;
	cvt.u32.u64 	%r106, %rd282;
	setp.ne.s32 	%p17, %r106, 24;
	@%p17 bra 	$L__BB158_25;
	st.local.u32 	[%rd34+24], %r140;
	and.b32  	%r36, %r31, 31;
	mul.wide.u32 	%rd241, %r33, 4;
	sub.s64 	%rd49, %rd34, %rd241;
	ld.local.u32 	%r141, [%rd49+24];
	ld.local.u32 	%r142, [%rd49+20];
	setp.eq.s32 	%p18, %r36, 0;
	@%p18 bra 	$L__BB158_28;
	shl.b32 	%r107, %r142, %r36;
	shl.b32 	%r108, %r141, %r36;
	mov.b32 	%r109, 32;
	sub.s32 	%r110, %r109, %r36;
	shr.u32 	%r111, %r142, %r110;
	add.s32 	%r141, %r111, %r108;
	ld.local.u32 	%r112, [%rd49+16];
	shr.u32 	%r113, %r112, %r110;
	add.s32 	%r142, %r113, %r107;
$L__BB158_28:
	shr.u32 	%r114, %r141, 30;
	shr.u32 	%r115, %r142, 30;
	shl.b32 	%r116, %r141, 2;
	or.b32  	%r117, %r116, %r115;
	shl.b32 	%r118, %r142, 2;
	bfe.u32 	%r119, %r141, 29, 1;
	add.s32 	%r120, %r119, %r114;
	neg.s32 	%r121, %r120;
	setp.lt.s32 	%p19, %r30, 0;
	selp.b32 	%r143, %r121, %r120, %p19;
	xor.b32  	%r122, %r117, %r30;
	bfe.s32 	%r123, %r141, 29, 1;
	xor.b32  	%r124, %r123, %r117;
	xor.b32  	%r125, %r123, %r118;
	cvt.u64.u32 	%rd242, %r124;
	shl.b64 	%rd243, %rd242, 32;
	cvt.u64.u32 	%rd244, %r125;
	or.b64  	%rd245, %rd243, %rd244;
	cvt.rn.f64.s64 	%fd3, %rd245;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f99, %fd4;
	neg.f32 	%f100, %f99;
	setp.lt.s32 	%p20, %r122, 0;
	selp.f32 	%f166, %f100, %f99, %p20;
$L__BB158_29:
	add.s32 	%r127, %r143, 1;
	mul.rn.f32 	%f102, %f166, %f166;
	and.b32  	%r128, %r143, 1;
	setp.eq.b32 	%p21, %r128, 1;
	selp.f32 	%f103, %f166, 0f3F800000, %p21;
	fma.rn.f32 	%f104, %f102, %f103, 0f00000000;
	fma.rn.f32 	%f105, %f102, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f106, 0fB94D4153, %f105, %p21;
	selp.f32 	%f107, 0f3C0885E4, 0f3D2AAABB, %p21;
	fma.rn.f32 	%f108, %f106, %f102, %f107;
	selp.f32 	%f109, 0fBE2AAAA8, 0fBEFFFFFF, %p21;
	fma.rn.f32 	%f110, %f108, %f102, %f109;
	fma.rn.f32 	%f111, %f110, %f104, %f103;
	and.b32  	%r129, %r127, 2;
	setp.eq.s32 	%p22, %r129, 0;
	mov.f32 	%f112, 0f00000000;
	sub.rn.f32 	%f113, %f112, %f111;
	selp.f32 	%f114, %f111, %f113, %p22;
	shl.b64 	%rd246, %rd36, 2;
	add.s64 	%rd247, %rd2, %rd246;
	ld.global.nc.f32 	%f115, [%rd247];
	fma.rn.f32 	%f116, %f115, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f117, %f116;
	mov.f32 	%f118, 0f4B400001;
	mov.f32 	%f119, 0f437C0000;
	fma.rm.f32 	%f120, %f117, %f119, %f118;
	add.rn.f32 	%f121, %f120, 0fCB40007F;
	neg.f32 	%f122, %f121;
	fma.rn.f32 	%f123, %f115, 0f3FB8AA3B, %f122;
	fma.rn.f32 	%f124, %f115, 0f32A57060, %f123;
	mov.b32 	%r130, %f120;
	shl.b32 	%r131, %r130, 23;
	mov.b32 	%f125, %r131;
	ex2.approx.ftz.f32 	%f126, %f124;
	mul.rn.f32 	%f127, %f126, %f125;
	neg.f32 	%f128, %f127;
	sub.rn.f32 	%f129, %f128, %f127;
	add.rn.f32 	%f130, %f129, %f129;
	add.rn.f32 	%f131, %f130, %f130;
	add.rn.f32 	%f132, %f131, %f131;
	add.rn.f32 	%f133, %f132, %f132;
	fma.rn.f32 	%f134, %f133, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f135, %f134;
	fma.rm.f32 	%f136, %f135, %f119, %f118;
	add.rn.f32 	%f137, %f136, 0fCB40007F;
	neg.f32 	%f138, %f137;
	fma.rn.f32 	%f139, %f133, 0f3FB8AA3B, %f138;
	fma.rn.f32 	%f140, %f133, 0f32A57060, %f139;
	mov.b32 	%r132, %f136;
	shl.b32 	%r133, %r132, 23;
	mov.b32 	%f141, %r133;
	ex2.approx.ftz.f32 	%f142, %f140;
	mul.rn.f32 	%f143, %f142, %f141;
	mul.lo.s64 	%rd248, %rd36, 19200;
	add.s64 	%rd249, %rd30, %rd248;
	mul.lo.s64 	%rd250, %rd280, 384;
	add.s64 	%rd251, %rd249, %rd250;
	mul.lo.s64 	%rd252, %rd46, 24;
	add.s64 	%rd253, %rd251, %rd252;
	add.s64 	%rd255, %rd253, %rd279;
	ld.global.nc.f32 	%f144, [%rd255+48];
	mul.rn.f32 	%f145, %f144, %f143;
	mul.rn.f32 	%f146, %f114, %f145;
	add.rn.f32 	%f164, %f20, %f146;
$L__BB158_7:
	add.rn.f32 	%f147, %f1, %f159;
	add.rn.f32 	%f148, %f147, %f160;
	add.rn.f32 	%f149, %f148, %f161;
	add.rn.f32 	%f150, %f149, %f162;
	add.rn.f32 	%f151, %f150, %f163;
	add.rn.f32 	%f152, %f151, %f164;
	mul.lo.s64 	%rd256, %rd36, 9600;
	add.s64 	%rd257, %rd31, %rd256;
	mul.lo.s64 	%rd258, %rd280, 192;
	add.s64 	%rd259, %rd257, %rd258;
	cvt.u32.u16 	%r134, %rs3;
	mul.wide.u32 	%rd260, %r134, 24;
	add.s64 	%rd261, %rd259, %rd260;
	add.s64 	%rd263, %rd261, %rd279;
	ld.global.nc.f32 	%f153, [%rd263+24];
	add.rn.f32 	%f154, %f152, %f153;
	mul.lo.s64 	%rd264, %rd36, 4800;
	add.s64 	%rd265, %rd32, %rd264;
	mul.lo.s64 	%rd266, %rd280, 96;
	add.s64 	%rd267, %rd265, %rd266;
	cvt.u32.u16 	%r135, %rs2;
	mul.wide.u32 	%rd268, %r135, 24;
	add.s64 	%rd269, %rd267, %rd268;
	add.s64 	%rd270, %rd269, %rd279;
	ld.global.nc.f32 	%f155, [%rd270+24];
	add.rn.f32 	%f156, %f154, %f155;
	mul.wide.u32 	%rd271, %r1, 4;
	add.s64 	%rd272, %rd33, %rd271;
	ld.global.nc.f32 	%f157, [%rd272];
	add.rn.f32 	%f158, %f156, %f157;
	add.s64 	%rd273, %rd1, %rd271;
	st.global.f32 	[%rd273], %f158;
	ret;

}
	// .globl	input_scatter_fusion_246
.visible .entry input_scatter_fusion_246(
	.param .u64 input_scatter_fusion_246_param_0,
	.param .u64 input_scatter_fusion_246_param_1,
	.param .u64 input_scatter_fusion_246_param_2,
	.param .u64 input_scatter_fusion_246_param_3
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot159[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<65>;
	.reg .f32 	%f<72>;
	.reg .b64 	%rd<43>;
	.reg .f64 	%fd<3>;

	mov.u64 	%SPL, __local_depot159;
	ld.param.u64 	%rd9, [input_scatter_fusion_246_param_0];
	ld.param.u64 	%rd10, [input_scatter_fusion_246_param_3];
	cvta.to.global.u64 	%rd11, %rd10;
	ld.param.u64 	%rd12, [input_scatter_fusion_246_param_1];
	ld.param.u64 	%rd13, [input_scatter_fusion_246_param_2];
	cvta.to.global.u64 	%rd1, %rd13;
	cvta.to.global.u64 	%rd2, %rd12;
	cvta.to.global.u64 	%rd3, %rd9;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	shl.b32 	%r19, %r17, 7;
	or.b32  	%r20, %r19, %r18;
	cvt.u16.u32 	%rs1, %r20;
	shr.u16 	%rs4, %rs1, 1;
	mul.hi.u16 	%rs5, %rs4, 5243;
	shr.u16 	%rs2, %rs5, 1;
	and.b16  	%rs6, %rs2, 63;
	cvt.u16.u32 	%rs7, %r17;
	and.b16  	%rs8, %rs7, 255;
	mul.lo.s16 	%rs9, %rs8, 41;
	shr.u16 	%rs3, %rs9, 10;
	cvt.u64.u16 	%rd5, %rs6;
	cvt.u32.u16 	%r21, %rs6;
	mul.wide.u32 	%rd15, %r21, 12;
	add.s64 	%rd16, %rd11, %rd15;
	cvt.u32.u16 	%r22, %rs3;
	mul.wide.u32 	%rd17, %r22, 4;
	add.s64 	%rd18, %rd16, %rd17;
	ld.global.nc.f32 	%f7, [%rd18];
	add.rn.f32 	%f8, %f7, %f7;
	add.rn.f32 	%f9, %f8, %f8;
	add.rn.f32 	%f10, %f9, %f9;
	add.rn.f32 	%f11, %f10, %f10;
	add.rn.f32 	%f1, %f11, %f11;
	mul.rn.f32 	%f12, %f1, 0f3F22F983;
	cvt.rni.s32.f32 	%r64, %f12;
	cvt.rn.f32.s32 	%f13, %r64;
	fma.rn.f32 	%f14, %f13, 0fBFC90FDA, %f1;
	fma.rn.f32 	%f15, %f13, 0fB3A22168, %f14;
	fma.rn.f32 	%f71, %f13, 0fA7C234C5, %f15;
	abs.f32 	%f3, %f1;
	setp.ltu.f32 	%p1, %f3, 0f47CE4780;
	mov.f32 	%f70, 0f00000000;
	@%p1 bra 	$L__BB159_8;
	setp.neu.f32 	%p2, %f3, 0f7F800000;
	@%p2 bra 	$L__BB159_3;
	mul.rn.f32 	%f71, %f1, %f70;
	mov.b32 	%r64, 0;
	bra.uni 	$L__BB159_8;
$L__BB159_3:
	add.u64 	%rd4, %SPL, 0;
	mov.b32 	%r2, %f1;
	shr.u32 	%r3, %r2, 23;
	and.b32  	%r24, %r3, 224;
	add.s32 	%r25, %r24, -128;
	shl.b32 	%r26, %r2, 8;
	or.b32  	%r30, %r26, -2147483648;
	shr.u32 	%r5, %r25, 5;
	mov.b32 	%r61, 0;
	mov.u64 	%rd42, 0;
	mov.u64 	%rd20, __cudart_i2opi_f;
$L__BB159_4:
	.pragma "nounroll";
	add.s64 	%rd21, %rd20, %rd42;
	ld.global.nc.u32 	%r29, [%rd21];
	// begin inline asm
	{
	mad.lo.cc.u32   %r27, %r29, %r30, %r61;
	madc.hi.u32     %r61, %r29, %r30,  0;
	}
	// end inline asm
	add.s64 	%rd22, %rd4, %rd42;
	st.local.u32 	[%rd22], %r27;
	add.s64 	%rd42, %rd42, 4;
	cvt.u32.u64 	%r32, %rd42;
	setp.ne.s32 	%p3, %r32, 24;
	@%p3 bra 	$L__BB159_4;
	st.local.u32 	[%rd4+24], %r61;
	and.b32  	%r8, %r3, 31;
	mul.wide.u32 	%rd23, %r5, 4;
	sub.s64 	%rd8, %rd4, %rd23;
	ld.local.u32 	%r62, [%rd8+24];
	ld.local.u32 	%r63, [%rd8+20];
	setp.eq.s32 	%p4, %r8, 0;
	@%p4 bra 	$L__BB159_7;
	shl.b32 	%r33, %r63, %r8;
	shl.b32 	%r34, %r62, %r8;
	mov.b32 	%r35, 32;
	sub.s32 	%r36, %r35, %r8;
	shr.u32 	%r37, %r63, %r36;
	add.s32 	%r62, %r37, %r34;
	ld.local.u32 	%r38, [%rd8+16];
	shr.u32 	%r39, %r38, %r36;
	add.s32 	%r63, %r39, %r33;
$L__BB159_7:
	shr.u32 	%r40, %r62, 30;
	shr.u32 	%r41, %r63, 30;
	shl.b32 	%r42, %r62, 2;
	or.b32  	%r43, %r42, %r41;
	shl.b32 	%r44, %r63, 2;
	bfe.u32 	%r45, %r62, 29, 1;
	add.s32 	%r46, %r45, %r40;
	neg.s32 	%r47, %r46;
	setp.lt.s32 	%p5, %r2, 0;
	selp.b32 	%r64, %r47, %r46, %p5;
	xor.b32  	%r48, %r43, %r2;
	bfe.s32 	%r49, %r62, 29, 1;
	xor.b32  	%r50, %r49, %r43;
	xor.b32  	%r51, %r49, %r44;
	cvt.u64.u32 	%rd24, %r50;
	shl.b64 	%rd25, %rd24, 32;
	cvt.u64.u32 	%rd26, %r51;
	or.b64  	%rd27, %rd25, %rd26;
	cvt.rn.f64.s64 	%fd1, %rd27;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f16, %fd2;
	neg.f32 	%f17, %f16;
	setp.lt.s32 	%p6, %r48, 0;
	selp.f32 	%f71, %f17, %f16, %p6;
$L__BB159_8:
	shl.b16 	%rs10, %rs3, 1;
	mul.lo.s16 	%rs11, %rs2, 50;
	sub.s16 	%rs12, %rs1, %rs11;
	cvt.u32.u16 	%r53, %rs10;
	mul.wide.u32 	%rd28, %r53, 12800;
	add.s64 	%rd29, %rd3, %rd28;
	mul.lo.s64 	%rd30, %rd5, 200;
	add.s64 	%rd31, %rd29, %rd30;
	cvt.u32.u16 	%r54, %rs12;
	mul.wide.u32 	%rd32, %r54, 4;
	add.s64 	%rd33, %rd31, %rd32;
	mul.rn.f32 	%f19, %f71, %f71;
	and.b32  	%r55, %r64, 1;
	setp.eq.b32 	%p7, %r55, 1;
	selp.f32 	%f20, 0f3F800000, %f71, %p7;
	fma.rn.f32 	%f21, %f19, %f20, 0f00000000;
	fma.rn.f32 	%f22, %f19, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f23, %f22, 0fB94D4153, %p7;
	selp.f32 	%f24, 0f3D2AAABB, 0f3C0885E4, %p7;
	fma.rn.f32 	%f25, %f23, %f19, %f24;
	selp.f32 	%f26, 0fBEFFFFFF, 0fBE2AAAA8, %p7;
	fma.rn.f32 	%f27, %f25, %f19, %f26;
	fma.rn.f32 	%f28, %f27, %f21, %f20;
	and.b32  	%r56, %r64, 2;
	setp.eq.s32 	%p8, %r56, 0;
	sub.rn.f32 	%f30, %f70, %f28;
	selp.f32 	%f31, %f28, %f30, %p8;
	shl.b64 	%rd34, %rd5, 2;
	add.s64 	%rd35, %rd1, %rd34;
	ld.global.nc.f32 	%f32, [%rd35];
	fma.rn.f32 	%f33, %f32, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f34, %f33;
	mov.f32 	%f35, 0f4B400001;
	mov.f32 	%f36, 0f437C0000;
	fma.rm.f32 	%f37, %f34, %f36, %f35;
	add.rn.f32 	%f38, %f37, 0fCB40007F;
	neg.f32 	%f39, %f38;
	fma.rn.f32 	%f40, %f32, 0f3FB8AA3B, %f39;
	fma.rn.f32 	%f41, %f32, 0f32A57060, %f40;
	mov.b32 	%r57, %f37;
	shl.b32 	%r58, %r57, 23;
	mov.b32 	%f42, %r58;
	ex2.approx.ftz.f32 	%f43, %f41;
	mul.rn.f32 	%f44, %f43, %f42;
	neg.f32 	%f45, %f44;
	sub.rn.f32 	%f46, %f45, %f44;
	add.rn.f32 	%f47, %f46, %f46;
	add.rn.f32 	%f48, %f47, %f47;
	add.rn.f32 	%f49, %f48, %f48;
	add.rn.f32 	%f50, %f49, %f49;
	add.rn.f32 	%f51, %f50, %f50;
	add.rn.f32 	%f52, %f51, %f51;
	add.rn.f32 	%f53, %f52, %f52;
	add.rn.f32 	%f54, %f53, %f53;
	fma.rn.f32 	%f55, %f54, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f56, %f55;
	fma.rm.f32 	%f57, %f56, %f36, %f35;
	add.rn.f32 	%f58, %f57, 0fCB40007F;
	neg.f32 	%f59, %f58;
	fma.rn.f32 	%f60, %f54, 0f3FB8AA3B, %f59;
	fma.rn.f32 	%f61, %f54, 0f32A57060, %f60;
	mov.b32 	%r59, %f57;
	shl.b32 	%r60, %r59, 23;
	mov.b32 	%f62, %r60;
	ex2.approx.ftz.f32 	%f63, %f61;
	mul.rn.f32 	%f64, %f63, %f62;
	mul.lo.s64 	%rd36, %rd5, 2400;
	add.s64 	%rd37, %rd2, %rd36;
	mul.wide.u32 	%rd38, %r54, 48;
	add.s64 	%rd39, %rd37, %rd38;
	mul.wide.u32 	%rd40, %r53, 4;
	add.s64 	%rd41, %rd39, %rd40;
	ld.global.nc.f32 	%f65, [%rd41+24];
	mul.rn.f32 	%f66, %f65, %f64;
	ld.global.f32 	%f67, [%rd33+12800];
	mul.rn.f32 	%f68, %f31, %f66;
	sub.rn.f32 	%f69, %f67, %f68;
	st.global.f32 	[%rd33+12800], %f69;
	ret;

}
	// .globl	input_scatter_fusion_247
.visible .entry input_scatter_fusion_247(
	.param .u64 input_scatter_fusion_247_param_0,
	.param .u64 input_scatter_fusion_247_param_1,
	.param .u64 input_scatter_fusion_247_param_2,
	.param .u64 input_scatter_fusion_247_param_3
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot160[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<65>;
	.reg .f32 	%f<72>;
	.reg .b64 	%rd<43>;
	.reg .f64 	%fd<3>;

	mov.u64 	%SPL, __local_depot160;
	ld.param.u64 	%rd9, [input_scatter_fusion_247_param_0];
	ld.param.u64 	%rd10, [input_scatter_fusion_247_param_3];
	cvta.to.global.u64 	%rd11, %rd10;
	ld.param.u64 	%rd12, [input_scatter_fusion_247_param_1];
	ld.param.u64 	%rd13, [input_scatter_fusion_247_param_2];
	cvta.to.global.u64 	%rd1, %rd13;
	cvta.to.global.u64 	%rd2, %rd12;
	cvta.to.global.u64 	%rd3, %rd9;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	shl.b32 	%r19, %r17, 7;
	or.b32  	%r20, %r19, %r18;
	cvt.u16.u32 	%rs1, %r20;
	shr.u16 	%rs4, %rs1, 1;
	mul.hi.u16 	%rs5, %rs4, 5243;
	shr.u16 	%rs2, %rs5, 1;
	and.b16  	%rs6, %rs2, 63;
	cvt.u16.u32 	%rs7, %r17;
	and.b16  	%rs8, %rs7, 255;
	mul.lo.s16 	%rs9, %rs8, 41;
	shr.u16 	%rs3, %rs9, 10;
	cvt.u64.u16 	%rd5, %rs6;
	cvt.u32.u16 	%r21, %rs6;
	mul.wide.u32 	%rd15, %r21, 12;
	add.s64 	%rd16, %rd11, %rd15;
	cvt.u32.u16 	%r22, %rs3;
	mul.wide.u32 	%rd17, %r22, 4;
	add.s64 	%rd18, %rd16, %rd17;
	ld.global.nc.f32 	%f7, [%rd18];
	add.rn.f32 	%f8, %f7, %f7;
	add.rn.f32 	%f9, %f8, %f8;
	add.rn.f32 	%f10, %f9, %f9;
	add.rn.f32 	%f11, %f10, %f10;
	add.rn.f32 	%f1, %f11, %f11;
	mul.rn.f32 	%f12, %f1, 0f3F22F983;
	cvt.rni.s32.f32 	%r64, %f12;
	cvt.rn.f32.s32 	%f13, %r64;
	fma.rn.f32 	%f14, %f13, 0fBFC90FDA, %f1;
	fma.rn.f32 	%f15, %f13, 0fB3A22168, %f14;
	fma.rn.f32 	%f71, %f13, 0fA7C234C5, %f15;
	abs.f32 	%f3, %f1;
	setp.ltu.f32 	%p1, %f3, 0f47CE4780;
	mov.f32 	%f70, 0f00000000;
	@%p1 bra 	$L__BB160_8;
	setp.neu.f32 	%p2, %f3, 0f7F800000;
	@%p2 bra 	$L__BB160_3;
	mul.rn.f32 	%f71, %f1, %f70;
	mov.b32 	%r64, 0;
	bra.uni 	$L__BB160_8;
$L__BB160_3:
	add.u64 	%rd4, %SPL, 0;
	mov.b32 	%r2, %f1;
	shr.u32 	%r3, %r2, 23;
	and.b32  	%r24, %r3, 224;
	add.s32 	%r25, %r24, -128;
	shl.b32 	%r26, %r2, 8;
	or.b32  	%r30, %r26, -2147483648;
	shr.u32 	%r5, %r25, 5;
	mov.b32 	%r61, 0;
	mov.u64 	%rd42, 0;
	mov.u64 	%rd20, __cudart_i2opi_f;
$L__BB160_4:
	.pragma "nounroll";
	add.s64 	%rd21, %rd20, %rd42;
	ld.global.nc.u32 	%r29, [%rd21];
	// begin inline asm
	{
	mad.lo.cc.u32   %r27, %r29, %r30, %r61;
	madc.hi.u32     %r61, %r29, %r30,  0;
	}
	// end inline asm
	add.s64 	%rd22, %rd4, %rd42;
	st.local.u32 	[%rd22], %r27;
	add.s64 	%rd42, %rd42, 4;
	cvt.u32.u64 	%r32, %rd42;
	setp.ne.s32 	%p3, %r32, 24;
	@%p3 bra 	$L__BB160_4;
	st.local.u32 	[%rd4+24], %r61;
	and.b32  	%r8, %r3, 31;
	mul.wide.u32 	%rd23, %r5, 4;
	sub.s64 	%rd8, %rd4, %rd23;
	ld.local.u32 	%r62, [%rd8+24];
	ld.local.u32 	%r63, [%rd8+20];
	setp.eq.s32 	%p4, %r8, 0;
	@%p4 bra 	$L__BB160_7;
	shl.b32 	%r33, %r63, %r8;
	shl.b32 	%r34, %r62, %r8;
	mov.b32 	%r35, 32;
	sub.s32 	%r36, %r35, %r8;
	shr.u32 	%r37, %r63, %r36;
	add.s32 	%r62, %r37, %r34;
	ld.local.u32 	%r38, [%rd8+16];
	shr.u32 	%r39, %r38, %r36;
	add.s32 	%r63, %r39, %r33;
$L__BB160_7:
	shr.u32 	%r40, %r62, 30;
	shr.u32 	%r41, %r63, 30;
	shl.b32 	%r42, %r62, 2;
	or.b32  	%r43, %r42, %r41;
	shl.b32 	%r44, %r63, 2;
	bfe.u32 	%r45, %r62, 29, 1;
	add.s32 	%r46, %r45, %r40;
	neg.s32 	%r47, %r46;
	setp.lt.s32 	%p5, %r2, 0;
	selp.b32 	%r64, %r47, %r46, %p5;
	xor.b32  	%r48, %r43, %r2;
	bfe.s32 	%r49, %r62, 29, 1;
	xor.b32  	%r50, %r49, %r43;
	xor.b32  	%r51, %r49, %r44;
	cvt.u64.u32 	%rd24, %r50;
	shl.b64 	%rd25, %rd24, 32;
	cvt.u64.u32 	%rd26, %r51;
	or.b64  	%rd27, %rd25, %rd26;
	cvt.rn.f64.s64 	%fd1, %rd27;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f16, %fd2;
	neg.f32 	%f17, %f16;
	setp.lt.s32 	%p6, %r48, 0;
	selp.f32 	%f71, %f17, %f16, %p6;
$L__BB160_8:
	shl.b16 	%rs10, %rs3, 1;
	mul.lo.s16 	%rs11, %rs2, 50;
	sub.s16 	%rs12, %rs1, %rs11;
	cvt.u32.u16 	%r53, %rs10;
	mul.wide.u32 	%rd28, %r53, 12800;
	add.s64 	%rd29, %rd3, %rd28;
	mul.lo.s64 	%rd30, %rd5, 200;
	add.s64 	%rd31, %rd29, %rd30;
	cvt.u32.u16 	%r54, %rs12;
	mul.wide.u32 	%rd32, %r54, 4;
	add.s64 	%rd33, %rd31, %rd32;
	mul.rn.f32 	%f19, %f71, %f71;
	and.b32  	%r55, %r64, 1;
	setp.eq.b32 	%p7, %r55, 1;
	selp.f32 	%f20, 0f3F800000, %f71, %p7;
	fma.rn.f32 	%f21, %f19, %f20, 0f00000000;
	fma.rn.f32 	%f22, %f19, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f23, %f22, 0fB94D4153, %p7;
	selp.f32 	%f24, 0f3D2AAABB, 0f3C0885E4, %p7;
	fma.rn.f32 	%f25, %f23, %f19, %f24;
	selp.f32 	%f26, 0fBEFFFFFF, 0fBE2AAAA8, %p7;
	fma.rn.f32 	%f27, %f25, %f19, %f26;
	fma.rn.f32 	%f28, %f27, %f21, %f20;
	and.b32  	%r56, %r64, 2;
	setp.eq.s32 	%p8, %r56, 0;
	sub.rn.f32 	%f30, %f70, %f28;
	selp.f32 	%f31, %f28, %f30, %p8;
	shl.b64 	%rd34, %rd5, 2;
	add.s64 	%rd35, %rd1, %rd34;
	ld.global.nc.f32 	%f32, [%rd35];
	fma.rn.f32 	%f33, %f32, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f34, %f33;
	mov.f32 	%f35, 0f4B400001;
	mov.f32 	%f36, 0f437C0000;
	fma.rm.f32 	%f37, %f34, %f36, %f35;
	add.rn.f32 	%f38, %f37, 0fCB40007F;
	neg.f32 	%f39, %f38;
	fma.rn.f32 	%f40, %f32, 0f3FB8AA3B, %f39;
	fma.rn.f32 	%f41, %f32, 0f32A57060, %f40;
	mov.b32 	%r57, %f37;
	shl.b32 	%r58, %r57, 23;
	mov.b32 	%f42, %r58;
	ex2.approx.ftz.f32 	%f43, %f41;
	mul.rn.f32 	%f44, %f43, %f42;
	neg.f32 	%f45, %f44;
	sub.rn.f32 	%f46, %f45, %f44;
	add.rn.f32 	%f47, %f46, %f46;
	add.rn.f32 	%f48, %f47, %f47;
	add.rn.f32 	%f49, %f48, %f48;
	add.rn.f32 	%f50, %f49, %f49;
	add.rn.f32 	%f51, %f50, %f50;
	add.rn.f32 	%f52, %f51, %f51;
	add.rn.f32 	%f53, %f52, %f52;
	add.rn.f32 	%f54, %f53, %f53;
	fma.rn.f32 	%f55, %f54, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f56, %f55;
	fma.rm.f32 	%f57, %f56, %f36, %f35;
	add.rn.f32 	%f58, %f57, 0fCB40007F;
	neg.f32 	%f59, %f58;
	fma.rn.f32 	%f60, %f54, 0f3FB8AA3B, %f59;
	fma.rn.f32 	%f61, %f54, 0f32A57060, %f60;
	mov.b32 	%r59, %f57;
	shl.b32 	%r60, %r59, 23;
	mov.b32 	%f62, %r60;
	ex2.approx.ftz.f32 	%f63, %f61;
	mul.rn.f32 	%f64, %f63, %f62;
	mul.lo.s64 	%rd36, %rd5, 2400;
	add.s64 	%rd37, %rd2, %rd36;
	mul.wide.u32 	%rd38, %r54, 48;
	add.s64 	%rd39, %rd37, %rd38;
	mul.wide.u32 	%rd40, %r53, 4;
	add.s64 	%rd41, %rd39, %rd40;
	ld.global.nc.f32 	%f65, [%rd41+28];
	mul.rn.f32 	%f66, %f65, %f64;
	mul.rn.f32 	%f67, %f31, %f66;
	ld.global.f32 	%f68, [%rd33];
	add.rn.f32 	%f69, %f68, %f67;
	st.global.f32 	[%rd33], %f69;
	ret;

}
	// .globl	loop_add_multiply_fusion_18
.visible .entry loop_add_multiply_fusion_18(
	.param .u64 loop_add_multiply_fusion_18_param_0,
	.param .u64 loop_add_multiply_fusion_18_param_1,
	.param .u64 loop_add_multiply_fusion_18_param_2,
	.param .u64 loop_add_multiply_fusion_18_param_3,
	.param .u64 loop_add_multiply_fusion_18_param_4,
	.param .u64 loop_add_multiply_fusion_18_param_5,
	.param .u64 loop_add_multiply_fusion_18_param_6,
	.param .u64 loop_add_multiply_fusion_18_param_7,
	.param .u64 loop_add_multiply_fusion_18_param_8,
	.param .u64 loop_add_multiply_fusion_18_param_9,
	.param .u64 loop_add_multiply_fusion_18_param_10
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot161[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<29>;
	.reg .b16 	%rs<17>;
	.reg .b32 	%r<176>;
	.reg .f32 	%f<159>;
	.reg .b64 	%rd<128>;
	.reg .f64 	%fd<7>;

	mov.u64 	%SPL, __local_depot161;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd30, [loop_add_multiply_fusion_18_param_1];
	ld.param.u64 	%rd34, [loop_add_multiply_fusion_18_param_3];
	ld.param.u64 	%rd36, [loop_add_multiply_fusion_18_param_4];
	cvta.to.global.u64 	%rd7, %rd36;
	cvta.to.global.u64 	%rd39, %rd30;
	add.u64 	%rd40, %SP, 0;
	mov.u32 	%r50, %ctaid.x;
	mov.u32 	%r51, %tid.x;
	shl.b32 	%r52, %r50, 7;
	or.b32  	%r1, %r52, %r51;
	cvt.u16.u32 	%rs2, %r1;
	mul.hi.u16 	%rs3, %rs2, -21845;
	shr.u16 	%rs4, %rs3, 2;
	mul.lo.s16 	%rs5, %rs4, 6;
	sub.s16 	%rs6, %rs2, %rs5;
	cvt.u32.u16 	%r2, %rs6;
	and.b16  	%rs1, %rs4, 1;
	shr.u16 	%rs7, %rs3, 3;
	mul.hi.u16 	%rs8, %rs7, 5243;
	shr.u16 	%rs9, %rs8, 2;
	mul.lo.s16 	%rs10, %rs9, 50;
	sub.s16 	%rs11, %rs7, %rs10;
	shr.u16 	%rs12, %rs2, 3;
	mul.hi.u16 	%rs13, %rs12, 6991;
	shr.u16 	%rs14, %rs13, 3;
	and.b16  	%rs15, %rs14, 63;
	cvt.u64.u16 	%rd14, %rs15;
	cvt.u32.u16 	%r53, %rs15;
	mul.wide.u32 	%rd43, %r53, 4;
	add.s64 	%rd44, %rd39, %rd43;
	ld.global.nc.f32 	%f26, [%rd44];
	fma.rn.f32 	%f27, %f26, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f28, %f27;
	mov.f32 	%f29, 0f4B400001;
	mov.f32 	%f30, 0f437C0000;
	fma.rm.f32 	%f31, %f28, %f30, %f29;
	add.rn.f32 	%f32, %f31, 0fCB40007F;
	neg.f32 	%f33, %f32;
	fma.rn.f32 	%f34, %f26, 0f3FB8AA3B, %f33;
	fma.rn.f32 	%f35, %f26, 0f32A57060, %f34;
	mov.b32 	%r54, %f31;
	shl.b32 	%r55, %r54, 23;
	mov.b32 	%f36, %r55;
	ex2.approx.ftz.f32 	%f37, %f35;
	mul.rn.f32 	%f38, %f37, %f36;
	neg.f32 	%f39, %f38;
	sub.rn.f32 	%f40, %f39, %f38;
	add.rn.f32 	%f41, %f40, %f40;
	add.rn.f32 	%f42, %f41, %f41;
	add.rn.f32 	%f43, %f42, %f42;
	add.rn.f32 	%f44, %f43, %f43;
	add.rn.f32 	%f45, %f44, %f44;
	add.rn.f32 	%f46, %f45, %f45;
	setp.eq.b16 	%p1, %rs1, 1;
	cvt.u64.u16 	%rd15, %rs11;
	cvt.u64.u16 	%rd16, %rs6;
	mov.f32 	%f155, 0f00000000;
	mov.f32 	%f153, %f155;
	@%p1 bra 	$L__BB161_20;
	bra.uni 	$L__BB161_1;
$L__BB161_20:
	cvt.u32.u16 	%r56, %rs11;
	mul.wide.u32 	%rd45, %r56, 48;
	mul.wide.u32 	%rd46, %r53, 2400;
	add.s64 	%rd47, %rd7, %rd46;
	add.s64 	%rd48, %rd47, %rd45;
	cvt.u32.u16 	%r57, %rs1;
	mul.wide.u32 	%rd49, %r57, 24;
	add.s64 	%rd50, %rd48, %rd49;
	mul.wide.u32 	%rd51, %r2, 4;
	add.s64 	%rd17, %rd50, %rd51;
	ld.global.nc.f32 	%f153, [%rd17];
$L__BB161_1:
	ld.param.u64 	%rd28, [loop_add_multiply_fusion_18_param_0];
	cvta.to.global.u64 	%rd8, %rd34;
	cvta.to.local.u64 	%rd11, %rd40;
	add.rn.f32 	%f1, %f46, %f46;
	setp.eq.s16 	%p2, %rs1, 0;
	shl.b64 	%rd121, %rd16, 2;
	shr.u32 	%r163, %r2, 1;
	mul.lo.s64 	%rd122, %rd14, 12;
	mul.lo.s64 	%rd123, %rd14, 2400;
	mul.lo.s64 	%rd124, %rd15, 48;
	mov.f32 	%f154, %f155;
	@%p2 bra 	$L__BB161_21;
	bra.uni 	$L__BB161_2;
$L__BB161_21:
	ld.param.u64 	%rd37, [loop_add_multiply_fusion_18_param_6];
	ld.param.u64 	%rd38, [loop_add_multiply_fusion_18_param_5];
	cvta.to.global.u64 	%rd5, %rd37;
	cvta.to.global.u64 	%rd6, %rd38;
	mul.lo.s64 	%rd52, %rd14, 1200;
	add.s64 	%rd53, %rd6, %rd52;
	mul.lo.s64 	%rd54, %rd15, 24;
	add.s64 	%rd55, %rd53, %rd54;
	add.s64 	%rd57, %rd55, %rd121;
	ld.global.nc.f32 	%f48, [%rd57];
	add.s64 	%rd58, %rd5, %rd52;
	add.s64 	%rd59, %rd58, %rd54;
	add.s64 	%rd60, %rd59, %rd121;
	ld.global.nc.f32 	%f49, [%rd60];
	add.rn.f32 	%f16, %f48, %f49;
	add.s64 	%rd62, %rd8, %rd122;
	mul.wide.u32 	%rd63, %r163, 4;
	add.s64 	%rd64, %rd62, %rd63;
	ld.global.nc.f32 	%f50, [%rd64];
	add.rn.f32 	%f51, %f50, %f50;
	add.rn.f32 	%f52, %f51, %f51;
	add.rn.f32 	%f53, %f52, %f52;
	add.rn.f32 	%f54, %f53, %f53;
	add.rn.f32 	%f17, %f54, %f54;
	mul.rn.f32 	%f55, %f17, 0f3F22F983;
	cvt.rni.s32.f32 	%r175, %f55;
	cvt.rn.f32.s32 	%f56, %r175;
	fma.rn.f32 	%f57, %f56, 0fBFC90FDA, %f17;
	fma.rn.f32 	%f58, %f56, 0fB3A22168, %f57;
	fma.rn.f32 	%f158, %f56, 0fA7C234C5, %f58;
	abs.f32 	%f19, %f17;
	setp.ltu.f32 	%p3, %f19, 0f47CE4780;
	@%p3 bra 	$L__BB161_29;
	setp.neu.f32 	%p4, %f19, 0f7F800000;
	@%p4 bra 	$L__BB161_24;
	mov.f32 	%f61, 0f00000000;
	mul.rn.f32 	%f158, %f17, %f61;
	mov.b32 	%r175, 0;
	bra.uni 	$L__BB161_29;
$L__BB161_24:
	mov.b32 	%r35, %f17;
	shr.u32 	%r36, %r35, 23;
	and.b32  	%r60, %r36, 224;
	add.s32 	%r61, %r60, -128;
	shl.b32 	%r62, %r35, 8;
	or.b32  	%r66, %r62, -2147483648;
	shr.u32 	%r38, %r61, 5;
	mov.b32 	%r172, 0;
	mov.u64 	%rd127, 0;
	mov.u64 	%rd66, __cudart_i2opi_f;
$L__BB161_25:
	.pragma "nounroll";
	add.s64 	%rd67, %rd66, %rd127;
	ld.global.nc.u32 	%r65, [%rd67];
	// begin inline asm
	{
	mad.lo.cc.u32   %r63, %r65, %r66, %r172;
	madc.hi.u32     %r172, %r65, %r66,  0;
	}
	// end inline asm
	add.s64 	%rd68, %rd11, %rd127;
	st.local.u32 	[%rd68], %r63;
	add.s64 	%rd127, %rd127, 4;
	cvt.u32.u64 	%r68, %rd127;
	setp.ne.s32 	%p5, %r68, 24;
	@%p5 bra 	$L__BB161_25;
	st.local.u32 	[%rd11+24], %r172;
	and.b32  	%r41, %r36, 31;
	mul.wide.u32 	%rd69, %r38, 4;
	sub.s64 	%rd27, %rd11, %rd69;
	ld.local.u32 	%r173, [%rd27+24];
	ld.local.u32 	%r174, [%rd27+20];
	setp.eq.s32 	%p6, %r41, 0;
	@%p6 bra 	$L__BB161_28;
	shl.b32 	%r69, %r174, %r41;
	shl.b32 	%r70, %r173, %r41;
	mov.b32 	%r71, 32;
	sub.s32 	%r72, %r71, %r41;
	shr.u32 	%r73, %r174, %r72;
	add.s32 	%r173, %r73, %r70;
	ld.local.u32 	%r74, [%rd27+16];
	shr.u32 	%r75, %r74, %r72;
	add.s32 	%r174, %r75, %r69;
$L__BB161_28:
	shr.u32 	%r76, %r173, 30;
	shr.u32 	%r77, %r174, 30;
	shl.b32 	%r78, %r173, 2;
	or.b32  	%r79, %r78, %r77;
	shl.b32 	%r80, %r174, 2;
	bfe.u32 	%r81, %r173, 29, 1;
	add.s32 	%r82, %r81, %r76;
	neg.s32 	%r83, %r82;
	setp.lt.s32 	%p7, %r35, 0;
	selp.b32 	%r175, %r83, %r82, %p7;
	xor.b32  	%r84, %r79, %r35;
	bfe.s32 	%r85, %r173, 29, 1;
	xor.b32  	%r86, %r85, %r79;
	xor.b32  	%r87, %r85, %r80;
	cvt.u64.u32 	%rd70, %r86;
	shl.b64 	%rd71, %rd70, 32;
	cvt.u64.u32 	%rd72, %r87;
	or.b64  	%rd73, %rd71, %rd72;
	cvt.rn.f64.s64 	%fd1, %rd73;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f59, %fd2;
	neg.f32 	%f60, %f59;
	setp.lt.s32 	%p8, %r84, 0;
	selp.f32 	%f158, %f60, %f59, %p8;
$L__BB161_29:
	add.s32 	%r89, %r175, 1;
	mul.rn.f32 	%f62, %f158, %f158;
	and.b32  	%r90, %r175, 1;
	setp.eq.b32 	%p9, %r90, 1;
	selp.f32 	%f63, %f158, 0f3F800000, %p9;
	fma.rn.f32 	%f64, %f62, %f63, 0f00000000;
	fma.rn.f32 	%f65, %f62, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f66, 0fB94D4153, %f65, %p9;
	selp.f32 	%f67, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f68, %f66, %f62, %f67;
	selp.f32 	%f69, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f70, %f68, %f62, %f69;
	fma.rn.f32 	%f71, %f70, %f64, %f63;
	and.b32  	%r91, %r89, 2;
	setp.eq.s32 	%p10, %r91, 0;
	mov.f32 	%f72, 0f00000000;
	sub.rn.f32 	%f73, %f72, %f71;
	selp.f32 	%f74, %f71, %f73, %p10;
	add.rn.f32 	%f75, %f1, %f1;
	fma.rn.f32 	%f76, %f75, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f77, %f76;
	fma.rm.f32 	%f80, %f77, %f30, %f29;
	add.rn.f32 	%f81, %f80, 0fCB40007F;
	neg.f32 	%f82, %f81;
	fma.rn.f32 	%f83, %f75, 0f3FB8AA3B, %f82;
	fma.rn.f32 	%f84, %f75, 0f32A57060, %f83;
	mov.b32 	%r92, %f80;
	shl.b32 	%r93, %r92, 23;
	mov.b32 	%f85, %r93;
	ex2.approx.ftz.f32 	%f86, %f84;
	mul.rn.f32 	%f87, %f86, %f85;
	add.s64 	%rd75, %rd7, %rd123;
	add.s64 	%rd77, %rd75, %rd124;
	add.s64 	%rd79, %rd77, %rd121;
	ld.global.nc.f32 	%f88, [%rd79+24];
	mul.rn.f32 	%f89, %f87, %f88;
	mul.rn.f32 	%f90, %f89, %f74;
	add.rn.f32 	%f154, %f16, %f90;
$L__BB161_2:
	cvta.to.global.u64 	%rd10, %rd28;
	@%p2 bra 	$L__BB161_30;
	bra.uni 	$L__BB161_3;
$L__BB161_30:
	add.s64 	%rd81, %rd7, %rd123;
	add.s64 	%rd83, %rd81, %rd124;
	add.s64 	%rd18, %rd83, %rd121;
	ld.global.nc.f32 	%f155, [%rd18];
$L__BB161_3:
	ld.param.u64 	%rd29, [loop_add_multiply_fusion_18_param_10];
	ld.param.u64 	%rd31, [loop_add_multiply_fusion_18_param_9];
	ld.param.u64 	%rd32, [loop_add_multiply_fusion_18_param_2];
	ld.param.u64 	%rd33, [loop_add_multiply_fusion_18_param_8];
	ld.param.u64 	%rd35, [loop_add_multiply_fusion_18_param_7];
	shl.b16 	%rs16, %rs1, 1;
	mul.lo.s64 	%rd85, %rd14, 4800;
	add.s64 	%rd86, %rd10, %rd85;
	mul.lo.s64 	%rd87, %rd15, 96;
	add.s64 	%rd88, %rd86, %rd87;
	cvt.u32.u16 	%r94, %rs16;
	mul.wide.u32 	%rd89, %r94, 24;
	add.s64 	%rd90, %rd88, %rd89;
	add.s64 	%rd92, %rd90, %rd121;
	ld.global.nc.f32 	%f5, [%rd92];
	add.s64 	%rd94, %rd8, %rd122;
	mul.wide.u32 	%rd95, %r163, 4;
	add.s64 	%rd96, %rd94, %rd95;
	ld.global.nc.f32 	%f92, [%rd96];
	add.rn.f32 	%f93, %f92, %f92;
	add.rn.f32 	%f94, %f93, %f93;
	add.rn.f32 	%f95, %f94, %f94;
	add.rn.f32 	%f6, %f95, %f95;
	mul.rn.f32 	%f96, %f6, 0f3F22F983;
	cvt.rni.s32.f32 	%r171, %f96;
	cvt.rn.f32.s32 	%f97, %r171;
	fma.rn.f32 	%f98, %f97, 0fBFC90FDA, %f6;
	fma.rn.f32 	%f99, %f97, 0fB3A22168, %f98;
	fma.rn.f32 	%f157, %f97, 0fA7C234C5, %f99;
	abs.f32 	%f8, %f6;
	setp.ltu.f32 	%p12, %f8, 0f47CE4780;
	setp.neu.f32 	%p28, %f8, 0f7F800000;
	mov.u32 	%r167, %r171;
	mov.f32 	%f156, %f157;
	@%p12 bra 	$L__BB161_11;
	@%p28 bra 	$L__BB161_6;
	mov.f32 	%f102, 0f00000000;
	mul.rn.f32 	%f156, %f6, %f102;
	mov.b32 	%r167, 0;
	bra.uni 	$L__BB161_11;
$L__BB161_6:
	mov.b32 	%r4, %f6;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r97, %r5, 224;
	add.s32 	%r98, %r97, -128;
	shl.b32 	%r99, %r4, 8;
	or.b32  	%r103, %r99, -2147483648;
	shr.u32 	%r7, %r98, 5;
	mov.b32 	%r164, 0;
	mov.u64 	%rd125, 0;
	mov.u64 	%rd98, __cudart_i2opi_f;
$L__BB161_7:
	.pragma "nounroll";
	add.s64 	%rd99, %rd98, %rd125;
	ld.global.nc.u32 	%r102, [%rd99];
	// begin inline asm
	{
	mad.lo.cc.u32   %r100, %r102, %r103, %r164;
	madc.hi.u32     %r164, %r102, %r103,  0;
	}
	// end inline asm
	add.s64 	%rd100, %rd11, %rd125;
	st.local.u32 	[%rd100], %r100;
	add.s64 	%rd125, %rd125, 4;
	cvt.u32.u64 	%r105, %rd125;
	setp.ne.s32 	%p14, %r105, 24;
	@%p14 bra 	$L__BB161_7;
	st.local.u32 	[%rd11+24], %r164;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd101, %r7, 4;
	sub.s64 	%rd21, %rd11, %rd101;
	ld.local.u32 	%r165, [%rd21+24];
	ld.local.u32 	%r166, [%rd21+20];
	setp.eq.s32 	%p15, %r10, 0;
	@%p15 bra 	$L__BB161_10;
	shl.b32 	%r106, %r166, %r10;
	shl.b32 	%r107, %r165, %r10;
	mov.b32 	%r108, 32;
	sub.s32 	%r109, %r108, %r10;
	shr.u32 	%r110, %r166, %r109;
	add.s32 	%r165, %r110, %r107;
	ld.local.u32 	%r111, [%rd21+16];
	shr.u32 	%r112, %r111, %r109;
	add.s32 	%r166, %r112, %r106;
$L__BB161_10:
	shr.u32 	%r113, %r165, 30;
	shr.u32 	%r114, %r166, 30;
	shl.b32 	%r115, %r165, 2;
	or.b32  	%r116, %r115, %r114;
	shl.b32 	%r117, %r166, 2;
	bfe.u32 	%r118, %r165, 29, 1;
	add.s32 	%r119, %r118, %r113;
	neg.s32 	%r120, %r119;
	setp.lt.s32 	%p16, %r4, 0;
	selp.b32 	%r167, %r120, %r119, %p16;
	xor.b32  	%r121, %r116, %r4;
	bfe.s32 	%r122, %r165, 29, 1;
	xor.b32  	%r123, %r122, %r116;
	xor.b32  	%r124, %r122, %r117;
	cvt.u64.u32 	%rd102, %r123;
	shl.b64 	%rd103, %rd102, 32;
	cvt.u64.u32 	%rd104, %r124;
	or.b64  	%rd105, %rd103, %rd104;
	cvt.rn.f64.s64 	%fd3, %rd105;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f100, %fd4;
	neg.f32 	%f101, %f100;
	setp.lt.s32 	%p17, %r121, 0;
	selp.f32 	%f156, %f101, %f100, %p17;
$L__BB161_11:
	cvta.to.global.u64 	%rd1, %rd29;
	cvta.to.global.u64 	%rd2, %rd31;
	cvta.to.global.u64 	%rd3, %rd33;
	cvta.to.global.u64 	%rd4, %rd35;
	cvta.to.global.u64 	%rd9, %rd32;
	@%p12 bra 	$L__BB161_19;
	@%p28 bra 	$L__BB161_14;
	mov.f32 	%f105, 0f00000000;
	mul.rn.f32 	%f157, %f6, %f105;
	mov.b32 	%r171, 0;
	bra.uni 	$L__BB161_19;
$L__BB161_14:
	mov.b32 	%r19, %f6;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r127, %r20, 224;
	add.s32 	%r128, %r127, -128;
	shl.b32 	%r129, %r19, 8;
	or.b32  	%r133, %r129, -2147483648;
	shr.u32 	%r22, %r128, 5;
	mov.b32 	%r168, 0;
	mov.u64 	%rd126, 0;
	mov.u64 	%rd107, __cudart_i2opi_f;
$L__BB161_15:
	.pragma "nounroll";
	add.s64 	%rd108, %rd107, %rd126;
	ld.global.nc.u32 	%r132, [%rd108];
	// begin inline asm
	{
	mad.lo.cc.u32   %r130, %r132, %r133, %r168;
	madc.hi.u32     %r168, %r132, %r133,  0;
	}
	// end inline asm
	add.s64 	%rd109, %rd11, %rd126;
	st.local.u32 	[%rd109], %r130;
	add.s64 	%rd126, %rd126, 4;
	cvt.u32.u64 	%r135, %rd126;
	setp.ne.s32 	%p20, %r135, 24;
	@%p20 bra 	$L__BB161_15;
	st.local.u32 	[%rd11+24], %r168;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd110, %r22, 4;
	sub.s64 	%rd24, %rd11, %rd110;
	ld.local.u32 	%r169, [%rd24+24];
	ld.local.u32 	%r170, [%rd24+20];
	setp.eq.s32 	%p21, %r25, 0;
	@%p21 bra 	$L__BB161_18;
	shl.b32 	%r136, %r170, %r25;
	shl.b32 	%r137, %r169, %r25;
	mov.b32 	%r138, 32;
	sub.s32 	%r139, %r138, %r25;
	shr.u32 	%r140, %r170, %r139;
	add.s32 	%r169, %r140, %r137;
	ld.local.u32 	%r141, [%rd24+16];
	shr.u32 	%r142, %r141, %r139;
	add.s32 	%r170, %r142, %r136;
$L__BB161_18:
	shr.u32 	%r143, %r169, 30;
	shr.u32 	%r144, %r170, 30;
	shl.b32 	%r145, %r169, 2;
	or.b32  	%r146, %r145, %r144;
	shl.b32 	%r147, %r170, 2;
	bfe.u32 	%r148, %r169, 29, 1;
	add.s32 	%r149, %r148, %r143;
	neg.s32 	%r150, %r149;
	setp.lt.s32 	%p22, %r19, 0;
	selp.b32 	%r171, %r150, %r149, %p22;
	xor.b32  	%r151, %r146, %r19;
	bfe.s32 	%r152, %r169, 29, 1;
	xor.b32  	%r153, %r152, %r146;
	xor.b32  	%r154, %r152, %r147;
	cvt.u64.u32 	%rd111, %r153;
	shl.b64 	%rd112, %rd111, 32;
	cvt.u64.u32 	%rd113, %r154;
	or.b64  	%rd114, %rd112, %rd113;
	cvt.rn.f64.s64 	%fd5, %rd114;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f103, %fd6;
	neg.f32 	%f104, %f103;
	setp.lt.s32 	%p23, %r151, 0;
	selp.f32 	%f157, %f104, %f103, %p23;
$L__BB161_19:
	add.s32 	%r156, %r167, 1;
	and.b32  	%r157, %r156, 2;
	setp.eq.s32 	%p24, %r157, 0;
	and.b32  	%r158, %r167, 1;
	setp.eq.b32 	%p25, %r158, 1;
	mul.rn.f32 	%f106, %f156, %f156;
	fma.rn.f32 	%f107, %f106, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f108, 0fB94D4153, %f107, %p25;
	selp.f32 	%f109, 0f3C0885E4, 0f3D2AAABB, %p25;
	fma.rn.f32 	%f110, %f108, %f106, %f109;
	selp.f32 	%f111, 0fBE2AAAA8, 0fBEFFFFFF, %p25;
	fma.rn.f32 	%f112, %f110, %f106, %f111;
	selp.f32 	%f113, %f156, 0f3F800000, %p25;
	fma.rn.f32 	%f114, %f106, %f113, 0f00000000;
	fma.rn.f32 	%f115, %f112, %f114, %f113;
	mov.f32 	%f116, 0f00000000;
	sub.rn.f32 	%f117, %f116, %f115;
	selp.f32 	%f118, %f115, %f117, %p24;
	mul.rn.f32 	%f119, %f5, %f118;
	fma.rn.f32 	%f120, %f1, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f121, %f120;
	fma.rm.f32 	%f124, %f121, %f30, %f29;
	add.rn.f32 	%f125, %f124, 0fCB40007F;
	neg.f32 	%f126, %f125;
	fma.rn.f32 	%f127, %f1, 0f3FB8AA3B, %f126;
	fma.rn.f32 	%f128, %f1, 0f32A57060, %f127;
	ex2.approx.ftz.f32 	%f129, %f128;
	mov.b32 	%r159, %f124;
	shl.b32 	%r160, %r159, 23;
	mov.b32 	%f130, %r160;
	mul.rn.f32 	%f131, %f129, %f130;
	add.rn.f32 	%f132, %f153, %f154;
	add.rn.f32 	%f133, %f132, %f155;
	mul.rn.f32 	%f134, %f133, %f131;
	mul.rn.f32 	%f135, %f5, %f134;
	mul.rn.f32 	%f136, %f157, %f157;
	and.b32  	%r161, %r171, 1;
	setp.eq.b32 	%p26, %r161, 1;
	selp.f32 	%f137, 0f3F800000, %f157, %p26;
	fma.rn.f32 	%f138, %f136, %f137, 0f00000000;
	fma.rn.f32 	%f139, %f136, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f140, %f139, 0fB94D4153, %p26;
	selp.f32 	%f141, 0f3D2AAABB, 0f3C0885E4, %p26;
	fma.rn.f32 	%f142, %f140, %f136, %f141;
	selp.f32 	%f143, 0fBEFFFFFF, 0fBE2AAAA8, %p26;
	fma.rn.f32 	%f144, %f142, %f136, %f143;
	fma.rn.f32 	%f145, %f144, %f138, %f137;
	and.b32  	%r162, %r171, 2;
	setp.eq.s32 	%p27, %r162, 0;
	sub.rn.f32 	%f146, %f116, %f145;
	selp.f32 	%f147, %f145, %f146, %p27;
	mul.wide.u32 	%rd115, %r1, 4;
	add.s64 	%rd116, %rd9, %rd115;
	ld.global.nc.f32 	%f148, [%rd116];
	mul.rn.f32 	%f149, %f148, %f147;
	add.rn.f32 	%f150, %f119, %f149;
	mul.rn.f32 	%f151, %f133, %f150;
	mul.rn.f32 	%f152, %f134, %f148;
	add.s64 	%rd117, %rd4, %rd115;
	st.global.f32 	[%rd117], %f135;
	add.s64 	%rd118, %rd3, %rd115;
	st.global.f32 	[%rd118], %f151;
	add.s64 	%rd119, %rd2, %rd115;
	st.global.f32 	[%rd119], %f152;
	add.s64 	%rd120, %rd1, %rd115;
	st.global.f32 	[%rd120], %f133;
	ret;

}
	// .globl	loop_multiply_transpose_fusion_6
.visible .entry loop_multiply_transpose_fusion_6(
	.param .u64 loop_multiply_transpose_fusion_6_param_0,
	.param .u64 loop_multiply_transpose_fusion_6_param_1,
	.param .u64 loop_multiply_transpose_fusion_6_param_2,
	.param .u64 loop_multiply_transpose_fusion_6_param_3,
	.param .u64 loop_multiply_transpose_fusion_6_param_4,
	.param .u64 loop_multiply_transpose_fusion_6_param_5,
	.param .u64 loop_multiply_transpose_fusion_6_param_6,
	.param .u64 loop_multiply_transpose_fusion_6_param_7,
	.param .u64 loop_multiply_transpose_fusion_6_param_8,
	.param .u64 loop_multiply_transpose_fusion_6_param_9,
	.param .u64 loop_multiply_transpose_fusion_6_param_10,
	.param .u64 loop_multiply_transpose_fusion_6_param_11
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot162[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<35>;
	.reg .b16 	%rs<18>;
	.reg .b32 	%r<246>;
	.reg .f32 	%f<196>;
	.reg .b64 	%rd<142>;
	.reg .f64 	%fd<9>;

	mov.u64 	%SPL, __local_depot162;
	ld.param.u64 	%rd36, [loop_multiply_transpose_fusion_6_param_0];
	ld.param.u64 	%rd38, [loop_multiply_transpose_fusion_6_param_1];
	ld.param.u64 	%rd40, [loop_multiply_transpose_fusion_6_param_2];
	ld.param.u64 	%rd46, [loop_multiply_transpose_fusion_6_param_5];
	cvta.to.global.u64 	%rd10, %rd40;
	cvta.to.global.u64 	%rd11, %rd38;
	cvta.to.global.u64 	%rd12, %rd36;
	add.u64 	%rd13, %SPL, 0;
	mov.u32 	%r67, %ctaid.x;
	shl.b32 	%r68, %r67, 7;
	mov.u32 	%r69, %tid.x;
	or.b32  	%r1, %r68, %r69;
	cvt.u16.u32 	%rs3, %r67;
	and.b16  	%rs4, %rs3, 255;
	mul.lo.s16 	%rs5, %rs4, 41;
	shr.u16 	%rs6, %rs5, 11;
	cvt.u32.u16 	%r2, %rs6;
	cvt.u16.u32 	%rs7, %r1;
	shr.u16 	%rs8, %rs7, 2;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	and.b16  	%rs1, %rs10, 63;
	shr.u32 	%r70, %r1, 1;
	cvt.u16.u32 	%rs11, %r70;
	shr.u16 	%rs12, %rs11, 1;
	mul.hi.u16 	%rs13, %rs12, 5243;
	shr.u16 	%rs14, %rs13, 1;
	mul.lo.s16 	%rs15, %rs14, 50;
	sub.s16 	%rs2, %rs11, %rs15;
	and.b32  	%r3, %r69, 1;
	mul.wide.u16 	%r4, %rs6, 2;
	cvt.u64.u16 	%rd17, %rs1;
	cvt.u32.u16 	%r71, %rs1;
	mul.wide.u32 	%rd52, %r71, 12;
	add.s64 	%rd53, %rd10, %rd52;
	mul.wide.u32 	%rd54, %r2, 4;
	add.s64 	%rd55, %rd53, %rd54;
	ld.global.nc.f32 	%f25, [%rd55];
	add.rn.f32 	%f26, %f25, %f25;
	add.rn.f32 	%f27, %f26, %f26;
	add.rn.f32 	%f28, %f27, %f27;
	add.rn.f32 	%f1, %f28, %f28;
	mul.rn.f32 	%f29, %f1, 0f3F22F983;
	cvt.rni.s32.f32 	%r237, %f29;
	cvt.rn.f32.s32 	%f30, %r237;
	fma.rn.f32 	%f31, %f30, 0fBFC90FDA, %f1;
	fma.rn.f32 	%f32, %f30, 0fB3A22168, %f31;
	fma.rn.f32 	%f193, %f30, 0fA7C234C5, %f32;
	abs.f32 	%f3, %f1;
	setp.ltu.f32 	%p1, %f3, 0f47CE4780;
	setp.neu.f32 	%p33, %f3, 0f7F800000;
	mov.f32 	%f191, 0f00000000;
	mov.u32 	%r233, %r237;
	mov.f32 	%f192, %f193;
	@%p1 bra 	$L__BB162_8;
	@%p33 bra 	$L__BB162_3;
	mul.rn.f32 	%f192, %f1, %f191;
	mov.b32 	%r233, 0;
	bra.uni 	$L__BB162_8;
$L__BB162_3:
	mov.b32 	%r6, %f1;
	shr.u32 	%r7, %r6, 23;
	and.b32  	%r73, %r7, 224;
	add.s32 	%r74, %r73, -128;
	shl.b32 	%r75, %r6, 8;
	or.b32  	%r79, %r75, -2147483648;
	shr.u32 	%r9, %r74, 5;
	mov.b32 	%r230, 0;
	mov.u64 	%rd138, 0;
	mov.u64 	%rd57, __cudart_i2opi_f;
$L__BB162_4:
	.pragma "nounroll";
	add.s64 	%rd58, %rd57, %rd138;
	ld.global.nc.u32 	%r78, [%rd58];
	// begin inline asm
	{
	mad.lo.cc.u32   %r76, %r78, %r79, %r230;
	madc.hi.u32     %r230, %r78, %r79,  0;
	}
	// end inline asm
	add.s64 	%rd59, %rd13, %rd138;
	st.local.u32 	[%rd59], %r76;
	add.s64 	%rd138, %rd138, 4;
	cvt.u32.u64 	%r81, %rd138;
	setp.ne.s32 	%p3, %r81, 24;
	@%p3 bra 	$L__BB162_4;
	st.local.u32 	[%rd13+24], %r230;
	and.b32  	%r12, %r7, 31;
	mul.wide.u32 	%rd60, %r9, 4;
	sub.s64 	%rd20, %rd13, %rd60;
	ld.local.u32 	%r231, [%rd20+24];
	ld.local.u32 	%r232, [%rd20+20];
	setp.eq.s32 	%p4, %r12, 0;
	@%p4 bra 	$L__BB162_7;
	shl.b32 	%r82, %r232, %r12;
	shl.b32 	%r83, %r231, %r12;
	mov.b32 	%r84, 32;
	sub.s32 	%r85, %r84, %r12;
	shr.u32 	%r86, %r232, %r85;
	add.s32 	%r231, %r86, %r83;
	ld.local.u32 	%r87, [%rd20+16];
	shr.u32 	%r88, %r87, %r85;
	add.s32 	%r232, %r88, %r82;
$L__BB162_7:
	shr.u32 	%r89, %r231, 30;
	shr.u32 	%r90, %r232, 30;
	shl.b32 	%r91, %r231, 2;
	or.b32  	%r92, %r91, %r90;
	shl.b32 	%r93, %r232, 2;
	bfe.u32 	%r94, %r231, 29, 1;
	add.s32 	%r95, %r94, %r89;
	neg.s32 	%r96, %r95;
	setp.lt.s32 	%p5, %r6, 0;
	selp.b32 	%r233, %r96, %r95, %p5;
	xor.b32  	%r97, %r92, %r6;
	bfe.s32 	%r98, %r231, 29, 1;
	xor.b32  	%r99, %r98, %r92;
	xor.b32  	%r100, %r98, %r93;
	cvt.u64.u32 	%rd61, %r99;
	shl.b64 	%rd62, %rd61, 32;
	cvt.u64.u32 	%rd63, %r100;
	or.b64  	%rd64, %rd62, %rd63;
	cvt.rn.f64.s64 	%fd1, %rd64;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f33, %fd2;
	neg.f32 	%f34, %f33;
	setp.lt.s32 	%p6, %r97, 0;
	selp.f32 	%f192, %f34, %f33, %p6;
$L__BB162_8:
	ld.param.u64 	%rd42, [loop_multiply_transpose_fusion_6_param_3];
	cvta.to.global.u64 	%rd7, %rd46;
	shl.b64 	%rd65, %rd17, 2;
	add.s64 	%rd66, %rd11, %rd65;
	ld.global.nc.f32 	%f7, [%rd66];
	mul.lo.s64 	%rd67, %rd17, 2400;
	add.s64 	%rd68, %rd12, %rd67;
	cvt.u32.u16 	%r102, %rs2;
	mul.wide.u32 	%rd69, %r102, 48;
	add.s64 	%rd70, %rd68, %rd69;
	mul.wide.u32 	%rd71, %r3, 24;
	add.s64 	%rd72, %rd70, %rd71;
	mul.wide.u32 	%rd73, %r4, 4;
	add.s64 	%rd21, %rd72, %rd73;
	ld.global.nc.f32 	%f8, [%rd21+4];
	@%p1 bra 	$L__BB162_16;
	@%p33 bra 	$L__BB162_11;
	mul.rn.f32 	%f193, %f1, %f191;
	mov.b32 	%r237, 0;
	bra.uni 	$L__BB162_16;
$L__BB162_11:
	mov.b32 	%r21, %f1;
	shr.u32 	%r22, %r21, 23;
	and.b32  	%r104, %r22, 224;
	add.s32 	%r105, %r104, -128;
	shl.b32 	%r106, %r21, 8;
	or.b32  	%r110, %r106, -2147483648;
	shr.u32 	%r24, %r105, 5;
	mov.b32 	%r234, 0;
	mov.u64 	%rd139, 0;
	mov.u64 	%rd75, __cudart_i2opi_f;
$L__BB162_12:
	.pragma "nounroll";
	add.s64 	%rd76, %rd75, %rd139;
	ld.global.nc.u32 	%r109, [%rd76];
	// begin inline asm
	{
	mad.lo.cc.u32   %r107, %r109, %r110, %r234;
	madc.hi.u32     %r234, %r109, %r110,  0;
	}
	// end inline asm
	add.s64 	%rd77, %rd13, %rd139;
	st.local.u32 	[%rd77], %r107;
	add.s64 	%rd139, %rd139, 4;
	cvt.u32.u64 	%r112, %rd139;
	setp.ne.s32 	%p9, %r112, 24;
	@%p9 bra 	$L__BB162_12;
	st.local.u32 	[%rd13+24], %r234;
	and.b32  	%r27, %r22, 31;
	mul.wide.u32 	%rd78, %r24, 4;
	sub.s64 	%rd24, %rd13, %rd78;
	ld.local.u32 	%r235, [%rd24+24];
	ld.local.u32 	%r236, [%rd24+20];
	setp.eq.s32 	%p10, %r27, 0;
	@%p10 bra 	$L__BB162_15;
	shl.b32 	%r113, %r236, %r27;
	shl.b32 	%r114, %r235, %r27;
	mov.b32 	%r115, 32;
	sub.s32 	%r116, %r115, %r27;
	shr.u32 	%r117, %r236, %r116;
	add.s32 	%r235, %r117, %r114;
	ld.local.u32 	%r118, [%rd24+16];
	shr.u32 	%r119, %r118, %r116;
	add.s32 	%r236, %r119, %r113;
$L__BB162_15:
	shr.u32 	%r120, %r235, 30;
	shr.u32 	%r121, %r236, 30;
	shl.b32 	%r122, %r235, 2;
	or.b32  	%r123, %r122, %r121;
	shl.b32 	%r124, %r236, 2;
	bfe.u32 	%r125, %r235, 29, 1;
	add.s32 	%r126, %r125, %r120;
	neg.s32 	%r127, %r126;
	setp.lt.s32 	%p11, %r21, 0;
	selp.b32 	%r237, %r127, %r126, %p11;
	xor.b32  	%r128, %r123, %r21;
	bfe.s32 	%r129, %r235, 29, 1;
	xor.b32  	%r130, %r129, %r123;
	xor.b32  	%r131, %r129, %r124;
	cvt.u64.u32 	%rd79, %r130;
	shl.b64 	%rd80, %rd79, 32;
	cvt.u64.u32 	%rd81, %r131;
	or.b64  	%rd82, %rd80, %rd81;
	cvt.rn.f64.s64 	%fd3, %rd82;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f36, %fd4;
	neg.f32 	%f37, %f36;
	setp.lt.s32 	%p12, %r128, 0;
	selp.f32 	%f193, %f37, %f36, %p12;
$L__BB162_16:
	ld.param.u64 	%rd37, [loop_multiply_transpose_fusion_6_param_11];
	ld.param.u64 	%rd39, [loop_multiply_transpose_fusion_6_param_10];
	ld.param.u64 	%rd41, [loop_multiply_transpose_fusion_6_param_9];
	ld.param.u64 	%rd43, [loop_multiply_transpose_fusion_6_param_8];
	ld.param.u64 	%rd44, [loop_multiply_transpose_fusion_6_param_4];
	ld.param.u64 	%rd45, [loop_multiply_transpose_fusion_6_param_7];
	ld.param.u64 	%rd47, [loop_multiply_transpose_fusion_6_param_6];
	cvta.to.global.u64 	%rd9, %rd42;
	ld.global.nc.f32 	%f12, [%rd21];
	shl.b16 	%rs16, %rs2, 1;
	cvt.u32.u16 	%r133, %rs16;
	mul.lo.s16 	%rs17, %rs1, 100;
	cvt.u32.u16 	%r134, %rs17;
	mul.lo.s32 	%r135, %r2, 6400;
	or.b32  	%r136, %r135, %r133;
	or.b32  	%r137, %r136, %r3;
	add.s32 	%r138, %r137, %r134;
	mul.hi.u32 	%r140, %r138, -1431655765;
	shr.u32 	%r141, %r140, 2;
	mul.lo.s32 	%r142, %r141, 6;
	sub.s32 	%r143, %r138, %r142;
	mul.hi.u32 	%r144, %r141, 85899346;
	mul.lo.s32 	%r145, %r144, 50;
	sub.s32 	%r146, %r141, %r145;
	mul.hi.u32 	%r147, %r138, 14316558;
	cvt.u64.u32 	%rd25, %r147;
	mul.wide.u32 	%rd83, %r147, 4;
	add.s64 	%rd84, %rd11, %rd83;
	ld.global.nc.f32 	%f13, [%rd84];
	cvt.u64.u32 	%rd26, %r146;
	cvt.u64.u32 	%rd27, %r143;
	mul.wide.u32 	%rd85, %r146, 48;
	mul.wide.u32 	%rd86, %r147, 2400;
	add.s64 	%rd87, %rd7, %rd86;
	add.s64 	%rd88, %rd87, %rd85;
	mul.wide.u32 	%rd89, %r143, 4;
	add.s64 	%rd90, %rd88, %rd89;
	ld.global.nc.f32 	%f14, [%rd90+24];
	shr.u32 	%r148, %r143, 1;
	mul.wide.u32 	%rd91, %r148, 4;
	mul.wide.u32 	%rd92, %r147, 12;
	add.s64 	%rd93, %rd10, %rd92;
	add.s64 	%rd94, %rd93, %rd91;
	ld.global.nc.f32 	%f39, [%rd94];
	add.rn.f32 	%f40, %f39, %f39;
	add.rn.f32 	%f41, %f40, %f40;
	add.rn.f32 	%f42, %f41, %f41;
	add.rn.f32 	%f15, %f42, %f42;
	mul.rn.f32 	%f43, %f15, 0f3F22F983;
	cvt.rni.s32.f32 	%r245, %f43;
	cvt.rn.f32.s32 	%f44, %r245;
	fma.rn.f32 	%f45, %f44, 0fBFC90FDA, %f15;
	fma.rn.f32 	%f46, %f44, 0fB3A22168, %f45;
	fma.rn.f32 	%f195, %f44, 0fA7C234C5, %f46;
	abs.f32 	%f17, %f15;
	setp.ltu.f32 	%p13, %f17, 0f47CE4780;
	setp.neu.f32 	%p34, %f17, 0f7F800000;
	mov.u32 	%r241, %r245;
	mov.f32 	%f194, %f195;
	@%p13 bra 	$L__BB162_24;
	@%p34 bra 	$L__BB162_19;
	mul.rn.f32 	%f194, %f15, %f191;
	mov.b32 	%r241, 0;
	bra.uni 	$L__BB162_24;
$L__BB162_19:
	mov.b32 	%r37, %f15;
	shr.u32 	%r38, %r37, 23;
	and.b32  	%r150, %r38, 224;
	add.s32 	%r151, %r150, -128;
	shl.b32 	%r152, %r37, 8;
	or.b32  	%r156, %r152, -2147483648;
	shr.u32 	%r40, %r151, 5;
	mov.b32 	%r238, 0;
	mov.u64 	%rd140, 0;
	mov.u64 	%rd96, __cudart_i2opi_f;
$L__BB162_20:
	.pragma "nounroll";
	add.s64 	%rd97, %rd96, %rd140;
	ld.global.nc.u32 	%r155, [%rd97];
	// begin inline asm
	{
	mad.lo.cc.u32   %r153, %r155, %r156, %r238;
	madc.hi.u32     %r238, %r155, %r156,  0;
	}
	// end inline asm
	add.s64 	%rd98, %rd13, %rd140;
	st.local.u32 	[%rd98], %r153;
	add.s64 	%rd140, %rd140, 4;
	cvt.u32.u64 	%r158, %rd140;
	setp.ne.s32 	%p15, %r158, 24;
	@%p15 bra 	$L__BB162_20;
	st.local.u32 	[%rd13+24], %r238;
	and.b32  	%r43, %r38, 31;
	mul.wide.u32 	%rd99, %r40, 4;
	sub.s64 	%rd31, %rd13, %rd99;
	ld.local.u32 	%r239, [%rd31+24];
	ld.local.u32 	%r240, [%rd31+20];
	setp.eq.s32 	%p16, %r43, 0;
	@%p16 bra 	$L__BB162_23;
	shl.b32 	%r159, %r240, %r43;
	shl.b32 	%r160, %r239, %r43;
	mov.b32 	%r161, 32;
	sub.s32 	%r162, %r161, %r43;
	shr.u32 	%r163, %r240, %r162;
	add.s32 	%r239, %r163, %r160;
	ld.local.u32 	%r164, [%rd31+16];
	shr.u32 	%r165, %r164, %r162;
	add.s32 	%r240, %r165, %r159;
$L__BB162_23:
	shr.u32 	%r166, %r239, 30;
	shr.u32 	%r167, %r240, 30;
	shl.b32 	%r168, %r239, 2;
	or.b32  	%r169, %r168, %r167;
	shl.b32 	%r170, %r240, 2;
	bfe.u32 	%r171, %r239, 29, 1;
	add.s32 	%r172, %r171, %r166;
	neg.s32 	%r173, %r172;
	setp.lt.s32 	%p17, %r37, 0;
	selp.b32 	%r241, %r173, %r172, %p17;
	xor.b32  	%r174, %r169, %r37;
	bfe.s32 	%r175, %r239, 29, 1;
	xor.b32  	%r176, %r175, %r169;
	xor.b32  	%r177, %r175, %r170;
	cvt.u64.u32 	%rd100, %r176;
	shl.b64 	%rd101, %rd100, 32;
	cvt.u64.u32 	%rd102, %r177;
	or.b64  	%rd103, %rd101, %rd102;
	cvt.rn.f64.s64 	%fd5, %rd103;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f47, %fd6;
	neg.f32 	%f48, %f47;
	setp.lt.s32 	%p18, %r174, 0;
	selp.f32 	%f194, %f48, %f47, %p18;
$L__BB162_24:
	cvta.to.global.u64 	%rd1, %rd37;
	cvta.to.global.u64 	%rd2, %rd39;
	cvta.to.global.u64 	%rd3, %rd41;
	cvta.to.global.u64 	%rd4, %rd43;
	cvta.to.global.u64 	%rd5, %rd45;
	cvta.to.global.u64 	%rd6, %rd47;
	cvta.to.global.u64 	%rd8, %rd44;
	cvt.u64.u32 	%rd28, %r148;
	mul.lo.s64 	%rd104, %rd25, 4800;
	add.s64 	%rd105, %rd9, %rd104;
	mul.lo.s64 	%rd106, %rd26, 96;
	add.s64 	%rd107, %rd105, %rd106;
	shl.b64 	%rd108, %rd27, 2;
	add.s64 	%rd32, %rd107, %rd108;
	ld.global.nc.f32 	%f21, [%rd32];
	@%p13 bra 	$L__BB162_32;
	@%p34 bra 	$L__BB162_27;
	mul.rn.f32 	%f195, %f15, %f191;
	mov.b32 	%r245, 0;
	bra.uni 	$L__BB162_32;
$L__BB162_27:
	mov.b32 	%r52, %f15;
	shr.u32 	%r53, %r52, 23;
	and.b32  	%r180, %r53, 224;
	add.s32 	%r181, %r180, -128;
	shl.b32 	%r182, %r52, 8;
	or.b32  	%r186, %r182, -2147483648;
	shr.u32 	%r55, %r181, 5;
	mov.b32 	%r242, 0;
	mov.u64 	%rd141, 0;
	mov.u64 	%rd110, __cudart_i2opi_f;
$L__BB162_28:
	.pragma "nounroll";
	add.s64 	%rd111, %rd110, %rd141;
	ld.global.nc.u32 	%r185, [%rd111];
	// begin inline asm
	{
	mad.lo.cc.u32   %r183, %r185, %r186, %r242;
	madc.hi.u32     %r242, %r185, %r186,  0;
	}
	// end inline asm
	add.s64 	%rd112, %rd13, %rd141;
	st.local.u32 	[%rd112], %r183;
	add.s64 	%rd141, %rd141, 4;
	cvt.u32.u64 	%r188, %rd141;
	setp.ne.s32 	%p21, %r188, 24;
	@%p21 bra 	$L__BB162_28;
	st.local.u32 	[%rd13+24], %r242;
	and.b32  	%r58, %r53, 31;
	mul.wide.u32 	%rd113, %r55, 4;
	sub.s64 	%rd35, %rd13, %rd113;
	ld.local.u32 	%r243, [%rd35+24];
	ld.local.u32 	%r244, [%rd35+20];
	setp.eq.s32 	%p22, %r58, 0;
	@%p22 bra 	$L__BB162_31;
	shl.b32 	%r189, %r244, %r58;
	shl.b32 	%r190, %r243, %r58;
	mov.b32 	%r191, 32;
	sub.s32 	%r192, %r191, %r58;
	shr.u32 	%r193, %r244, %r192;
	add.s32 	%r243, %r193, %r190;
	ld.local.u32 	%r194, [%rd35+16];
	shr.u32 	%r195, %r194, %r192;
	add.s32 	%r244, %r195, %r189;
$L__BB162_31:
	shr.u32 	%r196, %r243, 30;
	shr.u32 	%r197, %r244, 30;
	shl.b32 	%r198, %r243, 2;
	or.b32  	%r199, %r198, %r197;
	shl.b32 	%r200, %r244, 2;
	bfe.u32 	%r201, %r243, 29, 1;
	add.s32 	%r202, %r201, %r196;
	neg.s32 	%r203, %r202;
	setp.lt.s32 	%p23, %r52, 0;
	selp.b32 	%r245, %r203, %r202, %p23;
	xor.b32  	%r204, %r199, %r52;
	bfe.s32 	%r205, %r243, 29, 1;
	xor.b32  	%r206, %r205, %r199;
	xor.b32  	%r207, %r205, %r200;
	cvt.u64.u32 	%rd114, %r206;
	shl.b64 	%rd115, %rd114, 32;
	cvt.u64.u32 	%rd116, %r207;
	or.b64  	%rd117, %rd115, %rd116;
	cvt.rn.f64.s64 	%fd7, %rd117;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f50, %fd8;
	neg.f32 	%f51, %f50;
	setp.lt.s32 	%p24, %r204, 0;
	selp.f32 	%f195, %f51, %f50, %p24;
$L__BB162_32:
	cvt.u32.u64 	%r209, %rd27;
	add.s32 	%r210, %r241, 1;
	and.b32  	%r211, %r210, 2;
	setp.eq.s32 	%p25, %r211, 0;
	and.b32  	%r212, %r241, 1;
	setp.eq.b32 	%p26, %r212, 1;
	mul.rn.f32 	%f53, %f194, %f194;
	fma.rn.f32 	%f54, %f53, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f55, 0fB94D4153, %f54, %p26;
	selp.f32 	%f56, 0f3C0885E4, 0f3D2AAABB, %p26;
	fma.rn.f32 	%f57, %f55, %f53, %f56;
	selp.f32 	%f58, 0fBE2AAAA8, 0fBEFFFFFF, %p26;
	fma.rn.f32 	%f59, %f57, %f53, %f58;
	selp.f32 	%f60, %f194, 0f3F800000, %p26;
	fma.rn.f32 	%f61, %f53, %f60, 0f00000000;
	fma.rn.f32 	%f62, %f59, %f61, %f60;
	sub.rn.f32 	%f64, %f191, %f62;
	selp.f32 	%f65, %f62, %f64, %p25;
	mul.rn.f32 	%f66, %f21, %f65;
	fma.rn.f32 	%f67, %f13, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f68, %f67;
	mov.f32 	%f69, 0f4B400001;
	mov.f32 	%f70, 0f437C0000;
	fma.rm.f32 	%f71, %f68, %f70, %f69;
	add.rn.f32 	%f72, %f71, 0fCB40007F;
	neg.f32 	%f73, %f72;
	fma.rn.f32 	%f74, %f13, 0f3FB8AA3B, %f73;
	fma.rn.f32 	%f75, %f13, 0f32A57060, %f74;
	ex2.approx.ftz.f32 	%f76, %f75;
	mov.b32 	%r213, %f71;
	shl.b32 	%r214, %r213, 23;
	mov.b32 	%f77, %r214;
	mul.rn.f32 	%f78, %f76, %f77;
	neg.f32 	%f79, %f78;
	sub.rn.f32 	%f80, %f79, %f78;
	add.rn.f32 	%f81, %f80, %f80;
	add.rn.f32 	%f82, %f81, %f81;
	add.rn.f32 	%f83, %f82, %f82;
	add.rn.f32 	%f84, %f83, %f83;
	add.rn.f32 	%f85, %f84, %f84;
	add.rn.f32 	%f86, %f85, %f85;
	add.rn.f32 	%f87, %f86, %f86;
	fma.rn.f32 	%f88, %f87, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f89, %f88;
	fma.rm.f32 	%f90, %f89, %f70, %f69;
	add.rn.f32 	%f91, %f90, 0fCB40007F;
	neg.f32 	%f92, %f91;
	fma.rn.f32 	%f93, %f87, 0f3FB8AA3B, %f92;
	fma.rn.f32 	%f94, %f87, 0f32A57060, %f93;
	ex2.approx.ftz.f32 	%f95, %f94;
	mov.b32 	%r215, %f90;
	shl.b32 	%r216, %r215, 23;
	mov.b32 	%f96, %r216;
	mul.rn.f32 	%f97, %f95, %f96;
	add.rn.f32 	%f98, %f87, %f87;
	fma.rn.f32 	%f99, %f98, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f100, %f99;
	fma.rm.f32 	%f101, %f100, %f70, %f69;
	add.rn.f32 	%f102, %f101, 0fCB40007F;
	neg.f32 	%f103, %f102;
	fma.rn.f32 	%f104, %f98, 0f3FB8AA3B, %f103;
	fma.rn.f32 	%f105, %f98, 0f32A57060, %f104;
	ex2.approx.ftz.f32 	%f106, %f105;
	mov.b32 	%r217, %f101;
	shl.b32 	%r218, %r217, 23;
	mov.b32 	%f107, %r218;
	mul.rn.f32 	%f108, %f106, %f107;
	mul.rn.f32 	%f109, %f14, %f108;
	fma.rn.f32 	%f110, %f7, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f111, %f110;
	fma.rm.f32 	%f112, %f111, %f70, %f69;
	add.rn.f32 	%f113, %f112, 0fCB40007F;
	neg.f32 	%f114, %f113;
	fma.rn.f32 	%f115, %f7, 0f3FB8AA3B, %f114;
	fma.rn.f32 	%f116, %f7, 0f32A57060, %f115;
	ex2.approx.ftz.f32 	%f117, %f116;
	mov.b32 	%r219, %f112;
	shl.b32 	%r220, %r219, 23;
	mov.b32 	%f118, %r220;
	mul.rn.f32 	%f119, %f117, %f118;
	neg.f32 	%f120, %f119;
	sub.rn.f32 	%f121, %f120, %f119;
	add.rn.f32 	%f122, %f121, %f121;
	add.rn.f32 	%f123, %f122, %f122;
	add.rn.f32 	%f124, %f123, %f123;
	add.rn.f32 	%f125, %f124, %f124;
	add.rn.f32 	%f126, %f125, %f125;
	add.rn.f32 	%f127, %f126, %f126;
	add.rn.f32 	%f128, %f127, %f127;
	fma.rn.f32 	%f129, %f128, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f130, %f129;
	fma.rm.f32 	%f131, %f130, %f70, %f69;
	add.rn.f32 	%f132, %f131, 0fCB40007F;
	neg.f32 	%f133, %f132;
	fma.rn.f32 	%f134, %f128, 0f3FB8AA3B, %f133;
	fma.rn.f32 	%f135, %f128, 0f32A57060, %f134;
	ex2.approx.ftz.f32 	%f136, %f135;
	mov.b32 	%r221, %f131;
	shl.b32 	%r222, %r221, 23;
	mov.b32 	%f137, %r222;
	mul.rn.f32 	%f138, %f136, %f137;
	mul.rn.f32 	%f139, %f12, %f138;
	and.b32  	%r223, %r237, 2;
	setp.eq.s32 	%p27, %r223, 0;
	and.b32  	%r224, %r237, 1;
	setp.eq.b32 	%p28, %r224, 1;
	mul.rn.f32 	%f140, %f193, %f193;
	fma.rn.f32 	%f141, %f140, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f142, %f141, 0fB94D4153, %p28;
	selp.f32 	%f143, 0f3D2AAABB, 0f3C0885E4, %p28;
	fma.rn.f32 	%f144, %f142, %f140, %f143;
	selp.f32 	%f145, 0fBEFFFFFF, 0fBE2AAAA8, %p28;
	fma.rn.f32 	%f146, %f144, %f140, %f145;
	selp.f32 	%f147, 0f3F800000, %f193, %p28;
	fma.rn.f32 	%f148, %f140, %f147, 0f00000000;
	fma.rn.f32 	%f149, %f146, %f148, %f147;
	sub.rn.f32 	%f150, %f191, %f149;
	selp.f32 	%f151, %f149, %f150, %p27;
	neg.f32 	%f152, %f151;
	mul.rn.f32 	%f153, %f139, %f152;
	and.b32  	%r225, %r233, 2;
	setp.eq.s32 	%p29, %r225, 0;
	and.b32  	%r226, %r233, 1;
	setp.eq.b32 	%p30, %r226, 1;
	mul.rn.f32 	%f154, %f192, %f192;
	fma.rn.f32 	%f155, %f154, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f156, %f155, 0fB94D4153, %p30;
	selp.f32 	%f157, 0f3D2AAABB, 0f3C0885E4, %p30;
	fma.rn.f32 	%f158, %f156, %f154, %f157;
	selp.f32 	%f159, 0fBEFFFFFF, 0fBE2AAAA8, %p30;
	fma.rn.f32 	%f160, %f158, %f154, %f159;
	selp.f32 	%f161, 0f3F800000, %f192, %p30;
	fma.rn.f32 	%f162, %f154, %f161, 0f00000000;
	fma.rn.f32 	%f163, %f160, %f162, %f161;
	sub.rn.f32 	%f164, %f191, %f163;
	selp.f32 	%f165, %f163, %f164, %p29;
	mul.rn.f32 	%f166, %f8, %f138;
	mul.rn.f32 	%f167, %f165, %f166;
	mul.rn.f32 	%f168, %f195, %f195;
	and.b32  	%r227, %r245, 1;
	setp.eq.b32 	%p31, %r227, 1;
	selp.f32 	%f169, 0f3F800000, %f195, %p31;
	fma.rn.f32 	%f170, %f168, %f169, 0f00000000;
	fma.rn.f32 	%f171, %f168, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f172, %f171, 0fB94D4153, %p31;
	selp.f32 	%f173, 0f3D2AAABB, 0f3C0885E4, %p31;
	fma.rn.f32 	%f174, %f172, %f168, %f173;
	selp.f32 	%f175, 0fBEFFFFFF, 0fBE2AAAA8, %p31;
	fma.rn.f32 	%f176, %f174, %f168, %f175;
	fma.rn.f32 	%f177, %f176, %f170, %f169;
	and.b32  	%r228, %r245, 2;
	setp.eq.s32 	%p32, %r228, 0;
	sub.rn.f32 	%f178, %f191, %f177;
	selp.f32 	%f179, %f177, %f178, %p32;
	and.b32  	%r229, %r209, 1;
	mul.lo.s64 	%rd118, %rd25, 2400;
	add.s64 	%rd119, %rd8, %rd118;
	mul.lo.s64 	%rd120, %rd26, 48;
	add.s64 	%rd121, %rd119, %rd120;
	shl.b64 	%rd122, %rd28, 3;
	add.s64 	%rd123, %rd121, %rd122;
	mul.wide.u32 	%rd124, %r229, 4;
	add.s64 	%rd125, %rd123, %rd124;
	ld.global.nc.f32 	%f180, [%rd125];
	mul.rn.f32 	%f181, %f180, %f179;
	add.rn.f32 	%f182, %f66, %f181;
	mul.rn.f32 	%f183, %f182, %f97;
	ld.global.nc.f32 	%f184, [%rd32+24];
	add.rn.f32 	%f185, %f184, %f183;
	mul.rn.f32 	%f186, %f109, %f185;
	add.s64 	%rd126, %rd5, %rd118;
	add.s64 	%rd127, %rd126, %rd120;
	add.s64 	%rd129, %rd127, %rd108;
	ld.global.nc.f32 	%f187, [%rd129+24];
	mul.rn.f32 	%f188, %f187, %f97;
	add.s64 	%rd130, %rd6, %rd118;
	add.s64 	%rd131, %rd130, %rd120;
	add.s64 	%rd132, %rd131, %rd108;
	ld.global.nc.f32 	%f189, [%rd132];
	mul.rn.f32 	%f190, %f189, %f188;
	mul.wide.u32 	%rd133, %r1, 4;
	add.s64 	%rd134, %rd4, %rd133;
	st.global.f32 	[%rd134], %f167;
	add.s64 	%rd135, %rd3, %rd133;
	st.global.f32 	[%rd135], %f153;
	add.s64 	%rd136, %rd2, %rd133;
	st.global.f32 	[%rd136], %f186;
	add.s64 	%rd137, %rd1, %rd133;
	st.global.f32 	[%rd137], %f190;
	ret;

}
	// .globl	loop_broadcast_fusion_37
.visible .entry loop_broadcast_fusion_37(
	.param .u64 loop_broadcast_fusion_37_param_0
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<5>;

	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 10;
	or.b32  	%r4, %r3, %r2;
	setp.lt.u32 	%p1, %r4, 38400;
	@%p1 bra 	$L__BB163_2;
	bra.uni 	$L__BB163_1;
$L__BB163_2:
	ld.param.u64 	%rd2, [loop_broadcast_fusion_37_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.u32 	%rd4, %r4, 4;
	add.s64 	%rd1, %rd3, %rd4;
	mov.b32 	%r5, 0;
	st.global.u32 	[%rd1], %r5;
$L__BB163_1:
	ret;

}
	// .globl	input_scatter_fusion_248
.visible .entry input_scatter_fusion_248(
	.param .u64 input_scatter_fusion_248_param_0,
	.param .u64 input_scatter_fusion_248_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<16>;
	.reg .b32 	%r<11>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_248_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_248_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r2, 1;
	shr.u32 	%r6, %r4, 1;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r4;
	shr.u16 	%rs8, %rs7, 2;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	and.b16  	%rs11, %rs10, 63;
	cvt.u16.u32 	%rs12, %r1;
	and.b16  	%rs13, %rs12, 255;
	mul.lo.s16 	%rs14, %rs13, 41;
	shr.u16 	%rs15, %rs14, 10;
	cvt.u32.u16 	%r7, %rs15;
	and.b32  	%r8, %r7, 14;
	mul.wide.u32 	%rd5, %r8, 25600;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r9, %rs11;
	mul.wide.u32 	%rd7, %r9, 400;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r10, %rs6;
	mul.wide.u32 	%rd9, %r10, 8;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+25600];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+25600], %f3;
	ret;

}
	// .globl	wrapped_transpose_254
.visible .entry wrapped_transpose_254(
	.param .u64 wrapped_transpose_254_param_0,
	.param .u64 wrapped_transpose_254_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<16>;
	.reg .b32 	%r<9>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [wrapped_transpose_254_param_0];
	ld.param.u64 	%rd2, [wrapped_transpose_254_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	shr.u16 	%rs2, %rs1, 3;
	mul.hi.u16 	%rs3, %rs2, 6991;
	shr.u16 	%rs4, %rs3, 3;
	and.b16  	%rs5, %rs4, 63;
	mul.hi.u16 	%rs6, %rs1, -21845;
	shr.u16 	%rs7, %rs6, 3;
	mul.hi.u16 	%rs8, %rs7, 5243;
	shr.u16 	%rs9, %rs8, 2;
	mul.lo.s16 	%rs10, %rs9, 50;
	sub.s16 	%rs11, %rs7, %rs10;
	shr.u16 	%rs12, %rs6, 2;
	and.b16  	%rs13, %rs12, 1;
	mul.lo.s16 	%rs14, %rs12, 6;
	sub.s16 	%rs15, %rs1, %rs14;
	cvt.u32.u16 	%r5, %rs15;
	mul.wide.u32 	%rd5, %r5, 25600;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r6, %rs5;
	mul.wide.u32 	%rd7, %r6, 400;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r7, %rs11;
	mul.wide.u32 	%rd9, %r7, 8;
	add.s64 	%rd10, %rd8, %rd9;
	cvt.u32.u16 	%r8, %rs13;
	mul.wide.u32 	%rd11, %r8, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	st.global.f32 	[%rd14], %f1;
	ret;

}
	// .globl	input_scatter_fusion_249
.visible .entry input_scatter_fusion_249(
	.param .u64 input_scatter_fusion_249_param_0,
	.param .u64 input_scatter_fusion_249_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<16>;
	.reg .b32 	%r<11>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_249_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_249_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r2, 1;
	shr.u32 	%r6, %r4, 1;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r4;
	shr.u16 	%rs8, %rs7, 2;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	and.b16  	%rs11, %rs10, 63;
	cvt.u16.u32 	%rs12, %r1;
	and.b16  	%rs13, %rs12, 255;
	mul.lo.s16 	%rs14, %rs13, 41;
	shr.u16 	%rs15, %rs14, 10;
	cvt.u32.u16 	%r7, %rs15;
	and.b32  	%r8, %r7, 14;
	mul.wide.u32 	%rd5, %r8, 25600;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r9, %rs11;
	mul.wide.u32 	%rd7, %r9, 400;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r10, %rs6;
	mul.wide.u32 	%rd9, %r10, 8;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	loop_add_multiply_fusion_19
.visible .entry loop_add_multiply_fusion_19(
	.param .u64 loop_add_multiply_fusion_19_param_0,
	.param .u64 loop_add_multiply_fusion_19_param_1,
	.param .u64 loop_add_multiply_fusion_19_param_2,
	.param .u64 loop_add_multiply_fusion_19_param_3,
	.param .u64 loop_add_multiply_fusion_19_param_4,
	.param .u64 loop_add_multiply_fusion_19_param_5,
	.param .u64 loop_add_multiply_fusion_19_param_6,
	.param .u64 loop_add_multiply_fusion_19_param_7,
	.param .u64 loop_add_multiply_fusion_19_param_8,
	.param .u64 loop_add_multiply_fusion_19_param_9,
	.param .u64 loop_add_multiply_fusion_19_param_10,
	.param .u64 loop_add_multiply_fusion_19_param_11,
	.param .u64 loop_add_multiply_fusion_19_param_12
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot167[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<54>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<297>;
	.reg .f32 	%f<222>;
	.reg .b64 	%rd<176>;
	.reg .f64 	%fd<11>;

	mov.u64 	%SPL, __local_depot167;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd42, [loop_add_multiply_fusion_19_param_1];
	ld.param.u64 	%rd50, [loop_add_multiply_fusion_19_param_5];
	ld.param.u64 	%rd52, [loop_add_multiply_fusion_19_param_6];
	cvta.to.global.u64 	%rd7, %rd52;
	cvta.to.global.u64 	%rd53, %rd50;
	cvta.to.global.u64 	%rd54, %rd42;
	mov.u32 	%r83, %ctaid.x;
	mov.u32 	%r84, %tid.x;
	shl.b32 	%r85, %r83, 7;
	or.b32  	%r1, %r85, %r84;
	mul.hi.u32 	%r86, %r1, -1431655765;
	shr.u32 	%r2, %r86, 2;
	mul.lo.s32 	%r87, %r2, 6;
	sub.s32 	%r88, %r1, %r87;
	bfe.u32 	%r3, %r86, 2, 2;
	shr.u32 	%r89, %r86, 4;
	cvt.u16.u32 	%rs1, %r89;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r90, %r1, 458129845;
	bfe.u32 	%r91, %r90, 7, 6;
	cvt.u64.u32 	%rd17, %r91;
	mul.wide.u32 	%rd60, %r91, 4;
	add.s64 	%rd61, %rd54, %rd60;
	ld.global.nc.f32 	%f40, [%rd61];
	fma.rn.f32 	%f41, %f40, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f42, %f41;
	mov.f32 	%f43, 0f4B400001;
	mov.f32 	%f44, 0f437C0000;
	fma.rm.f32 	%f45, %f42, %f44, %f43;
	add.rn.f32 	%f46, %f45, 0fCB40007F;
	neg.f32 	%f47, %f46;
	fma.rn.f32 	%f48, %f40, 0f3FB8AA3B, %f47;
	fma.rn.f32 	%f49, %f40, 0f32A57060, %f48;
	mov.b32 	%r92, %f45;
	shl.b32 	%r93, %r92, 23;
	mov.b32 	%f50, %r93;
	ex2.approx.ftz.f32 	%f51, %f49;
	mul.rn.f32 	%f52, %f51, %f50;
	neg.f32 	%f53, %f52;
	sub.rn.f32 	%f54, %f53, %f52;
	add.rn.f32 	%f55, %f54, %f54;
	add.rn.f32 	%f56, %f55, %f55;
	add.rn.f32 	%f57, %f56, %f56;
	add.rn.f32 	%f58, %f57, %f57;
	setp.eq.s32 	%p1, %r3, 2;
	cvt.u64.u16 	%rd18, %rs6;
	cvt.u64.u32 	%rd19, %r88;
	cvt.u32.u16 	%r94, %rs6;
	mul.wide.u32 	%rd62, %r94, 48;
	mul.wide.u32 	%rd63, %r91, 2400;
	add.s64 	%rd64, %rd53, %rd63;
	add.s64 	%rd65, %rd64, %rd62;
	mul.wide.u32 	%rd66, %r88, 4;
	add.s64 	%rd20, %rd65, %rd66;
	mov.f32 	%f216, 0f00000000;
	mov.f32 	%f213, %f216;
	@%p1 bra 	$L__BB167_37;
	bra.uni 	$L__BB167_1;
$L__BB167_37:
	ld.global.nc.f32 	%f213, [%rd20+24];
$L__BB167_1:
	ld.param.u64 	%rd46, [loop_add_multiply_fusion_19_param_3];
	add.u64 	%rd55, %SP, 0;
	add.rn.f32 	%f1, %f58, %f58;
	add.s32 	%r95, %r3, -1;
	and.b32  	%r96, %r95, 1;
	setp.eq.b32 	%p2, %r96, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mul.lo.s64 	%rd67, %rd17, 2400;
	add.s64 	%rd68, %rd7, %rd67;
	mul.lo.s64 	%rd69, %rd18, 48;
	add.s64 	%rd70, %rd68, %rd69;
	shl.b64 	%rd73, %rd19, 2;
	mov.f32 	%f214, %f216;
	@%p5 bra 	$L__BB167_38;
	bra.uni 	$L__BB167_2;
$L__BB167_38:
	setp.gt.u32 	%p6, %r95, 1;
	selp.u32 	%r97, 1, 0, %p6;
	mul.wide.u32 	%rd71, %r97, 24;
	add.s64 	%rd72, %rd70, %rd71;
	add.s64 	%rd21, %rd72, %rd73;
	ld.global.nc.f32 	%f214, [%rd21];
$L__BB167_2:
	cvta.to.global.u64 	%rd9, %rd46;
	cvta.to.local.u64 	%rd12, %rd55;
	add.rn.f32 	%f2, %f1, %f1;
	and.b32  	%r98, %r2, 1;
	setp.eq.b32 	%p7, %r98, 1;
	xor.pred  	%p9, %p7, %p3;
	not.pred 	%p10, %p9;
	cvt.u32.u64 	%r276, %rd19;
	mul.lo.s64 	%rd170, %rd17, 12;
	mov.f32 	%f215, %f216;
	@%p10 bra 	$L__BB167_39;
	bra.uni 	$L__BB167_3;
$L__BB167_39:
	ld.param.u64 	%rd49, [loop_add_multiply_fusion_19_param_8];
	ld.param.u64 	%rd51, [loop_add_multiply_fusion_19_param_7];
	cvta.to.global.u64 	%rd5, %rd49;
	cvta.to.global.u64 	%rd6, %rd51;
	shr.u32 	%r100, %r3, 1;
	cvt.u64.u32 	%rd36, %r100;
	add.s64 	%rd75, %rd6, %rd67;
	add.s64 	%rd77, %rd75, %rd69;
	mul.wide.u32 	%rd78, %r100, 24;
	add.s64 	%rd79, %rd77, %rd78;
	add.s64 	%rd81, %rd79, %rd73;
	ld.global.nc.f32 	%f61, [%rd81];
	add.s64 	%rd82, %rd5, %rd67;
	add.s64 	%rd83, %rd82, %rd69;
	add.s64 	%rd84, %rd83, %rd78;
	add.s64 	%rd85, %rd84, %rd73;
	ld.global.nc.f32 	%f62, [%rd85];
	add.rn.f32 	%f30, %f61, %f62;
	shr.u32 	%r101, %r276, 1;
	add.s64 	%rd87, %rd9, %rd170;
	mul.wide.u32 	%rd88, %r101, 4;
	add.s64 	%rd89, %rd87, %rd88;
	ld.global.nc.f32 	%f63, [%rd89];
	add.rn.f32 	%f64, %f63, %f63;
	add.rn.f32 	%f65, %f64, %f64;
	add.rn.f32 	%f66, %f65, %f65;
	add.rn.f32 	%f31, %f66, %f66;
	mul.rn.f32 	%f67, %f31, 0f3F22F983;
	cvt.rni.s32.f32 	%r296, %f67;
	cvt.rn.f32.s32 	%f68, %r296;
	fma.rn.f32 	%f69, %f68, 0fBFC90FDA, %f31;
	fma.rn.f32 	%f70, %f68, 0fB3A22168, %f69;
	fma.rn.f32 	%f221, %f68, 0fA7C234C5, %f70;
	abs.f32 	%f33, %f31;
	setp.ltu.f32 	%p11, %f33, 0f47CE4780;
	@%p11 bra 	$L__BB167_47;
	setp.neu.f32 	%p12, %f33, 0f7F800000;
	@%p12 bra 	$L__BB167_42;
	mov.f32 	%f73, 0f00000000;
	mul.rn.f32 	%f221, %f31, %f73;
	mov.b32 	%r296, 0;
	bra.uni 	$L__BB167_47;
$L__BB167_42:
	mov.b32 	%r68, %f31;
	shr.u32 	%r69, %r68, 23;
	and.b32  	%r103, %r69, 224;
	add.s32 	%r104, %r103, -128;
	shl.b32 	%r105, %r68, 8;
	or.b32  	%r109, %r105, -2147483648;
	shr.u32 	%r71, %r104, 5;
	mov.b32 	%r293, 0;
	mov.u64 	%rd175, 0;
	mov.u64 	%rd91, __cudart_i2opi_f;
$L__BB167_43:
	.pragma "nounroll";
	add.s64 	%rd92, %rd91, %rd175;
	ld.global.nc.u32 	%r108, [%rd92];
	// begin inline asm
	{
	mad.lo.cc.u32   %r106, %r108, %r109, %r293;
	madc.hi.u32     %r293, %r108, %r109,  0;
	}
	// end inline asm
	add.s64 	%rd93, %rd12, %rd175;
	st.local.u32 	[%rd93], %r106;
	add.s64 	%rd175, %rd175, 4;
	cvt.u32.u64 	%r111, %rd175;
	setp.ne.s32 	%p13, %r111, 24;
	@%p13 bra 	$L__BB167_43;
	st.local.u32 	[%rd12+24], %r293;
	and.b32  	%r74, %r69, 31;
	mul.wide.u32 	%rd94, %r71, 4;
	sub.s64 	%rd39, %rd12, %rd94;
	ld.local.u32 	%r294, [%rd39+24];
	ld.local.u32 	%r295, [%rd39+20];
	setp.eq.s32 	%p14, %r74, 0;
	@%p14 bra 	$L__BB167_46;
	shl.b32 	%r112, %r295, %r74;
	shl.b32 	%r113, %r294, %r74;
	mov.b32 	%r114, 32;
	sub.s32 	%r115, %r114, %r74;
	shr.u32 	%r116, %r295, %r115;
	add.s32 	%r294, %r116, %r113;
	ld.local.u32 	%r117, [%rd39+16];
	shr.u32 	%r118, %r117, %r115;
	add.s32 	%r295, %r118, %r112;
$L__BB167_46:
	shr.u32 	%r119, %r294, 30;
	shr.u32 	%r120, %r295, 30;
	shl.b32 	%r121, %r294, 2;
	or.b32  	%r122, %r121, %r120;
	shl.b32 	%r123, %r295, 2;
	bfe.u32 	%r124, %r294, 29, 1;
	add.s32 	%r125, %r124, %r119;
	neg.s32 	%r126, %r125;
	setp.lt.s32 	%p15, %r68, 0;
	selp.b32 	%r296, %r126, %r125, %p15;
	xor.b32  	%r127, %r122, %r68;
	bfe.s32 	%r128, %r294, 29, 1;
	xor.b32  	%r129, %r128, %r122;
	xor.b32  	%r130, %r128, %r123;
	cvt.u64.u32 	%rd95, %r129;
	shl.b64 	%rd96, %rd95, 32;
	cvt.u64.u32 	%rd97, %r130;
	or.b64  	%rd98, %rd96, %rd97;
	cvt.rn.f64.s64 	%fd1, %rd98;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f71, %fd2;
	neg.f32 	%f72, %f71;
	setp.lt.s32 	%p16, %r127, 0;
	selp.f32 	%f221, %f72, %f71, %p16;
$L__BB167_47:
	add.s32 	%r132, %r296, 1;
	mul.rn.f32 	%f74, %f221, %f221;
	and.b32  	%r133, %r296, 1;
	setp.eq.b32 	%p17, %r133, 1;
	selp.f32 	%f75, %f221, 0f3F800000, %p17;
	fma.rn.f32 	%f76, %f74, %f75, 0f00000000;
	fma.rn.f32 	%f77, %f74, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f78, 0fB94D4153, %f77, %p17;
	selp.f32 	%f79, 0f3C0885E4, 0f3D2AAABB, %p17;
	fma.rn.f32 	%f80, %f78, %f74, %f79;
	selp.f32 	%f81, 0fBE2AAAA8, 0fBEFFFFFF, %p17;
	fma.rn.f32 	%f82, %f80, %f74, %f81;
	fma.rn.f32 	%f83, %f82, %f76, %f75;
	and.b32  	%r134, %r132, 2;
	setp.eq.s32 	%p18, %r134, 0;
	mov.f32 	%f84, 0f00000000;
	sub.rn.f32 	%f85, %f84, %f83;
	selp.f32 	%f86, %f83, %f85, %p18;
	add.rn.f32 	%f87, %f2, %f2;
	fma.rn.f32 	%f88, %f87, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f89, %f88;
	fma.rm.f32 	%f92, %f89, %f44, %f43;
	add.rn.f32 	%f93, %f92, 0fCB40007F;
	neg.f32 	%f94, %f93;
	fma.rn.f32 	%f95, %f87, 0f3FB8AA3B, %f94;
	fma.rn.f32 	%f96, %f87, 0f32A57060, %f95;
	mov.b32 	%r135, %f92;
	shl.b32 	%r136, %r135, 23;
	mov.b32 	%f97, %r136;
	ex2.approx.ftz.f32 	%f98, %f96;
	mul.rn.f32 	%f99, %f98, %f97;
	mul.lo.s64 	%rd103, %rd36, 24;
	add.s64 	%rd104, %rd70, %rd103;
	add.s64 	%rd106, %rd104, %rd73;
	ld.global.nc.f32 	%f100, [%rd106];
	mul.rn.f32 	%f101, %f99, %f100;
	mul.rn.f32 	%f102, %f101, %f86;
	add.rn.f32 	%f215, %f30, %f102;
$L__BB167_3:
	ld.param.u64 	%rd40, [loop_add_multiply_fusion_19_param_0];
	setp.eq.s32 	%p19, %r3, 0;
	@%p19 bra 	$L__BB167_48;
	bra.uni 	$L__BB167_4;
$L__BB167_48:
	ld.global.nc.f32 	%f216, [%rd20];
$L__BB167_4:
	ld.param.u64 	%rd44, [loop_add_multiply_fusion_19_param_2];
	cvta.to.global.u64 	%rd11, %rd40;
	shr.u32 	%r138, %r276, 1;
	add.s64 	%rd108, %rd9, %rd170;
	mul.wide.u32 	%rd109, %r138, 4;
	add.s64 	%rd110, %rd108, %rd109;
	ld.global.nc.f32 	%f104, [%rd110];
	add.rn.f32 	%f105, %f104, %f104;
	add.rn.f32 	%f7, %f105, %f105;
	mul.rn.f32 	%f106, %f7, 0f3F22F983;
	cvt.rni.s32.f32 	%r284, %f106;
	cvt.rn.f32.s32 	%f107, %r284;
	fma.rn.f32 	%f108, %f107, 0fBFC90FDA, %f7;
	fma.rn.f32 	%f109, %f107, 0fB3A22168, %f108;
	fma.rn.f32 	%f218, %f107, 0fA7C234C5, %f109;
	abs.f32 	%f9, %f7;
	setp.ltu.f32 	%p20, %f9, 0f47CE4780;
	setp.neu.f32 	%p52, %f9, 0f7F800000;
	mov.u32 	%r280, %r284;
	mov.f32 	%f217, %f218;
	@%p20 bra 	$L__BB167_12;
	@%p52 bra 	$L__BB167_7;
	mov.f32 	%f112, 0f00000000;
	mul.rn.f32 	%f217, %f7, %f112;
	mov.b32 	%r280, 0;
	bra.uni 	$L__BB167_12;
$L__BB167_7:
	mov.b32 	%r6, %f7;
	shr.u32 	%r7, %r6, 23;
	and.b32  	%r140, %r7, 224;
	add.s32 	%r141, %r140, -128;
	shl.b32 	%r142, %r6, 8;
	or.b32  	%r146, %r142, -2147483648;
	shr.u32 	%r9, %r141, 5;
	mov.b32 	%r277, 0;
	mov.u64 	%rd171, 0;
	mov.u64 	%rd112, __cudart_i2opi_f;
$L__BB167_8:
	.pragma "nounroll";
	add.s64 	%rd113, %rd112, %rd171;
	ld.global.nc.u32 	%r145, [%rd113];
	// begin inline asm
	{
	mad.lo.cc.u32   %r143, %r145, %r146, %r277;
	madc.hi.u32     %r277, %r145, %r146,  0;
	}
	// end inline asm
	add.s64 	%rd114, %rd12, %rd171;
	st.local.u32 	[%rd114], %r143;
	add.s64 	%rd171, %rd171, 4;
	cvt.u32.u64 	%r148, %rd171;
	setp.ne.s32 	%p22, %r148, 24;
	@%p22 bra 	$L__BB167_8;
	st.local.u32 	[%rd12+24], %r277;
	and.b32  	%r12, %r7, 31;
	mul.wide.u32 	%rd115, %r9, 4;
	sub.s64 	%rd25, %rd12, %rd115;
	ld.local.u32 	%r278, [%rd25+24];
	ld.local.u32 	%r279, [%rd25+20];
	setp.eq.s32 	%p23, %r12, 0;
	@%p23 bra 	$L__BB167_11;
	shl.b32 	%r149, %r279, %r12;
	shl.b32 	%r150, %r278, %r12;
	mov.b32 	%r151, 32;
	sub.s32 	%r152, %r151, %r12;
	shr.u32 	%r153, %r279, %r152;
	add.s32 	%r278, %r153, %r150;
	ld.local.u32 	%r154, [%rd25+16];
	shr.u32 	%r155, %r154, %r152;
	add.s32 	%r279, %r155, %r149;
$L__BB167_11:
	shr.u32 	%r156, %r278, 30;
	shr.u32 	%r157, %r279, 30;
	shl.b32 	%r158, %r278, 2;
	or.b32  	%r159, %r158, %r157;
	shl.b32 	%r160, %r279, 2;
	bfe.u32 	%r161, %r278, 29, 1;
	add.s32 	%r162, %r161, %r156;
	neg.s32 	%r163, %r162;
	setp.lt.s32 	%p24, %r6, 0;
	selp.b32 	%r280, %r163, %r162, %p24;
	xor.b32  	%r164, %r159, %r6;
	bfe.s32 	%r165, %r278, 29, 1;
	xor.b32  	%r166, %r165, %r159;
	xor.b32  	%r167, %r165, %r160;
	cvt.u64.u32 	%rd116, %r166;
	shl.b64 	%rd117, %rd116, 32;
	cvt.u64.u32 	%rd118, %r167;
	or.b64  	%rd119, %rd117, %rd118;
	cvt.rn.f64.s64 	%fd3, %rd119;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f110, %fd4;
	neg.f32 	%f111, %f110;
	setp.lt.s32 	%p25, %r164, 0;
	selp.f32 	%f217, %f111, %f110, %p25;
$L__BB167_12:
	cvta.to.global.u64 	%rd10, %rd44;
	shl.b32 	%r4, %r3, 1;
	cvt.u64.u32 	%rd22, %r138;
	shl.b32 	%r169, %r3, 2;
	mul.lo.s64 	%rd120, %rd17, 19200;
	add.s64 	%rd121, %rd11, %rd120;
	mul.lo.s64 	%rd122, %rd18, 384;
	add.s64 	%rd123, %rd121, %rd122;
	mul.wide.u32 	%rd124, %r169, 24;
	add.s64 	%rd125, %rd123, %rd124;
	add.s64 	%rd26, %rd125, %rd73;
	ld.global.nc.f32 	%f13, [%rd26];
	@%p20 bra 	$L__BB167_20;
	@%p52 bra 	$L__BB167_15;
	mov.f32 	%f115, 0f00000000;
	mul.rn.f32 	%f218, %f7, %f115;
	mov.b32 	%r284, 0;
	bra.uni 	$L__BB167_20;
$L__BB167_15:
	mov.b32 	%r21, %f7;
	shr.u32 	%r22, %r21, 23;
	and.b32  	%r171, %r22, 224;
	add.s32 	%r172, %r171, -128;
	shl.b32 	%r173, %r21, 8;
	or.b32  	%r177, %r173, -2147483648;
	shr.u32 	%r24, %r172, 5;
	mov.b32 	%r281, 0;
	mov.u64 	%rd172, 0;
	mov.u64 	%rd128, __cudart_i2opi_f;
$L__BB167_16:
	.pragma "nounroll";
	add.s64 	%rd129, %rd128, %rd172;
	ld.global.nc.u32 	%r176, [%rd129];
	// begin inline asm
	{
	mad.lo.cc.u32   %r174, %r176, %r177, %r281;
	madc.hi.u32     %r281, %r176, %r177,  0;
	}
	// end inline asm
	add.s64 	%rd130, %rd12, %rd172;
	st.local.u32 	[%rd130], %r174;
	add.s64 	%rd172, %rd172, 4;
	cvt.u32.u64 	%r179, %rd172;
	setp.ne.s32 	%p28, %r179, 24;
	@%p28 bra 	$L__BB167_16;
	st.local.u32 	[%rd12+24], %r281;
	and.b32  	%r27, %r22, 31;
	mul.wide.u32 	%rd131, %r24, 4;
	sub.s64 	%rd29, %rd12, %rd131;
	ld.local.u32 	%r282, [%rd29+24];
	ld.local.u32 	%r283, [%rd29+20];
	setp.eq.s32 	%p29, %r27, 0;
	@%p29 bra 	$L__BB167_19;
	shl.b32 	%r180, %r283, %r27;
	shl.b32 	%r181, %r282, %r27;
	mov.b32 	%r182, 32;
	sub.s32 	%r183, %r182, %r27;
	shr.u32 	%r184, %r283, %r183;
	add.s32 	%r282, %r184, %r181;
	ld.local.u32 	%r185, [%rd29+16];
	shr.u32 	%r186, %r185, %r183;
	add.s32 	%r283, %r186, %r180;
$L__BB167_19:
	shr.u32 	%r187, %r282, 30;
	shr.u32 	%r188, %r283, 30;
	shl.b32 	%r189, %r282, 2;
	or.b32  	%r190, %r189, %r188;
	shl.b32 	%r191, %r283, 2;
	bfe.u32 	%r192, %r282, 29, 1;
	add.s32 	%r193, %r192, %r187;
	neg.s32 	%r194, %r193;
	setp.lt.s32 	%p30, %r21, 0;
	selp.b32 	%r284, %r194, %r193, %p30;
	xor.b32  	%r195, %r190, %r21;
	bfe.s32 	%r196, %r282, 29, 1;
	xor.b32  	%r197, %r196, %r190;
	xor.b32  	%r198, %r196, %r191;
	cvt.u64.u32 	%rd132, %r197;
	shl.b64 	%rd133, %rd132, 32;
	cvt.u64.u32 	%rd134, %r198;
	or.b64  	%rd135, %rd133, %rd134;
	cvt.rn.f64.s64 	%fd5, %rd135;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f113, %fd6;
	neg.f32 	%f114, %f113;
	setp.lt.s32 	%p31, %r195, 0;
	selp.f32 	%f218, %f114, %f113, %p31;
$L__BB167_20:
	ld.param.u64 	%rd41, [loop_add_multiply_fusion_19_param_12];
	ld.param.u64 	%rd43, [loop_add_multiply_fusion_19_param_11];
	ld.param.u64 	%rd45, [loop_add_multiply_fusion_19_param_10];
	ld.param.u64 	%rd47, [loop_add_multiply_fusion_19_param_9];
	ld.param.u64 	%rd48, [loop_add_multiply_fusion_19_param_4];
	and.b32  	%r201, %r276, 1;
	mul.lo.s64 	%rd136, %rd17, 9600;
	add.s64 	%rd137, %rd10, %rd136;
	mul.lo.s64 	%rd138, %rd18, 192;
	add.s64 	%rd139, %rd137, %rd138;
	mul.wide.u32 	%rd140, %r4, 24;
	add.s64 	%rd141, %rd139, %rd140;
	shl.b64 	%rd142, %rd22, 3;
	add.s64 	%rd143, %rd141, %rd142;
	mul.wide.u32 	%rd144, %r201, 4;
	add.s64 	%rd145, %rd143, %rd144;
	ld.global.nc.f32 	%f17, [%rd145];
	ld.global.nc.f32 	%f18, [%rd26+24];
	add.rn.f32 	%f19, %f7, %f7;
	mul.rn.f32 	%f116, %f19, 0f3F22F983;
	cvt.rni.s32.f32 	%r292, %f116;
	cvt.rn.f32.s32 	%f117, %r292;
	fma.rn.f32 	%f118, %f117, 0fBFC90FDA, %f19;
	fma.rn.f32 	%f119, %f117, 0fB3A22168, %f118;
	fma.rn.f32 	%f220, %f117, 0fA7C234C5, %f119;
	abs.f32 	%f21, %f19;
	setp.ltu.f32 	%p32, %f21, 0f47CE4780;
	setp.neu.f32 	%p53, %f21, 0f7F800000;
	mov.u32 	%r288, %r292;
	mov.f32 	%f219, %f220;
	@%p32 bra 	$L__BB167_28;
	@%p53 bra 	$L__BB167_23;
	mov.f32 	%f122, 0f00000000;
	mul.rn.f32 	%f219, %f19, %f122;
	mov.b32 	%r288, 0;
	bra.uni 	$L__BB167_28;
$L__BB167_23:
	mov.b32 	%r37, %f19;
	shr.u32 	%r38, %r37, 23;
	and.b32  	%r203, %r38, 224;
	add.s32 	%r204, %r203, -128;
	shl.b32 	%r205, %r37, 8;
	or.b32  	%r209, %r205, -2147483648;
	shr.u32 	%r40, %r204, 5;
	mov.b32 	%r285, 0;
	mov.u64 	%rd173, 0;
	mov.u64 	%rd147, __cudart_i2opi_f;
$L__BB167_24:
	.pragma "nounroll";
	add.s64 	%rd148, %rd147, %rd173;
	ld.global.nc.u32 	%r208, [%rd148];
	// begin inline asm
	{
	mad.lo.cc.u32   %r206, %r208, %r209, %r285;
	madc.hi.u32     %r285, %r208, %r209,  0;
	}
	// end inline asm
	add.s64 	%rd149, %rd12, %rd173;
	st.local.u32 	[%rd149], %r206;
	add.s64 	%rd173, %rd173, 4;
	cvt.u32.u64 	%r211, %rd173;
	setp.ne.s32 	%p34, %r211, 24;
	@%p34 bra 	$L__BB167_24;
	st.local.u32 	[%rd12+24], %r285;
	and.b32  	%r43, %r38, 31;
	mul.wide.u32 	%rd150, %r40, 4;
	sub.s64 	%rd32, %rd12, %rd150;
	ld.local.u32 	%r286, [%rd32+24];
	ld.local.u32 	%r287, [%rd32+20];
	setp.eq.s32 	%p35, %r43, 0;
	@%p35 bra 	$L__BB167_27;
	shl.b32 	%r212, %r287, %r43;
	shl.b32 	%r213, %r286, %r43;
	mov.b32 	%r214, 32;
	sub.s32 	%r215, %r214, %r43;
	shr.u32 	%r216, %r287, %r215;
	add.s32 	%r286, %r216, %r213;
	ld.local.u32 	%r217, [%rd32+16];
	shr.u32 	%r218, %r217, %r215;
	add.s32 	%r287, %r218, %r212;
$L__BB167_27:
	shr.u32 	%r219, %r286, 30;
	shr.u32 	%r220, %r287, 30;
	shl.b32 	%r221, %r286, 2;
	or.b32  	%r222, %r221, %r220;
	shl.b32 	%r223, %r287, 2;
	bfe.u32 	%r224, %r286, 29, 1;
	add.s32 	%r225, %r224, %r219;
	neg.s32 	%r226, %r225;
	setp.lt.s32 	%p36, %r37, 0;
	selp.b32 	%r288, %r226, %r225, %p36;
	xor.b32  	%r227, %r222, %r37;
	bfe.s32 	%r228, %r286, 29, 1;
	xor.b32  	%r229, %r228, %r222;
	xor.b32  	%r230, %r228, %r223;
	cvt.u64.u32 	%rd151, %r229;
	shl.b64 	%rd152, %rd151, 32;
	cvt.u64.u32 	%rd153, %r230;
	or.b64  	%rd154, %rd152, %rd153;
	cvt.rn.f64.s64 	%fd7, %rd154;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f120, %fd8;
	neg.f32 	%f121, %f120;
	setp.lt.s32 	%p37, %r227, 0;
	selp.f32 	%f219, %f121, %f120, %p37;
$L__BB167_28:
	cvta.to.global.u64 	%rd1, %rd41;
	cvta.to.global.u64 	%rd2, %rd43;
	cvta.to.global.u64 	%rd3, %rd45;
	cvta.to.global.u64 	%rd4, %rd47;
	cvta.to.global.u64 	%rd8, %rd48;
	@%p32 bra 	$L__BB167_36;
	@%p53 bra 	$L__BB167_31;
	mov.f32 	%f125, 0f00000000;
	mul.rn.f32 	%f220, %f19, %f125;
	mov.b32 	%r292, 0;
	bra.uni 	$L__BB167_36;
$L__BB167_31:
	mov.b32 	%r52, %f19;
	shr.u32 	%r53, %r52, 23;
	and.b32  	%r233, %r53, 224;
	add.s32 	%r234, %r233, -128;
	shl.b32 	%r235, %r52, 8;
	or.b32  	%r239, %r235, -2147483648;
	shr.u32 	%r55, %r234, 5;
	mov.b32 	%r289, 0;
	mov.u64 	%rd174, 0;
	mov.u64 	%rd156, __cudart_i2opi_f;
$L__BB167_32:
	.pragma "nounroll";
	add.s64 	%rd157, %rd156, %rd174;
	ld.global.nc.u32 	%r238, [%rd157];
	// begin inline asm
	{
	mad.lo.cc.u32   %r236, %r238, %r239, %r289;
	madc.hi.u32     %r289, %r238, %r239,  0;
	}
	// end inline asm
	add.s64 	%rd158, %rd12, %rd174;
	st.local.u32 	[%rd158], %r236;
	add.s64 	%rd174, %rd174, 4;
	cvt.u32.u64 	%r241, %rd174;
	setp.ne.s32 	%p40, %r241, 24;
	@%p40 bra 	$L__BB167_32;
	st.local.u32 	[%rd12+24], %r289;
	and.b32  	%r58, %r53, 31;
	mul.wide.u32 	%rd159, %r55, 4;
	sub.s64 	%rd35, %rd12, %rd159;
	ld.local.u32 	%r290, [%rd35+24];
	ld.local.u32 	%r291, [%rd35+20];
	setp.eq.s32 	%p41, %r58, 0;
	@%p41 bra 	$L__BB167_35;
	shl.b32 	%r242, %r291, %r58;
	shl.b32 	%r243, %r290, %r58;
	mov.b32 	%r244, 32;
	sub.s32 	%r245, %r244, %r58;
	shr.u32 	%r246, %r291, %r245;
	add.s32 	%r290, %r246, %r243;
	ld.local.u32 	%r247, [%rd35+16];
	shr.u32 	%r248, %r247, %r245;
	add.s32 	%r291, %r248, %r242;
$L__BB167_35:
	shr.u32 	%r249, %r290, 30;
	shr.u32 	%r250, %r291, 30;
	shl.b32 	%r251, %r290, 2;
	or.b32  	%r252, %r251, %r250;
	shl.b32 	%r253, %r291, 2;
	bfe.u32 	%r254, %r290, 29, 1;
	add.s32 	%r255, %r254, %r249;
	neg.s32 	%r256, %r255;
	setp.lt.s32 	%p42, %r52, 0;
	selp.b32 	%r292, %r256, %r255, %p42;
	xor.b32  	%r257, %r252, %r52;
	bfe.s32 	%r258, %r290, 29, 1;
	xor.b32  	%r259, %r258, %r252;
	xor.b32  	%r260, %r258, %r253;
	cvt.u64.u32 	%rd160, %r259;
	shl.b64 	%rd161, %rd160, 32;
	cvt.u64.u32 	%rd162, %r260;
	or.b64  	%rd163, %rd161, %rd162;
	cvt.rn.f64.s64 	%fd9, %rd163;
	mul.rn.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f123, %fd10;
	neg.f32 	%f124, %f123;
	setp.lt.s32 	%p43, %r257, 0;
	selp.f32 	%f220, %f124, %f123, %p43;
$L__BB167_36:
	add.s32 	%r262, %r288, 1;
	and.b32  	%r263, %r262, 2;
	setp.eq.s32 	%p44, %r263, 0;
	and.b32  	%r264, %r288, 1;
	setp.eq.b32 	%p45, %r264, 1;
	mul.rn.f32 	%f126, %f219, %f219;
	fma.rn.f32 	%f127, %f126, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f128, 0fB94D4153, %f127, %p45;
	selp.f32 	%f129, 0f3C0885E4, 0f3D2AAABB, %p45;
	fma.rn.f32 	%f130, %f128, %f126, %f129;
	selp.f32 	%f131, 0fBE2AAAA8, 0fBEFFFFFF, %p45;
	fma.rn.f32 	%f132, %f130, %f126, %f131;
	selp.f32 	%f133, %f219, 0f3F800000, %p45;
	fma.rn.f32 	%f134, %f126, %f133, 0f00000000;
	fma.rn.f32 	%f135, %f132, %f134, %f133;
	mov.f32 	%f136, 0f00000000;
	sub.rn.f32 	%f137, %f136, %f135;
	selp.f32 	%f138, %f135, %f137, %p44;
	fma.rn.f32 	%f139, %f1, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f140, %f139;
	fma.rm.f32 	%f143, %f140, %f44, %f43;
	add.rn.f32 	%f144, %f143, 0fCB40007F;
	neg.f32 	%f145, %f144;
	fma.rn.f32 	%f146, %f1, 0f3FB8AA3B, %f145;
	fma.rn.f32 	%f147, %f1, 0f32A57060, %f146;
	ex2.approx.ftz.f32 	%f148, %f147;
	mov.b32 	%r265, %f143;
	shl.b32 	%r266, %r265, 23;
	mov.b32 	%f149, %r266;
	mul.rn.f32 	%f150, %f148, %f149;
	add.s32 	%r267, %r280, 1;
	and.b32  	%r268, %r267, 2;
	setp.eq.s32 	%p46, %r268, 0;
	and.b32  	%r269, %r280, 1;
	setp.eq.b32 	%p47, %r269, 1;
	mul.rn.f32 	%f151, %f217, %f217;
	fma.rn.f32 	%f152, %f151, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f153, 0fB94D4153, %f152, %p47;
	selp.f32 	%f154, 0f3C0885E4, 0f3D2AAABB, %p47;
	fma.rn.f32 	%f155, %f153, %f151, %f154;
	selp.f32 	%f156, 0fBE2AAAA8, 0fBEFFFFFF, %p47;
	fma.rn.f32 	%f157, %f155, %f151, %f156;
	selp.f32 	%f158, %f217, 0f3F800000, %p47;
	fma.rn.f32 	%f159, %f151, %f158, 0f00000000;
	fma.rn.f32 	%f160, %f157, %f159, %f158;
	sub.rn.f32 	%f161, %f136, %f160;
	selp.f32 	%f162, %f160, %f161, %p46;
	mul.rn.f32 	%f163, %f13, %f162;
	and.b32  	%r270, %r284, 2;
	setp.eq.s32 	%p48, %r270, 0;
	and.b32  	%r271, %r284, 1;
	setp.eq.b32 	%p49, %r271, 1;
	mul.rn.f32 	%f164, %f218, %f218;
	fma.rn.f32 	%f165, %f164, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f166, %f165, 0fB94D4153, %p49;
	selp.f32 	%f167, 0f3D2AAABB, 0f3C0885E4, %p49;
	fma.rn.f32 	%f168, %f166, %f164, %f167;
	selp.f32 	%f169, 0fBEFFFFFF, 0fBE2AAAA8, %p49;
	fma.rn.f32 	%f170, %f168, %f164, %f169;
	selp.f32 	%f171, 0f3F800000, %f218, %p49;
	fma.rn.f32 	%f172, %f164, %f171, 0f00000000;
	fma.rn.f32 	%f173, %f170, %f172, %f171;
	sub.rn.f32 	%f174, %f136, %f173;
	selp.f32 	%f175, %f173, %f174, %p48;
	mul.rn.f32 	%f176, %f17, %f175;
	add.rn.f32 	%f177, %f163, %f176;
	mul.rn.f32 	%f178, %f177, %f150;
	add.rn.f32 	%f179, %f18, %f178;
	mul.rn.f32 	%f180, %f138, %f179;
	fma.rn.f32 	%f181, %f2, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f182, %f181;
	fma.rm.f32 	%f183, %f182, %f44, %f43;
	add.rn.f32 	%f184, %f183, 0fCB40007F;
	neg.f32 	%f185, %f184;
	fma.rn.f32 	%f186, %f2, 0f3FB8AA3B, %f185;
	fma.rn.f32 	%f187, %f2, 0f32A57060, %f186;
	ex2.approx.ftz.f32 	%f188, %f187;
	mov.b32 	%r272, %f183;
	shl.b32 	%r273, %r272, 23;
	mov.b32 	%f189, %r273;
	mul.rn.f32 	%f190, %f188, %f189;
	add.rn.f32 	%f191, %f213, %f214;
	add.rn.f32 	%f192, %f191, %f215;
	add.rn.f32 	%f193, %f192, %f216;
	mul.rn.f32 	%f194, %f193, %f190;
	mul.rn.f32 	%f195, %f194, %f179;
	mul.rn.f32 	%f196, %f220, %f220;
	and.b32  	%r274, %r292, 1;
	setp.eq.b32 	%p50, %r274, 1;
	selp.f32 	%f197, 0f3F800000, %f220, %p50;
	fma.rn.f32 	%f198, %f196, %f197, 0f00000000;
	fma.rn.f32 	%f199, %f196, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f200, %f199, 0fB94D4153, %p50;
	selp.f32 	%f201, 0f3D2AAABB, 0f3C0885E4, %p50;
	fma.rn.f32 	%f202, %f200, %f196, %f201;
	selp.f32 	%f203, 0fBEFFFFFF, 0fBE2AAAA8, %p50;
	fma.rn.f32 	%f204, %f202, %f196, %f203;
	fma.rn.f32 	%f205, %f204, %f198, %f197;
	and.b32  	%r275, %r292, 2;
	setp.eq.s32 	%p51, %r275, 0;
	sub.rn.f32 	%f206, %f136, %f205;
	selp.f32 	%f207, %f205, %f206, %p51;
	mul.wide.u32 	%rd164, %r1, 4;
	add.s64 	%rd165, %rd8, %rd164;
	ld.global.nc.f32 	%f208, [%rd165];
	mul.rn.f32 	%f209, %f208, %f207;
	add.rn.f32 	%f210, %f180, %f209;
	mul.rn.f32 	%f211, %f193, %f210;
	mul.rn.f32 	%f212, %f194, %f208;
	add.s64 	%rd166, %rd4, %rd164;
	st.global.f32 	[%rd166], %f195;
	add.s64 	%rd167, %rd3, %rd164;
	st.global.f32 	[%rd167], %f211;
	add.s64 	%rd168, %rd2, %rd164;
	st.global.f32 	[%rd168], %f212;
	add.s64 	%rd169, %rd1, %rd164;
	st.global.f32 	[%rd169], %f193;
	ret;

}
	// .globl	loop_transpose_fusion_111
.visible .entry loop_transpose_fusion_111(
	.param .u64 loop_transpose_fusion_111_param_0,
	.param .u64 loop_transpose_fusion_111_param_1,
	.param .u64 loop_transpose_fusion_111_param_2,
	.param .u64 loop_transpose_fusion_111_param_3,
	.param .u64 loop_transpose_fusion_111_param_4
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot168[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<17>;
	.reg .b32 	%r<118>;
	.reg .f32 	%f<89>;
	.reg .b64 	%rd<59>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot168;
	ld.param.u64 	%rd15, [loop_transpose_fusion_111_param_0];
	ld.param.u64 	%rd16, [loop_transpose_fusion_111_param_4];
	ld.param.u64 	%rd17, [loop_transpose_fusion_111_param_1];
	ld.param.u64 	%rd18, [loop_transpose_fusion_111_param_3];
	ld.param.u64 	%rd19, [loop_transpose_fusion_111_param_2];
	cvta.to.global.u64 	%rd3, %rd19;
	cvta.to.global.u64 	%rd20, %rd17;
	cvta.to.global.u64 	%rd4, %rd15;
	add.u64 	%rd5, %SPL, 0;
	mov.u32 	%r34, %ctaid.x;
	shl.b32 	%r35, %r34, 7;
	mov.u32 	%r36, %tid.x;
	or.b32  	%r1, %r35, %r36;
	cvt.u16.u32 	%rs3, %r34;
	shr.u16 	%rs4, %rs3, 2;
	mul.hi.u16 	%rs5, %rs4, 5243;
	shr.u16 	%rs6, %rs5, 1;
	cvt.u16.u32 	%rs7, %r1;
	shr.u16 	%rs8, %rs7, 3;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	and.b16  	%rs11, %rs10, 63;
	shr.u32 	%r37, %r1, 2;
	cvt.u16.u32 	%rs12, %r37;
	shr.u16 	%rs13, %rs12, 1;
	mul.hi.u16 	%rs14, %rs13, 5243;
	shr.u16 	%rs15, %rs14, 1;
	mul.lo.s16 	%rs16, %rs15, 50;
	sub.s16 	%rs1, %rs12, %rs16;
	and.b32  	%r2, %r36, 3;
	and.b16  	%rs2, %rs5, 2046;
	cvt.u64.u16 	%rd7, %rs11;
	cvt.u32.u16 	%r38, %rs11;
	mul.wide.u32 	%rd23, %r38, 12;
	add.s64 	%rd24, %rd20, %rd23;
	cvt.u32.u16 	%r39, %rs6;
	mul.wide.u32 	%rd25, %r39, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f12, [%rd26];
	add.rn.f32 	%f13, %f12, %f12;
	add.rn.f32 	%f14, %f13, %f13;
	add.rn.f32 	%f1, %f14, %f14;
	mul.rn.f32 	%f15, %f1, 0f3F22F983;
	cvt.rni.s32.f32 	%r117, %f15;
	cvt.rn.f32.s32 	%f16, %r117;
	fma.rn.f32 	%f17, %f16, 0fBFC90FDA, %f1;
	fma.rn.f32 	%f18, %f16, 0fB3A22168, %f17;
	fma.rn.f32 	%f88, %f16, 0fA7C234C5, %f18;
	abs.f32 	%f3, %f1;
	setp.ltu.f32 	%p1, %f3, 0f47CE4780;
	setp.neu.f32 	%p17, %f3, 0f7F800000;
	mov.f32 	%f86, 0f00000000;
	mov.u32 	%r113, %r117;
	mov.f32 	%f87, %f88;
	@%p1 bra 	$L__BB168_8;
	@%p17 bra 	$L__BB168_3;
	mul.rn.f32 	%f87, %f1, %f86;
	mov.b32 	%r113, 0;
	bra.uni 	$L__BB168_8;
$L__BB168_3:
	mov.b32 	%r4, %f1;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r41, %r5, 224;
	add.s32 	%r42, %r41, -128;
	shl.b32 	%r43, %r4, 8;
	or.b32  	%r47, %r43, -2147483648;
	shr.u32 	%r7, %r42, 5;
	mov.b32 	%r110, 0;
	mov.u64 	%rd57, 0;
	mov.u64 	%rd28, __cudart_i2opi_f;
$L__BB168_4:
	.pragma "nounroll";
	add.s64 	%rd29, %rd28, %rd57;
	ld.global.nc.u32 	%r46, [%rd29];
	// begin inline asm
	{
	mad.lo.cc.u32   %r44, %r46, %r47, %r110;
	madc.hi.u32     %r110, %r46, %r47,  0;
	}
	// end inline asm
	add.s64 	%rd30, %rd5, %rd57;
	st.local.u32 	[%rd30], %r44;
	add.s64 	%rd57, %rd57, 4;
	cvt.u32.u64 	%r49, %rd57;
	setp.ne.s32 	%p3, %r49, 24;
	@%p3 bra 	$L__BB168_4;
	st.local.u32 	[%rd5+24], %r110;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd31, %r7, 4;
	sub.s64 	%rd10, %rd5, %rd31;
	ld.local.u32 	%r111, [%rd10+24];
	ld.local.u32 	%r112, [%rd10+20];
	setp.eq.s32 	%p4, %r10, 0;
	@%p4 bra 	$L__BB168_7;
	shl.b32 	%r50, %r112, %r10;
	shl.b32 	%r51, %r111, %r10;
	mov.b32 	%r52, 32;
	sub.s32 	%r53, %r52, %r10;
	shr.u32 	%r54, %r112, %r53;
	add.s32 	%r111, %r54, %r51;
	ld.local.u32 	%r55, [%rd10+16];
	shr.u32 	%r56, %r55, %r53;
	add.s32 	%r112, %r56, %r50;
$L__BB168_7:
	shr.u32 	%r57, %r111, 30;
	shr.u32 	%r58, %r112, 30;
	shl.b32 	%r59, %r111, 2;
	or.b32  	%r60, %r59, %r58;
	shl.b32 	%r61, %r112, 2;
	bfe.u32 	%r62, %r111, 29, 1;
	add.s32 	%r63, %r62, %r57;
	neg.s32 	%r64, %r63;
	setp.lt.s32 	%p5, %r4, 0;
	selp.b32 	%r113, %r64, %r63, %p5;
	xor.b32  	%r65, %r60, %r4;
	bfe.s32 	%r66, %r111, 29, 1;
	xor.b32  	%r67, %r66, %r60;
	xor.b32  	%r68, %r66, %r61;
	cvt.u64.u32 	%rd32, %r67;
	shl.b64 	%rd33, %rd32, 32;
	cvt.u64.u32 	%rd34, %r68;
	or.b64  	%rd35, %rd33, %rd34;
	cvt.rn.f64.s64 	%fd1, %rd35;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f19, %fd2;
	neg.f32 	%f20, %f19;
	setp.lt.s32 	%p6, %r65, 0;
	selp.f32 	%f87, %f20, %f19, %p6;
$L__BB168_8:
	cvta.to.global.u64 	%rd1, %rd16;
	cvta.to.global.u64 	%rd2, %rd18;
	shl.b64 	%rd36, %rd7, 2;
	add.s64 	%rd37, %rd3, %rd36;
	ld.global.nc.f32 	%f7, [%rd37];
	mul.lo.s64 	%rd38, %rd7, 4800;
	add.s64 	%rd39, %rd4, %rd38;
	cvt.u32.u16 	%r70, %rs1;
	mul.wide.u32 	%rd40, %r70, 96;
	add.s64 	%rd41, %rd39, %rd40;
	mul.wide.u32 	%rd42, %r2, 24;
	add.s64 	%rd43, %rd41, %rd42;
	cvt.u32.u16 	%r71, %rs2;
	mul.wide.u32 	%rd44, %r71, 4;
	add.s64 	%rd11, %rd43, %rd44;
	ld.global.nc.f32 	%f8, [%rd11+4];
	@%p1 bra 	$L__BB168_16;
	@%p17 bra 	$L__BB168_11;
	mul.rn.f32 	%f88, %f1, %f86;
	mov.b32 	%r117, 0;
	bra.uni 	$L__BB168_16;
$L__BB168_11:
	mov.b32 	%r19, %f1;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r73, %r20, 224;
	add.s32 	%r74, %r73, -128;
	shl.b32 	%r75, %r19, 8;
	or.b32  	%r79, %r75, -2147483648;
	shr.u32 	%r22, %r74, 5;
	mov.b32 	%r114, 0;
	mov.u64 	%rd58, 0;
	mov.u64 	%rd46, __cudart_i2opi_f;
$L__BB168_12:
	.pragma "nounroll";
	add.s64 	%rd47, %rd46, %rd58;
	ld.global.nc.u32 	%r78, [%rd47];
	// begin inline asm
	{
	mad.lo.cc.u32   %r76, %r78, %r79, %r114;
	madc.hi.u32     %r114, %r78, %r79,  0;
	}
	// end inline asm
	add.s64 	%rd48, %rd5, %rd58;
	st.local.u32 	[%rd48], %r76;
	add.s64 	%rd58, %rd58, 4;
	cvt.u32.u64 	%r81, %rd58;
	setp.ne.s32 	%p9, %r81, 24;
	@%p9 bra 	$L__BB168_12;
	st.local.u32 	[%rd5+24], %r114;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd49, %r22, 4;
	sub.s64 	%rd14, %rd5, %rd49;
	ld.local.u32 	%r115, [%rd14+24];
	ld.local.u32 	%r116, [%rd14+20];
	setp.eq.s32 	%p10, %r25, 0;
	@%p10 bra 	$L__BB168_15;
	shl.b32 	%r82, %r116, %r25;
	shl.b32 	%r83, %r115, %r25;
	mov.b32 	%r84, 32;
	sub.s32 	%r85, %r84, %r25;
	shr.u32 	%r86, %r116, %r85;
	add.s32 	%r115, %r86, %r83;
	ld.local.u32 	%r87, [%rd14+16];
	shr.u32 	%r88, %r87, %r85;
	add.s32 	%r116, %r88, %r82;
$L__BB168_15:
	shr.u32 	%r89, %r115, 30;
	shr.u32 	%r90, %r116, 30;
	shl.b32 	%r91, %r115, 2;
	or.b32  	%r92, %r91, %r90;
	shl.b32 	%r93, %r116, 2;
	bfe.u32 	%r94, %r115, 29, 1;
	add.s32 	%r95, %r94, %r89;
	neg.s32 	%r96, %r95;
	setp.lt.s32 	%p11, %r19, 0;
	selp.b32 	%r117, %r96, %r95, %p11;
	xor.b32  	%r97, %r92, %r19;
	bfe.s32 	%r98, %r115, 29, 1;
	xor.b32  	%r99, %r98, %r92;
	xor.b32  	%r100, %r98, %r93;
	cvt.u64.u32 	%rd50, %r99;
	shl.b64 	%rd51, %rd50, 32;
	cvt.u64.u32 	%rd52, %r100;
	or.b64  	%rd53, %rd51, %rd52;
	cvt.rn.f64.s64 	%fd3, %rd53;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f22, %fd4;
	neg.f32 	%f23, %f22;
	setp.lt.s32 	%p12, %r97, 0;
	selp.f32 	%f88, %f23, %f22, %p12;
$L__BB168_16:
	and.b32  	%r102, %r113, 2;
	setp.eq.s32 	%p13, %r102, 0;
	and.b32  	%r103, %r113, 1;
	setp.eq.b32 	%p14, %r103, 1;
	mul.rn.f32 	%f25, %f87, %f87;
	fma.rn.f32 	%f26, %f25, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f27, %f26, 0fB94D4153, %p14;
	selp.f32 	%f28, 0f3D2AAABB, 0f3C0885E4, %p14;
	fma.rn.f32 	%f29, %f27, %f25, %f28;
	selp.f32 	%f30, 0fBEFFFFFF, 0fBE2AAAA8, %p14;
	fma.rn.f32 	%f31, %f29, %f25, %f30;
	selp.f32 	%f32, 0f3F800000, %f87, %p14;
	fma.rn.f32 	%f33, %f25, %f32, 0f00000000;
	fma.rn.f32 	%f34, %f31, %f33, %f32;
	sub.rn.f32 	%f36, %f86, %f34;
	selp.f32 	%f37, %f34, %f36, %p13;
	fma.rn.f32 	%f38, %f7, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f39, %f38;
	mov.f32 	%f40, 0f4B400001;
	mov.f32 	%f41, 0f437C0000;
	fma.rm.f32 	%f42, %f39, %f41, %f40;
	add.rn.f32 	%f43, %f42, 0fCB40007F;
	neg.f32 	%f44, %f43;
	fma.rn.f32 	%f45, %f7, 0f3FB8AA3B, %f44;
	fma.rn.f32 	%f46, %f7, 0f32A57060, %f45;
	ex2.approx.ftz.f32 	%f47, %f46;
	mov.b32 	%r104, %f42;
	shl.b32 	%r105, %r104, 23;
	mov.b32 	%f48, %r105;
	mul.rn.f32 	%f49, %f47, %f48;
	neg.f32 	%f50, %f49;
	sub.rn.f32 	%f51, %f50, %f49;
	add.rn.f32 	%f52, %f51, %f51;
	add.rn.f32 	%f53, %f52, %f52;
	add.rn.f32 	%f54, %f53, %f53;
	add.rn.f32 	%f55, %f54, %f54;
	add.rn.f32 	%f56, %f55, %f55;
	add.rn.f32 	%f57, %f56, %f56;
	fma.rn.f32 	%f58, %f57, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f59, %f58;
	fma.rm.f32 	%f60, %f59, %f41, %f40;
	add.rn.f32 	%f61, %f60, 0fCB40007F;
	neg.f32 	%f62, %f61;
	fma.rn.f32 	%f63, %f57, 0f3FB8AA3B, %f62;
	fma.rn.f32 	%f64, %f57, 0f32A57060, %f63;
	ex2.approx.ftz.f32 	%f65, %f64;
	mov.b32 	%r106, %f60;
	shl.b32 	%r107, %r106, 23;
	mov.b32 	%f66, %r107;
	mul.rn.f32 	%f67, %f65, %f66;
	mul.rn.f32 	%f68, %f8, %f67;
	mul.rn.f32 	%f69, %f37, %f68;
	mul.rn.f32 	%f70, %f88, %f88;
	and.b32  	%r108, %r117, 1;
	setp.eq.b32 	%p15, %r108, 1;
	selp.f32 	%f71, 0f3F800000, %f88, %p15;
	fma.rn.f32 	%f72, %f70, %f71, 0f00000000;
	fma.rn.f32 	%f73, %f70, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f74, %f73, 0fB94D4153, %p15;
	selp.f32 	%f75, 0f3D2AAABB, 0f3C0885E4, %p15;
	fma.rn.f32 	%f76, %f74, %f70, %f75;
	selp.f32 	%f77, 0fBEFFFFFF, 0fBE2AAAA8, %p15;
	fma.rn.f32 	%f78, %f76, %f70, %f77;
	fma.rn.f32 	%f79, %f78, %f72, %f71;
	and.b32  	%r109, %r117, 2;
	setp.eq.s32 	%p16, %r109, 0;
	sub.rn.f32 	%f80, %f86, %f79;
	selp.f32 	%f81, %f79, %f80, %p16;
	ld.global.nc.f32 	%f82, [%rd11];
	mul.rn.f32 	%f83, %f82, %f67;
	neg.f32 	%f84, %f81;
	mul.rn.f32 	%f85, %f83, %f84;
	mul.wide.u32 	%rd54, %r1, 4;
	add.s64 	%rd55, %rd2, %rd54;
	st.global.f32 	[%rd55], %f69;
	add.s64 	%rd56, %rd1, %rd54;
	st.global.f32 	[%rd56], %f85;
	ret;

}
	// .globl	loop_broadcast_fusion_38
.visible .entry loop_broadcast_fusion_38(
	.param .u64 loop_broadcast_fusion_38_param_0
)
.reqntid 1024, 1, 1
{
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [loop_broadcast_fusion_38_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 10;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.wide.u32 	%rd3, %r4, 4;
	add.s64 	%rd4, %rd2, %rd3;
	mov.b32 	%r5, 0;
	st.global.u32 	[%rd4], %r5;
	ret;

}
	// .globl	input_scatter_fusion_250
.visible .entry input_scatter_fusion_250(
	.param .u64 input_scatter_fusion_250_param_0,
	.param .u64 input_scatter_fusion_250_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<16>;
	.reg .b32 	%r<10>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_250_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_250_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r2, 3;
	shr.u32 	%r6, %r4, 2;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r4;
	shr.u16 	%rs8, %rs7, 3;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	and.b16  	%rs11, %rs10, 63;
	cvt.u16.u32 	%rs12, %r1;
	shr.u16 	%rs13, %rs12, 2;
	mul.hi.u16 	%rs14, %rs13, 5243;
	and.b16  	%rs15, %rs14, 2046;
	cvt.u32.u16 	%r7, %rs15;
	mul.wide.u32 	%rd5, %r7, 51200;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r8, %rs11;
	mul.wide.u32 	%rd7, %r8, 800;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r9, %rs6;
	mul.wide.u32 	%rd9, %r9, 16;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+51200];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+51200], %f3;
	ret;

}
	// .globl	wrapped_transpose_256
.visible .entry wrapped_transpose_256(
	.param .u64 wrapped_transpose_256_param_0,
	.param .u64 wrapped_transpose_256_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [wrapped_transpose_256_param_0];
	ld.param.u64 	%rd2, [wrapped_transpose_256_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.hi.u32 	%r5, %r4, 458129845;
	bfe.u32 	%r6, %r5, 7, 6;
	mul.hi.u32 	%r7, %r4, -1431655765;
	shr.u32 	%r8, %r7, 4;
	cvt.u16.u32 	%rs1, %r8;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	shr.u32 	%r9, %r7, 2;
	bfe.u32 	%r10, %r7, 2, 2;
	mul.lo.s32 	%r11, %r9, 6;
	sub.s32 	%r12, %r4, %r11;
	mul.wide.u32 	%rd5, %r12, 51200;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r6, 800;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r13, %rs6;
	mul.wide.u32 	%rd9, %r13, 16;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r10, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	st.global.f32 	[%rd14], %f1;
	ret;

}
	// .globl	input_scatter_fusion_251
.visible .entry input_scatter_fusion_251(
	.param .u64 input_scatter_fusion_251_param_0,
	.param .u64 input_scatter_fusion_251_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<16>;
	.reg .b32 	%r<10>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_251_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_251_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r2, 3;
	shr.u32 	%r6, %r4, 2;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r4;
	shr.u16 	%rs8, %rs7, 3;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	and.b16  	%rs11, %rs10, 63;
	cvt.u16.u32 	%rs12, %r1;
	shr.u16 	%rs13, %rs12, 2;
	mul.hi.u16 	%rs14, %rs13, 5243;
	and.b16  	%rs15, %rs14, 2046;
	cvt.u32.u16 	%r7, %rs15;
	mul.wide.u32 	%rd5, %r7, 51200;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r8, %rs11;
	mul.wide.u32 	%rd7, %r8, 800;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r9, %rs6;
	mul.wide.u32 	%rd9, %r9, 16;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	input_add_reduce_fusion_39
.visible .entry input_add_reduce_fusion_39(
	.param .u64 input_add_reduce_fusion_39_param_0,
	.param .u64 input_add_reduce_fusion_39_param_1,
	.param .u64 input_add_reduce_fusion_39_param_2,
	.param .u64 input_add_reduce_fusion_39_param_3,
	.param .u64 input_add_reduce_fusion_39_param_4,
	.param .u64 input_add_reduce_fusion_39_param_5,
	.param .u64 input_add_reduce_fusion_39_param_6,
	.param .u64 input_add_reduce_fusion_39_param_7,
	.param .u64 input_add_reduce_fusion_39_param_8
)
.reqntid 1024, 1, 1
{
	.local .align 4 .b8 	__local_depot173[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<35>;
	.reg .b16 	%rs<23>;
	.reg .b32 	%r<140>;
	.reg .f32 	%f<188>;
	.reg .b64 	%rd<158>;
	.reg .f64 	%fd<5>;
	// demoted variable
	.shared .align 4 .b8 shared_cache12[4224];
	mov.u64 	%SPL, __local_depot173;
	ld.param.u64 	%rd29, [input_add_reduce_fusion_39_param_0];
	ld.param.u64 	%rd30, [input_add_reduce_fusion_39_param_8];
	cvta.to.global.u64 	%rd1, %rd30;
	ld.param.u64 	%rd31, [input_add_reduce_fusion_39_param_1];
	ld.param.u64 	%rd32, [input_add_reduce_fusion_39_param_7];
	cvta.to.global.u64 	%rd2, %rd32;
	ld.param.u64 	%rd33, [input_add_reduce_fusion_39_param_2];
	ld.param.u64 	%rd34, [input_add_reduce_fusion_39_param_6];
	cvta.to.global.u64 	%rd3, %rd34;
	ld.param.u64 	%rd35, [input_add_reduce_fusion_39_param_3];
	ld.param.u64 	%rd36, [input_add_reduce_fusion_39_param_5];
	cvta.to.global.u64 	%rd4, %rd36;
	ld.param.u64 	%rd37, [input_add_reduce_fusion_39_param_4];
	cvta.to.global.u64 	%rd38, %rd37;
	cvta.to.global.u64 	%rd5, %rd35;
	cvta.to.global.u64 	%rd6, %rd33;
	cvta.to.global.u64 	%rd39, %rd31;
	cvta.to.global.u64 	%rd7, %rd29;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r40, %tid.x;
	mov.u32 	%r41, %ctaid.x;
	shr.u32 	%r1, %r40, 5;
	and.b32  	%r2, %r40, 31;
	and.b32  	%r42, %r41, 1;
	shr.u32 	%r43, %r41, 1;
	setp.eq.s32 	%p4, %r42, 0;
	selp.b32 	%r3, 32, 16, %p4;
	shl.b32 	%r4, %r42, 5;
	or.b32  	%r5, %r4, %r2;
	cvt.u16.u32 	%rs1, %r5;
	mul.lo.s16 	%rs2, %rs1, 43;
	shr.u16 	%rs3, %rs2, 8;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs5, 254;
	cvt.u32.u16 	%r44, %rs3;
	cvt.u64.u32 	%rd10, %r43;
	mul.wide.u32 	%rd42, %r43, 4;
	add.s64 	%rd11, %rd39, %rd42;
	add.s16 	%rs7, %rs3, -2;
	and.b16  	%rs8, %rs7, 128;
	and.b16  	%rs9, %rs3, 1;
	setp.eq.b16 	%p5, %rs9, 1;
	not.pred 	%p6, %p5;
	shr.u16 	%rs10, %rs8, 7;
	add.s16 	%rs11, %rs7, %rs10;
	cvt.s16.s8 	%rs12, %rs11;
	shr.s16 	%rs13, %rs12, 1;
	add.s32 	%r45, %r5, -12;
	setp.lt.u32 	%p7, %r45, 36;
	and.pred  	%p1, %p7, %p6;
	add.s16 	%rs14, %rs13, 1;
	cvt.s32.s16 	%r46, %rs14;
	cvt.u64.u32 	%rd12, %r46;
	cvt.u64.u16 	%rd43, %rs5;
	and.b64  	%rd13, %rd43, 255;
	add.s32 	%r47, %r44, -1;
	and.b32  	%r48, %r47, 1;
	setp.eq.b32 	%p8, %r48, 1;
	not.pred 	%p9, %p8;
	cvt.s8.s32 	%rs15, %r47;
	cvt.u16.u32 	%rs16, %r47;
	and.b16  	%rs17, %rs16, 128;
	shr.u16 	%rs18, %rs17, 7;
	add.s16 	%rs19, %rs15, %rs18;
	shr.s16 	%rs20, %rs19, 1;
	cvt.s32.s16 	%r49, %rs20;
	add.s32 	%r50, %r5, -6;
	setp.lt.u32 	%p10, %r50, 48;
	and.pred  	%p2, %p10, %p9;
	cvt.u64.u32 	%rd14, %r49;
	shr.u16 	%rs21, %rs2, 9;
	setp.lt.u32 	%p11, %r5, 48;
	and.pred  	%p3, %p11, %p6;
	cvt.u64.u16 	%rd15, %rs21;
	shr.u16 	%rs22, %rs6, 1;
	cvt.u32.u16 	%r51, %rs22;
	mul.wide.u32 	%rd44, %r51, 4;
	mul.wide.u32 	%rd45, %r43, 12;
	add.s64 	%rd46, %rd38, %rd45;
	add.s64 	%rd16, %rd46, %rd44;
	mul.wide.u32 	%rd17, %r44, 2;
	cvt.u64.u16 	%rd18, %rs3;
	mov.f32 	%f1, 0f00000000;
	mov.f32 	%f46, 0f4B400001;
	mov.f32 	%f47, 0f437C0000;
	mul.lo.s64 	%rd51, %rd12, 24;
	mul.lo.s64 	%rd58, %rd14, 24;
	mul.lo.s64 	%rd99, %rd17, 24;
	mul.lo.s64 	%rd136, %rd18, 24;
	mov.u32 	%r131, %r1;
	bra.uni 	$L__BB173_1;
$L__BB173_13:
	add.rn.f32 	%f1, %f1, %f119;
	add.rn.f32 	%f15, %f182, %f183;
	add.rn.f32 	%f17, %f15, %f184;
	add.rn.f32 	%f164, %f17, %f185;
	mul.lo.s64 	%rd132, %rd10, 9600;
	add.s64 	%rd133, %rd1, %rd132;
	mul.lo.s64 	%rd134, %rd19, 192;
	add.s64 	%rd135, %rd133, %rd134;
	add.s64 	%rd137, %rd135, %rd136;
	add.s64 	%rd139, %rd137, %rd53;
	st.global.f32 	[%rd139], %f164;
$L__BB173_2:
	add.s32 	%r7, %r131, 32;
	setp.lt.u32 	%p31, %r131, 18;
	mov.u32 	%r131, %r7;
	@%p31 bra 	$L__BB173_1;
	bra.uni 	$L__BB173_3;
$L__BB173_1:
	setp.lt.u32 	%p12, %r2, %r3;
	@%p12 bra 	$L__BB173_5;
	bra.uni 	$L__BB173_2;
$L__BB173_5:
	ld.global.nc.f32 	%f43, [%rd11];
	mul.lo.s64 	%rd47, %rd10, 4800;
	add.s64 	%rd48, %rd6, %rd47;
	mul.wide.u32 	%rd49, %r131, 96;
	add.s64 	%rd50, %rd48, %rd49;
	add.s64 	%rd52, %rd50, %rd51;
	shl.b64 	%rd53, %rd13, 2;
	add.s64 	%rd20, %rd52, %rd53;
	mov.f32 	%f185, 0f00000000;
	mov.f32 	%f178, %f185;
	@%p1 bra 	$L__BB173_14;
	bra.uni 	$L__BB173_6;
$L__BB173_14:
	ld.global.nc.f32 	%f178, [%rd20];
$L__BB173_6:
	fma.rn.f32 	%f44, %f43, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f45, %f44;
	fma.rm.f32 	%f48, %f45, %f47, %f46;
	add.rn.f32 	%f49, %f48, 0fCB40007F;
	neg.f32 	%f50, %f49;
	fma.rn.f32 	%f51, %f43, 0f3FB8AA3B, %f50;
	fma.rn.f32 	%f52, %f43, 0f32A57060, %f51;
	mov.b32 	%r52, %f48;
	shl.b32 	%r53, %r52, 23;
	mov.b32 	%f53, %r53;
	ex2.approx.ftz.f32 	%f54, %f52;
	mul.rn.f32 	%f55, %f54, %f53;
	neg.f32 	%f56, %f55;
	sub.rn.f32 	%f57, %f56, %f55;
	add.rn.f32 	%f58, %f57, %f57;
	add.rn.f32 	%f59, %f58, %f58;
	add.rn.f32 	%f60, %f59, %f59;
	add.rn.f32 	%f61, %f60, %f60;
	add.rn.f32 	%f4, %f61, %f61;
	fma.rn.f32 	%f62, %f4, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f63, %f62;
	fma.rm.f32 	%f64, %f63, %f47, %f46;
	add.rn.f32 	%f65, %f64, 0fCB40007F;
	neg.f32 	%f66, %f65;
	cvt.u64.u32 	%rd19, %r131;
	add.s64 	%rd55, %rd5, %rd47;
	mul.lo.s64 	%rd56, %rd19, 96;
	add.s64 	%rd57, %rd55, %rd56;
	add.s64 	%rd59, %rd57, %rd58;
	add.s64 	%rd21, %rd59, %rd53;
	mov.f32 	%f179, %f185;
	@%p2 bra 	$L__BB173_15;
	bra.uni 	$L__BB173_7;
$L__BB173_15:
	ld.global.nc.f32 	%f179, [%rd21];
$L__BB173_7:
	fma.rn.f32 	%f67, %f4, 0f3FB8AA3B, %f66;
	mov.u64 	%rd155, __cudart_i2opi_f;
	mov.f32 	%f180, %f185;
	@%p3 bra 	$L__BB173_16;
	bra.uni 	$L__BB173_8;
$L__BB173_16:
	add.s64 	%rd62, %rd4, %rd47;
	add.s64 	%rd64, %rd62, %rd56;
	mul.lo.s64 	%rd65, %rd15, 24;
	add.s64 	%rd66, %rd64, %rd65;
	add.s64 	%rd68, %rd66, %rd53;
	ld.global.nc.f32 	%f73, [%rd68];
	add.s64 	%rd69, %rd3, %rd47;
	add.s64 	%rd70, %rd69, %rd56;
	add.s64 	%rd71, %rd70, %rd65;
	add.s64 	%rd72, %rd71, %rd53;
	ld.global.nc.f32 	%f74, [%rd72];
	add.rn.f32 	%f21, %f73, %f74;
	ld.global.nc.f32 	%f75, [%rd16];
	add.rn.f32 	%f76, %f75, %f75;
	add.rn.f32 	%f77, %f76, %f76;
	add.rn.f32 	%f22, %f77, %f77;
	mul.rn.f32 	%f78, %f22, 0f3F22F983;
	cvt.rni.s32.f32 	%r135, %f78;
	cvt.rn.f32.s32 	%f79, %r135;
	fma.rn.f32 	%f80, %f79, 0fBFC90FDA, %f22;
	fma.rn.f32 	%f81, %f79, 0fB3A22168, %f80;
	fma.rn.f32 	%f186, %f79, 0fA7C234C5, %f81;
	abs.f32 	%f24, %f22;
	setp.ltu.f32 	%p13, %f24, 0f47CE4780;
	@%p13 bra 	$L__BB173_24;
	setp.neu.f32 	%p14, %f24, 0f7F800000;
	@%p14 bra 	$L__BB173_19;
	mov.f32 	%f84, 0f00000000;
	mul.rn.f32 	%f186, %f22, %f84;
	mov.b32 	%r135, 0;
	bra.uni 	$L__BB173_24;
$L__BB173_19:
	mov.b32 	%r9, %f22;
	shr.u32 	%r10, %r9, 23;
	and.b32  	%r57, %r10, 224;
	add.s32 	%r58, %r57, -128;
	shl.b32 	%r59, %r9, 8;
	or.b32  	%r63, %r59, -2147483648;
	shr.u32 	%r12, %r58, 5;
	mov.b32 	%r132, 0;
	mov.u64 	%rd156, 0;
$L__BB173_20:
	.pragma "nounroll";
	add.s64 	%rd75, %rd155, %rd156;
	ld.global.nc.u32 	%r62, [%rd75];
	// begin inline asm
	{
	mad.lo.cc.u32   %r60, %r62, %r63, %r132;
	madc.hi.u32     %r132, %r62, %r63,  0;
	}
	// end inline asm
	add.s64 	%rd76, %rd8, %rd156;
	st.local.u32 	[%rd76], %r60;
	add.s64 	%rd156, %rd156, 4;
	cvt.u32.u64 	%r65, %rd156;
	setp.ne.s32 	%p15, %r65, 24;
	@%p15 bra 	$L__BB173_20;
	st.local.u32 	[%rd8+24], %r132;
	and.b32  	%r15, %r10, 31;
	mul.wide.u32 	%rd77, %r12, 4;
	sub.s64 	%rd25, %rd8, %rd77;
	ld.local.u32 	%r133, [%rd25+24];
	ld.local.u32 	%r134, [%rd25+20];
	setp.eq.s32 	%p16, %r15, 0;
	@%p16 bra 	$L__BB173_23;
	shl.b32 	%r66, %r134, %r15;
	shl.b32 	%r67, %r133, %r15;
	mov.b32 	%r68, 32;
	sub.s32 	%r69, %r68, %r15;
	shr.u32 	%r70, %r134, %r69;
	add.s32 	%r133, %r70, %r67;
	ld.local.u32 	%r71, [%rd25+16];
	shr.u32 	%r72, %r71, %r69;
	add.s32 	%r134, %r72, %r66;
$L__BB173_23:
	shr.u32 	%r73, %r133, 30;
	shr.u32 	%r74, %r134, 30;
	shl.b32 	%r75, %r133, 2;
	or.b32  	%r76, %r75, %r74;
	shl.b32 	%r77, %r134, 2;
	bfe.u32 	%r78, %r133, 29, 1;
	add.s32 	%r79, %r78, %r73;
	neg.s32 	%r80, %r79;
	setp.lt.s32 	%p17, %r9, 0;
	selp.b32 	%r135, %r80, %r79, %p17;
	xor.b32  	%r81, %r76, %r9;
	bfe.s32 	%r82, %r133, 29, 1;
	xor.b32  	%r83, %r82, %r76;
	xor.b32  	%r84, %r82, %r77;
	cvt.u64.u32 	%rd78, %r83;
	shl.b64 	%rd79, %rd78, 32;
	cvt.u64.u32 	%rd80, %r84;
	or.b64  	%rd81, %rd79, %rd80;
	cvt.rn.f64.s64 	%fd1, %rd81;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f82, %fd2;
	neg.f32 	%f83, %f82;
	setp.lt.s32 	%p18, %r81, 0;
	selp.f32 	%f186, %f83, %f82, %p18;
$L__BB173_24:
	add.s32 	%r86, %r135, 1;
	mul.rn.f32 	%f85, %f186, %f186;
	and.b32  	%r87, %r135, 1;
	setp.eq.b32 	%p19, %r87, 1;
	selp.f32 	%f86, %f186, 0f3F800000, %p19;
	fma.rn.f32 	%f87, %f85, %f86, 0f00000000;
	fma.rn.f32 	%f88, %f85, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f89, 0fB94D4153, %f88, %p19;
	selp.f32 	%f90, 0f3C0885E4, 0f3D2AAABB, %p19;
	fma.rn.f32 	%f91, %f89, %f85, %f90;
	selp.f32 	%f92, 0fBE2AAAA8, 0fBEFFFFFF, %p19;
	fma.rn.f32 	%f93, %f91, %f85, %f92;
	fma.rn.f32 	%f94, %f93, %f87, %f86;
	and.b32  	%r88, %r86, 2;
	setp.eq.s32 	%p20, %r88, 0;
	mov.f32 	%f95, 0f00000000;
	sub.rn.f32 	%f96, %f95, %f94;
	selp.f32 	%f97, %f94, %f96, %p20;
	add.rn.f32 	%f98, %f4, %f4;
	fma.rn.f32 	%f99, %f98, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f100, %f99;
	fma.rm.f32 	%f103, %f100, %f47, %f46;
	add.rn.f32 	%f104, %f103, 0fCB40007F;
	neg.f32 	%f105, %f104;
	fma.rn.f32 	%f106, %f98, 0f3FB8AA3B, %f105;
	fma.rn.f32 	%f107, %f98, 0f32A57060, %f106;
	mov.b32 	%r89, %f103;
	shl.b32 	%r90, %r89, 23;
	mov.b32 	%f108, %r90;
	ex2.approx.ftz.f32 	%f109, %f107;
	mul.rn.f32 	%f110, %f109, %f108;
	add.s64 	%rd87, %rd57, %rd65;
	add.s64 	%rd89, %rd87, %rd53;
	ld.global.nc.f32 	%f111, [%rd89];
	mul.rn.f32 	%f112, %f110, %f111;
	mul.rn.f32 	%f113, %f112, %f97;
	add.rn.f32 	%f180, %f21, %f113;
$L__BB173_8:
	fma.rn.f32 	%f68, %f4, 0f32A57060, %f67;
	setp.lt.u32 	%p21, %r5, 6;
	add.s64 	%rd93, %rd48, %rd56;
	add.s64 	%rd22, %rd93, %rd53;
	mov.f32 	%f181, %f185;
	@%p21 bra 	$L__BB173_25;
	bra.uni 	$L__BB173_9;
$L__BB173_25:
	ld.global.nc.f32 	%f181, [%rd22];
$L__BB173_9:
	mov.b32 	%r54, %f64;
	ex2.approx.ftz.f32 	%f70, %f68;
	add.rn.f32 	%f8, %f178, %f179;
	add.rn.f32 	%f10, %f8, %f180;
	mul.lo.s64 	%rd95, %rd10, 19200;
	add.s64 	%rd96, %rd7, %rd95;
	mul.lo.s64 	%rd97, %rd19, 384;
	add.s64 	%rd98, %rd96, %rd97;
	add.s64 	%rd100, %rd98, %rd99;
	add.s64 	%rd102, %rd100, %rd53;
	ld.global.nc.f32 	%f118, [%rd102];
	mov.f32 	%f182, %f185;
	@%p1 bra 	$L__BB173_26;
	bra.uni 	$L__BB173_10;
$L__BB173_26:
	ld.global.nc.f32 	%f182, [%rd20];
$L__BB173_10:
	shl.b32 	%r55, %r54, 23;
	mov.b32 	%f69, %r55;
	mul.rn.f32 	%f5, %f70, %f69;
	add.rn.f32 	%f116, %f10, %f181;
	mov.f32 	%f183, %f185;
	@%p2 bra 	$L__BB173_27;
	bra.uni 	$L__BB173_11;
$L__BB173_27:
	ld.global.nc.f32 	%f183, [%rd21];
$L__BB173_11:
	mul.rn.f32 	%f117, %f5, %f116;
	mov.f32 	%f184, %f185;
	@%p3 bra 	$L__BB173_28;
	bra.uni 	$L__BB173_12;
$L__BB173_28:
	add.s64 	%rd104, %rd4, %rd47;
	add.s64 	%rd106, %rd104, %rd56;
	mul.lo.s64 	%rd107, %rd15, 24;
	add.s64 	%rd108, %rd106, %rd107;
	add.s64 	%rd110, %rd108, %rd53;
	ld.global.nc.f32 	%f122, [%rd110];
	add.s64 	%rd111, %rd3, %rd47;
	add.s64 	%rd112, %rd111, %rd56;
	add.s64 	%rd113, %rd112, %rd107;
	add.s64 	%rd114, %rd113, %rd53;
	ld.global.nc.f32 	%f123, [%rd114];
	add.rn.f32 	%f32, %f122, %f123;
	ld.global.nc.f32 	%f124, [%rd16];
	add.rn.f32 	%f125, %f124, %f124;
	add.rn.f32 	%f126, %f125, %f125;
	add.rn.f32 	%f33, %f126, %f126;
	mul.rn.f32 	%f127, %f33, 0f3F22F983;
	cvt.rni.s32.f32 	%r139, %f127;
	cvt.rn.f32.s32 	%f128, %r139;
	fma.rn.f32 	%f129, %f128, 0fBFC90FDA, %f33;
	fma.rn.f32 	%f130, %f128, 0fB3A22168, %f129;
	fma.rn.f32 	%f187, %f128, 0fA7C234C5, %f130;
	abs.f32 	%f35, %f33;
	setp.ltu.f32 	%p22, %f35, 0f47CE4780;
	@%p22 bra 	$L__BB173_36;
	setp.neu.f32 	%p23, %f35, 0f7F800000;
	@%p23 bra 	$L__BB173_31;
	mov.f32 	%f133, 0f00000000;
	mul.rn.f32 	%f187, %f33, %f133;
	mov.b32 	%r139, 0;
	bra.uni 	$L__BB173_36;
$L__BB173_31:
	mov.b32 	%r136, 0;
	mov.b32 	%r25, %f33;
	shr.u32 	%r26, %r25, 23;
	and.b32  	%r92, %r26, 224;
	add.s32 	%r93, %r92, -128;
	shl.b32 	%r94, %r25, 8;
	or.b32  	%r98, %r94, -2147483648;
	shr.u32 	%r28, %r93, 5;
	mov.u64 	%rd157, 0;
$L__BB173_32:
	.pragma "nounroll";
	add.s64 	%rd117, %rd155, %rd157;
	ld.global.nc.u32 	%r97, [%rd117];
	// begin inline asm
	{
	mad.lo.cc.u32   %r95, %r97, %r98, %r136;
	madc.hi.u32     %r136, %r97, %r98,  0;
	}
	// end inline asm
	add.s64 	%rd118, %rd8, %rd157;
	st.local.u32 	[%rd118], %r95;
	add.s64 	%rd157, %rd157, 4;
	cvt.u32.u64 	%r100, %rd157;
	setp.ne.s32 	%p24, %r100, 24;
	@%p24 bra 	$L__BB173_32;
	st.local.u32 	[%rd8+24], %r136;
	and.b32  	%r31, %r26, 31;
	mul.wide.u32 	%rd119, %r28, 4;
	sub.s64 	%rd28, %rd8, %rd119;
	ld.local.u32 	%r137, [%rd28+24];
	ld.local.u32 	%r138, [%rd28+20];
	setp.eq.s32 	%p25, %r31, 0;
	@%p25 bra 	$L__BB173_35;
	shl.b32 	%r101, %r138, %r31;
	shl.b32 	%r102, %r137, %r31;
	mov.b32 	%r103, 32;
	sub.s32 	%r104, %r103, %r31;
	shr.u32 	%r105, %r138, %r104;
	add.s32 	%r137, %r105, %r102;
	ld.local.u32 	%r106, [%rd28+16];
	shr.u32 	%r107, %r106, %r104;
	add.s32 	%r138, %r107, %r101;
$L__BB173_35:
	shr.u32 	%r108, %r137, 30;
	shr.u32 	%r109, %r138, 30;
	shl.b32 	%r110, %r137, 2;
	or.b32  	%r111, %r110, %r109;
	shl.b32 	%r112, %r138, 2;
	bfe.u32 	%r113, %r137, 29, 1;
	add.s32 	%r114, %r113, %r108;
	neg.s32 	%r115, %r114;
	setp.lt.s32 	%p26, %r25, 0;
	selp.b32 	%r139, %r115, %r114, %p26;
	xor.b32  	%r116, %r111, %r25;
	bfe.s32 	%r117, %r137, 29, 1;
	xor.b32  	%r118, %r117, %r111;
	xor.b32  	%r119, %r117, %r112;
	cvt.u64.u32 	%rd120, %r118;
	shl.b64 	%rd121, %rd120, 32;
	cvt.u64.u32 	%rd122, %r119;
	or.b64  	%rd123, %rd121, %rd122;
	cvt.rn.f64.s64 	%fd3, %rd123;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f131, %fd4;
	neg.f32 	%f132, %f131;
	setp.lt.s32 	%p27, %r116, 0;
	selp.f32 	%f187, %f132, %f131, %p27;
$L__BB173_36:
	add.s32 	%r121, %r139, 1;
	mul.rn.f32 	%f134, %f187, %f187;
	and.b32  	%r122, %r139, 1;
	setp.eq.b32 	%p28, %r122, 1;
	selp.f32 	%f135, %f187, 0f3F800000, %p28;
	fma.rn.f32 	%f136, %f134, %f135, 0f00000000;
	fma.rn.f32 	%f137, %f134, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f138, 0fB94D4153, %f137, %p28;
	selp.f32 	%f139, 0f3C0885E4, 0f3D2AAABB, %p28;
	fma.rn.f32 	%f140, %f138, %f134, %f139;
	selp.f32 	%f141, 0fBE2AAAA8, 0fBEFFFFFF, %p28;
	fma.rn.f32 	%f142, %f140, %f134, %f141;
	fma.rn.f32 	%f143, %f142, %f136, %f135;
	and.b32  	%r123, %r121, 2;
	setp.eq.s32 	%p29, %r123, 0;
	mov.f32 	%f144, 0f00000000;
	sub.rn.f32 	%f145, %f144, %f143;
	selp.f32 	%f146, %f143, %f145, %p29;
	add.rn.f32 	%f147, %f4, %f4;
	fma.rn.f32 	%f148, %f147, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f149, %f148;
	fma.rm.f32 	%f152, %f149, %f47, %f46;
	add.rn.f32 	%f153, %f152, 0fCB40007F;
	neg.f32 	%f154, %f153;
	fma.rn.f32 	%f155, %f147, 0f3FB8AA3B, %f154;
	fma.rn.f32 	%f156, %f147, 0f32A57060, %f155;
	mov.b32 	%r124, %f152;
	shl.b32 	%r125, %r124, 23;
	mov.b32 	%f157, %r125;
	ex2.approx.ftz.f32 	%f158, %f156;
	mul.rn.f32 	%f159, %f158, %f157;
	add.s64 	%rd129, %rd57, %rd107;
	add.s64 	%rd131, %rd129, %rd53;
	ld.global.nc.f32 	%f160, [%rd131];
	mul.rn.f32 	%f161, %f159, %f160;
	mul.rn.f32 	%f162, %f161, %f146;
	add.rn.f32 	%f184, %f32, %f162;
$L__BB173_12:
	mul.rn.f32 	%f119, %f118, %f117;
	@%p21 bra 	$L__BB173_37;
	bra.uni 	$L__BB173_13;
$L__BB173_37:
	ld.global.nc.f32 	%f185, [%rd22];
	bra.uni 	$L__BB173_13;
$L__BB173_3:
	mul.wide.u32 	%rd140, %r2, 132;
	mov.u64 	%rd141, shared_cache12;
	add.s64 	%rd142, %rd141, %rd140;
	mul.wide.u32 	%rd143, %r1, 4;
	add.s64 	%rd144, %rd142, %rd143;
	st.shared.f32 	[%rd144], %f1;
	bar.sync 	0;
	mul.wide.u32 	%rd145, %r1, 132;
	add.s64 	%rd146, %rd141, %rd145;
	mul.wide.u32 	%rd147, %r2, 4;
	add.s64 	%rd148, %rd146, %rd147;
	ld.shared.f32 	%f165, [%rd148];
	shfl.sync.down.b32	%f166, %f165, 16, 31, -1;
	add.rn.f32 	%f167, %f165, %f166;
	shfl.sync.down.b32	%f168, %f167, 8, 31, -1;
	add.rn.f32 	%f169, %f167, %f168;
	shfl.sync.down.b32	%f170, %f169, 4, 31, -1;
	add.rn.f32 	%f171, %f169, %f170;
	shfl.sync.down.b32	%f172, %f171, 2, 31, -1;
	add.rn.f32 	%f173, %f171, %f172;
	shfl.sync.down.b32	%f174, %f173, 1, 31, -1;
	add.rn.f32 	%f3, %f173, %f174;
	st.shared.f32 	[%rd148], %f3;
	setp.lt.u32 	%p32, %r1, %r3;
	setp.eq.s32 	%p33, %r2, 0;
	and.pred  	%p34, %p33, %p32;
	@%p34 bra 	$L__BB173_38;
	bra.uni 	$L__BB173_4;
$L__BB173_38:
	or.b32  	%r126, %r4, %r1;
	mul.hi.u32 	%r127, %r126, 715827883;
	mul.lo.s32 	%r128, %r127, 6;
	sub.s32 	%r129, %r126, %r128;
	mul.lo.s64 	%rd149, %rd10, 192;
	add.s64 	%rd150, %rd2, %rd149;
	mul.wide.u32 	%rd151, %r127, 24;
	add.s64 	%rd152, %rd150, %rd151;
	mul.wide.u32 	%rd153, %r129, 4;
	add.s64 	%rd154, %rd152, %rd153;
	neg.f32 	%f175, %f3;
	st.global.f32 	[%rd154], %f175;
$L__BB173_4:
	ret;

}
	// .globl	loop_transpose_fusion_112
.visible .entry loop_transpose_fusion_112(
	.param .u64 loop_transpose_fusion_112_param_0,
	.param .u64 loop_transpose_fusion_112_param_1,
	.param .u64 loop_transpose_fusion_112_param_2,
	.param .u64 loop_transpose_fusion_112_param_3,
	.param .u64 loop_transpose_fusion_112_param_4
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot174[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<119>;
	.reg .f32 	%f<87>;
	.reg .b64 	%rd<59>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot174;
	ld.param.u64 	%rd15, [loop_transpose_fusion_112_param_0];
	ld.param.u64 	%rd16, [loop_transpose_fusion_112_param_4];
	ld.param.u64 	%rd17, [loop_transpose_fusion_112_param_1];
	ld.param.u64 	%rd18, [loop_transpose_fusion_112_param_3];
	ld.param.u64 	%rd19, [loop_transpose_fusion_112_param_2];
	cvta.to.global.u64 	%rd3, %rd19;
	cvta.to.global.u64 	%rd20, %rd17;
	cvta.to.global.u64 	%rd4, %rd15;
	add.u64 	%rd5, %SPL, 0;
	mov.u32 	%r34, %ctaid.x;
	shl.b32 	%r35, %r34, 7;
	mov.u32 	%r36, %tid.x;
	or.b32  	%r1, %r35, %r36;
	cvt.u16.u32 	%rs3, %r34;
	shr.u16 	%rs4, %rs3, 3;
	mul.hi.u16 	%rs5, %rs4, 5243;
	shr.u16 	%rs6, %rs5, 1;
	mul.hi.u32 	%r37, %r1, 1374389535;
	bfe.u32 	%r38, %r37, 7, 6;
	shr.u32 	%r39, %r1, 3;
	cvt.u16.u32 	%rs7, %r39;
	shr.u16 	%rs8, %rs7, 1;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	mul.lo.s16 	%rs11, %rs10, 50;
	sub.s16 	%rs1, %rs7, %rs11;
	and.b32  	%r2, %r36, 7;
	and.b16  	%rs2, %rs5, 1022;
	cvt.u64.u32 	%rd7, %r38;
	mul.wide.u32 	%rd23, %r38, 12;
	add.s64 	%rd24, %rd20, %rd23;
	cvt.u32.u16 	%r40, %rs6;
	mul.wide.u32 	%rd25, %r40, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f12, [%rd26];
	add.rn.f32 	%f13, %f12, %f12;
	add.rn.f32 	%f1, %f13, %f13;
	mul.rn.f32 	%f14, %f1, 0f3F22F983;
	cvt.rni.s32.f32 	%r118, %f14;
	cvt.rn.f32.s32 	%f15, %r118;
	fma.rn.f32 	%f16, %f15, 0fBFC90FDA, %f1;
	fma.rn.f32 	%f17, %f15, 0fB3A22168, %f16;
	fma.rn.f32 	%f86, %f15, 0fA7C234C5, %f17;
	abs.f32 	%f3, %f1;
	setp.ltu.f32 	%p1, %f3, 0f47CE4780;
	setp.neu.f32 	%p17, %f3, 0f7F800000;
	mov.f32 	%f84, 0f00000000;
	mov.u32 	%r114, %r118;
	mov.f32 	%f85, %f86;
	@%p1 bra 	$L__BB174_8;
	@%p17 bra 	$L__BB174_3;
	mul.rn.f32 	%f85, %f1, %f84;
	mov.b32 	%r114, 0;
	bra.uni 	$L__BB174_8;
$L__BB174_3:
	mov.b32 	%r4, %f1;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r42, %r5, 224;
	add.s32 	%r43, %r42, -128;
	shl.b32 	%r44, %r4, 8;
	or.b32  	%r48, %r44, -2147483648;
	shr.u32 	%r7, %r43, 5;
	mov.b32 	%r111, 0;
	mov.u64 	%rd57, 0;
	mov.u64 	%rd28, __cudart_i2opi_f;
$L__BB174_4:
	.pragma "nounroll";
	add.s64 	%rd29, %rd28, %rd57;
	ld.global.nc.u32 	%r47, [%rd29];
	// begin inline asm
	{
	mad.lo.cc.u32   %r45, %r47, %r48, %r111;
	madc.hi.u32     %r111, %r47, %r48,  0;
	}
	// end inline asm
	add.s64 	%rd30, %rd5, %rd57;
	st.local.u32 	[%rd30], %r45;
	add.s64 	%rd57, %rd57, 4;
	cvt.u32.u64 	%r50, %rd57;
	setp.ne.s32 	%p3, %r50, 24;
	@%p3 bra 	$L__BB174_4;
	st.local.u32 	[%rd5+24], %r111;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd31, %r7, 4;
	sub.s64 	%rd10, %rd5, %rd31;
	ld.local.u32 	%r112, [%rd10+24];
	ld.local.u32 	%r113, [%rd10+20];
	setp.eq.s32 	%p4, %r10, 0;
	@%p4 bra 	$L__BB174_7;
	shl.b32 	%r51, %r113, %r10;
	shl.b32 	%r52, %r112, %r10;
	mov.b32 	%r53, 32;
	sub.s32 	%r54, %r53, %r10;
	shr.u32 	%r55, %r113, %r54;
	add.s32 	%r112, %r55, %r52;
	ld.local.u32 	%r56, [%rd10+16];
	shr.u32 	%r57, %r56, %r54;
	add.s32 	%r113, %r57, %r51;
$L__BB174_7:
	shr.u32 	%r58, %r112, 30;
	shr.u32 	%r59, %r113, 30;
	shl.b32 	%r60, %r112, 2;
	or.b32  	%r61, %r60, %r59;
	shl.b32 	%r62, %r113, 2;
	bfe.u32 	%r63, %r112, 29, 1;
	add.s32 	%r64, %r63, %r58;
	neg.s32 	%r65, %r64;
	setp.lt.s32 	%p5, %r4, 0;
	selp.b32 	%r114, %r65, %r64, %p5;
	xor.b32  	%r66, %r61, %r4;
	bfe.s32 	%r67, %r112, 29, 1;
	xor.b32  	%r68, %r67, %r61;
	xor.b32  	%r69, %r67, %r62;
	cvt.u64.u32 	%rd32, %r68;
	shl.b64 	%rd33, %rd32, 32;
	cvt.u64.u32 	%rd34, %r69;
	or.b64  	%rd35, %rd33, %rd34;
	cvt.rn.f64.s64 	%fd1, %rd35;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f18, %fd2;
	neg.f32 	%f19, %f18;
	setp.lt.s32 	%p6, %r66, 0;
	selp.f32 	%f85, %f19, %f18, %p6;
$L__BB174_8:
	cvta.to.global.u64 	%rd1, %rd16;
	cvta.to.global.u64 	%rd2, %rd18;
	shl.b64 	%rd36, %rd7, 2;
	add.s64 	%rd37, %rd3, %rd36;
	ld.global.nc.f32 	%f7, [%rd37];
	mul.lo.s64 	%rd38, %rd7, 9600;
	add.s64 	%rd39, %rd4, %rd38;
	cvt.u32.u16 	%r71, %rs1;
	mul.wide.u32 	%rd40, %r71, 192;
	add.s64 	%rd41, %rd39, %rd40;
	mul.wide.u32 	%rd42, %r2, 24;
	add.s64 	%rd43, %rd41, %rd42;
	cvt.u32.u16 	%r72, %rs2;
	mul.wide.u32 	%rd44, %r72, 4;
	add.s64 	%rd11, %rd43, %rd44;
	ld.global.nc.f32 	%f8, [%rd11];
	@%p1 bra 	$L__BB174_16;
	@%p17 bra 	$L__BB174_11;
	mul.rn.f32 	%f86, %f1, %f84;
	mov.b32 	%r118, 0;
	bra.uni 	$L__BB174_16;
$L__BB174_11:
	mov.b32 	%r19, %f1;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r74, %r20, 224;
	add.s32 	%r75, %r74, -128;
	shl.b32 	%r76, %r19, 8;
	or.b32  	%r80, %r76, -2147483648;
	shr.u32 	%r22, %r75, 5;
	mov.b32 	%r115, 0;
	mov.u64 	%rd58, 0;
	mov.u64 	%rd46, __cudart_i2opi_f;
$L__BB174_12:
	.pragma "nounroll";
	add.s64 	%rd47, %rd46, %rd58;
	ld.global.nc.u32 	%r79, [%rd47];
	// begin inline asm
	{
	mad.lo.cc.u32   %r77, %r79, %r80, %r115;
	madc.hi.u32     %r115, %r79, %r80,  0;
	}
	// end inline asm
	add.s64 	%rd48, %rd5, %rd58;
	st.local.u32 	[%rd48], %r77;
	add.s64 	%rd58, %rd58, 4;
	cvt.u32.u64 	%r82, %rd58;
	setp.ne.s32 	%p9, %r82, 24;
	@%p9 bra 	$L__BB174_12;
	st.local.u32 	[%rd5+24], %r115;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd49, %r22, 4;
	sub.s64 	%rd14, %rd5, %rd49;
	ld.local.u32 	%r116, [%rd14+24];
	ld.local.u32 	%r117, [%rd14+20];
	setp.eq.s32 	%p10, %r25, 0;
	@%p10 bra 	$L__BB174_15;
	shl.b32 	%r83, %r117, %r25;
	shl.b32 	%r84, %r116, %r25;
	mov.b32 	%r85, 32;
	sub.s32 	%r86, %r85, %r25;
	shr.u32 	%r87, %r117, %r86;
	add.s32 	%r116, %r87, %r84;
	ld.local.u32 	%r88, [%rd14+16];
	shr.u32 	%r89, %r88, %r86;
	add.s32 	%r117, %r89, %r83;
$L__BB174_15:
	shr.u32 	%r90, %r116, 30;
	shr.u32 	%r91, %r117, 30;
	shl.b32 	%r92, %r116, 2;
	or.b32  	%r93, %r92, %r91;
	shl.b32 	%r94, %r117, 2;
	bfe.u32 	%r95, %r116, 29, 1;
	add.s32 	%r96, %r95, %r90;
	neg.s32 	%r97, %r96;
	setp.lt.s32 	%p11, %r19, 0;
	selp.b32 	%r118, %r97, %r96, %p11;
	xor.b32  	%r98, %r93, %r19;
	bfe.s32 	%r99, %r116, 29, 1;
	xor.b32  	%r100, %r99, %r93;
	xor.b32  	%r101, %r99, %r94;
	cvt.u64.u32 	%rd50, %r100;
	shl.b64 	%rd51, %rd50, 32;
	cvt.u64.u32 	%rd52, %r101;
	or.b64  	%rd53, %rd51, %rd52;
	cvt.rn.f64.s64 	%fd3, %rd53;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f21, %fd4;
	neg.f32 	%f22, %f21;
	setp.lt.s32 	%p12, %r98, 0;
	selp.f32 	%f86, %f22, %f21, %p12;
$L__BB174_16:
	fma.rn.f32 	%f24, %f7, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f25, %f24;
	mov.f32 	%f26, 0f4B400001;
	mov.f32 	%f27, 0f437C0000;
	fma.rm.f32 	%f28, %f25, %f27, %f26;
	add.rn.f32 	%f29, %f28, 0fCB40007F;
	neg.f32 	%f30, %f29;
	fma.rn.f32 	%f31, %f7, 0f3FB8AA3B, %f30;
	fma.rn.f32 	%f32, %f7, 0f32A57060, %f31;
	ex2.approx.ftz.f32 	%f33, %f32;
	mov.b32 	%r103, %f28;
	shl.b32 	%r104, %r103, 23;
	mov.b32 	%f34, %r104;
	mul.rn.f32 	%f35, %f33, %f34;
	neg.f32 	%f36, %f35;
	sub.rn.f32 	%f37, %f36, %f35;
	add.rn.f32 	%f38, %f37, %f37;
	add.rn.f32 	%f39, %f38, %f38;
	add.rn.f32 	%f40, %f39, %f39;
	add.rn.f32 	%f41, %f40, %f40;
	add.rn.f32 	%f42, %f41, %f41;
	fma.rn.f32 	%f43, %f42, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f44, %f43;
	fma.rm.f32 	%f45, %f44, %f27, %f26;
	add.rn.f32 	%f46, %f45, 0fCB40007F;
	neg.f32 	%f47, %f46;
	fma.rn.f32 	%f48, %f42, 0f3FB8AA3B, %f47;
	fma.rn.f32 	%f49, %f42, 0f32A57060, %f48;
	ex2.approx.ftz.f32 	%f50, %f49;
	mov.b32 	%r105, %f45;
	shl.b32 	%r106, %r105, 23;
	mov.b32 	%f51, %r106;
	mul.rn.f32 	%f52, %f50, %f51;
	mul.rn.f32 	%f53, %f8, %f52;
	and.b32  	%r107, %r114, 2;
	setp.eq.s32 	%p13, %r107, 0;
	and.b32  	%r108, %r114, 1;
	setp.eq.b32 	%p14, %r108, 1;
	mul.rn.f32 	%f54, %f85, %f85;
	fma.rn.f32 	%f55, %f54, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f56, %f55, 0fB94D4153, %p14;
	selp.f32 	%f57, 0f3D2AAABB, 0f3C0885E4, %p14;
	fma.rn.f32 	%f58, %f56, %f54, %f57;
	selp.f32 	%f59, 0fBEFFFFFF, 0fBE2AAAA8, %p14;
	fma.rn.f32 	%f60, %f58, %f54, %f59;
	selp.f32 	%f61, 0f3F800000, %f85, %p14;
	fma.rn.f32 	%f62, %f54, %f61, 0f00000000;
	fma.rn.f32 	%f63, %f60, %f62, %f61;
	sub.rn.f32 	%f65, %f84, %f63;
	selp.f32 	%f66, %f63, %f65, %p13;
	neg.f32 	%f67, %f66;
	mul.rn.f32 	%f68, %f53, %f67;
	mul.rn.f32 	%f69, %f86, %f86;
	and.b32  	%r109, %r118, 1;
	setp.eq.b32 	%p15, %r109, 1;
	selp.f32 	%f70, 0f3F800000, %f86, %p15;
	fma.rn.f32 	%f71, %f69, %f70, 0f00000000;
	fma.rn.f32 	%f72, %f69, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f73, %f72, 0fB94D4153, %p15;
	selp.f32 	%f74, 0f3D2AAABB, 0f3C0885E4, %p15;
	fma.rn.f32 	%f75, %f73, %f69, %f74;
	selp.f32 	%f76, 0fBEFFFFFF, 0fBE2AAAA8, %p15;
	fma.rn.f32 	%f77, %f75, %f69, %f76;
	fma.rn.f32 	%f78, %f77, %f71, %f70;
	and.b32  	%r110, %r118, 2;
	setp.eq.s32 	%p16, %r110, 0;
	sub.rn.f32 	%f79, %f84, %f78;
	selp.f32 	%f80, %f78, %f79, %p16;
	ld.global.nc.f32 	%f81, [%rd11+4];
	mul.rn.f32 	%f82, %f81, %f52;
	mul.rn.f32 	%f83, %f80, %f82;
	mul.wide.u32 	%rd54, %r1, 4;
	add.s64 	%rd55, %rd2, %rd54;
	st.global.f32 	[%rd55], %f68;
	add.s64 	%rd56, %rd1, %rd54;
	st.global.f32 	[%rd56], %f83;
	ret;

}
	// .globl	loop_broadcast_fusion_39
.visible .entry loop_broadcast_fusion_39(
	.param .u64 loop_broadcast_fusion_39_param_0
)
.reqntid 1024, 1, 1
{
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [loop_broadcast_fusion_39_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 10;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.wide.u32 	%rd3, %r4, 4;
	add.s64 	%rd4, %rd2, %rd3;
	mov.b32 	%r5, 0;
	st.global.u32 	[%rd4], %r5;
	ret;

}
	// .globl	input_scatter_fusion_252
.visible .entry input_scatter_fusion_252(
	.param .u64 input_scatter_fusion_252_param_0,
	.param .u64 input_scatter_fusion_252_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<11>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_252_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_252_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r2, 7;
	shr.u32 	%r6, %r4, 3;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r7, %r4, 1374389535;
	bfe.u32 	%r8, %r7, 7, 6;
	cvt.u16.u32 	%rs7, %r1;
	shr.u16 	%rs8, %rs7, 3;
	mul.hi.u16 	%rs9, %rs8, 5243;
	and.b16  	%rs10, %rs9, 1022;
	cvt.u32.u16 	%r9, %rs10;
	mul.wide.u32 	%rd5, %r9, 102400;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r8, 1600;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r10, %rs6;
	mul.wide.u32 	%rd9, %r10, 32;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+102400];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+102400], %f3;
	ret;

}
	// .globl	wrapped_transpose_258
.visible .entry wrapped_transpose_258(
	.param .u64 wrapped_transpose_258_param_0,
	.param .u64 wrapped_transpose_258_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [wrapped_transpose_258_param_0];
	ld.param.u64 	%rd2, [wrapped_transpose_258_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.hi.u32 	%r5, %r4, 458129845;
	bfe.u32 	%r6, %r5, 8, 6;
	mul.hi.u32 	%r7, %r4, -1431655765;
	shr.u32 	%r8, %r7, 5;
	cvt.u16.u32 	%rs1, %r8;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	shr.u32 	%r9, %r7, 2;
	bfe.u32 	%r10, %r7, 2, 3;
	mul.lo.s32 	%r11, %r9, 6;
	sub.s32 	%r12, %r4, %r11;
	mul.wide.u32 	%rd5, %r12, 102400;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r6, 1600;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r13, %rs6;
	mul.wide.u32 	%rd9, %r13, 32;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r10, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	st.global.f32 	[%rd14], %f1;
	ret;

}
	// .globl	input_scatter_fusion_253
.visible .entry input_scatter_fusion_253(
	.param .u64 input_scatter_fusion_253_param_0,
	.param .u64 input_scatter_fusion_253_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<11>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_253_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_253_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r2, 7;
	shr.u32 	%r6, %r4, 3;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r7, %r4, 1374389535;
	bfe.u32 	%r8, %r7, 7, 6;
	cvt.u16.u32 	%rs7, %r1;
	shr.u16 	%rs8, %rs7, 3;
	mul.hi.u16 	%rs9, %rs8, 5243;
	and.b16  	%rs10, %rs9, 1022;
	cvt.u32.u16 	%r9, %rs10;
	mul.wide.u32 	%rd5, %r9, 102400;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r8, 1600;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r10, %rs6;
	mul.wide.u32 	%rd9, %r10, 32;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	input_add_reduce_fusion_40
.visible .entry input_add_reduce_fusion_40(
	.param .u64 input_add_reduce_fusion_40_param_0,
	.param .u64 input_add_reduce_fusion_40_param_1,
	.param .u64 input_add_reduce_fusion_40_param_2,
	.param .u64 input_add_reduce_fusion_40_param_3,
	.param .u64 input_add_reduce_fusion_40_param_4,
	.param .u64 input_add_reduce_fusion_40_param_5,
	.param .u64 input_add_reduce_fusion_40_param_6,
	.param .u64 input_add_reduce_fusion_40_param_7,
	.param .u64 input_add_reduce_fusion_40_param_8
)
.reqntid 1024, 1, 1
{
	.local .align 4 .b8 	__local_depot179[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<29>;
	.reg .b32 	%r<139>;
	.reg .f32 	%f<170>;
	.reg .b64 	%rd<157>;
	.reg .f64 	%fd<5>;
	// demoted variable
	.shared .align 4 .b8 shared_cache13[4224];
	mov.u64 	%SPL, __local_depot179;
	ld.param.u64 	%rd27, [input_add_reduce_fusion_40_param_0];
	ld.param.u64 	%rd28, [input_add_reduce_fusion_40_param_8];
	cvta.to.global.u64 	%rd1, %rd28;
	ld.param.u64 	%rd29, [input_add_reduce_fusion_40_param_1];
	ld.param.u64 	%rd30, [input_add_reduce_fusion_40_param_7];
	cvta.to.global.u64 	%rd2, %rd30;
	ld.param.u64 	%rd31, [input_add_reduce_fusion_40_param_2];
	ld.param.u64 	%rd32, [input_add_reduce_fusion_40_param_6];
	cvta.to.global.u64 	%rd3, %rd32;
	ld.param.u64 	%rd33, [input_add_reduce_fusion_40_param_3];
	ld.param.u64 	%rd34, [input_add_reduce_fusion_40_param_5];
	cvta.to.global.u64 	%rd4, %rd34;
	ld.param.u64 	%rd35, [input_add_reduce_fusion_40_param_4];
	cvta.to.global.u64 	%rd36, %rd35;
	cvta.to.global.u64 	%rd5, %rd33;
	cvta.to.global.u64 	%rd6, %rd31;
	cvta.to.global.u64 	%rd37, %rd29;
	cvta.to.global.u64 	%rd7, %rd27;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r40, %tid.x;
	mov.u32 	%r41, %ctaid.x;
	shr.u32 	%r1, %r40, 5;
	and.b32  	%r2, %r40, 31;
	cvt.u16.u32 	%rs1, %r41;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 9;
	mul.lo.s16 	%rs5, %rs4, 3;
	sub.s16 	%rs6, %rs1, %rs5;
	shl.b16 	%rs7, %rs6, 5;
	cvt.u32.u16 	%r42, %rs7;
	and.b32  	%r3, %r42, 224;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs8, %r4;
	mul.lo.s16 	%rs9, %rs8, 43;
	shr.u16 	%rs10, %rs9, 8;
	mul.lo.s16 	%rs11, %rs10, 6;
	sub.s16 	%rs12, %rs8, %rs11;
	and.b16  	%rs13, %rs12, 254;
	cvt.u32.u16 	%r43, %rs10;
	cvt.u64.u16 	%rd10, %rs4;
	cvt.u32.u16 	%r44, %rs4;
	mul.wide.u32 	%rd40, %r44, 4;
	add.s64 	%rd41, %rd37, %rd40;
	ld.global.nc.f32 	%f42, [%rd41];
	fma.rn.f32 	%f43, %f42, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f44, %f43;
	mov.f32 	%f45, 0f4B400001;
	mov.f32 	%f46, 0f437C0000;
	fma.rm.f32 	%f47, %f44, %f46, %f45;
	add.rn.f32 	%f48, %f47, 0fCB40007F;
	neg.f32 	%f49, %f48;
	fma.rn.f32 	%f50, %f42, 0f3FB8AA3B, %f49;
	fma.rn.f32 	%f51, %f42, 0f32A57060, %f50;
	mov.b32 	%r45, %f47;
	shl.b32 	%r46, %r45, 23;
	mov.b32 	%f52, %r46;
	ex2.approx.ftz.f32 	%f53, %f51;
	mul.rn.f32 	%f54, %f53, %f52;
	neg.f32 	%f55, %f54;
	sub.rn.f32 	%f56, %f55, %f54;
	add.rn.f32 	%f57, %f56, %f56;
	add.rn.f32 	%f58, %f57, %f57;
	add.rn.f32 	%f59, %f58, %f58;
	add.rn.f32 	%f60, %f59, %f59;
	fma.rn.f32 	%f61, %f60, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f62, %f61;
	fma.rm.f32 	%f63, %f62, %f46, %f45;
	add.rn.f32 	%f64, %f63, 0fCB40007F;
	neg.f32 	%f65, %f64;
	fma.rn.f32 	%f66, %f60, 0f3FB8AA3B, %f65;
	fma.rn.f32 	%f67, %f60, 0f32A57060, %f66;
	mov.b32 	%r47, %f63;
	shl.b32 	%r48, %r47, 23;
	mov.b32 	%f68, %r48;
	ex2.approx.ftz.f32 	%f69, %f67;
	mul.rn.f32 	%f1, %f69, %f68;
	add.s16 	%rs14, %rs10, -2;
	and.b16  	%rs15, %rs14, 128;
	setp.gt.u32 	%p3, %r4, 11;
	and.b32  	%r5, %r43, 1;
	setp.eq.s32 	%p4, %r5, 0;
	and.pred  	%p1, %p3, %p4;
	shr.u16 	%rs16, %rs15, 7;
	add.s16 	%rs17, %rs14, %rs16;
	cvt.s16.s8 	%rs18, %rs17;
	shr.s16 	%rs19, %rs18, 1;
	add.s16 	%rs20, %rs19, 1;
	cvt.s32.s16 	%r49, %rs20;
	cvt.u64.u32 	%rd11, %r49;
	cvt.u64.u16 	%rd42, %rs12;
	and.b64  	%rd12, %rd42, 255;
	add.s32 	%r50, %r43, -1;
	setp.gt.u32 	%p5, %r4, 5;
	and.b32  	%r51, %r50, 1;
	setp.eq.b32 	%p6, %r51, 1;
	not.pred 	%p7, %p6;
	and.pred  	%p2, %p5, %p7;
	cvt.s8.s32 	%rs21, %r50;
	cvt.u16.u32 	%rs22, %r50;
	and.b16  	%rs23, %rs22, 128;
	shr.u16 	%rs24, %rs23, 7;
	add.s16 	%rs25, %rs21, %rs24;
	shr.s16 	%rs26, %rs25, 1;
	cvt.s32.s16 	%r52, %rs26;
	cvt.u64.u32 	%rd13, %r52;
	shr.u16 	%rs27, %rs9, 9;
	cvt.u64.u16 	%rd14, %rs27;
	shr.u16 	%rs28, %rs13, 1;
	cvt.u32.u16 	%r53, %rs28;
	mul.wide.u32 	%rd43, %r53, 4;
	mul.wide.u32 	%rd44, %r44, 12;
	add.s64 	%rd45, %rd36, %rd44;
	add.s64 	%rd15, %rd45, %rd43;
	add.rn.f32 	%f70, %f60, %f60;
	fma.rn.f32 	%f71, %f70, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f72, %f71;
	fma.rm.f32 	%f73, %f72, %f46, %f45;
	add.rn.f32 	%f74, %f73, 0fCB40007F;
	neg.f32 	%f75, %f74;
	fma.rn.f32 	%f76, %f70, 0f3FB8AA3B, %f75;
	fma.rn.f32 	%f2, %f70, 0f32A57060, %f76;
	mov.b32 	%r54, %f73;
	shl.b32 	%r55, %r54, 23;
	mov.b32 	%f3, %r55;
	cvt.u64.u16 	%rd16, %rs10;
	mov.f32 	%f41, 0f00000000;
	mul.lo.s64 	%rd50, %rd11, 24;
	mul.lo.s64 	%rd57, %rd13, 24;
	setp.lt.u32 	%p17, %r4, 6;
	mov.u32 	%r6, %r1;
	mov.f32 	%f4, %f41;
	bra.uni 	$L__BB179_1;
$L__BB179_10:
	add.s32 	%r6, %r6, 32;
	add.rn.f32 	%f4, %f4, %f114;
	add.rn.f32 	%f15, %f164, %f165;
	add.rn.f32 	%f17, %f15, %f166;
	cvt.u32.u64 	%r122, %rd17;
	add.rn.f32 	%f147, %f17, %f167;
	add.s64 	%rd132, %rd1, %rd94;
	add.s64 	%rd134, %rd132, %rd96;
	add.s64 	%rd136, %rd134, %rd98;
	add.s64 	%rd138, %rd136, %rd52;
	st.global.f32 	[%rd138], %f147;
	setp.gt.u32 	%p28, %r122, 17;
	@%p28 bra 	$L__BB179_11;
$L__BB179_1:
	mul.lo.s64 	%rd46, %rd10, 9600;
	add.s64 	%rd47, %rd6, %rd46;
	mul.wide.u32 	%rd48, %r6, 192;
	add.s64 	%rd49, %rd47, %rd48;
	add.s64 	%rd51, %rd49, %rd50;
	shl.b64 	%rd52, %rd12, 2;
	add.s64 	%rd18, %rd51, %rd52;
	mov.f32 	%f160, %f41;
	@%p1 bra 	$L__BB179_2;
	bra.uni 	$L__BB179_3;
$L__BB179_2:
	ld.global.nc.f32 	%f160, [%rd18];
$L__BB179_3:
	cvt.u64.u32 	%rd17, %r6;
	add.s64 	%rd54, %rd5, %rd46;
	mul.lo.s64 	%rd55, %rd17, 192;
	add.s64 	%rd56, %rd54, %rd55;
	add.s64 	%rd58, %rd56, %rd57;
	add.s64 	%rd19, %rd58, %rd52;
	mov.f32 	%f161, %f41;
	@%p2 bra 	$L__BB179_13;
	bra.uni 	$L__BB179_4;
$L__BB179_13:
	ld.global.nc.f32 	%f161, [%rd19];
$L__BB179_4:
	mov.u64 	%rd154, __cudart_i2opi_f;
	mov.f32 	%f162, %f41;
	@%p4 bra 	$L__BB179_14;
	bra.uni 	$L__BB179_5;
$L__BB179_14:
	add.s64 	%rd61, %rd4, %rd46;
	add.s64 	%rd63, %rd61, %rd55;
	mul.lo.s64 	%rd64, %rd14, 24;
	add.s64 	%rd65, %rd63, %rd64;
	add.s64 	%rd67, %rd65, %rd52;
	ld.global.nc.f32 	%f80, [%rd67];
	add.s64 	%rd68, %rd3, %rd46;
	add.s64 	%rd69, %rd68, %rd55;
	add.s64 	%rd70, %rd69, %rd64;
	add.s64 	%rd71, %rd70, %rd52;
	ld.global.nc.f32 	%f81, [%rd71];
	add.rn.f32 	%f21, %f80, %f81;
	ld.global.nc.f32 	%f82, [%rd15];
	add.rn.f32 	%f83, %f82, %f82;
	add.rn.f32 	%f22, %f83, %f83;
	mul.rn.f32 	%f84, %f22, 0f3F22F983;
	cvt.rni.s32.f32 	%r134, %f84;
	cvt.rn.f32.s32 	%f85, %r134;
	fma.rn.f32 	%f86, %f85, 0fBFC90FDA, %f22;
	fma.rn.f32 	%f87, %f85, 0fB3A22168, %f86;
	fma.rn.f32 	%f168, %f85, 0fA7C234C5, %f87;
	abs.f32 	%f24, %f22;
	setp.ltu.f32 	%p9, %f24, 0f47CE4780;
	@%p9 bra 	$L__BB179_22;
	setp.neu.f32 	%p10, %f24, 0f7F800000;
	@%p10 bra 	$L__BB179_17;
	mov.f32 	%f90, 0f00000000;
	mul.rn.f32 	%f168, %f22, %f90;
	mov.b32 	%r134, 0;
	bra.uni 	$L__BB179_22;
$L__BB179_17:
	mov.b32 	%r9, %f22;
	shr.u32 	%r10, %r9, 23;
	and.b32  	%r57, %r10, 224;
	add.s32 	%r58, %r57, -128;
	shl.b32 	%r59, %r9, 8;
	or.b32  	%r63, %r59, -2147483648;
	shr.u32 	%r12, %r58, 5;
	mov.b32 	%r131, 0;
	mov.u64 	%rd155, 0;
$L__BB179_18:
	.pragma "nounroll";
	add.s64 	%rd74, %rd154, %rd155;
	ld.global.nc.u32 	%r62, [%rd74];
	// begin inline asm
	{
	mad.lo.cc.u32   %r60, %r62, %r63, %r131;
	madc.hi.u32     %r131, %r62, %r63,  0;
	}
	// end inline asm
	add.s64 	%rd75, %rd8, %rd155;
	st.local.u32 	[%rd75], %r60;
	add.s64 	%rd155, %rd155, 4;
	cvt.u32.u64 	%r65, %rd155;
	setp.ne.s32 	%p11, %r65, 24;
	@%p11 bra 	$L__BB179_18;
	st.local.u32 	[%rd8+24], %r131;
	and.b32  	%r15, %r10, 31;
	mul.wide.u32 	%rd76, %r12, 4;
	sub.s64 	%rd23, %rd8, %rd76;
	ld.local.u32 	%r132, [%rd23+24];
	ld.local.u32 	%r133, [%rd23+20];
	setp.eq.s32 	%p12, %r15, 0;
	@%p12 bra 	$L__BB179_21;
	shl.b32 	%r66, %r133, %r15;
	shl.b32 	%r67, %r132, %r15;
	mov.b32 	%r68, 32;
	sub.s32 	%r69, %r68, %r15;
	shr.u32 	%r70, %r133, %r69;
	add.s32 	%r132, %r70, %r67;
	ld.local.u32 	%r71, [%rd23+16];
	shr.u32 	%r72, %r71, %r69;
	add.s32 	%r133, %r72, %r66;
$L__BB179_21:
	shr.u32 	%r73, %r132, 30;
	shr.u32 	%r74, %r133, 30;
	shl.b32 	%r75, %r132, 2;
	or.b32  	%r76, %r75, %r74;
	shl.b32 	%r77, %r133, 2;
	bfe.u32 	%r78, %r132, 29, 1;
	add.s32 	%r79, %r78, %r73;
	neg.s32 	%r80, %r79;
	setp.lt.s32 	%p13, %r9, 0;
	selp.b32 	%r134, %r80, %r79, %p13;
	xor.b32  	%r81, %r76, %r9;
	bfe.s32 	%r82, %r132, 29, 1;
	xor.b32  	%r83, %r82, %r76;
	xor.b32  	%r84, %r82, %r77;
	cvt.u64.u32 	%rd77, %r83;
	shl.b64 	%rd78, %rd77, 32;
	cvt.u64.u32 	%rd79, %r84;
	or.b64  	%rd80, %rd78, %rd79;
	cvt.rn.f64.s64 	%fd1, %rd80;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f88, %fd2;
	neg.f32 	%f89, %f88;
	setp.lt.s32 	%p14, %r81, 0;
	selp.f32 	%f168, %f89, %f88, %p14;
$L__BB179_22:
	add.s32 	%r86, %r134, 1;
	mul.rn.f32 	%f91, %f168, %f168;
	and.b32  	%r87, %r134, 1;
	setp.eq.b32 	%p15, %r87, 1;
	selp.f32 	%f92, %f168, 0f3F800000, %p15;
	fma.rn.f32 	%f93, %f91, %f92, 0f00000000;
	fma.rn.f32 	%f94, %f91, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f95, 0fB94D4153, %f94, %p15;
	selp.f32 	%f96, 0f3C0885E4, 0f3D2AAABB, %p15;
	fma.rn.f32 	%f97, %f95, %f91, %f96;
	selp.f32 	%f98, 0fBE2AAAA8, 0fBEFFFFFF, %p15;
	fma.rn.f32 	%f99, %f97, %f91, %f98;
	fma.rn.f32 	%f100, %f99, %f93, %f92;
	and.b32  	%r88, %r86, 2;
	setp.eq.s32 	%p16, %r88, 0;
	mov.f32 	%f101, 0f00000000;
	sub.rn.f32 	%f102, %f101, %f100;
	selp.f32 	%f103, %f100, %f102, %p16;
	ex2.approx.ftz.f32 	%f104, %f2;
	mul.rn.f32 	%f105, %f104, %f3;
	add.s64 	%rd86, %rd56, %rd64;
	add.s64 	%rd88, %rd86, %rd52;
	ld.global.nc.f32 	%f106, [%rd88];
	mul.rn.f32 	%f107, %f105, %f106;
	mul.rn.f32 	%f108, %f107, %f103;
	add.rn.f32 	%f162, %f21, %f108;
$L__BB179_5:
	add.s64 	%rd92, %rd47, %rd55;
	add.s64 	%rd20, %rd92, %rd52;
	mov.f32 	%f163, %f41;
	@%p17 bra 	$L__BB179_23;
	bra.uni 	$L__BB179_6;
$L__BB179_23:
	ld.global.nc.f32 	%f163, [%rd20];
$L__BB179_6:
	add.rn.f32 	%f8, %f160, %f161;
	add.rn.f32 	%f10, %f8, %f162;
	mul.lo.s64 	%rd94, %rd10, 19200;
	add.s64 	%rd95, %rd7, %rd94;
	mul.lo.s64 	%rd96, %rd17, 384;
	add.s64 	%rd97, %rd95, %rd96;
	mul.lo.s64 	%rd98, %rd16, 24;
	add.s64 	%rd99, %rd97, %rd98;
	add.s64 	%rd101, %rd99, %rd52;
	ld.global.nc.f32 	%f113, [%rd101];
	mov.f32 	%f164, %f41;
	@%p1 bra 	$L__BB179_24;
	bra.uni 	$L__BB179_7;
$L__BB179_24:
	ld.global.nc.f32 	%f164, [%rd18];
$L__BB179_7:
	add.rn.f32 	%f111, %f10, %f163;
	mov.f32 	%f165, %f41;
	@%p2 bra 	$L__BB179_25;
	bra.uni 	$L__BB179_8;
$L__BB179_25:
	ld.global.nc.f32 	%f165, [%rd19];
$L__BB179_8:
	mul.rn.f32 	%f112, %f1, %f111;
	mov.f32 	%f166, %f41;
	@%p4 bra 	$L__BB179_26;
	bra.uni 	$L__BB179_9;
$L__BB179_26:
	add.s64 	%rd103, %rd4, %rd46;
	add.s64 	%rd105, %rd103, %rd55;
	mul.lo.s64 	%rd106, %rd14, 24;
	add.s64 	%rd107, %rd105, %rd106;
	add.s64 	%rd109, %rd107, %rd52;
	ld.global.nc.f32 	%f117, [%rd109];
	add.s64 	%rd110, %rd3, %rd46;
	add.s64 	%rd111, %rd110, %rd55;
	add.s64 	%rd112, %rd111, %rd106;
	add.s64 	%rd113, %rd112, %rd52;
	ld.global.nc.f32 	%f118, [%rd113];
	add.rn.f32 	%f32, %f117, %f118;
	ld.global.nc.f32 	%f119, [%rd15];
	add.rn.f32 	%f120, %f119, %f119;
	add.rn.f32 	%f33, %f120, %f120;
	mul.rn.f32 	%f121, %f33, 0f3F22F983;
	cvt.rni.s32.f32 	%r138, %f121;
	cvt.rn.f32.s32 	%f122, %r138;
	fma.rn.f32 	%f123, %f122, 0fBFC90FDA, %f33;
	fma.rn.f32 	%f124, %f122, 0fB3A22168, %f123;
	fma.rn.f32 	%f169, %f122, 0fA7C234C5, %f124;
	abs.f32 	%f35, %f33;
	setp.ltu.f32 	%p19, %f35, 0f47CE4780;
	@%p19 bra 	$L__BB179_34;
	setp.neu.f32 	%p20, %f35, 0f7F800000;
	@%p20 bra 	$L__BB179_29;
	mov.f32 	%f127, 0f00000000;
	mul.rn.f32 	%f169, %f33, %f127;
	mov.b32 	%r138, 0;
	bra.uni 	$L__BB179_34;
$L__BB179_29:
	mov.b32 	%r135, 0;
	mov.b32 	%r25, %f33;
	shr.u32 	%r26, %r25, 23;
	and.b32  	%r90, %r26, 224;
	add.s32 	%r91, %r90, -128;
	shl.b32 	%r92, %r25, 8;
	or.b32  	%r96, %r92, -2147483648;
	shr.u32 	%r28, %r91, 5;
	mov.u64 	%rd156, 0;
$L__BB179_30:
	.pragma "nounroll";
	add.s64 	%rd116, %rd154, %rd156;
	ld.global.nc.u32 	%r95, [%rd116];
	// begin inline asm
	{
	mad.lo.cc.u32   %r93, %r95, %r96, %r135;
	madc.hi.u32     %r135, %r95, %r96,  0;
	}
	// end inline asm
	add.s64 	%rd117, %rd8, %rd156;
	st.local.u32 	[%rd117], %r93;
	add.s64 	%rd156, %rd156, 4;
	cvt.u32.u64 	%r98, %rd156;
	setp.ne.s32 	%p21, %r98, 24;
	@%p21 bra 	$L__BB179_30;
	st.local.u32 	[%rd8+24], %r135;
	and.b32  	%r31, %r26, 31;
	mul.wide.u32 	%rd118, %r28, 4;
	sub.s64 	%rd26, %rd8, %rd118;
	ld.local.u32 	%r136, [%rd26+24];
	ld.local.u32 	%r137, [%rd26+20];
	setp.eq.s32 	%p22, %r31, 0;
	@%p22 bra 	$L__BB179_33;
	shl.b32 	%r99, %r137, %r31;
	shl.b32 	%r100, %r136, %r31;
	mov.b32 	%r101, 32;
	sub.s32 	%r102, %r101, %r31;
	shr.u32 	%r103, %r137, %r102;
	add.s32 	%r136, %r103, %r100;
	ld.local.u32 	%r104, [%rd26+16];
	shr.u32 	%r105, %r104, %r102;
	add.s32 	%r137, %r105, %r99;
$L__BB179_33:
	shr.u32 	%r106, %r136, 30;
	shr.u32 	%r107, %r137, 30;
	shl.b32 	%r108, %r136, 2;
	or.b32  	%r109, %r108, %r107;
	shl.b32 	%r110, %r137, 2;
	bfe.u32 	%r111, %r136, 29, 1;
	add.s32 	%r112, %r111, %r106;
	neg.s32 	%r113, %r112;
	setp.lt.s32 	%p23, %r25, 0;
	selp.b32 	%r138, %r113, %r112, %p23;
	xor.b32  	%r114, %r109, %r25;
	bfe.s32 	%r115, %r136, 29, 1;
	xor.b32  	%r116, %r115, %r109;
	xor.b32  	%r117, %r115, %r110;
	cvt.u64.u32 	%rd119, %r116;
	shl.b64 	%rd120, %rd119, 32;
	cvt.u64.u32 	%rd121, %r117;
	or.b64  	%rd122, %rd120, %rd121;
	cvt.rn.f64.s64 	%fd3, %rd122;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f125, %fd4;
	neg.f32 	%f126, %f125;
	setp.lt.s32 	%p24, %r114, 0;
	selp.f32 	%f169, %f126, %f125, %p24;
$L__BB179_34:
	add.s32 	%r119, %r138, 1;
	mul.rn.f32 	%f128, %f169, %f169;
	and.b32  	%r120, %r138, 1;
	setp.eq.b32 	%p25, %r120, 1;
	selp.f32 	%f129, %f169, 0f3F800000, %p25;
	fma.rn.f32 	%f130, %f128, %f129, 0f00000000;
	fma.rn.f32 	%f131, %f128, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f132, 0fB94D4153, %f131, %p25;
	selp.f32 	%f133, 0f3C0885E4, 0f3D2AAABB, %p25;
	fma.rn.f32 	%f134, %f132, %f128, %f133;
	selp.f32 	%f135, 0fBE2AAAA8, 0fBEFFFFFF, %p25;
	fma.rn.f32 	%f136, %f134, %f128, %f135;
	fma.rn.f32 	%f137, %f136, %f130, %f129;
	and.b32  	%r121, %r119, 2;
	setp.eq.s32 	%p26, %r121, 0;
	mov.f32 	%f138, 0f00000000;
	sub.rn.f32 	%f139, %f138, %f137;
	selp.f32 	%f140, %f137, %f139, %p26;
	ex2.approx.ftz.f32 	%f141, %f2;
	mul.rn.f32 	%f142, %f141, %f3;
	add.s64 	%rd128, %rd56, %rd106;
	add.s64 	%rd130, %rd128, %rd52;
	ld.global.nc.f32 	%f143, [%rd130];
	mul.rn.f32 	%f144, %f142, %f143;
	mul.rn.f32 	%f145, %f144, %f140;
	add.rn.f32 	%f166, %f32, %f145;
$L__BB179_9:
	mul.rn.f32 	%f114, %f113, %f112;
	mov.f32 	%f167, %f41;
	@%p17 bra 	$L__BB179_35;
	bra.uni 	$L__BB179_10;
$L__BB179_35:
	ld.global.nc.f32 	%f167, [%rd20];
	bra.uni 	$L__BB179_10;
$L__BB179_11:
	mul.wide.u32 	%rd139, %r2, 132;
	mov.u64 	%rd140, shared_cache13;
	add.s64 	%rd141, %rd140, %rd139;
	mul.wide.u32 	%rd142, %r1, 4;
	add.s64 	%rd143, %rd141, %rd142;
	st.shared.f32 	[%rd143], %f4;
	bar.sync 	0;
	mul.wide.u32 	%rd144, %r1, 132;
	add.s64 	%rd145, %rd140, %rd144;
	mul.wide.u32 	%rd146, %r2, 4;
	add.s64 	%rd147, %rd145, %rd146;
	ld.shared.f32 	%f148, [%rd147];
	shfl.sync.down.b32	%f149, %f148, 16, 31, -1;
	add.rn.f32 	%f150, %f148, %f149;
	shfl.sync.down.b32	%f151, %f150, 8, 31, -1;
	add.rn.f32 	%f152, %f150, %f151;
	shfl.sync.down.b32	%f153, %f152, 4, 31, -1;
	add.rn.f32 	%f154, %f152, %f153;
	shfl.sync.down.b32	%f155, %f154, 2, 31, -1;
	add.rn.f32 	%f156, %f154, %f155;
	shfl.sync.down.b32	%f157, %f156, 1, 31, -1;
	add.rn.f32 	%f5, %f156, %f157;
	st.shared.f32 	[%rd147], %f5;
	setp.eq.s32 	%p29, %r2, 0;
	@%p29 bra 	$L__BB179_36;
	bra.uni 	$L__BB179_12;
$L__BB179_36:
	or.b32  	%r123, %r1, %r3;
	mul.hi.u32 	%r125, %r123, -1431655765;
	shr.u32 	%r126, %r125, 2;
	mul.lo.s32 	%r127, %r126, 6;
	sub.s32 	%r128, %r123, %r127;
	mul.lo.s64 	%rd148, %rd10, 384;
	add.s64 	%rd149, %rd2, %rd148;
	mul.wide.u32 	%rd150, %r126, 24;
	add.s64 	%rd151, %rd149, %rd150;
	mul.wide.u32 	%rd152, %r128, 4;
	add.s64 	%rd153, %rd151, %rd152;
	neg.f32 	%f158, %f5;
	st.global.f32 	[%rd153], %f158;
$L__BB179_12:
	ret;

}
	// .globl	input_reduce_transpose_fusion_12
.visible .entry input_reduce_transpose_fusion_12(
	.param .u64 input_reduce_transpose_fusion_12_param_0,
	.param .u64 input_reduce_transpose_fusion_12_param_1,
	.param .u64 input_reduce_transpose_fusion_12_param_2,
	.param .u64 input_reduce_transpose_fusion_12_param_3,
	.param .u64 input_reduce_transpose_fusion_12_param_4,
	.param .u64 input_reduce_transpose_fusion_12_param_5,
	.param .u64 input_reduce_transpose_fusion_12_param_6,
	.param .u64 input_reduce_transpose_fusion_12_param_7,
	.param .u64 input_reduce_transpose_fusion_12_param_8,
	.param .u64 input_reduce_transpose_fusion_12_param_9
)
.reqntid 1024, 1, 1
{
	.local .align 4 .b8 	__local_depot180[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<41>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<252>;
	.reg .f32 	%f<206>;
	.reg .b64 	%rd<183>;
	.reg .f64 	%fd<9>;
	// demoted variable
	.shared .align 4 .b8 shared_cache14[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache15[4224];
	mov.u64 	%SPL, __local_depot180;
	ld.param.u64 	%rd43, [input_reduce_transpose_fusion_12_param_0];
	ld.param.u64 	%rd44, [input_reduce_transpose_fusion_12_param_9];
	cvta.to.global.u64 	%rd1, %rd44;
	ld.param.u64 	%rd45, [input_reduce_transpose_fusion_12_param_1];
	ld.param.u64 	%rd46, [input_reduce_transpose_fusion_12_param_8];
	cvta.to.global.u64 	%rd2, %rd46;
	ld.param.u64 	%rd47, [input_reduce_transpose_fusion_12_param_2];
	ld.param.u64 	%rd48, [input_reduce_transpose_fusion_12_param_7];
	cvta.to.global.u64 	%rd3, %rd48;
	ld.param.u64 	%rd49, [input_reduce_transpose_fusion_12_param_3];
	ld.param.u64 	%rd50, [input_reduce_transpose_fusion_12_param_6];
	cvta.to.global.u64 	%rd4, %rd50;
	ld.param.u64 	%rd51, [input_reduce_transpose_fusion_12_param_4];
	ld.param.u64 	%rd52, [input_reduce_transpose_fusion_12_param_5];
	cvta.to.global.u64 	%rd5, %rd52;
	cvta.to.global.u64 	%rd6, %rd51;
	cvta.to.global.u64 	%rd7, %rd49;
	cvta.to.global.u64 	%rd8, %rd47;
	cvta.to.global.u64 	%rd9, %rd45;
	cvta.to.global.u64 	%rd10, %rd43;
	add.u64 	%rd11, %SPL, 0;
	mov.u32 	%r72, %tid.x;
	mov.u32 	%r73, %ctaid.x;
	shr.u32 	%r1, %r72, 5;
	and.b32  	%r2, %r72, 31;
	and.b32  	%r74, %r73, 1;
	shr.u32 	%r75, %r73, 1;
	setp.eq.s32 	%p2, %r74, 0;
	selp.b32 	%r3, 32, 16, %p2;
	shl.b32 	%r4, %r74, 5;
	or.b32  	%r76, %r4, %r2;
	cvt.u16.u32 	%rs1, %r76;
	mul.lo.s16 	%rs2, %rs1, 43;
	shr.u16 	%rs3, %rs2, 8;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	cvt.u32.u16 	%r77, %rs5;
	cvt.u64.u32 	%rd15, %r75;
	mul.wide.u32 	%rd57, %r75, 4;
	add.s64 	%rd16, %rd8, %rd57;
	cvt.u64.u16 	%rd17, %rs3;
	cvt.u64.u16 	%rd58, %rs5;
	and.b64  	%rd18, %rd58, 255;
	and.b32  	%r78, %r77, 1;
	bfe.u32 	%r79, %r77, 1, 7;
	cvt.u64.u32 	%rd19, %r79;
	cvt.u64.u32 	%rd20, %r78;
	mul.wide.u32 	%rd59, %r79, 4;
	mul.wide.u32 	%rd60, %r75, 12;
	add.s64 	%rd61, %rd9, %rd60;
	add.s64 	%rd21, %rd61, %rd59;
	shr.u16 	%rs6, %rs2, 7;
	cvt.u64.u16 	%rd62, %rs6;
	and.b64  	%rd22, %rd62, 254;
	mad.lo.s32 	%r5, %r75, 2400, %r76;
	and.b32  	%r80, %r72, 15;
	cvt.u64.u32 	%rd23, %r80;
	mov.f32 	%f198, 0f00000000;
	setp.lt.u32 	%p3, %r2, %r3;
	mov.f32 	%f36, 0f4B400001;
	mul.lo.s64 	%rd67, %rd17, 24;
	shl.b64 	%rd74, %rd19, 3;
	shl.b64 	%rd76, %rd20, 2;
	mul.lo.s64 	%rd91, %rd22, 24;
	mov.u32 	%r235, %r1;
	mov.f32 	%f199, %f198;
	bra.uni 	$L__BB180_1;
$L__BB180_32:
	mul.rn.f32 	%f205, %f21, %f84;
	mov.b32 	%r251, 0;
$L__BB180_38:
	add.rn.f32 	%f199, %f199, %f64;
	add.rn.f32 	%f198, %f198, %f106;
	cvt.u64.u32 	%rd34, %r156;
	cvt.u64.u32 	%rd38, %r39;
	mul.rn.f32 	%f162, %f205, %f205;
	and.b32  	%r223, %r251, 1;
	setp.eq.b32 	%p34, %r223, 1;
	selp.f32 	%f163, 0f3F800000, %f205, %p34;
	fma.rn.f32 	%f164, %f162, %f163, 0f00000000;
	fma.rn.f32 	%f165, %f162, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f166, %f165, 0fB94D4153, %p34;
	selp.f32 	%f167, 0f3D2AAABB, 0f3C0885E4, %p34;
	fma.rn.f32 	%f168, %f166, %f162, %f167;
	selp.f32 	%f169, 0fBEFFFFFF, 0fBE2AAAA8, %p34;
	fma.rn.f32 	%f170, %f168, %f162, %f169;
	fma.rn.f32 	%f171, %f170, %f164, %f163;
	and.b32  	%r224, %r251, 2;
	setp.eq.s32 	%p35, %r224, 0;
	sub.rn.f32 	%f173, %f84, %f171;
	selp.f32 	%f174, %f171, %f173, %p35;
	ld.global.nc.f32 	%f175, [%rd39+4];
	mul.rn.f32 	%f176, %f27, %f175;
	mul.rn.f32 	%f177, %f176, %f174;
	mul.lo.s64 	%rd135, %rd34, 204800;
	add.s64 	%rd136, %rd4, %rd135;
	mul.lo.s64 	%rd137, %rd33, 3200;
	add.s64 	%rd138, %rd136, %rd137;
	shl.b64 	%rd139, %rd38, 6;
	add.s64 	%rd140, %rd138, %rd139;
	shl.b64 	%rd141, %rd23, 2;
	add.s64 	%rd142, %rd140, %rd141;
	st.global.f32 	[%rd142], %f28;
	add.s64 	%rd143, %rd3, %rd135;
	add.s64 	%rd144, %rd143, %rd137;
	add.s64 	%rd145, %rd144, %rd139;
	add.s64 	%rd146, %rd145, %rd141;
	st.global.f32 	[%rd146], %f177;
$L__BB180_2:
	add.s32 	%r7, %r235, 32;
	setp.lt.u32 	%p36, %r235, 18;
	mov.u32 	%r235, %r7;
	@%p36 bra 	$L__BB180_1;
	bra.uni 	$L__BB180_3;
$L__BB180_1:
	@%p3 bra 	$L__BB180_6;
	bra.uni 	$L__BB180_2;
$L__BB180_6:
	ld.global.nc.f32 	%f33, [%rd16];
	fma.rn.f32 	%f34, %f33, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f35, %f34;
	mov.f32 	%f37, 0f437C0000;
	fma.rm.f32 	%f38, %f35, %f37, %f36;
	add.rn.f32 	%f39, %f38, 0fCB40007F;
	neg.f32 	%f40, %f39;
	fma.rn.f32 	%f41, %f33, 0f3FB8AA3B, %f40;
	fma.rn.f32 	%f42, %f33, 0f32A57060, %f41;
	mov.b32 	%r81, %f38;
	shl.b32 	%r82, %r81, 23;
	mov.b32 	%f43, %r82;
	ex2.approx.ftz.f32 	%f44, %f42;
	mul.rn.f32 	%f45, %f44, %f43;
	neg.f32 	%f46, %f45;
	sub.rn.f32 	%f47, %f46, %f45;
	add.rn.f32 	%f48, %f47, %f47;
	add.rn.f32 	%f49, %f48, %f48;
	add.rn.f32 	%f50, %f49, %f49;
	add.rn.f32 	%f51, %f50, %f50;
	add.rn.f32 	%f52, %f51, %f51;
	fma.rn.f32 	%f53, %f52, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f54, %f53;
	fma.rm.f32 	%f55, %f54, %f37, %f36;
	add.rn.f32 	%f56, %f55, 0fCB40007F;
	neg.f32 	%f57, %f56;
	fma.rn.f32 	%f58, %f52, 0f3FB8AA3B, %f57;
	fma.rn.f32 	%f59, %f52, 0f32A57060, %f58;
	mov.b32 	%r83, %f55;
	ex2.approx.ftz.f32 	%f61, %f59;
	mul.lo.s64 	%rd63, %rd15, 9600;
	add.s64 	%rd64, %rd6, %rd63;
	mul.wide.u32 	%rd65, %r235, 192;
	add.s64 	%rd66, %rd64, %rd65;
	add.s64 	%rd68, %rd66, %rd67;
	shl.b64 	%rd69, %rd18, 2;
	add.s64 	%rd70, %rd68, %rd69;
	ld.global.nc.f32 	%f7, [%rd70];
	add.s64 	%rd71, %rd7, %rd63;
	add.s64 	%rd72, %rd71, %rd65;
	add.s64 	%rd73, %rd72, %rd67;
	add.s64 	%rd75, %rd73, %rd74;
	add.s64 	%rd77, %rd75, %rd76;
	ld.global.nc.f32 	%f8, [%rd77];
	ld.global.nc.f32 	%f65, [%rd21];
	add.rn.f32 	%f66, %f65, %f65;
	add.rn.f32 	%f10, %f66, %f66;
	mul.rn.f32 	%f67, %f10, 0f3F22F983;
	cvt.rni.s32.f32 	%r243, %f67;
	cvt.rn.f32.s32 	%f68, %r243;
	fma.rn.f32 	%f69, %f68, 0fBFC90FDA, %f10;
	fma.rn.f32 	%f70, %f68, 0fB3A22168, %f69;
	fma.rn.f32 	%f203, %f68, 0fA7C234C5, %f70;
	abs.f32 	%f12, %f10;
	setp.ltu.f32 	%p4, %f12, 0f47CE4780;
	setp.neu.f32 	%p39, %f12, 0f7F800000;
	mov.u64 	%rd178, __cudart_i2opi_f;
	mov.u32 	%r239, %r243;
	mov.f32 	%f202, %f203;
	@%p4 bra 	$L__BB180_14;
	@%p39 bra 	$L__BB180_9;
	mov.f32 	%f73, 0f00000000;
	mul.rn.f32 	%f202, %f10, %f73;
	mov.b32 	%r239, 0;
	bra.uni 	$L__BB180_14;
$L__BB180_9:
	mov.b32 	%r236, 0;
	mov.b32 	%r9, %f10;
	shr.u32 	%r10, %r9, 23;
	and.b32  	%r86, %r10, 224;
	add.s32 	%r87, %r86, -128;
	shl.b32 	%r88, %r9, 8;
	or.b32  	%r92, %r88, -2147483648;
	shr.u32 	%r12, %r87, 5;
	mov.u64 	%rd179, 0;
$L__BB180_10:
	.pragma "nounroll";
	add.s64 	%rd80, %rd178, %rd179;
	ld.global.nc.u32 	%r91, [%rd80];
	// begin inline asm
	{
	mad.lo.cc.u32   %r89, %r91, %r92, %r236;
	madc.hi.u32     %r236, %r91, %r92,  0;
	}
	// end inline asm
	add.s64 	%rd81, %rd11, %rd179;
	st.local.u32 	[%rd81], %r89;
	add.s64 	%rd179, %rd179, 4;
	cvt.u32.u64 	%r94, %rd179;
	setp.ne.s32 	%p6, %r94, 24;
	@%p6 bra 	$L__BB180_10;
	st.local.u32 	[%rd11+24], %r236;
	and.b32  	%r15, %r10, 31;
	mul.wide.u32 	%rd82, %r12, 4;
	sub.s64 	%rd29, %rd11, %rd82;
	ld.local.u32 	%r237, [%rd29+24];
	ld.local.u32 	%r238, [%rd29+20];
	setp.eq.s32 	%p7, %r15, 0;
	@%p7 bra 	$L__BB180_13;
	shl.b32 	%r95, %r238, %r15;
	shl.b32 	%r96, %r237, %r15;
	mov.b32 	%r97, 32;
	sub.s32 	%r98, %r97, %r15;
	shr.u32 	%r99, %r238, %r98;
	add.s32 	%r237, %r99, %r96;
	ld.local.u32 	%r100, [%rd29+16];
	shr.u32 	%r101, %r100, %r98;
	add.s32 	%r238, %r101, %r95;
$L__BB180_13:
	shr.u32 	%r102, %r237, 30;
	shr.u32 	%r103, %r238, 30;
	shl.b32 	%r104, %r237, 2;
	or.b32  	%r105, %r104, %r103;
	shl.b32 	%r106, %r238, 2;
	bfe.u32 	%r107, %r237, 29, 1;
	add.s32 	%r108, %r107, %r102;
	neg.s32 	%r109, %r108;
	setp.lt.s32 	%p8, %r9, 0;
	selp.b32 	%r239, %r109, %r108, %p8;
	xor.b32  	%r110, %r105, %r9;
	bfe.s32 	%r111, %r237, 29, 1;
	xor.b32  	%r112, %r111, %r105;
	xor.b32  	%r113, %r111, %r106;
	cvt.u64.u32 	%rd83, %r112;
	shl.b64 	%rd84, %rd83, 32;
	cvt.u64.u32 	%rd85, %r113;
	or.b64  	%rd86, %rd84, %rd85;
	cvt.rn.f64.s64 	%fd1, %rd86;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f71, %fd2;
	neg.f32 	%f72, %f71;
	setp.lt.s32 	%p9, %r110, 0;
	selp.f32 	%f202, %f72, %f71, %p9;
$L__BB180_14:
	shl.b32 	%r84, %r83, 23;
	mov.b32 	%f60, %r84;
	mul.rn.f32 	%f62, %f61, %f60;
	cvt.u64.u32 	%rd26, %r235;
	add.s32 	%r115, %r239, 1;
	mul.rn.f32 	%f74, %f202, %f202;
	and.b32  	%r116, %r239, 1;
	setp.eq.b32 	%p11, %r116, 1;
	selp.f32 	%f75, %f202, 0f3F800000, %p11;
	fma.rn.f32 	%f76, %f74, %f75, 0f00000000;
	fma.rn.f32 	%f77, %f74, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f78, 0fB94D4153, %f77, %p11;
	selp.f32 	%f79, 0f3C0885E4, 0f3D2AAABB, %p11;
	fma.rn.f32 	%f80, %f78, %f74, %f79;
	selp.f32 	%f81, 0fBE2AAAA8, 0fBEFFFFFF, %p11;
	fma.rn.f32 	%f82, %f80, %f74, %f81;
	fma.rn.f32 	%f83, %f82, %f76, %f75;
	and.b32  	%r117, %r115, 2;
	setp.eq.s32 	%p12, %r117, 0;
	mov.f32 	%f84, 0f00000000;
	sub.rn.f32 	%f85, %f84, %f83;
	selp.f32 	%f86, %f83, %f85, %p12;
	mul.lo.s64 	%rd87, %rd15, 19200;
	add.s64 	%rd88, %rd5, %rd87;
	mul.lo.s64 	%rd89, %rd26, 384;
	add.s64 	%rd90, %rd88, %rd89;
	add.s64 	%rd92, %rd90, %rd91;
	add.s64 	%rd94, %rd92, %rd69;
	ld.global.nc.f32 	%f87, [%rd94];
	mul.rn.f32 	%f16, %f87, %f86;
	@%p4 bra 	$L__BB180_22;
	@%p39 bra 	$L__BB180_17;
	mul.rn.f32 	%f203, %f10, %f84;
	mov.b32 	%r243, 0;
	bra.uni 	$L__BB180_22;
$L__BB180_17:
	mov.b32 	%r24, %f10;
	shr.u32 	%r25, %r24, 23;
	and.b32  	%r119, %r25, 224;
	add.s32 	%r120, %r119, -128;
	shl.b32 	%r121, %r24, 8;
	or.b32  	%r125, %r121, -2147483648;
	shr.u32 	%r27, %r120, 5;
	mov.b32 	%r240, 0;
	mov.u64 	%rd180, 0;
$L__BB180_18:
	.pragma "nounroll";
	add.s64 	%rd97, %rd178, %rd180;
	ld.global.nc.u32 	%r124, [%rd97];
	// begin inline asm
	{
	mad.lo.cc.u32   %r122, %r124, %r125, %r240;
	madc.hi.u32     %r240, %r124, %r125,  0;
	}
	// end inline asm
	add.s64 	%rd98, %rd11, %rd180;
	st.local.u32 	[%rd98], %r122;
	add.s64 	%rd180, %rd180, 4;
	cvt.u32.u64 	%r127, %rd180;
	setp.ne.s32 	%p14, %r127, 24;
	@%p14 bra 	$L__BB180_18;
	st.local.u32 	[%rd11+24], %r240;
	and.b32  	%r30, %r25, 31;
	mul.wide.u32 	%rd99, %r27, 4;
	sub.s64 	%rd32, %rd11, %rd99;
	ld.local.u32 	%r241, [%rd32+24];
	ld.local.u32 	%r242, [%rd32+20];
	setp.eq.s32 	%p15, %r30, 0;
	@%p15 bra 	$L__BB180_21;
	shl.b32 	%r128, %r242, %r30;
	shl.b32 	%r129, %r241, %r30;
	mov.b32 	%r130, 32;
	sub.s32 	%r131, %r130, %r30;
	shr.u32 	%r132, %r242, %r131;
	add.s32 	%r241, %r132, %r129;
	ld.local.u32 	%r133, [%rd32+16];
	shr.u32 	%r134, %r133, %r131;
	add.s32 	%r242, %r134, %r128;
$L__BB180_21:
	shr.u32 	%r135, %r241, 30;
	shr.u32 	%r136, %r242, 30;
	shl.b32 	%r137, %r241, 2;
	or.b32  	%r138, %r137, %r136;
	shl.b32 	%r139, %r242, 2;
	bfe.u32 	%r140, %r241, 29, 1;
	add.s32 	%r141, %r140, %r135;
	neg.s32 	%r142, %r141;
	setp.lt.s32 	%p16, %r24, 0;
	selp.b32 	%r243, %r142, %r141, %p16;
	xor.b32  	%r143, %r138, %r24;
	bfe.s32 	%r144, %r241, 29, 1;
	xor.b32  	%r145, %r144, %r138;
	xor.b32  	%r146, %r144, %r139;
	cvt.u64.u32 	%rd100, %r145;
	shl.b64 	%rd101, %rd100, 32;
	cvt.u64.u32 	%rd102, %r146;
	or.b64  	%rd103, %rd101, %rd102;
	cvt.rn.f64.s64 	%fd3, %rd103;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f88, %fd4;
	neg.f32 	%f89, %f88;
	setp.lt.s32 	%p17, %r143, 0;
	selp.f32 	%f203, %f89, %f88, %p17;
$L__BB180_22:
	mul.rn.f32 	%f63, %f7, %f62;
	mul.rn.f32 	%f91, %f203, %f203;
	and.b32  	%r148, %r243, 1;
	setp.eq.b32 	%p18, %r148, 1;
	selp.f32 	%f92, 0f3F800000, %f203, %p18;
	fma.rn.f32 	%f93, %f91, %f92, 0f00000000;
	fma.rn.f32 	%f94, %f91, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f95, %f94, 0fB94D4153, %p18;
	selp.f32 	%f96, 0f3D2AAABB, 0f3C0885E4, %p18;
	fma.rn.f32 	%f97, %f95, %f91, %f96;
	selp.f32 	%f98, 0fBEFFFFFF, 0fBE2AAAA8, %p18;
	fma.rn.f32 	%f99, %f97, %f91, %f98;
	fma.rn.f32 	%f100, %f99, %f93, %f92;
	and.b32  	%r149, %r243, 2;
	setp.eq.s32 	%p19, %r149, 0;
	sub.rn.f32 	%f102, %f84, %f100;
	selp.f32 	%f103, %f100, %f102, %p19;
	mul.rn.f32 	%f104, %f8, %f103;
	add.rn.f32 	%f105, %f16, %f104;
	mad.lo.s32 	%r150, %r235, 48, %r5;
	mul.hi.u32 	%r154, %r150, 1374389535;
	bfe.u32 	%r155, %r154, 8, 6;
	shr.u32 	%r156, %r154, 14;
	mul.wide.u32 	%rd104, %r155, 12;
	add.s64 	%rd105, %rd9, %rd104;
	mul.wide.u32 	%rd106, %r156, 4;
	add.s64 	%rd107, %rd105, %rd106;
	ld.global.nc.f32 	%f107, [%rd107];
	add.rn.f32 	%f21, %f107, %f107;
	mul.rn.f32 	%f108, %f21, 0f3F22F983;
	cvt.rni.s32.f32 	%r251, %f108;
	cvt.rn.f32.s32 	%f109, %r251;
	fma.rn.f32 	%f110, %f109, 0fBFC90FDA, %f21;
	fma.rn.f32 	%f111, %f109, 0fB3A22168, %f110;
	fma.rn.f32 	%f205, %f109, 0fA7C234C5, %f111;
	abs.f32 	%f23, %f21;
	setp.ltu.f32 	%p20, %f23, 0f47CE4780;
	setp.neu.f32 	%p40, %f23, 0f7F800000;
	mov.u32 	%r247, %r251;
	mov.f32 	%f204, %f205;
	@%p20 bra 	$L__BB180_30;
	@%p40 bra 	$L__BB180_25;
	mul.rn.f32 	%f204, %f21, %f84;
	mov.b32 	%r247, 0;
	bra.uni 	$L__BB180_30;
$L__BB180_25:
	mov.b32 	%r42, %f21;
	shr.u32 	%r43, %r42, 23;
	and.b32  	%r158, %r43, 224;
	add.s32 	%r159, %r158, -128;
	shl.b32 	%r160, %r42, 8;
	or.b32  	%r164, %r160, -2147483648;
	shr.u32 	%r45, %r159, 5;
	mov.b32 	%r244, 0;
	mov.u64 	%rd181, 0;
$L__BB180_26:
	.pragma "nounroll";
	add.s64 	%rd110, %rd178, %rd181;
	ld.global.nc.u32 	%r163, [%rd110];
	// begin inline asm
	{
	mad.lo.cc.u32   %r161, %r163, %r164, %r244;
	madc.hi.u32     %r244, %r163, %r164,  0;
	}
	// end inline asm
	add.s64 	%rd111, %rd11, %rd181;
	st.local.u32 	[%rd111], %r161;
	add.s64 	%rd181, %rd181, 4;
	cvt.u32.u64 	%r166, %rd181;
	setp.ne.s32 	%p22, %r166, 24;
	@%p22 bra 	$L__BB180_26;
	st.local.u32 	[%rd11+24], %r244;
	and.b32  	%r48, %r43, 31;
	mul.wide.u32 	%rd112, %r45, 4;
	sub.s64 	%rd37, %rd11, %rd112;
	ld.local.u32 	%r245, [%rd37+24];
	ld.local.u32 	%r246, [%rd37+20];
	setp.eq.s32 	%p23, %r48, 0;
	@%p23 bra 	$L__BB180_29;
	shl.b32 	%r167, %r246, %r48;
	shl.b32 	%r168, %r245, %r48;
	mov.b32 	%r169, 32;
	sub.s32 	%r170, %r169, %r48;
	shr.u32 	%r171, %r246, %r170;
	add.s32 	%r245, %r171, %r168;
	ld.local.u32 	%r172, [%rd37+16];
	shr.u32 	%r173, %r172, %r170;
	add.s32 	%r246, %r173, %r167;
$L__BB180_29:
	shr.u32 	%r174, %r245, 30;
	shr.u32 	%r175, %r246, 30;
	shl.b32 	%r176, %r245, 2;
	or.b32  	%r177, %r176, %r175;
	shl.b32 	%r178, %r246, 2;
	bfe.u32 	%r179, %r245, 29, 1;
	add.s32 	%r180, %r179, %r174;
	neg.s32 	%r181, %r180;
	setp.lt.s32 	%p24, %r42, 0;
	selp.b32 	%r247, %r181, %r180, %p24;
	xor.b32  	%r182, %r177, %r42;
	bfe.s32 	%r183, %r245, 29, 1;
	xor.b32  	%r184, %r183, %r177;
	xor.b32  	%r185, %r183, %r178;
	cvt.u64.u32 	%rd113, %r184;
	shl.b64 	%rd114, %rd113, 32;
	cvt.u64.u32 	%rd115, %r185;
	or.b64  	%rd116, %rd114, %rd115;
	cvt.rn.f64.s64 	%fd5, %rd116;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f112, %fd6;
	neg.f32 	%f113, %f112;
	setp.lt.s32 	%p25, %r182, 0;
	selp.f32 	%f204, %f113, %f112, %p25;
$L__BB180_30:
	mul.rn.f32 	%f64, %f8, %f63;
	mul.rn.f32 	%f106, %f7, %f105;
	shr.u32 	%r151, %r150, 4;
	mul.hi.u32 	%r152, %r151, 85899346;
	mul.lo.s32 	%r153, %r152, 50;
	sub.s32 	%r39, %r151, %r153;
	shl.b32 	%r40, %r156, 1;
	cvt.u64.u32 	%rd33, %r155;
	mul.rn.f32 	%f115, %f204, %f204;
	and.b32  	%r187, %r247, 1;
	setp.eq.b32 	%p27, %r187, 1;
	selp.f32 	%f116, 0f3F800000, %f204, %p27;
	fma.rn.f32 	%f117, %f115, %f116, 0f00000000;
	fma.rn.f32 	%f118, %f115, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f119, %f118, 0fB94D4153, %p27;
	selp.f32 	%f120, 0f3D2AAABB, 0f3C0885E4, %p27;
	fma.rn.f32 	%f121, %f119, %f115, %f120;
	selp.f32 	%f122, 0fBEFFFFFF, 0fBE2AAAA8, %p27;
	fma.rn.f32 	%f123, %f121, %f115, %f122;
	fma.rn.f32 	%f124, %f123, %f117, %f116;
	and.b32  	%r188, %r247, 2;
	setp.eq.s32 	%p28, %r188, 0;
	sub.rn.f32 	%f126, %f84, %f124;
	selp.f32 	%f127, %f124, %f126, %p28;
	shl.b64 	%rd117, %rd33, 2;
	add.s64 	%rd118, %rd8, %rd117;
	ld.global.nc.f32 	%f128, [%rd118];
	fma.rn.f32 	%f129, %f128, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f130, %f129;
	fma.rm.f32 	%f133, %f130, %f37, %f36;
	add.rn.f32 	%f134, %f133, 0fCB40007F;
	neg.f32 	%f135, %f134;
	fma.rn.f32 	%f136, %f128, 0f3FB8AA3B, %f135;
	fma.rn.f32 	%f137, %f128, 0f32A57060, %f136;
	mov.b32 	%r189, %f133;
	shl.b32 	%r190, %r189, 23;
	mov.b32 	%f138, %r190;
	ex2.approx.ftz.f32 	%f139, %f137;
	mul.rn.f32 	%f140, %f139, %f138;
	neg.f32 	%f141, %f140;
	sub.rn.f32 	%f142, %f141, %f140;
	add.rn.f32 	%f143, %f142, %f142;
	add.rn.f32 	%f144, %f143, %f143;
	add.rn.f32 	%f145, %f144, %f144;
	add.rn.f32 	%f146, %f145, %f145;
	fma.rn.f32 	%f147, %f146, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f148, %f147;
	fma.rm.f32 	%f149, %f148, %f37, %f36;
	add.rn.f32 	%f150, %f149, 0fCB40007F;
	neg.f32 	%f151, %f150;
	fma.rn.f32 	%f152, %f146, 0f3FB8AA3B, %f151;
	fma.rn.f32 	%f153, %f146, 0f32A57060, %f152;
	mov.b32 	%r191, %f149;
	shl.b32 	%r192, %r191, 23;
	mov.b32 	%f154, %r192;
	ex2.approx.ftz.f32 	%f155, %f153;
	mul.rn.f32 	%f27, %f155, %f154;
	mul.lo.s64 	%rd119, %rd33, 19200;
	add.s64 	%rd120, %rd10, %rd119;
	mul.wide.u32 	%rd121, %r39, 384;
	add.s64 	%rd122, %rd120, %rd121;
	mul.lo.s64 	%rd123, %rd23, 24;
	add.s64 	%rd124, %rd122, %rd123;
	mul.wide.u32 	%rd125, %r40, 4;
	add.s64 	%rd39, %rd124, %rd125;
	ld.global.nc.f32 	%f156, [%rd39];
	mul.rn.f32 	%f157, %f156, %f27;
	neg.f32 	%f158, %f127;
	mul.rn.f32 	%f28, %f157, %f158;
	@%p20 bra 	$L__BB180_38;
	@%p40 bra 	$L__BB180_33;
	bra.uni 	$L__BB180_32;
$L__BB180_33:
	mov.b32 	%r57, %f21;
	shr.u32 	%r58, %r57, 23;
	and.b32  	%r194, %r58, 224;
	add.s32 	%r195, %r194, -128;
	shl.b32 	%r196, %r57, 8;
	or.b32  	%r200, %r196, -2147483648;
	shr.u32 	%r60, %r195, 5;
	mov.b32 	%r248, 0;
	mov.u64 	%rd182, 0;
$L__BB180_34:
	.pragma "nounroll";
	add.s64 	%rd128, %rd178, %rd182;
	ld.global.nc.u32 	%r199, [%rd128];
	// begin inline asm
	{
	mad.lo.cc.u32   %r197, %r199, %r200, %r248;
	madc.hi.u32     %r248, %r199, %r200,  0;
	}
	// end inline asm
	add.s64 	%rd129, %rd11, %rd182;
	st.local.u32 	[%rd129], %r197;
	add.s64 	%rd182, %rd182, 4;
	cvt.u32.u64 	%r202, %rd182;
	setp.ne.s32 	%p30, %r202, 24;
	@%p30 bra 	$L__BB180_34;
	st.local.u32 	[%rd11+24], %r248;
	and.b32  	%r63, %r58, 31;
	mul.wide.u32 	%rd130, %r60, 4;
	sub.s64 	%rd42, %rd11, %rd130;
	ld.local.u32 	%r249, [%rd42+24];
	ld.local.u32 	%r250, [%rd42+20];
	setp.eq.s32 	%p31, %r63, 0;
	@%p31 bra 	$L__BB180_37;
	shl.b32 	%r203, %r250, %r63;
	shl.b32 	%r204, %r249, %r63;
	mov.b32 	%r205, 32;
	sub.s32 	%r206, %r205, %r63;
	shr.u32 	%r207, %r250, %r206;
	add.s32 	%r249, %r207, %r204;
	ld.local.u32 	%r208, [%rd42+16];
	shr.u32 	%r209, %r208, %r206;
	add.s32 	%r250, %r209, %r203;
$L__BB180_37:
	shr.u32 	%r210, %r249, 30;
	shr.u32 	%r211, %r250, 30;
	shl.b32 	%r212, %r249, 2;
	or.b32  	%r213, %r212, %r211;
	shl.b32 	%r214, %r250, 2;
	bfe.u32 	%r215, %r249, 29, 1;
	add.s32 	%r216, %r215, %r210;
	neg.s32 	%r217, %r216;
	setp.lt.s32 	%p32, %r57, 0;
	selp.b32 	%r251, %r217, %r216, %p32;
	xor.b32  	%r218, %r213, %r57;
	bfe.s32 	%r219, %r249, 29, 1;
	xor.b32  	%r220, %r219, %r213;
	xor.b32  	%r221, %r219, %r214;
	cvt.u64.u32 	%rd131, %r220;
	shl.b64 	%rd132, %rd131, 32;
	cvt.u64.u32 	%rd133, %r221;
	or.b64  	%rd134, %rd132, %rd133;
	cvt.rn.f64.s64 	%fd7, %rd134;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f159, %fd8;
	neg.f32 	%f160, %f159;
	setp.lt.s32 	%p33, %r218, 0;
	selp.f32 	%f205, %f160, %f159, %p33;
	bra.uni 	$L__BB180_38;
$L__BB180_3:
	cvt.u64.u32 	%rd24, %r2;
	cvt.u64.u32 	%rd25, %r1;
	mul.wide.u32 	%rd147, %r2, 132;
	mov.u64 	%rd148, shared_cache14;
	add.s64 	%rd149, %rd148, %rd147;
	mul.wide.u32 	%rd150, %r1, 4;
	add.s64 	%rd151, %rd149, %rd150;
	st.shared.f32 	[%rd151], %f199;
	bar.sync 	0;
	mul.wide.u32 	%rd152, %r1, 132;
	add.s64 	%rd153, %rd148, %rd152;
	mul.wide.u32 	%rd154, %r2, 4;
	add.s64 	%rd155, %rd153, %rd154;
	ld.shared.f32 	%f178, [%rd155];
	shfl.sync.down.b32	%f179, %f178, 16, 31, -1;
	add.rn.f32 	%f180, %f178, %f179;
	shfl.sync.down.b32	%f181, %f180, 8, 31, -1;
	add.rn.f32 	%f182, %f180, %f181;
	shfl.sync.down.b32	%f183, %f182, 4, 31, -1;
	add.rn.f32 	%f184, %f182, %f183;
	shfl.sync.down.b32	%f185, %f184, 2, 31, -1;
	add.rn.f32 	%f186, %f184, %f185;
	shfl.sync.down.b32	%f187, %f186, 1, 31, -1;
	add.rn.f32 	%f5, %f186, %f187;
	st.shared.f32 	[%rd155], %f5;
	setp.lt.u32 	%p37, %r1, %r3;
	setp.eq.s32 	%p38, %r2, 0;
	and.pred  	%p1, %p38, %p37;
	or.b32  	%r233, %r4, %r1;
	mul.lo.s64 	%rd177, %rd15, 192;
	@%p1 bra 	$L__BB180_39;
	bra.uni 	$L__BB180_4;
$L__BB180_39:
	mul.hi.u32 	%r226, %r233, 715827883;
	mul.lo.s32 	%r227, %r226, 6;
	sub.s32 	%r228, %r233, %r227;
	add.s64 	%rd157, %rd2, %rd177;
	mul.wide.u32 	%rd158, %r226, 24;
	add.s64 	%rd159, %rd157, %rd158;
	mul.wide.u32 	%rd160, %r228, 4;
	add.s64 	%rd161, %rd159, %rd160;
	st.global.f32 	[%rd161], %f5;
$L__BB180_4:
	mul.lo.s64 	%rd162, %rd24, 132;
	mov.u64 	%rd163, shared_cache15;
	add.s64 	%rd164, %rd163, %rd162;
	shl.b64 	%rd165, %rd25, 2;
	add.s64 	%rd166, %rd164, %rd165;
	st.shared.f32 	[%rd166], %f198;
	bar.sync 	0;
	mul.lo.s64 	%rd167, %rd25, 132;
	add.s64 	%rd168, %rd163, %rd167;
	shl.b64 	%rd169, %rd24, 2;
	add.s64 	%rd170, %rd168, %rd169;
	ld.shared.f32 	%f188, [%rd170];
	shfl.sync.down.b32	%f189, %f188, 16, 31, -1;
	add.rn.f32 	%f190, %f188, %f189;
	shfl.sync.down.b32	%f191, %f190, 8, 31, -1;
	add.rn.f32 	%f192, %f190, %f191;
	shfl.sync.down.b32	%f193, %f192, 4, 31, -1;
	add.rn.f32 	%f194, %f192, %f193;
	shfl.sync.down.b32	%f195, %f194, 2, 31, -1;
	add.rn.f32 	%f196, %f194, %f195;
	shfl.sync.down.b32	%f197, %f196, 1, 31, -1;
	add.rn.f32 	%f6, %f196, %f197;
	st.shared.f32 	[%rd170], %f6;
	@%p1 bra 	$L__BB180_40;
	bra.uni 	$L__BB180_5;
$L__BB180_40:
	mul.hi.u32 	%r230, %r233, 715827883;
	mul.lo.s32 	%r231, %r230, 6;
	sub.s32 	%r232, %r233, %r231;
	add.s64 	%rd172, %rd1, %rd177;
	mul.wide.u32 	%rd173, %r230, 24;
	add.s64 	%rd174, %rd172, %rd173;
	mul.wide.u32 	%rd175, %r232, 4;
	add.s64 	%rd176, %rd174, %rd175;
	st.global.f32 	[%rd176], %f6;
$L__BB180_5:
	ret;

}
	// .globl	loop_broadcast_fusion_40
.visible .entry loop_broadcast_fusion_40(
	.param .u64 loop_broadcast_fusion_40_param_0
)
.reqntid 256, 1, 1
{
	.reg .b32 	%r<6>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [loop_broadcast_fusion_40_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	shl.b32 	%r3, %r2, 10;
	shl.b32 	%r4, %r1, 2;
	or.b32  	%r5, %r3, %r4;
	mul.wide.u32 	%rd3, %r5, 4;
	add.s64 	%rd4, %rd2, %rd3;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd4], {%f1, %f1, %f1, %f1};
	ret;

}
	// .globl	input_scatter_fusion_254
.visible .entry input_scatter_fusion_254(
	.param .u64 input_scatter_fusion_254_param_0,
	.param .u64 input_scatter_fusion_254_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<11>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_254_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_254_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r2, 15;
	shr.u32 	%r6, %r4, 4;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r7, %r4, 1374389535;
	bfe.u32 	%r8, %r7, 8, 6;
	cvt.u16.u32 	%rs7, %r1;
	shr.u16 	%rs8, %rs7, 4;
	mul.hi.u16 	%rs9, %rs8, 2622;
	shl.b16 	%rs10, %rs9, 1;
	cvt.u32.u16 	%r9, %rs10;
	mul.wide.u32 	%rd5, %r9, 204800;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r8, 3200;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r10, %rs6;
	mul.wide.u32 	%rd9, %r10, 64;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+204800];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+204800], %f3;
	ret;

}
	// .globl	wrapped_transpose_260
.visible .entry wrapped_transpose_260(
	.param .u64 wrapped_transpose_260_param_0,
	.param .u64 wrapped_transpose_260_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<28>;
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<32>;

	ld.param.u64 	%rd1, [wrapped_transpose_260_param_0];
	ld.param.u64 	%rd2, [wrapped_transpose_260_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	mul.hi.u32 	%r6, %r5, 458129845;
	bfe.u32 	%r7, %r6, 9, 6;
	or.b32  	%r8, %r5, 3;
	mul.hi.u32 	%r9, %r5, 715827883;
	shr.u32 	%r10, %r9, 4;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r8, 715827883;
	and.b32  	%r12, %r11, 15;
	mul.lo.s32 	%r13, %r11, 6;
	sub.s32 	%r14, %r8, %r13;
	or.b32  	%r15, %r5, 2;
	mul.hi.u32 	%r16, %r15, 715827883;
	and.b32  	%r17, %r16, 15;
	mul.lo.s32 	%r18, %r16, 6;
	sub.s32 	%r19, %r15, %r18;
	or.b32  	%r20, %r5, 1;
	and.b32  	%r21, %r9, 15;
	mul.hi.u32 	%r22, %r20, 715827883;
	mul.lo.s32 	%r23, %r22, 6;
	sub.s32 	%r24, %r20, %r23;
	mul.lo.s32 	%r25, %r9, 6;
	sub.s32 	%r26, %r5, %r25;
	mul.wide.u32 	%rd5, %r26, 204800;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r7, 3200;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r27, %rs6;
	mul.wide.u32 	%rd9, %r27, 64;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r21, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r5, 4;
	add.s64 	%rd14, %rd3, %rd13;
	mul.wide.u32 	%rd15, %r24, 204800;
	add.s64 	%rd16, %rd4, %rd15;
	add.s64 	%rd17, %rd16, %rd7;
	add.s64 	%rd18, %rd17, %rd9;
	add.s64 	%rd19, %rd18, %rd11;
	ld.global.nc.f32 	%f2, [%rd19];
	mul.wide.u32 	%rd20, %r19, 204800;
	add.s64 	%rd21, %rd4, %rd20;
	add.s64 	%rd22, %rd21, %rd7;
	add.s64 	%rd23, %rd22, %rd9;
	mul.wide.u32 	%rd24, %r17, 4;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.nc.f32 	%f3, [%rd25];
	mul.wide.u32 	%rd26, %r14, 204800;
	add.s64 	%rd27, %rd4, %rd26;
	add.s64 	%rd28, %rd27, %rd7;
	add.s64 	%rd29, %rd28, %rd9;
	mul.wide.u32 	%rd30, %r12, 4;
	add.s64 	%rd31, %rd29, %rd30;
	ld.global.nc.f32 	%f4, [%rd31];
	st.global.v4.f32 	[%rd14], {%f1, %f2, %f3, %f4};
	ret;

}
	// .globl	input_scatter_fusion_255
.visible .entry input_scatter_fusion_255(
	.param .u64 input_scatter_fusion_255_param_0,
	.param .u64 input_scatter_fusion_255_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<11>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_255_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_255_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r2, 15;
	shr.u32 	%r6, %r4, 4;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r7, %r4, 1374389535;
	bfe.u32 	%r8, %r7, 8, 6;
	cvt.u16.u32 	%rs7, %r1;
	shr.u16 	%rs8, %rs7, 4;
	mul.hi.u16 	%rs9, %rs8, 2622;
	shl.b16 	%rs10, %rs9, 1;
	cvt.u32.u16 	%r9, %rs10;
	mul.wide.u32 	%rd5, %r9, 204800;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r8, 3200;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r10, %rs6;
	mul.wide.u32 	%rd9, %r10, 64;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	input_add_reduce_fusion_41
.visible .entry input_add_reduce_fusion_41(
	.param .u64 input_add_reduce_fusion_41_param_0,
	.param .u64 input_add_reduce_fusion_41_param_1,
	.param .u64 input_add_reduce_fusion_41_param_2,
	.param .u64 input_add_reduce_fusion_41_param_3,
	.param .u64 input_add_reduce_fusion_41_param_4,
	.param .u64 input_add_reduce_fusion_41_param_5,
	.param .u64 input_add_reduce_fusion_41_param_6,
	.param .u64 input_add_reduce_fusion_41_param_7,
	.param .u64 input_add_reduce_fusion_41_param_8,
	.param .u64 input_add_reduce_fusion_41_param_9
)
.reqntid 1024, 1, 1
{
	.local .align 4 .b8 	__local_depot185[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<26>;
	.reg .b32 	%r<142>;
	.reg .f32 	%f<184>;
	.reg .b64 	%rd<164>;
	.reg .f64 	%fd<5>;
	// demoted variable
	.shared .align 4 .b8 shared_cache16[4224];
	mov.u64 	%SPL, __local_depot185;
	ld.param.u64 	%rd30, [input_add_reduce_fusion_41_param_0];
	ld.param.u64 	%rd31, [input_add_reduce_fusion_41_param_9];
	cvta.to.global.u64 	%rd1, %rd31;
	ld.param.u64 	%rd32, [input_add_reduce_fusion_41_param_1];
	ld.param.u64 	%rd33, [input_add_reduce_fusion_41_param_8];
	cvta.to.global.u64 	%rd2, %rd33;
	ld.param.u64 	%rd34, [input_add_reduce_fusion_41_param_2];
	ld.param.u64 	%rd35, [input_add_reduce_fusion_41_param_7];
	cvta.to.global.u64 	%rd3, %rd35;
	ld.param.u64 	%rd36, [input_add_reduce_fusion_41_param_3];
	ld.param.u64 	%rd37, [input_add_reduce_fusion_41_param_6];
	cvta.to.global.u64 	%rd4, %rd37;
	ld.param.u64 	%rd38, [input_add_reduce_fusion_41_param_4];
	ld.param.u64 	%rd39, [input_add_reduce_fusion_41_param_5];
	cvta.to.global.u64 	%rd40, %rd39;
	cvta.to.global.u64 	%rd41, %rd38;
	cvta.to.global.u64 	%rd5, %rd36;
	cvta.to.global.u64 	%rd6, %rd34;
	cvta.to.global.u64 	%rd42, %rd32;
	cvta.to.global.u64 	%rd7, %rd30;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r40, %tid.x;
	mov.u32 	%r41, %ctaid.x;
	shr.u32 	%r1, %r40, 5;
	and.b32  	%r2, %r40, 31;
	cvt.u16.u32 	%rs1, %r41;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r3, %rs6;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs7, %r4;
	and.b16  	%rs8, %rs7, 255;
	mul.lo.s16 	%rs9, %rs8, 171;
	shr.u16 	%rs10, %rs9, 10;
	mul.lo.s16 	%rs11, %rs10, 6;
	sub.s16 	%rs12, %rs7, %rs11;
	cvt.u32.u16 	%r42, %rs12;
	cvt.u32.u16 	%r43, %rs10;
	cvt.u64.u16 	%rd10, %rs3;
	cvt.u32.u16 	%r44, %rs3;
	mul.wide.u32 	%rd45, %r44, 4;
	add.s64 	%rd46, %rd42, %rd45;
	ld.global.nc.f32 	%f1, [%rd46];
	add.s16 	%rs13, %rs10, -2;
	and.b16  	%rs14, %rs13, 128;
	setp.gt.u32 	%p3, %r4, 11;
	and.b32  	%r5, %r43, 1;
	setp.eq.s32 	%p4, %r5, 0;
	and.pred  	%p1, %p3, %p4;
	shr.u16 	%rs15, %rs14, 7;
	add.s16 	%rs16, %rs13, %rs15;
	cvt.s16.s8 	%rs17, %rs16;
	shr.s16 	%rs18, %rs17, 1;
	add.s16 	%rs19, %rs18, 1;
	cvt.s32.s16 	%r45, %rs19;
	cvt.u64.u32 	%rd11, %r45;
	cvt.u64.u16 	%rd47, %rs12;
	and.b64  	%rd12, %rd47, 255;
	add.s32 	%r46, %r43, -1;
	setp.gt.u32 	%p5, %r4, 5;
	and.b32  	%r47, %r46, 1;
	setp.eq.b32 	%p6, %r47, 1;
	not.pred 	%p7, %p6;
	and.pred  	%p2, %p5, %p7;
	cvt.u16.u32 	%rs20, %r46;
	and.b16  	%rs21, %rs20, 128;
	shr.u16 	%rs22, %rs21, 7;
	add.s16 	%rs23, %rs20, %rs22;
	shr.s16 	%rs24, %rs23, 1;
	cvt.s32.s16 	%r48, %rs24;
	cvt.u64.u32 	%rd13, %r48;
	shr.u16 	%rs25, %rs9, 11;
	cvt.u64.u16 	%rd14, %rs25;
	bfe.u32 	%r49, %r42, 1, 7;
	cvt.u64.u32 	%rd15, %r49;
	mul.wide.u32 	%rd48, %r49, 4;
	mul.wide.u32 	%rd49, %r44, 12;
	add.s64 	%rd50, %rd40, %rd49;
	add.s64 	%rd16, %rd50, %rd48;
	add.s64 	%rd17, %rd41, %rd45;
	and.b32  	%r50, %r42, 1;
	cvt.u64.u16 	%rd18, %rs10;
	cvt.u64.u32 	%rd19, %r50;
	mov.f32 	%f39, 0f00000000;
	mul.lo.s64 	%rd55, %rd11, 24;
	mul.lo.s64 	%rd62, %rd13, 24;
	setp.lt.u32 	%p17, %r4, 6;
	shl.b64 	%rd105, %rd15, 3;
	shl.b64 	%rd107, %rd19, 2;
	mov.u32 	%r6, %r1;
	mov.f32 	%f2, %f39;
	bra.uni 	$L__BB185_1;
$L__BB185_10:
	add.s32 	%r6, %r6, 32;
	add.rn.f32 	%f2, %f2, %f103;
	add.rn.f32 	%f13, %f178, %f179;
	add.rn.f32 	%f15, %f13, %f180;
	cvt.u32.u64 	%r125, %rd20;
	add.rn.f32 	%f162, %f15, %f181;
	add.s64 	%rd139, %rd1, %rd99;
	add.s64 	%rd141, %rd139, %rd101;
	add.s64 	%rd143, %rd141, %rd103;
	add.s64 	%rd145, %rd143, %rd57;
	st.global.f32 	[%rd145], %f162;
	setp.gt.u32 	%p28, %r125, 17;
	@%p28 bra 	$L__BB185_11;
$L__BB185_1:
	mul.lo.s64 	%rd51, %rd10, 19200;
	add.s64 	%rd52, %rd6, %rd51;
	mul.wide.u32 	%rd53, %r6, 384;
	add.s64 	%rd54, %rd52, %rd53;
	add.s64 	%rd56, %rd54, %rd55;
	shl.b64 	%rd57, %rd12, 2;
	add.s64 	%rd21, %rd56, %rd57;
	mov.f32 	%f174, %f39;
	@%p1 bra 	$L__BB185_2;
	bra.uni 	$L__BB185_3;
$L__BB185_2:
	ld.global.nc.f32 	%f174, [%rd21];
$L__BB185_3:
	cvt.u64.u32 	%rd20, %r6;
	add.s64 	%rd59, %rd5, %rd51;
	mul.lo.s64 	%rd60, %rd20, 384;
	add.s64 	%rd61, %rd59, %rd60;
	add.s64 	%rd63, %rd61, %rd62;
	add.s64 	%rd22, %rd63, %rd57;
	mov.f32 	%f175, %f39;
	@%p2 bra 	$L__BB185_13;
	bra.uni 	$L__BB185_4;
$L__BB185_13:
	ld.global.nc.f32 	%f175, [%rd22];
$L__BB185_4:
	mov.u64 	%rd161, __cudart_i2opi_f;
	mov.f32 	%f176, %f39;
	@%p4 bra 	$L__BB185_14;
	bra.uni 	$L__BB185_5;
$L__BB185_14:
	add.s64 	%rd66, %rd4, %rd51;
	add.s64 	%rd68, %rd66, %rd60;
	mul.lo.s64 	%rd69, %rd14, 24;
	add.s64 	%rd70, %rd68, %rd69;
	add.s64 	%rd72, %rd70, %rd57;
	ld.global.nc.f32 	%f43, [%rd72];
	add.s64 	%rd73, %rd3, %rd51;
	add.s64 	%rd74, %rd73, %rd60;
	add.s64 	%rd75, %rd74, %rd69;
	add.s64 	%rd76, %rd75, %rd57;
	ld.global.nc.f32 	%f44, [%rd76];
	add.rn.f32 	%f19, %f43, %f44;
	ld.global.nc.f32 	%f45, [%rd16];
	add.rn.f32 	%f20, %f45, %f45;
	mul.rn.f32 	%f46, %f20, 0f3F22F983;
	cvt.rni.s32.f32 	%r137, %f46;
	cvt.rn.f32.s32 	%f47, %r137;
	fma.rn.f32 	%f48, %f47, 0fBFC90FDA, %f20;
	fma.rn.f32 	%f49, %f47, 0fB3A22168, %f48;
	fma.rn.f32 	%f182, %f47, 0fA7C234C5, %f49;
	abs.f32 	%f22, %f20;
	setp.ltu.f32 	%p9, %f22, 0f47CE4780;
	@%p9 bra 	$L__BB185_22;
	setp.neu.f32 	%p10, %f22, 0f7F800000;
	@%p10 bra 	$L__BB185_17;
	mov.f32 	%f52, 0f00000000;
	mul.rn.f32 	%f182, %f20, %f52;
	mov.b32 	%r137, 0;
	bra.uni 	$L__BB185_22;
$L__BB185_17:
	mov.b32 	%r9, %f20;
	shr.u32 	%r10, %r9, 23;
	and.b32  	%r52, %r10, 224;
	add.s32 	%r53, %r52, -128;
	shl.b32 	%r54, %r9, 8;
	or.b32  	%r58, %r54, -2147483648;
	shr.u32 	%r12, %r53, 5;
	mov.b32 	%r134, 0;
	mov.u64 	%rd162, 0;
$L__BB185_18:
	.pragma "nounroll";
	add.s64 	%rd79, %rd161, %rd162;
	ld.global.nc.u32 	%r57, [%rd79];
	// begin inline asm
	{
	mad.lo.cc.u32   %r55, %r57, %r58, %r134;
	madc.hi.u32     %r134, %r57, %r58,  0;
	}
	// end inline asm
	add.s64 	%rd80, %rd8, %rd162;
	st.local.u32 	[%rd80], %r55;
	add.s64 	%rd162, %rd162, 4;
	cvt.u32.u64 	%r60, %rd162;
	setp.ne.s32 	%p11, %r60, 24;
	@%p11 bra 	$L__BB185_18;
	st.local.u32 	[%rd8+24], %r134;
	and.b32  	%r15, %r10, 31;
	mul.wide.u32 	%rd81, %r12, 4;
	sub.s64 	%rd26, %rd8, %rd81;
	ld.local.u32 	%r135, [%rd26+24];
	ld.local.u32 	%r136, [%rd26+20];
	setp.eq.s32 	%p12, %r15, 0;
	@%p12 bra 	$L__BB185_21;
	shl.b32 	%r61, %r136, %r15;
	shl.b32 	%r62, %r135, %r15;
	mov.b32 	%r63, 32;
	sub.s32 	%r64, %r63, %r15;
	shr.u32 	%r65, %r136, %r64;
	add.s32 	%r135, %r65, %r62;
	ld.local.u32 	%r66, [%rd26+16];
	shr.u32 	%r67, %r66, %r64;
	add.s32 	%r136, %r67, %r61;
$L__BB185_21:
	shr.u32 	%r68, %r135, 30;
	shr.u32 	%r69, %r136, 30;
	shl.b32 	%r70, %r135, 2;
	or.b32  	%r71, %r70, %r69;
	shl.b32 	%r72, %r136, 2;
	bfe.u32 	%r73, %r135, 29, 1;
	add.s32 	%r74, %r73, %r68;
	neg.s32 	%r75, %r74;
	setp.lt.s32 	%p13, %r9, 0;
	selp.b32 	%r137, %r75, %r74, %p13;
	xor.b32  	%r76, %r71, %r9;
	bfe.s32 	%r77, %r135, 29, 1;
	xor.b32  	%r78, %r77, %r71;
	xor.b32  	%r79, %r77, %r72;
	cvt.u64.u32 	%rd82, %r78;
	shl.b64 	%rd83, %rd82, 32;
	cvt.u64.u32 	%rd84, %r79;
	or.b64  	%rd85, %rd83, %rd84;
	cvt.rn.f64.s64 	%fd1, %rd85;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f50, %fd2;
	neg.f32 	%f51, %f50;
	setp.lt.s32 	%p14, %r76, 0;
	selp.f32 	%f182, %f51, %f50, %p14;
$L__BB185_22:
	add.s32 	%r81, %r137, 1;
	mul.rn.f32 	%f53, %f182, %f182;
	and.b32  	%r82, %r137, 1;
	setp.eq.b32 	%p15, %r82, 1;
	selp.f32 	%f54, %f182, 0f3F800000, %p15;
	fma.rn.f32 	%f55, %f53, %f54, 0f00000000;
	fma.rn.f32 	%f56, %f53, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f57, 0fB94D4153, %f56, %p15;
	selp.f32 	%f58, 0f3C0885E4, 0f3D2AAABB, %p15;
	fma.rn.f32 	%f59, %f57, %f53, %f58;
	selp.f32 	%f60, 0fBE2AAAA8, 0fBEFFFFFF, %p15;
	fma.rn.f32 	%f61, %f59, %f53, %f60;
	fma.rn.f32 	%f62, %f61, %f55, %f54;
	and.b32  	%r83, %r81, 2;
	setp.eq.s32 	%p16, %r83, 0;
	mov.f32 	%f63, 0f00000000;
	sub.rn.f32 	%f64, %f63, %f62;
	selp.f32 	%f65, %f62, %f64, %p16;
	ld.global.nc.f32 	%f66, [%rd17];
	fma.rn.f32 	%f67, %f66, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f68, %f67;
	mov.f32 	%f69, 0f4B400001;
	mov.f32 	%f70, 0f437C0000;
	fma.rm.f32 	%f71, %f68, %f70, %f69;
	add.rn.f32 	%f72, %f71, 0fCB40007F;
	neg.f32 	%f73, %f72;
	fma.rn.f32 	%f74, %f66, 0f3FB8AA3B, %f73;
	fma.rn.f32 	%f75, %f66, 0f32A57060, %f74;
	mov.b32 	%r84, %f71;
	shl.b32 	%r85, %r84, 23;
	mov.b32 	%f76, %r85;
	ex2.approx.ftz.f32 	%f77, %f75;
	mul.rn.f32 	%f78, %f77, %f76;
	neg.f32 	%f79, %f78;
	sub.rn.f32 	%f80, %f79, %f78;
	add.rn.f32 	%f81, %f80, %f80;
	add.rn.f32 	%f82, %f81, %f81;
	add.rn.f32 	%f83, %f82, %f82;
	add.rn.f32 	%f84, %f83, %f83;
	fma.rn.f32 	%f85, %f84, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f86, %f85;
	fma.rm.f32 	%f87, %f86, %f70, %f69;
	add.rn.f32 	%f88, %f87, 0fCB40007F;
	neg.f32 	%f89, %f88;
	fma.rn.f32 	%f90, %f84, 0f3FB8AA3B, %f89;
	fma.rn.f32 	%f91, %f84, 0f32A57060, %f90;
	mov.b32 	%r86, %f87;
	shl.b32 	%r87, %r86, 23;
	mov.b32 	%f92, %r87;
	ex2.approx.ftz.f32 	%f93, %f91;
	mul.rn.f32 	%f94, %f93, %f92;
	add.s64 	%rd91, %rd61, %rd69;
	add.s64 	%rd93, %rd91, %rd57;
	ld.global.nc.f32 	%f95, [%rd93];
	mul.rn.f32 	%f96, %f95, %f94;
	mul.rn.f32 	%f97, %f65, %f96;
	add.rn.f32 	%f176, %f19, %f97;
$L__BB185_5:
	add.s64 	%rd97, %rd52, %rd60;
	add.s64 	%rd23, %rd97, %rd57;
	mov.f32 	%f177, %f39;
	@%p17 bra 	$L__BB185_23;
	bra.uni 	$L__BB185_6;
$L__BB185_23:
	ld.global.nc.f32 	%f177, [%rd23];
$L__BB185_6:
	add.rn.f32 	%f6, %f174, %f175;
	add.rn.f32 	%f8, %f6, %f176;
	mul.lo.s64 	%rd99, %rd10, 38400;
	add.s64 	%rd100, %rd7, %rd99;
	mul.lo.s64 	%rd101, %rd20, 768;
	add.s64 	%rd102, %rd100, %rd101;
	mul.lo.s64 	%rd103, %rd18, 24;
	add.s64 	%rd104, %rd102, %rd103;
	add.s64 	%rd106, %rd104, %rd105;
	add.s64 	%rd108, %rd106, %rd107;
	ld.global.nc.f32 	%f102, [%rd108];
	mov.f32 	%f178, %f39;
	@%p1 bra 	$L__BB185_24;
	bra.uni 	$L__BB185_7;
$L__BB185_24:
	ld.global.nc.f32 	%f178, [%rd21];
$L__BB185_7:
	add.rn.f32 	%f100, %f8, %f177;
	mov.f32 	%f179, %f39;
	@%p2 bra 	$L__BB185_25;
	bra.uni 	$L__BB185_8;
$L__BB185_25:
	ld.global.nc.f32 	%f179, [%rd22];
$L__BB185_8:
	mul.rn.f32 	%f101, %f1, %f100;
	mov.f32 	%f180, %f39;
	@%p4 bra 	$L__BB185_26;
	bra.uni 	$L__BB185_9;
$L__BB185_26:
	add.s64 	%rd110, %rd4, %rd51;
	add.s64 	%rd112, %rd110, %rd60;
	mul.lo.s64 	%rd113, %rd14, 24;
	add.s64 	%rd114, %rd112, %rd113;
	add.s64 	%rd116, %rd114, %rd57;
	ld.global.nc.f32 	%f106, [%rd116];
	add.s64 	%rd117, %rd3, %rd51;
	add.s64 	%rd118, %rd117, %rd60;
	add.s64 	%rd119, %rd118, %rd113;
	add.s64 	%rd120, %rd119, %rd57;
	ld.global.nc.f32 	%f107, [%rd120];
	add.rn.f32 	%f30, %f106, %f107;
	ld.global.nc.f32 	%f108, [%rd16];
	add.rn.f32 	%f31, %f108, %f108;
	mul.rn.f32 	%f109, %f31, 0f3F22F983;
	cvt.rni.s32.f32 	%r141, %f109;
	cvt.rn.f32.s32 	%f110, %r141;
	fma.rn.f32 	%f111, %f110, 0fBFC90FDA, %f31;
	fma.rn.f32 	%f112, %f110, 0fB3A22168, %f111;
	fma.rn.f32 	%f183, %f110, 0fA7C234C5, %f112;
	abs.f32 	%f33, %f31;
	setp.ltu.f32 	%p19, %f33, 0f47CE4780;
	@%p19 bra 	$L__BB185_34;
	setp.neu.f32 	%p20, %f33, 0f7F800000;
	@%p20 bra 	$L__BB185_29;
	mov.f32 	%f115, 0f00000000;
	mul.rn.f32 	%f183, %f31, %f115;
	mov.b32 	%r141, 0;
	bra.uni 	$L__BB185_34;
$L__BB185_29:
	mov.b32 	%r138, 0;
	mov.b32 	%r25, %f31;
	shr.u32 	%r26, %r25, 23;
	and.b32  	%r89, %r26, 224;
	add.s32 	%r90, %r89, -128;
	shl.b32 	%r91, %r25, 8;
	or.b32  	%r95, %r91, -2147483648;
	shr.u32 	%r28, %r90, 5;
	mov.u64 	%rd163, 0;
$L__BB185_30:
	.pragma "nounroll";
	add.s64 	%rd123, %rd161, %rd163;
	ld.global.nc.u32 	%r94, [%rd123];
	// begin inline asm
	{
	mad.lo.cc.u32   %r92, %r94, %r95, %r138;
	madc.hi.u32     %r138, %r94, %r95,  0;
	}
	// end inline asm
	add.s64 	%rd124, %rd8, %rd163;
	st.local.u32 	[%rd124], %r92;
	add.s64 	%rd163, %rd163, 4;
	cvt.u32.u64 	%r97, %rd163;
	setp.ne.s32 	%p21, %r97, 24;
	@%p21 bra 	$L__BB185_30;
	st.local.u32 	[%rd8+24], %r138;
	and.b32  	%r31, %r26, 31;
	mul.wide.u32 	%rd125, %r28, 4;
	sub.s64 	%rd29, %rd8, %rd125;
	ld.local.u32 	%r139, [%rd29+24];
	ld.local.u32 	%r140, [%rd29+20];
	setp.eq.s32 	%p22, %r31, 0;
	@%p22 bra 	$L__BB185_33;
	shl.b32 	%r98, %r140, %r31;
	shl.b32 	%r99, %r139, %r31;
	mov.b32 	%r100, 32;
	sub.s32 	%r101, %r100, %r31;
	shr.u32 	%r102, %r140, %r101;
	add.s32 	%r139, %r102, %r99;
	ld.local.u32 	%r103, [%rd29+16];
	shr.u32 	%r104, %r103, %r101;
	add.s32 	%r140, %r104, %r98;
$L__BB185_33:
	shr.u32 	%r105, %r139, 30;
	shr.u32 	%r106, %r140, 30;
	shl.b32 	%r107, %r139, 2;
	or.b32  	%r108, %r107, %r106;
	shl.b32 	%r109, %r140, 2;
	bfe.u32 	%r110, %r139, 29, 1;
	add.s32 	%r111, %r110, %r105;
	neg.s32 	%r112, %r111;
	setp.lt.s32 	%p23, %r25, 0;
	selp.b32 	%r141, %r112, %r111, %p23;
	xor.b32  	%r113, %r108, %r25;
	bfe.s32 	%r114, %r139, 29, 1;
	xor.b32  	%r115, %r114, %r108;
	xor.b32  	%r116, %r114, %r109;
	cvt.u64.u32 	%rd126, %r115;
	shl.b64 	%rd127, %rd126, 32;
	cvt.u64.u32 	%rd128, %r116;
	or.b64  	%rd129, %rd127, %rd128;
	cvt.rn.f64.s64 	%fd3, %rd129;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f113, %fd4;
	neg.f32 	%f114, %f113;
	setp.lt.s32 	%p24, %r113, 0;
	selp.f32 	%f183, %f114, %f113, %p24;
$L__BB185_34:
	add.s32 	%r118, %r141, 1;
	mul.rn.f32 	%f116, %f183, %f183;
	and.b32  	%r119, %r141, 1;
	setp.eq.b32 	%p25, %r119, 1;
	selp.f32 	%f117, %f183, 0f3F800000, %p25;
	fma.rn.f32 	%f118, %f116, %f117, 0f00000000;
	fma.rn.f32 	%f119, %f116, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f120, 0fB94D4153, %f119, %p25;
	selp.f32 	%f121, 0f3C0885E4, 0f3D2AAABB, %p25;
	fma.rn.f32 	%f122, %f120, %f116, %f121;
	selp.f32 	%f123, 0fBE2AAAA8, 0fBEFFFFFF, %p25;
	fma.rn.f32 	%f124, %f122, %f116, %f123;
	fma.rn.f32 	%f125, %f124, %f118, %f117;
	and.b32  	%r120, %r118, 2;
	setp.eq.s32 	%p26, %r120, 0;
	mov.f32 	%f126, 0f00000000;
	sub.rn.f32 	%f127, %f126, %f125;
	selp.f32 	%f128, %f125, %f127, %p26;
	ld.global.nc.f32 	%f129, [%rd17];
	fma.rn.f32 	%f130, %f129, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f131, %f130;
	mov.f32 	%f132, 0f4B400001;
	mov.f32 	%f133, 0f437C0000;
	fma.rm.f32 	%f134, %f131, %f133, %f132;
	add.rn.f32 	%f135, %f134, 0fCB40007F;
	neg.f32 	%f136, %f135;
	fma.rn.f32 	%f137, %f129, 0f3FB8AA3B, %f136;
	fma.rn.f32 	%f138, %f129, 0f32A57060, %f137;
	mov.b32 	%r121, %f134;
	shl.b32 	%r122, %r121, 23;
	mov.b32 	%f139, %r122;
	ex2.approx.ftz.f32 	%f140, %f138;
	mul.rn.f32 	%f141, %f140, %f139;
	neg.f32 	%f142, %f141;
	sub.rn.f32 	%f143, %f142, %f141;
	add.rn.f32 	%f144, %f143, %f143;
	add.rn.f32 	%f145, %f144, %f144;
	add.rn.f32 	%f146, %f145, %f145;
	add.rn.f32 	%f147, %f146, %f146;
	fma.rn.f32 	%f148, %f147, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f149, %f148;
	fma.rm.f32 	%f150, %f149, %f133, %f132;
	add.rn.f32 	%f151, %f150, 0fCB40007F;
	neg.f32 	%f152, %f151;
	fma.rn.f32 	%f153, %f147, 0f3FB8AA3B, %f152;
	fma.rn.f32 	%f154, %f147, 0f32A57060, %f153;
	mov.b32 	%r123, %f150;
	shl.b32 	%r124, %r123, 23;
	mov.b32 	%f155, %r124;
	ex2.approx.ftz.f32 	%f156, %f154;
	mul.rn.f32 	%f157, %f156, %f155;
	add.s64 	%rd135, %rd61, %rd113;
	add.s64 	%rd137, %rd135, %rd57;
	ld.global.nc.f32 	%f158, [%rd137];
	mul.rn.f32 	%f159, %f158, %f157;
	mul.rn.f32 	%f160, %f128, %f159;
	add.rn.f32 	%f180, %f30, %f160;
$L__BB185_9:
	mul.rn.f32 	%f103, %f102, %f101;
	mov.f32 	%f181, %f39;
	@%p17 bra 	$L__BB185_35;
	bra.uni 	$L__BB185_10;
$L__BB185_35:
	ld.global.nc.f32 	%f181, [%rd23];
	bra.uni 	$L__BB185_10;
$L__BB185_11:
	mul.wide.u32 	%rd146, %r2, 132;
	mov.u64 	%rd147, shared_cache16;
	add.s64 	%rd148, %rd147, %rd146;
	mul.wide.u32 	%rd149, %r1, 4;
	add.s64 	%rd150, %rd148, %rd149;
	st.shared.f32 	[%rd150], %f2;
	bar.sync 	0;
	mul.wide.u32 	%rd151, %r1, 132;
	add.s64 	%rd152, %rd147, %rd151;
	mul.wide.u32 	%rd153, %r2, 4;
	add.s64 	%rd154, %rd152, %rd153;
	ld.shared.f32 	%f163, [%rd154];
	shfl.sync.down.b32	%f164, %f163, 16, 31, -1;
	add.rn.f32 	%f165, %f163, %f164;
	shfl.sync.down.b32	%f166, %f165, 8, 31, -1;
	add.rn.f32 	%f167, %f165, %f166;
	shfl.sync.down.b32	%f168, %f167, 4, 31, -1;
	add.rn.f32 	%f169, %f167, %f168;
	shfl.sync.down.b32	%f170, %f169, 2, 31, -1;
	add.rn.f32 	%f171, %f169, %f170;
	shfl.sync.down.b32	%f172, %f171, 1, 31, -1;
	add.rn.f32 	%f3, %f171, %f172;
	st.shared.f32 	[%rd154], %f3;
	setp.eq.s32 	%p29, %r2, 0;
	@%p29 bra 	$L__BB185_36;
	bra.uni 	$L__BB185_12;
$L__BB185_36:
	or.b32  	%r126, %r1, %r3;
	mul.hi.u32 	%r128, %r126, -1431655765;
	shr.u32 	%r129, %r128, 2;
	mul.lo.s32 	%r130, %r129, 6;
	sub.s32 	%r131, %r126, %r130;
	mul.lo.s64 	%rd155, %rd10, 768;
	add.s64 	%rd156, %rd2, %rd155;
	mul.wide.u32 	%rd157, %r129, 24;
	add.s64 	%rd158, %rd156, %rd157;
	mul.wide.u32 	%rd159, %r131, 4;
	add.s64 	%rd160, %rd158, %rd159;
	st.global.f32 	[%rd160], %f3;
$L__BB185_12:
	ret;

}
	// .globl	input_reduce_transpose_fusion_13
.visible .entry input_reduce_transpose_fusion_13(
	.param .u64 input_reduce_transpose_fusion_13_param_0,
	.param .u64 input_reduce_transpose_fusion_13_param_1,
	.param .u64 input_reduce_transpose_fusion_13_param_2,
	.param .u64 input_reduce_transpose_fusion_13_param_3,
	.param .u64 input_reduce_transpose_fusion_13_param_4,
	.param .u64 input_reduce_transpose_fusion_13_param_5,
	.param .u64 input_reduce_transpose_fusion_13_param_6,
	.param .u64 input_reduce_transpose_fusion_13_param_7,
	.param .u64 input_reduce_transpose_fusion_13_param_8,
	.param .u64 input_reduce_transpose_fusion_13_param_9,
	.param .u64 input_reduce_transpose_fusion_13_param_10
)
.reqntid 1024, 1, 1
{
	.local .align 4 .b8 	__local_depot186[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<38>;
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<241>;
	.reg .f32 	%f<169>;
	.reg .b64 	%rd<184>;
	.reg .f64 	%fd<9>;
	// demoted variable
	.shared .align 4 .b8 shared_cache17[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache18[4224];
	mov.u64 	%SPL, __local_depot186;
	ld.param.u64 	%rd40, [input_reduce_transpose_fusion_13_param_0];
	ld.param.u64 	%rd41, [input_reduce_transpose_fusion_13_param_10];
	cvta.to.global.u64 	%rd1, %rd41;
	ld.param.u64 	%rd42, [input_reduce_transpose_fusion_13_param_1];
	ld.param.u64 	%rd43, [input_reduce_transpose_fusion_13_param_9];
	cvta.to.global.u64 	%rd2, %rd43;
	ld.param.u64 	%rd44, [input_reduce_transpose_fusion_13_param_2];
	ld.param.u64 	%rd45, [input_reduce_transpose_fusion_13_param_8];
	cvta.to.global.u64 	%rd3, %rd45;
	ld.param.u64 	%rd46, [input_reduce_transpose_fusion_13_param_3];
	ld.param.u64 	%rd47, [input_reduce_transpose_fusion_13_param_7];
	cvta.to.global.u64 	%rd4, %rd47;
	ld.param.u64 	%rd48, [input_reduce_transpose_fusion_13_param_4];
	ld.param.u64 	%rd49, [input_reduce_transpose_fusion_13_param_6];
	cvta.to.global.u64 	%rd5, %rd49;
	ld.param.u64 	%rd50, [input_reduce_transpose_fusion_13_param_5];
	cvta.to.global.u64 	%rd6, %rd50;
	cvta.to.global.u64 	%rd51, %rd48;
	cvta.to.global.u64 	%rd7, %rd46;
	cvta.to.global.u64 	%rd8, %rd44;
	cvta.to.global.u64 	%rd9, %rd42;
	cvta.to.global.u64 	%rd10, %rd40;
	add.u64 	%rd11, %SPL, 0;
	mov.u32 	%r67, %tid.x;
	mov.u32 	%r68, %ctaid.x;
	shr.u32 	%r1, %r67, 5;
	and.b32  	%r69, %r67, 31;
	cvt.u16.u32 	%rs1, %r68;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 9;
	mul.lo.s16 	%rs5, %rs4, 3;
	sub.s16 	%rs6, %rs1, %rs5;
	shl.b16 	%rs7, %rs6, 5;
	cvt.u32.u16 	%r70, %rs7;
	and.b32  	%r2, %r70, 224;
	cvt.u32.u16 	%r71, %rs4;
	or.b32  	%r72, %r69, %r2;
	cvt.u16.u32 	%rs8, %r72;
	mul.lo.s16 	%rs9, %rs8, 43;
	shr.u16 	%rs10, %rs9, 8;
	mul.lo.s16 	%rs11, %rs10, 6;
	sub.s16 	%rs12, %rs8, %rs11;
	cvt.u32.u16 	%r73, %rs12;
	cvt.u64.u16 	%rd15, %rs4;
	cvt.u64.u16 	%rd16, %rs10;
	cvt.u64.u16 	%rd56, %rs12;
	and.b64  	%rd17, %rd56, 255;
	bfe.u32 	%r74, %r73, 1, 7;
	cvt.u64.u32 	%rd18, %r74;
	mul.wide.u32 	%rd57, %r74, 4;
	mul.wide.u32 	%rd58, %r71, 12;
	add.s64 	%rd59, %rd7, %rd58;
	add.s64 	%rd60, %rd59, %rd57;
	ld.global.nc.f32 	%f26, [%rd60];
	add.rn.f32 	%f27, %f26, %f26;
	mul.rn.f32 	%f28, %f27, 0f3F22F983;
	cvt.rni.s32.f32 	%r75, %f28;
	cvt.rn.f32.s32 	%f29, %r75;
	fma.rn.f32 	%f30, %f29, 0fBFC90FDA, %f27;
	fma.rn.f32 	%f31, %f29, 0fB3A22168, %f30;
	fma.rn.f32 	%f32, %f29, 0fA7C234C5, %f31;
	abs.f32 	%f33, %f27;
	setp.ltu.f32 	%p2, %f33, 0f47CE4780;
	setp.eq.f32 	%p3, %f33, 0f7F800000;
	mov.b32 	%r3, %f27;
	shr.u32 	%r76, %r3, 23;
	and.b32  	%r77, %r76, 224;
	add.s32 	%r78, %r77, -128;
	shl.b32 	%r79, %r3, 8;
	or.b32  	%r4, %r79, -2147483648;
	shr.u32 	%r80, %r78, 5;
	bfe.u32 	%r5, %r3, 23, 5;
	mul.wide.u32 	%rd61, %r80, 4;
	sub.s64 	%rd19, %rd11, %rd61;
	mov.b32 	%r81, 32;
	sub.s32 	%r6, %r81, %r5;
	mov.f32 	%f163, 0f00000000;
	mul.rn.f32 	%f34, %f27, %f163;
	and.b32  	%r82, %r73, 1;
	cvt.u64.u32 	%rd21, %r82;
	mul.wide.u32 	%rd62, %r71, 4;
	add.s64 	%rd22, %rd51, %rd62;
	mad.lo.s32 	%r7, %r71, 4800, %r2;
	cvt.u64.u32 	%rd23, %r69;
	or.pred  	%p1, %p2, %p3;
	selp.b32 	%r8, %r75, 0, %p2;
	selp.f32 	%f1, %f32, %f34, %p2;
	shl.b64 	%rd101, %rd18, 3;
	shl.b64 	%rd103, %rd21, 2;
	mov.u32 	%r224, %r1;
	mov.f32 	%f164, %f163;
	bra.uni 	$L__BB186_1;
$L__BB186_23:
	mul.rn.f32 	%f168, %f12, %f47;
	mov.b32 	%r240, 0;
$L__BB186_29:
	add.s32 	%r224, %r224, 32;
	add.rn.f32 	%f164, %f164, %f69;
	add.rn.f32 	%f163, %f163, %f100;
	cvt.u64.u32 	%rd30, %r145;
	cvt.u64.u32 	%rd34, %r33;
	mul.rn.f32 	%f127, %f168, %f168;
	and.b32  	%r209, %r240, 1;
	setp.eq.b32 	%p30, %r209, 1;
	selp.f32 	%f128, 0f3F800000, %f168, %p30;
	fma.rn.f32 	%f129, %f127, %f128, 0f00000000;
	fma.rn.f32 	%f130, %f127, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f131, %f130, 0fB94D4153, %p30;
	selp.f32 	%f132, 0f3D2AAABB, 0f3C0885E4, %p30;
	fma.rn.f32 	%f133, %f131, %f127, %f132;
	selp.f32 	%f134, 0fBEFFFFFF, 0fBE2AAAA8, %p30;
	fma.rn.f32 	%f135, %f133, %f127, %f134;
	fma.rn.f32 	%f136, %f135, %f129, %f128;
	and.b32  	%r210, %r240, 2;
	setp.eq.s32 	%p31, %r210, 0;
	sub.rn.f32 	%f138, %f47, %f136;
	selp.f32 	%f139, %f136, %f138, %p31;
	ld.global.nc.f32 	%f140, [%rd35+4];
	mul.rn.f32 	%f141, %f18, %f140;
	mul.rn.f32 	%f142, %f141, %f139;
	mul.lo.s64 	%rd136, %rd30, 409600;
	add.s64 	%rd137, %rd2, %rd136;
	mul.lo.s64 	%rd138, %rd29, 6400;
	add.s64 	%rd139, %rd137, %rd138;
	shl.b64 	%rd140, %rd34, 7;
	add.s64 	%rd141, %rd139, %rd140;
	shl.b64 	%rd142, %rd23, 2;
	add.s64 	%rd143, %rd141, %rd142;
	st.global.f32 	[%rd143], %f19;
	add.s64 	%rd144, %rd1, %rd136;
	add.s64 	%rd145, %rd144, %rd138;
	add.s64 	%rd146, %rd145, %rd140;
	add.s64 	%rd147, %rd146, %rd142;
	st.global.f32 	[%rd147], %f142;
	setp.lt.u32 	%p32, %r132, 18;
	@%p32 bra 	$L__BB186_1;
	bra.uni 	$L__BB186_30;
$L__BB186_1:
	mul.lo.s64 	%rd63, %rd15, 19200;
	add.s64 	%rd64, %rd10, %rd63;
	mul.wide.u32 	%rd65, %r224, 384;
	add.s64 	%rd66, %rd64, %rd65;
	mul.lo.s64 	%rd67, %rd16, 24;
	add.s64 	%rd68, %rd66, %rd67;
	shl.b64 	%rd69, %rd17, 2;
	add.s64 	%rd70, %rd68, %rd69;
	ld.global.nc.f32 	%f4, [%rd70];
	mov.u64 	%rd179, __cudart_i2opi_f;
	setp.eq.s32 	%p35, %r5, 0;
	setp.lt.s32 	%p36, %r3, 0;
	mov.u32 	%r228, %r8;
	mov.f32 	%f165, %f1;
	@%p1 bra 	$L__BB186_7;
	mov.b32 	%r225, 0;
	mov.u64 	%rd180, 0;
$L__BB186_3:
	.pragma "nounroll";
	add.s64 	%rd73, %rd179, %rd180;
	ld.global.nc.u32 	%r86, [%rd73];
	// begin inline asm
	{
	mad.lo.cc.u32   %r84, %r86, %r4, %r225;
	madc.hi.u32     %r225, %r86, %r4,  0;
	}
	// end inline asm
	add.s64 	%rd74, %rd11, %rd180;
	st.local.u32 	[%rd74], %r84;
	add.s64 	%rd180, %rd180, 4;
	cvt.u32.u64 	%r89, %rd180;
	setp.ne.s32 	%p4, %r89, 24;
	@%p4 bra 	$L__BB186_3;
	st.local.u32 	[%rd11+24], %r225;
	ld.local.u32 	%r226, [%rd19+24];
	ld.local.u32 	%r227, [%rd19+20];
	@%p35 bra 	$L__BB186_6;
	shl.b32 	%r15, %r227, %r5;
	shl.b32 	%r90, %r226, %r5;
	shr.u32 	%r91, %r227, %r6;
	add.s32 	%r226, %r91, %r90;
	ld.local.u32 	%r92, [%rd19+16];
	shr.u32 	%r93, %r92, %r6;
	add.s32 	%r227, %r93, %r15;
$L__BB186_6:
	shr.u32 	%r94, %r226, 30;
	shr.u32 	%r95, %r227, 30;
	shl.b32 	%r96, %r226, 2;
	or.b32  	%r97, %r96, %r95;
	shl.b32 	%r98, %r227, 2;
	bfe.u32 	%r99, %r226, 29, 1;
	add.s32 	%r100, %r99, %r94;
	neg.s32 	%r101, %r100;
	selp.b32 	%r228, %r101, %r100, %p36;
	xor.b32  	%r102, %r97, %r3;
	bfe.s32 	%r103, %r226, 29, 1;
	xor.b32  	%r104, %r103, %r97;
	xor.b32  	%r105, %r103, %r98;
	cvt.u64.u32 	%rd75, %r104;
	shl.b64 	%rd76, %rd75, 32;
	cvt.u64.u32 	%rd77, %r105;
	or.b64  	%rd78, %rd76, %rd77;
	cvt.rn.f64.s64 	%fd1, %rd78;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f35, %fd2;
	neg.f32 	%f36, %f35;
	setp.lt.s32 	%p7, %r102, 0;
	selp.f32 	%f165, %f36, %f35, %p7;
$L__BB186_7:
	cvt.u64.u32 	%rd24, %r224;
	add.s32 	%r106, %r228, 1;
	mul.rn.f32 	%f37, %f165, %f165;
	and.b32  	%r107, %r228, 1;
	setp.eq.b32 	%p8, %r107, 1;
	selp.f32 	%f38, %f165, 0f3F800000, %p8;
	fma.rn.f32 	%f39, %f37, %f38, 0f00000000;
	fma.rn.f32 	%f40, %f37, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f41, 0fB94D4153, %f40, %p8;
	selp.f32 	%f42, 0f3C0885E4, 0f3D2AAABB, %p8;
	fma.rn.f32 	%f43, %f41, %f37, %f42;
	selp.f32 	%f44, 0fBE2AAAA8, 0fBEFFFFFF, %p8;
	fma.rn.f32 	%f45, %f43, %f37, %f44;
	fma.rn.f32 	%f46, %f45, %f39, %f38;
	and.b32  	%r108, %r106, 2;
	setp.eq.s32 	%p9, %r108, 0;
	mov.f32 	%f47, 0f00000000;
	sub.rn.f32 	%f48, %f47, %f46;
	selp.f32 	%f49, %f46, %f48, %p9;
	add.s64 	%rd80, %rd8, %rd63;
	mul.lo.s64 	%rd81, %rd24, 384;
	add.s64 	%rd82, %rd80, %rd81;
	add.s64 	%rd84, %rd82, %rd67;
	add.s64 	%rd86, %rd84, %rd69;
	ld.global.nc.f32 	%f50, [%rd86];
	mul.rn.f32 	%f7, %f50, %f49;
	mov.u32 	%r232, %r8;
	mov.f32 	%f166, %f1;
	@%p1 bra 	$L__BB186_13;
	mov.b32 	%r229, 0;
	mov.u64 	%rd181, 0;
$L__BB186_9:
	.pragma "nounroll";
	add.s64 	%rd89, %rd179, %rd181;
	ld.global.nc.u32 	%r112, [%rd89];
	// begin inline asm
	{
	mad.lo.cc.u32   %r110, %r112, %r4, %r229;
	madc.hi.u32     %r229, %r112, %r4,  0;
	}
	// end inline asm
	add.s64 	%rd90, %rd11, %rd181;
	st.local.u32 	[%rd90], %r110;
	add.s64 	%rd181, %rd181, 4;
	cvt.u32.u64 	%r115, %rd181;
	setp.ne.s32 	%p10, %r115, 24;
	@%p10 bra 	$L__BB186_9;
	st.local.u32 	[%rd11+24], %r229;
	ld.local.u32 	%r230, [%rd19+24];
	ld.local.u32 	%r231, [%rd19+20];
	@%p35 bra 	$L__BB186_12;
	shl.b32 	%r26, %r231, %r5;
	shl.b32 	%r116, %r230, %r5;
	shr.u32 	%r117, %r231, %r6;
	add.s32 	%r230, %r117, %r116;
	ld.local.u32 	%r118, [%rd19+16];
	shr.u32 	%r119, %r118, %r6;
	add.s32 	%r231, %r119, %r26;
$L__BB186_12:
	shr.u32 	%r120, %r230, 30;
	shr.u32 	%r121, %r231, 30;
	shl.b32 	%r122, %r230, 2;
	or.b32  	%r123, %r122, %r121;
	shl.b32 	%r124, %r231, 2;
	bfe.u32 	%r125, %r230, 29, 1;
	add.s32 	%r126, %r125, %r120;
	neg.s32 	%r127, %r126;
	selp.b32 	%r232, %r127, %r126, %p36;
	xor.b32  	%r128, %r123, %r3;
	bfe.s32 	%r129, %r230, 29, 1;
	xor.b32  	%r130, %r129, %r123;
	xor.b32  	%r131, %r129, %r124;
	cvt.u64.u32 	%rd91, %r130;
	shl.b64 	%rd92, %rd91, 32;
	cvt.u64.u32 	%rd93, %r131;
	or.b64  	%rd94, %rd92, %rd93;
	cvt.rn.f64.s64 	%fd3, %rd94;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f51, %fd4;
	neg.f32 	%f52, %f51;
	setp.lt.s32 	%p13, %r128, 0;
	selp.f32 	%f166, %f52, %f51, %p13;
$L__BB186_13:
	cvt.u32.u64 	%r132, %rd24;
	mul.rn.f32 	%f53, %f166, %f166;
	and.b32  	%r133, %r232, 1;
	setp.eq.b32 	%p14, %r133, 1;
	selp.f32 	%f54, 0f3F800000, %f166, %p14;
	fma.rn.f32 	%f55, %f53, %f54, 0f00000000;
	fma.rn.f32 	%f56, %f53, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f57, %f56, 0fB94D4153, %p14;
	selp.f32 	%f58, 0f3D2AAABB, 0f3C0885E4, %p14;
	fma.rn.f32 	%f59, %f57, %f53, %f58;
	selp.f32 	%f60, 0fBEFFFFFF, 0fBE2AAAA8, %p14;
	fma.rn.f32 	%f61, %f59, %f53, %f60;
	fma.rn.f32 	%f62, %f61, %f55, %f54;
	and.b32  	%r134, %r232, 2;
	setp.eq.s32 	%p15, %r134, 0;
	sub.rn.f32 	%f64, %f47, %f62;
	selp.f32 	%f65, %f62, %f64, %p15;
	add.s64 	%rd96, %rd9, %rd63;
	add.s64 	%rd98, %rd96, %rd81;
	add.s64 	%rd100, %rd98, %rd67;
	add.s64 	%rd102, %rd100, %rd101;
	add.s64 	%rd104, %rd102, %rd103;
	ld.global.nc.f32 	%f66, [%rd104];
	mul.rn.f32 	%f67, %f66, %f65;
	add.rn.f32 	%f68, %f7, %f67;
	ld.global.nc.f32 	%f70, [%rd22];
	fma.rn.f32 	%f71, %f70, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f72, %f71;
	mov.f32 	%f73, 0f4B400001;
	mov.f32 	%f74, 0f437C0000;
	fma.rm.f32 	%f75, %f72, %f74, %f73;
	add.rn.f32 	%f76, %f75, 0fCB40007F;
	neg.f32 	%f77, %f76;
	fma.rn.f32 	%f78, %f70, 0f3FB8AA3B, %f77;
	fma.rn.f32 	%f79, %f70, 0f32A57060, %f78;
	mov.b32 	%r135, %f75;
	shl.b32 	%r136, %r135, 23;
	mov.b32 	%f80, %r136;
	ex2.approx.ftz.f32 	%f81, %f79;
	mul.rn.f32 	%f82, %f81, %f80;
	neg.f32 	%f83, %f82;
	sub.rn.f32 	%f84, %f83, %f82;
	add.rn.f32 	%f85, %f84, %f84;
	add.rn.f32 	%f86, %f85, %f85;
	add.rn.f32 	%f87, %f86, %f86;
	add.rn.f32 	%f88, %f87, %f87;
	fma.rn.f32 	%f89, %f88, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f90, %f89;
	fma.rm.f32 	%f91, %f90, %f74, %f73;
	add.rn.f32 	%f92, %f91, 0fCB40007F;
	neg.f32 	%f93, %f92;
	fma.rn.f32 	%f94, %f88, 0f3FB8AA3B, %f93;
	fma.rn.f32 	%f95, %f88, 0f32A57060, %f94;
	mov.b32 	%r137, %f91;
	shl.b32 	%r138, %r137, 23;
	mov.b32 	%f96, %r138;
	ex2.approx.ftz.f32 	%f97, %f95;
	mul.rn.f32 	%f98, %f97, %f96;
	mul.rn.f32 	%f99, %f4, %f98;
	mad.lo.s32 	%r139, %r132, 96, %r7;
	mul.hi.u32 	%r143, %r139, 1374389535;
	bfe.u32 	%r144, %r143, 9, 6;
	shr.u32 	%r145, %r143, 15;
	mul.wide.u32 	%rd105, %r144, 12;
	add.s64 	%rd106, %rd7, %rd105;
	mul.wide.u32 	%rd107, %r145, 4;
	add.s64 	%rd108, %rd106, %rd107;
	ld.global.nc.f32 	%f12, [%rd108];
	mul.rn.f32 	%f101, %f12, 0f3F22F983;
	cvt.rni.s32.f32 	%r240, %f101;
	cvt.rn.f32.s32 	%f102, %r240;
	fma.rn.f32 	%f103, %f102, 0fBFC90FDA, %f12;
	fma.rn.f32 	%f104, %f102, 0fB3A22168, %f103;
	fma.rn.f32 	%f168, %f102, 0fA7C234C5, %f104;
	abs.f32 	%f14, %f12;
	setp.ltu.f32 	%p16, %f14, 0f47CE4780;
	setp.neu.f32 	%p37, %f14, 0f7F800000;
	mov.u32 	%r236, %r240;
	mov.f32 	%f167, %f168;
	@%p16 bra 	$L__BB186_21;
	@%p37 bra 	$L__BB186_16;
	mul.rn.f32 	%f167, %f12, %f47;
	mov.b32 	%r236, 0;
	bra.uni 	$L__BB186_21;
$L__BB186_16:
	mov.b32 	%r36, %f12;
	shr.u32 	%r37, %r36, 23;
	and.b32  	%r147, %r37, 224;
	add.s32 	%r148, %r147, -128;
	shl.b32 	%r149, %r36, 8;
	or.b32  	%r153, %r149, -2147483648;
	shr.u32 	%r39, %r148, 5;
	mov.b32 	%r233, 0;
	mov.u64 	%rd182, 0;
$L__BB186_17:
	.pragma "nounroll";
	add.s64 	%rd111, %rd179, %rd182;
	ld.global.nc.u32 	%r152, [%rd111];
	// begin inline asm
	{
	mad.lo.cc.u32   %r150, %r152, %r153, %r233;
	madc.hi.u32     %r233, %r152, %r153,  0;
	}
	// end inline asm
	add.s64 	%rd112, %rd11, %rd182;
	st.local.u32 	[%rd112], %r150;
	add.s64 	%rd182, %rd182, 4;
	cvt.u32.u64 	%r155, %rd182;
	setp.ne.s32 	%p18, %r155, 24;
	@%p18 bra 	$L__BB186_17;
	st.local.u32 	[%rd11+24], %r233;
	and.b32  	%r42, %r37, 31;
	mul.wide.u32 	%rd113, %r39, 4;
	sub.s64 	%rd33, %rd11, %rd113;
	ld.local.u32 	%r234, [%rd33+24];
	ld.local.u32 	%r235, [%rd33+20];
	setp.eq.s32 	%p19, %r42, 0;
	@%p19 bra 	$L__BB186_20;
	shl.b32 	%r156, %r235, %r42;
	shl.b32 	%r157, %r234, %r42;
	sub.s32 	%r159, %r81, %r42;
	shr.u32 	%r160, %r235, %r159;
	add.s32 	%r234, %r160, %r157;
	ld.local.u32 	%r161, [%rd33+16];
	shr.u32 	%r162, %r161, %r159;
	add.s32 	%r235, %r162, %r156;
$L__BB186_20:
	shr.u32 	%r163, %r234, 30;
	shr.u32 	%r164, %r235, 30;
	shl.b32 	%r165, %r234, 2;
	or.b32  	%r166, %r165, %r164;
	shl.b32 	%r167, %r235, 2;
	bfe.u32 	%r168, %r234, 29, 1;
	add.s32 	%r169, %r168, %r163;
	neg.s32 	%r170, %r169;
	setp.lt.s32 	%p20, %r36, 0;
	selp.b32 	%r236, %r170, %r169, %p20;
	xor.b32  	%r171, %r166, %r36;
	bfe.s32 	%r172, %r234, 29, 1;
	xor.b32  	%r173, %r172, %r166;
	xor.b32  	%r174, %r172, %r167;
	cvt.u64.u32 	%rd114, %r173;
	shl.b64 	%rd115, %rd114, 32;
	cvt.u64.u32 	%rd116, %r174;
	or.b64  	%rd117, %rd115, %rd116;
	cvt.rn.f64.s64 	%fd5, %rd117;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f105, %fd6;
	neg.f32 	%f106, %f105;
	setp.lt.s32 	%p21, %r171, 0;
	selp.f32 	%f167, %f106, %f105, %p21;
$L__BB186_21:
	mul.rn.f32 	%f69, %f4, %f68;
	mul.rn.f32 	%f100, %f66, %f99;
	shr.u32 	%r140, %r139, 5;
	mul.hi.u32 	%r141, %r140, 85899346;
	mul.lo.s32 	%r142, %r141, 50;
	sub.s32 	%r33, %r140, %r142;
	shl.b32 	%r34, %r145, 1;
	cvt.u64.u32 	%rd29, %r144;
	mul.rn.f32 	%f108, %f167, %f167;
	and.b32  	%r176, %r236, 1;
	setp.eq.b32 	%p23, %r176, 1;
	selp.f32 	%f109, 0f3F800000, %f167, %p23;
	fma.rn.f32 	%f110, %f108, %f109, 0f00000000;
	fma.rn.f32 	%f111, %f108, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f112, %f111, 0fB94D4153, %p23;
	selp.f32 	%f113, 0f3D2AAABB, 0f3C0885E4, %p23;
	fma.rn.f32 	%f114, %f112, %f108, %f113;
	selp.f32 	%f115, 0fBEFFFFFF, 0fBE2AAAA8, %p23;
	fma.rn.f32 	%f116, %f114, %f108, %f115;
	fma.rn.f32 	%f117, %f116, %f110, %f109;
	and.b32  	%r177, %r236, 2;
	setp.eq.s32 	%p24, %r177, 0;
	sub.rn.f32 	%f119, %f47, %f117;
	selp.f32 	%f120, %f117, %f119, %p24;
	shl.b64 	%rd118, %rd29, 2;
	add.s64 	%rd119, %rd5, %rd118;
	ld.global.nc.f32 	%f18, [%rd119];
	mul.lo.s64 	%rd120, %rd29, 38400;
	add.s64 	%rd121, %rd6, %rd120;
	mul.wide.u32 	%rd122, %r33, 768;
	add.s64 	%rd123, %rd121, %rd122;
	mul.lo.s64 	%rd124, %rd23, 24;
	add.s64 	%rd125, %rd123, %rd124;
	mul.wide.u32 	%rd126, %r34, 4;
	add.s64 	%rd35, %rd125, %rd126;
	ld.global.nc.f32 	%f121, [%rd35];
	mul.rn.f32 	%f122, %f18, %f121;
	neg.f32 	%f123, %f120;
	mul.rn.f32 	%f19, %f122, %f123;
	@%p16 bra 	$L__BB186_29;
	@%p37 bra 	$L__BB186_24;
	bra.uni 	$L__BB186_23;
$L__BB186_24:
	mov.b32 	%r51, %f12;
	shr.u32 	%r52, %r51, 23;
	and.b32  	%r179, %r52, 224;
	add.s32 	%r180, %r179, -128;
	shl.b32 	%r181, %r51, 8;
	or.b32  	%r185, %r181, -2147483648;
	shr.u32 	%r54, %r180, 5;
	mov.b32 	%r237, 0;
	mov.u64 	%rd183, 0;
$L__BB186_25:
	.pragma "nounroll";
	add.s64 	%rd129, %rd179, %rd183;
	ld.global.nc.u32 	%r184, [%rd129];
	// begin inline asm
	{
	mad.lo.cc.u32   %r182, %r184, %r185, %r237;
	madc.hi.u32     %r237, %r184, %r185,  0;
	}
	// end inline asm
	add.s64 	%rd130, %rd11, %rd183;
	st.local.u32 	[%rd130], %r182;
	add.s64 	%rd183, %rd183, 4;
	cvt.u32.u64 	%r187, %rd183;
	setp.ne.s32 	%p26, %r187, 24;
	@%p26 bra 	$L__BB186_25;
	st.local.u32 	[%rd11+24], %r237;
	and.b32  	%r57, %r52, 31;
	mul.wide.u32 	%rd131, %r54, 4;
	sub.s64 	%rd38, %rd11, %rd131;
	ld.local.u32 	%r238, [%rd38+24];
	ld.local.u32 	%r239, [%rd38+20];
	setp.eq.s32 	%p27, %r57, 0;
	@%p27 bra 	$L__BB186_28;
	shl.b32 	%r188, %r239, %r57;
	shl.b32 	%r189, %r238, %r57;
	sub.s32 	%r191, %r81, %r57;
	shr.u32 	%r192, %r239, %r191;
	add.s32 	%r238, %r192, %r189;
	ld.local.u32 	%r193, [%rd38+16];
	shr.u32 	%r194, %r193, %r191;
	add.s32 	%r239, %r194, %r188;
$L__BB186_28:
	shr.u32 	%r195, %r238, 30;
	shr.u32 	%r196, %r239, 30;
	shl.b32 	%r197, %r238, 2;
	or.b32  	%r198, %r197, %r196;
	shl.b32 	%r199, %r239, 2;
	bfe.u32 	%r200, %r238, 29, 1;
	add.s32 	%r201, %r200, %r195;
	neg.s32 	%r202, %r201;
	setp.lt.s32 	%p28, %r51, 0;
	selp.b32 	%r240, %r202, %r201, %p28;
	xor.b32  	%r203, %r198, %r51;
	bfe.s32 	%r204, %r238, 29, 1;
	xor.b32  	%r205, %r204, %r198;
	xor.b32  	%r206, %r204, %r199;
	cvt.u64.u32 	%rd132, %r205;
	shl.b64 	%rd133, %rd132, 32;
	cvt.u64.u32 	%rd134, %r206;
	or.b64  	%rd135, %rd133, %rd134;
	cvt.rn.f64.s64 	%fd7, %rd135;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f124, %fd8;
	neg.f32 	%f125, %f124;
	setp.lt.s32 	%p29, %r203, 0;
	selp.f32 	%f168, %f125, %f124, %p29;
	bra.uni 	$L__BB186_29;
$L__BB186_30:
	cvt.u32.u64 	%r66, %rd23;
	cvt.u64.u32 	%rd39, %r1;
	mul.lo.s64 	%rd148, %rd23, 132;
	mov.u64 	%rd149, shared_cache17;
	add.s64 	%rd150, %rd149, %rd148;
	mul.wide.u32 	%rd151, %r1, 4;
	add.s64 	%rd152, %rd150, %rd151;
	st.shared.f32 	[%rd152], %f164;
	bar.sync 	0;
	mul.wide.u32 	%rd153, %r1, 132;
	add.s64 	%rd154, %rd149, %rd153;
	add.s64 	%rd156, %rd154, %rd142;
	ld.shared.f32 	%f143, [%rd156];
	shfl.sync.down.b32	%f144, %f143, 16, 31, -1;
	add.rn.f32 	%f145, %f143, %f144;
	shfl.sync.down.b32	%f146, %f145, 8, 31, -1;
	add.rn.f32 	%f147, %f145, %f146;
	shfl.sync.down.b32	%f148, %f147, 4, 31, -1;
	add.rn.f32 	%f149, %f147, %f148;
	shfl.sync.down.b32	%f150, %f149, 2, 31, -1;
	add.rn.f32 	%f151, %f149, %f150;
	shfl.sync.down.b32	%f152, %f151, 1, 31, -1;
	add.rn.f32 	%f23, %f151, %f152;
	st.shared.f32 	[%rd156], %f23;
	setp.eq.s32 	%p33, %r66, 0;
	@%p33 bra 	$L__BB186_33;
	bra.uni 	$L__BB186_31;
$L__BB186_33:
	or.b32  	%r211, %r1, %r2;
	mul.hi.u32 	%r213, %r211, -1431655765;
	shr.u32 	%r214, %r213, 2;
	mul.lo.s32 	%r215, %r214, 6;
	sub.s32 	%r216, %r211, %r215;
	mul.lo.s64 	%rd157, %rd15, 384;
	add.s64 	%rd158, %rd4, %rd157;
	mul.wide.u32 	%rd159, %r214, 24;
	add.s64 	%rd160, %rd158, %rd159;
	mul.wide.u32 	%rd161, %r216, 4;
	add.s64 	%rd162, %rd160, %rd161;
	st.global.f32 	[%rd162], %f23;
$L__BB186_31:
	mov.u64 	%rd164, shared_cache18;
	add.s64 	%rd165, %rd164, %rd148;
	shl.b64 	%rd166, %rd39, 2;
	add.s64 	%rd167, %rd165, %rd166;
	st.shared.f32 	[%rd167], %f163;
	bar.sync 	0;
	mul.lo.s64 	%rd168, %rd39, 132;
	add.s64 	%rd169, %rd164, %rd168;
	add.s64 	%rd171, %rd169, %rd142;
	ld.shared.f32 	%f153, [%rd171];
	shfl.sync.down.b32	%f154, %f153, 16, 31, -1;
	add.rn.f32 	%f155, %f153, %f154;
	shfl.sync.down.b32	%f156, %f155, 8, 31, -1;
	add.rn.f32 	%f157, %f155, %f156;
	shfl.sync.down.b32	%f158, %f157, 4, 31, -1;
	add.rn.f32 	%f159, %f157, %f158;
	shfl.sync.down.b32	%f160, %f159, 2, 31, -1;
	add.rn.f32 	%f161, %f159, %f160;
	shfl.sync.down.b32	%f162, %f161, 1, 31, -1;
	add.rn.f32 	%f24, %f161, %f162;
	st.shared.f32 	[%rd171], %f24;
	@%p33 bra 	$L__BB186_34;
	bra.uni 	$L__BB186_32;
$L__BB186_34:
	or.b32  	%r217, %r1, %r2;
	mul.hi.u32 	%r219, %r217, -1431655765;
	shr.u32 	%r220, %r219, 2;
	mul.lo.s32 	%r221, %r220, 6;
	sub.s32 	%r222, %r217, %r221;
	mul.lo.s64 	%rd172, %rd15, 384;
	add.s64 	%rd173, %rd3, %rd172;
	mul.wide.u32 	%rd174, %r220, 24;
	add.s64 	%rd175, %rd173, %rd174;
	mul.wide.u32 	%rd176, %r222, 4;
	add.s64 	%rd177, %rd175, %rd176;
	st.global.f32 	[%rd177], %f24;
$L__BB186_32:
	ret;

}
	// .globl	loop_broadcast_fusion_41
.visible .entry loop_broadcast_fusion_41(
	.param .u64 loop_broadcast_fusion_41_param_0
)
.reqntid 256, 1, 1
{
	.reg .b32 	%r<6>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [loop_broadcast_fusion_41_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	shl.b32 	%r3, %r2, 10;
	shl.b32 	%r4, %r1, 2;
	or.b32  	%r5, %r3, %r4;
	mul.wide.u32 	%rd3, %r5, 4;
	add.s64 	%rd4, %rd2, %rd3;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd4], {%f1, %f1, %f1, %f1};
	ret;

}
	// .globl	input_scatter_fusion_256
.visible .entry input_scatter_fusion_256(
	.param .u64 input_scatter_fusion_256_param_0,
	.param .u64 input_scatter_fusion_256_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<11>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_256_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_256_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r2, 31;
	shr.u32 	%r6, %r4, 5;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r7, %r4, 1374389535;
	bfe.u32 	%r8, %r7, 9, 6;
	cvt.u16.u32 	%rs7, %r1;
	shr.u16 	%rs8, %rs7, 5;
	mul.hi.u16 	%rs9, %rs8, 2622;
	shl.b16 	%rs10, %rs9, 1;
	cvt.u32.u16 	%r9, %rs10;
	mul.wide.u32 	%rd5, %r9, 409600;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r8, 6400;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r10, %rs6;
	mul.wide.u32 	%rd9, %r10, 128;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+409600];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+409600], %f3;
	ret;

}
	// .globl	wrapped_transpose_262
.visible .entry wrapped_transpose_262(
	.param .u64 wrapped_transpose_262_param_0,
	.param .u64 wrapped_transpose_262_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<28>;
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<32>;

	ld.param.u64 	%rd1, [wrapped_transpose_262_param_0];
	ld.param.u64 	%rd2, [wrapped_transpose_262_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	mul.hi.u32 	%r6, %r5, 458129845;
	bfe.u32 	%r7, %r6, 10, 6;
	or.b32  	%r8, %r5, 3;
	mul.hi.u32 	%r9, %r5, 715827883;
	shr.u32 	%r10, %r9, 5;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r8, 715827883;
	and.b32  	%r12, %r11, 31;
	mul.lo.s32 	%r13, %r11, 6;
	sub.s32 	%r14, %r8, %r13;
	or.b32  	%r15, %r5, 2;
	mul.hi.u32 	%r16, %r15, 715827883;
	and.b32  	%r17, %r16, 31;
	mul.lo.s32 	%r18, %r16, 6;
	sub.s32 	%r19, %r15, %r18;
	or.b32  	%r20, %r5, 1;
	and.b32  	%r21, %r9, 31;
	mul.hi.u32 	%r22, %r20, 715827883;
	mul.lo.s32 	%r23, %r22, 6;
	sub.s32 	%r24, %r20, %r23;
	mul.lo.s32 	%r25, %r9, 6;
	sub.s32 	%r26, %r5, %r25;
	mul.wide.u32 	%rd5, %r26, 409600;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r7, 6400;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r27, %rs6;
	mul.wide.u32 	%rd9, %r27, 128;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r21, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r5, 4;
	add.s64 	%rd14, %rd3, %rd13;
	mul.wide.u32 	%rd15, %r24, 409600;
	add.s64 	%rd16, %rd4, %rd15;
	add.s64 	%rd17, %rd16, %rd7;
	add.s64 	%rd18, %rd17, %rd9;
	add.s64 	%rd19, %rd18, %rd11;
	ld.global.nc.f32 	%f2, [%rd19];
	mul.wide.u32 	%rd20, %r19, 409600;
	add.s64 	%rd21, %rd4, %rd20;
	add.s64 	%rd22, %rd21, %rd7;
	add.s64 	%rd23, %rd22, %rd9;
	mul.wide.u32 	%rd24, %r17, 4;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.nc.f32 	%f3, [%rd25];
	mul.wide.u32 	%rd26, %r14, 409600;
	add.s64 	%rd27, %rd4, %rd26;
	add.s64 	%rd28, %rd27, %rd7;
	add.s64 	%rd29, %rd28, %rd9;
	mul.wide.u32 	%rd30, %r12, 4;
	add.s64 	%rd31, %rd29, %rd30;
	ld.global.nc.f32 	%f4, [%rd31];
	st.global.v4.f32 	[%rd14], {%f1, %f2, %f3, %f4};
	ret;

}
	// .globl	input_scatter_fusion_257
.visible .entry input_scatter_fusion_257(
	.param .u64 input_scatter_fusion_257_param_0,
	.param .u64 input_scatter_fusion_257_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<11>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_257_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_257_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r2, 31;
	shr.u32 	%r6, %r4, 5;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r7, %r4, 1374389535;
	bfe.u32 	%r8, %r7, 9, 6;
	cvt.u16.u32 	%rs7, %r1;
	shr.u16 	%rs8, %rs7, 5;
	mul.hi.u16 	%rs9, %rs8, 2622;
	shl.b16 	%rs10, %rs9, 1;
	cvt.u32.u16 	%r9, %rs10;
	mul.wide.u32 	%rd5, %r9, 409600;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r8, 6400;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r10, %rs6;
	mul.wide.u32 	%rd9, %r10, 128;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	input_add_reduce_fusion_42
.visible .entry input_add_reduce_fusion_42(
	.param .u64 input_add_reduce_fusion_42_param_0,
	.param .u64 input_add_reduce_fusion_42_param_1,
	.param .u64 input_add_reduce_fusion_42_param_2,
	.param .u64 input_add_reduce_fusion_42_param_3,
	.param .u64 input_add_reduce_fusion_42_param_4,
	.param .u64 input_add_reduce_fusion_42_param_5,
	.param .u64 input_add_reduce_fusion_42_param_6,
	.param .u64 input_add_reduce_fusion_42_param_7,
	.param .u64 input_add_reduce_fusion_42_param_8,
	.param .u64 input_add_reduce_fusion_42_param_9
)
.reqntid 1024, 1, 1
{
	.local .align 4 .b8 	__local_depot191[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<25>;
	.reg .b32 	%r<134>;
	.reg .f32 	%f<126>;
	.reg .b64 	%rd<163>;
	.reg .f64 	%fd<5>;
	// demoted variable
	.shared .align 4 .b8 shared_cache19[4224];
	mov.u64 	%SPL, __local_depot191;
	ld.param.u64 	%rd30, [input_add_reduce_fusion_42_param_0];
	ld.param.u64 	%rd31, [input_add_reduce_fusion_42_param_9];
	cvta.to.global.u64 	%rd1, %rd31;
	ld.param.u64 	%rd32, [input_add_reduce_fusion_42_param_1];
	ld.param.u64 	%rd33, [input_add_reduce_fusion_42_param_8];
	cvta.to.global.u64 	%rd2, %rd33;
	ld.param.u64 	%rd34, [input_add_reduce_fusion_42_param_2];
	ld.param.u64 	%rd35, [input_add_reduce_fusion_42_param_7];
	cvta.to.global.u64 	%rd3, %rd35;
	ld.param.u64 	%rd36, [input_add_reduce_fusion_42_param_3];
	ld.param.u64 	%rd37, [input_add_reduce_fusion_42_param_6];
	cvta.to.global.u64 	%rd4, %rd37;
	ld.param.u64 	%rd38, [input_add_reduce_fusion_42_param_4];
	ld.param.u64 	%rd39, [input_add_reduce_fusion_42_param_5];
	cvta.to.global.u64 	%rd40, %rd39;
	cvta.to.global.u64 	%rd41, %rd38;
	cvta.to.global.u64 	%rd5, %rd36;
	cvta.to.global.u64 	%rd6, %rd34;
	cvta.to.global.u64 	%rd42, %rd32;
	cvta.to.global.u64 	%rd7, %rd30;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r40, %tid.x;
	mov.u32 	%r41, %ctaid.x;
	shr.u32 	%r1, %r40, 5;
	and.b32  	%r2, %r40, 31;
	cvt.u16.u32 	%rs1, %r41;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 3;
	mul.lo.s16 	%rs4, %rs3, 12;
	sub.s16 	%rs5, %rs1, %rs4;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r3, %rs6;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs7, %r4;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r42, %rs10;
	cvt.u32.u16 	%r43, %rs8;
	cvt.u64.u16 	%rd10, %rs3;
	cvt.u32.u16 	%r44, %rs3;
	mul.wide.u32 	%rd45, %r44, 4;
	add.s64 	%rd46, %rd42, %rd45;
	ld.global.nc.f32 	%f1, [%rd46];
	setp.gt.u32 	%p3, %r4, 11;
	and.b32  	%r5, %r43, 1;
	setp.eq.s32 	%p4, %r5, 0;
	and.pred  	%p1, %p3, %p4;
	add.s16 	%rs11, %rs8, -2;
	and.b16  	%rs12, %rs11, 128;
	shr.u16 	%rs13, %rs12, 7;
	add.s16 	%rs14, %rs11, %rs13;
	cvt.s16.s8 	%rs15, %rs14;
	shr.s16 	%rs16, %rs15, 1;
	add.s16 	%rs17, %rs16, 1;
	cvt.s32.s16 	%r45, %rs17;
	cvt.u64.u32 	%rd11, %r45;
	cvt.u64.u16 	%rd12, %rs10;
	add.s32 	%r46, %r43, -1;
	setp.gt.u32 	%p5, %r4, 5;
	and.b32  	%r47, %r46, 1;
	setp.eq.b32 	%p6, %r47, 1;
	not.pred 	%p7, %p6;
	and.pred  	%p2, %p5, %p7;
	cvt.u16.u32 	%rs18, %r46;
	and.b16  	%rs19, %rs18, 128;
	shr.u16 	%rs20, %rs19, 7;
	add.s16 	%rs21, %rs18, %rs20;
	cvt.s16.s8 	%rs22, %rs21;
	shr.s16 	%rs23, %rs22, 1;
	cvt.s32.s16 	%r48, %rs23;
	cvt.u64.u32 	%rd13, %r48;
	shr.u16 	%rs24, %rs8, 1;
	cvt.u64.u16 	%rd14, %rs24;
	shr.u32 	%r49, %r42, 1;
	cvt.u64.u32 	%rd15, %r49;
	mul.wide.u32 	%rd47, %r49, 4;
	mul.wide.u32 	%rd48, %r44, 12;
	add.s64 	%rd49, %rd40, %rd48;
	add.s64 	%rd16, %rd49, %rd47;
	add.s64 	%rd17, %rd41, %rd45;
	and.b32  	%r50, %r42, 1;
	cvt.u64.u16 	%rd18, %rs8;
	cvt.u64.u32 	%rd19, %r50;
	mov.f32 	%f39, 0f00000000;
	mul.lo.s64 	%rd54, %rd11, 24;
	mul.lo.s64 	%rd61, %rd13, 24;
	setp.lt.u32 	%p17, %r4, 6;
	shl.b64 	%rd104, %rd15, 3;
	shl.b64 	%rd106, %rd19, 2;
	mov.u32 	%r6, %r1;
	mov.f32 	%f2, %f39;
	bra.uni 	$L__BB191_1;
$L__BB191_10:
	add.s32 	%r6, %r6, 32;
	add.rn.f32 	%f2, %f2, %f74;
	add.rn.f32 	%f13, %f120, %f121;
	add.rn.f32 	%f15, %f13, %f122;
	cvt.u32.u64 	%r117, %rd20;
	add.rn.f32 	%f104, %f15, %f123;
	add.s64 	%rd138, %rd1, %rd98;
	add.s64 	%rd140, %rd138, %rd100;
	add.s64 	%rd142, %rd140, %rd102;
	add.s64 	%rd144, %rd142, %rd56;
	st.global.f32 	[%rd144], %f104;
	setp.gt.u32 	%p28, %r117, 17;
	@%p28 bra 	$L__BB191_11;
$L__BB191_1:
	mul.lo.s64 	%rd50, %rd10, 38400;
	add.s64 	%rd51, %rd6, %rd50;
	mul.wide.u32 	%rd52, %r6, 768;
	add.s64 	%rd53, %rd51, %rd52;
	add.s64 	%rd55, %rd53, %rd54;
	shl.b64 	%rd56, %rd12, 2;
	add.s64 	%rd21, %rd55, %rd56;
	mov.f32 	%f116, %f39;
	@%p1 bra 	$L__BB191_2;
	bra.uni 	$L__BB191_3;
$L__BB191_2:
	ld.global.nc.f32 	%f116, [%rd21];
$L__BB191_3:
	cvt.u64.u32 	%rd20, %r6;
	add.s64 	%rd58, %rd5, %rd50;
	mul.lo.s64 	%rd59, %rd20, 768;
	add.s64 	%rd60, %rd58, %rd59;
	add.s64 	%rd62, %rd60, %rd61;
	add.s64 	%rd22, %rd62, %rd56;
	mov.f32 	%f117, %f39;
	@%p2 bra 	$L__BB191_13;
	bra.uni 	$L__BB191_4;
$L__BB191_13:
	ld.global.nc.f32 	%f117, [%rd22];
$L__BB191_4:
	mov.u64 	%rd160, __cudart_i2opi_f;
	mov.f32 	%f118, %f39;
	@%p4 bra 	$L__BB191_14;
	bra.uni 	$L__BB191_5;
$L__BB191_14:
	add.s64 	%rd65, %rd4, %rd50;
	add.s64 	%rd67, %rd65, %rd59;
	mul.lo.s64 	%rd68, %rd14, 24;
	add.s64 	%rd69, %rd67, %rd68;
	add.s64 	%rd71, %rd69, %rd56;
	ld.global.nc.f32 	%f43, [%rd71];
	add.s64 	%rd72, %rd3, %rd50;
	add.s64 	%rd73, %rd72, %rd59;
	add.s64 	%rd74, %rd73, %rd68;
	add.s64 	%rd75, %rd74, %rd56;
	ld.global.nc.f32 	%f44, [%rd75];
	add.rn.f32 	%f19, %f43, %f44;
	ld.global.nc.f32 	%f20, [%rd16];
	mul.rn.f32 	%f45, %f20, 0f3F22F983;
	cvt.rni.s32.f32 	%r129, %f45;
	cvt.rn.f32.s32 	%f46, %r129;
	fma.rn.f32 	%f47, %f46, 0fBFC90FDA, %f20;
	fma.rn.f32 	%f48, %f46, 0fB3A22168, %f47;
	fma.rn.f32 	%f124, %f46, 0fA7C234C5, %f48;
	abs.f32 	%f22, %f20;
	setp.ltu.f32 	%p9, %f22, 0f47CE4780;
	@%p9 bra 	$L__BB191_22;
	setp.neu.f32 	%p10, %f22, 0f7F800000;
	@%p10 bra 	$L__BB191_17;
	mov.f32 	%f51, 0f00000000;
	mul.rn.f32 	%f124, %f20, %f51;
	mov.b32 	%r129, 0;
	bra.uni 	$L__BB191_22;
$L__BB191_17:
	mov.b32 	%r9, %f20;
	shr.u32 	%r10, %r9, 23;
	and.b32  	%r52, %r10, 224;
	add.s32 	%r53, %r52, -128;
	shl.b32 	%r54, %r9, 8;
	or.b32  	%r58, %r54, -2147483648;
	shr.u32 	%r12, %r53, 5;
	mov.b32 	%r126, 0;
	mov.u64 	%rd161, 0;
$L__BB191_18:
	.pragma "nounroll";
	add.s64 	%rd78, %rd160, %rd161;
	ld.global.nc.u32 	%r57, [%rd78];
	// begin inline asm
	{
	mad.lo.cc.u32   %r55, %r57, %r58, %r126;
	madc.hi.u32     %r126, %r57, %r58,  0;
	}
	// end inline asm
	add.s64 	%rd79, %rd8, %rd161;
	st.local.u32 	[%rd79], %r55;
	add.s64 	%rd161, %rd161, 4;
	cvt.u32.u64 	%r60, %rd161;
	setp.ne.s32 	%p11, %r60, 24;
	@%p11 bra 	$L__BB191_18;
	st.local.u32 	[%rd8+24], %r126;
	and.b32  	%r15, %r10, 31;
	mul.wide.u32 	%rd80, %r12, 4;
	sub.s64 	%rd26, %rd8, %rd80;
	ld.local.u32 	%r127, [%rd26+24];
	ld.local.u32 	%r128, [%rd26+20];
	setp.eq.s32 	%p12, %r15, 0;
	@%p12 bra 	$L__BB191_21;
	shl.b32 	%r61, %r128, %r15;
	shl.b32 	%r62, %r127, %r15;
	mov.b32 	%r63, 32;
	sub.s32 	%r64, %r63, %r15;
	shr.u32 	%r65, %r128, %r64;
	add.s32 	%r127, %r65, %r62;
	ld.local.u32 	%r66, [%rd26+16];
	shr.u32 	%r67, %r66, %r64;
	add.s32 	%r128, %r67, %r61;
$L__BB191_21:
	shr.u32 	%r68, %r127, 30;
	shr.u32 	%r69, %r128, 30;
	shl.b32 	%r70, %r127, 2;
	or.b32  	%r71, %r70, %r69;
	shl.b32 	%r72, %r128, 2;
	bfe.u32 	%r73, %r127, 29, 1;
	add.s32 	%r74, %r73, %r68;
	neg.s32 	%r75, %r74;
	setp.lt.s32 	%p13, %r9, 0;
	selp.b32 	%r129, %r75, %r74, %p13;
	xor.b32  	%r76, %r71, %r9;
	bfe.s32 	%r77, %r127, 29, 1;
	xor.b32  	%r78, %r77, %r71;
	xor.b32  	%r79, %r77, %r72;
	cvt.u64.u32 	%rd81, %r78;
	shl.b64 	%rd82, %rd81, 32;
	cvt.u64.u32 	%rd83, %r79;
	or.b64  	%rd84, %rd82, %rd83;
	cvt.rn.f64.s64 	%fd1, %rd84;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f49, %fd2;
	neg.f32 	%f50, %f49;
	setp.lt.s32 	%p14, %r76, 0;
	selp.f32 	%f124, %f50, %f49, %p14;
$L__BB191_22:
	add.s32 	%r81, %r129, 1;
	mul.rn.f32 	%f52, %f124, %f124;
	and.b32  	%r82, %r129, 1;
	setp.eq.b32 	%p15, %r82, 1;
	selp.f32 	%f53, %f124, 0f3F800000, %p15;
	fma.rn.f32 	%f54, %f52, %f53, 0f00000000;
	fma.rn.f32 	%f55, %f52, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f56, 0fB94D4153, %f55, %p15;
	selp.f32 	%f57, 0f3C0885E4, 0f3D2AAABB, %p15;
	fma.rn.f32 	%f58, %f56, %f52, %f57;
	selp.f32 	%f59, 0fBE2AAAA8, 0fBEFFFFFF, %p15;
	fma.rn.f32 	%f60, %f58, %f52, %f59;
	fma.rn.f32 	%f61, %f60, %f54, %f53;
	and.b32  	%r83, %r81, 2;
	setp.eq.s32 	%p16, %r83, 0;
	mov.f32 	%f62, 0f00000000;
	sub.rn.f32 	%f63, %f62, %f61;
	selp.f32 	%f64, %f61, %f63, %p16;
	ld.global.nc.f32 	%f65, [%rd17];
	add.s64 	%rd90, %rd60, %rd68;
	add.s64 	%rd92, %rd90, %rd56;
	ld.global.nc.f32 	%f66, [%rd92];
	mul.rn.f32 	%f67, %f65, %f66;
	mul.rn.f32 	%f68, %f67, %f64;
	add.rn.f32 	%f118, %f19, %f68;
$L__BB191_5:
	add.s64 	%rd96, %rd51, %rd59;
	add.s64 	%rd23, %rd96, %rd56;
	mov.f32 	%f119, %f39;
	@%p17 bra 	$L__BB191_23;
	bra.uni 	$L__BB191_6;
$L__BB191_23:
	ld.global.nc.f32 	%f119, [%rd23];
$L__BB191_6:
	add.rn.f32 	%f6, %f116, %f117;
	add.rn.f32 	%f8, %f6, %f118;
	mul.lo.s64 	%rd98, %rd10, 76800;
	add.s64 	%rd99, %rd7, %rd98;
	mul.lo.s64 	%rd100, %rd20, 1536;
	add.s64 	%rd101, %rd99, %rd100;
	mul.lo.s64 	%rd102, %rd18, 24;
	add.s64 	%rd103, %rd101, %rd102;
	add.s64 	%rd105, %rd103, %rd104;
	add.s64 	%rd107, %rd105, %rd106;
	ld.global.nc.f32 	%f73, [%rd107];
	mov.f32 	%f120, %f39;
	@%p1 bra 	$L__BB191_24;
	bra.uni 	$L__BB191_7;
$L__BB191_24:
	ld.global.nc.f32 	%f120, [%rd21];
$L__BB191_7:
	add.rn.f32 	%f71, %f8, %f119;
	mov.f32 	%f121, %f39;
	@%p2 bra 	$L__BB191_25;
	bra.uni 	$L__BB191_8;
$L__BB191_25:
	ld.global.nc.f32 	%f121, [%rd22];
$L__BB191_8:
	mul.rn.f32 	%f72, %f1, %f71;
	mov.f32 	%f122, %f39;
	@%p4 bra 	$L__BB191_26;
	bra.uni 	$L__BB191_9;
$L__BB191_26:
	add.s64 	%rd109, %rd4, %rd50;
	add.s64 	%rd111, %rd109, %rd59;
	mul.lo.s64 	%rd112, %rd14, 24;
	add.s64 	%rd113, %rd111, %rd112;
	add.s64 	%rd115, %rd113, %rd56;
	ld.global.nc.f32 	%f77, [%rd115];
	add.s64 	%rd116, %rd3, %rd50;
	add.s64 	%rd117, %rd116, %rd59;
	add.s64 	%rd118, %rd117, %rd112;
	add.s64 	%rd119, %rd118, %rd56;
	ld.global.nc.f32 	%f78, [%rd119];
	add.rn.f32 	%f30, %f77, %f78;
	ld.global.nc.f32 	%f31, [%rd16];
	mul.rn.f32 	%f79, %f31, 0f3F22F983;
	cvt.rni.s32.f32 	%r133, %f79;
	cvt.rn.f32.s32 	%f80, %r133;
	fma.rn.f32 	%f81, %f80, 0fBFC90FDA, %f31;
	fma.rn.f32 	%f82, %f80, 0fB3A22168, %f81;
	fma.rn.f32 	%f125, %f80, 0fA7C234C5, %f82;
	abs.f32 	%f33, %f31;
	setp.ltu.f32 	%p19, %f33, 0f47CE4780;
	@%p19 bra 	$L__BB191_34;
	setp.neu.f32 	%p20, %f33, 0f7F800000;
	@%p20 bra 	$L__BB191_29;
	mov.f32 	%f85, 0f00000000;
	mul.rn.f32 	%f125, %f31, %f85;
	mov.b32 	%r133, 0;
	bra.uni 	$L__BB191_34;
$L__BB191_29:
	mov.b32 	%r130, 0;
	mov.b32 	%r25, %f31;
	shr.u32 	%r26, %r25, 23;
	and.b32  	%r85, %r26, 224;
	add.s32 	%r86, %r85, -128;
	shl.b32 	%r87, %r25, 8;
	or.b32  	%r91, %r87, -2147483648;
	shr.u32 	%r28, %r86, 5;
	mov.u64 	%rd162, 0;
$L__BB191_30:
	.pragma "nounroll";
	add.s64 	%rd122, %rd160, %rd162;
	ld.global.nc.u32 	%r90, [%rd122];
	// begin inline asm
	{
	mad.lo.cc.u32   %r88, %r90, %r91, %r130;
	madc.hi.u32     %r130, %r90, %r91,  0;
	}
	// end inline asm
	add.s64 	%rd123, %rd8, %rd162;
	st.local.u32 	[%rd123], %r88;
	add.s64 	%rd162, %rd162, 4;
	cvt.u32.u64 	%r93, %rd162;
	setp.ne.s32 	%p21, %r93, 24;
	@%p21 bra 	$L__BB191_30;
	st.local.u32 	[%rd8+24], %r130;
	and.b32  	%r31, %r26, 31;
	mul.wide.u32 	%rd124, %r28, 4;
	sub.s64 	%rd29, %rd8, %rd124;
	ld.local.u32 	%r131, [%rd29+24];
	ld.local.u32 	%r132, [%rd29+20];
	setp.eq.s32 	%p22, %r31, 0;
	@%p22 bra 	$L__BB191_33;
	shl.b32 	%r94, %r132, %r31;
	shl.b32 	%r95, %r131, %r31;
	mov.b32 	%r96, 32;
	sub.s32 	%r97, %r96, %r31;
	shr.u32 	%r98, %r132, %r97;
	add.s32 	%r131, %r98, %r95;
	ld.local.u32 	%r99, [%rd29+16];
	shr.u32 	%r100, %r99, %r97;
	add.s32 	%r132, %r100, %r94;
$L__BB191_33:
	shr.u32 	%r101, %r131, 30;
	shr.u32 	%r102, %r132, 30;
	shl.b32 	%r103, %r131, 2;
	or.b32  	%r104, %r103, %r102;
	shl.b32 	%r105, %r132, 2;
	bfe.u32 	%r106, %r131, 29, 1;
	add.s32 	%r107, %r106, %r101;
	neg.s32 	%r108, %r107;
	setp.lt.s32 	%p23, %r25, 0;
	selp.b32 	%r133, %r108, %r107, %p23;
	xor.b32  	%r109, %r104, %r25;
	bfe.s32 	%r110, %r131, 29, 1;
	xor.b32  	%r111, %r110, %r104;
	xor.b32  	%r112, %r110, %r105;
	cvt.u64.u32 	%rd125, %r111;
	shl.b64 	%rd126, %rd125, 32;
	cvt.u64.u32 	%rd127, %r112;
	or.b64  	%rd128, %rd126, %rd127;
	cvt.rn.f64.s64 	%fd3, %rd128;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f83, %fd4;
	neg.f32 	%f84, %f83;
	setp.lt.s32 	%p24, %r109, 0;
	selp.f32 	%f125, %f84, %f83, %p24;
$L__BB191_34:
	add.s32 	%r114, %r133, 1;
	mul.rn.f32 	%f86, %f125, %f125;
	and.b32  	%r115, %r133, 1;
	setp.eq.b32 	%p25, %r115, 1;
	selp.f32 	%f87, %f125, 0f3F800000, %p25;
	fma.rn.f32 	%f88, %f86, %f87, 0f00000000;
	fma.rn.f32 	%f89, %f86, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f90, 0fB94D4153, %f89, %p25;
	selp.f32 	%f91, 0f3C0885E4, 0f3D2AAABB, %p25;
	fma.rn.f32 	%f92, %f90, %f86, %f91;
	selp.f32 	%f93, 0fBE2AAAA8, 0fBEFFFFFF, %p25;
	fma.rn.f32 	%f94, %f92, %f86, %f93;
	fma.rn.f32 	%f95, %f94, %f88, %f87;
	and.b32  	%r116, %r114, 2;
	setp.eq.s32 	%p26, %r116, 0;
	mov.f32 	%f96, 0f00000000;
	sub.rn.f32 	%f97, %f96, %f95;
	selp.f32 	%f98, %f95, %f97, %p26;
	ld.global.nc.f32 	%f99, [%rd17];
	add.s64 	%rd134, %rd60, %rd112;
	add.s64 	%rd136, %rd134, %rd56;
	ld.global.nc.f32 	%f100, [%rd136];
	mul.rn.f32 	%f101, %f99, %f100;
	mul.rn.f32 	%f102, %f101, %f98;
	add.rn.f32 	%f122, %f30, %f102;
$L__BB191_9:
	mul.rn.f32 	%f74, %f73, %f72;
	mov.f32 	%f123, %f39;
	@%p17 bra 	$L__BB191_35;
	bra.uni 	$L__BB191_10;
$L__BB191_35:
	ld.global.nc.f32 	%f123, [%rd23];
	bra.uni 	$L__BB191_10;
$L__BB191_11:
	mul.wide.u32 	%rd145, %r2, 132;
	mov.u64 	%rd146, shared_cache19;
	add.s64 	%rd147, %rd146, %rd145;
	mul.wide.u32 	%rd148, %r1, 4;
	add.s64 	%rd149, %rd147, %rd148;
	st.shared.f32 	[%rd149], %f2;
	bar.sync 	0;
	mul.wide.u32 	%rd150, %r1, 132;
	add.s64 	%rd151, %rd146, %rd150;
	mul.wide.u32 	%rd152, %r2, 4;
	add.s64 	%rd153, %rd151, %rd152;
	ld.shared.f32 	%f105, [%rd153];
	shfl.sync.down.b32	%f106, %f105, 16, 31, -1;
	add.rn.f32 	%f107, %f105, %f106;
	shfl.sync.down.b32	%f108, %f107, 8, 31, -1;
	add.rn.f32 	%f109, %f107, %f108;
	shfl.sync.down.b32	%f110, %f109, 4, 31, -1;
	add.rn.f32 	%f111, %f109, %f110;
	shfl.sync.down.b32	%f112, %f111, 2, 31, -1;
	add.rn.f32 	%f113, %f111, %f112;
	shfl.sync.down.b32	%f114, %f113, 1, 31, -1;
	add.rn.f32 	%f3, %f113, %f114;
	st.shared.f32 	[%rd153], %f3;
	setp.eq.s32 	%p29, %r2, 0;
	@%p29 bra 	$L__BB191_36;
	bra.uni 	$L__BB191_12;
$L__BB191_36:
	or.b32  	%r118, %r1, %r3;
	mul.hi.u32 	%r120, %r118, -1431655765;
	shr.u32 	%r121, %r120, 2;
	mul.lo.s32 	%r122, %r121, 6;
	sub.s32 	%r123, %r118, %r122;
	mul.lo.s64 	%rd154, %rd10, 1536;
	add.s64 	%rd155, %rd2, %rd154;
	mul.wide.u32 	%rd156, %r121, 24;
	add.s64 	%rd157, %rd155, %rd156;
	mul.wide.u32 	%rd158, %r123, 4;
	add.s64 	%rd159, %rd157, %rd158;
	st.global.f32 	[%rd159], %f3;
$L__BB191_12:
	ret;

}
	// .globl	loop_transpose_fusion_113
.visible .entry loop_transpose_fusion_113(
	.param .u64 loop_transpose_fusion_113_param_0,
	.param .u64 loop_transpose_fusion_113_param_1,
	.param .u64 loop_transpose_fusion_113_param_2,
	.param .u64 loop_transpose_fusion_113_param_3,
	.param .u64 loop_transpose_fusion_113_param_4
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<13>;
	.reg .f32 	%f<28>;
	.reg .b64 	%rd<28>;

	ld.param.u64 	%rd1, [loop_transpose_fusion_113_param_0];
	ld.param.u64 	%rd2, [loop_transpose_fusion_113_param_4];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_transpose_fusion_113_param_1];
	ld.param.u64 	%rd5, [loop_transpose_fusion_113_param_3];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_transpose_fusion_113_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	cvta.to.global.u64 	%rd9, %rd4;
	cvta.to.global.u64 	%rd10, %rd1;
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r2, %r1, 2;
	mov.u32 	%r3, %ctaid.x;
	shl.b32 	%r4, %r3, 9;
	or.b32  	%r5, %r4, %r2;
	cvt.u16.u32 	%rs1, %r3;
	shr.u16 	%rs2, %rs1, 4;
	mul.hi.u16 	%rs3, %rs2, 2622;
	mul.hi.u32 	%r6, %r5, 1374389535;
	bfe.u32 	%r7, %r6, 10, 6;
	shr.u32 	%r8, %r5, 6;
	cvt.u16.u32 	%rs4, %r8;
	shr.u16 	%rs5, %rs4, 1;
	mul.hi.u16 	%rs6, %rs5, 5243;
	shr.u16 	%rs7, %rs6, 1;
	mul.lo.s16 	%rs8, %rs7, 50;
	sub.s16 	%rs9, %rs4, %rs8;
	and.b32  	%r9, %r2, 60;
	shl.b16 	%rs10, %rs3, 1;
	mul.wide.u32 	%rd11, %r7, 12;
	add.s64 	%rd12, %rd8, %rd11;
	cvt.u32.u16 	%r10, %rs3;
	mul.wide.u32 	%rd13, %r10, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	mul.wide.u32 	%rd15, %r7, 4;
	add.s64 	%rd16, %rd9, %rd15;
	ld.global.nc.f32 	%f2, [%rd16];
	cvt.u32.u16 	%r11, %rs9;
	mul.wide.u32 	%rd17, %r11, 1536;
	mul.wide.u32 	%rd18, %r7, 76800;
	add.s64 	%rd19, %rd10, %rd18;
	add.s64 	%rd20, %rd19, %rd17;
	mul.wide.u32 	%rd21, %r9, 24;
	add.s64 	%rd22, %rd20, %rd21;
	cvt.u32.u16 	%r12, %rs10;
	mul.wide.u32 	%rd23, %r12, 4;
	add.s64 	%rd24, %rd22, %rd23;
	ld.global.nc.v2.f32 	{%f3, %f4}, [%rd24];
	mul.rn.f32 	%f5, %f2, %f4;
	mul.rn.f32 	%f6, %f1, %f5;
	mul.rn.f32 	%f7, %f2, %f3;
	neg.f32 	%f8, %f1;
	mul.rn.f32 	%f9, %f7, %f8;
	mul.wide.u32 	%rd25, %r5, 4;
	add.s64 	%rd26, %rd6, %rd25;
	add.s64 	%rd27, %rd3, %rd25;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd24+24];
	mul.rn.f32 	%f12, %f2, %f11;
	mul.rn.f32 	%f13, %f1, %f12;
	mul.rn.f32 	%f14, %f2, %f10;
	mul.rn.f32 	%f15, %f14, %f8;
	ld.global.nc.v2.f32 	{%f16, %f17}, [%rd24+48];
	mul.rn.f32 	%f18, %f2, %f17;
	mul.rn.f32 	%f19, %f1, %f18;
	mul.rn.f32 	%f20, %f2, %f16;
	mul.rn.f32 	%f21, %f20, %f8;
	ld.global.nc.v2.f32 	{%f22, %f23}, [%rd24+72];
	mul.rn.f32 	%f24, %f2, %f23;
	mul.rn.f32 	%f25, %f1, %f24;
	mul.rn.f32 	%f26, %f2, %f22;
	mul.rn.f32 	%f27, %f26, %f8;
	st.global.v4.f32 	[%rd26], {%f6, %f13, %f19, %f25};
	st.global.v4.f32 	[%rd27], {%f9, %f15, %f21, %f27};
	ret;

}
	// .globl	loop_broadcast_fusion_42
.visible .entry loop_broadcast_fusion_42(
	.param .u64 loop_broadcast_fusion_42_param_0
)
.reqntid 256, 1, 1
{
	.reg .b32 	%r<6>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [loop_broadcast_fusion_42_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	shl.b32 	%r3, %r2, 10;
	shl.b32 	%r4, %r1, 2;
	or.b32  	%r5, %r3, %r4;
	mul.wide.u32 	%rd3, %r5, 4;
	add.s64 	%rd4, %rd2, %rd3;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd4], {%f1, %f1, %f1, %f1};
	ret;

}
	// .globl	input_scatter_fusion_258
.visible .entry input_scatter_fusion_258(
	.param .u64 input_scatter_fusion_258_param_0,
	.param .u64 input_scatter_fusion_258_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<17>;
	.reg .b32 	%r<10>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_258_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_258_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r2, 63;
	shr.u32 	%r6, %r4, 6;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, 18351;
	sub.s16 	%rs9, %rs7, %rs8;
	shr.u16 	%rs10, %rs9, 1;
	add.s16 	%rs11, %rs10, %rs8;
	shr.u16 	%rs12, %rs11, 4;
	and.b16  	%rs13, %rs12, 63;
	shr.u16 	%rs14, %rs7, 6;
	mul.hi.u16 	%rs15, %rs14, 2622;
	shl.b16 	%rs16, %rs15, 1;
	cvt.u32.u16 	%r7, %rs16;
	mul.wide.u32 	%rd5, %r7, 819200;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r8, %rs13;
	mul.wide.u32 	%rd7, %r8, 12800;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r9, %rs6;
	mul.wide.u32 	%rd9, %r9, 256;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+819200];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+819200], %f3;
	ret;

}
	// .globl	wrapped_transpose_264
.visible .entry wrapped_transpose_264(
	.param .u64 wrapped_transpose_264_param_0,
	.param .u64 wrapped_transpose_264_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<28>;
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<32>;

	ld.param.u64 	%rd1, [wrapped_transpose_264_param_0];
	ld.param.u64 	%rd2, [wrapped_transpose_264_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	mul.hi.u32 	%r6, %r5, 458129845;
	bfe.u32 	%r7, %r6, 11, 6;
	or.b32  	%r8, %r5, 3;
	mul.hi.u32 	%r9, %r5, 715827883;
	shr.u32 	%r10, %r9, 6;
	cvt.u16.u32 	%rs1, %r10;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	mul.hi.u32 	%r11, %r8, 715827883;
	and.b32  	%r12, %r11, 63;
	mul.lo.s32 	%r13, %r11, 6;
	sub.s32 	%r14, %r8, %r13;
	or.b32  	%r15, %r5, 2;
	mul.hi.u32 	%r16, %r15, 715827883;
	and.b32  	%r17, %r16, 63;
	mul.lo.s32 	%r18, %r16, 6;
	sub.s32 	%r19, %r15, %r18;
	or.b32  	%r20, %r5, 1;
	and.b32  	%r21, %r9, 63;
	mul.hi.u32 	%r22, %r20, 715827883;
	mul.lo.s32 	%r23, %r22, 6;
	sub.s32 	%r24, %r20, %r23;
	mul.lo.s32 	%r25, %r9, 6;
	sub.s32 	%r26, %r5, %r25;
	mul.wide.u32 	%rd5, %r26, 819200;
	add.s64 	%rd6, %rd4, %rd5;
	mul.wide.u32 	%rd7, %r7, 12800;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r27, %rs6;
	mul.wide.u32 	%rd9, %r27, 256;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r21, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r5, 4;
	add.s64 	%rd14, %rd3, %rd13;
	mul.wide.u32 	%rd15, %r24, 819200;
	add.s64 	%rd16, %rd4, %rd15;
	add.s64 	%rd17, %rd16, %rd7;
	add.s64 	%rd18, %rd17, %rd9;
	add.s64 	%rd19, %rd18, %rd11;
	ld.global.nc.f32 	%f2, [%rd19];
	mul.wide.u32 	%rd20, %r19, 819200;
	add.s64 	%rd21, %rd4, %rd20;
	add.s64 	%rd22, %rd21, %rd7;
	add.s64 	%rd23, %rd22, %rd9;
	mul.wide.u32 	%rd24, %r17, 4;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.nc.f32 	%f3, [%rd25];
	mul.wide.u32 	%rd26, %r14, 819200;
	add.s64 	%rd27, %rd4, %rd26;
	add.s64 	%rd28, %rd27, %rd7;
	add.s64 	%rd29, %rd28, %rd9;
	mul.wide.u32 	%rd30, %r12, 4;
	add.s64 	%rd31, %rd29, %rd30;
	ld.global.nc.f32 	%f4, [%rd31];
	st.global.v4.f32 	[%rd14], {%f1, %f2, %f3, %f4};
	ret;

}
	// .globl	input_scatter_fusion_259
.visible .entry input_scatter_fusion_259(
	.param .u64 input_scatter_fusion_259_param_0,
	.param .u64 input_scatter_fusion_259_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<17>;
	.reg .b32 	%r<10>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_259_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_259_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r2, 63;
	shr.u32 	%r6, %r4, 6;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, 18351;
	sub.s16 	%rs9, %rs7, %rs8;
	shr.u16 	%rs10, %rs9, 1;
	add.s16 	%rs11, %rs10, %rs8;
	shr.u16 	%rs12, %rs11, 4;
	and.b16  	%rs13, %rs12, 63;
	shr.u16 	%rs14, %rs7, 6;
	mul.hi.u16 	%rs15, %rs14, 2622;
	shl.b16 	%rs16, %rs15, 1;
	cvt.u32.u16 	%r7, %rs16;
	mul.wide.u32 	%rd5, %r7, 819200;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r8, %rs13;
	mul.wide.u32 	%rd7, %r8, 12800;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r9, %rs6;
	mul.wide.u32 	%rd9, %r9, 256;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	input_add_reduce_fusion_43
.visible .entry input_add_reduce_fusion_43(
	.param .u64 input_add_reduce_fusion_43_param_0,
	.param .u64 input_add_reduce_fusion_43_param_1,
	.param .u64 input_add_reduce_fusion_43_param_2,
	.param .u64 input_add_reduce_fusion_43_param_3,
	.param .u64 input_add_reduce_fusion_43_param_4,
	.param .u64 input_add_reduce_fusion_43_param_5,
	.param .u64 input_add_reduce_fusion_43_param_6,
	.param .u64 input_add_reduce_fusion_43_param_7,
	.param .u64 input_add_reduce_fusion_43_param_8,
	.param .u64 input_add_reduce_fusion_43_param_9
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<14>;
	.reg .b16 	%rs<31>;
	.reg .b32 	%r<29>;
	.reg .f32 	%f<74>;
	.reg .b64 	%rd<114>;
	// demoted variable
	.shared .align 4 .b8 shared_cache20[4224];
	ld.param.u64 	%rd33, [input_add_reduce_fusion_43_param_0];
	ld.param.u64 	%rd34, [input_add_reduce_fusion_43_param_9];
	cvta.to.global.u64 	%rd35, %rd34;
	ld.param.u64 	%rd36, [input_add_reduce_fusion_43_param_1];
	ld.param.u64 	%rd37, [input_add_reduce_fusion_43_param_8];
	cvta.to.global.u64 	%rd1, %rd37;
	ld.param.u64 	%rd38, [input_add_reduce_fusion_43_param_2];
	ld.param.u64 	%rd39, [input_add_reduce_fusion_43_param_7];
	cvta.to.global.u64 	%rd40, %rd39;
	ld.param.u64 	%rd41, [input_add_reduce_fusion_43_param_3];
	ld.param.u64 	%rd42, [input_add_reduce_fusion_43_param_6];
	cvta.to.global.u64 	%rd43, %rd42;
	ld.param.u64 	%rd44, [input_add_reduce_fusion_43_param_4];
	ld.param.u64 	%rd45, [input_add_reduce_fusion_43_param_5];
	cvta.to.global.u64 	%rd46, %rd45;
	cvta.to.global.u64 	%rd47, %rd44;
	cvta.to.global.u64 	%rd48, %rd41;
	cvta.to.global.u64 	%rd49, %rd38;
	cvta.to.global.u64 	%rd50, %rd36;
	cvta.to.global.u64 	%rd51, %rd33;
	mov.u32 	%r9, %tid.x;
	mov.u32 	%r10, %ctaid.x;
	shr.u32 	%r1, %r9, 5;
	and.b32  	%r2, %r9, 31;
	cvt.u16.u32 	%rs1, %r10;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 4;
	mul.lo.s16 	%rs4, %rs3, 24;
	sub.s16 	%rs5, %rs1, %rs4;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r3, %rs6;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs7, %r4;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r11, %rs10;
	cvt.u32.u16 	%r12, %rs8;
	cvt.u64.u16 	%rd2, %rs3;
	cvt.u32.u16 	%r13, %rs3;
	mul.wide.u32 	%rd52, %r13, 4;
	add.s64 	%rd53, %rd50, %rd52;
	ld.global.nc.f32 	%f1, [%rd53];
	add.s16 	%rs11, %rs8, -2;
	setp.gt.u32 	%p3, %r4, 11;
	and.b32  	%r5, %r12, 1;
	setp.eq.s32 	%p4, %r5, 0;
	and.pred  	%p1, %p3, %p4;
	shr.u16 	%rs12, %rs11, 15;
	add.s16 	%rs13, %rs11, %rs12;
	shr.s16 	%rs14, %rs13, 1;
	add.s16 	%rs15, %rs14, 1;
	cvt.s64.s16 	%rd54, %rs15;
	and.b64  	%rd55, %rd54, 4294967295;
	add.s32 	%r14, %r12, -1;
	setp.gt.u32 	%p5, %r4, 5;
	and.b32  	%r15, %r14, 1;
	setp.eq.b32 	%p6, %r15, 1;
	not.pred 	%p7, %p6;
	and.pred  	%p2, %p5, %p7;
	cvt.u16.u32 	%rs16, %r14;
	shr.u16 	%rs17, %rs16, 15;
	add.s16 	%rs18, %rs16, %rs17;
	shr.s16 	%rs19, %rs18, 1;
	cvt.s64.s16 	%rd56, %rs19;
	and.b64  	%rd57, %rd56, 4294967295;
	shr.u32 	%r16, %r11, 1;
	mul.wide.u32 	%rd58, %r16, 4;
	mul.wide.u32 	%rd59, %r13, 12;
	add.s64 	%rd60, %rd46, %rd59;
	add.s64 	%rd3, %rd60, %rd58;
	add.s64 	%rd4, %rd47, %rd52;
	add.s32 	%r7, %r1, -32;
	shl.b16 	%rs20, %rs1, 5;
	cvt.u16.u32 	%rs21, %r9;
	and.b16  	%rs22, %rs21, 31;
	or.b16  	%rs23, %rs20, %rs22;
	mul.lo.s16 	%rs24, %rs3, 768;
	sub.s16 	%rs25, %rs23, %rs24;
	mul.hi.u16 	%rs26, %rs25, -21845;
	shr.u16 	%rs27, %rs26, 2;
	mul.lo.s16 	%rs28, %rs27, 6;
	sub.s16 	%rs29, %rs23, %rs28;
	sub.s16 	%rs30, %rs29, %rs24;
	cvt.u32.u16 	%r17, %rs30;
	mul.wide.u32 	%rd5, %r17, 4;
	mul.wide.u32 	%rd61, %r13, 76800;
	cvt.u64.u32 	%rd62, %r9;
	shr.u64 	%rd63, %rd62, 5;
	mul.lo.s64 	%rd64, %rd63, 1536;
	add.s64 	%rd65, %rd61, %rd64;
	cvt.u32.u16 	%r18, %rs25;
	mul.hi.u32 	%r19, %r18, 357913942;
	mul.wide.u32 	%rd66, %r19, 24;
	add.s64 	%rd67, %rd65, %rd66;
	add.s64 	%rd21, %rd48, %rd67;
	add.s64 	%rd20, %rd40, %rd67;
	add.s64 	%rd19, %rd43, %rd67;
	add.s64 	%rd18, %rd49, %rd65;
	mul.wide.u32 	%rd68, %r13, 153600;
	mul.lo.s64 	%rd69, %rd63, 3072;
	add.s64 	%rd70, %rd68, %rd69;
	mul.hi.u32 	%r20, %r18, 715827883;
	mul.wide.u32 	%rd71, %r20, 24;
	add.s64 	%rd72, %rd70, %rd71;
	add.s64 	%rd17, %rd35, %rd72;
	and.b64  	%rd73, %rd5, 262136;
	add.s64 	%rd74, %rd72, %rd73;
	and.b32  	%r21, %r9, 1;
	mul.wide.u32 	%rd75, %r21, 4;
	or.b64  	%rd76, %rd74, %rd75;
	add.s64 	%rd16, %rd51, %rd76;
	mul.lo.s64 	%rd77, %rd57, 24;
	add.s64 	%rd78, %rd65, %rd77;
	add.s64 	%rd15, %rd48, %rd78;
	mul.lo.s64 	%rd79, %rd55, 24;
	add.s64 	%rd80, %rd65, %rd79;
	add.s64 	%rd14, %rd49, %rd80;
	mov.f32 	%f25, 0f00000000;
	setp.lt.u32 	%p9, %r4, 6;
	mov.f32 	%f2, %f25;
	bra.uni 	$L__BB197_1;
$L__BB197_10:
	add.rn.f32 	%f2, %f2, %f42;
	add.rn.f32 	%f13, %f70, %f71;
	add.rn.f32 	%f15, %f13, %f72;
	add.rn.f32 	%f54, %f15, %f73;
	add.s64 	%rd87, %rd17, %rd5;
	st.global.f32 	[%rd87], %f54;
	add.s32 	%r7, %r7, 32;
	add.s64 	%rd21, %rd21, 49152;
	add.s64 	%rd20, %rd20, 49152;
	add.s64 	%rd19, %rd19, 49152;
	add.s64 	%rd18, %rd18, 49152;
	add.s64 	%rd17, %rd17, 98304;
	add.s64 	%rd16, %rd16, 98304;
	add.s64 	%rd15, %rd15, 49152;
	add.s64 	%rd14, %rd14, 49152;
	setp.gt.u32 	%p12, %r7, 17;
	@%p12 bra 	$L__BB197_11;
$L__BB197_1:
	add.s64 	%rd22, %rd14, %rd5;
	mov.f32 	%f66, %f25;
	@%p1 bra 	$L__BB197_2;
	bra.uni 	$L__BB197_3;
$L__BB197_2:
	ld.global.nc.f32 	%f66, [%rd22];
$L__BB197_3:
	add.s64 	%rd23, %rd15, %rd5;
	mov.f32 	%f67, %f25;
	@%p2 bra 	$L__BB197_13;
	bra.uni 	$L__BB197_4;
$L__BB197_13:
	ld.global.nc.f32 	%f67, [%rd23];
$L__BB197_4:
	add.s64 	%rd103, %rd19, %rd5;
	add.s64 	%rd104, %rd20, %rd5;
	add.s64 	%rd105, %rd21, %rd5;
	mov.f32 	%f68, %f25;
	@%p4 bra 	$L__BB197_14;
	bra.uni 	$L__BB197_5;
$L__BB197_14:
	ld.global.nc.f32 	%f29, [%rd103];
	ld.global.nc.f32 	%f30, [%rd104];
	add.rn.f32 	%f31, %f29, %f30;
	ld.global.nc.f32 	%f32, [%rd3];
	ld.global.nc.f32 	%f33, [%rd4];
	ld.global.nc.f32 	%f34, [%rd105];
	mul.rn.f32 	%f35, %f33, %f34;
	mul.rn.f32 	%f36, %f32, %f35;
	add.rn.f32 	%f68, %f31, %f36;
$L__BB197_5:
	add.s64 	%rd24, %rd18, %rd5;
	mov.f32 	%f69, %f25;
	@%p9 bra 	$L__BB197_15;
	bra.uni 	$L__BB197_6;
$L__BB197_15:
	ld.global.nc.f32 	%f69, [%rd24];
$L__BB197_6:
	add.rn.f32 	%f6, %f66, %f67;
	add.rn.f32 	%f8, %f6, %f68;
	ld.global.nc.f32 	%f41, [%rd16];
	mov.f32 	%f70, %f25;
	@%p1 bra 	$L__BB197_16;
	bra.uni 	$L__BB197_7;
$L__BB197_16:
	ld.global.nc.f32 	%f70, [%rd22];
$L__BB197_7:
	add.rn.f32 	%f39, %f8, %f69;
	mov.f32 	%f71, %f25;
	@%p2 bra 	$L__BB197_17;
	bra.uni 	$L__BB197_8;
$L__BB197_17:
	ld.global.nc.f32 	%f71, [%rd23];
$L__BB197_8:
	mul.rn.f32 	%f40, %f1, %f39;
	mov.f32 	%f72, %f25;
	@%p4 bra 	$L__BB197_18;
	bra.uni 	$L__BB197_9;
$L__BB197_18:
	ld.global.nc.f32 	%f45, [%rd103];
	ld.global.nc.f32 	%f46, [%rd104];
	add.rn.f32 	%f47, %f45, %f46;
	ld.global.nc.f32 	%f48, [%rd3];
	ld.global.nc.f32 	%f49, [%rd4];
	ld.global.nc.f32 	%f50, [%rd105];
	mul.rn.f32 	%f51, %f49, %f50;
	mul.rn.f32 	%f52, %f48, %f51;
	add.rn.f32 	%f72, %f47, %f52;
$L__BB197_9:
	mul.rn.f32 	%f42, %f41, %f40;
	mov.f32 	%f73, %f25;
	@%p9 bra 	$L__BB197_19;
	bra.uni 	$L__BB197_10;
$L__BB197_19:
	ld.global.nc.f32 	%f73, [%rd24];
	bra.uni 	$L__BB197_10;
$L__BB197_11:
	mul.wide.u32 	%rd88, %r2, 132;
	mov.u64 	%rd89, shared_cache20;
	add.s64 	%rd90, %rd89, %rd88;
	mul.wide.u32 	%rd91, %r1, 4;
	add.s64 	%rd92, %rd90, %rd91;
	st.shared.f32 	[%rd92], %f2;
	bar.sync 	0;
	mul.wide.u32 	%rd93, %r1, 132;
	add.s64 	%rd94, %rd89, %rd93;
	mul.wide.u32 	%rd95, %r2, 4;
	add.s64 	%rd96, %rd94, %rd95;
	ld.shared.f32 	%f55, [%rd96];
	shfl.sync.down.b32	%f56, %f55, 16, 31, -1;
	add.rn.f32 	%f57, %f55, %f56;
	shfl.sync.down.b32	%f58, %f57, 8, 31, -1;
	add.rn.f32 	%f59, %f57, %f58;
	shfl.sync.down.b32	%f60, %f59, 4, 31, -1;
	add.rn.f32 	%f61, %f59, %f60;
	shfl.sync.down.b32	%f62, %f61, 2, 31, -1;
	add.rn.f32 	%f63, %f61, %f62;
	shfl.sync.down.b32	%f64, %f63, 1, 31, -1;
	add.rn.f32 	%f3, %f63, %f64;
	st.shared.f32 	[%rd96], %f3;
	setp.eq.s32 	%p13, %r2, 0;
	@%p13 bra 	$L__BB197_20;
	bra.uni 	$L__BB197_12;
$L__BB197_20:
	or.b32  	%r22, %r1, %r3;
	mul.hi.u32 	%r24, %r22, -1431655765;
	shr.u32 	%r25, %r24, 2;
	mul.lo.s32 	%r26, %r25, 6;
	sub.s32 	%r27, %r22, %r26;
	mul.lo.s64 	%rd97, %rd2, 3072;
	add.s64 	%rd98, %rd1, %rd97;
	mul.wide.u32 	%rd99, %r25, 24;
	add.s64 	%rd100, %rd98, %rd99;
	mul.wide.u32 	%rd101, %r27, 4;
	add.s64 	%rd102, %rd100, %rd101;
	st.global.f32 	[%rd102], %f3;
$L__BB197_12:
	ret;

}
	// .globl	loop_transpose_fusion_114
.visible .entry loop_transpose_fusion_114(
	.param .u64 loop_transpose_fusion_114_param_0,
	.param .u64 loop_transpose_fusion_114_param_1,
	.param .u64 loop_transpose_fusion_114_param_2,
	.param .u64 loop_transpose_fusion_114_param_3,
	.param .u64 loop_transpose_fusion_114_param_4
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<13>;
	.reg .f32 	%f<28>;
	.reg .b64 	%rd<28>;

	ld.param.u64 	%rd1, [loop_transpose_fusion_114_param_0];
	ld.param.u64 	%rd2, [loop_transpose_fusion_114_param_4];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_transpose_fusion_114_param_1];
	ld.param.u64 	%rd5, [loop_transpose_fusion_114_param_3];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_transpose_fusion_114_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	cvta.to.global.u64 	%rd9, %rd4;
	cvta.to.global.u64 	%rd10, %rd1;
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r2, %r1, 2;
	mov.u32 	%r3, %ctaid.x;
	shl.b32 	%r4, %r3, 9;
	or.b32  	%r5, %r4, %r2;
	cvt.u16.u32 	%rs1, %r3;
	shr.u16 	%rs2, %rs1, 5;
	mul.hi.u16 	%rs3, %rs2, 2622;
	mul.hi.u32 	%r6, %r5, 1374389535;
	bfe.u32 	%r7, %r6, 11, 6;
	shr.u32 	%r8, %r5, 7;
	cvt.u16.u32 	%rs4, %r8;
	shr.u16 	%rs5, %rs4, 1;
	mul.hi.u16 	%rs6, %rs5, 5243;
	shr.u16 	%rs7, %rs6, 1;
	mul.lo.s16 	%rs8, %rs7, 50;
	sub.s16 	%rs9, %rs4, %rs8;
	and.b32  	%r9, %r2, 124;
	shl.b16 	%rs10, %rs3, 1;
	mul.wide.u32 	%rd11, %r7, 12;
	add.s64 	%rd12, %rd8, %rd11;
	cvt.u32.u16 	%r10, %rs3;
	mul.wide.u32 	%rd13, %r10, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	mul.wide.u32 	%rd15, %r7, 4;
	add.s64 	%rd16, %rd9, %rd15;
	ld.global.nc.f32 	%f2, [%rd16];
	cvt.u32.u16 	%r11, %rs9;
	mul.wide.u32 	%rd17, %r11, 3072;
	mul.wide.u32 	%rd18, %r7, 153600;
	add.s64 	%rd19, %rd10, %rd18;
	add.s64 	%rd20, %rd19, %rd17;
	mul.wide.u32 	%rd21, %r9, 24;
	add.s64 	%rd22, %rd20, %rd21;
	cvt.u32.u16 	%r12, %rs10;
	mul.wide.u32 	%rd23, %r12, 4;
	add.s64 	%rd24, %rd22, %rd23;
	ld.global.nc.v2.f32 	{%f3, %f4}, [%rd24];
	mul.rn.f32 	%f5, %f2, %f4;
	mul.rn.f32 	%f6, %f1, %f5;
	mul.rn.f32 	%f7, %f2, %f3;
	neg.f32 	%f8, %f1;
	mul.rn.f32 	%f9, %f7, %f8;
	mul.wide.u32 	%rd25, %r5, 4;
	add.s64 	%rd26, %rd6, %rd25;
	add.s64 	%rd27, %rd3, %rd25;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd24+24];
	mul.rn.f32 	%f12, %f2, %f11;
	mul.rn.f32 	%f13, %f1, %f12;
	mul.rn.f32 	%f14, %f2, %f10;
	mul.rn.f32 	%f15, %f14, %f8;
	ld.global.nc.v2.f32 	{%f16, %f17}, [%rd24+48];
	mul.rn.f32 	%f18, %f2, %f17;
	mul.rn.f32 	%f19, %f1, %f18;
	mul.rn.f32 	%f20, %f2, %f16;
	mul.rn.f32 	%f21, %f20, %f8;
	ld.global.nc.v2.f32 	{%f22, %f23}, [%rd24+72];
	mul.rn.f32 	%f24, %f2, %f23;
	mul.rn.f32 	%f25, %f1, %f24;
	mul.rn.f32 	%f26, %f2, %f22;
	mul.rn.f32 	%f27, %f26, %f8;
	st.global.v4.f32 	[%rd26], {%f6, %f13, %f19, %f25};
	st.global.v4.f32 	[%rd27], {%f9, %f15, %f21, %f27};
	ret;

}
	// .globl	loop_broadcast_fusion_43
.visible .entry loop_broadcast_fusion_43(
	.param .u64 loop_broadcast_fusion_43_param_0
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd2, [loop_broadcast_fusion_43_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 9;
	shl.b32 	%r4, %r2, 2;
	or.b32  	%r5, %r3, %r4;
	mul.wide.u32 	%rd4, %r5, 4;
	add.s64 	%rd1, %rd3, %rd4;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd1], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+3538944], {%f1, %f1, %f1, %f1};
	setp.gt.u32 	%p1, %r5, 688127;
	@%p1 bra 	$L__BB199_2;
	st.global.v4.f32 	[%rd1+7077888], {%f1, %f1, %f1, %f1};
$L__BB199_2:
	ret;

}
	// .globl	input_scatter_fusion_260
.visible .entry input_scatter_fusion_260(
	.param .u64 input_scatter_fusion_260_param_0,
	.param .u64 input_scatter_fusion_260_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_260_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_260_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r1;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	and.b16  	%rs7, %rs4, 63;
	shr.u16 	%rs8, %rs1, 7;
	mul.hi.u16 	%rs9, %rs8, 2622;
	shl.b16 	%rs10, %rs9, 1;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd5, %r5, 1638400;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r6, %rs7;
	mul.wide.u32 	%rd7, %r6, 25600;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r7, %rs6;
	mul.wide.u32 	%rd9, %r7, 512;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r2, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+1638400];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+1638400], %f3;
	ret;

}
	// .globl	wrapped_transpose_266
.visible .entry wrapped_transpose_266(
	.param .u64 wrapped_transpose_266_param_0,
	.param .u64 wrapped_transpose_266_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<27>;
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<32>;

	ld.param.u64 	%rd1, [wrapped_transpose_266_param_0];
	ld.param.u64 	%rd2, [wrapped_transpose_266_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	cvt.u16.u32 	%rs1, %r1;
	mul.hi.u16 	%rs2, %rs1, -19223;
	sub.s16 	%rs3, %rs1, %rs2;
	shr.u16 	%rs4, %rs3, 1;
	add.s16 	%rs5, %rs4, %rs2;
	shr.u16 	%rs6, %rs5, 6;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	or.b32  	%r6, %r5, 3;
	mul.hi.u32 	%r7, %r5, 715827883;
	shr.u32 	%r8, %r7, 7;
	cvt.u16.u32 	%rs7, %r8;
	shr.u16 	%rs8, %rs7, 1;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	mul.lo.s16 	%rs11, %rs10, 50;
	sub.s16 	%rs12, %rs7, %rs11;
	mul.hi.u32 	%r9, %r6, 715827883;
	and.b32  	%r10, %r9, 127;
	mul.lo.s32 	%r11, %r9, 6;
	sub.s32 	%r12, %r6, %r11;
	or.b32  	%r13, %r5, 2;
	mul.hi.u32 	%r14, %r13, 715827883;
	and.b32  	%r15, %r14, 127;
	mul.lo.s32 	%r16, %r14, 6;
	sub.s32 	%r17, %r13, %r16;
	or.b32  	%r18, %r5, 1;
	and.b32  	%r19, %r7, 127;
	mul.hi.u32 	%r20, %r18, 715827883;
	mul.lo.s32 	%r21, %r20, 6;
	sub.s32 	%r22, %r18, %r21;
	mul.lo.s32 	%r23, %r7, 6;
	sub.s32 	%r24, %r5, %r23;
	mul.wide.u32 	%rd5, %r24, 1638400;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r25, %rs6;
	mul.wide.u32 	%rd7, %r25, 25600;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r26, %rs12;
	mul.wide.u32 	%rd9, %r26, 512;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r19, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r5, 4;
	add.s64 	%rd14, %rd3, %rd13;
	mul.wide.u32 	%rd15, %r22, 1638400;
	add.s64 	%rd16, %rd4, %rd15;
	add.s64 	%rd17, %rd16, %rd7;
	add.s64 	%rd18, %rd17, %rd9;
	add.s64 	%rd19, %rd18, %rd11;
	ld.global.nc.f32 	%f2, [%rd19];
	mul.wide.u32 	%rd20, %r17, 1638400;
	add.s64 	%rd21, %rd4, %rd20;
	add.s64 	%rd22, %rd21, %rd7;
	add.s64 	%rd23, %rd22, %rd9;
	mul.wide.u32 	%rd24, %r15, 4;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.nc.f32 	%f3, [%rd25];
	mul.wide.u32 	%rd26, %r12, 1638400;
	add.s64 	%rd27, %rd4, %rd26;
	add.s64 	%rd28, %rd27, %rd7;
	add.s64 	%rd29, %rd28, %rd9;
	mul.wide.u32 	%rd30, %r10, 4;
	add.s64 	%rd31, %rd29, %rd30;
	ld.global.nc.f32 	%f4, [%rd31];
	st.global.v4.f32 	[%rd14], {%f1, %f2, %f3, %f4};
	ret;

}
	// .globl	input_scatter_fusion_261
.visible .entry input_scatter_fusion_261(
	.param .u64 input_scatter_fusion_261_param_0,
	.param .u64 input_scatter_fusion_261_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_261_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_261_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r1;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	and.b16  	%rs7, %rs4, 63;
	shr.u16 	%rs8, %rs1, 7;
	mul.hi.u16 	%rs9, %rs8, 2622;
	shl.b16 	%rs10, %rs9, 1;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd5, %r5, 1638400;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r6, %rs7;
	mul.wide.u32 	%rd7, %r6, 25600;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r7, %rs6;
	mul.wide.u32 	%rd9, %r7, 512;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r2, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	loop_add_fusion_373
.visible .entry loop_add_fusion_373(
	.param .u64 loop_add_fusion_373_param_0,
	.param .u64 loop_add_fusion_373_param_1,
	.param .u64 loop_add_fusion_373_param_2,
	.param .u64 loop_add_fusion_373_param_3,
	.param .u64 loop_add_fusion_373_param_4,
	.param .u64 loop_add_fusion_373_param_5,
	.param .u64 loop_add_fusion_373_param_6,
	.param .u64 loop_add_fusion_373_param_7,
	.param .u64 loop_add_fusion_373_param_8,
	.param .u64 loop_add_fusion_373_param_9,
	.param .u64 loop_add_fusion_373_param_10,
	.param .u64 loop_add_fusion_373_param_11,
	.param .u64 loop_add_fusion_373_param_12,
	.param .u64 loop_add_fusion_373_param_13,
	.param .u64 loop_add_fusion_373_param_14,
	.param .u64 loop_add_fusion_373_param_15,
	.param .u64 loop_add_fusion_373_param_16
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<65>;
	.reg .f32 	%f<190>;
	.reg .b64 	%rd<357>;

	ld.param.u64 	%rd42, [loop_add_fusion_373_param_0];
	ld.param.u64 	%rd44, [loop_add_fusion_373_param_1];
	cvta.to.global.u64 	%rd16, %rd44;
	cvta.to.global.u64 	%rd17, %rd42;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	shl.b32 	%r19, %r17, 9;
	shl.b32 	%r20, %r18, 2;
	or.b32  	%r1, %r19, %r20;
	mul.hi.u32 	%r2, %r1, 715827883;
	mul.lo.s32 	%r21, %r2, 6;
	sub.s32 	%r3, %r1, %r21;
	and.b32  	%r4, %r2, 255;
	cvt.u16.u32 	%rs3, %r17;
	mul.hi.u16 	%rs4, %rs3, -21845;
	shr.u16 	%rs5, %rs4, 1;
	mul.hi.u16 	%rs6, %rs5, 5243;
	shr.u16 	%rs7, %rs6, 2;
	mul.lo.s16 	%rs8, %rs7, 50;
	sub.s16 	%rs1, %rs5, %rs8;
	cvt.u32.u16 	%r5, %rs1;
	shr.u16 	%rs9, %rs3, 1;
	mul.hi.u16 	%rs10, %rs9, -9611;
	shr.u16 	%rs2, %rs10, 6;
	setp.gt.u32 	%p2, %r4, 1;
	and.b32  	%r13, %r2, 1;
	setp.eq.s32 	%p3, %r13, 0;
	and.pred  	%p1, %p2, %p3;
	mov.f32 	%f177, 0f00000000;
	cvt.u64.u32 	%rd353, %r3;
	cvt.u64.u16 	%rd352, %rs1;
	cvt.u64.u16 	%rd351, %rs2;
	add.s32 	%r64, %r2, 254;
	@%p1 bra 	$L__BB203_21;
	bra.uni 	$L__BB203_1;
$L__BB203_21:
	bfe.u32 	%r30, %r64, 1, 7;
	cvt.u32.u16 	%r31, %rs2;
	mul.wide.u32 	%rd59, %r31, 152400;
	add.s64 	%rd60, %rd16, %rd59;
	mul.wide.u32 	%rd61, %r5, 3048;
	add.s64 	%rd62, %rd60, %rd61;
	mul.wide.u32 	%rd63, %r30, 24;
	add.s64 	%rd64, %rd62, %rd63;
	mul.wide.u32 	%rd65, %r3, 4;
	add.s64 	%rd66, %rd64, %rd65;
	ld.global.nc.f32 	%f174, [%rd66];
	bra.uni 	$L__BB203_2;
$L__BB203_1:
	mov.f32 	%f174, %f177;
$L__BB203_2:
	or.b32  	%r22, %r1, 1;
	ld.param.u64 	%rd46, [loop_add_fusion_373_param_2];
	ld.param.u64 	%rd48, [loop_add_fusion_373_param_3];
	ld.param.u64 	%rd50, [loop_add_fusion_373_param_4];
	ld.param.u64 	%rd52, [loop_add_fusion_373_param_5];
	add.s32 	%r33, %r4, -1;
	and.b32  	%r14, %r33, 1;
	setp.eq.s32 	%p4, %r14, 0;
	shr.u32 	%r34, %r33, 1;
	mul.lo.s64 	%rd67, %rd351, 153600;
	add.s64 	%rd68, %rd17, %rd67;
	mul.lo.s64 	%rd69, %rd352, 3072;
	add.s64 	%rd70, %rd68, %rd69;
	shl.b64 	%rd73, %rd353, 2;
	mov.f32 	%f175, %f177;
	@%p4 bra 	$L__BB203_22;
	bra.uni 	$L__BB203_3;
$L__BB203_22:
	mul.wide.u32 	%rd71, %r34, 24;
	add.s64 	%rd72, %rd70, %rd71;
	add.s64 	%rd25, %rd72, %rd73;
	ld.global.nc.f32 	%f175, [%rd25];
$L__BB203_3:
	mul.hi.u32 	%r23, %r22, 715827883;
	ld.param.u64 	%rd43, [loop_add_fusion_373_param_16];
	ld.param.u64 	%rd45, [loop_add_fusion_373_param_15];
	ld.param.u64 	%rd47, [loop_add_fusion_373_param_14];
	ld.param.u64 	%rd49, [loop_add_fusion_373_param_13];
	ld.param.u64 	%rd51, [loop_add_fusion_373_param_12];
	ld.param.u64 	%rd53, [loop_add_fusion_373_param_11];
	ld.param.u64 	%rd54, [loop_add_fusion_373_param_6];
	ld.param.u64 	%rd55, [loop_add_fusion_373_param_10];
	ld.param.u64 	%rd56, [loop_add_fusion_373_param_7];
	ld.param.u64 	%rd57, [loop_add_fusion_373_param_9];
	ld.param.u64 	%rd58, [loop_add_fusion_373_param_8];
	cvta.to.global.u64 	%rd12, %rd52;
	cvta.to.global.u64 	%rd13, %rd50;
	cvta.to.global.u64 	%rd14, %rd48;
	cvta.to.global.u64 	%rd15, %rd46;
	add.rn.f32 	%f3, %f174, %f175;
	shr.u32 	%r63, %r4, 1;
	mov.f32 	%f176, %f177;
	@%p3 bra 	$L__BB203_23;
	bra.uni 	$L__BB203_4;
$L__BB203_23:
	add.s64 	%rd75, %rd14, %rd67;
	add.s64 	%rd77, %rd75, %rd69;
	mul.wide.u32 	%rd78, %r63, 24;
	add.s64 	%rd79, %rd77, %rd78;
	add.s64 	%rd81, %rd79, %rd73;
	ld.global.nc.f32 	%f42, [%rd81];
	add.s64 	%rd82, %rd13, %rd67;
	add.s64 	%rd83, %rd82, %rd69;
	add.s64 	%rd84, %rd83, %rd78;
	add.s64 	%rd85, %rd84, %rd73;
	ld.global.nc.f32 	%f43, [%rd85];
	add.rn.f32 	%f44, %f42, %f43;
	shr.u32 	%r36, %r3, 1;
	mul.lo.s64 	%rd86, %rd351, 12;
	add.s64 	%rd87, %rd12, %rd86;
	mul.wide.u32 	%rd88, %r36, 4;
	add.s64 	%rd89, %rd87, %rd88;
	ld.global.nc.f32 	%f45, [%rd89];
	shl.b64 	%rd90, %rd351, 2;
	add.s64 	%rd91, %rd15, %rd90;
	ld.global.nc.f32 	%f46, [%rd91];
	add.s64 	%rd94, %rd70, %rd78;
	add.s64 	%rd95, %rd94, %rd73;
	ld.global.nc.f32 	%f47, [%rd95];
	mul.rn.f32 	%f48, %f46, %f47;
	mul.rn.f32 	%f49, %f45, %f48;
	add.rn.f32 	%f176, %f44, %f49;
$L__BB203_4:
	mul.lo.s32 	%r24, %r23, 6;
	cvta.to.global.u64 	%rd1, %rd43;
	cvta.to.global.u64 	%rd2, %rd45;
	cvta.to.global.u64 	%rd3, %rd47;
	cvta.to.global.u64 	%rd4, %rd49;
	cvta.to.global.u64 	%rd5, %rd51;
	cvta.to.global.u64 	%rd6, %rd53;
	cvta.to.global.u64 	%rd7, %rd55;
	cvta.to.global.u64 	%rd8, %rd57;
	cvta.to.global.u64 	%rd9, %rd58;
	cvta.to.global.u64 	%rd10, %rd56;
	cvta.to.global.u64 	%rd11, %rd54;
	add.rn.f32 	%f5, %f3, %f176;
	setp.eq.s32 	%p6, %r4, 0;
	@%p6 bra 	$L__BB203_24;
	bra.uni 	$L__BB203_5;
$L__BB203_24:
	shl.b32 	%r37, %r5, 10;
	mul.lo.s64 	%rd96, %rd351, 1228800;
	add.s64 	%rd97, %rd6, %rd96;
	mul.wide.u32 	%rd98, %r37, 24;
	add.s64 	%rd99, %rd97, %rd98;
	add.s64 	%rd101, %rd99, %rd73;
	ld.global.nc.f32 	%f51, [%rd101+72];
	mul.lo.s64 	%rd102, %rd351, 613200;
	add.s64 	%rd103, %rd3, %rd102;
	mul.lo.s64 	%rd104, %rd352, 12264;
	add.s64 	%rd105, %rd103, %rd104;
	add.s64 	%rd106, %rd105, %rd73;
	ld.global.nc.f32 	%f52, [%rd106+24];
	add.s64 	%rd107, %rd2, %rd102;
	add.s64 	%rd108, %rd107, %rd104;
	add.s64 	%rd109, %rd108, %rd73;
	ld.global.nc.f32 	%f53, [%rd109+24];
	add.rn.f32 	%f54, %f52, %f53;
	shr.u32 	%r38, %r3, 1;
	mul.lo.s64 	%rd110, %rd351, 12;
	add.s64 	%rd111, %rd4, %rd110;
	mul.wide.u32 	%rd112, %r38, 4;
	add.s64 	%rd113, %rd111, %rd112;
	ld.global.nc.f32 	%f55, [%rd113];
	shl.b64 	%rd114, %rd351, 2;
	add.s64 	%rd115, %rd5, %rd114;
	ld.global.nc.f32 	%f56, [%rd115];
	ld.global.nc.f32 	%f57, [%rd101+96];
	mul.rn.f32 	%f58, %f56, %f57;
	mul.rn.f32 	%f59, %f55, %f58;
	add.rn.f32 	%f60, %f54, %f59;
	add.rn.f32 	%f61, %f51, %f60;
	mul.lo.s64 	%rd116, %rd351, 306000;
	add.s64 	%rd117, %rd8, %rd116;
	mul.lo.s64 	%rd118, %rd352, 6120;
	add.s64 	%rd119, %rd117, %rd118;
	add.s64 	%rd120, %rd119, %rd73;
	ld.global.nc.f32 	%f62, [%rd120];
	add.s64 	%rd121, %rd7, %rd116;
	add.s64 	%rd122, %rd121, %rd118;
	add.s64 	%rd123, %rd122, %rd73;
	ld.global.nc.f32 	%f63, [%rd123];
	add.rn.f32 	%f64, %f62, %f63;
	add.s64 	%rd124, %rd9, %rd110;
	add.s64 	%rd125, %rd124, %rd112;
	ld.global.nc.f32 	%f65, [%rd125];
	add.s64 	%rd126, %rd10, %rd114;
	ld.global.nc.f32 	%f66, [%rd126];
	add.s64 	%rd127, %rd11, %rd116;
	add.s64 	%rd128, %rd127, %rd118;
	add.s64 	%rd129, %rd128, %rd73;
	ld.global.nc.f32 	%f67, [%rd129];
	mul.rn.f32 	%f68, %f66, %f67;
	mul.rn.f32 	%f69, %f65, %f68;
	add.rn.f32 	%f70, %f64, %f69;
	add.rn.f32 	%f177, %f61, %f70;
$L__BB203_5:
	sub.s32 	%r6, %r22, %r24;
	add.rn.f32 	%f71, %f5, %f177;
	mul.wide.u32 	%rd130, %r1, 4;
	add.s64 	%rd26, %rd1, %rd130;
	st.global.f32 	[%rd26], %f71;
	mul.lo.s64 	%rd346, %rd351, 152400;
	mul.lo.s64 	%rd347, %rd352, 3048;
	cvt.u64.u32 	%rd354, %r6;
	@%p1 bra 	$L__BB203_25;
	bra.uni 	$L__BB203_6;
$L__BB203_25:
	bfe.u32 	%r40, %r64, 1, 7;
	add.s64 	%rd132, %rd16, %rd346;
	add.s64 	%rd134, %rd132, %rd347;
	mul.wide.u32 	%rd135, %r40, 24;
	add.s64 	%rd136, %rd134, %rd135;
	mul.wide.u32 	%rd137, %r6, 4;
	add.s64 	%rd138, %rd136, %rd137;
	ld.global.nc.f32 	%f178, [%rd138];
	bra.uni 	$L__BB203_7;
$L__BB203_6:
	mov.f32 	%f178, 0f00000000;
$L__BB203_7:
	or.b32  	%r25, %r1, 2;
	shl.b64 	%rd145, %rd354, 2;
	mov.f32 	%f181, 0f00000000;
	mov.f32 	%f179, %f181;
	@%p4 bra 	$L__BB203_26;
	bra.uni 	$L__BB203_8;
$L__BB203_26:
	cvt.u64.u32 	%rd24, %r34;
	mul.lo.s64 	%rd143, %rd24, 24;
	add.s64 	%rd144, %rd70, %rd143;
	add.s64 	%rd29, %rd144, %rd145;
	ld.global.nc.f32 	%f179, [%rd29];
$L__BB203_8:
	mul.hi.u32 	%r7, %r25, 715827883;
	add.rn.f32 	%f9, %f178, %f179;
	mov.f32 	%f180, %f181;
	@%p3 bra 	$L__BB203_27;
	bra.uni 	$L__BB203_9;
$L__BB203_27:
	add.s64 	%rd147, %rd14, %rd67;
	add.s64 	%rd149, %rd147, %rd69;
	mul.wide.u32 	%rd150, %r63, 24;
	add.s64 	%rd151, %rd149, %rd150;
	add.s64 	%rd153, %rd151, %rd145;
	ld.global.nc.f32 	%f75, [%rd153];
	add.s64 	%rd154, %rd13, %rd67;
	add.s64 	%rd155, %rd154, %rd69;
	add.s64 	%rd156, %rd155, %rd150;
	add.s64 	%rd157, %rd156, %rd145;
	ld.global.nc.f32 	%f76, [%rd157];
	add.rn.f32 	%f77, %f75, %f76;
	shr.u32 	%r42, %r6, 1;
	mul.lo.s64 	%rd158, %rd351, 12;
	add.s64 	%rd159, %rd12, %rd158;
	mul.wide.u32 	%rd160, %r42, 4;
	add.s64 	%rd161, %rd159, %rd160;
	ld.global.nc.f32 	%f78, [%rd161];
	shl.b64 	%rd162, %rd351, 2;
	add.s64 	%rd163, %rd15, %rd162;
	ld.global.nc.f32 	%f79, [%rd163];
	add.s64 	%rd166, %rd70, %rd150;
	add.s64 	%rd167, %rd166, %rd145;
	ld.global.nc.f32 	%f80, [%rd167];
	mul.rn.f32 	%f81, %f79, %f80;
	mul.rn.f32 	%f82, %f78, %f81;
	add.rn.f32 	%f180, %f77, %f82;
$L__BB203_9:
	mul.lo.s32 	%r26, %r7, 6;
	and.b32  	%r9, %r7, 255;
	add.rn.f32 	%f11, %f9, %f180;
	@%p6 bra 	$L__BB203_28;
	bra.uni 	$L__BB203_10;
$L__BB203_28:
	shl.b32 	%r43, %r5, 10;
	mul.lo.s64 	%rd168, %rd351, 1228800;
	add.s64 	%rd169, %rd6, %rd168;
	mul.wide.u32 	%rd170, %r43, 24;
	add.s64 	%rd171, %rd169, %rd170;
	add.s64 	%rd173, %rd171, %rd145;
	ld.global.nc.f32 	%f84, [%rd173+72];
	mul.lo.s64 	%rd174, %rd351, 613200;
	add.s64 	%rd175, %rd3, %rd174;
	mul.lo.s64 	%rd176, %rd352, 12264;
	add.s64 	%rd177, %rd175, %rd176;
	add.s64 	%rd178, %rd177, %rd145;
	ld.global.nc.f32 	%f85, [%rd178+24];
	add.s64 	%rd179, %rd2, %rd174;
	add.s64 	%rd180, %rd179, %rd176;
	add.s64 	%rd181, %rd180, %rd145;
	ld.global.nc.f32 	%f86, [%rd181+24];
	add.rn.f32 	%f87, %f85, %f86;
	shr.u32 	%r44, %r6, 1;
	mul.lo.s64 	%rd182, %rd351, 12;
	add.s64 	%rd183, %rd4, %rd182;
	mul.wide.u32 	%rd184, %r44, 4;
	add.s64 	%rd185, %rd183, %rd184;
	ld.global.nc.f32 	%f88, [%rd185];
	shl.b64 	%rd186, %rd351, 2;
	add.s64 	%rd187, %rd5, %rd186;
	ld.global.nc.f32 	%f89, [%rd187];
	ld.global.nc.f32 	%f90, [%rd173+96];
	mul.rn.f32 	%f91, %f89, %f90;
	mul.rn.f32 	%f92, %f88, %f91;
	add.rn.f32 	%f93, %f87, %f92;
	add.rn.f32 	%f94, %f84, %f93;
	mul.lo.s64 	%rd188, %rd351, 306000;
	add.s64 	%rd189, %rd8, %rd188;
	mul.lo.s64 	%rd190, %rd352, 6120;
	add.s64 	%rd191, %rd189, %rd190;
	add.s64 	%rd192, %rd191, %rd145;
	ld.global.nc.f32 	%f95, [%rd192];
	add.s64 	%rd193, %rd7, %rd188;
	add.s64 	%rd194, %rd193, %rd190;
	add.s64 	%rd195, %rd194, %rd145;
	ld.global.nc.f32 	%f96, [%rd195];
	add.rn.f32 	%f97, %f95, %f96;
	add.s64 	%rd196, %rd9, %rd182;
	add.s64 	%rd197, %rd196, %rd184;
	ld.global.nc.f32 	%f98, [%rd197];
	add.s64 	%rd198, %rd10, %rd186;
	ld.global.nc.f32 	%f99, [%rd198];
	add.s64 	%rd199, %rd11, %rd188;
	add.s64 	%rd200, %rd199, %rd190;
	add.s64 	%rd201, %rd200, %rd145;
	ld.global.nc.f32 	%f100, [%rd201];
	mul.rn.f32 	%f101, %f99, %f100;
	mul.rn.f32 	%f102, %f98, %f101;
	add.rn.f32 	%f103, %f97, %f102;
	add.rn.f32 	%f181, %f94, %f103;
$L__BB203_10:
	sub.s32 	%r8, %r25, %r26;
	add.rn.f32 	%f104, %f11, %f181;
	st.global.f32 	[%rd26+4], %f104;
	setp.gt.u32 	%p10, %r9, 1;
	and.b32  	%r15, %r7, 1;
	setp.eq.s32 	%p11, %r15, 0;
	cvt.u64.u32 	%rd355, %r8;
	and.pred  	%p12, %p10, %p11;
	@%p12 bra 	$L__BB203_29;
	bra.uni 	$L__BB203_11;
$L__BB203_29:
	add.s32 	%r45, %r7, 254;
	bfe.u32 	%r46, %r45, 1, 7;
	add.s64 	%rd203, %rd16, %rd346;
	add.s64 	%rd205, %rd203, %rd347;
	mul.wide.u32 	%rd206, %r46, 24;
	add.s64 	%rd207, %rd205, %rd206;
	mul.wide.u32 	%rd208, %r8, 4;
	add.s64 	%rd209, %rd207, %rd208;
	ld.global.nc.f32 	%f182, [%rd209];
	bra.uni 	$L__BB203_12;
$L__BB203_11:
	mov.f32 	%f182, 0f00000000;
$L__BB203_12:
	or.b32  	%r27, %r1, 3;
	add.s32 	%r47, %r9, -1;
	and.b32  	%r48, %r47, 1;
	setp.eq.b32 	%p13, %r48, 1;
	mov.pred 	%p14, 0;
	xor.pred  	%p15, %p13, %p14;
	not.pred 	%p16, %p15;
	shl.b64 	%rd216, %rd355, 2;
	mov.f32 	%f185, 0f00000000;
	mov.f32 	%f183, %f185;
	@%p16 bra 	$L__BB203_30;
	bra.uni 	$L__BB203_13;
$L__BB203_30:
	shr.u32 	%r49, %r47, 1;
	mul.wide.u32 	%rd214, %r49, 24;
	add.s64 	%rd215, %rd70, %rd214;
	add.s64 	%rd32, %rd215, %rd216;
	ld.global.nc.f32 	%f183, [%rd32];
$L__BB203_13:
	mul.hi.u32 	%r10, %r27, 715827883;
	add.rn.f32 	%f15, %f182, %f183;
	mov.f32 	%f184, %f185;
	@%p11 bra 	$L__BB203_31;
	bra.uni 	$L__BB203_14;
$L__BB203_31:
	shr.u32 	%r50, %r9, 1;
	add.s64 	%rd218, %rd14, %rd67;
	add.s64 	%rd220, %rd218, %rd69;
	mul.wide.u32 	%rd221, %r50, 24;
	add.s64 	%rd222, %rd220, %rd221;
	add.s64 	%rd224, %rd222, %rd216;
	ld.global.nc.f32 	%f108, [%rd224];
	add.s64 	%rd225, %rd13, %rd67;
	add.s64 	%rd226, %rd225, %rd69;
	add.s64 	%rd227, %rd226, %rd221;
	add.s64 	%rd228, %rd227, %rd216;
	ld.global.nc.f32 	%f109, [%rd228];
	add.rn.f32 	%f110, %f108, %f109;
	shr.u32 	%r51, %r8, 1;
	mul.lo.s64 	%rd229, %rd351, 12;
	add.s64 	%rd230, %rd12, %rd229;
	mul.wide.u32 	%rd231, %r51, 4;
	add.s64 	%rd232, %rd230, %rd231;
	ld.global.nc.f32 	%f111, [%rd232];
	shl.b64 	%rd233, %rd351, 2;
	add.s64 	%rd234, %rd15, %rd233;
	ld.global.nc.f32 	%f112, [%rd234];
	add.s64 	%rd237, %rd70, %rd221;
	add.s64 	%rd238, %rd237, %rd216;
	ld.global.nc.f32 	%f113, [%rd238];
	mul.rn.f32 	%f114, %f112, %f113;
	mul.rn.f32 	%f115, %f111, %f114;
	add.rn.f32 	%f184, %f110, %f115;
$L__BB203_14:
	mul.lo.s32 	%r28, %r10, 6;
	and.b32  	%r12, %r10, 255;
	add.rn.f32 	%f17, %f15, %f184;
	setp.eq.s32 	%p18, %r9, 0;
	@%p18 bra 	$L__BB203_32;
	bra.uni 	$L__BB203_15;
$L__BB203_32:
	shl.b32 	%r52, %r5, 10;
	mul.lo.s64 	%rd239, %rd351, 1228800;
	add.s64 	%rd240, %rd6, %rd239;
	mul.wide.u32 	%rd241, %r52, 24;
	add.s64 	%rd242, %rd240, %rd241;
	add.s64 	%rd244, %rd242, %rd216;
	ld.global.nc.f32 	%f117, [%rd244+72];
	mul.lo.s64 	%rd245, %rd351, 613200;
	add.s64 	%rd246, %rd3, %rd245;
	mul.lo.s64 	%rd247, %rd352, 12264;
	add.s64 	%rd248, %rd246, %rd247;
	add.s64 	%rd249, %rd248, %rd216;
	ld.global.nc.f32 	%f118, [%rd249+24];
	add.s64 	%rd250, %rd2, %rd245;
	add.s64 	%rd251, %rd250, %rd247;
	add.s64 	%rd252, %rd251, %rd216;
	ld.global.nc.f32 	%f119, [%rd252+24];
	add.rn.f32 	%f120, %f118, %f119;
	shr.u32 	%r53, %r8, 1;
	mul.lo.s64 	%rd253, %rd351, 12;
	add.s64 	%rd254, %rd4, %rd253;
	mul.wide.u32 	%rd255, %r53, 4;
	add.s64 	%rd256, %rd254, %rd255;
	ld.global.nc.f32 	%f121, [%rd256];
	shl.b64 	%rd257, %rd351, 2;
	add.s64 	%rd258, %rd5, %rd257;
	ld.global.nc.f32 	%f122, [%rd258];
	ld.global.nc.f32 	%f123, [%rd244+96];
	mul.rn.f32 	%f124, %f122, %f123;
	mul.rn.f32 	%f125, %f121, %f124;
	add.rn.f32 	%f126, %f120, %f125;
	add.rn.f32 	%f127, %f117, %f126;
	mul.lo.s64 	%rd259, %rd351, 306000;
	add.s64 	%rd260, %rd8, %rd259;
	mul.lo.s64 	%rd261, %rd352, 6120;
	add.s64 	%rd262, %rd260, %rd261;
	add.s64 	%rd263, %rd262, %rd216;
	ld.global.nc.f32 	%f128, [%rd263];
	add.s64 	%rd264, %rd7, %rd259;
	add.s64 	%rd265, %rd264, %rd261;
	add.s64 	%rd266, %rd265, %rd216;
	ld.global.nc.f32 	%f129, [%rd266];
	add.rn.f32 	%f130, %f128, %f129;
	add.s64 	%rd267, %rd9, %rd253;
	add.s64 	%rd268, %rd267, %rd255;
	ld.global.nc.f32 	%f131, [%rd268];
	add.s64 	%rd269, %rd10, %rd257;
	ld.global.nc.f32 	%f132, [%rd269];
	add.s64 	%rd270, %rd11, %rd259;
	add.s64 	%rd271, %rd270, %rd261;
	add.s64 	%rd272, %rd271, %rd216;
	ld.global.nc.f32 	%f133, [%rd272];
	mul.rn.f32 	%f134, %f132, %f133;
	mul.rn.f32 	%f135, %f131, %f134;
	add.rn.f32 	%f136, %f130, %f135;
	add.rn.f32 	%f185, %f127, %f136;
$L__BB203_15:
	sub.s32 	%r11, %r27, %r28;
	add.rn.f32 	%f137, %f17, %f185;
	st.global.f32 	[%rd26+8], %f137;
	setp.gt.u32 	%p19, %r12, 1;
	and.b32  	%r16, %r10, 1;
	setp.eq.s32 	%p20, %r16, 0;
	cvt.u64.u32 	%rd356, %r11;
	and.pred  	%p21, %p19, %p20;
	@%p21 bra 	$L__BB203_33;
	bra.uni 	$L__BB203_16;
$L__BB203_33:
	add.s32 	%r54, %r10, 254;
	bfe.u32 	%r55, %r54, 1, 7;
	add.s64 	%rd274, %rd16, %rd346;
	add.s64 	%rd276, %rd274, %rd347;
	mul.wide.u32 	%rd277, %r55, 24;
	add.s64 	%rd278, %rd276, %rd277;
	mul.wide.u32 	%rd279, %r11, 4;
	add.s64 	%rd280, %rd278, %rd279;
	ld.global.nc.f32 	%f186, [%rd280];
	bra.uni 	$L__BB203_17;
$L__BB203_16:
	mov.f32 	%f186, 0f00000000;
$L__BB203_17:
	add.s32 	%r56, %r12, -1;
	and.b32  	%r57, %r56, 1;
	setp.eq.b32 	%p22, %r57, 1;
	xor.pred  	%p24, %p22, %p14;
	not.pred 	%p25, %p24;
	shl.b64 	%rd287, %rd356, 2;
	mov.f32 	%f189, 0f00000000;
	mov.f32 	%f187, %f189;
	@%p25 bra 	$L__BB203_34;
	bra.uni 	$L__BB203_18;
$L__BB203_34:
	shr.u32 	%r58, %r56, 1;
	mul.wide.u32 	%rd285, %r58, 24;
	add.s64 	%rd286, %rd70, %rd285;
	add.s64 	%rd35, %rd286, %rd287;
	ld.global.nc.f32 	%f187, [%rd35];
$L__BB203_18:
	mov.f32 	%f188, %f189;
	@%p20 bra 	$L__BB203_35;
	bra.uni 	$L__BB203_19;
$L__BB203_35:
	shr.u32 	%r59, %r12, 1;
	add.s64 	%rd289, %rd14, %rd67;
	add.s64 	%rd291, %rd289, %rd69;
	mul.wide.u32 	%rd292, %r59, 24;
	add.s64 	%rd293, %rd291, %rd292;
	add.s64 	%rd295, %rd293, %rd287;
	ld.global.nc.f32 	%f141, [%rd295];
	add.s64 	%rd296, %rd13, %rd67;
	add.s64 	%rd297, %rd296, %rd69;
	add.s64 	%rd298, %rd297, %rd292;
	add.s64 	%rd299, %rd298, %rd287;
	ld.global.nc.f32 	%f142, [%rd299];
	add.rn.f32 	%f143, %f141, %f142;
	shr.u32 	%r60, %r11, 1;
	mul.lo.s64 	%rd300, %rd351, 12;
	add.s64 	%rd301, %rd12, %rd300;
	mul.wide.u32 	%rd302, %r60, 4;
	add.s64 	%rd303, %rd301, %rd302;
	ld.global.nc.f32 	%f144, [%rd303];
	shl.b64 	%rd304, %rd351, 2;
	add.s64 	%rd305, %rd15, %rd304;
	ld.global.nc.f32 	%f145, [%rd305];
	add.s64 	%rd308, %rd70, %rd292;
	add.s64 	%rd309, %rd308, %rd287;
	ld.global.nc.f32 	%f146, [%rd309];
	mul.rn.f32 	%f147, %f145, %f146;
	mul.rn.f32 	%f148, %f144, %f147;
	add.rn.f32 	%f188, %f143, %f148;
$L__BB203_19:
	setp.eq.s32 	%p27, %r12, 0;
	@%p27 bra 	$L__BB203_36;
	bra.uni 	$L__BB203_20;
$L__BB203_36:
	shl.b32 	%r61, %r5, 10;
	mul.lo.s64 	%rd310, %rd351, 1228800;
	add.s64 	%rd311, %rd6, %rd310;
	mul.wide.u32 	%rd312, %r61, 24;
	add.s64 	%rd313, %rd311, %rd312;
	add.s64 	%rd315, %rd313, %rd287;
	ld.global.nc.f32 	%f150, [%rd315+72];
	mul.lo.s64 	%rd316, %rd351, 613200;
	add.s64 	%rd317, %rd3, %rd316;
	mul.lo.s64 	%rd318, %rd352, 12264;
	add.s64 	%rd319, %rd317, %rd318;
	add.s64 	%rd320, %rd319, %rd287;
	ld.global.nc.f32 	%f151, [%rd320+24];
	add.s64 	%rd321, %rd2, %rd316;
	add.s64 	%rd322, %rd321, %rd318;
	add.s64 	%rd323, %rd322, %rd287;
	ld.global.nc.f32 	%f152, [%rd323+24];
	add.rn.f32 	%f153, %f151, %f152;
	shr.u32 	%r62, %r11, 1;
	mul.lo.s64 	%rd324, %rd351, 12;
	add.s64 	%rd325, %rd4, %rd324;
	mul.wide.u32 	%rd326, %r62, 4;
	add.s64 	%rd327, %rd325, %rd326;
	ld.global.nc.f32 	%f154, [%rd327];
	shl.b64 	%rd328, %rd351, 2;
	add.s64 	%rd329, %rd5, %rd328;
	ld.global.nc.f32 	%f155, [%rd329];
	ld.global.nc.f32 	%f156, [%rd315+96];
	mul.rn.f32 	%f157, %f155, %f156;
	mul.rn.f32 	%f158, %f154, %f157;
	add.rn.f32 	%f159, %f153, %f158;
	add.rn.f32 	%f160, %f150, %f159;
	mul.lo.s64 	%rd330, %rd351, 306000;
	add.s64 	%rd331, %rd8, %rd330;
	mul.lo.s64 	%rd332, %rd352, 6120;
	add.s64 	%rd333, %rd331, %rd332;
	add.s64 	%rd334, %rd333, %rd287;
	ld.global.nc.f32 	%f161, [%rd334];
	add.s64 	%rd335, %rd7, %rd330;
	add.s64 	%rd336, %rd335, %rd332;
	add.s64 	%rd337, %rd336, %rd287;
	ld.global.nc.f32 	%f162, [%rd337];
	add.rn.f32 	%f163, %f161, %f162;
	add.s64 	%rd338, %rd9, %rd324;
	add.s64 	%rd339, %rd338, %rd326;
	ld.global.nc.f32 	%f164, [%rd339];
	add.s64 	%rd340, %rd10, %rd328;
	ld.global.nc.f32 	%f165, [%rd340];
	add.s64 	%rd341, %rd11, %rd330;
	add.s64 	%rd342, %rd341, %rd332;
	add.s64 	%rd343, %rd342, %rd287;
	ld.global.nc.f32 	%f166, [%rd343];
	mul.rn.f32 	%f167, %f165, %f166;
	mul.rn.f32 	%f168, %f164, %f167;
	add.rn.f32 	%f169, %f163, %f168;
	add.rn.f32 	%f189, %f160, %f169;
$L__BB203_20:
	add.rn.f32 	%f170, %f186, %f187;
	add.rn.f32 	%f171, %f170, %f188;
	add.rn.f32 	%f172, %f171, %f189;
	st.global.f32 	[%rd26+12], %f172;
	ret;

}
	// .globl	loop_transpose_fusion_115
.visible .entry loop_transpose_fusion_115(
	.param .u64 loop_transpose_fusion_115_param_0,
	.param .u64 loop_transpose_fusion_115_param_1,
	.param .u64 loop_transpose_fusion_115_param_2,
	.param .u64 loop_transpose_fusion_115_param_3,
	.param .u64 loop_transpose_fusion_115_param_4
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<17>;
	.reg .b32 	%r<12>;
	.reg .f32 	%f<28>;
	.reg .b64 	%rd<28>;

	ld.param.u64 	%rd1, [loop_transpose_fusion_115_param_0];
	ld.param.u64 	%rd2, [loop_transpose_fusion_115_param_4];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_transpose_fusion_115_param_1];
	ld.param.u64 	%rd5, [loop_transpose_fusion_115_param_3];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_transpose_fusion_115_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	cvta.to.global.u64 	%rd9, %rd4;
	cvta.to.global.u64 	%rd10, %rd1;
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r2, %r1, 2;
	mov.u32 	%r3, %ctaid.x;
	shl.b32 	%r4, %r3, 9;
	or.b32  	%r5, %r4, %r2;
	cvt.u16.u32 	%rs1, %r3;
	shr.u16 	%rs2, %rs1, 6;
	mul.hi.u16 	%rs3, %rs2, 2622;
	mul.hi.u16 	%rs4, %rs1, 18351;
	sub.s16 	%rs5, %rs1, %rs4;
	shr.u16 	%rs6, %rs5, 1;
	add.s16 	%rs7, %rs6, %rs4;
	shr.u16 	%rs8, %rs7, 4;
	and.b16  	%rs9, %rs8, 63;
	shr.u32 	%r6, %r5, 8;
	cvt.u16.u32 	%rs10, %r6;
	shr.u16 	%rs11, %rs10, 1;
	mul.hi.u16 	%rs12, %rs11, 5243;
	shr.u16 	%rs13, %rs12, 1;
	mul.lo.s16 	%rs14, %rs13, 50;
	sub.s16 	%rs15, %rs10, %rs14;
	and.b32  	%r7, %r2, 252;
	shl.b16 	%rs16, %rs3, 1;
	cvt.u32.u16 	%r8, %rs9;
	mul.wide.u32 	%rd11, %r8, 12;
	add.s64 	%rd12, %rd8, %rd11;
	cvt.u32.u16 	%r9, %rs3;
	mul.wide.u32 	%rd13, %r9, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	mul.wide.u32 	%rd15, %r8, 4;
	add.s64 	%rd16, %rd9, %rd15;
	ld.global.nc.f32 	%f2, [%rd16];
	cvt.u32.u16 	%r10, %rs15;
	mul.wide.u32 	%rd17, %r10, 6144;
	mul.wide.u32 	%rd18, %r8, 307200;
	add.s64 	%rd19, %rd10, %rd18;
	add.s64 	%rd20, %rd19, %rd17;
	mul.wide.u32 	%rd21, %r7, 24;
	add.s64 	%rd22, %rd20, %rd21;
	cvt.u32.u16 	%r11, %rs16;
	mul.wide.u32 	%rd23, %r11, 4;
	add.s64 	%rd24, %rd22, %rd23;
	ld.global.nc.v2.f32 	{%f3, %f4}, [%rd24];
	mul.rn.f32 	%f5, %f2, %f4;
	mul.rn.f32 	%f6, %f1, %f5;
	mul.rn.f32 	%f7, %f2, %f3;
	neg.f32 	%f8, %f1;
	mul.rn.f32 	%f9, %f7, %f8;
	mul.wide.u32 	%rd25, %r5, 4;
	add.s64 	%rd26, %rd6, %rd25;
	add.s64 	%rd27, %rd3, %rd25;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd24+24];
	mul.rn.f32 	%f12, %f2, %f11;
	mul.rn.f32 	%f13, %f1, %f12;
	mul.rn.f32 	%f14, %f2, %f10;
	mul.rn.f32 	%f15, %f14, %f8;
	ld.global.nc.v2.f32 	{%f16, %f17}, [%rd24+48];
	mul.rn.f32 	%f18, %f2, %f17;
	mul.rn.f32 	%f19, %f1, %f18;
	mul.rn.f32 	%f20, %f2, %f16;
	mul.rn.f32 	%f21, %f20, %f8;
	ld.global.nc.v2.f32 	{%f22, %f23}, [%rd24+72];
	mul.rn.f32 	%f24, %f2, %f23;
	mul.rn.f32 	%f25, %f1, %f24;
	mul.rn.f32 	%f26, %f2, %f22;
	mul.rn.f32 	%f27, %f26, %f8;
	st.global.v4.f32 	[%rd26], {%f6, %f13, %f19, %f25};
	st.global.v4.f32 	[%rd27], {%f9, %f15, %f21, %f27};
	ret;

}
	// .globl	loop_broadcast_fusion_44
.visible .entry loop_broadcast_fusion_44(
	.param .u64 loop_broadcast_fusion_44_param_0
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd2, [loop_broadcast_fusion_44_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 9;
	shl.b32 	%r4, %r2, 2;
	or.b32  	%r5, %r3, %r4;
	mul.wide.u32 	%rd4, %r5, 4;
	add.s64 	%rd1, %rd3, %rd4;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd1], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+3538944], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+7077888], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+10616832], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+14155776], {%f1, %f1, %f1, %f1};
	setp.gt.u32 	%p1, %r5, 491519;
	@%p1 bra 	$L__BB205_2;
	st.global.v4.f32 	[%rd1+17694720], {%f1, %f1, %f1, %f1};
$L__BB205_2:
	ret;

}
	// .globl	input_scatter_fusion_262
.visible .entry input_scatter_fusion_262(
	.param .u64 input_scatter_fusion_262_param_0,
	.param .u64 input_scatter_fusion_262_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<15>;
	.reg .b32 	%r<10>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_262_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_262_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r4, 255;
	shr.u32 	%r6, %r1, 1;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r1;
	shr.u16 	%rs8, %rs7, 2;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	and.b16  	%rs11, %rs10, 63;
	shr.u16 	%rs12, %rs7, 8;
	mul.hi.u16 	%rs13, %rs12, 2622;
	shl.b16 	%rs14, %rs13, 1;
	cvt.u32.u16 	%r7, %rs14;
	mul.wide.u32 	%rd5, %r7, 3276800;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r8, %rs11;
	mul.wide.u32 	%rd7, %r8, 51200;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r9, %rs6;
	mul.wide.u32 	%rd9, %r9, 1024;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+3276800];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+3276800], %f3;
	ret;

}
	// .globl	wrapped_transpose_268
.visible .entry wrapped_transpose_268(
	.param .u64 wrapped_transpose_268_param_0,
	.param .u64 wrapped_transpose_268_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<26>;
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<32>;

	ld.param.u64 	%rd1, [wrapped_transpose_268_param_0];
	ld.param.u64 	%rd2, [wrapped_transpose_268_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	cvt.u16.u32 	%rs1, %r1;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, -9611;
	shr.u16 	%rs4, %rs3, 6;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	or.b32  	%r6, %r5, 3;
	mul.hi.u16 	%rs5, %rs1, -21845;
	shr.u16 	%rs6, %rs5, 1;
	mul.hi.u16 	%rs7, %rs6, 5243;
	shr.u16 	%rs8, %rs7, 2;
	mul.lo.s16 	%rs9, %rs8, 50;
	sub.s16 	%rs10, %rs6, %rs9;
	mul.hi.u32 	%r7, %r6, 715827883;
	and.b32  	%r8, %r7, 255;
	mul.lo.s32 	%r9, %r7, 6;
	sub.s32 	%r10, %r6, %r9;
	or.b32  	%r11, %r5, 2;
	mul.hi.u32 	%r12, %r11, 715827883;
	and.b32  	%r13, %r12, 255;
	mul.lo.s32 	%r14, %r12, 6;
	sub.s32 	%r15, %r11, %r14;
	or.b32  	%r16, %r5, 1;
	mul.hi.u32 	%r17, %r5, 715827883;
	and.b32  	%r18, %r17, 255;
	mul.hi.u32 	%r19, %r16, 715827883;
	mul.lo.s32 	%r20, %r19, 6;
	sub.s32 	%r21, %r16, %r20;
	mul.lo.s32 	%r22, %r17, 6;
	sub.s32 	%r23, %r5, %r22;
	mul.wide.u32 	%rd5, %r23, 3276800;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r24, %rs4;
	mul.wide.u32 	%rd7, %r24, 51200;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r25, %rs10;
	mul.wide.u32 	%rd9, %r25, 1024;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r18, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r5, 4;
	add.s64 	%rd14, %rd3, %rd13;
	mul.wide.u32 	%rd15, %r21, 3276800;
	add.s64 	%rd16, %rd4, %rd15;
	add.s64 	%rd17, %rd16, %rd7;
	add.s64 	%rd18, %rd17, %rd9;
	add.s64 	%rd19, %rd18, %rd11;
	ld.global.nc.f32 	%f2, [%rd19];
	mul.wide.u32 	%rd20, %r15, 3276800;
	add.s64 	%rd21, %rd4, %rd20;
	add.s64 	%rd22, %rd21, %rd7;
	add.s64 	%rd23, %rd22, %rd9;
	mul.wide.u32 	%rd24, %r13, 4;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.nc.f32 	%f3, [%rd25];
	mul.wide.u32 	%rd26, %r10, 3276800;
	add.s64 	%rd27, %rd4, %rd26;
	add.s64 	%rd28, %rd27, %rd7;
	add.s64 	%rd29, %rd28, %rd9;
	mul.wide.u32 	%rd30, %r8, 4;
	add.s64 	%rd31, %rd29, %rd30;
	ld.global.nc.f32 	%f4, [%rd31];
	st.global.v4.f32 	[%rd14], {%f1, %f2, %f3, %f4};
	ret;

}
	// .globl	input_scatter_fusion_263
.visible .entry input_scatter_fusion_263(
	.param .u64 input_scatter_fusion_263_param_0,
	.param .u64 input_scatter_fusion_263_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<15>;
	.reg .b32 	%r<10>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_263_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_263_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r4, 255;
	shr.u32 	%r6, %r1, 1;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r1;
	shr.u16 	%rs8, %rs7, 2;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	and.b16  	%rs11, %rs10, 63;
	shr.u16 	%rs12, %rs7, 8;
	mul.hi.u16 	%rs13, %rs12, 2622;
	shl.b16 	%rs14, %rs13, 1;
	cvt.u32.u16 	%r7, %rs14;
	mul.wide.u32 	%rd5, %r7, 3276800;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r8, %rs11;
	mul.wide.u32 	%rd7, %r8, 51200;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r9, %rs6;
	mul.wide.u32 	%rd9, %r9, 1024;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	input_add_reduce_fusion_44
.visible .entry input_add_reduce_fusion_44(
	.param .u64 input_add_reduce_fusion_44_param_0,
	.param .u64 input_add_reduce_fusion_44_param_1,
	.param .u64 input_add_reduce_fusion_44_param_2,
	.param .u64 input_add_reduce_fusion_44_param_3,
	.param .u64 input_add_reduce_fusion_44_param_4,
	.param .u64 input_add_reduce_fusion_44_param_5,
	.param .u64 input_add_reduce_fusion_44_param_6,
	.param .u64 input_add_reduce_fusion_44_param_7,
	.param .u64 input_add_reduce_fusion_44_param_8,
	.param .u64 input_add_reduce_fusion_44_param_9,
	.param .u64 input_add_reduce_fusion_44_param_10,
	.param .u64 input_add_reduce_fusion_44_param_11,
	.param .u64 input_add_reduce_fusion_44_param_12,
	.param .u64 input_add_reduce_fusion_44_param_13
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<14>;
	.reg .b16 	%rs<30>;
	.reg .b32 	%r<30>;
	.reg .f32 	%f<92>;
	.reg .b64 	%rd<148>;
	// demoted variable
	.shared .align 4 .b8 shared_cache21[4224];
	ld.param.u64 	%rd39, [input_add_reduce_fusion_44_param_0];
	ld.param.u64 	%rd40, [input_add_reduce_fusion_44_param_13];
	cvta.to.global.u64 	%rd41, %rd40;
	ld.param.u64 	%rd42, [input_add_reduce_fusion_44_param_1];
	ld.param.u64 	%rd43, [input_add_reduce_fusion_44_param_12];
	cvta.to.global.u64 	%rd1, %rd43;
	ld.param.u64 	%rd44, [input_add_reduce_fusion_44_param_2];
	ld.param.u64 	%rd45, [input_add_reduce_fusion_44_param_11];
	cvta.to.global.u64 	%rd46, %rd45;
	ld.param.u64 	%rd47, [input_add_reduce_fusion_44_param_3];
	ld.param.u64 	%rd48, [input_add_reduce_fusion_44_param_10];
	cvta.to.global.u64 	%rd49, %rd48;
	ld.param.u64 	%rd50, [input_add_reduce_fusion_44_param_4];
	ld.param.u64 	%rd51, [input_add_reduce_fusion_44_param_9];
	cvta.to.global.u64 	%rd52, %rd51;
	ld.param.u64 	%rd53, [input_add_reduce_fusion_44_param_5];
	ld.param.u64 	%rd54, [input_add_reduce_fusion_44_param_8];
	cvta.to.global.u64 	%rd55, %rd54;
	ld.param.u64 	%rd56, [input_add_reduce_fusion_44_param_6];
	ld.param.u64 	%rd57, [input_add_reduce_fusion_44_param_7];
	cvta.to.global.u64 	%rd58, %rd57;
	cvta.to.global.u64 	%rd59, %rd56;
	cvta.to.global.u64 	%rd60, %rd53;
	cvta.to.global.u64 	%rd61, %rd50;
	cvta.to.global.u64 	%rd62, %rd47;
	cvta.to.global.u64 	%rd63, %rd44;
	cvta.to.global.u64 	%rd64, %rd42;
	cvta.to.global.u64 	%rd65, %rd39;
	mov.u32 	%r9, %tid.x;
	mov.u32 	%r10, %ctaid.x;
	shr.u32 	%r1, %r9, 5;
	and.b32  	%r2, %r9, 31;
	cvt.u16.u32 	%rs1, %r10;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 6;
	mul.lo.s16 	%rs4, %rs3, 96;
	sub.s16 	%rs5, %rs1, %rs4;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r3, %rs6;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs7, %r4;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r11, %rs10;
	cvt.u32.u16 	%r12, %rs8;
	cvt.u64.u16 	%rd2, %rs3;
	cvt.u32.u16 	%r13, %rs3;
	mul.wide.u32 	%rd66, %r13, 4;
	add.s64 	%rd67, %rd64, %rd66;
	ld.global.nc.f32 	%f1, [%rd67];
	add.s16 	%rs11, %rs8, -2;
	setp.gt.u32 	%p3, %r4, 11;
	and.b32  	%r5, %r12, 1;
	setp.eq.s32 	%p4, %r5, 0;
	and.pred  	%p1, %p3, %p4;
	shr.u16 	%rs12, %rs11, 15;
	add.s16 	%rs13, %rs11, %rs12;
	shr.s16 	%rs14, %rs13, 1;
	add.s32 	%r14, %r12, -1;
	setp.gt.u32 	%p5, %r4, 5;
	and.b32  	%r15, %r14, 1;
	setp.eq.b32 	%p6, %r15, 1;
	not.pred 	%p7, %p6;
	and.pred  	%p2, %p5, %p7;
	cvt.u16.u32 	%rs15, %r14;
	shr.u16 	%rs16, %rs15, 15;
	add.s16 	%rs17, %rs15, %rs16;
	shr.s16 	%rs18, %rs17, 1;
	cvt.s64.s16 	%rd68, %rs18;
	and.b64  	%rd69, %rd68, 4294967295;
	shr.u32 	%r16, %r11, 1;
	mul.wide.u32 	%rd70, %r16, 4;
	mul.wide.u32 	%rd71, %r13, 12;
	add.s64 	%rd72, %rd55, %rd71;
	add.s64 	%rd3, %rd72, %rd70;
	add.s64 	%rd4, %rd58, %rd66;
	add.s64 	%rd73, %rd63, %rd71;
	add.s64 	%rd5, %rd73, %rd70;
	add.s32 	%r7, %r1, -32;
	shl.b16 	%rs19, %rs1, 5;
	cvt.u16.u32 	%rs20, %r9;
	and.b16  	%rs21, %rs20, 31;
	or.b16  	%rs22, %rs19, %rs21;
	mul.lo.s16 	%rs23, %rs3, 3072;
	sub.s16 	%rs24, %rs22, %rs23;
	mul.hi.u16 	%rs25, %rs24, -21845;
	shr.u16 	%rs26, %rs25, 2;
	mul.lo.s16 	%rs27, %rs26, 6;
	sub.s16 	%rs28, %rs22, %rs27;
	sub.s16 	%rs29, %rs28, %rs23;
	cvt.u32.u16 	%r17, %rs29;
	mul.wide.u32 	%rd6, %r17, 4;
	mul.wide.u32 	%rd74, %r13, 613200;
	cvt.u64.u32 	%rd75, %r9;
	shr.u64 	%rd76, %rd75, 5;
	mul.lo.s64 	%rd77, %rd76, 12264;
	add.s64 	%rd78, %rd74, %rd77;
	add.s64 	%rd26, %rd61, %rd78;
	add.s64 	%rd25, %rd62, %rd78;
	mul.wide.u32 	%rd79, %r13, 307200;
	mul.lo.s64 	%rd80, %rd76, 6144;
	add.s64 	%rd81, %rd79, %rd80;
	cvt.u32.u16 	%r18, %rs24;
	mul.hi.u32 	%r19, %r18, 357913942;
	mul.wide.u32 	%rd82, %r19, 24;
	add.s64 	%rd83, %rd81, %rd82;
	add.s64 	%rd24, %rd59, %rd83;
	add.s64 	%rd23, %rd49, %rd83;
	add.s64 	%rd22, %rd52, %rd83;
	mul.wide.u32 	%rd84, %r13, 614400;
	mul.lo.s64 	%rd85, %rd76, 12288;
	add.s64 	%rd86, %rd84, %rd85;
	mul.hi.u32 	%r20, %r18, 715827883;
	mul.wide.u32 	%rd87, %r20, 24;
	add.s64 	%rd88, %rd86, %rd87;
	add.s64 	%rd21, %rd41, %rd88;
	and.b64  	%rd89, %rd6, 262136;
	add.s64 	%rd90, %rd88, %rd89;
	and.b32  	%r21, %r9, 1;
	mul.wide.u32 	%rd91, %r21, 4;
	or.b64  	%rd92, %rd90, %rd91;
	add.s64 	%rd20, %rd65, %rd92;
	mul.lo.s64 	%rd93, %rd69, 24;
	add.s64 	%rd94, %rd81, %rd93;
	add.s64 	%rd19, %rd59, %rd94;
	mul.wide.u32 	%rd95, %r13, 306000;
	mul.lo.s64 	%rd96, %rd76, 6120;
	add.s64 	%rd97, %rd95, %rd96;
	cvt.s32.s16 	%r22, %rs14;
	mul.wide.s32 	%rd98, %r22, 24;
	add.s64 	%rd99, %rd97, %rd98;
	add.s64 	%rd18, %rd46, %rd99;
	mul.wide.u32 	%rd100, %r13, 1228800;
	mul.lo.s64 	%rd101, %rd76, 24576;
	add.s64 	%rd102, %rd100, %rd101;
	add.s64 	%rd103, %rd102, %rd60;
	add.s64 	%rd17, %rd103, 24;
	mov.f32 	%f25, 0f00000000;
	setp.lt.u32 	%p9, %r4, 6;
	mov.f32 	%f2, %f25;
	bra.uni 	$L__BB209_1;
$L__BB209_10:
	add.rn.f32 	%f2, %f2, %f51;
	add.rn.f32 	%f13, %f88, %f89;
	add.rn.f32 	%f15, %f13, %f90;
	add.rn.f32 	%f72, %f15, %f91;
	add.s64 	%rd116, %rd21, %rd6;
	st.global.f32 	[%rd116], %f72;
	add.s32 	%r7, %r7, 32;
	add.s64 	%rd26, %rd26, 392448;
	add.s64 	%rd25, %rd25, 392448;
	add.s64 	%rd24, %rd24, 196608;
	add.s64 	%rd23, %rd23, 196608;
	add.s64 	%rd22, %rd22, 196608;
	add.s64 	%rd21, %rd21, 393216;
	add.s64 	%rd20, %rd20, 393216;
	add.s64 	%rd19, %rd19, 196608;
	add.s64 	%rd18, %rd18, 195840;
	add.s64 	%rd17, %rd17, 786432;
	setp.gt.u32 	%p12, %r7, 17;
	@%p12 bra 	$L__BB209_11;
$L__BB209_1:
	add.s64 	%rd27, %rd18, %rd6;
	mov.f32 	%f84, %f25;
	@%p1 bra 	$L__BB209_2;
	bra.uni 	$L__BB209_3;
$L__BB209_2:
	ld.global.nc.f32 	%f84, [%rd27];
$L__BB209_3:
	add.s64 	%rd28, %rd19, %rd6;
	mov.f32 	%f85, %f25;
	@%p2 bra 	$L__BB209_13;
	bra.uni 	$L__BB209_4;
$L__BB209_13:
	ld.global.nc.f32 	%f85, [%rd28];
$L__BB209_4:
	add.s64 	%rd135, %rd22, %rd6;
	add.s64 	%rd136, %rd23, %rd6;
	add.s64 	%rd137, %rd24, %rd6;
	mov.f32 	%f86, %f25;
	@%p4 bra 	$L__BB209_14;
	bra.uni 	$L__BB209_5;
$L__BB209_14:
	ld.global.nc.f32 	%f29, [%rd135];
	ld.global.nc.f32 	%f30, [%rd136];
	add.rn.f32 	%f31, %f29, %f30;
	ld.global.nc.f32 	%f32, [%rd3];
	ld.global.nc.f32 	%f33, [%rd4];
	ld.global.nc.f32 	%f34, [%rd137];
	mul.rn.f32 	%f35, %f33, %f34;
	mul.rn.f32 	%f36, %f32, %f35;
	add.rn.f32 	%f86, %f31, %f36;
$L__BB209_5:
	add.s64 	%rd132, %rd17, %rd6;
	add.s64 	%rd133, %rd25, %rd6;
	add.s64 	%rd134, %rd26, %rd6;
	mov.f32 	%f87, %f25;
	@%p9 bra 	$L__BB209_15;
	bra.uni 	$L__BB209_6;
$L__BB209_15:
	ld.global.nc.f32 	%f38, [%rd132];
	ld.global.nc.f32 	%f39, [%rd133];
	ld.global.nc.f32 	%f40, [%rd134];
	add.rn.f32 	%f41, %f39, %f40;
	ld.global.nc.f32 	%f42, [%rd5];
	ld.global.nc.f32 	%f43, [%rd132+24];
	mul.rn.f32 	%f44, %f1, %f43;
	mul.rn.f32 	%f45, %f42, %f44;
	add.rn.f32 	%f46, %f41, %f45;
	add.rn.f32 	%f87, %f38, %f46;
$L__BB209_6:
	add.rn.f32 	%f6, %f84, %f85;
	add.rn.f32 	%f8, %f6, %f86;
	ld.global.nc.f32 	%f50, [%rd20];
	mov.f32 	%f88, %f25;
	@%p1 bra 	$L__BB209_16;
	bra.uni 	$L__BB209_7;
$L__BB209_16:
	ld.global.nc.f32 	%f88, [%rd27];
$L__BB209_7:
	add.rn.f32 	%f48, %f8, %f87;
	mov.f32 	%f89, %f25;
	@%p2 bra 	$L__BB209_17;
	bra.uni 	$L__BB209_8;
$L__BB209_17:
	ld.global.nc.f32 	%f89, [%rd28];
$L__BB209_8:
	mul.rn.f32 	%f49, %f1, %f48;
	mov.f32 	%f90, %f25;
	@%p4 bra 	$L__BB209_18;
	bra.uni 	$L__BB209_9;
$L__BB209_18:
	ld.global.nc.f32 	%f54, [%rd135];
	ld.global.nc.f32 	%f55, [%rd136];
	add.rn.f32 	%f56, %f54, %f55;
	ld.global.nc.f32 	%f57, [%rd3];
	ld.global.nc.f32 	%f58, [%rd4];
	ld.global.nc.f32 	%f59, [%rd137];
	mul.rn.f32 	%f60, %f58, %f59;
	mul.rn.f32 	%f61, %f57, %f60;
	add.rn.f32 	%f90, %f56, %f61;
$L__BB209_9:
	mul.rn.f32 	%f51, %f50, %f49;
	mov.f32 	%f91, %f25;
	@%p9 bra 	$L__BB209_19;
	bra.uni 	$L__BB209_10;
$L__BB209_19:
	ld.global.nc.f32 	%f63, [%rd132];
	ld.global.nc.f32 	%f64, [%rd133];
	ld.global.nc.f32 	%f65, [%rd134];
	add.rn.f32 	%f66, %f64, %f65;
	ld.global.nc.f32 	%f67, [%rd5];
	ld.global.nc.f32 	%f68, [%rd132+24];
	mul.rn.f32 	%f69, %f1, %f68;
	mul.rn.f32 	%f70, %f67, %f69;
	add.rn.f32 	%f71, %f66, %f70;
	add.rn.f32 	%f91, %f63, %f71;
	bra.uni 	$L__BB209_10;
$L__BB209_11:
	mul.wide.u32 	%rd117, %r2, 132;
	mov.u64 	%rd118, shared_cache21;
	add.s64 	%rd119, %rd118, %rd117;
	mul.wide.u32 	%rd120, %r1, 4;
	add.s64 	%rd121, %rd119, %rd120;
	st.shared.f32 	[%rd121], %f2;
	bar.sync 	0;
	mul.wide.u32 	%rd122, %r1, 132;
	add.s64 	%rd123, %rd118, %rd122;
	mul.wide.u32 	%rd124, %r2, 4;
	add.s64 	%rd125, %rd123, %rd124;
	ld.shared.f32 	%f73, [%rd125];
	shfl.sync.down.b32	%f74, %f73, 16, 31, -1;
	add.rn.f32 	%f75, %f73, %f74;
	shfl.sync.down.b32	%f76, %f75, 8, 31, -1;
	add.rn.f32 	%f77, %f75, %f76;
	shfl.sync.down.b32	%f78, %f77, 4, 31, -1;
	add.rn.f32 	%f79, %f77, %f78;
	shfl.sync.down.b32	%f80, %f79, 2, 31, -1;
	add.rn.f32 	%f81, %f79, %f80;
	shfl.sync.down.b32	%f82, %f81, 1, 31, -1;
	add.rn.f32 	%f3, %f81, %f82;
	st.shared.f32 	[%rd125], %f3;
	setp.eq.s32 	%p13, %r2, 0;
	@%p13 bra 	$L__BB209_20;
	bra.uni 	$L__BB209_12;
$L__BB209_20:
	or.b32  	%r23, %r1, %r3;
	mul.hi.u32 	%r25, %r23, -1431655765;
	shr.u32 	%r26, %r25, 2;
	mul.lo.s32 	%r27, %r26, 6;
	sub.s32 	%r28, %r23, %r27;
	mul.lo.s64 	%rd126, %rd2, 12288;
	add.s64 	%rd127, %rd1, %rd126;
	mul.wide.u32 	%rd128, %r26, 24;
	add.s64 	%rd129, %rd127, %rd128;
	mul.wide.u32 	%rd130, %r28, 4;
	add.s64 	%rd131, %rd129, %rd130;
	st.global.f32 	[%rd131], %f3;
$L__BB209_12:
	ret;

}
	// .globl	input_reduce_fusion_308
.visible .entry input_reduce_fusion_308(
	.param .u64 input_reduce_fusion_308_param_0,
	.param .u64 input_reduce_fusion_308_param_1,
	.param .u64 input_reduce_fusion_308_param_2,
	.param .u64 input_reduce_fusion_308_param_3,
	.param .u64 input_reduce_fusion_308_param_4,
	.param .u64 input_reduce_fusion_308_param_5,
	.param .u64 input_reduce_fusion_308_param_6,
	.param .u64 input_reduce_fusion_308_param_7
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<28>;
	.reg .f32 	%f<43>;
	.reg .b64 	%rd<89>;
	// demoted variable
	.shared .align 4 .b8 shared_cache22[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache23[4224];
	ld.param.u64 	%rd15, [input_reduce_fusion_308_param_0];
	ld.param.u64 	%rd16, [input_reduce_fusion_308_param_7];
	cvta.to.global.u64 	%rd1, %rd16;
	ld.param.u64 	%rd17, [input_reduce_fusion_308_param_1];
	ld.param.u64 	%rd18, [input_reduce_fusion_308_param_6];
	cvta.to.global.u64 	%rd2, %rd18;
	ld.param.u64 	%rd19, [input_reduce_fusion_308_param_2];
	ld.param.u64 	%rd20, [input_reduce_fusion_308_param_5];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [input_reduce_fusion_308_param_3];
	ld.param.u64 	%rd23, [input_reduce_fusion_308_param_4];
	cvta.to.global.u64 	%rd24, %rd23;
	cvta.to.global.u64 	%rd25, %rd22;
	cvta.to.global.u64 	%rd26, %rd19;
	cvta.to.global.u64 	%rd27, %rd17;
	cvta.to.global.u64 	%rd28, %rd15;
	mov.u32 	%r7, %tid.x;
	mov.u32 	%r8, %ctaid.x;
	shr.u32 	%r1, %r7, 5;
	and.b32  	%r2, %r7, 31;
	cvt.u16.u32 	%rs1, %r8;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 6;
	mul.lo.s16 	%rs4, %rs3, 96;
	sub.s16 	%rs5, %rs1, %rs4;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r3, %rs6;
	or.b32  	%r9, %r2, %r3;
	cvt.u16.u32 	%rs7, %r9;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r10, %rs10;
	cvt.u64.u16 	%rd3, %rs3;
	cvt.u32.u16 	%r11, %rs3;
	mul.wide.u32 	%rd29, %r11, 4;
	add.s64 	%rd30, %rd26, %rd29;
	ld.global.nc.f32 	%f1, [%rd30];
	shr.u32 	%r12, %r10, 1;
	mul.wide.u32 	%rd31, %r12, 4;
	mul.wide.u32 	%rd32, %r11, 12;
	add.s64 	%rd33, %rd21, %rd32;
	add.s64 	%rd34, %rd33, %rd31;
	ld.global.nc.f32 	%f2, [%rd34];
	add.s64 	%rd35, %rd24, %rd32;
	add.s64 	%rd36, %rd35, %rd31;
	ld.global.nc.f32 	%f3, [%rd36];
	and.b32  	%r13, %r10, 1;
	add.s32 	%r27, %r1, -32;
	mul.wide.u32 	%rd37, %r11, 1228800;
	cvt.u64.u32 	%rd38, %r7;
	shr.u64 	%rd39, %rd38, 5;
	mul.lo.s64 	%rd40, %rd39, 24576;
	add.s64 	%rd41, %rd37, %rd40;
	cvt.u32.u16 	%r14, %rs8;
	mul.wide.u32 	%rd42, %r14, 48;
	add.s64 	%rd43, %rd41, %rd42;
	mul.wide.u32 	%rd44, %r10, 4;
	add.s64 	%rd45, %rd43, %rd44;
	add.s64 	%rd88, %rd28, %rd45;
	mul.wide.u32 	%rd46, %r11, 614400;
	mul.lo.s64 	%rd47, %rd39, 12288;
	add.s64 	%rd48, %rd46, %rd47;
	mul.wide.u32 	%rd49, %r14, 24;
	add.s64 	%rd50, %rd48, %rd49;
	add.s64 	%rd51, %rd50, %rd44;
	add.s64 	%rd87, %rd27, %rd51;
	mul.wide.u32 	%rd52, %r12, 8;
	add.s64 	%rd53, %rd50, %rd52;
	mul.wide.u32 	%rd54, %r13, 4;
	or.b64  	%rd55, %rd53, %rd54;
	add.s64 	%rd86, %rd25, %rd55;
	mov.f32 	%f41, 0f00000000;
	mov.f32 	%f42, %f41;
$L__BB210_1:
	ld.global.nc.f32 	%f11, [%rd87];
	mul.rn.f32 	%f12, %f1, %f11;
	ld.global.nc.f32 	%f13, [%rd88];
	mul.rn.f32 	%f14, %f12, %f13;
	add.rn.f32 	%f42, %f42, %f14;
	mul.rn.f32 	%f15, %f13, %f2;
	ld.global.nc.f32 	%f16, [%rd86];
	mul.rn.f32 	%f17, %f3, %f16;
	add.rn.f32 	%f18, %f15, %f17;
	mul.rn.f32 	%f19, %f11, %f18;
	add.rn.f32 	%f41, %f41, %f19;
	add.s32 	%r27, %r27, 32;
	add.s64 	%rd88, %rd88, 786432;
	add.s64 	%rd87, %rd87, 393216;
	add.s64 	%rd86, %rd86, 393216;
	setp.lt.u32 	%p1, %r27, 18;
	@%p1 bra 	$L__BB210_1;
	cvt.u64.u32 	%rd13, %r2;
	cvt.u64.u32 	%rd14, %r1;
	mul.wide.u32 	%rd56, %r2, 132;
	mov.u64 	%rd57, shared_cache22;
	add.s64 	%rd58, %rd57, %rd56;
	mul.wide.u32 	%rd59, %r1, 4;
	add.s64 	%rd60, %rd58, %rd59;
	st.shared.f32 	[%rd60], %f42;
	bar.sync 	0;
	mul.wide.u32 	%rd61, %r1, 132;
	add.s64 	%rd62, %rd57, %rd61;
	mul.wide.u32 	%rd63, %r2, 4;
	add.s64 	%rd64, %rd62, %rd63;
	ld.shared.f32 	%f20, [%rd64];
	shfl.sync.down.b32	%f21, %f20, 16, 31, -1;
	add.rn.f32 	%f22, %f20, %f21;
	shfl.sync.down.b32	%f23, %f22, 8, 31, -1;
	add.rn.f32 	%f24, %f22, %f23;
	shfl.sync.down.b32	%f25, %f24, 4, 31, -1;
	add.rn.f32 	%f26, %f24, %f25;
	shfl.sync.down.b32	%f27, %f26, 2, 31, -1;
	add.rn.f32 	%f28, %f26, %f27;
	shfl.sync.down.b32	%f29, %f28, 1, 31, -1;
	add.rn.f32 	%f8, %f28, %f29;
	st.shared.f32 	[%rd64], %f8;
	setp.eq.s32 	%p2, %r2, 0;
	@%p2 bra 	$L__BB210_5;
	bra.uni 	$L__BB210_3;
$L__BB210_5:
	or.b32  	%r15, %r1, %r3;
	mul.hi.u32 	%r17, %r15, -1431655765;
	shr.u32 	%r18, %r17, 2;
	mul.lo.s32 	%r19, %r18, 6;
	sub.s32 	%r20, %r15, %r19;
	mul.lo.s64 	%rd65, %rd3, 12288;
	add.s64 	%rd66, %rd2, %rd65;
	mul.wide.u32 	%rd67, %r18, 24;
	add.s64 	%rd68, %rd66, %rd67;
	mul.wide.u32 	%rd69, %r20, 4;
	add.s64 	%rd70, %rd68, %rd69;
	neg.f32 	%f30, %f8;
	st.global.f32 	[%rd70], %f30;
$L__BB210_3:
	mul.lo.s64 	%rd71, %rd13, 132;
	mov.u64 	%rd72, shared_cache23;
	add.s64 	%rd73, %rd72, %rd71;
	shl.b64 	%rd74, %rd14, 2;
	add.s64 	%rd75, %rd73, %rd74;
	st.shared.f32 	[%rd75], %f41;
	bar.sync 	0;
	mul.lo.s64 	%rd76, %rd14, 132;
	add.s64 	%rd77, %rd72, %rd76;
	shl.b64 	%rd78, %rd13, 2;
	add.s64 	%rd79, %rd77, %rd78;
	ld.shared.f32 	%f31, [%rd79];
	shfl.sync.down.b32	%f32, %f31, 16, 31, -1;
	add.rn.f32 	%f33, %f31, %f32;
	shfl.sync.down.b32	%f34, %f33, 8, 31, -1;
	add.rn.f32 	%f35, %f33, %f34;
	shfl.sync.down.b32	%f36, %f35, 4, 31, -1;
	add.rn.f32 	%f37, %f35, %f36;
	shfl.sync.down.b32	%f38, %f37, 2, 31, -1;
	add.rn.f32 	%f39, %f37, %f38;
	shfl.sync.down.b32	%f40, %f39, 1, 31, -1;
	add.rn.f32 	%f9, %f39, %f40;
	st.shared.f32 	[%rd79], %f9;
	@%p2 bra 	$L__BB210_6;
	bra.uni 	$L__BB210_4;
$L__BB210_6:
	or.b32  	%r21, %r1, %r3;
	mul.hi.u32 	%r23, %r21, -1431655765;
	shr.u32 	%r24, %r23, 2;
	mul.lo.s32 	%r25, %r24, 6;
	sub.s32 	%r26, %r21, %r25;
	mul.lo.s64 	%rd80, %rd3, 12288;
	add.s64 	%rd81, %rd1, %rd80;
	mul.wide.u32 	%rd82, %r24, 24;
	add.s64 	%rd83, %rd81, %rd82;
	mul.wide.u32 	%rd84, %r26, 4;
	add.s64 	%rd85, %rd83, %rd84;
	st.global.f32 	[%rd85], %f9;
$L__BB210_4:
	ret;

}
	// .globl	input_reduce_fusion_309
.visible .entry input_reduce_fusion_309(
	.param .u64 input_reduce_fusion_309_param_0,
	.param .u64 input_reduce_fusion_309_param_1,
	.param .u64 input_reduce_fusion_309_param_2,
	.param .u64 input_reduce_fusion_309_param_3,
	.param .u64 input_reduce_fusion_309_param_4
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<11>;
	.reg .b64 	%rd<35>;

	ld.param.u64 	%rd5, [input_reduce_fusion_309_param_0];
	ld.param.u64 	%rd7, [input_reduce_fusion_309_param_1];
	ld.param.u64 	%rd8, [input_reduce_fusion_309_param_3];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [input_reduce_fusion_309_param_2];
	cvta.to.global.u64 	%rd11, %rd10;
	cvta.to.global.u64 	%rd12, %rd7;
	cvta.to.global.u64 	%rd13, %rd5;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	shr.u32 	%r3, %r1, 1;
	and.b32  	%r4, %r1, 1;
	shl.b32 	%r5, %r2, 7;
	cvt.u16.u32 	%rs1, %r2;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 3;
	or.b32  	%r6, %r3, %r5;
	mul.hi.u32 	%r7, %r6, 1431655766;
	mul.lo.s32 	%r8, %r7, 3;
	sub.s32 	%r9, %r6, %r8;
	and.b32  	%r10, %r7, 511;
	shl.b32 	%r11, %r9, 1;
	or.b32  	%r12, %r11, %r4;
	cvt.u32.u16 	%r13, %rs3;
	mul.wide.u32 	%rd14, %r13, 12288;
	add.s64 	%rd15, %rd11, %rd14;
	mul.wide.u32 	%rd16, %r10, 24;
	add.s64 	%rd17, %rd15, %rd16;
	mul.wide.u32 	%rd18, %r12, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.nc.f32 	%f3, [%rd19];
	mul.wide.u32 	%rd20, %r9, 4;
	mul.wide.u32 	%rd21, %r13, 12;
	add.s64 	%rd22, %rd9, %rd21;
	add.s64 	%rd23, %rd22, %rd20;
	ld.global.nc.f32 	%f4, [%rd23];
	mul.rn.f32 	%f5, %f3, %f4;
	add.s64 	%rd24, %rd12, %rd14;
	add.s64 	%rd25, %rd24, %rd16;
	add.s64 	%rd26, %rd25, %rd18;
	ld.global.nc.f32 	%f6, [%rd26];
	add.s64 	%rd27, %rd13, %rd21;
	add.s64 	%rd28, %rd27, %rd20;
	ld.global.nc.f32 	%f7, [%rd28];
	mul.rn.f32 	%f8, %f6, %f7;
	add.rn.f32 	%f9, %f5, %f8;
	add.rn.f32 	%f1, %f9, 0f00000000;
	shfl.sync.down.b32	%f2, %f1, 1, 31, -1;
	setp.eq.s32 	%p1, %r4, 0;
	@%p1 bra 	$L__BB211_2;
	bra.uni 	$L__BB211_1;
$L__BB211_2:
	ld.param.u64 	%rd6, [input_reduce_fusion_309_param_4];
	cvta.to.global.u64 	%rd1, %rd6;
	cvt.u64.u16 	%rd2, %rs3;
	cvt.u64.u32 	%rd3, %r10;
	cvt.u64.u32 	%rd4, %r9;
	add.rn.f32 	%f10, %f1, %f2;
	mul.lo.s64 	%rd29, %rd2, 6144;
	add.s64 	%rd30, %rd1, %rd29;
	shl.b64 	%rd31, %rd4, 11;
	add.s64 	%rd32, %rd30, %rd31;
	shl.b64 	%rd33, %rd3, 2;
	add.s64 	%rd34, %rd32, %rd33;
	st.global.f32 	[%rd34], %f10;
$L__BB211_1:
	ret;

}
	// .globl	input_reduce_fusion_310
.visible .entry input_reduce_fusion_310(
	.param .u64 input_reduce_fusion_310_param_0,
	.param .u64 input_reduce_fusion_310_param_1,
	.param .u64 input_reduce_fusion_310_param_2,
	.param .u64 input_reduce_fusion_310_param_3,
	.param .u64 input_reduce_fusion_310_param_4,
	.param .u64 input_reduce_fusion_310_param_5,
	.param .u64 input_reduce_fusion_310_param_6,
	.param .u64 input_reduce_fusion_310_param_7
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<28>;
	.reg .f32 	%f<43>;
	.reg .b64 	%rd<83>;
	// demoted variable
	.shared .align 4 .b8 shared_cache24[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache25[4224];
	ld.param.u64 	%rd15, [input_reduce_fusion_310_param_0];
	ld.param.u64 	%rd16, [input_reduce_fusion_310_param_7];
	cvta.to.global.u64 	%rd1, %rd16;
	ld.param.u64 	%rd17, [input_reduce_fusion_310_param_1];
	ld.param.u64 	%rd18, [input_reduce_fusion_310_param_6];
	cvta.to.global.u64 	%rd2, %rd18;
	ld.param.u64 	%rd19, [input_reduce_fusion_310_param_2];
	ld.param.u64 	%rd20, [input_reduce_fusion_310_param_5];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [input_reduce_fusion_310_param_3];
	ld.param.u64 	%rd23, [input_reduce_fusion_310_param_4];
	cvta.to.global.u64 	%rd24, %rd23;
	cvta.to.global.u64 	%rd25, %rd22;
	cvta.to.global.u64 	%rd26, %rd19;
	cvta.to.global.u64 	%rd27, %rd17;
	cvta.to.global.u64 	%rd28, %rd15;
	mov.u32 	%r7, %tid.x;
	mov.u32 	%r8, %ctaid.x;
	shr.u32 	%r1, %r7, 5;
	and.b32  	%r2, %r7, 31;
	cvt.u16.u32 	%rs1, %r8;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 5;
	mul.lo.s16 	%rs4, %rs3, 48;
	sub.s16 	%rs5, %rs1, %rs4;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r3, %rs6;
	or.b32  	%r9, %r2, %r3;
	cvt.u16.u32 	%rs7, %r9;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r10, %rs10;
	cvt.u64.u16 	%rd3, %rs3;
	cvt.u32.u16 	%r11, %rs3;
	mul.wide.u32 	%rd29, %r11, 4;
	add.s64 	%rd30, %rd26, %rd29;
	ld.global.nc.f32 	%f1, [%rd30];
	shr.u32 	%r12, %r10, 1;
	mul.wide.u32 	%rd31, %r12, 4;
	mul.wide.u32 	%rd32, %r11, 12;
	add.s64 	%rd33, %rd21, %rd32;
	add.s64 	%rd34, %rd33, %rd31;
	ld.global.nc.f32 	%f2, [%rd34];
	add.s64 	%rd35, %rd24, %rd32;
	add.s64 	%rd36, %rd35, %rd31;
	ld.global.nc.f32 	%f3, [%rd36];
	and.b32  	%r13, %r10, 1;
	add.s32 	%r27, %r1, -32;
	mul.wide.u32 	%rd37, %r11, 307200;
	cvt.u64.u32 	%rd38, %r7;
	shr.u64 	%rd39, %rd38, 5;
	mul.lo.s64 	%rd40, %rd39, 6144;
	add.s64 	%rd41, %rd37, %rd40;
	cvt.u32.u16 	%r14, %rs8;
	mul.wide.u32 	%rd42, %r14, 24;
	add.s64 	%rd43, %rd41, %rd42;
	mul.wide.u32 	%rd44, %r10, 4;
	add.s64 	%rd45, %rd43, %rd44;
	add.s64 	%rd82, %rd27, %rd45;
	add.s64 	%rd81, %rd28, %rd45;
	mul.wide.u32 	%rd46, %r12, 8;
	add.s64 	%rd47, %rd43, %rd46;
	mul.wide.u32 	%rd48, %r13, 4;
	or.b64  	%rd49, %rd47, %rd48;
	add.s64 	%rd80, %rd25, %rd49;
	mov.f32 	%f41, 0f00000000;
	mov.f32 	%f42, %f41;
$L__BB212_1:
	ld.global.nc.f32 	%f11, [%rd82];
	mul.rn.f32 	%f12, %f1, %f11;
	ld.global.nc.f32 	%f13, [%rd81];
	mul.rn.f32 	%f14, %f12, %f13;
	add.rn.f32 	%f42, %f42, %f14;
	mul.rn.f32 	%f15, %f13, %f2;
	ld.global.nc.f32 	%f16, [%rd80];
	mul.rn.f32 	%f17, %f3, %f16;
	add.rn.f32 	%f18, %f15, %f17;
	mul.rn.f32 	%f19, %f11, %f18;
	add.rn.f32 	%f41, %f41, %f19;
	add.s32 	%r27, %r27, 32;
	add.s64 	%rd82, %rd82, 196608;
	add.s64 	%rd81, %rd81, 196608;
	add.s64 	%rd80, %rd80, 196608;
	setp.lt.u32 	%p1, %r27, 18;
	@%p1 bra 	$L__BB212_1;
	cvt.u64.u32 	%rd13, %r2;
	cvt.u64.u32 	%rd14, %r1;
	mul.wide.u32 	%rd50, %r2, 132;
	mov.u64 	%rd51, shared_cache24;
	add.s64 	%rd52, %rd51, %rd50;
	mul.wide.u32 	%rd53, %r1, 4;
	add.s64 	%rd54, %rd52, %rd53;
	st.shared.f32 	[%rd54], %f42;
	bar.sync 	0;
	mul.wide.u32 	%rd55, %r1, 132;
	add.s64 	%rd56, %rd51, %rd55;
	mul.wide.u32 	%rd57, %r2, 4;
	add.s64 	%rd58, %rd56, %rd57;
	ld.shared.f32 	%f20, [%rd58];
	shfl.sync.down.b32	%f21, %f20, 16, 31, -1;
	add.rn.f32 	%f22, %f20, %f21;
	shfl.sync.down.b32	%f23, %f22, 8, 31, -1;
	add.rn.f32 	%f24, %f22, %f23;
	shfl.sync.down.b32	%f25, %f24, 4, 31, -1;
	add.rn.f32 	%f26, %f24, %f25;
	shfl.sync.down.b32	%f27, %f26, 2, 31, -1;
	add.rn.f32 	%f28, %f26, %f27;
	shfl.sync.down.b32	%f29, %f28, 1, 31, -1;
	add.rn.f32 	%f8, %f28, %f29;
	st.shared.f32 	[%rd58], %f8;
	setp.eq.s32 	%p2, %r2, 0;
	@%p2 bra 	$L__BB212_5;
	bra.uni 	$L__BB212_3;
$L__BB212_5:
	or.b32  	%r15, %r1, %r3;
	mul.hi.u32 	%r17, %r15, -1431655765;
	shr.u32 	%r18, %r17, 2;
	mul.lo.s32 	%r19, %r18, 6;
	sub.s32 	%r20, %r15, %r19;
	mul.lo.s64 	%rd59, %rd3, 6144;
	add.s64 	%rd60, %rd2, %rd59;
	mul.wide.u32 	%rd61, %r18, 24;
	add.s64 	%rd62, %rd60, %rd61;
	mul.wide.u32 	%rd63, %r20, 4;
	add.s64 	%rd64, %rd62, %rd63;
	neg.f32 	%f30, %f8;
	st.global.f32 	[%rd64], %f30;
$L__BB212_3:
	mul.lo.s64 	%rd65, %rd13, 132;
	mov.u64 	%rd66, shared_cache25;
	add.s64 	%rd67, %rd66, %rd65;
	shl.b64 	%rd68, %rd14, 2;
	add.s64 	%rd69, %rd67, %rd68;
	st.shared.f32 	[%rd69], %f41;
	bar.sync 	0;
	mul.lo.s64 	%rd70, %rd14, 132;
	add.s64 	%rd71, %rd66, %rd70;
	shl.b64 	%rd72, %rd13, 2;
	add.s64 	%rd73, %rd71, %rd72;
	ld.shared.f32 	%f31, [%rd73];
	shfl.sync.down.b32	%f32, %f31, 16, 31, -1;
	add.rn.f32 	%f33, %f31, %f32;
	shfl.sync.down.b32	%f34, %f33, 8, 31, -1;
	add.rn.f32 	%f35, %f33, %f34;
	shfl.sync.down.b32	%f36, %f35, 4, 31, -1;
	add.rn.f32 	%f37, %f35, %f36;
	shfl.sync.down.b32	%f38, %f37, 2, 31, -1;
	add.rn.f32 	%f39, %f37, %f38;
	shfl.sync.down.b32	%f40, %f39, 1, 31, -1;
	add.rn.f32 	%f9, %f39, %f40;
	st.shared.f32 	[%rd73], %f9;
	@%p2 bra 	$L__BB212_6;
	bra.uni 	$L__BB212_4;
$L__BB212_6:
	or.b32  	%r21, %r1, %r3;
	mul.hi.u32 	%r23, %r21, -1431655765;
	shr.u32 	%r24, %r23, 2;
	mul.lo.s32 	%r25, %r24, 6;
	sub.s32 	%r26, %r21, %r25;
	mul.lo.s64 	%rd74, %rd3, 6144;
	add.s64 	%rd75, %rd1, %rd74;
	mul.wide.u32 	%rd76, %r24, 24;
	add.s64 	%rd77, %rd75, %rd76;
	mul.wide.u32 	%rd78, %r26, 4;
	add.s64 	%rd79, %rd77, %rd78;
	st.global.f32 	[%rd79], %f9;
$L__BB212_4:
	ret;

}
	// .globl	input_reduce_fusion_311
.visible .entry input_reduce_fusion_311(
	.param .u64 input_reduce_fusion_311_param_0,
	.param .u64 input_reduce_fusion_311_param_1,
	.param .u64 input_reduce_fusion_311_param_2,
	.param .u64 input_reduce_fusion_311_param_3
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<22>;
	.reg .f32 	%f<21>;
	.reg .b64 	%rd<48>;
	// demoted variable
	.shared .align 4 .b8 shared_cache26[4224];
	ld.param.u64 	%rd9, [input_reduce_fusion_311_param_0];
	ld.param.u64 	%rd10, [input_reduce_fusion_311_param_3];
	cvta.to.global.u64 	%rd1, %rd10;
	ld.param.u64 	%rd11, [input_reduce_fusion_311_param_1];
	ld.param.u64 	%rd12, [input_reduce_fusion_311_param_2];
	cvta.to.global.u64 	%rd13, %rd12;
	cvta.to.global.u64 	%rd14, %rd11;
	cvta.to.global.u64 	%rd15, %rd9;
	mov.u32 	%r7, %tid.x;
	mov.u32 	%r8, %ctaid.x;
	shr.u32 	%r1, %r7, 5;
	and.b32  	%r2, %r7, 31;
	cvt.u16.u32 	%rs1, %r8;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 5;
	mul.lo.s16 	%rs4, %rs3, 48;
	sub.s16 	%rs5, %rs1, %rs4;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r3, %rs6;
	or.b32  	%r9, %r2, %r3;
	cvt.u16.u32 	%rs7, %r9;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r10, %rs10;
	cvt.u64.u16 	%rd2, %rs3;
	cvt.u32.u16 	%r11, %rs3;
	mul.wide.u32 	%rd16, %r11, 4;
	add.s64 	%rd17, %rd13, %rd16;
	ld.global.nc.f32 	%f1, [%rd17];
	and.b32  	%r12, %r10, 1;
	shr.u32 	%r13, %r10, 1;
	add.s32 	%r21, %r1, -32;
	mul.wide.u32 	%rd18, %r11, 307200;
	cvt.u64.u32 	%rd19, %r7;
	shr.u64 	%rd20, %rd19, 5;
	mul.lo.s64 	%rd21, %rd20, 6144;
	add.s64 	%rd22, %rd18, %rd21;
	cvt.u32.u16 	%r14, %rs8;
	mul.wide.u32 	%rd23, %r14, 24;
	add.s64 	%rd24, %rd22, %rd23;
	mul.wide.u32 	%rd25, %r10, 4;
	add.s64 	%rd26, %rd24, %rd25;
	add.s64 	%rd47, %rd14, %rd26;
	mul.wide.u32 	%rd27, %r13, 8;
	add.s64 	%rd28, %rd24, %rd27;
	mul.wide.u32 	%rd29, %r12, 4;
	or.b64  	%rd30, %rd28, %rd29;
	add.s64 	%rd46, %rd15, %rd30;
	mov.f32 	%f20, 0f00000000;
$L__BB213_1:
	ld.global.nc.f32 	%f6, [%rd47];
	mul.rn.f32 	%f7, %f1, %f6;
	ld.global.nc.f32 	%f8, [%rd46];
	mul.rn.f32 	%f9, %f7, %f8;
	add.rn.f32 	%f20, %f20, %f9;
	add.s32 	%r21, %r21, 32;
	add.s64 	%rd47, %rd47, 196608;
	add.s64 	%rd46, %rd46, 196608;
	setp.lt.u32 	%p1, %r21, 18;
	@%p1 bra 	$L__BB213_1;
	mul.wide.u32 	%rd31, %r2, 132;
	mov.u64 	%rd32, shared_cache26;
	add.s64 	%rd33, %rd32, %rd31;
	mul.wide.u32 	%rd34, %r1, 4;
	add.s64 	%rd35, %rd33, %rd34;
	st.shared.f32 	[%rd35], %f20;
	bar.sync 	0;
	mul.wide.u32 	%rd36, %r1, 132;
	add.s64 	%rd37, %rd32, %rd36;
	mul.wide.u32 	%rd38, %r2, 4;
	add.s64 	%rd39, %rd37, %rd38;
	ld.shared.f32 	%f10, [%rd39];
	shfl.sync.down.b32	%f11, %f10, 16, 31, -1;
	add.rn.f32 	%f12, %f10, %f11;
	shfl.sync.down.b32	%f13, %f12, 8, 31, -1;
	add.rn.f32 	%f14, %f12, %f13;
	shfl.sync.down.b32	%f15, %f14, 4, 31, -1;
	add.rn.f32 	%f16, %f14, %f15;
	shfl.sync.down.b32	%f17, %f16, 2, 31, -1;
	add.rn.f32 	%f18, %f16, %f17;
	shfl.sync.down.b32	%f19, %f18, 1, 31, -1;
	add.rn.f32 	%f4, %f18, %f19;
	st.shared.f32 	[%rd39], %f4;
	setp.ne.s32 	%p2, %r2, 0;
	@%p2 bra 	$L__BB213_4;
	or.b32  	%r15, %r1, %r3;
	mul.hi.u32 	%r17, %r15, -1431655765;
	shr.u32 	%r18, %r17, 2;
	mul.lo.s32 	%r19, %r18, 6;
	sub.s32 	%r20, %r15, %r19;
	mul.lo.s64 	%rd40, %rd2, 6144;
	add.s64 	%rd41, %rd1, %rd40;
	mul.wide.u32 	%rd42, %r18, 24;
	add.s64 	%rd43, %rd41, %rd42;
	mul.wide.u32 	%rd44, %r20, 4;
	add.s64 	%rd45, %rd43, %rd44;
	st.global.f32 	[%rd45], %f4;
$L__BB213_4:
	ret;

}
	// .globl	input_reduce_fusion_312
.visible .entry input_reduce_fusion_312(
	.param .u64 input_reduce_fusion_312_param_0,
	.param .u64 input_reduce_fusion_312_param_1,
	.param .u64 input_reduce_fusion_312_param_2,
	.param .u64 input_reduce_fusion_312_param_3,
	.param .u64 input_reduce_fusion_312_param_4
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<12>;
	.reg .f32 	%f<11>;
	.reg .b64 	%rd<35>;

	ld.param.u64 	%rd5, [input_reduce_fusion_312_param_0];
	ld.param.u64 	%rd7, [input_reduce_fusion_312_param_1];
	ld.param.u64 	%rd8, [input_reduce_fusion_312_param_3];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [input_reduce_fusion_312_param_2];
	cvta.to.global.u64 	%rd11, %rd10;
	cvta.to.global.u64 	%rd12, %rd7;
	cvta.to.global.u64 	%rd13, %rd5;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	shr.u32 	%r3, %r1, 1;
	and.b32  	%r4, %r1, 1;
	shl.b32 	%r5, %r2, 7;
	cvt.u16.u32 	%rs1, %r2;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	or.b32  	%r6, %r3, %r5;
	cvt.u16.u32 	%rs4, %r6;
	mul.hi.u16 	%rs5, %rs4, -21845;
	shr.u16 	%rs6, %rs5, 1;
	mul.lo.s16 	%rs7, %rs6, 3;
	sub.s16 	%rs8, %rs4, %rs7;
	and.b16  	%rs9, %rs6, 255;
	shl.b16 	%rs10, %rs8, 1;
	cvt.u32.u16 	%r7, %rs10;
	or.b32  	%r8, %r4, %r7;
	cvt.u32.u16 	%r9, %rs3;
	mul.wide.u32 	%rd14, %r9, 6144;
	add.s64 	%rd15, %rd11, %rd14;
	cvt.u32.u16 	%r10, %rs9;
	mul.wide.u32 	%rd16, %r10, 24;
	add.s64 	%rd17, %rd15, %rd16;
	mul.wide.u32 	%rd18, %r8, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.nc.f32 	%f3, [%rd19];
	cvt.u32.u16 	%r11, %rs8;
	mul.wide.u32 	%rd20, %r11, 4;
	mul.wide.u32 	%rd21, %r9, 12;
	add.s64 	%rd22, %rd9, %rd21;
	add.s64 	%rd23, %rd22, %rd20;
	ld.global.nc.f32 	%f4, [%rd23];
	mul.rn.f32 	%f5, %f3, %f4;
	add.s64 	%rd24, %rd12, %rd14;
	add.s64 	%rd25, %rd24, %rd16;
	add.s64 	%rd26, %rd25, %rd18;
	ld.global.nc.f32 	%f6, [%rd26];
	add.s64 	%rd27, %rd13, %rd21;
	add.s64 	%rd28, %rd27, %rd20;
	ld.global.nc.f32 	%f7, [%rd28];
	mul.rn.f32 	%f8, %f6, %f7;
	add.rn.f32 	%f9, %f5, %f8;
	add.rn.f32 	%f1, %f9, 0f00000000;
	shfl.sync.down.b32	%f2, %f1, 1, 31, -1;
	setp.eq.s32 	%p1, %r4, 0;
	@%p1 bra 	$L__BB214_2;
	bra.uni 	$L__BB214_1;
$L__BB214_2:
	ld.param.u64 	%rd6, [input_reduce_fusion_312_param_4];
	cvta.to.global.u64 	%rd1, %rd6;
	cvt.u64.u16 	%rd2, %rs3;
	cvt.u64.u16 	%rd3, %rs9;
	cvt.u64.u16 	%rd4, %rs8;
	add.rn.f32 	%f10, %f1, %f2;
	mul.lo.s64 	%rd29, %rd2, 3072;
	add.s64 	%rd30, %rd1, %rd29;
	shl.b64 	%rd31, %rd4, 10;
	add.s64 	%rd32, %rd30, %rd31;
	shl.b64 	%rd33, %rd3, 2;
	add.s64 	%rd34, %rd32, %rd33;
	st.global.f32 	[%rd34], %f10;
$L__BB214_1:
	ret;

}
	// .globl	input_reduce_fusion_313
.visible .entry input_reduce_fusion_313(
	.param .u64 input_reduce_fusion_313_param_0,
	.param .u64 input_reduce_fusion_313_param_1,
	.param .u64 input_reduce_fusion_313_param_2,
	.param .u64 input_reduce_fusion_313_param_3,
	.param .u64 input_reduce_fusion_313_param_4,
	.param .u64 input_reduce_fusion_313_param_5,
	.param .u64 input_reduce_fusion_313_param_6,
	.param .u64 input_reduce_fusion_313_param_7
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<28>;
	.reg .f32 	%f<43>;
	.reg .b64 	%rd<89>;
	// demoted variable
	.shared .align 4 .b8 shared_cache27[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache28[4224];
	ld.param.u64 	%rd15, [input_reduce_fusion_313_param_0];
	ld.param.u64 	%rd16, [input_reduce_fusion_313_param_7];
	cvta.to.global.u64 	%rd1, %rd16;
	ld.param.u64 	%rd17, [input_reduce_fusion_313_param_1];
	ld.param.u64 	%rd18, [input_reduce_fusion_313_param_6];
	cvta.to.global.u64 	%rd2, %rd18;
	ld.param.u64 	%rd19, [input_reduce_fusion_313_param_2];
	ld.param.u64 	%rd20, [input_reduce_fusion_313_param_5];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [input_reduce_fusion_313_param_3];
	ld.param.u64 	%rd23, [input_reduce_fusion_313_param_4];
	cvta.to.global.u64 	%rd24, %rd23;
	cvta.to.global.u64 	%rd25, %rd22;
	cvta.to.global.u64 	%rd26, %rd19;
	cvta.to.global.u64 	%rd27, %rd17;
	cvta.to.global.u64 	%rd28, %rd15;
	mov.u32 	%r7, %tid.x;
	mov.u32 	%r8, %ctaid.x;
	shr.u32 	%r1, %r7, 5;
	and.b32  	%r2, %r7, 31;
	cvt.u16.u32 	%rs1, %r8;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 4;
	mul.lo.s16 	%rs4, %rs3, 24;
	sub.s16 	%rs5, %rs1, %rs4;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r3, %rs6;
	or.b32  	%r9, %r2, %r3;
	cvt.u16.u32 	%rs7, %r9;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r10, %rs10;
	cvt.u64.u16 	%rd3, %rs3;
	cvt.u32.u16 	%r11, %rs3;
	mul.wide.u32 	%rd29, %r11, 4;
	add.s64 	%rd30, %rd26, %rd29;
	ld.global.nc.f32 	%f1, [%rd30];
	shr.u32 	%r12, %r10, 1;
	mul.wide.u32 	%rd31, %r12, 4;
	mul.wide.u32 	%rd32, %r11, 12;
	add.s64 	%rd33, %rd21, %rd32;
	add.s64 	%rd34, %rd33, %rd31;
	ld.global.nc.f32 	%f2, [%rd34];
	add.s64 	%rd35, %rd24, %rd32;
	add.s64 	%rd36, %rd35, %rd31;
	ld.global.nc.f32 	%f3, [%rd36];
	and.b32  	%r13, %r10, 1;
	add.s32 	%r27, %r1, -32;
	mul.wide.u32 	%rd37, %r11, 153600;
	cvt.u64.u32 	%rd38, %r7;
	shr.u64 	%rd39, %rd38, 5;
	mul.lo.s64 	%rd40, %rd39, 3072;
	add.s64 	%rd41, %rd37, %rd40;
	cvt.u32.u16 	%r14, %rs8;
	mul.wide.u32 	%rd42, %r14, 24;
	add.s64 	%rd43, %rd41, %rd42;
	mul.wide.u32 	%rd44, %r10, 4;
	add.s64 	%rd45, %rd43, %rd44;
	add.s64 	%rd88, %rd27, %rd45;
	mul.wide.u32 	%rd46, %r11, 307200;
	mul.lo.s64 	%rd47, %rd39, 6144;
	add.s64 	%rd48, %rd46, %rd47;
	mul.wide.u32 	%rd49, %r14, 48;
	add.s64 	%rd50, %rd48, %rd49;
	add.s64 	%rd51, %rd50, %rd44;
	add.s64 	%rd87, %rd28, %rd51;
	mul.wide.u32 	%rd52, %r12, 8;
	add.s64 	%rd53, %rd43, %rd52;
	mul.wide.u32 	%rd54, %r13, 4;
	or.b64  	%rd55, %rd53, %rd54;
	add.s64 	%rd86, %rd25, %rd55;
	mov.f32 	%f41, 0f00000000;
	mov.f32 	%f42, %f41;
$L__BB215_1:
	ld.global.nc.f32 	%f11, [%rd88];
	mul.rn.f32 	%f12, %f1, %f11;
	ld.global.nc.f32 	%f13, [%rd87];
	mul.rn.f32 	%f14, %f12, %f13;
	add.rn.f32 	%f42, %f42, %f14;
	mul.rn.f32 	%f15, %f13, %f2;
	ld.global.nc.f32 	%f16, [%rd86];
	mul.rn.f32 	%f17, %f3, %f16;
	add.rn.f32 	%f18, %f15, %f17;
	mul.rn.f32 	%f19, %f11, %f18;
	add.rn.f32 	%f41, %f41, %f19;
	add.s32 	%r27, %r27, 32;
	add.s64 	%rd88, %rd88, 98304;
	add.s64 	%rd87, %rd87, 196608;
	add.s64 	%rd86, %rd86, 98304;
	setp.lt.u32 	%p1, %r27, 18;
	@%p1 bra 	$L__BB215_1;
	cvt.u64.u32 	%rd13, %r2;
	cvt.u64.u32 	%rd14, %r1;
	mul.wide.u32 	%rd56, %r2, 132;
	mov.u64 	%rd57, shared_cache27;
	add.s64 	%rd58, %rd57, %rd56;
	mul.wide.u32 	%rd59, %r1, 4;
	add.s64 	%rd60, %rd58, %rd59;
	st.shared.f32 	[%rd60], %f42;
	bar.sync 	0;
	mul.wide.u32 	%rd61, %r1, 132;
	add.s64 	%rd62, %rd57, %rd61;
	mul.wide.u32 	%rd63, %r2, 4;
	add.s64 	%rd64, %rd62, %rd63;
	ld.shared.f32 	%f20, [%rd64];
	shfl.sync.down.b32	%f21, %f20, 16, 31, -1;
	add.rn.f32 	%f22, %f20, %f21;
	shfl.sync.down.b32	%f23, %f22, 8, 31, -1;
	add.rn.f32 	%f24, %f22, %f23;
	shfl.sync.down.b32	%f25, %f24, 4, 31, -1;
	add.rn.f32 	%f26, %f24, %f25;
	shfl.sync.down.b32	%f27, %f26, 2, 31, -1;
	add.rn.f32 	%f28, %f26, %f27;
	shfl.sync.down.b32	%f29, %f28, 1, 31, -1;
	add.rn.f32 	%f8, %f28, %f29;
	st.shared.f32 	[%rd64], %f8;
	setp.eq.s32 	%p2, %r2, 0;
	@%p2 bra 	$L__BB215_5;
	bra.uni 	$L__BB215_3;
$L__BB215_5:
	or.b32  	%r15, %r1, %r3;
	mul.hi.u32 	%r17, %r15, -1431655765;
	shr.u32 	%r18, %r17, 2;
	mul.lo.s32 	%r19, %r18, 6;
	sub.s32 	%r20, %r15, %r19;
	mul.lo.s64 	%rd65, %rd3, 3072;
	add.s64 	%rd66, %rd2, %rd65;
	mul.wide.u32 	%rd67, %r18, 24;
	add.s64 	%rd68, %rd66, %rd67;
	mul.wide.u32 	%rd69, %r20, 4;
	add.s64 	%rd70, %rd68, %rd69;
	neg.f32 	%f30, %f8;
	st.global.f32 	[%rd70], %f30;
$L__BB215_3:
	mul.lo.s64 	%rd71, %rd13, 132;
	mov.u64 	%rd72, shared_cache28;
	add.s64 	%rd73, %rd72, %rd71;
	shl.b64 	%rd74, %rd14, 2;
	add.s64 	%rd75, %rd73, %rd74;
	st.shared.f32 	[%rd75], %f41;
	bar.sync 	0;
	mul.lo.s64 	%rd76, %rd14, 132;
	add.s64 	%rd77, %rd72, %rd76;
	shl.b64 	%rd78, %rd13, 2;
	add.s64 	%rd79, %rd77, %rd78;
	ld.shared.f32 	%f31, [%rd79];
	shfl.sync.down.b32	%f32, %f31, 16, 31, -1;
	add.rn.f32 	%f33, %f31, %f32;
	shfl.sync.down.b32	%f34, %f33, 8, 31, -1;
	add.rn.f32 	%f35, %f33, %f34;
	shfl.sync.down.b32	%f36, %f35, 4, 31, -1;
	add.rn.f32 	%f37, %f35, %f36;
	shfl.sync.down.b32	%f38, %f37, 2, 31, -1;
	add.rn.f32 	%f39, %f37, %f38;
	shfl.sync.down.b32	%f40, %f39, 1, 31, -1;
	add.rn.f32 	%f9, %f39, %f40;
	st.shared.f32 	[%rd79], %f9;
	@%p2 bra 	$L__BB215_6;
	bra.uni 	$L__BB215_4;
$L__BB215_6:
	or.b32  	%r21, %r1, %r3;
	mul.hi.u32 	%r23, %r21, -1431655765;
	shr.u32 	%r24, %r23, 2;
	mul.lo.s32 	%r25, %r24, 6;
	sub.s32 	%r26, %r21, %r25;
	mul.lo.s64 	%rd80, %rd3, 3072;
	add.s64 	%rd81, %rd1, %rd80;
	mul.wide.u32 	%rd82, %r24, 24;
	add.s64 	%rd83, %rd81, %rd82;
	mul.wide.u32 	%rd84, %r26, 4;
	add.s64 	%rd85, %rd83, %rd84;
	st.global.f32 	[%rd85], %f9;
$L__BB215_4:
	ret;

}
	// .globl	input_reduce_fusion_314
.visible .entry input_reduce_fusion_314(
	.param .u64 input_reduce_fusion_314_param_0,
	.param .u64 input_reduce_fusion_314_param_1,
	.param .u64 input_reduce_fusion_314_param_2,
	.param .u64 input_reduce_fusion_314_param_3,
	.param .u64 input_reduce_fusion_314_param_4
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<12>;
	.reg .f32 	%f<11>;
	.reg .b64 	%rd<35>;

	ld.param.u64 	%rd5, [input_reduce_fusion_314_param_0];
	ld.param.u64 	%rd7, [input_reduce_fusion_314_param_1];
	ld.param.u64 	%rd8, [input_reduce_fusion_314_param_3];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [input_reduce_fusion_314_param_2];
	cvta.to.global.u64 	%rd11, %rd10;
	cvta.to.global.u64 	%rd12, %rd7;
	cvta.to.global.u64 	%rd13, %rd5;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	shr.u32 	%r3, %r1, 1;
	and.b32  	%r4, %r1, 1;
	shl.b32 	%r5, %r2, 7;
	cvt.u16.u32 	%rs1, %r2;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 9;
	or.b32  	%r6, %r3, %r5;
	cvt.u16.u32 	%rs5, %r6;
	mul.hi.u16 	%rs6, %rs5, -21845;
	shr.u16 	%rs7, %rs6, 1;
	mul.lo.s16 	%rs8, %rs7, 3;
	sub.s16 	%rs9, %rs5, %rs8;
	and.b16  	%rs10, %rs7, 127;
	shl.b16 	%rs11, %rs9, 1;
	cvt.u32.u16 	%r7, %rs11;
	or.b32  	%r8, %r4, %r7;
	cvt.u32.u16 	%r9, %rs4;
	mul.wide.u32 	%rd14, %r9, 3072;
	add.s64 	%rd15, %rd11, %rd14;
	cvt.u32.u16 	%r10, %rs10;
	mul.wide.u32 	%rd16, %r10, 24;
	add.s64 	%rd17, %rd15, %rd16;
	mul.wide.u32 	%rd18, %r8, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.nc.f32 	%f3, [%rd19];
	cvt.u32.u16 	%r11, %rs9;
	mul.wide.u32 	%rd20, %r11, 4;
	mul.wide.u32 	%rd21, %r9, 12;
	add.s64 	%rd22, %rd9, %rd21;
	add.s64 	%rd23, %rd22, %rd20;
	ld.global.nc.f32 	%f4, [%rd23];
	mul.rn.f32 	%f5, %f3, %f4;
	add.s64 	%rd24, %rd12, %rd14;
	add.s64 	%rd25, %rd24, %rd16;
	add.s64 	%rd26, %rd25, %rd18;
	ld.global.nc.f32 	%f6, [%rd26];
	add.s64 	%rd27, %rd13, %rd21;
	add.s64 	%rd28, %rd27, %rd20;
	ld.global.nc.f32 	%f7, [%rd28];
	mul.rn.f32 	%f8, %f6, %f7;
	add.rn.f32 	%f9, %f5, %f8;
	add.rn.f32 	%f1, %f9, 0f00000000;
	shfl.sync.down.b32	%f2, %f1, 1, 31, -1;
	setp.eq.s32 	%p1, %r4, 0;
	@%p1 bra 	$L__BB216_2;
	bra.uni 	$L__BB216_1;
$L__BB216_2:
	ld.param.u64 	%rd6, [input_reduce_fusion_314_param_4];
	cvta.to.global.u64 	%rd1, %rd6;
	cvt.u64.u16 	%rd2, %rs4;
	cvt.u64.u16 	%rd3, %rs10;
	cvt.u64.u16 	%rd4, %rs9;
	add.rn.f32 	%f10, %f1, %f2;
	mul.lo.s64 	%rd29, %rd2, 1536;
	add.s64 	%rd30, %rd1, %rd29;
	shl.b64 	%rd31, %rd4, 9;
	add.s64 	%rd32, %rd30, %rd31;
	shl.b64 	%rd33, %rd3, 2;
	add.s64 	%rd34, %rd32, %rd33;
	st.global.f32 	[%rd34], %f10;
$L__BB216_1:
	ret;

}
	// .globl	input_reduce_fusion_315
.visible .entry input_reduce_fusion_315(
	.param .u64 input_reduce_fusion_315_param_0,
	.param .u64 input_reduce_fusion_315_param_1,
	.param .u64 input_reduce_fusion_315_param_2,
	.param .u64 input_reduce_fusion_315_param_3,
	.param .u64 input_reduce_fusion_315_param_4,
	.param .u64 input_reduce_fusion_315_param_5,
	.param .u64 input_reduce_fusion_315_param_6,
	.param .u64 input_reduce_fusion_315_param_7
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<28>;
	.reg .f32 	%f<43>;
	.reg .b64 	%rd<83>;
	// demoted variable
	.shared .align 4 .b8 shared_cache29[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache30[4224];
	ld.param.u64 	%rd15, [input_reduce_fusion_315_param_0];
	ld.param.u64 	%rd16, [input_reduce_fusion_315_param_7];
	cvta.to.global.u64 	%rd1, %rd16;
	ld.param.u64 	%rd17, [input_reduce_fusion_315_param_1];
	ld.param.u64 	%rd18, [input_reduce_fusion_315_param_6];
	cvta.to.global.u64 	%rd2, %rd18;
	ld.param.u64 	%rd19, [input_reduce_fusion_315_param_2];
	ld.param.u64 	%rd20, [input_reduce_fusion_315_param_5];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [input_reduce_fusion_315_param_3];
	ld.param.u64 	%rd23, [input_reduce_fusion_315_param_4];
	cvta.to.global.u64 	%rd24, %rd23;
	cvta.to.global.u64 	%rd25, %rd22;
	cvta.to.global.u64 	%rd26, %rd19;
	cvta.to.global.u64 	%rd27, %rd17;
	cvta.to.global.u64 	%rd28, %rd15;
	mov.u32 	%r7, %tid.x;
	mov.u32 	%r8, %ctaid.x;
	shr.u32 	%r1, %r7, 5;
	and.b32  	%r2, %r7, 31;
	cvt.u16.u32 	%rs1, %r8;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 3;
	mul.lo.s16 	%rs4, %rs3, 12;
	sub.s16 	%rs5, %rs1, %rs4;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r3, %rs6;
	or.b32  	%r9, %r2, %r3;
	cvt.u16.u32 	%rs7, %r9;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r10, %rs10;
	cvt.u64.u16 	%rd3, %rs3;
	cvt.u32.u16 	%r11, %rs3;
	mul.wide.u32 	%rd29, %r11, 4;
	add.s64 	%rd30, %rd26, %rd29;
	ld.global.nc.f32 	%f1, [%rd30];
	shr.u32 	%r12, %r10, 1;
	mul.wide.u32 	%rd31, %r12, 4;
	mul.wide.u32 	%rd32, %r11, 12;
	add.s64 	%rd33, %rd21, %rd32;
	add.s64 	%rd34, %rd33, %rd31;
	ld.global.nc.f32 	%f2, [%rd34];
	add.s64 	%rd35, %rd24, %rd32;
	add.s64 	%rd36, %rd35, %rd31;
	ld.global.nc.f32 	%f3, [%rd36];
	and.b32  	%r13, %r10, 1;
	add.s32 	%r27, %r1, -32;
	mul.wide.u32 	%rd37, %r11, 76800;
	cvt.u64.u32 	%rd38, %r7;
	shr.u64 	%rd39, %rd38, 5;
	mul.lo.s64 	%rd40, %rd39, 1536;
	add.s64 	%rd41, %rd37, %rd40;
	cvt.u32.u16 	%r14, %rs8;
	mul.wide.u32 	%rd42, %r14, 24;
	add.s64 	%rd43, %rd41, %rd42;
	mul.wide.u32 	%rd44, %r10, 4;
	add.s64 	%rd45, %rd43, %rd44;
	add.s64 	%rd82, %rd27, %rd45;
	add.s64 	%rd81, %rd28, %rd45;
	mul.wide.u32 	%rd46, %r12, 8;
	add.s64 	%rd47, %rd43, %rd46;
	mul.wide.u32 	%rd48, %r13, 4;
	or.b64  	%rd49, %rd47, %rd48;
	add.s64 	%rd80, %rd25, %rd49;
	mov.f32 	%f41, 0f00000000;
	mov.f32 	%f42, %f41;
$L__BB217_1:
	ld.global.nc.f32 	%f11, [%rd82];
	mul.rn.f32 	%f12, %f1, %f11;
	ld.global.nc.f32 	%f13, [%rd81];
	mul.rn.f32 	%f14, %f12, %f13;
	add.rn.f32 	%f42, %f42, %f14;
	mul.rn.f32 	%f15, %f13, %f2;
	ld.global.nc.f32 	%f16, [%rd80];
	mul.rn.f32 	%f17, %f3, %f16;
	add.rn.f32 	%f18, %f15, %f17;
	mul.rn.f32 	%f19, %f11, %f18;
	add.rn.f32 	%f41, %f41, %f19;
	add.s32 	%r27, %r27, 32;
	add.s64 	%rd82, %rd82, 49152;
	add.s64 	%rd81, %rd81, 49152;
	add.s64 	%rd80, %rd80, 49152;
	setp.lt.u32 	%p1, %r27, 18;
	@%p1 bra 	$L__BB217_1;
	cvt.u64.u32 	%rd13, %r2;
	cvt.u64.u32 	%rd14, %r1;
	mul.wide.u32 	%rd50, %r2, 132;
	mov.u64 	%rd51, shared_cache29;
	add.s64 	%rd52, %rd51, %rd50;
	mul.wide.u32 	%rd53, %r1, 4;
	add.s64 	%rd54, %rd52, %rd53;
	st.shared.f32 	[%rd54], %f42;
	bar.sync 	0;
	mul.wide.u32 	%rd55, %r1, 132;
	add.s64 	%rd56, %rd51, %rd55;
	mul.wide.u32 	%rd57, %r2, 4;
	add.s64 	%rd58, %rd56, %rd57;
	ld.shared.f32 	%f20, [%rd58];
	shfl.sync.down.b32	%f21, %f20, 16, 31, -1;
	add.rn.f32 	%f22, %f20, %f21;
	shfl.sync.down.b32	%f23, %f22, 8, 31, -1;
	add.rn.f32 	%f24, %f22, %f23;
	shfl.sync.down.b32	%f25, %f24, 4, 31, -1;
	add.rn.f32 	%f26, %f24, %f25;
	shfl.sync.down.b32	%f27, %f26, 2, 31, -1;
	add.rn.f32 	%f28, %f26, %f27;
	shfl.sync.down.b32	%f29, %f28, 1, 31, -1;
	add.rn.f32 	%f8, %f28, %f29;
	st.shared.f32 	[%rd58], %f8;
	setp.eq.s32 	%p2, %r2, 0;
	@%p2 bra 	$L__BB217_5;
	bra.uni 	$L__BB217_3;
$L__BB217_5:
	or.b32  	%r15, %r1, %r3;
	mul.hi.u32 	%r17, %r15, -1431655765;
	shr.u32 	%r18, %r17, 2;
	mul.lo.s32 	%r19, %r18, 6;
	sub.s32 	%r20, %r15, %r19;
	mul.lo.s64 	%rd59, %rd3, 1536;
	add.s64 	%rd60, %rd2, %rd59;
	mul.wide.u32 	%rd61, %r18, 24;
	add.s64 	%rd62, %rd60, %rd61;
	mul.wide.u32 	%rd63, %r20, 4;
	add.s64 	%rd64, %rd62, %rd63;
	neg.f32 	%f30, %f8;
	st.global.f32 	[%rd64], %f30;
$L__BB217_3:
	mul.lo.s64 	%rd65, %rd13, 132;
	mov.u64 	%rd66, shared_cache30;
	add.s64 	%rd67, %rd66, %rd65;
	shl.b64 	%rd68, %rd14, 2;
	add.s64 	%rd69, %rd67, %rd68;
	st.shared.f32 	[%rd69], %f41;
	bar.sync 	0;
	mul.lo.s64 	%rd70, %rd14, 132;
	add.s64 	%rd71, %rd66, %rd70;
	shl.b64 	%rd72, %rd13, 2;
	add.s64 	%rd73, %rd71, %rd72;
	ld.shared.f32 	%f31, [%rd73];
	shfl.sync.down.b32	%f32, %f31, 16, 31, -1;
	add.rn.f32 	%f33, %f31, %f32;
	shfl.sync.down.b32	%f34, %f33, 8, 31, -1;
	add.rn.f32 	%f35, %f33, %f34;
	shfl.sync.down.b32	%f36, %f35, 4, 31, -1;
	add.rn.f32 	%f37, %f35, %f36;
	shfl.sync.down.b32	%f38, %f37, 2, 31, -1;
	add.rn.f32 	%f39, %f37, %f38;
	shfl.sync.down.b32	%f40, %f39, 1, 31, -1;
	add.rn.f32 	%f9, %f39, %f40;
	st.shared.f32 	[%rd73], %f9;
	@%p2 bra 	$L__BB217_6;
	bra.uni 	$L__BB217_4;
$L__BB217_6:
	or.b32  	%r21, %r1, %r3;
	mul.hi.u32 	%r23, %r21, -1431655765;
	shr.u32 	%r24, %r23, 2;
	mul.lo.s32 	%r25, %r24, 6;
	sub.s32 	%r26, %r21, %r25;
	mul.lo.s64 	%rd74, %rd3, 1536;
	add.s64 	%rd75, %rd1, %rd74;
	mul.wide.u32 	%rd76, %r24, 24;
	add.s64 	%rd77, %rd75, %rd76;
	mul.wide.u32 	%rd78, %r26, 4;
	add.s64 	%rd79, %rd77, %rd78;
	st.global.f32 	[%rd79], %f9;
$L__BB217_4:
	ret;

}
	// .globl	input_reduce_fusion_316
.visible .entry input_reduce_fusion_316(
	.param .u64 input_reduce_fusion_316_param_0,
	.param .u64 input_reduce_fusion_316_param_1,
	.param .u64 input_reduce_fusion_316_param_2,
	.param .u64 input_reduce_fusion_316_param_3,
	.param .u64 input_reduce_fusion_316_param_4
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<12>;
	.reg .f32 	%f<11>;
	.reg .b64 	%rd<35>;

	ld.param.u64 	%rd5, [input_reduce_fusion_316_param_0];
	ld.param.u64 	%rd7, [input_reduce_fusion_316_param_1];
	ld.param.u64 	%rd8, [input_reduce_fusion_316_param_3];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [input_reduce_fusion_316_param_2];
	cvta.to.global.u64 	%rd11, %rd10;
	cvta.to.global.u64 	%rd12, %rd7;
	cvta.to.global.u64 	%rd13, %rd5;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	shr.u32 	%r3, %r1, 1;
	and.b32  	%r4, %r1, 1;
	shl.b32 	%r5, %r2, 7;
	or.b32  	%r6, %r3, %r5;
	cvt.u16.u32 	%rs1, %r6;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs3, 63;
	shr.u16 	%rs7, %rs2, 7;
	shl.b16 	%rs8, %rs5, 1;
	cvt.u32.u16 	%r7, %rs8;
	or.b32  	%r8, %r4, %r7;
	cvt.u32.u16 	%r9, %rs7;
	mul.wide.u32 	%rd14, %r9, 1536;
	add.s64 	%rd15, %rd11, %rd14;
	cvt.u32.u16 	%r10, %rs6;
	mul.wide.u32 	%rd16, %r10, 24;
	add.s64 	%rd17, %rd15, %rd16;
	mul.wide.u32 	%rd18, %r8, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.nc.f32 	%f3, [%rd19];
	cvt.u32.u16 	%r11, %rs5;
	mul.wide.u32 	%rd20, %r11, 4;
	mul.wide.u32 	%rd21, %r9, 12;
	add.s64 	%rd22, %rd9, %rd21;
	add.s64 	%rd23, %rd22, %rd20;
	ld.global.nc.f32 	%f4, [%rd23];
	mul.rn.f32 	%f5, %f3, %f4;
	add.s64 	%rd24, %rd12, %rd14;
	add.s64 	%rd25, %rd24, %rd16;
	add.s64 	%rd26, %rd25, %rd18;
	ld.global.nc.f32 	%f6, [%rd26];
	add.s64 	%rd27, %rd13, %rd21;
	add.s64 	%rd28, %rd27, %rd20;
	ld.global.nc.f32 	%f7, [%rd28];
	mul.rn.f32 	%f8, %f6, %f7;
	add.rn.f32 	%f9, %f5, %f8;
	add.rn.f32 	%f1, %f9, 0f00000000;
	shfl.sync.down.b32	%f2, %f1, 1, 31, -1;
	setp.eq.s32 	%p1, %r4, 0;
	@%p1 bra 	$L__BB218_2;
	bra.uni 	$L__BB218_1;
$L__BB218_2:
	ld.param.u64 	%rd6, [input_reduce_fusion_316_param_4];
	cvta.to.global.u64 	%rd1, %rd6;
	cvt.u64.u16 	%rd2, %rs7;
	cvt.u64.u16 	%rd3, %rs6;
	cvt.u64.u16 	%rd4, %rs5;
	add.rn.f32 	%f10, %f1, %f2;
	mul.lo.s64 	%rd29, %rd2, 768;
	add.s64 	%rd30, %rd1, %rd29;
	shl.b64 	%rd31, %rd4, 8;
	add.s64 	%rd32, %rd30, %rd31;
	shl.b64 	%rd33, %rd3, 2;
	add.s64 	%rd34, %rd32, %rd33;
	st.global.f32 	[%rd34], %f10;
$L__BB218_1:
	ret;

}
	// .globl	input_reduce_fusion_317
.visible .entry input_reduce_fusion_317(
	.param .u64 input_reduce_fusion_317_param_0,
	.param .u64 input_reduce_fusion_317_param_1,
	.param .u64 input_reduce_fusion_317_param_2,
	.param .u64 input_reduce_fusion_317_param_3,
	.param .u64 input_reduce_fusion_317_param_4,
	.param .u64 input_reduce_fusion_317_param_5,
	.param .u64 input_reduce_fusion_317_param_6
)
.reqntid 1024, 1, 1
{
	.local .align 4 .b8 	__local_depot219[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<21>;
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<121>;
	.reg .f32 	%f<86>;
	.reg .b64 	%rd<117>;
	.reg .f64 	%fd<5>;
	// demoted variable
	.shared .align 4 .b8 shared_cache31[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache32[4224];
	mov.u64 	%SPL, __local_depot219;
	ld.param.u64 	%rd23, [input_reduce_fusion_317_param_0];
	ld.param.u64 	%rd24, [input_reduce_fusion_317_param_6];
	cvta.to.global.u64 	%rd1, %rd24;
	ld.param.u64 	%rd25, [input_reduce_fusion_317_param_1];
	ld.param.u64 	%rd26, [input_reduce_fusion_317_param_5];
	cvta.to.global.u64 	%rd2, %rd26;
	ld.param.u64 	%rd27, [input_reduce_fusion_317_param_2];
	ld.param.u64 	%rd28, [input_reduce_fusion_317_param_4];
	cvta.to.global.u64 	%rd29, %rd28;
	ld.param.u64 	%rd30, [input_reduce_fusion_317_param_3];
	cvta.to.global.u64 	%rd3, %rd30;
	cvta.to.global.u64 	%rd31, %rd27;
	cvta.to.global.u64 	%rd4, %rd25;
	cvta.to.global.u64 	%rd5, %rd23;
	add.u64 	%rd6, %SPL, 0;
	mov.u32 	%r33, %tid.x;
	mov.u32 	%r34, %ctaid.x;
	shr.u32 	%r1, %r33, 5;
	and.b32  	%r2, %r33, 31;
	cvt.u16.u32 	%rs1, %r34;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r3, %rs6;
	or.b32  	%r35, %r2, %r3;
	cvt.u16.u32 	%rs7, %r35;
	and.b16  	%rs8, %rs7, 255;
	mul.lo.s16 	%rs9, %rs8, 171;
	shr.u16 	%rs10, %rs9, 10;
	mul.lo.s16 	%rs11, %rs10, 6;
	sub.s16 	%rs12, %rs7, %rs11;
	cvt.u32.u16 	%r36, %rs12;
	cvt.u64.u16 	%rd8, %rs3;
	cvt.u32.u16 	%r37, %rs3;
	mul.wide.u32 	%rd34, %r37, 4;
	add.s64 	%rd35, %rd31, %rd34;
	ld.global.nc.f32 	%f1, [%rd35];
	cvt.u64.u16 	%rd9, %rs10;
	cvt.u64.u16 	%rd36, %rs12;
	and.b64  	%rd10, %rd36, 255;
	shl.b16 	%rs13, %rs10, 1;
	cvt.u64.u16 	%rd11, %rs13;
	bfe.u32 	%r38, %r36, 1, 7;
	cvt.u64.u32 	%rd12, %r38;
	mul.wide.u32 	%rd37, %r38, 4;
	mul.wide.u32 	%rd38, %r37, 12;
	add.s64 	%rd39, %rd29, %rd38;
	add.s64 	%rd40, %rd39, %rd37;
	ld.global.nc.f32 	%f17, [%rd40];
	mul.rn.f32 	%f18, %f17, 0f3F22F983;
	cvt.rni.s32.f32 	%r39, %f18;
	cvt.rn.f32.s32 	%f19, %r39;
	fma.rn.f32 	%f20, %f19, 0fBFC90FDA, %f17;
	fma.rn.f32 	%f21, %f19, 0fB3A22168, %f20;
	fma.rn.f32 	%f22, %f19, 0fA7C234C5, %f21;
	abs.f32 	%f23, %f17;
	setp.ltu.f32 	%p2, %f23, 0f47CE4780;
	setp.eq.f32 	%p3, %f23, 0f7F800000;
	mov.b32 	%r4, %f17;
	shr.u32 	%r40, %r4, 23;
	and.b32  	%r41, %r40, 224;
	add.s32 	%r42, %r41, -128;
	shl.b32 	%r43, %r4, 8;
	or.b32  	%r5, %r43, -2147483648;
	shr.u32 	%r44, %r42, 5;
	bfe.u32 	%r6, %r4, 23, 5;
	mul.wide.u32 	%rd41, %r44, 4;
	sub.s64 	%rd13, %rd6, %rd41;
	mov.b32 	%r45, 32;
	sub.s32 	%r7, %r45, %r6;
	mov.f32 	%f82, 0f00000000;
	mul.rn.f32 	%f24, %f17, %f82;
	and.b32  	%r46, %r36, 1;
	cvt.u64.u32 	%rd15, %r46;
	or.pred  	%p1, %p2, %p3;
	selp.b32 	%r8, %r39, 0, %p2;
	selp.f32 	%f2, %f22, %f24, %p2;
	shl.b64 	%rd48, %rd10, 2;
	mul.lo.s64 	%rd54, %rd11, 24;
	shl.b64 	%rd79, %rd12, 3;
	shl.b64 	%rd81, %rd15, 2;
	mov.u32 	%r112, %r1;
	mov.f32 	%f83, %f82;
	bra.uni 	$L__BB219_1;
$L__BB219_12:
	shr.u32 	%r84, %r118, 30;
	shr.u32 	%r85, %r119, 30;
	shl.b32 	%r86, %r118, 2;
	or.b32  	%r87, %r86, %r85;
	shl.b32 	%r88, %r119, 2;
	bfe.u32 	%r89, %r118, 29, 1;
	add.s32 	%r90, %r89, %r84;
	neg.s32 	%r91, %r90;
	selp.b32 	%r120, %r91, %r90, %p20;
	xor.b32  	%r92, %r87, %r4;
	bfe.s32 	%r93, %r118, 29, 1;
	xor.b32  	%r94, %r93, %r87;
	xor.b32  	%r95, %r93, %r88;
	cvt.u64.u32 	%rd69, %r94;
	shl.b64 	%rd70, %rd69, 32;
	cvt.u64.u32 	%rd71, %r95;
	or.b64  	%rd72, %rd70, %rd71;
	cvt.rn.f64.s64 	%fd3, %rd72;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f42, %fd4;
	neg.f32 	%f43, %f42;
	setp.lt.s32 	%p13, %r92, 0;
	selp.f32 	%f85, %f43, %f42, %p13;
$L__BB219_13:
	add.s32 	%r10, %r112, 32;
	cvt.u64.u32 	%rd16, %r112;
	add.rn.f32 	%f83, %f83, %f26;
	cvt.u32.u64 	%r96, %rd16;
	mul.rn.f32 	%f44, %f85, %f85;
	and.b32  	%r97, %r120, 1;
	setp.eq.b32 	%p14, %r97, 1;
	selp.f32 	%f45, 0f3F800000, %f85, %p14;
	fma.rn.f32 	%f46, %f44, %f45, 0f00000000;
	fma.rn.f32 	%f47, %f44, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f48, %f47, 0fB94D4153, %p14;
	selp.f32 	%f49, 0f3D2AAABB, 0f3C0885E4, %p14;
	fma.rn.f32 	%f50, %f48, %f44, %f49;
	selp.f32 	%f51, 0fBEFFFFFF, 0fBE2AAAA8, %p14;
	fma.rn.f32 	%f52, %f50, %f44, %f51;
	fma.rn.f32 	%f53, %f52, %f46, %f45;
	and.b32  	%r98, %r120, 2;
	setp.eq.s32 	%p15, %r98, 0;
	sub.rn.f32 	%f55, %f39, %f53;
	selp.f32 	%f56, %f53, %f55, %p15;
	add.s64 	%rd74, %rd3, %rd42;
	mul.lo.s64 	%rd75, %rd16, 768;
	add.s64 	%rd76, %rd74, %rd75;
	add.s64 	%rd78, %rd76, %rd46;
	add.s64 	%rd80, %rd78, %rd79;
	add.s64 	%rd82, %rd80, %rd81;
	ld.global.nc.f32 	%f57, [%rd82];
	mul.rn.f32 	%f58, %f57, %f56;
	add.rn.f32 	%f59, %f10, %f58;
	mul.rn.f32 	%f60, %f5, %f59;
	add.rn.f32 	%f82, %f82, %f60;
	setp.lt.u32 	%p16, %r96, 18;
	mov.u32 	%r112, %r10;
	@%p16 bra 	$L__BB219_1;
	bra.uni 	$L__BB219_14;
$L__BB219_1:
	mul.lo.s64 	%rd42, %rd8, 38400;
	add.s64 	%rd43, %rd4, %rd42;
	mul.wide.u32 	%rd44, %r112, 768;
	add.s64 	%rd45, %rd43, %rd44;
	mul.lo.s64 	%rd46, %rd9, 24;
	add.s64 	%rd47, %rd45, %rd46;
	add.s64 	%rd49, %rd47, %rd48;
	ld.global.nc.f32 	%f5, [%rd49];
	mul.rn.f32 	%f25, %f1, %f5;
	mul.lo.s64 	%rd50, %rd8, 76800;
	add.s64 	%rd51, %rd5, %rd50;
	mul.wide.u32 	%rd52, %r112, 1536;
	add.s64 	%rd53, %rd51, %rd52;
	add.s64 	%rd55, %rd53, %rd54;
	add.s64 	%rd56, %rd55, %rd48;
	ld.global.nc.f32 	%f6, [%rd56];
	mov.u64 	%rd114, __cudart_i2opi_f;
	setp.eq.s32 	%p19, %r6, 0;
	setp.lt.s32 	%p20, %r4, 0;
	mov.u32 	%r116, %r8;
	mov.f32 	%f84, %f2;
	@%p1 bra 	$L__BB219_7;
	mov.b32 	%r113, 0;
	mov.u64 	%rd115, 0;
$L__BB219_3:
	.pragma "nounroll";
	add.s64 	%rd59, %rd114, %rd115;
	ld.global.nc.u32 	%r50, [%rd59];
	// begin inline asm
	{
	mad.lo.cc.u32   %r48, %r50, %r5, %r113;
	madc.hi.u32     %r113, %r50, %r5,  0;
	}
	// end inline asm
	add.s64 	%rd60, %rd6, %rd115;
	st.local.u32 	[%rd60], %r48;
	add.s64 	%rd115, %rd115, 4;
	cvt.u32.u64 	%r53, %rd115;
	setp.ne.s32 	%p4, %r53, 24;
	@%p4 bra 	$L__BB219_3;
	st.local.u32 	[%rd6+24], %r113;
	ld.local.u32 	%r114, [%rd13+24];
	ld.local.u32 	%r115, [%rd13+20];
	@%p19 bra 	$L__BB219_6;
	shl.b32 	%r15, %r115, %r6;
	shl.b32 	%r54, %r114, %r6;
	shr.u32 	%r55, %r115, %r7;
	add.s32 	%r114, %r55, %r54;
	ld.local.u32 	%r56, [%rd13+16];
	shr.u32 	%r57, %r56, %r7;
	add.s32 	%r115, %r57, %r15;
$L__BB219_6:
	shr.u32 	%r58, %r114, 30;
	shr.u32 	%r59, %r115, 30;
	shl.b32 	%r60, %r114, 2;
	or.b32  	%r61, %r60, %r59;
	shl.b32 	%r62, %r115, 2;
	bfe.u32 	%r63, %r114, 29, 1;
	add.s32 	%r64, %r63, %r58;
	neg.s32 	%r65, %r64;
	selp.b32 	%r116, %r65, %r64, %p20;
	xor.b32  	%r66, %r61, %r4;
	bfe.s32 	%r67, %r114, 29, 1;
	xor.b32  	%r68, %r67, %r61;
	xor.b32  	%r69, %r67, %r62;
	cvt.u64.u32 	%rd61, %r68;
	shl.b64 	%rd62, %rd61, 32;
	cvt.u64.u32 	%rd63, %r69;
	or.b64  	%rd64, %rd62, %rd63;
	cvt.rn.f64.s64 	%fd1, %rd64;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f27, %fd2;
	neg.f32 	%f28, %f27;
	setp.lt.s32 	%p7, %r66, 0;
	selp.f32 	%f84, %f28, %f27, %p7;
$L__BB219_7:
	mul.rn.f32 	%f26, %f25, %f6;
	add.s32 	%r70, %r116, 1;
	mul.rn.f32 	%f29, %f84, %f84;
	and.b32  	%r71, %r116, 1;
	setp.eq.b32 	%p8, %r71, 1;
	selp.f32 	%f30, %f84, 0f3F800000, %p8;
	fma.rn.f32 	%f31, %f29, %f30, 0f00000000;
	fma.rn.f32 	%f32, %f29, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f33, 0fB94D4153, %f32, %p8;
	selp.f32 	%f34, 0f3C0885E4, 0f3D2AAABB, %p8;
	fma.rn.f32 	%f35, %f33, %f29, %f34;
	selp.f32 	%f36, 0fBE2AAAA8, 0fBEFFFFFF, %p8;
	fma.rn.f32 	%f37, %f35, %f29, %f36;
	fma.rn.f32 	%f38, %f37, %f31, %f30;
	and.b32  	%r72, %r70, 2;
	setp.eq.s32 	%p9, %r72, 0;
	mov.f32 	%f39, 0f00000000;
	sub.rn.f32 	%f40, %f39, %f38;
	selp.f32 	%f41, %f38, %f40, %p9;
	mul.rn.f32 	%f10, %f6, %f41;
	mov.u32 	%r120, %r8;
	mov.f32 	%f85, %f2;
	@%p1 bra 	$L__BB219_13;
	mov.b32 	%r117, 0;
	mov.u64 	%rd116, 0;
$L__BB219_9:
	.pragma "nounroll";
	add.s64 	%rd67, %rd114, %rd116;
	ld.global.nc.u32 	%r76, [%rd67];
	// begin inline asm
	{
	mad.lo.cc.u32   %r74, %r76, %r5, %r117;
	madc.hi.u32     %r117, %r76, %r5,  0;
	}
	// end inline asm
	add.s64 	%rd68, %rd6, %rd116;
	st.local.u32 	[%rd68], %r74;
	add.s64 	%rd116, %rd116, 4;
	cvt.u32.u64 	%r79, %rd116;
	setp.ne.s32 	%p10, %r79, 24;
	@%p10 bra 	$L__BB219_9;
	st.local.u32 	[%rd6+24], %r117;
	ld.local.u32 	%r118, [%rd13+24];
	ld.local.u32 	%r119, [%rd13+20];
	@%p19 bra 	$L__BB219_12;
	shl.b32 	%r26, %r119, %r6;
	shl.b32 	%r80, %r118, %r6;
	shr.u32 	%r81, %r119, %r7;
	add.s32 	%r118, %r81, %r80;
	ld.local.u32 	%r82, [%rd13+16];
	shr.u32 	%r83, %r82, %r7;
	add.s32 	%r119, %r83, %r26;
	bra.uni 	$L__BB219_12;
$L__BB219_14:
	cvt.u64.u32 	%rd21, %r2;
	cvt.u64.u32 	%rd22, %r1;
	mul.wide.u32 	%rd83, %r2, 132;
	mov.u64 	%rd84, shared_cache31;
	add.s64 	%rd85, %rd84, %rd83;
	mul.wide.u32 	%rd86, %r1, 4;
	add.s64 	%rd87, %rd85, %rd86;
	st.shared.f32 	[%rd87], %f83;
	bar.sync 	0;
	mul.wide.u32 	%rd88, %r1, 132;
	add.s64 	%rd89, %rd84, %rd88;
	mul.wide.u32 	%rd90, %r2, 4;
	add.s64 	%rd91, %rd89, %rd90;
	ld.shared.f32 	%f61, [%rd91];
	shfl.sync.down.b32	%f62, %f61, 16, 31, -1;
	add.rn.f32 	%f63, %f61, %f62;
	shfl.sync.down.b32	%f64, %f63, 8, 31, -1;
	add.rn.f32 	%f65, %f63, %f64;
	shfl.sync.down.b32	%f66, %f65, 4, 31, -1;
	add.rn.f32 	%f67, %f65, %f66;
	shfl.sync.down.b32	%f68, %f67, 2, 31, -1;
	add.rn.f32 	%f69, %f67, %f68;
	shfl.sync.down.b32	%f70, %f69, 1, 31, -1;
	add.rn.f32 	%f14, %f69, %f70;
	st.shared.f32 	[%rd91], %f14;
	setp.eq.s32 	%p17, %r2, 0;
	@%p17 bra 	$L__BB219_17;
	bra.uni 	$L__BB219_15;
$L__BB219_17:
	or.b32  	%r99, %r1, %r3;
	mul.hi.u32 	%r101, %r99, -1431655765;
	shr.u32 	%r102, %r101, 2;
	mul.lo.s32 	%r103, %r102, 6;
	sub.s32 	%r104, %r99, %r103;
	mul.lo.s64 	%rd92, %rd8, 768;
	add.s64 	%rd93, %rd2, %rd92;
	mul.wide.u32 	%rd94, %r102, 24;
	add.s64 	%rd95, %rd93, %rd94;
	mul.wide.u32 	%rd96, %r104, 4;
	add.s64 	%rd97, %rd95, %rd96;
	neg.f32 	%f71, %f14;
	st.global.f32 	[%rd97], %f71;
$L__BB219_15:
	mul.lo.s64 	%rd98, %rd21, 132;
	mov.u64 	%rd99, shared_cache32;
	add.s64 	%rd100, %rd99, %rd98;
	shl.b64 	%rd101, %rd22, 2;
	add.s64 	%rd102, %rd100, %rd101;
	st.shared.f32 	[%rd102], %f82;
	bar.sync 	0;
	mul.lo.s64 	%rd103, %rd22, 132;
	add.s64 	%rd104, %rd99, %rd103;
	shl.b64 	%rd105, %rd21, 2;
	add.s64 	%rd106, %rd104, %rd105;
	ld.shared.f32 	%f72, [%rd106];
	shfl.sync.down.b32	%f73, %f72, 16, 31, -1;
	add.rn.f32 	%f74, %f72, %f73;
	shfl.sync.down.b32	%f75, %f74, 8, 31, -1;
	add.rn.f32 	%f76, %f74, %f75;
	shfl.sync.down.b32	%f77, %f76, 4, 31, -1;
	add.rn.f32 	%f78, %f76, %f77;
	shfl.sync.down.b32	%f79, %f78, 2, 31, -1;
	add.rn.f32 	%f80, %f78, %f79;
	shfl.sync.down.b32	%f81, %f80, 1, 31, -1;
	add.rn.f32 	%f15, %f80, %f81;
	st.shared.f32 	[%rd106], %f15;
	@%p17 bra 	$L__BB219_18;
	bra.uni 	$L__BB219_16;
$L__BB219_18:
	or.b32  	%r105, %r1, %r3;
	mul.hi.u32 	%r107, %r105, -1431655765;
	shr.u32 	%r108, %r107, 2;
	mul.lo.s32 	%r109, %r108, 6;
	sub.s32 	%r110, %r105, %r109;
	mul.lo.s64 	%rd107, %rd8, 768;
	add.s64 	%rd108, %rd1, %rd107;
	mul.wide.u32 	%rd109, %r108, 24;
	add.s64 	%rd110, %rd108, %rd109;
	mul.wide.u32 	%rd111, %r110, 4;
	add.s64 	%rd112, %rd110, %rd111;
	st.global.f32 	[%rd112], %f15;
$L__BB219_16:
	ret;

}
	// .globl	input_reduce_fusion_318
.visible .entry input_reduce_fusion_318(
	.param .u64 input_reduce_fusion_318_param_0,
	.param .u64 input_reduce_fusion_318_param_1,
	.param .u64 input_reduce_fusion_318_param_2,
	.param .u64 input_reduce_fusion_318_param_3
)
.reqntid 256, 1, 1
{
	.local .align 4 .b8 	__local_depot220[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<19>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<122>;
	.reg .f32 	%f<57>;
	.reg .b64 	%rd<64>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot220;
	ld.param.u64 	%rd14, [input_reduce_fusion_318_param_0];
	ld.param.u64 	%rd16, [input_reduce_fusion_318_param_1];
	ld.param.u64 	%rd17, [input_reduce_fusion_318_param_2];
	cvta.to.global.u64 	%rd18, %rd17;
	cvta.to.global.u64 	%rd19, %rd16;
	cvta.to.global.u64 	%rd2, %rd14;
	add.u64 	%rd3, %SPL, 0;
	mov.u32 	%r34, %tid.x;
	mov.u32 	%r35, %ctaid.x;
	shr.u32 	%r36, %r34, 1;
	and.b32  	%r1, %r34, 1;
	shl.b32 	%r37, %r35, 7;
	or.b32  	%r2, %r36, %r37;
	cvt.u16.u32 	%rs1, %r2;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs3, 31;
	shr.u16 	%rs7, %rs2, 6;
	shl.b16 	%rs8, %rs5, 1;
	cvt.u32.u16 	%r38, %rs8;
	or.b32  	%r39, %r1, %r38;
	cvt.u64.u16 	%rd5, %rs7;
	cvt.u64.u16 	%rd6, %rs6;
	cvt.u64.u32 	%rd7, %r39;
	cvt.u32.u16 	%r40, %rs7;
	mul.wide.u32 	%rd22, %r40, 768;
	add.s64 	%rd23, %rd19, %rd22;
	cvt.u32.u16 	%r41, %rs6;
	mul.wide.u32 	%rd24, %r41, 24;
	add.s64 	%rd25, %rd23, %rd24;
	mul.wide.u32 	%rd26, %r39, 4;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.f32 	%f1, [%rd27];
	cvt.u32.u16 	%r42, %rs5;
	mul.wide.u32 	%rd28, %r42, 4;
	mul.wide.u32 	%rd29, %r40, 12;
	add.s64 	%rd30, %rd18, %rd29;
	add.s64 	%rd31, %rd30, %rd28;
	ld.global.nc.f32 	%f2, [%rd31];
	mul.rn.f32 	%f15, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r121, %f15;
	cvt.rn.f32.s32 	%f16, %r121;
	fma.rn.f32 	%f17, %f16, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f18, %f16, 0fB3A22168, %f17;
	fma.rn.f32 	%f56, %f16, 0fA7C234C5, %f18;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p1, %f4, 0f47CE4780;
	mov.f32 	%f54, 0f00000000;
	setp.neu.f32 	%p18, %f4, 0f7F800000;
	mov.u32 	%r117, %r121;
	mov.f32 	%f55, %f56;
	@%p1 bra 	$L__BB220_8;
	@%p18 bra 	$L__BB220_3;
	mul.rn.f32 	%f55, %f2, %f54;
	mov.b32 	%r117, 0;
	bra.uni 	$L__BB220_8;
$L__BB220_3:
	mov.b32 	%r4, %f2;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r44, %r5, 224;
	add.s32 	%r45, %r44, -128;
	shl.b32 	%r46, %r4, 8;
	or.b32  	%r50, %r46, -2147483648;
	shr.u32 	%r7, %r45, 5;
	mov.b32 	%r114, 0;
	mov.u64 	%rd62, 0;
	mov.u64 	%rd33, __cudart_i2opi_f;
$L__BB220_4:
	.pragma "nounroll";
	add.s64 	%rd34, %rd33, %rd62;
	ld.global.nc.u32 	%r49, [%rd34];
	// begin inline asm
	{
	mad.lo.cc.u32   %r47, %r49, %r50, %r114;
	madc.hi.u32     %r114, %r49, %r50,  0;
	}
	// end inline asm
	add.s64 	%rd35, %rd3, %rd62;
	st.local.u32 	[%rd35], %r47;
	add.s64 	%rd62, %rd62, 4;
	cvt.u32.u64 	%r52, %rd62;
	setp.ne.s32 	%p3, %r52, 24;
	@%p3 bra 	$L__BB220_4;
	st.local.u32 	[%rd3+24], %r114;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd36, %r7, 4;
	sub.s64 	%rd10, %rd3, %rd36;
	ld.local.u32 	%r115, [%rd10+24];
	ld.local.u32 	%r116, [%rd10+20];
	setp.eq.s32 	%p4, %r10, 0;
	@%p4 bra 	$L__BB220_7;
	shl.b32 	%r53, %r116, %r10;
	shl.b32 	%r54, %r115, %r10;
	mov.b32 	%r55, 32;
	sub.s32 	%r56, %r55, %r10;
	shr.u32 	%r57, %r116, %r56;
	add.s32 	%r115, %r57, %r54;
	ld.local.u32 	%r58, [%rd10+16];
	shr.u32 	%r59, %r58, %r56;
	add.s32 	%r116, %r59, %r53;
$L__BB220_7:
	shr.u32 	%r60, %r115, 30;
	shr.u32 	%r61, %r116, 30;
	shl.b32 	%r62, %r115, 2;
	or.b32  	%r63, %r62, %r61;
	shl.b32 	%r64, %r116, 2;
	bfe.u32 	%r65, %r115, 29, 1;
	add.s32 	%r66, %r65, %r60;
	neg.s32 	%r67, %r66;
	setp.lt.s32 	%p5, %r4, 0;
	selp.b32 	%r117, %r67, %r66, %p5;
	xor.b32  	%r68, %r63, %r4;
	bfe.s32 	%r69, %r115, 29, 1;
	xor.b32  	%r70, %r69, %r63;
	xor.b32  	%r71, %r69, %r64;
	cvt.u64.u32 	%rd37, %r70;
	shl.b64 	%rd38, %rd37, 32;
	cvt.u64.u32 	%rd39, %r71;
	or.b64  	%rd40, %rd38, %rd39;
	cvt.rn.f64.s64 	%fd1, %rd40;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f19, %fd2;
	neg.f32 	%f20, %f19;
	setp.lt.s32 	%p6, %r68, 0;
	selp.f32 	%f55, %f20, %f19, %p6;
$L__BB220_8:
	add.s32 	%r73, %r117, 1;
	mul.rn.f32 	%f22, %f55, %f55;
	and.b32  	%r74, %r117, 1;
	setp.eq.b32 	%p8, %r74, 1;
	selp.f32 	%f23, %f55, 0f3F800000, %p8;
	fma.rn.f32 	%f24, %f22, %f23, 0f00000000;
	fma.rn.f32 	%f25, %f22, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f26, 0fB94D4153, %f25, %p8;
	selp.f32 	%f27, 0f3C0885E4, 0f3D2AAABB, %p8;
	fma.rn.f32 	%f28, %f26, %f22, %f27;
	selp.f32 	%f29, 0fBE2AAAA8, 0fBEFFFFFF, %p8;
	fma.rn.f32 	%f30, %f28, %f22, %f29;
	fma.rn.f32 	%f31, %f30, %f24, %f23;
	and.b32  	%r75, %r73, 2;
	setp.eq.s32 	%p9, %r75, 0;
	sub.rn.f32 	%f33, %f54, %f31;
	selp.f32 	%f34, %f31, %f33, %p9;
	mul.rn.f32 	%f8, %f1, %f34;
	mul.lo.s64 	%rd41, %rd5, 768;
	add.s64 	%rd42, %rd2, %rd41;
	mul.lo.s64 	%rd43, %rd6, 24;
	add.s64 	%rd44, %rd42, %rd43;
	shl.b64 	%rd45, %rd7, 2;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.nc.f32 	%f9, [%rd46];
	@%p1 bra 	$L__BB220_16;
	@%p18 bra 	$L__BB220_11;
	mul.rn.f32 	%f56, %f2, %f54;
	mov.b32 	%r121, 0;
	bra.uni 	$L__BB220_16;
$L__BB220_11:
	mov.b32 	%r19, %f2;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r77, %r20, 224;
	add.s32 	%r78, %r77, -128;
	shl.b32 	%r79, %r19, 8;
	or.b32  	%r83, %r79, -2147483648;
	shr.u32 	%r22, %r78, 5;
	mov.b32 	%r118, 0;
	mov.u64 	%rd63, 0;
	mov.u64 	%rd48, __cudart_i2opi_f;
$L__BB220_12:
	.pragma "nounroll";
	add.s64 	%rd49, %rd48, %rd63;
	ld.global.nc.u32 	%r82, [%rd49];
	// begin inline asm
	{
	mad.lo.cc.u32   %r80, %r82, %r83, %r118;
	madc.hi.u32     %r118, %r82, %r83,  0;
	}
	// end inline asm
	add.s64 	%rd50, %rd3, %rd63;
	st.local.u32 	[%rd50], %r80;
	add.s64 	%rd63, %rd63, 4;
	cvt.u32.u64 	%r85, %rd63;
	setp.ne.s32 	%p11, %r85, 24;
	@%p11 bra 	$L__BB220_12;
	st.local.u32 	[%rd3+24], %r118;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd51, %r22, 4;
	sub.s64 	%rd13, %rd3, %rd51;
	ld.local.u32 	%r119, [%rd13+24];
	ld.local.u32 	%r120, [%rd13+20];
	setp.eq.s32 	%p12, %r25, 0;
	@%p12 bra 	$L__BB220_15;
	shl.b32 	%r86, %r120, %r25;
	shl.b32 	%r87, %r119, %r25;
	mov.b32 	%r88, 32;
	sub.s32 	%r89, %r88, %r25;
	shr.u32 	%r90, %r120, %r89;
	add.s32 	%r119, %r90, %r87;
	ld.local.u32 	%r91, [%rd13+16];
	shr.u32 	%r92, %r91, %r89;
	add.s32 	%r120, %r92, %r86;
$L__BB220_15:
	shr.u32 	%r93, %r119, 30;
	shr.u32 	%r94, %r120, 30;
	shl.b32 	%r95, %r119, 2;
	or.b32  	%r96, %r95, %r94;
	shl.b32 	%r97, %r120, 2;
	bfe.u32 	%r98, %r119, 29, 1;
	add.s32 	%r99, %r98, %r93;
	neg.s32 	%r100, %r99;
	setp.lt.s32 	%p13, %r19, 0;
	selp.b32 	%r121, %r100, %r99, %p13;
	xor.b32  	%r101, %r96, %r19;
	bfe.s32 	%r102, %r119, 29, 1;
	xor.b32  	%r103, %r102, %r96;
	xor.b32  	%r104, %r102, %r97;
	cvt.u64.u32 	%rd52, %r103;
	shl.b64 	%rd53, %rd52, 32;
	cvt.u64.u32 	%rd54, %r104;
	or.b64  	%rd55, %rd53, %rd54;
	cvt.rn.f64.s64 	%fd3, %rd55;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f35, %fd4;
	neg.f32 	%f36, %f35;
	setp.lt.s32 	%p14, %r101, 0;
	selp.f32 	%f56, %f36, %f35, %p14;
$L__BB220_16:
	mul.rn.f32 	%f38, %f56, %f56;
	and.b32  	%r106, %r121, 1;
	setp.eq.b32 	%p15, %r106, 1;
	selp.f32 	%f39, 0f3F800000, %f56, %p15;
	fma.rn.f32 	%f40, %f38, %f39, 0f00000000;
	fma.rn.f32 	%f41, %f38, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f42, %f41, 0fB94D4153, %p15;
	selp.f32 	%f43, 0f3D2AAABB, 0f3C0885E4, %p15;
	fma.rn.f32 	%f44, %f42, %f38, %f43;
	selp.f32 	%f45, 0fBEFFFFFF, 0fBE2AAAA8, %p15;
	fma.rn.f32 	%f46, %f44, %f38, %f45;
	fma.rn.f32 	%f47, %f46, %f40, %f39;
	and.b32  	%r107, %r121, 2;
	setp.eq.s32 	%p16, %r107, 0;
	sub.rn.f32 	%f49, %f54, %f47;
	selp.f32 	%f50, %f47, %f49, %p16;
	mul.rn.f32 	%f51, %f9, %f50;
	add.rn.f32 	%f52, %f8, %f51;
	add.rn.f32 	%f13, %f52, 0f00000000;
	shfl.sync.down.b32	%f14, %f13, 1, 31, -1;
	setp.ne.s32 	%p17, %r1, 0;
	@%p17 bra 	$L__BB220_18;
	ld.param.u64 	%rd15, [input_reduce_fusion_318_param_3];
	cvta.to.global.u64 	%rd1, %rd15;
	add.rn.f32 	%f53, %f13, %f14;
	mul.hi.u32 	%r108, %r2, 1431655766;
	mul.lo.s32 	%r109, %r108, 3;
	sub.s32 	%r110, %r2, %r109;
	and.b32  	%r111, %r108, 31;
	mul.hi.u32 	%r112, %r2, 715827883;
	shr.u32 	%r113, %r112, 4;
	mul.wide.u32 	%rd56, %r113, 384;
	add.s64 	%rd57, %rd1, %rd56;
	mul.wide.u32 	%rd58, %r110, 128;
	add.s64 	%rd59, %rd57, %rd58;
	mul.wide.u32 	%rd60, %r111, 4;
	add.s64 	%rd61, %rd59, %rd60;
	st.global.f32 	[%rd61], %f53;
$L__BB220_18:
	ret;

}
	// .globl	input_concatenate_fusion_324
.visible .entry input_concatenate_fusion_324(
	.param .u64 input_concatenate_fusion_324_param_0,
	.param .u64 input_concatenate_fusion_324_param_1,
	.param .u64 input_concatenate_fusion_324_param_2,
	.param .u64 input_concatenate_fusion_324_param_3,
	.param .u64 input_concatenate_fusion_324_param_4,
	.param .u64 input_concatenate_fusion_324_param_5
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot221[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<36>;
	.reg .b16 	%rs<18>;
	.reg .b32 	%r<225>;
	.reg .f32 	%f<169>;
	.reg .b64 	%rd<124>;
	.reg .f64 	%fd<9>;

	mov.u64 	%SPL, __local_depot221;
	ld.param.u64 	%rd30, [input_concatenate_fusion_324_param_0];
	ld.param.u64 	%rd31, [input_concatenate_fusion_324_param_5];
	ld.param.u64 	%rd32, [input_concatenate_fusion_324_param_1];
	ld.param.u64 	%rd33, [input_concatenate_fusion_324_param_4];
	cvta.to.global.u64 	%rd2, %rd33;
	ld.param.u64 	%rd34, [input_concatenate_fusion_324_param_2];
	ld.param.u64 	%rd35, [input_concatenate_fusion_324_param_3];
	cvta.to.global.u64 	%rd4, %rd34;
	cvta.to.global.u64 	%rd36, %rd32;
	cvta.to.global.u64 	%rd37, %rd30;
	add.u64 	%rd5, %SPL, 0;
	mov.u32 	%r63, %ctaid.x;
	mov.u32 	%r64, %tid.x;
	shl.b32 	%r65, %r63, 7;
	or.b32  	%r66, %r65, %r64;
	cvt.u16.u32 	%rs3, %r66;
	mul.hi.u16 	%rs4, %rs3, -21845;
	shr.u16 	%rs5, %rs4, 1;
	mul.lo.s16 	%rs6, %rs5, 3;
	sub.s16 	%rs1, %rs3, %rs6;
	mul.hi.u16 	%rs7, %rs5, 5243;
	shr.u16 	%rs8, %rs7, 2;
	mul.lo.s16 	%rs9, %rs8, 50;
	sub.s16 	%rs10, %rs5, %rs9;
	shr.u16 	%rs11, %rs3, 1;
	mul.hi.u16 	%rs12, %rs11, -9611;
	shr.u16 	%rs13, %rs12, 6;
	and.b16  	%rs14, %rs13, 63;
	shl.b16 	%rs15, %rs1, 1;
	cvt.u64.u16 	%rd9, %rs14;
	cvt.u32.u16 	%r67, %rs14;
	mul.wide.u32 	%rd42, %r67, 4;
	add.s64 	%rd43, %rd36, %rd42;
	ld.global.nc.f32 	%f25, [%rd43];
	fma.rn.f32 	%f26, %f25, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f27, %f26;
	mov.f32 	%f28, 0f4B400001;
	mov.f32 	%f29, 0f437C0000;
	fma.rm.f32 	%f30, %f27, %f29, %f28;
	add.rn.f32 	%f31, %f30, 0fCB40007F;
	neg.f32 	%f32, %f31;
	fma.rn.f32 	%f33, %f25, 0f3FB8AA3B, %f32;
	fma.rn.f32 	%f34, %f25, 0f32A57060, %f33;
	mov.b32 	%r68, %f30;
	shl.b32 	%r69, %r68, 23;
	mov.b32 	%f35, %r69;
	ex2.approx.ftz.f32 	%f36, %f34;
	mul.rn.f32 	%f37, %f36, %f35;
	neg.f32 	%f38, %f37;
	sub.rn.f32 	%f39, %f38, %f37;
	add.rn.f32 	%f40, %f39, %f39;
	add.rn.f32 	%f41, %f40, %f40;
	add.rn.f32 	%f42, %f41, %f41;
	add.rn.f32 	%f43, %f42, %f42;
	add.rn.f32 	%f44, %f43, %f43;
	add.rn.f32 	%f45, %f44, %f44;
	add.rn.f32 	%f46, %f45, %f45;
	add.rn.f32 	%f47, %f46, %f46;
	fma.rn.f32 	%f48, %f47, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f49, %f48;
	fma.rm.f32 	%f50, %f49, %f29, %f28;
	add.rn.f32 	%f51, %f50, 0fCB40007F;
	neg.f32 	%f52, %f51;
	fma.rn.f32 	%f53, %f47, 0f3FB8AA3B, %f52;
	fma.rn.f32 	%f54, %f47, 0f32A57060, %f53;
	mov.b32 	%r70, %f50;
	shl.b32 	%r71, %r70, 23;
	mov.b32 	%f55, %r71;
	ex2.approx.ftz.f32 	%f56, %f54;
	mul.rn.f32 	%f1, %f56, %f55;
	cvt.u64.u16 	%rd10, %rs10;
	cvt.u32.u16 	%r72, %rs10;
	mul.wide.u32 	%rd44, %r72, 48;
	mul.wide.u32 	%rd45, %r67, 2400;
	add.s64 	%rd46, %rd37, %rd45;
	add.s64 	%rd47, %rd46, %rd44;
	cvt.u32.u16 	%r73, %rs15;
	mul.wide.u32 	%rd48, %r73, 4;
	add.s64 	%rd12, %rd47, %rd48;
	ld.global.nc.f32 	%f57, [%rd12+24];
	or.b16  	%rs16, %rs15, 1;
	setp.gt.u16 	%p1, %rs1, 1;
	selp.b16 	%rs2, 5, %rs16, %p1;
	fma.rn.f32 	%f58, %f46, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f59, %f58;
	fma.rm.f32 	%f60, %f59, %f29, %f28;
	add.rn.f32 	%f61, %f60, 0fCB40007F;
	neg.f32 	%f62, %f61;
	fma.rn.f32 	%f63, %f46, 0f3FB8AA3B, %f62;
	fma.rn.f32 	%f64, %f46, 0f32A57060, %f63;
	mov.b32 	%r74, %f60;
	shl.b32 	%r75, %r74, 23;
	mov.b32 	%f65, %r75;
	ex2.approx.ftz.f32 	%f66, %f64;
	shr.u16 	%rs17, %rs2, 1;
	cvt.u32.u16 	%r76, %rs17;
	mul.wide.u32 	%rd49, %r76, 4;
	mul.wide.u32 	%rd50, %r67, 12;
	add.s64 	%rd51, %rd2, %rd50;
	add.s64 	%rd52, %rd51, %rd49;
	ld.global.nc.f32 	%f67, [%rd52];
	add.rn.f32 	%f68, %f67, %f67;
	add.rn.f32 	%f69, %f68, %f68;
	add.rn.f32 	%f70, %f69, %f69;
	add.rn.f32 	%f4, %f70, %f70;
	mul.rn.f32 	%f71, %f4, 0f3F22F983;
	cvt.rni.s32.f32 	%r216, %f71;
	cvt.rn.f32.s32 	%f72, %r216;
	fma.rn.f32 	%f73, %f72, 0fBFC90FDA, %f4;
	fma.rn.f32 	%f74, %f72, 0fB3A22168, %f73;
	fma.rn.f32 	%f166, %f72, 0fA7C234C5, %f74;
	abs.f32 	%f6, %f4;
	setp.ltu.f32 	%p2, %f6, 0f47CE4780;
	mov.f32 	%f164, 0f00000000;
	setp.neu.f32 	%p34, %f6, 0f7F800000;
	mov.u32 	%r212, %r216;
	mov.f32 	%f165, %f166;
	@%p2 bra 	$L__BB221_8;
	@%p34 bra 	$L__BB221_3;
	mul.rn.f32 	%f165, %f4, %f164;
	mov.b32 	%r212, 0;
	bra.uni 	$L__BB221_8;
$L__BB221_3:
	mov.b32 	%r2, %f4;
	shr.u32 	%r3, %r2, 23;
	and.b32  	%r78, %r3, 224;
	add.s32 	%r79, %r78, -128;
	shl.b32 	%r80, %r2, 8;
	or.b32  	%r84, %r80, -2147483648;
	shr.u32 	%r5, %r79, 5;
	mov.b32 	%r209, 0;
	mov.u64 	%rd120, 0;
	mov.u64 	%rd54, __cudart_i2opi_f;
$L__BB221_4:
	.pragma "nounroll";
	add.s64 	%rd55, %rd54, %rd120;
	ld.global.nc.u32 	%r83, [%rd55];
	// begin inline asm
	{
	mad.lo.cc.u32   %r81, %r83, %r84, %r209;
	madc.hi.u32     %r209, %r83, %r84,  0;
	}
	// end inline asm
	add.s64 	%rd56, %rd5, %rd120;
	st.local.u32 	[%rd56], %r81;
	add.s64 	%rd120, %rd120, 4;
	cvt.u32.u64 	%r86, %rd120;
	setp.ne.s32 	%p4, %r86, 24;
	@%p4 bra 	$L__BB221_4;
	st.local.u32 	[%rd5+24], %r209;
	and.b32  	%r8, %r3, 31;
	mul.wide.u32 	%rd57, %r5, 4;
	sub.s64 	%rd16, %rd5, %rd57;
	ld.local.u32 	%r210, [%rd16+24];
	ld.local.u32 	%r211, [%rd16+20];
	setp.eq.s32 	%p5, %r8, 0;
	@%p5 bra 	$L__BB221_7;
	shl.b32 	%r87, %r211, %r8;
	shl.b32 	%r88, %r210, %r8;
	mov.b32 	%r89, 32;
	sub.s32 	%r90, %r89, %r8;
	shr.u32 	%r91, %r211, %r90;
	add.s32 	%r210, %r91, %r88;
	ld.local.u32 	%r92, [%rd16+16];
	shr.u32 	%r93, %r92, %r90;
	add.s32 	%r211, %r93, %r87;
$L__BB221_7:
	shr.u32 	%r94, %r210, 30;
	shr.u32 	%r95, %r211, 30;
	shl.b32 	%r96, %r210, 2;
	or.b32  	%r97, %r96, %r95;
	shl.b32 	%r98, %r211, 2;
	bfe.u32 	%r99, %r210, 29, 1;
	add.s32 	%r100, %r99, %r94;
	neg.s32 	%r101, %r100;
	setp.lt.s32 	%p6, %r2, 0;
	selp.b32 	%r212, %r101, %r100, %p6;
	xor.b32  	%r102, %r97, %r2;
	bfe.s32 	%r103, %r210, 29, 1;
	xor.b32  	%r104, %r103, %r97;
	xor.b32  	%r105, %r103, %r98;
	cvt.u64.u32 	%rd58, %r104;
	shl.b64 	%rd59, %rd58, 32;
	cvt.u64.u32 	%rd60, %r105;
	or.b64  	%rd61, %rd59, %rd60;
	cvt.rn.f64.s64 	%fd1, %rd61;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f75, %fd2;
	neg.f32 	%f76, %f75;
	setp.lt.s32 	%p7, %r102, 0;
	selp.f32 	%f165, %f76, %f75, %p7;
$L__BB221_8:
	cvta.to.global.u64 	%rd1, %rd31;
	cvta.to.global.u64 	%rd3, %rd35;
	cvt.u64.u16 	%rd11, %rs15;
	mul.rn.f32 	%f2, %f57, %f1;
	mul.rn.f32 	%f3, %f66, %f65;
	cvt.u64.u16 	%rd13, %rs17;
	add.s32 	%r107, %r212, 1;
	mul.rn.f32 	%f78, %f165, %f165;
	and.b32  	%r108, %r212, 1;
	setp.eq.b32 	%p9, %r108, 1;
	selp.f32 	%f79, %f165, 0f3F800000, %p9;
	fma.rn.f32 	%f80, %f78, %f79, 0f00000000;
	fma.rn.f32 	%f81, %f78, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f82, 0fB94D4153, %f81, %p9;
	selp.f32 	%f83, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f84, %f82, %f78, %f83;
	selp.f32 	%f85, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f86, %f84, %f78, %f85;
	fma.rn.f32 	%f87, %f86, %f80, %f79;
	and.b32  	%r109, %r107, 2;
	setp.eq.s32 	%p10, %r109, 0;
	sub.rn.f32 	%f89, %f164, %f87;
	selp.f32 	%f90, %f87, %f89, %p10;
	mul.lo.s64 	%rd62, %rd9, 4800;
	add.s64 	%rd63, %rd4, %rd62;
	mul.lo.s64 	%rd64, %rd10, 96;
	add.s64 	%rd65, %rd63, %rd64;
	cvt.u32.u16 	%r110, %rs2;
	mul.wide.u32 	%rd66, %r110, 4;
	add.s64 	%rd17, %rd65, %rd66;
	ld.global.nc.f32 	%f91, [%rd17];
	mul.rn.f32 	%f10, %f91, %f90;
	@%p2 bra 	$L__BB221_16;
	@%p34 bra 	$L__BB221_11;
	mul.rn.f32 	%f166, %f4, %f164;
	mov.b32 	%r216, 0;
	bra.uni 	$L__BB221_16;
$L__BB221_11:
	mov.b32 	%r17, %f4;
	shr.u32 	%r18, %r17, 23;
	and.b32  	%r112, %r18, 224;
	add.s32 	%r113, %r112, -128;
	shl.b32 	%r114, %r17, 8;
	or.b32  	%r118, %r114, -2147483648;
	shr.u32 	%r20, %r113, 5;
	mov.b32 	%r213, 0;
	mov.u64 	%rd121, 0;
	mov.u64 	%rd68, __cudart_i2opi_f;
$L__BB221_12:
	.pragma "nounroll";
	add.s64 	%rd69, %rd68, %rd121;
	ld.global.nc.u32 	%r117, [%rd69];
	// begin inline asm
	{
	mad.lo.cc.u32   %r115, %r117, %r118, %r213;
	madc.hi.u32     %r213, %r117, %r118,  0;
	}
	// end inline asm
	add.s64 	%rd70, %rd5, %rd121;
	st.local.u32 	[%rd70], %r115;
	add.s64 	%rd121, %rd121, 4;
	cvt.u32.u64 	%r120, %rd121;
	setp.ne.s32 	%p12, %r120, 24;
	@%p12 bra 	$L__BB221_12;
	st.local.u32 	[%rd5+24], %r213;
	and.b32  	%r23, %r18, 31;
	mul.wide.u32 	%rd71, %r20, 4;
	sub.s64 	%rd20, %rd5, %rd71;
	ld.local.u32 	%r214, [%rd20+24];
	ld.local.u32 	%r215, [%rd20+20];
	setp.eq.s32 	%p13, %r23, 0;
	@%p13 bra 	$L__BB221_15;
	shl.b32 	%r121, %r215, %r23;
	shl.b32 	%r122, %r214, %r23;
	mov.b32 	%r123, 32;
	sub.s32 	%r124, %r123, %r23;
	shr.u32 	%r125, %r215, %r124;
	add.s32 	%r214, %r125, %r122;
	ld.local.u32 	%r126, [%rd20+16];
	shr.u32 	%r127, %r126, %r124;
	add.s32 	%r215, %r127, %r121;
$L__BB221_15:
	shr.u32 	%r128, %r214, 30;
	shr.u32 	%r129, %r215, 30;
	shl.b32 	%r130, %r214, 2;
	or.b32  	%r131, %r130, %r129;
	shl.b32 	%r132, %r215, 2;
	bfe.u32 	%r133, %r214, 29, 1;
	add.s32 	%r134, %r133, %r128;
	neg.s32 	%r135, %r134;
	setp.lt.s32 	%p14, %r17, 0;
	selp.b32 	%r216, %r135, %r134, %p14;
	xor.b32  	%r136, %r131, %r17;
	bfe.s32 	%r137, %r214, 29, 1;
	xor.b32  	%r138, %r137, %r131;
	xor.b32  	%r139, %r137, %r132;
	cvt.u64.u32 	%rd72, %r138;
	shl.b64 	%rd73, %rd72, 32;
	cvt.u64.u32 	%rd74, %r139;
	or.b64  	%rd75, %rd73, %rd74;
	cvt.rn.f64.s64 	%fd3, %rd75;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f92, %fd4;
	neg.f32 	%f93, %f92;
	setp.lt.s32 	%p15, %r136, 0;
	selp.f32 	%f166, %f93, %f92, %p15;
$L__BB221_16:
	mul.rn.f32 	%f95, %f166, %f166;
	and.b32  	%r141, %r216, 1;
	setp.eq.b32 	%p16, %r141, 1;
	selp.f32 	%f96, 0f3F800000, %f166, %p16;
	fma.rn.f32 	%f97, %f95, %f96, 0f00000000;
	fma.rn.f32 	%f98, %f95, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f99, %f98, 0fB94D4153, %p16;
	selp.f32 	%f100, 0f3D2AAABB, 0f3C0885E4, %p16;
	fma.rn.f32 	%f101, %f99, %f95, %f100;
	selp.f32 	%f102, 0fBEFFFFFF, 0fBE2AAAA8, %p16;
	fma.rn.f32 	%f103, %f101, %f95, %f102;
	fma.rn.f32 	%f104, %f103, %f97, %f96;
	and.b32  	%r142, %r216, 2;
	setp.eq.s32 	%p17, %r142, 0;
	sub.rn.f32 	%f106, %f164, %f104;
	selp.f32 	%f107, %f104, %f106, %p17;
	mul.lo.s64 	%rd76, %rd9, 2400;
	add.s64 	%rd77, %rd3, %rd76;
	mul.lo.s64 	%rd78, %rd10, 48;
	add.s64 	%rd79, %rd77, %rd78;
	shl.b64 	%rd80, %rd13, 3;
	add.s64 	%rd81, %rd79, %rd80;
	ld.global.nc.f32 	%f108, [%rd81+4];
	mul.rn.f32 	%f109, %f108, %f107;
	add.rn.f32 	%f110, %f10, %f109;
	mul.rn.f32 	%f111, %f3, %f110;
	ld.global.nc.f32 	%f112, [%rd17+24];
	add.rn.f32 	%f113, %f112, %f111;
	neg.f32 	%f114, %f113;
	mul.rn.f32 	%f115, %f2, %f114;
	mul.lo.s64 	%rd82, %rd9, 1200;
	add.s64 	%rd83, %rd1, %rd82;
	mul.lo.s64 	%rd84, %rd10, 24;
	add.s64 	%rd85, %rd83, %rd84;
	shl.b64 	%rd86, %rd11, 2;
	add.s64 	%rd21, %rd85, %rd86;
	st.global.f32 	[%rd21], %f115;
	ld.global.nc.f32 	%f14, [%rd12+28];
	mul.lo.s64 	%rd87, %rd9, 12;
	add.s64 	%rd88, %rd2, %rd87;
	cvt.u32.u16 	%r143, %rs1;
	mul.wide.u32 	%rd89, %r143, 4;
	add.s64 	%rd90, %rd88, %rd89;
	ld.global.nc.f32 	%f116, [%rd90];
	add.rn.f32 	%f117, %f116, %f116;
	add.rn.f32 	%f118, %f117, %f117;
	add.rn.f32 	%f119, %f118, %f118;
	add.rn.f32 	%f15, %f119, %f119;
	mul.rn.f32 	%f120, %f15, 0f3F22F983;
	cvt.rni.s32.f32 	%r224, %f120;
	cvt.rn.f32.s32 	%f121, %r224;
	fma.rn.f32 	%f122, %f121, 0fBFC90FDA, %f15;
	fma.rn.f32 	%f123, %f121, 0fB3A22168, %f122;
	fma.rn.f32 	%f168, %f121, 0fA7C234C5, %f123;
	abs.f32 	%f17, %f15;
	setp.ltu.f32 	%p18, %f17, 0f47CE4780;
	setp.neu.f32 	%p35, %f17, 0f7F800000;
	mov.u32 	%r220, %r224;
	mov.f32 	%f167, %f168;
	@%p18 bra 	$L__BB221_24;
	@%p35 bra 	$L__BB221_19;
	mul.rn.f32 	%f167, %f15, %f164;
	mov.b32 	%r220, 0;
	bra.uni 	$L__BB221_24;
$L__BB221_19:
	mov.b32 	%r33, %f15;
	shr.u32 	%r34, %r33, 23;
	and.b32  	%r145, %r34, 224;
	add.s32 	%r146, %r145, -128;
	shl.b32 	%r147, %r33, 8;
	or.b32  	%r151, %r147, -2147483648;
	shr.u32 	%r36, %r146, 5;
	mov.b32 	%r217, 0;
	mov.u64 	%rd122, 0;
	mov.u64 	%rd92, __cudart_i2opi_f;
$L__BB221_20:
	.pragma "nounroll";
	add.s64 	%rd93, %rd92, %rd122;
	ld.global.nc.u32 	%r150, [%rd93];
	// begin inline asm
	{
	mad.lo.cc.u32   %r148, %r150, %r151, %r217;
	madc.hi.u32     %r217, %r150, %r151,  0;
	}
	// end inline asm
	add.s64 	%rd94, %rd5, %rd122;
	st.local.u32 	[%rd94], %r148;
	add.s64 	%rd122, %rd122, 4;
	cvt.u32.u64 	%r153, %rd122;
	setp.ne.s32 	%p20, %r153, 24;
	@%p20 bra 	$L__BB221_20;
	st.local.u32 	[%rd5+24], %r217;
	and.b32  	%r39, %r34, 31;
	mul.wide.u32 	%rd95, %r36, 4;
	sub.s64 	%rd25, %rd5, %rd95;
	ld.local.u32 	%r218, [%rd25+24];
	ld.local.u32 	%r219, [%rd25+20];
	setp.eq.s32 	%p21, %r39, 0;
	@%p21 bra 	$L__BB221_23;
	shl.b32 	%r154, %r219, %r39;
	shl.b32 	%r155, %r218, %r39;
	mov.b32 	%r156, 32;
	sub.s32 	%r157, %r156, %r39;
	shr.u32 	%r158, %r219, %r157;
	add.s32 	%r218, %r158, %r155;
	ld.local.u32 	%r159, [%rd25+16];
	shr.u32 	%r160, %r159, %r157;
	add.s32 	%r219, %r160, %r154;
$L__BB221_23:
	shr.u32 	%r161, %r218, 30;
	shr.u32 	%r162, %r219, 30;
	shl.b32 	%r163, %r218, 2;
	or.b32  	%r164, %r163, %r162;
	shl.b32 	%r165, %r219, 2;
	bfe.u32 	%r166, %r218, 29, 1;
	add.s32 	%r167, %r166, %r161;
	neg.s32 	%r168, %r167;
	setp.lt.s32 	%p22, %r33, 0;
	selp.b32 	%r220, %r168, %r167, %p22;
	xor.b32  	%r169, %r164, %r33;
	bfe.s32 	%r170, %r218, 29, 1;
	xor.b32  	%r171, %r170, %r164;
	xor.b32  	%r172, %r170, %r165;
	cvt.u64.u32 	%rd96, %r171;
	shl.b64 	%rd97, %rd96, 32;
	cvt.u64.u32 	%rd98, %r172;
	or.b64  	%rd99, %rd97, %rd98;
	cvt.rn.f64.s64 	%fd5, %rd99;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f124, %fd6;
	neg.f32 	%f125, %f124;
	setp.lt.s32 	%p23, %r169, 0;
	selp.f32 	%f167, %f125, %f124, %p23;
$L__BB221_24:
	cvt.u64.u16 	%rd22, %rs1;
	add.s64 	%rd26, %rd65, %rd86;
	ld.global.nc.f32 	%f21, [%rd26];
	@%p18 bra 	$L__BB221_32;
	@%p35 bra 	$L__BB221_27;
	mul.rn.f32 	%f168, %f15, %f164;
	mov.b32 	%r224, 0;
	bra.uni 	$L__BB221_32;
$L__BB221_27:
	mov.b32 	%r48, %f15;
	shr.u32 	%r49, %r48, 23;
	and.b32  	%r175, %r49, 224;
	add.s32 	%r176, %r175, -128;
	shl.b32 	%r177, %r48, 8;
	or.b32  	%r181, %r177, -2147483648;
	shr.u32 	%r51, %r176, 5;
	mov.b32 	%r221, 0;
	mov.u64 	%rd123, 0;
	mov.u64 	%rd106, __cudart_i2opi_f;
$L__BB221_28:
	.pragma "nounroll";
	add.s64 	%rd107, %rd106, %rd123;
	ld.global.nc.u32 	%r180, [%rd107];
	// begin inline asm
	{
	mad.lo.cc.u32   %r178, %r180, %r181, %r221;
	madc.hi.u32     %r221, %r180, %r181,  0;
	}
	// end inline asm
	add.s64 	%rd108, %rd5, %rd123;
	st.local.u32 	[%rd108], %r178;
	add.s64 	%rd123, %rd123, 4;
	cvt.u32.u64 	%r183, %rd123;
	setp.ne.s32 	%p26, %r183, 24;
	@%p26 bra 	$L__BB221_28;
	st.local.u32 	[%rd5+24], %r221;
	and.b32  	%r54, %r49, 31;
	mul.wide.u32 	%rd109, %r51, 4;
	sub.s64 	%rd29, %rd5, %rd109;
	ld.local.u32 	%r222, [%rd29+24];
	ld.local.u32 	%r223, [%rd29+20];
	setp.eq.s32 	%p27, %r54, 0;
	@%p27 bra 	$L__BB221_31;
	shl.b32 	%r184, %r223, %r54;
	shl.b32 	%r185, %r222, %r54;
	mov.b32 	%r186, 32;
	sub.s32 	%r187, %r186, %r54;
	shr.u32 	%r188, %r223, %r187;
	add.s32 	%r222, %r188, %r185;
	ld.local.u32 	%r189, [%rd29+16];
	shr.u32 	%r190, %r189, %r187;
	add.s32 	%r223, %r190, %r184;
$L__BB221_31:
	shr.u32 	%r191, %r222, 30;
	shr.u32 	%r192, %r223, 30;
	shl.b32 	%r193, %r222, 2;
	or.b32  	%r194, %r193, %r192;
	shl.b32 	%r195, %r223, 2;
	bfe.u32 	%r196, %r222, 29, 1;
	add.s32 	%r197, %r196, %r191;
	neg.s32 	%r198, %r197;
	setp.lt.s32 	%p28, %r48, 0;
	selp.b32 	%r224, %r198, %r197, %p28;
	xor.b32  	%r199, %r194, %r48;
	bfe.s32 	%r200, %r222, 29, 1;
	xor.b32  	%r201, %r200, %r194;
	xor.b32  	%r202, %r200, %r195;
	cvt.u64.u32 	%rd110, %r201;
	shl.b64 	%rd111, %rd110, 32;
	cvt.u64.u32 	%rd112, %r202;
	or.b64  	%rd113, %rd111, %rd112;
	cvt.rn.f64.s64 	%fd7, %rd113;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f127, %fd8;
	neg.f32 	%f128, %f127;
	setp.lt.s32 	%p29, %r199, 0;
	selp.f32 	%f168, %f128, %f127, %p29;
$L__BB221_32:
	add.s32 	%r204, %r220, 1;
	and.b32  	%r205, %r204, 2;
	setp.eq.s32 	%p30, %r205, 0;
	and.b32  	%r206, %r220, 1;
	setp.eq.b32 	%p31, %r206, 1;
	mul.rn.f32 	%f130, %f167, %f167;
	fma.rn.f32 	%f131, %f130, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f132, 0fB94D4153, %f131, %p31;
	selp.f32 	%f133, 0f3C0885E4, 0f3D2AAABB, %p31;
	fma.rn.f32 	%f134, %f132, %f130, %f133;
	selp.f32 	%f135, 0fBE2AAAA8, 0fBEFFFFFF, %p31;
	fma.rn.f32 	%f136, %f134, %f130, %f135;
	selp.f32 	%f137, %f167, 0f3F800000, %p31;
	fma.rn.f32 	%f138, %f130, %f137, 0f00000000;
	fma.rn.f32 	%f139, %f136, %f138, %f137;
	sub.rn.f32 	%f141, %f164, %f139;
	selp.f32 	%f142, %f139, %f141, %p30;
	mul.rn.f32 	%f143, %f21, %f142;
	mul.rn.f32 	%f144, %f1, %f14;
	mul.rn.f32 	%f145, %f168, %f168;
	and.b32  	%r207, %r224, 1;
	setp.eq.b32 	%p32, %r207, 1;
	selp.f32 	%f146, 0f3F800000, %f168, %p32;
	fma.rn.f32 	%f147, %f145, %f146, 0f00000000;
	fma.rn.f32 	%f148, %f145, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f149, %f148, 0fB94D4153, %p32;
	selp.f32 	%f150, 0f3D2AAABB, 0f3C0885E4, %p32;
	fma.rn.f32 	%f151, %f149, %f145, %f150;
	selp.f32 	%f152, 0fBEFFFFFF, 0fBE2AAAA8, %p32;
	fma.rn.f32 	%f153, %f151, %f145, %f152;
	fma.rn.f32 	%f154, %f153, %f147, %f146;
	and.b32  	%r208, %r224, 2;
	setp.eq.s32 	%p33, %r208, 0;
	sub.rn.f32 	%f155, %f164, %f154;
	selp.f32 	%f156, %f154, %f155, %p33;
	shl.b64 	%rd118, %rd22, 3;
	add.s64 	%rd119, %rd79, %rd118;
	ld.global.nc.f32 	%f157, [%rd119];
	mul.rn.f32 	%f158, %f157, %f156;
	add.rn.f32 	%f159, %f143, %f158;
	mul.rn.f32 	%f160, %f3, %f159;
	ld.global.nc.f32 	%f161, [%rd26+24];
	add.rn.f32 	%f162, %f161, %f160;
	mul.rn.f32 	%f163, %f144, %f162;
	st.global.f32 	[%rd21+4], %f163;
	ret;

}
	// .globl	loop_reduce_fusion_44
.visible .entry loop_reduce_fusion_44(
	.param .u64 loop_reduce_fusion_44_param_0,
	.param .u64 loop_reduce_fusion_44_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<7>;
	.reg .f32 	%f<101>;
	.reg .b64 	%rd<11>;

	ld.param.u64 	%rd1, [loop_reduce_fusion_44_param_0];
	ld.param.u64 	%rd2, [loop_reduce_fusion_44_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	cvt.u32.u16 	%r5, %rs5;
	mul.wide.u32 	%rd5, %r5, 4;
	cvt.u32.u16 	%r6, %rs3;
	mul.wide.u32 	%rd6, %r6, 1200;
	add.s64 	%rd7, %rd4, %rd6;
	add.s64 	%rd8, %rd7, %rd5;
	ld.global.nc.f32 	%f1, [%rd8];
	add.rn.f32 	%f2, %f1, 0f00000000;
	ld.global.nc.f32 	%f3, [%rd8+24];
	add.rn.f32 	%f4, %f2, %f3;
	ld.global.nc.f32 	%f5, [%rd8+48];
	add.rn.f32 	%f6, %f4, %f5;
	ld.global.nc.f32 	%f7, [%rd8+72];
	add.rn.f32 	%f8, %f6, %f7;
	ld.global.nc.f32 	%f9, [%rd8+96];
	add.rn.f32 	%f10, %f8, %f9;
	ld.global.nc.f32 	%f11, [%rd8+120];
	add.rn.f32 	%f12, %f10, %f11;
	ld.global.nc.f32 	%f13, [%rd8+144];
	add.rn.f32 	%f14, %f12, %f13;
	ld.global.nc.f32 	%f15, [%rd8+168];
	add.rn.f32 	%f16, %f14, %f15;
	ld.global.nc.f32 	%f17, [%rd8+192];
	add.rn.f32 	%f18, %f16, %f17;
	ld.global.nc.f32 	%f19, [%rd8+216];
	add.rn.f32 	%f20, %f18, %f19;
	ld.global.nc.f32 	%f21, [%rd8+240];
	add.rn.f32 	%f22, %f20, %f21;
	ld.global.nc.f32 	%f23, [%rd8+264];
	add.rn.f32 	%f24, %f22, %f23;
	ld.global.nc.f32 	%f25, [%rd8+288];
	add.rn.f32 	%f26, %f24, %f25;
	ld.global.nc.f32 	%f27, [%rd8+312];
	add.rn.f32 	%f28, %f26, %f27;
	ld.global.nc.f32 	%f29, [%rd8+336];
	add.rn.f32 	%f30, %f28, %f29;
	ld.global.nc.f32 	%f31, [%rd8+360];
	add.rn.f32 	%f32, %f30, %f31;
	ld.global.nc.f32 	%f33, [%rd8+384];
	add.rn.f32 	%f34, %f32, %f33;
	ld.global.nc.f32 	%f35, [%rd8+408];
	add.rn.f32 	%f36, %f34, %f35;
	ld.global.nc.f32 	%f37, [%rd8+432];
	add.rn.f32 	%f38, %f36, %f37;
	ld.global.nc.f32 	%f39, [%rd8+456];
	add.rn.f32 	%f40, %f38, %f39;
	ld.global.nc.f32 	%f41, [%rd8+480];
	add.rn.f32 	%f42, %f40, %f41;
	ld.global.nc.f32 	%f43, [%rd8+504];
	add.rn.f32 	%f44, %f42, %f43;
	ld.global.nc.f32 	%f45, [%rd8+528];
	add.rn.f32 	%f46, %f44, %f45;
	ld.global.nc.f32 	%f47, [%rd8+552];
	add.rn.f32 	%f48, %f46, %f47;
	ld.global.nc.f32 	%f49, [%rd8+576];
	add.rn.f32 	%f50, %f48, %f49;
	ld.global.nc.f32 	%f51, [%rd8+600];
	add.rn.f32 	%f52, %f50, %f51;
	ld.global.nc.f32 	%f53, [%rd8+624];
	add.rn.f32 	%f54, %f52, %f53;
	ld.global.nc.f32 	%f55, [%rd8+648];
	add.rn.f32 	%f56, %f54, %f55;
	ld.global.nc.f32 	%f57, [%rd8+672];
	add.rn.f32 	%f58, %f56, %f57;
	ld.global.nc.f32 	%f59, [%rd8+696];
	add.rn.f32 	%f60, %f58, %f59;
	ld.global.nc.f32 	%f61, [%rd8+720];
	add.rn.f32 	%f62, %f60, %f61;
	ld.global.nc.f32 	%f63, [%rd8+744];
	add.rn.f32 	%f64, %f62, %f63;
	ld.global.nc.f32 	%f65, [%rd8+768];
	add.rn.f32 	%f66, %f64, %f65;
	ld.global.nc.f32 	%f67, [%rd8+792];
	add.rn.f32 	%f68, %f66, %f67;
	ld.global.nc.f32 	%f69, [%rd8+816];
	add.rn.f32 	%f70, %f68, %f69;
	ld.global.nc.f32 	%f71, [%rd8+840];
	add.rn.f32 	%f72, %f70, %f71;
	ld.global.nc.f32 	%f73, [%rd8+864];
	add.rn.f32 	%f74, %f72, %f73;
	ld.global.nc.f32 	%f75, [%rd8+888];
	add.rn.f32 	%f76, %f74, %f75;
	ld.global.nc.f32 	%f77, [%rd8+912];
	add.rn.f32 	%f78, %f76, %f77;
	ld.global.nc.f32 	%f79, [%rd8+936];
	add.rn.f32 	%f80, %f78, %f79;
	ld.global.nc.f32 	%f81, [%rd8+960];
	add.rn.f32 	%f82, %f80, %f81;
	ld.global.nc.f32 	%f83, [%rd8+984];
	add.rn.f32 	%f84, %f82, %f83;
	ld.global.nc.f32 	%f85, [%rd8+1008];
	add.rn.f32 	%f86, %f84, %f85;
	ld.global.nc.f32 	%f87, [%rd8+1032];
	add.rn.f32 	%f88, %f86, %f87;
	ld.global.nc.f32 	%f89, [%rd8+1056];
	add.rn.f32 	%f90, %f88, %f89;
	ld.global.nc.f32 	%f91, [%rd8+1080];
	add.rn.f32 	%f92, %f90, %f91;
	ld.global.nc.f32 	%f93, [%rd8+1104];
	add.rn.f32 	%f94, %f92, %f93;
	ld.global.nc.f32 	%f95, [%rd8+1128];
	add.rn.f32 	%f96, %f94, %f95;
	ld.global.nc.f32 	%f97, [%rd8+1152];
	add.rn.f32 	%f98, %f96, %f97;
	ld.global.nc.f32 	%f99, [%rd8+1176];
	add.rn.f32 	%f100, %f98, %f99;
	mul.wide.u32 	%rd9, %r4, 4;
	add.s64 	%rd10, %rd3, %rd9;
	st.global.f32 	[%rd10], %f100;
	ret;

}
	// .globl	input_concatenate_fusion_325
.visible .entry input_concatenate_fusion_325(
	.param .u64 input_concatenate_fusion_325_param_0,
	.param .u64 input_concatenate_fusion_325_param_1,
	.param .u64 input_concatenate_fusion_325_param_2,
	.param .u64 input_concatenate_fusion_325_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<17>;
	.reg .b32 	%r<13>;
	.reg .f32 	%f<42>;
	.reg .b64 	%rd<27>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_325_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_325_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [input_concatenate_fusion_325_param_1];
	ld.param.u64 	%rd5, [input_concatenate_fusion_325_param_2];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 5243;
	shr.u16 	%rs7, %rs6, 2;
	mul.lo.s16 	%rs8, %rs7, 50;
	sub.s16 	%rs9, %rs3, %rs8;
	shr.u16 	%rs10, %rs1, 1;
	mul.hi.u16 	%rs11, %rs10, -9611;
	shr.u16 	%rs12, %rs11, 6;
	and.b16  	%rs13, %rs12, 63;
	shl.b16 	%rs14, %rs5, 1;
	cvt.u32.u16 	%r5, %rs13;
	mul.wide.u32 	%rd9, %r5, 4;
	add.s64 	%rd10, %rd7, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	fma.rn.f32 	%f2, %f1, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f3, %f2;
	mov.f32 	%f4, 0f4B400001;
	mov.f32 	%f5, 0f437C0000;
	fma.rm.f32 	%f6, %f3, %f5, %f4;
	add.rn.f32 	%f7, %f6, 0fCB40007F;
	neg.f32 	%f8, %f7;
	fma.rn.f32 	%f9, %f1, 0f3FB8AA3B, %f8;
	fma.rn.f32 	%f10, %f1, 0f32A57060, %f9;
	mov.b32 	%r6, %f6;
	shl.b32 	%r7, %r6, 23;
	mov.b32 	%f11, %r7;
	ex2.approx.ftz.f32 	%f12, %f10;
	mul.rn.f32 	%f13, %f12, %f11;
	neg.f32 	%f14, %f13;
	sub.rn.f32 	%f15, %f14, %f13;
	add.rn.f32 	%f16, %f15, %f15;
	add.rn.f32 	%f17, %f16, %f16;
	add.rn.f32 	%f18, %f17, %f17;
	add.rn.f32 	%f19, %f18, %f18;
	add.rn.f32 	%f20, %f19, %f19;
	add.rn.f32 	%f21, %f20, %f20;
	add.rn.f32 	%f22, %f21, %f21;
	fma.rn.f32 	%f23, %f22, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f24, %f23;
	fma.rm.f32 	%f25, %f24, %f5, %f4;
	add.rn.f32 	%f26, %f25, 0fCB40007F;
	neg.f32 	%f27, %f26;
	fma.rn.f32 	%f28, %f22, 0f3FB8AA3B, %f27;
	fma.rn.f32 	%f29, %f22, 0f32A57060, %f28;
	mov.b32 	%r8, %f25;
	shl.b32 	%r9, %r8, 23;
	mov.b32 	%f30, %r9;
	ex2.approx.ftz.f32 	%f31, %f29;
	mul.rn.f32 	%f32, %f31, %f30;
	cvt.u32.u16 	%r10, %rs9;
	mul.wide.u32 	%rd11, %r10, 48;
	mul.wide.u32 	%rd12, %r5, 2400;
	add.s64 	%rd13, %rd8, %rd12;
	add.s64 	%rd14, %rd13, %rd11;
	cvt.u32.u16 	%r11, %rs14;
	mul.wide.u32 	%rd15, %r11, 4;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.nc.v2.f32 	{%f33, %f34}, [%rd16+24];
	mul.rn.f32 	%f35, %f33, %f32;
	or.b16  	%rs15, %rs14, 1;
	setp.gt.u16 	%p1, %rs5, 1;
	selp.b16 	%rs16, 5, %rs15, %p1;
	cvt.u32.u16 	%r12, %rs16;
	mul.wide.u32 	%rd17, %r12, 4;
	add.s64 	%rd18, %rd6, %rd12;
	add.s64 	%rd19, %rd18, %rd11;
	add.s64 	%rd20, %rd19, %rd17;
	ld.global.nc.f32 	%f36, [%rd20];
	neg.f32 	%f37, %f36;
	mul.rn.f32 	%f38, %f35, %f37;
	mul.wide.u32 	%rd21, %r10, 24;
	mul.wide.u32 	%rd22, %r5, 1200;
	add.s64 	%rd23, %rd3, %rd22;
	add.s64 	%rd24, %rd23, %rd21;
	add.s64 	%rd25, %rd24, %rd15;
	mul.rn.f32 	%f39, %f34, %f32;
	add.s64 	%rd26, %rd19, %rd15;
	ld.global.nc.f32 	%f40, [%rd26];
	mul.rn.f32 	%f41, %f40, %f39;
	st.global.v2.f32 	[%rd25], {%f38, %f41};
	ret;

}
	// .globl	loop_reduce_fusion_45
.visible .entry loop_reduce_fusion_45(
	.param .u64 loop_reduce_fusion_45_param_0,
	.param .u64 loop_reduce_fusion_45_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<7>;
	.reg .f32 	%f<102>;
	.reg .b64 	%rd<11>;

	ld.param.u64 	%rd1, [loop_reduce_fusion_45_param_0];
	ld.param.u64 	%rd2, [loop_reduce_fusion_45_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs3, 63;
	cvt.u32.u16 	%r5, %rs5;
	mul.wide.u32 	%rd5, %r5, 4;
	cvt.u32.u16 	%r6, %rs6;
	mul.wide.u32 	%rd6, %r6, 1200;
	add.s64 	%rd7, %rd4, %rd6;
	add.s64 	%rd8, %rd7, %rd5;
	ld.global.nc.f32 	%f1, [%rd8];
	add.rn.f32 	%f2, %f1, 0f00000000;
	ld.global.nc.f32 	%f3, [%rd8+24];
	add.rn.f32 	%f4, %f2, %f3;
	ld.global.nc.f32 	%f5, [%rd8+48];
	add.rn.f32 	%f6, %f4, %f5;
	ld.global.nc.f32 	%f7, [%rd8+72];
	add.rn.f32 	%f8, %f6, %f7;
	ld.global.nc.f32 	%f9, [%rd8+96];
	add.rn.f32 	%f10, %f8, %f9;
	ld.global.nc.f32 	%f11, [%rd8+120];
	add.rn.f32 	%f12, %f10, %f11;
	ld.global.nc.f32 	%f13, [%rd8+144];
	add.rn.f32 	%f14, %f12, %f13;
	ld.global.nc.f32 	%f15, [%rd8+168];
	add.rn.f32 	%f16, %f14, %f15;
	ld.global.nc.f32 	%f17, [%rd8+192];
	add.rn.f32 	%f18, %f16, %f17;
	ld.global.nc.f32 	%f19, [%rd8+216];
	add.rn.f32 	%f20, %f18, %f19;
	ld.global.nc.f32 	%f21, [%rd8+240];
	add.rn.f32 	%f22, %f20, %f21;
	ld.global.nc.f32 	%f23, [%rd8+264];
	add.rn.f32 	%f24, %f22, %f23;
	ld.global.nc.f32 	%f25, [%rd8+288];
	add.rn.f32 	%f26, %f24, %f25;
	ld.global.nc.f32 	%f27, [%rd8+312];
	add.rn.f32 	%f28, %f26, %f27;
	ld.global.nc.f32 	%f29, [%rd8+336];
	add.rn.f32 	%f30, %f28, %f29;
	ld.global.nc.f32 	%f31, [%rd8+360];
	add.rn.f32 	%f32, %f30, %f31;
	ld.global.nc.f32 	%f33, [%rd8+384];
	add.rn.f32 	%f34, %f32, %f33;
	ld.global.nc.f32 	%f35, [%rd8+408];
	add.rn.f32 	%f36, %f34, %f35;
	ld.global.nc.f32 	%f37, [%rd8+432];
	add.rn.f32 	%f38, %f36, %f37;
	ld.global.nc.f32 	%f39, [%rd8+456];
	add.rn.f32 	%f40, %f38, %f39;
	ld.global.nc.f32 	%f41, [%rd8+480];
	add.rn.f32 	%f42, %f40, %f41;
	ld.global.nc.f32 	%f43, [%rd8+504];
	add.rn.f32 	%f44, %f42, %f43;
	ld.global.nc.f32 	%f45, [%rd8+528];
	add.rn.f32 	%f46, %f44, %f45;
	ld.global.nc.f32 	%f47, [%rd8+552];
	add.rn.f32 	%f48, %f46, %f47;
	ld.global.nc.f32 	%f49, [%rd8+576];
	add.rn.f32 	%f50, %f48, %f49;
	ld.global.nc.f32 	%f51, [%rd8+600];
	add.rn.f32 	%f52, %f50, %f51;
	ld.global.nc.f32 	%f53, [%rd8+624];
	add.rn.f32 	%f54, %f52, %f53;
	ld.global.nc.f32 	%f55, [%rd8+648];
	add.rn.f32 	%f56, %f54, %f55;
	ld.global.nc.f32 	%f57, [%rd8+672];
	add.rn.f32 	%f58, %f56, %f57;
	ld.global.nc.f32 	%f59, [%rd8+696];
	add.rn.f32 	%f60, %f58, %f59;
	ld.global.nc.f32 	%f61, [%rd8+720];
	add.rn.f32 	%f62, %f60, %f61;
	ld.global.nc.f32 	%f63, [%rd8+744];
	add.rn.f32 	%f64, %f62, %f63;
	ld.global.nc.f32 	%f65, [%rd8+768];
	add.rn.f32 	%f66, %f64, %f65;
	ld.global.nc.f32 	%f67, [%rd8+792];
	add.rn.f32 	%f68, %f66, %f67;
	ld.global.nc.f32 	%f69, [%rd8+816];
	add.rn.f32 	%f70, %f68, %f69;
	ld.global.nc.f32 	%f71, [%rd8+840];
	add.rn.f32 	%f72, %f70, %f71;
	ld.global.nc.f32 	%f73, [%rd8+864];
	add.rn.f32 	%f74, %f72, %f73;
	ld.global.nc.f32 	%f75, [%rd8+888];
	add.rn.f32 	%f76, %f74, %f75;
	ld.global.nc.f32 	%f77, [%rd8+912];
	add.rn.f32 	%f78, %f76, %f77;
	ld.global.nc.f32 	%f79, [%rd8+936];
	add.rn.f32 	%f80, %f78, %f79;
	ld.global.nc.f32 	%f81, [%rd8+960];
	add.rn.f32 	%f82, %f80, %f81;
	ld.global.nc.f32 	%f83, [%rd8+984];
	add.rn.f32 	%f84, %f82, %f83;
	ld.global.nc.f32 	%f85, [%rd8+1008];
	add.rn.f32 	%f86, %f84, %f85;
	ld.global.nc.f32 	%f87, [%rd8+1032];
	add.rn.f32 	%f88, %f86, %f87;
	ld.global.nc.f32 	%f89, [%rd8+1056];
	add.rn.f32 	%f90, %f88, %f89;
	ld.global.nc.f32 	%f91, [%rd8+1080];
	add.rn.f32 	%f92, %f90, %f91;
	ld.global.nc.f32 	%f93, [%rd8+1104];
	add.rn.f32 	%f94, %f92, %f93;
	ld.global.nc.f32 	%f95, [%rd8+1128];
	add.rn.f32 	%f96, %f94, %f95;
	ld.global.nc.f32 	%f97, [%rd8+1152];
	add.rn.f32 	%f98, %f96, %f97;
	ld.global.nc.f32 	%f99, [%rd8+1176];
	add.rn.f32 	%f100, %f98, %f99;
	neg.f32 	%f101, %f100;
	mul.wide.u32 	%rd9, %r4, 4;
	add.s64 	%rd10, %rd3, %rd9;
	st.global.f32 	[%rd10], %f101;
	ret;

}
	// .globl	input_reduce_fusion_319
.visible .entry input_reduce_fusion_319(
	.param .u64 input_reduce_fusion_319_param_0,
	.param .u64 input_reduce_fusion_319_param_1,
	.param .u64 input_reduce_fusion_319_param_2,
	.param .u64 input_reduce_fusion_319_param_3,
	.param .u64 input_reduce_fusion_319_param_4,
	.param .u64 input_reduce_fusion_319_param_5,
	.param .u64 input_reduce_fusion_319_param_6
)
.reqntid 256, 1, 1
{
	.local .align 4 .b8 	__local_depot225[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<40>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<231>;
	.reg .f32 	%f<318>;
	.reg .b64 	%rd<105>;
	.reg .f64 	%fd<9>;

	mov.u64 	%SPL, __local_depot225;
	mov.u32 	%r67, %tid.x;
	mov.u32 	%r68, %ctaid.x;
	shr.u32 	%r1, %r67, 1;
	and.b32  	%r2, %r67, 1;
	setp.eq.s32 	%p2, %r68, 0;
	selp.b32 	%r3, 128, 64, %p2;
	shl.b32 	%r4, %r68, 7;
	setp.ge.u32 	%p3, %r1, %r3;
	mov.f32 	%f313, 0f00000000;
	mov.f32 	%f314, %f313;
	@%p3 bra 	$L__BB225_12;
	ld.param.u64 	%rd26, [input_reduce_fusion_319_param_0];
	ld.param.u64 	%rd28, [input_reduce_fusion_319_param_1];
	ld.param.u64 	%rd30, [input_reduce_fusion_319_param_2];
	ld.param.u64 	%rd31, [input_reduce_fusion_319_param_4];
	cvta.to.global.u64 	%rd5, %rd30;
	cvta.to.global.u64 	%rd6, %rd28;
	cvta.to.global.u64 	%rd7, %rd26;
	add.u64 	%rd8, %SPL, 0;
	or.b32  	%r69, %r1, %r4;
	cvt.u16.u32 	%rs1, %r69;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 9;
	mul.lo.s16 	%rs5, %rs4, 3;
	sub.s16 	%rs6, %rs1, %rs5;
	shl.b16 	%rs7, %rs6, 1;
	cvt.u32.u16 	%r70, %rs7;
	and.b32  	%r71, %r70, 254;
	or.b32  	%r72, %r2, %r71;
	cvt.u64.u16 	%rd12, %rs4;
	cvt.u64.u32 	%rd13, %r72;
	mul.wide.u32 	%rd37, %r72, 4;
	cvt.u32.u16 	%r73, %rs4;
	mul.wide.u32 	%rd38, %r73, 24;
	add.s64 	%rd39, %rd5, %rd38;
	add.s64 	%rd40, %rd39, %rd37;
	ld.global.nc.f32 	%f1, [%rd40];
	cvt.u32.u16 	%r74, %rs6;
	and.b32  	%r75, %r74, 255;
	mul.wide.u32 	%rd41, %r75, 4;
	mul.wide.u32 	%rd42, %r73, 12;
	add.s64 	%rd43, %rd6, %rd42;
	add.s64 	%rd44, %rd43, %rd41;
	ld.global.nc.f32 	%f32, [%rd44];
	add.rn.f32 	%f33, %f32, %f32;
	add.rn.f32 	%f34, %f33, %f33;
	add.rn.f32 	%f35, %f34, %f34;
	add.rn.f32 	%f2, %f35, %f35;
	add.rn.f32 	%f3, %f2, %f2;
	mul.rn.f32 	%f36, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r222, %f36;
	cvt.rn.f32.s32 	%f37, %r222;
	fma.rn.f32 	%f38, %f37, 0fBFC90FDA, %f3;
	fma.rn.f32 	%f39, %f37, 0fB3A22168, %f38;
	fma.rn.f32 	%f315, %f37, 0fA7C234C5, %f39;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p4, %f5, 0f47CE4780;
	setp.neu.f32 	%p38, %f5, 0f7F800000;
	mov.u32 	%r218, %r222;
	mov.f32 	%f312, %f315;
	@%p4 bra 	$L__BB225_9;
	@%p38 bra 	$L__BB225_4;
	mov.f32 	%f42, 0f00000000;
	mul.rn.f32 	%f312, %f3, %f42;
	mov.b32 	%r218, 0;
	bra.uni 	$L__BB225_9;
$L__BB225_4:
	mov.b32 	%r215, 0;
	mov.b32 	%r6, %f3;
	shr.u32 	%r7, %r6, 23;
	and.b32  	%r77, %r7, 224;
	add.s32 	%r78, %r77, -128;
	shl.b32 	%r79, %r6, 8;
	or.b32  	%r83, %r79, -2147483648;
	shr.u32 	%r9, %r78, 5;
	mov.u64 	%rd101, 0;
	mov.u64 	%rd46, __cudart_i2opi_f;
$L__BB225_5:
	.pragma "nounroll";
	add.s64 	%rd47, %rd46, %rd101;
	ld.global.nc.u32 	%r82, [%rd47];
	// begin inline asm
	{
	mad.lo.cc.u32   %r80, %r82, %r83, %r215;
	madc.hi.u32     %r215, %r82, %r83,  0;
	}
	// end inline asm
	add.s64 	%rd48, %rd8, %rd101;
	st.local.u32 	[%rd48], %r80;
	add.s64 	%rd101, %rd101, 4;
	cvt.u32.u64 	%r85, %rd101;
	setp.ne.s32 	%p6, %r85, 24;
	@%p6 bra 	$L__BB225_5;
	st.local.u32 	[%rd8+24], %r215;
	and.b32  	%r12, %r7, 31;
	mul.wide.u32 	%rd49, %r9, 4;
	sub.s64 	%rd16, %rd8, %rd49;
	ld.local.u32 	%r216, [%rd16+24];
	ld.local.u32 	%r217, [%rd16+20];
	setp.eq.s32 	%p7, %r12, 0;
	@%p7 bra 	$L__BB225_8;
	shl.b32 	%r86, %r217, %r12;
	shl.b32 	%r87, %r216, %r12;
	mov.b32 	%r88, 32;
	sub.s32 	%r89, %r88, %r12;
	shr.u32 	%r90, %r217, %r89;
	add.s32 	%r216, %r90, %r87;
	ld.local.u32 	%r91, [%rd16+16];
	shr.u32 	%r92, %r91, %r89;
	add.s32 	%r217, %r92, %r86;
$L__BB225_8:
	shr.u32 	%r93, %r216, 30;
	shr.u32 	%r94, %r217, 30;
	shl.b32 	%r95, %r216, 2;
	or.b32  	%r96, %r95, %r94;
	shl.b32 	%r97, %r217, 2;
	bfe.u32 	%r98, %r216, 29, 1;
	add.s32 	%r99, %r98, %r93;
	neg.s32 	%r100, %r99;
	setp.lt.s32 	%p8, %r6, 0;
	selp.b32 	%r218, %r100, %r99, %p8;
	xor.b32  	%r101, %r96, %r6;
	bfe.s32 	%r102, %r216, 29, 1;
	xor.b32  	%r103, %r102, %r96;
	xor.b32  	%r104, %r102, %r97;
	cvt.u64.u32 	%rd50, %r103;
	shl.b64 	%rd51, %rd50, 32;
	cvt.u64.u32 	%rd52, %r104;
	or.b64  	%rd53, %rd51, %rd52;
	cvt.rn.f64.s64 	%fd1, %rd53;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f40, %fd2;
	neg.f32 	%f41, %f40;
	setp.lt.s32 	%p9, %r101, 0;
	selp.f32 	%f312, %f41, %f40, %p9;
$L__BB225_9:
	ld.param.u64 	%rd32, [input_reduce_fusion_319_param_3];
	cvta.to.global.u64 	%rd3, %rd31;
	add.s32 	%r106, %r218, 1;
	mul.rn.f32 	%f43, %f312, %f312;
	and.b32  	%r107, %r218, 1;
	setp.eq.b32 	%p11, %r107, 1;
	selp.f32 	%f44, %f312, 0f3F800000, %p11;
	fma.rn.f32 	%f45, %f43, %f44, 0f00000000;
	fma.rn.f32 	%f46, %f43, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f47, 0fB94D4153, %f46, %p11;
	selp.f32 	%f48, 0f3C0885E4, 0f3D2AAABB, %p11;
	fma.rn.f32 	%f49, %f47, %f43, %f48;
	selp.f32 	%f50, 0fBE2AAAA8, 0fBEFFFFFF, %p11;
	fma.rn.f32 	%f51, %f49, %f43, %f50;
	fma.rn.f32 	%f52, %f51, %f45, %f44;
	and.b32  	%r108, %r106, 2;
	mov.f32 	%f53, 0f00000000;
	sub.rn.f32 	%f54, %f53, %f52;
	mul.lo.s64 	%rd54, %rd12, 1200;
	add.s64 	%rd55, %rd7, %rd54;
	shl.b64 	%rd56, %rd13, 2;
	add.s64 	%rd57, %rd55, %rd56;
	ld.global.nc.f32 	%f55, [%rd57];
	add.rn.f32 	%f56, %f55, 0f00000000;
	ld.global.nc.f32 	%f57, [%rd57+24];
	add.rn.f32 	%f58, %f56, %f57;
	ld.global.nc.f32 	%f59, [%rd57+48];
	add.rn.f32 	%f60, %f58, %f59;
	ld.global.nc.f32 	%f61, [%rd57+72];
	add.rn.f32 	%f62, %f60, %f61;
	ld.global.nc.f32 	%f63, [%rd57+96];
	add.rn.f32 	%f64, %f62, %f63;
	ld.global.nc.f32 	%f65, [%rd57+120];
	add.rn.f32 	%f66, %f64, %f65;
	ld.global.nc.f32 	%f67, [%rd57+144];
	add.rn.f32 	%f68, %f66, %f67;
	ld.global.nc.f32 	%f69, [%rd57+168];
	add.rn.f32 	%f70, %f68, %f69;
	ld.global.nc.f32 	%f71, [%rd57+192];
	add.rn.f32 	%f72, %f70, %f71;
	ld.global.nc.f32 	%f73, [%rd57+216];
	add.rn.f32 	%f74, %f72, %f73;
	ld.global.nc.f32 	%f75, [%rd57+240];
	add.rn.f32 	%f76, %f74, %f75;
	ld.global.nc.f32 	%f77, [%rd57+264];
	add.rn.f32 	%f78, %f76, %f77;
	ld.global.nc.f32 	%f79, [%rd57+288];
	add.rn.f32 	%f80, %f78, %f79;
	ld.global.nc.f32 	%f81, [%rd57+312];
	add.rn.f32 	%f82, %f80, %f81;
	ld.global.nc.f32 	%f83, [%rd57+336];
	add.rn.f32 	%f84, %f82, %f83;
	ld.global.nc.f32 	%f85, [%rd57+360];
	add.rn.f32 	%f86, %f84, %f85;
	ld.global.nc.f32 	%f87, [%rd57+384];
	add.rn.f32 	%f88, %f86, %f87;
	ld.global.nc.f32 	%f89, [%rd57+408];
	add.rn.f32 	%f90, %f88, %f89;
	ld.global.nc.f32 	%f91, [%rd57+432];
	add.rn.f32 	%f92, %f90, %f91;
	ld.global.nc.f32 	%f93, [%rd57+456];
	add.rn.f32 	%f94, %f92, %f93;
	ld.global.nc.f32 	%f95, [%rd57+480];
	add.rn.f32 	%f96, %f94, %f95;
	ld.global.nc.f32 	%f97, [%rd57+504];
	add.rn.f32 	%f98, %f96, %f97;
	ld.global.nc.f32 	%f99, [%rd57+528];
	add.rn.f32 	%f100, %f98, %f99;
	ld.global.nc.f32 	%f101, [%rd57+552];
	add.rn.f32 	%f102, %f100, %f101;
	ld.global.nc.f32 	%f103, [%rd57+576];
	add.rn.f32 	%f104, %f102, %f103;
	ld.global.nc.f32 	%f105, [%rd57+600];
	add.rn.f32 	%f106, %f104, %f105;
	ld.global.nc.f32 	%f107, [%rd57+624];
	add.rn.f32 	%f108, %f106, %f107;
	ld.global.nc.f32 	%f109, [%rd57+648];
	add.rn.f32 	%f110, %f108, %f109;
	ld.global.nc.f32 	%f111, [%rd57+672];
	add.rn.f32 	%f112, %f110, %f111;
	ld.global.nc.f32 	%f113, [%rd57+696];
	add.rn.f32 	%f114, %f112, %f113;
	ld.global.nc.f32 	%f115, [%rd57+720];
	add.rn.f32 	%f116, %f114, %f115;
	ld.global.nc.f32 	%f117, [%rd57+744];
	add.rn.f32 	%f118, %f116, %f117;
	ld.global.nc.f32 	%f119, [%rd57+768];
	add.rn.f32 	%f120, %f118, %f119;
	ld.global.nc.f32 	%f121, [%rd57+792];
	add.rn.f32 	%f122, %f120, %f121;
	ld.global.nc.f32 	%f123, [%rd57+816];
	add.rn.f32 	%f124, %f122, %f123;
	ld.global.nc.f32 	%f125, [%rd57+840];
	add.rn.f32 	%f126, %f124, %f125;
	ld.global.nc.f32 	%f127, [%rd57+864];
	add.rn.f32 	%f128, %f126, %f127;
	ld.global.nc.f32 	%f129, [%rd57+888];
	add.rn.f32 	%f130, %f128, %f129;
	ld.global.nc.f32 	%f131, [%rd57+912];
	add.rn.f32 	%f132, %f130, %f131;
	ld.global.nc.f32 	%f133, [%rd57+936];
	add.rn.f32 	%f134, %f132, %f133;
	ld.global.nc.f32 	%f135, [%rd57+960];
	add.rn.f32 	%f136, %f134, %f135;
	ld.global.nc.f32 	%f137, [%rd57+984];
	add.rn.f32 	%f138, %f136, %f137;
	ld.global.nc.f32 	%f139, [%rd57+1008];
	add.rn.f32 	%f140, %f138, %f139;
	ld.global.nc.f32 	%f141, [%rd57+1032];
	add.rn.f32 	%f142, %f140, %f141;
	ld.global.nc.f32 	%f143, [%rd57+1056];
	add.rn.f32 	%f144, %f142, %f143;
	ld.global.nc.f32 	%f145, [%rd57+1080];
	add.rn.f32 	%f146, %f144, %f145;
	ld.global.nc.f32 	%f147, [%rd57+1104];
	add.rn.f32 	%f148, %f146, %f147;
	ld.global.nc.f32 	%f149, [%rd57+1128];
	add.rn.f32 	%f150, %f148, %f149;
	ld.global.nc.f32 	%f151, [%rd57+1152];
	add.rn.f32 	%f152, %f150, %f151;
	ld.global.nc.f32 	%f153, [%rd57+1176];
	add.rn.f32 	%f9, %f152, %f153;
	setp.eq.s32 	%p12, %r108, 0;
	selp.f32 	%f154, %f52, %f54, %p12;
	@%p4 bra 	$L__BB225_20;
	@%p38 bra 	$L__BB225_15;
	mul.rn.f32 	%f315, %f3, %f53;
	mov.b32 	%r222, 0;
	bra.uni 	$L__BB225_20;
$L__BB225_15:
	mov.b32 	%r21, %f3;
	shr.u32 	%r22, %r21, 23;
	and.b32  	%r110, %r22, 224;
	add.s32 	%r111, %r110, -128;
	shl.b32 	%r112, %r21, 8;
	or.b32  	%r116, %r112, -2147483648;
	shr.u32 	%r24, %r111, 5;
	mov.b32 	%r219, 0;
	mov.u64 	%rd102, 0;
	mov.u64 	%rd59, __cudart_i2opi_f;
$L__BB225_16:
	.pragma "nounroll";
	add.s64 	%rd60, %rd59, %rd102;
	ld.global.nc.u32 	%r115, [%rd60];
	// begin inline asm
	{
	mad.lo.cc.u32   %r113, %r115, %r116, %r219;
	madc.hi.u32     %r219, %r115, %r116,  0;
	}
	// end inline asm
	add.s64 	%rd61, %rd8, %rd102;
	st.local.u32 	[%rd61], %r113;
	add.s64 	%rd102, %rd102, 4;
	cvt.u32.u64 	%r118, %rd102;
	setp.ne.s32 	%p14, %r118, 24;
	@%p14 bra 	$L__BB225_16;
	st.local.u32 	[%rd8+24], %r219;
	and.b32  	%r27, %r22, 31;
	mul.wide.u32 	%rd62, %r24, 4;
	sub.s64 	%rd19, %rd8, %rd62;
	ld.local.u32 	%r220, [%rd19+24];
	ld.local.u32 	%r221, [%rd19+20];
	setp.eq.s32 	%p15, %r27, 0;
	@%p15 bra 	$L__BB225_19;
	shl.b32 	%r119, %r221, %r27;
	shl.b32 	%r120, %r220, %r27;
	mov.b32 	%r121, 32;
	sub.s32 	%r122, %r121, %r27;
	shr.u32 	%r123, %r221, %r122;
	add.s32 	%r220, %r123, %r120;
	ld.local.u32 	%r124, [%rd19+16];
	shr.u32 	%r125, %r124, %r122;
	add.s32 	%r221, %r125, %r119;
$L__BB225_19:
	shr.u32 	%r126, %r220, 30;
	shr.u32 	%r127, %r221, 30;
	shl.b32 	%r128, %r220, 2;
	or.b32  	%r129, %r128, %r127;
	shl.b32 	%r130, %r221, 2;
	bfe.u32 	%r131, %r220, 29, 1;
	add.s32 	%r132, %r131, %r126;
	neg.s32 	%r133, %r132;
	setp.lt.s32 	%p16, %r21, 0;
	selp.b32 	%r222, %r133, %r132, %p16;
	xor.b32  	%r134, %r129, %r21;
	bfe.s32 	%r135, %r220, 29, 1;
	xor.b32  	%r136, %r135, %r129;
	xor.b32  	%r137, %r135, %r130;
	cvt.u64.u32 	%rd63, %r136;
	shl.b64 	%rd64, %rd63, 32;
	cvt.u64.u32 	%rd65, %r137;
	or.b64  	%rd66, %rd64, %rd65;
	cvt.rn.f64.s64 	%fd3, %rd66;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f155, %fd4;
	neg.f32 	%f156, %f155;
	setp.lt.s32 	%p17, %r134, 0;
	selp.f32 	%f315, %f156, %f155, %p17;
$L__BB225_20:
	mul.rn.f32 	%f10, %f1, %f154;
	cvta.to.global.u64 	%rd4, %rd32;
	mul.rn.f32 	%f158, %f315, %f315;
	and.b32  	%r139, %r222, 1;
	setp.eq.b32 	%p18, %r139, 1;
	selp.f32 	%f159, 0f3F800000, %f315, %p18;
	fma.rn.f32 	%f160, %f158, %f159, 0f00000000;
	fma.rn.f32 	%f161, %f158, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f162, %f161, 0fB94D4153, %p18;
	selp.f32 	%f163, 0f3D2AAABB, 0f3C0885E4, %p18;
	fma.rn.f32 	%f164, %f162, %f158, %f163;
	selp.f32 	%f165, 0fBEFFFFFF, 0fBE2AAAA8, %p18;
	fma.rn.f32 	%f166, %f164, %f158, %f165;
	fma.rn.f32 	%f167, %f166, %f160, %f159;
	and.b32  	%r140, %r222, 2;
	setp.eq.s32 	%p19, %r140, 0;
	sub.rn.f32 	%f169, %f53, %f167;
	selp.f32 	%f170, %f167, %f169, %p19;
	mul.rn.f32 	%f171, %f9, %f170;
	add.s64 	%rd68, %rd3, %rd54;
	add.s64 	%rd70, %rd68, %rd56;
	ld.global.nc.f32 	%f173, [%rd70];
	add.rn.f32 	%f174, %f173, 0f00000000;
	ld.global.nc.f32 	%f175, [%rd70+24];
	add.rn.f32 	%f176, %f174, %f175;
	ld.global.nc.f32 	%f177, [%rd70+48];
	add.rn.f32 	%f178, %f176, %f177;
	ld.global.nc.f32 	%f179, [%rd70+72];
	add.rn.f32 	%f180, %f178, %f179;
	ld.global.nc.f32 	%f181, [%rd70+96];
	add.rn.f32 	%f182, %f180, %f181;
	ld.global.nc.f32 	%f183, [%rd70+120];
	add.rn.f32 	%f184, %f182, %f183;
	ld.global.nc.f32 	%f185, [%rd70+144];
	add.rn.f32 	%f186, %f184, %f185;
	ld.global.nc.f32 	%f187, [%rd70+168];
	add.rn.f32 	%f188, %f186, %f187;
	ld.global.nc.f32 	%f189, [%rd70+192];
	add.rn.f32 	%f190, %f188, %f189;
	ld.global.nc.f32 	%f191, [%rd70+216];
	add.rn.f32 	%f192, %f190, %f191;
	ld.global.nc.f32 	%f193, [%rd70+240];
	add.rn.f32 	%f194, %f192, %f193;
	ld.global.nc.f32 	%f195, [%rd70+264];
	add.rn.f32 	%f196, %f194, %f195;
	ld.global.nc.f32 	%f197, [%rd70+288];
	add.rn.f32 	%f198, %f196, %f197;
	ld.global.nc.f32 	%f199, [%rd70+312];
	add.rn.f32 	%f200, %f198, %f199;
	ld.global.nc.f32 	%f201, [%rd70+336];
	add.rn.f32 	%f202, %f200, %f201;
	ld.global.nc.f32 	%f203, [%rd70+360];
	add.rn.f32 	%f204, %f202, %f203;
	ld.global.nc.f32 	%f205, [%rd70+384];
	add.rn.f32 	%f206, %f204, %f205;
	ld.global.nc.f32 	%f207, [%rd70+408];
	add.rn.f32 	%f208, %f206, %f207;
	ld.global.nc.f32 	%f209, [%rd70+432];
	add.rn.f32 	%f210, %f208, %f209;
	ld.global.nc.f32 	%f211, [%rd70+456];
	add.rn.f32 	%f212, %f210, %f211;
	ld.global.nc.f32 	%f213, [%rd70+480];
	add.rn.f32 	%f214, %f212, %f213;
	ld.global.nc.f32 	%f215, [%rd70+504];
	add.rn.f32 	%f216, %f214, %f215;
	ld.global.nc.f32 	%f217, [%rd70+528];
	add.rn.f32 	%f218, %f216, %f217;
	ld.global.nc.f32 	%f219, [%rd70+552];
	add.rn.f32 	%f220, %f218, %f219;
	ld.global.nc.f32 	%f221, [%rd70+576];
	add.rn.f32 	%f222, %f220, %f221;
	ld.global.nc.f32 	%f223, [%rd70+600];
	add.rn.f32 	%f224, %f222, %f223;
	ld.global.nc.f32 	%f225, [%rd70+624];
	add.rn.f32 	%f226, %f224, %f225;
	ld.global.nc.f32 	%f227, [%rd70+648];
	add.rn.f32 	%f228, %f226, %f227;
	ld.global.nc.f32 	%f229, [%rd70+672];
	add.rn.f32 	%f230, %f228, %f229;
	ld.global.nc.f32 	%f231, [%rd70+696];
	add.rn.f32 	%f232, %f230, %f231;
	ld.global.nc.f32 	%f233, [%rd70+720];
	add.rn.f32 	%f234, %f232, %f233;
	ld.global.nc.f32 	%f235, [%rd70+744];
	add.rn.f32 	%f236, %f234, %f235;
	ld.global.nc.f32 	%f237, [%rd70+768];
	add.rn.f32 	%f238, %f236, %f237;
	ld.global.nc.f32 	%f239, [%rd70+792];
	add.rn.f32 	%f240, %f238, %f239;
	ld.global.nc.f32 	%f241, [%rd70+816];
	add.rn.f32 	%f242, %f240, %f241;
	ld.global.nc.f32 	%f243, [%rd70+840];
	add.rn.f32 	%f244, %f242, %f243;
	ld.global.nc.f32 	%f245, [%rd70+864];
	add.rn.f32 	%f246, %f244, %f245;
	ld.global.nc.f32 	%f247, [%rd70+888];
	add.rn.f32 	%f248, %f246, %f247;
	ld.global.nc.f32 	%f249, [%rd70+912];
	add.rn.f32 	%f250, %f248, %f249;
	ld.global.nc.f32 	%f251, [%rd70+936];
	add.rn.f32 	%f252, %f250, %f251;
	ld.global.nc.f32 	%f253, [%rd70+960];
	add.rn.f32 	%f254, %f252, %f253;
	ld.global.nc.f32 	%f255, [%rd70+984];
	add.rn.f32 	%f256, %f254, %f255;
	ld.global.nc.f32 	%f257, [%rd70+1008];
	add.rn.f32 	%f258, %f256, %f257;
	ld.global.nc.f32 	%f259, [%rd70+1032];
	add.rn.f32 	%f260, %f258, %f259;
	ld.global.nc.f32 	%f261, [%rd70+1056];
	add.rn.f32 	%f262, %f260, %f261;
	ld.global.nc.f32 	%f263, [%rd70+1080];
	add.rn.f32 	%f264, %f262, %f263;
	ld.global.nc.f32 	%f265, [%rd70+1104];
	add.rn.f32 	%f266, %f264, %f265;
	ld.global.nc.f32 	%f267, [%rd70+1128];
	add.rn.f32 	%f268, %f266, %f267;
	ld.global.nc.f32 	%f269, [%rd70+1152];
	add.rn.f32 	%f270, %f268, %f269;
	ld.global.nc.f32 	%f271, [%rd70+1176];
	add.rn.f32 	%f18, %f270, %f271;
	mul.rn.f32 	%f272, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r230, %f272;
	cvt.rn.f32.s32 	%f273, %r230;
	fma.rn.f32 	%f274, %f273, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f275, %f273, 0fB3A22168, %f274;
	fma.rn.f32 	%f317, %f273, 0fA7C234C5, %f275;
	abs.f32 	%f21, %f2;
	setp.ltu.f32 	%p20, %f21, 0f47CE4780;
	setp.neu.f32 	%p39, %f21, 0f7F800000;
	mov.u32 	%r226, %r230;
	mov.f32 	%f316, %f317;
	@%p20 bra 	$L__BB225_28;
	@%p39 bra 	$L__BB225_23;
	mul.rn.f32 	%f316, %f2, %f53;
	mov.b32 	%r226, 0;
	bra.uni 	$L__BB225_28;
$L__BB225_23:
	mov.b32 	%r37, %f2;
	shr.u32 	%r38, %r37, 23;
	and.b32  	%r142, %r38, 224;
	add.s32 	%r143, %r142, -128;
	shl.b32 	%r144, %r37, 8;
	or.b32  	%r148, %r144, -2147483648;
	shr.u32 	%r40, %r143, 5;
	mov.b32 	%r223, 0;
	mov.u64 	%rd103, 0;
	mov.u64 	%rd72, __cudart_i2opi_f;
$L__BB225_24:
	.pragma "nounroll";
	add.s64 	%rd73, %rd72, %rd103;
	ld.global.nc.u32 	%r147, [%rd73];
	// begin inline asm
	{
	mad.lo.cc.u32   %r145, %r147, %r148, %r223;
	madc.hi.u32     %r223, %r147, %r148,  0;
	}
	// end inline asm
	add.s64 	%rd74, %rd8, %rd103;
	st.local.u32 	[%rd74], %r145;
	add.s64 	%rd103, %rd103, 4;
	cvt.u32.u64 	%r150, %rd103;
	setp.ne.s32 	%p22, %r150, 24;
	@%p22 bra 	$L__BB225_24;
	st.local.u32 	[%rd8+24], %r223;
	and.b32  	%r43, %r38, 31;
	mul.wide.u32 	%rd75, %r40, 4;
	sub.s64 	%rd22, %rd8, %rd75;
	ld.local.u32 	%r224, [%rd22+24];
	ld.local.u32 	%r225, [%rd22+20];
	setp.eq.s32 	%p23, %r43, 0;
	@%p23 bra 	$L__BB225_27;
	shl.b32 	%r151, %r225, %r43;
	shl.b32 	%r152, %r224, %r43;
	mov.b32 	%r153, 32;
	sub.s32 	%r154, %r153, %r43;
	shr.u32 	%r155, %r225, %r154;
	add.s32 	%r224, %r155, %r152;
	ld.local.u32 	%r156, [%rd22+16];
	shr.u32 	%r157, %r156, %r154;
	add.s32 	%r225, %r157, %r151;
$L__BB225_27:
	shr.u32 	%r158, %r224, 30;
	shr.u32 	%r159, %r225, 30;
	shl.b32 	%r160, %r224, 2;
	or.b32  	%r161, %r160, %r159;
	shl.b32 	%r162, %r225, 2;
	bfe.u32 	%r163, %r224, 29, 1;
	add.s32 	%r164, %r163, %r158;
	neg.s32 	%r165, %r164;
	setp.lt.s32 	%p24, %r37, 0;
	selp.b32 	%r226, %r165, %r164, %p24;
	xor.b32  	%r166, %r161, %r37;
	bfe.s32 	%r167, %r224, 29, 1;
	xor.b32  	%r168, %r167, %r161;
	xor.b32  	%r169, %r167, %r162;
	cvt.u64.u32 	%rd76, %r168;
	shl.b64 	%rd77, %rd76, 32;
	cvt.u64.u32 	%rd78, %r169;
	or.b64  	%rd79, %rd77, %rd78;
	cvt.rn.f64.s64 	%fd5, %rd79;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f276, %fd6;
	neg.f32 	%f277, %f276;
	setp.lt.s32 	%p25, %r166, 0;
	selp.f32 	%f316, %f277, %f276, %p25;
$L__BB225_28:
	sub.rn.f32 	%f172, %f10, %f171;
	add.s32 	%r171, %r226, 1;
	mul.rn.f32 	%f279, %f316, %f316;
	and.b32  	%r172, %r226, 1;
	setp.eq.b32 	%p27, %r172, 1;
	selp.f32 	%f280, %f316, 0f3F800000, %p27;
	fma.rn.f32 	%f281, %f279, %f280, 0f00000000;
	fma.rn.f32 	%f282, %f279, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f283, 0fB94D4153, %f282, %p27;
	selp.f32 	%f284, 0f3C0885E4, 0f3D2AAABB, %p27;
	fma.rn.f32 	%f285, %f283, %f279, %f284;
	selp.f32 	%f286, 0fBE2AAAA8, 0fBEFFFFFF, %p27;
	fma.rn.f32 	%f287, %f285, %f279, %f286;
	fma.rn.f32 	%f288, %f287, %f281, %f280;
	and.b32  	%r173, %r171, 2;
	setp.eq.s32 	%p28, %r173, 0;
	sub.rn.f32 	%f290, %f53, %f288;
	selp.f32 	%f291, %f288, %f290, %p28;
	mul.rn.f32 	%f25, %f18, %f291;
	mul.lo.s64 	%rd80, %rd12, 24;
	add.s64 	%rd81, %rd4, %rd80;
	add.s64 	%rd83, %rd81, %rd56;
	ld.global.nc.f32 	%f26, [%rd83];
	@%p20 bra 	$L__BB225_36;
	@%p39 bra 	$L__BB225_31;
	mul.rn.f32 	%f317, %f2, %f53;
	mov.b32 	%r230, 0;
	bra.uni 	$L__BB225_36;
$L__BB225_31:
	mov.b32 	%r52, %f2;
	shr.u32 	%r53, %r52, 23;
	and.b32  	%r175, %r53, 224;
	add.s32 	%r176, %r175, -128;
	shl.b32 	%r177, %r52, 8;
	or.b32  	%r181, %r177, -2147483648;
	shr.u32 	%r55, %r176, 5;
	mov.b32 	%r227, 0;
	mov.u64 	%rd104, 0;
	mov.u64 	%rd85, __cudart_i2opi_f;
$L__BB225_32:
	.pragma "nounroll";
	add.s64 	%rd86, %rd85, %rd104;
	ld.global.nc.u32 	%r180, [%rd86];
	// begin inline asm
	{
	mad.lo.cc.u32   %r178, %r180, %r181, %r227;
	madc.hi.u32     %r227, %r180, %r181,  0;
	}
	// end inline asm
	add.s64 	%rd87, %rd8, %rd104;
	st.local.u32 	[%rd87], %r178;
	add.s64 	%rd104, %rd104, 4;
	cvt.u32.u64 	%r183, %rd104;
	setp.ne.s32 	%p30, %r183, 24;
	@%p30 bra 	$L__BB225_32;
	st.local.u32 	[%rd8+24], %r227;
	and.b32  	%r58, %r53, 31;
	mul.wide.u32 	%rd88, %r55, 4;
	sub.s64 	%rd25, %rd8, %rd88;
	ld.local.u32 	%r228, [%rd25+24];
	ld.local.u32 	%r229, [%rd25+20];
	setp.eq.s32 	%p31, %r58, 0;
	@%p31 bra 	$L__BB225_35;
	shl.b32 	%r184, %r229, %r58;
	shl.b32 	%r185, %r228, %r58;
	mov.b32 	%r186, 32;
	sub.s32 	%r187, %r186, %r58;
	shr.u32 	%r188, %r229, %r187;
	add.s32 	%r228, %r188, %r185;
	ld.local.u32 	%r189, [%rd25+16];
	shr.u32 	%r190, %r189, %r187;
	add.s32 	%r229, %r190, %r184;
$L__BB225_35:
	shr.u32 	%r191, %r228, 30;
	shr.u32 	%r192, %r229, 30;
	shl.b32 	%r193, %r228, 2;
	or.b32  	%r194, %r193, %r192;
	shl.b32 	%r195, %r229, 2;
	bfe.u32 	%r196, %r228, 29, 1;
	add.s32 	%r197, %r196, %r191;
	neg.s32 	%r198, %r197;
	setp.lt.s32 	%p32, %r52, 0;
	selp.b32 	%r230, %r198, %r197, %p32;
	xor.b32  	%r199, %r194, %r52;
	bfe.s32 	%r200, %r228, 29, 1;
	xor.b32  	%r201, %r200, %r194;
	xor.b32  	%r202, %r200, %r195;
	cvt.u64.u32 	%rd89, %r201;
	shl.b64 	%rd90, %rd89, 32;
	cvt.u64.u32 	%rd91, %r202;
	or.b64  	%rd92, %rd90, %rd91;
	cvt.rn.f64.s64 	%fd7, %rd92;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f292, %fd8;
	neg.f32 	%f293, %f292;
	setp.lt.s32 	%p33, %r199, 0;
	selp.f32 	%f317, %f293, %f292, %p33;
$L__BB225_36:
	add.rn.f32 	%f313, %f172, 0f00000000;
	mul.rn.f32 	%f295, %f317, %f317;
	and.b32  	%r204, %r230, 1;
	setp.eq.b32 	%p34, %r204, 1;
	selp.f32 	%f296, 0f3F800000, %f317, %p34;
	fma.rn.f32 	%f297, %f295, %f296, 0f00000000;
	fma.rn.f32 	%f298, %f295, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f299, %f298, 0fB94D4153, %p34;
	selp.f32 	%f300, 0f3D2AAABB, 0f3C0885E4, %p34;
	fma.rn.f32 	%f301, %f299, %f295, %f300;
	selp.f32 	%f302, 0fBEFFFFFF, 0fBE2AAAA8, %p34;
	fma.rn.f32 	%f303, %f301, %f295, %f302;
	fma.rn.f32 	%f304, %f303, %f297, %f296;
	and.b32  	%r205, %r230, 2;
	setp.eq.s32 	%p35, %r205, 0;
	sub.rn.f32 	%f306, %f53, %f304;
	selp.f32 	%f307, %f304, %f306, %p35;
	mul.rn.f32 	%f308, %f26, %f307;
	add.rn.f32 	%f309, %f25, %f308;
	add.rn.f32 	%f314, %f309, 0f00000000;
$L__BB225_12:
	setp.lt.u32 	%p36, %r1, %r3;
	shfl.sync.down.b32	%f13, %f313, 1, 31, -1;
	setp.eq.s32 	%p37, %r2, 0;
	and.pred  	%p1, %p37, %p36;
	@%p1 bra 	$L__BB225_37;
	bra.uni 	$L__BB225_13;
$L__BB225_37:
	ld.param.u64 	%rd29, [input_reduce_fusion_319_param_5];
	cvta.to.global.u64 	%rd2, %rd29;
	add.rn.f32 	%f310, %f313, %f13;
	or.b32  	%r206, %r4, %r1;
	mul.hi.u32 	%r207, %r206, 1431655766;
	mul.lo.s32 	%r208, %r207, 3;
	sub.s32 	%r209, %r206, %r208;
	mul.wide.u32 	%rd93, %r209, 4;
	mul.wide.u32 	%rd94, %r207, 12;
	add.s64 	%rd95, %rd2, %rd94;
	add.s64 	%rd96, %rd95, %rd93;
	st.global.f32 	[%rd96], %f310;
$L__BB225_13:
	shfl.sync.down.b32	%f14, %f314, 1, 31, -1;
	@%p1 bra 	$L__BB225_38;
	bra.uni 	$L__BB225_14;
$L__BB225_38:
	ld.param.u64 	%rd27, [input_reduce_fusion_319_param_6];
	cvta.to.global.u64 	%rd1, %rd27;
	add.rn.f32 	%f311, %f314, %f14;
	or.b32  	%r210, %r4, %r1;
	mul.hi.u32 	%r211, %r210, 1431655766;
	mul.lo.s32 	%r212, %r211, 3;
	sub.s32 	%r213, %r210, %r212;
	mul.wide.u32 	%rd97, %r213, 4;
	mul.wide.u32 	%rd98, %r211, 12;
	add.s64 	%rd99, %rd1, %rd98;
	add.s64 	%rd100, %rd99, %rd97;
	st.global.f32 	[%rd100], %f311;
$L__BB225_14:
	ret;

}
	// .globl	loop_reduce_fusion_46
.visible .entry loop_reduce_fusion_46(
	.param .u64 loop_reduce_fusion_46_param_0,
	.param .u64 loop_reduce_fusion_46_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<101>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd1, [loop_reduce_fusion_46_param_0];
	ld.param.u64 	%rd2, [loop_reduce_fusion_46_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs3, 1;
	shr.u16 	%rs7, %rs2, 3;
	cvt.u32.u16 	%r5, %rs7;
	mul.wide.u32 	%rd5, %r5, 2400;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r6, %rs6;
	mul.wide.u32 	%rd7, %r6, 24;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r7, %rs5;
	mul.wide.u32 	%rd9, %r7, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	add.rn.f32 	%f2, %f1, 0f00000000;
	ld.global.nc.f32 	%f3, [%rd10+48];
	add.rn.f32 	%f4, %f2, %f3;
	ld.global.nc.f32 	%f5, [%rd10+96];
	add.rn.f32 	%f6, %f4, %f5;
	ld.global.nc.f32 	%f7, [%rd10+144];
	add.rn.f32 	%f8, %f6, %f7;
	ld.global.nc.f32 	%f9, [%rd10+192];
	add.rn.f32 	%f10, %f8, %f9;
	ld.global.nc.f32 	%f11, [%rd10+240];
	add.rn.f32 	%f12, %f10, %f11;
	ld.global.nc.f32 	%f13, [%rd10+288];
	add.rn.f32 	%f14, %f12, %f13;
	ld.global.nc.f32 	%f15, [%rd10+336];
	add.rn.f32 	%f16, %f14, %f15;
	ld.global.nc.f32 	%f17, [%rd10+384];
	add.rn.f32 	%f18, %f16, %f17;
	ld.global.nc.f32 	%f19, [%rd10+432];
	add.rn.f32 	%f20, %f18, %f19;
	ld.global.nc.f32 	%f21, [%rd10+480];
	add.rn.f32 	%f22, %f20, %f21;
	ld.global.nc.f32 	%f23, [%rd10+528];
	add.rn.f32 	%f24, %f22, %f23;
	ld.global.nc.f32 	%f25, [%rd10+576];
	add.rn.f32 	%f26, %f24, %f25;
	ld.global.nc.f32 	%f27, [%rd10+624];
	add.rn.f32 	%f28, %f26, %f27;
	ld.global.nc.f32 	%f29, [%rd10+672];
	add.rn.f32 	%f30, %f28, %f29;
	ld.global.nc.f32 	%f31, [%rd10+720];
	add.rn.f32 	%f32, %f30, %f31;
	ld.global.nc.f32 	%f33, [%rd10+768];
	add.rn.f32 	%f34, %f32, %f33;
	ld.global.nc.f32 	%f35, [%rd10+816];
	add.rn.f32 	%f36, %f34, %f35;
	ld.global.nc.f32 	%f37, [%rd10+864];
	add.rn.f32 	%f38, %f36, %f37;
	ld.global.nc.f32 	%f39, [%rd10+912];
	add.rn.f32 	%f40, %f38, %f39;
	ld.global.nc.f32 	%f41, [%rd10+960];
	add.rn.f32 	%f42, %f40, %f41;
	ld.global.nc.f32 	%f43, [%rd10+1008];
	add.rn.f32 	%f44, %f42, %f43;
	ld.global.nc.f32 	%f45, [%rd10+1056];
	add.rn.f32 	%f46, %f44, %f45;
	ld.global.nc.f32 	%f47, [%rd10+1104];
	add.rn.f32 	%f48, %f46, %f47;
	ld.global.nc.f32 	%f49, [%rd10+1152];
	add.rn.f32 	%f50, %f48, %f49;
	ld.global.nc.f32 	%f51, [%rd10+1200];
	add.rn.f32 	%f52, %f50, %f51;
	ld.global.nc.f32 	%f53, [%rd10+1248];
	add.rn.f32 	%f54, %f52, %f53;
	ld.global.nc.f32 	%f55, [%rd10+1296];
	add.rn.f32 	%f56, %f54, %f55;
	ld.global.nc.f32 	%f57, [%rd10+1344];
	add.rn.f32 	%f58, %f56, %f57;
	ld.global.nc.f32 	%f59, [%rd10+1392];
	add.rn.f32 	%f60, %f58, %f59;
	ld.global.nc.f32 	%f61, [%rd10+1440];
	add.rn.f32 	%f62, %f60, %f61;
	ld.global.nc.f32 	%f63, [%rd10+1488];
	add.rn.f32 	%f64, %f62, %f63;
	ld.global.nc.f32 	%f65, [%rd10+1536];
	add.rn.f32 	%f66, %f64, %f65;
	ld.global.nc.f32 	%f67, [%rd10+1584];
	add.rn.f32 	%f68, %f66, %f67;
	ld.global.nc.f32 	%f69, [%rd10+1632];
	add.rn.f32 	%f70, %f68, %f69;
	ld.global.nc.f32 	%f71, [%rd10+1680];
	add.rn.f32 	%f72, %f70, %f71;
	ld.global.nc.f32 	%f73, [%rd10+1728];
	add.rn.f32 	%f74, %f72, %f73;
	ld.global.nc.f32 	%f75, [%rd10+1776];
	add.rn.f32 	%f76, %f74, %f75;
	ld.global.nc.f32 	%f77, [%rd10+1824];
	add.rn.f32 	%f78, %f76, %f77;
	ld.global.nc.f32 	%f79, [%rd10+1872];
	add.rn.f32 	%f80, %f78, %f79;
	ld.global.nc.f32 	%f81, [%rd10+1920];
	add.rn.f32 	%f82, %f80, %f81;
	ld.global.nc.f32 	%f83, [%rd10+1968];
	add.rn.f32 	%f84, %f82, %f83;
	ld.global.nc.f32 	%f85, [%rd10+2016];
	add.rn.f32 	%f86, %f84, %f85;
	ld.global.nc.f32 	%f87, [%rd10+2064];
	add.rn.f32 	%f88, %f86, %f87;
	ld.global.nc.f32 	%f89, [%rd10+2112];
	add.rn.f32 	%f90, %f88, %f89;
	ld.global.nc.f32 	%f91, [%rd10+2160];
	add.rn.f32 	%f92, %f90, %f91;
	ld.global.nc.f32 	%f93, [%rd10+2208];
	add.rn.f32 	%f94, %f92, %f93;
	ld.global.nc.f32 	%f95, [%rd10+2256];
	add.rn.f32 	%f96, %f94, %f95;
	ld.global.nc.f32 	%f97, [%rd10+2304];
	add.rn.f32 	%f98, %f96, %f97;
	ld.global.nc.f32 	%f99, [%rd10+2352];
	add.rn.f32 	%f100, %f98, %f99;
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd3, %rd11;
	st.global.f32 	[%rd12], %f100;
	ret;

}
	// .globl	input_reduce_fusion_320
.visible .entry input_reduce_fusion_320(
	.param .u64 input_reduce_fusion_320_param_0,
	.param .u64 input_reduce_fusion_320_param_1,
	.param .u64 input_reduce_fusion_320_param_2,
	.param .u64 input_reduce_fusion_320_param_3
)
.reqntid 256, 1, 1
{
	.local .align 4 .b8 	__local_depot227[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<19>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<121>;
	.reg .f32 	%f<160>;
	.reg .b64 	%rd<64>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot227;
	ld.param.u64 	%rd14, [input_reduce_fusion_320_param_0];
	ld.param.u64 	%rd16, [input_reduce_fusion_320_param_1];
	ld.param.u64 	%rd17, [input_reduce_fusion_320_param_2];
	cvta.to.global.u64 	%rd18, %rd17;
	cvta.to.global.u64 	%rd19, %rd16;
	cvta.to.global.u64 	%rd2, %rd14;
	add.u64 	%rd3, %SPL, 0;
	mov.u32 	%r34, %tid.x;
	mov.u32 	%r35, %ctaid.x;
	shr.u32 	%r36, %r34, 1;
	and.b32  	%r1, %r34, 1;
	shl.b32 	%r37, %r35, 7;
	or.b32  	%r2, %r36, %r37;
	cvt.u16.u32 	%rs1, %r2;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs3, 1;
	shr.u16 	%rs7, %rs2, 2;
	shl.b16 	%rs8, %rs5, 1;
	cvt.u32.u16 	%r38, %rs8;
	or.b32  	%r39, %r1, %r38;
	cvt.u64.u16 	%rd5, %rs7;
	cvt.u64.u16 	%rd6, %rs6;
	cvt.u64.u32 	%rd7, %r39;
	cvt.u32.u16 	%r40, %rs7;
	mul.wide.u32 	%rd22, %r40, 2400;
	add.s64 	%rd23, %rd18, %rd22;
	cvt.u32.u16 	%r41, %rs6;
	mul.wide.u32 	%rd24, %r41, 24;
	add.s64 	%rd25, %rd23, %rd24;
	mul.wide.u32 	%rd26, %r39, 4;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.f32 	%f15, [%rd27];
	add.rn.f32 	%f16, %f15, 0f00000000;
	ld.global.nc.f32 	%f17, [%rd27+48];
	add.rn.f32 	%f18, %f16, %f17;
	ld.global.nc.f32 	%f19, [%rd27+96];
	add.rn.f32 	%f20, %f18, %f19;
	ld.global.nc.f32 	%f21, [%rd27+144];
	add.rn.f32 	%f22, %f20, %f21;
	ld.global.nc.f32 	%f23, [%rd27+192];
	add.rn.f32 	%f24, %f22, %f23;
	ld.global.nc.f32 	%f25, [%rd27+240];
	add.rn.f32 	%f26, %f24, %f25;
	ld.global.nc.f32 	%f27, [%rd27+288];
	add.rn.f32 	%f28, %f26, %f27;
	ld.global.nc.f32 	%f29, [%rd27+336];
	add.rn.f32 	%f30, %f28, %f29;
	ld.global.nc.f32 	%f31, [%rd27+384];
	add.rn.f32 	%f32, %f30, %f31;
	ld.global.nc.f32 	%f33, [%rd27+432];
	add.rn.f32 	%f34, %f32, %f33;
	ld.global.nc.f32 	%f35, [%rd27+480];
	add.rn.f32 	%f36, %f34, %f35;
	ld.global.nc.f32 	%f37, [%rd27+528];
	add.rn.f32 	%f38, %f36, %f37;
	ld.global.nc.f32 	%f39, [%rd27+576];
	add.rn.f32 	%f40, %f38, %f39;
	ld.global.nc.f32 	%f41, [%rd27+624];
	add.rn.f32 	%f42, %f40, %f41;
	ld.global.nc.f32 	%f43, [%rd27+672];
	add.rn.f32 	%f44, %f42, %f43;
	ld.global.nc.f32 	%f45, [%rd27+720];
	add.rn.f32 	%f46, %f44, %f45;
	ld.global.nc.f32 	%f47, [%rd27+768];
	add.rn.f32 	%f48, %f46, %f47;
	ld.global.nc.f32 	%f49, [%rd27+816];
	add.rn.f32 	%f50, %f48, %f49;
	ld.global.nc.f32 	%f51, [%rd27+864];
	add.rn.f32 	%f52, %f50, %f51;
	ld.global.nc.f32 	%f53, [%rd27+912];
	add.rn.f32 	%f54, %f52, %f53;
	ld.global.nc.f32 	%f55, [%rd27+960];
	add.rn.f32 	%f56, %f54, %f55;
	ld.global.nc.f32 	%f57, [%rd27+1008];
	add.rn.f32 	%f58, %f56, %f57;
	ld.global.nc.f32 	%f59, [%rd27+1056];
	add.rn.f32 	%f60, %f58, %f59;
	ld.global.nc.f32 	%f61, [%rd27+1104];
	add.rn.f32 	%f62, %f60, %f61;
	ld.global.nc.f32 	%f63, [%rd27+1152];
	add.rn.f32 	%f64, %f62, %f63;
	ld.global.nc.f32 	%f65, [%rd27+1200];
	add.rn.f32 	%f66, %f64, %f65;
	ld.global.nc.f32 	%f67, [%rd27+1248];
	add.rn.f32 	%f68, %f66, %f67;
	ld.global.nc.f32 	%f69, [%rd27+1296];
	add.rn.f32 	%f70, %f68, %f69;
	ld.global.nc.f32 	%f71, [%rd27+1344];
	add.rn.f32 	%f72, %f70, %f71;
	ld.global.nc.f32 	%f73, [%rd27+1392];
	add.rn.f32 	%f74, %f72, %f73;
	ld.global.nc.f32 	%f75, [%rd27+1440];
	add.rn.f32 	%f76, %f74, %f75;
	ld.global.nc.f32 	%f77, [%rd27+1488];
	add.rn.f32 	%f78, %f76, %f77;
	ld.global.nc.f32 	%f79, [%rd27+1536];
	add.rn.f32 	%f80, %f78, %f79;
	ld.global.nc.f32 	%f81, [%rd27+1584];
	add.rn.f32 	%f82, %f80, %f81;
	ld.global.nc.f32 	%f83, [%rd27+1632];
	add.rn.f32 	%f84, %f82, %f83;
	ld.global.nc.f32 	%f85, [%rd27+1680];
	add.rn.f32 	%f86, %f84, %f85;
	ld.global.nc.f32 	%f87, [%rd27+1728];
	add.rn.f32 	%f88, %f86, %f87;
	ld.global.nc.f32 	%f89, [%rd27+1776];
	add.rn.f32 	%f90, %f88, %f89;
	ld.global.nc.f32 	%f91, [%rd27+1824];
	add.rn.f32 	%f92, %f90, %f91;
	ld.global.nc.f32 	%f93, [%rd27+1872];
	add.rn.f32 	%f94, %f92, %f93;
	ld.global.nc.f32 	%f95, [%rd27+1920];
	add.rn.f32 	%f96, %f94, %f95;
	ld.global.nc.f32 	%f97, [%rd27+1968];
	add.rn.f32 	%f98, %f96, %f97;
	ld.global.nc.f32 	%f99, [%rd27+2016];
	add.rn.f32 	%f100, %f98, %f99;
	ld.global.nc.f32 	%f101, [%rd27+2064];
	add.rn.f32 	%f102, %f100, %f101;
	ld.global.nc.f32 	%f103, [%rd27+2112];
	add.rn.f32 	%f104, %f102, %f103;
	ld.global.nc.f32 	%f105, [%rd27+2160];
	add.rn.f32 	%f106, %f104, %f105;
	ld.global.nc.f32 	%f107, [%rd27+2208];
	add.rn.f32 	%f108, %f106, %f107;
	ld.global.nc.f32 	%f109, [%rd27+2256];
	add.rn.f32 	%f110, %f108, %f109;
	ld.global.nc.f32 	%f111, [%rd27+2304];
	add.rn.f32 	%f112, %f110, %f111;
	ld.global.nc.f32 	%f113, [%rd27+2352];
	add.rn.f32 	%f1, %f112, %f113;
	cvt.u32.u16 	%r42, %rs5;
	mul.wide.u32 	%rd28, %r42, 4;
	mul.wide.u32 	%rd29, %r40, 12;
	add.s64 	%rd30, %rd19, %rd29;
	add.s64 	%rd31, %rd30, %rd28;
	ld.global.nc.f32 	%f114, [%rd31];
	add.rn.f32 	%f115, %f114, %f114;
	add.rn.f32 	%f116, %f115, %f115;
	add.rn.f32 	%f117, %f116, %f116;
	add.rn.f32 	%f2, %f117, %f117;
	mul.rn.f32 	%f118, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r120, %f118;
	cvt.rn.f32.s32 	%f119, %r120;
	fma.rn.f32 	%f120, %f119, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f121, %f119, 0fB3A22168, %f120;
	fma.rn.f32 	%f159, %f119, 0fA7C234C5, %f121;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p1, %f4, 0f47CE4780;
	mov.f32 	%f157, 0f00000000;
	setp.neu.f32 	%p18, %f4, 0f7F800000;
	mov.u32 	%r116, %r120;
	mov.f32 	%f158, %f159;
	@%p1 bra 	$L__BB227_8;
	@%p18 bra 	$L__BB227_3;
	mul.rn.f32 	%f158, %f2, %f157;
	mov.b32 	%r116, 0;
	bra.uni 	$L__BB227_8;
$L__BB227_3:
	mov.b32 	%r4, %f2;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r44, %r5, 224;
	add.s32 	%r45, %r44, -128;
	shl.b32 	%r46, %r4, 8;
	or.b32  	%r50, %r46, -2147483648;
	shr.u32 	%r7, %r45, 5;
	mov.b32 	%r113, 0;
	mov.u64 	%rd62, 0;
	mov.u64 	%rd33, __cudart_i2opi_f;
$L__BB227_4:
	.pragma "nounroll";
	add.s64 	%rd34, %rd33, %rd62;
	ld.global.nc.u32 	%r49, [%rd34];
	// begin inline asm
	{
	mad.lo.cc.u32   %r47, %r49, %r50, %r113;
	madc.hi.u32     %r113, %r49, %r50,  0;
	}
	// end inline asm
	add.s64 	%rd35, %rd3, %rd62;
	st.local.u32 	[%rd35], %r47;
	add.s64 	%rd62, %rd62, 4;
	cvt.u32.u64 	%r52, %rd62;
	setp.ne.s32 	%p3, %r52, 24;
	@%p3 bra 	$L__BB227_4;
	st.local.u32 	[%rd3+24], %r113;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd36, %r7, 4;
	sub.s64 	%rd10, %rd3, %rd36;
	ld.local.u32 	%r114, [%rd10+24];
	ld.local.u32 	%r115, [%rd10+20];
	setp.eq.s32 	%p4, %r10, 0;
	@%p4 bra 	$L__BB227_7;
	shl.b32 	%r53, %r115, %r10;
	shl.b32 	%r54, %r114, %r10;
	mov.b32 	%r55, 32;
	sub.s32 	%r56, %r55, %r10;
	shr.u32 	%r57, %r115, %r56;
	add.s32 	%r114, %r57, %r54;
	ld.local.u32 	%r58, [%rd10+16];
	shr.u32 	%r59, %r58, %r56;
	add.s32 	%r115, %r59, %r53;
$L__BB227_7:
	shr.u32 	%r60, %r114, 30;
	shr.u32 	%r61, %r115, 30;
	shl.b32 	%r62, %r114, 2;
	or.b32  	%r63, %r62, %r61;
	shl.b32 	%r64, %r115, 2;
	bfe.u32 	%r65, %r114, 29, 1;
	add.s32 	%r66, %r65, %r60;
	neg.s32 	%r67, %r66;
	setp.lt.s32 	%p5, %r4, 0;
	selp.b32 	%r116, %r67, %r66, %p5;
	xor.b32  	%r68, %r63, %r4;
	bfe.s32 	%r69, %r114, 29, 1;
	xor.b32  	%r70, %r69, %r63;
	xor.b32  	%r71, %r69, %r64;
	cvt.u64.u32 	%rd37, %r70;
	shl.b64 	%rd38, %rd37, 32;
	cvt.u64.u32 	%rd39, %r71;
	or.b64  	%rd40, %rd38, %rd39;
	cvt.rn.f64.s64 	%fd1, %rd40;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f122, %fd2;
	neg.f32 	%f123, %f122;
	setp.lt.s32 	%p6, %r68, 0;
	selp.f32 	%f158, %f123, %f122, %p6;
$L__BB227_8:
	add.s32 	%r73, %r116, 1;
	mul.rn.f32 	%f125, %f158, %f158;
	and.b32  	%r74, %r116, 1;
	setp.eq.b32 	%p8, %r74, 1;
	selp.f32 	%f126, %f158, 0f3F800000, %p8;
	fma.rn.f32 	%f127, %f125, %f126, 0f00000000;
	fma.rn.f32 	%f128, %f125, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f129, 0fB94D4153, %f128, %p8;
	selp.f32 	%f130, 0f3C0885E4, 0f3D2AAABB, %p8;
	fma.rn.f32 	%f131, %f129, %f125, %f130;
	selp.f32 	%f132, 0fBE2AAAA8, 0fBEFFFFFF, %p8;
	fma.rn.f32 	%f133, %f131, %f125, %f132;
	fma.rn.f32 	%f134, %f133, %f127, %f126;
	and.b32  	%r75, %r73, 2;
	setp.eq.s32 	%p9, %r75, 0;
	sub.rn.f32 	%f136, %f157, %f134;
	selp.f32 	%f137, %f134, %f136, %p9;
	mul.rn.f32 	%f8, %f1, %f137;
	mul.lo.s64 	%rd41, %rd5, 48;
	add.s64 	%rd42, %rd2, %rd41;
	mul.lo.s64 	%rd43, %rd6, 24;
	add.s64 	%rd44, %rd42, %rd43;
	shl.b64 	%rd45, %rd7, 2;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.nc.f32 	%f9, [%rd46];
	@%p1 bra 	$L__BB227_16;
	@%p18 bra 	$L__BB227_11;
	mul.rn.f32 	%f159, %f2, %f157;
	mov.b32 	%r120, 0;
	bra.uni 	$L__BB227_16;
$L__BB227_11:
	mov.b32 	%r19, %f2;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r77, %r20, 224;
	add.s32 	%r78, %r77, -128;
	shl.b32 	%r79, %r19, 8;
	or.b32  	%r83, %r79, -2147483648;
	shr.u32 	%r22, %r78, 5;
	mov.b32 	%r117, 0;
	mov.u64 	%rd63, 0;
	mov.u64 	%rd48, __cudart_i2opi_f;
$L__BB227_12:
	.pragma "nounroll";
	add.s64 	%rd49, %rd48, %rd63;
	ld.global.nc.u32 	%r82, [%rd49];
	// begin inline asm
	{
	mad.lo.cc.u32   %r80, %r82, %r83, %r117;
	madc.hi.u32     %r117, %r82, %r83,  0;
	}
	// end inline asm
	add.s64 	%rd50, %rd3, %rd63;
	st.local.u32 	[%rd50], %r80;
	add.s64 	%rd63, %rd63, 4;
	cvt.u32.u64 	%r85, %rd63;
	setp.ne.s32 	%p11, %r85, 24;
	@%p11 bra 	$L__BB227_12;
	st.local.u32 	[%rd3+24], %r117;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd51, %r22, 4;
	sub.s64 	%rd13, %rd3, %rd51;
	ld.local.u32 	%r118, [%rd13+24];
	ld.local.u32 	%r119, [%rd13+20];
	setp.eq.s32 	%p12, %r25, 0;
	@%p12 bra 	$L__BB227_15;
	shl.b32 	%r86, %r119, %r25;
	shl.b32 	%r87, %r118, %r25;
	mov.b32 	%r88, 32;
	sub.s32 	%r89, %r88, %r25;
	shr.u32 	%r90, %r119, %r89;
	add.s32 	%r118, %r90, %r87;
	ld.local.u32 	%r91, [%rd13+16];
	shr.u32 	%r92, %r91, %r89;
	add.s32 	%r119, %r92, %r86;
$L__BB227_15:
	shr.u32 	%r93, %r118, 30;
	shr.u32 	%r94, %r119, 30;
	shl.b32 	%r95, %r118, 2;
	or.b32  	%r96, %r95, %r94;
	shl.b32 	%r97, %r119, 2;
	bfe.u32 	%r98, %r118, 29, 1;
	add.s32 	%r99, %r98, %r93;
	neg.s32 	%r100, %r99;
	setp.lt.s32 	%p13, %r19, 0;
	selp.b32 	%r120, %r100, %r99, %p13;
	xor.b32  	%r101, %r96, %r19;
	bfe.s32 	%r102, %r118, 29, 1;
	xor.b32  	%r103, %r102, %r96;
	xor.b32  	%r104, %r102, %r97;
	cvt.u64.u32 	%rd52, %r103;
	shl.b64 	%rd53, %rd52, 32;
	cvt.u64.u32 	%rd54, %r104;
	or.b64  	%rd55, %rd53, %rd54;
	cvt.rn.f64.s64 	%fd3, %rd55;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f138, %fd4;
	neg.f32 	%f139, %f138;
	setp.lt.s32 	%p14, %r101, 0;
	selp.f32 	%f159, %f139, %f138, %p14;
$L__BB227_16:
	mul.rn.f32 	%f141, %f159, %f159;
	and.b32  	%r106, %r120, 1;
	setp.eq.b32 	%p15, %r106, 1;
	selp.f32 	%f142, 0f3F800000, %f159, %p15;
	fma.rn.f32 	%f143, %f141, %f142, 0f00000000;
	fma.rn.f32 	%f144, %f141, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f145, %f144, 0fB94D4153, %p15;
	selp.f32 	%f146, 0f3D2AAABB, 0f3C0885E4, %p15;
	fma.rn.f32 	%f147, %f145, %f141, %f146;
	selp.f32 	%f148, 0fBEFFFFFF, 0fBE2AAAA8, %p15;
	fma.rn.f32 	%f149, %f147, %f141, %f148;
	fma.rn.f32 	%f150, %f149, %f143, %f142;
	and.b32  	%r107, %r120, 2;
	setp.eq.s32 	%p16, %r107, 0;
	sub.rn.f32 	%f152, %f157, %f150;
	selp.f32 	%f153, %f150, %f152, %p16;
	mul.rn.f32 	%f154, %f9, %f153;
	sub.rn.f32 	%f155, %f8, %f154;
	add.rn.f32 	%f13, %f155, 0f00000000;
	shfl.sync.down.b32	%f14, %f13, 1, 31, -1;
	setp.ne.s32 	%p17, %r1, 0;
	@%p17 bra 	$L__BB227_18;
	ld.param.u64 	%rd15, [input_reduce_fusion_320_param_3];
	cvta.to.global.u64 	%rd1, %rd15;
	add.rn.f32 	%f156, %f13, %f14;
	mul.hi.u32 	%r108, %r2, 1431655766;
	mul.lo.s32 	%r109, %r108, 3;
	sub.s32 	%r110, %r2, %r109;
	and.b32  	%r111, %r108, 1;
	mul.hi.u32 	%r112, %r2, 715827883;
	mul.wide.u32 	%rd56, %r112, 24;
	add.s64 	%rd57, %rd1, %rd56;
	mul.wide.u32 	%rd58, %r110, 8;
	add.s64 	%rd59, %rd57, %rd58;
	mul.wide.u32 	%rd60, %r111, 4;
	add.s64 	%rd61, %rd59, %rd60;
	st.global.f32 	[%rd61], %f156;
$L__BB227_18:
	ret;

}
	// .globl	loop_add_fusion_374
.visible .entry loop_add_fusion_374(
	.param .u64 loop_add_fusion_374_param_0,
	.param .u64 loop_add_fusion_374_param_1,
	.param .u64 loop_add_fusion_374_param_2,
	.param .u64 loop_add_fusion_374_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<11>;
	.reg .b16 	%rs<15>;
	.reg .b32 	%r<13>;
	.reg .f32 	%f<20>;
	.reg .b64 	%rd<30>;

	ld.param.u64 	%rd12, [loop_add_fusion_374_param_2];
	cvta.to.global.u64 	%rd13, %rd12;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %tid.x;
	shl.b32 	%r5, %r3, 7;
	or.b32  	%r1, %r5, %r4;
	and.b32  	%r2, %r4, 3;
	shr.u32 	%r6, %r1, 2;
	cvt.u16.u32 	%rs1, %r6;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 9;
	mul.lo.s16 	%rs5, %rs4, 3;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, -21845;
	shr.u16 	%rs9, %rs8, 3;
	and.b32  	%r7, %r4, 1;
	setp.eq.b32 	%p1, %r7, 1;
	not.pred 	%p2, %p1;
	setp.ne.s32 	%p3, %r2, 0;
	cvt.u64.u16 	%rd14, %rs6;
	cvt.u32.u16 	%r8, %rs6;
	and.b32  	%r9, %r8, 255;
	mul.wide.u32 	%rd15, %r9, 4;
	cvt.u32.u16 	%r10, %rs9;
	mul.wide.u32 	%rd16, %r10, 12;
	add.s64 	%rd17, %rd13, %rd16;
	add.s64 	%rd6, %rd17, %rd15;
	mov.f32 	%f18, 0f00000000;
	and.pred  	%p4, %p2, %p3;
	mov.f32 	%f16, %f18;
	@%p4 bra 	$L__BB228_4;
	bra.uni 	$L__BB228_1;
$L__BB228_4:
	ld.global.nc.f32 	%f16, [%rd6];
$L__BB228_1:
	ld.param.u64 	%rd10, [loop_add_fusion_374_param_3];
	cvt.u64.u16 	%rd4, %rs9;
	and.b64  	%rd5, %rd14, 255;
	add.s32 	%r11, %r2, -1;
	and.b32  	%r12, %r11, 1;
	setp.eq.b32 	%p5, %r12, 1;
	mov.pred 	%p6, 0;
	xor.pred  	%p7, %p5, %p6;
	not.pred 	%p8, %p7;
	mov.f32 	%f17, %f18;
	@%p8 bra 	$L__BB228_5;
	bra.uni 	$L__BB228_2;
$L__BB228_5:
	ld.param.u64 	%rd11, [loop_add_fusion_374_param_1];
	cvta.to.global.u64 	%rd2, %rd11;
	cvt.u16.u32 	%rs10, %r11;
	and.b16  	%rs11, %rs10, 128;
	shr.u16 	%rs12, %rs11, 7;
	add.s16 	%rs13, %rs10, %rs12;
	shr.u16 	%rs14, %rs13, 1;
	cvt.u64.u16 	%rd18, %rs14;
	and.b64  	%rd7, %rd18, 255;
	setp.eq.s32 	%p9, %r2, 3;
	mov.f32 	%f19, 0f00000000;
	@%p9 bra 	$L__BB228_7;
	bra.uni 	$L__BB228_6;
$L__BB228_7:
	ld.global.nc.f32 	%f19, [%rd6];
$L__BB228_6:
	mul.lo.s64 	%rd19, %rd4, 24;
	add.s64 	%rd20, %rd2, %rd19;
	shl.b64 	%rd21, %rd5, 3;
	add.s64 	%rd22, %rd20, %rd21;
	shl.b64 	%rd23, %rd7, 2;
	add.s64 	%rd24, %rd22, %rd23;
	ld.global.nc.f32 	%f12, [%rd24];
	add.rn.f32 	%f17, %f19, %f12;
$L__BB228_2:
	cvta.to.global.u64 	%rd1, %rd10;
	setp.eq.s32 	%p10, %r2, 2;
	@%p10 bra 	$L__BB228_8;
	bra.uni 	$L__BB228_3;
$L__BB228_8:
	ld.param.u64 	%rd9, [loop_add_fusion_374_param_0];
	cvta.to.global.u64 	%rd3, %rd9;
	mul.lo.s64 	%rd25, %rd4, 12;
	add.s64 	%rd26, %rd3, %rd25;
	shl.b64 	%rd27, %rd5, 2;
	add.s64 	%rd8, %rd26, %rd27;
	ld.global.nc.f32 	%f18, [%rd8];
$L__BB228_3:
	add.rn.f32 	%f14, %f16, %f17;
	add.rn.f32 	%f15, %f14, %f18;
	mul.wide.u32 	%rd28, %r1, 4;
	add.s64 	%rd29, %rd1, %rd28;
	st.global.f32 	[%rd29], %f15;
	ret;

}
	// .globl	loop_pad_fusion_27
.visible .entry loop_pad_fusion_27(
	.param .u64 loop_pad_fusion_27_param_0,
	.param .u64 loop_pad_fusion_27_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<10>;
	.reg .b32 	%r<11>;
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd4, [loop_pad_fusion_27_param_1];
	cvta.to.global.u64 	%rd1, %rd4;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r4, %r3, 7;
	or.b32  	%r2, %r4, %r1;
	and.b32  	%r5, %r1, 1;
	setp.eq.b32 	%p1, %r5, 1;
	mov.pred 	%p2, 0;
	xor.pred  	%p3, %p1, %p2;
	not.pred 	%p4, %p3;
	mov.f32 	%f4, 0f00000000;
	@%p4 bra 	$L__BB229_2;
	bra.uni 	$L__BB229_1;
$L__BB229_2:
	ld.param.u64 	%rd3, [loop_pad_fusion_27_param_0];
	cvta.to.global.u64 	%rd2, %rd3;
	cvt.u16.u32 	%rs1, %r2;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 4;
	shr.u32 	%r6, %r2, 3;
	cvt.u16.u32 	%rs4, %r6;
	and.b16  	%rs5, %rs4, 255;
	mul.lo.s16 	%rs6, %rs5, 171;
	shr.u16 	%rs7, %rs6, 9;
	mul.lo.s16 	%rs8, %rs7, 3;
	sub.s16 	%rs9, %rs4, %rs8;
	bfe.u32 	%r7, %r1, 1, 2;
	cvt.u32.u16 	%r8, %rs3;
	mul.wide.u32 	%rd5, %r8, 48;
	add.s64 	%rd6, %rd2, %rd5;
	cvt.u32.u16 	%r9, %rs9;
	and.b32  	%r10, %r9, 255;
	mul.wide.u32 	%rd7, %r10, 16;
	add.s64 	%rd8, %rd6, %rd7;
	mul.wide.u32 	%rd9, %r7, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f4, [%rd10];
$L__BB229_1:
	mul.wide.u32 	%rd11, %r2, 4;
	add.s64 	%rd12, %rd1, %rd11;
	st.global.f32 	[%rd12], %f4;
	ret;

}
	// .globl	loop_multiply_fusion_98
.visible .entry loop_multiply_fusion_98(
	.param .u64 loop_multiply_fusion_98_param_0,
	.param .u64 loop_multiply_fusion_98_param_1,
	.param .u64 loop_multiply_fusion_98_param_2,
	.param .u64 loop_multiply_fusion_98_param_3,
	.param .u64 loop_multiply_fusion_98_param_4,
	.param .u64 loop_multiply_fusion_98_param_5,
	.param .u64 loop_multiply_fusion_98_param_6,
	.param .u64 loop_multiply_fusion_98_param_7
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot230[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<20>;
	.reg .b16 	%rs<18>;
	.reg .b32 	%r<120>;
	.reg .f32 	%f<99>;
	.reg .b64 	%rd<81>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot230;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd23, [loop_multiply_fusion_98_param_2];
	ld.param.u64 	%rd24, [loop_multiply_fusion_98_param_5];
	ld.param.u64 	%rd25, [loop_multiply_fusion_98_param_3];
	cvta.to.global.u64 	%rd27, %rd25;
	cvta.to.global.u64 	%rd28, %rd23;
	mov.u32 	%r34, %ctaid.x;
	mov.u32 	%r35, %tid.x;
	shl.b32 	%r36, %r34, 7;
	or.b32  	%r1, %r36, %r35;
	cvt.u16.u32 	%rs2, %r1;
	mul.hi.u16 	%rs3, %rs2, -21845;
	shr.u16 	%rs4, %rs3, 2;
	mul.lo.s16 	%rs5, %rs4, 6;
	sub.s16 	%rs1, %rs2, %rs5;
	mul.hi.u16 	%rs6, %rs4, 21846;
	mul.lo.s16 	%rs7, %rs6, 3;
	sub.s16 	%rs8, %rs4, %rs7;
	cvt.u32.u16 	%r37, %rs8;
	mul.hi.u16 	%rs9, %rs2, -7281;
	shr.u16 	%rs10, %rs9, 4;
	mul.hi.u16 	%rs11, %rs10, 1311;
	mul.lo.s16 	%rs12, %rs11, 50;
	sub.s16 	%rs13, %rs10, %rs12;
	mul.hi.u16 	%rs14, %rs2, -28253;
	shr.u16 	%rs15, %rs14, 9;
	and.b16  	%rs16, %rs15, 63;
	cvt.u32.u16 	%r38, %rs16;
	mul.wide.u32 	%rd32, %r38, 4;
	add.s64 	%rd33, %rd27, %rd32;
	ld.global.nc.f32 	%f1, [%rd33];
	cvt.u32.u16 	%r39, %rs13;
	mul.wide.u32 	%rd34, %r39, 96;
	mul.wide.u32 	%rd35, %r38, 4800;
	add.s64 	%rd36, %rd28, %rd35;
	add.s64 	%rd37, %rd36, %rd34;
	mul.wide.u32 	%rd38, %r37, 24;
	add.s64 	%rd39, %rd37, %rd38;
	cvt.u32.u16 	%r40, %rs1;
	mul.wide.u32 	%rd40, %r40, 4;
	add.s64 	%rd41, %rd39, %rd40;
	ld.global.nc.f32 	%f2, [%rd41+24];
	and.b32  	%r2, %r37, 1;
	setp.eq.s32 	%p1, %r2, 0;
	mov.f32 	%f96, 0f00000000;
	mov.f32 	%f95, %f96;
	@%p1 bra 	$L__BB230_19;
	bra.uni 	$L__BB230_1;
$L__BB230_19:
	ld.param.u64 	%rd21, [loop_multiply_fusion_98_param_1];
	cvta.to.global.u64 	%rd29, %rd21;
	shr.u32 	%r41, %r37, 1;
	mul.wide.u32 	%rd42, %r39, 48;
	mul.wide.u32 	%rd43, %r38, 2400;
	add.s64 	%rd44, %rd29, %rd43;
	add.s64 	%rd45, %rd44, %rd42;
	mul.wide.u32 	%rd46, %r41, 24;
	add.s64 	%rd47, %rd45, %rd46;
	add.s64 	%rd11, %rd47, %rd40;
	ld.global.nc.f32 	%f95, [%rd11];
$L__BB230_1:
	add.u64 	%rd30, %SP, 0;
	cvt.u64.u16 	%rd8, %rs16;
	cvta.to.global.u64 	%rd3, %rd24;
	setp.ne.s32 	%p2, %r2, 0;
	@%p2 bra 	$L__BB230_20;
	bra.uni 	$L__BB230_2;
$L__BB230_20:
	ld.param.u64 	%rd19, [loop_multiply_fusion_98_param_0];
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u64.u16 	%rd9, %rs13;
	cvt.u64.u16 	%rd10, %rs1;
	mul.lo.s64 	%rd48, %rd8, 2400;
	add.s64 	%rd49, %rd5, %rd48;
	mul.lo.s64 	%rd50, %rd9, 48;
	add.s64 	%rd51, %rd49, %rd50;
	shl.b64 	%rd52, %rd10, 2;
	add.s64 	%rd12, %rd51, %rd52;
	ld.global.nc.f32 	%f96, [%rd12];
$L__BB230_2:
	ld.param.u64 	%rd20, [loop_multiply_fusion_98_param_7];
	ld.param.u64 	%rd22, [loop_multiply_fusion_98_param_6];
	ld.param.u64 	%rd26, [loop_multiply_fusion_98_param_4];
	cvta.to.local.u64 	%rd6, %rd30;
	shr.u16 	%rs17, %rs1, 1;
	mul.lo.s64 	%rd53, %rd8, 12;
	add.s64 	%rd54, %rd3, %rd53;
	cvt.u32.u16 	%r42, %rs17;
	mul.wide.u32 	%rd55, %r42, 4;
	add.s64 	%rd56, %rd54, %rd55;
	ld.global.nc.f32 	%f18, [%rd56];
	add.rn.f32 	%f19, %f18, %f18;
	add.rn.f32 	%f20, %f19, %f19;
	add.rn.f32 	%f5, %f20, %f20;
	mul.rn.f32 	%f21, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r119, %f21;
	cvt.rn.f32.s32 	%f22, %r119;
	fma.rn.f32 	%f23, %f22, 0fBFC90FDA, %f5;
	fma.rn.f32 	%f24, %f22, 0fB3A22168, %f23;
	fma.rn.f32 	%f98, %f22, 0fA7C234C5, %f24;
	abs.f32 	%f7, %f5;
	setp.ltu.f32 	%p3, %f7, 0f47CE4780;
	setp.neu.f32 	%p19, %f7, 0f7F800000;
	mov.u32 	%r115, %r119;
	mov.f32 	%f97, %f98;
	@%p3 bra 	$L__BB230_10;
	@%p19 bra 	$L__BB230_5;
	mov.f32 	%f27, 0f00000000;
	mul.rn.f32 	%f97, %f5, %f27;
	mov.b32 	%r115, 0;
	bra.uni 	$L__BB230_10;
$L__BB230_5:
	mov.b32 	%r4, %f5;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r44, %r5, 224;
	add.s32 	%r45, %r44, -128;
	shl.b32 	%r46, %r4, 8;
	or.b32  	%r50, %r46, -2147483648;
	shr.u32 	%r7, %r45, 5;
	mov.b32 	%r112, 0;
	mov.u64 	%rd79, 0;
	mov.u64 	%rd58, __cudart_i2opi_f;
$L__BB230_6:
	.pragma "nounroll";
	add.s64 	%rd59, %rd58, %rd79;
	ld.global.nc.u32 	%r49, [%rd59];
	// begin inline asm
	{
	mad.lo.cc.u32   %r47, %r49, %r50, %r112;
	madc.hi.u32     %r112, %r49, %r50,  0;
	}
	// end inline asm
	add.s64 	%rd60, %rd6, %rd79;
	st.local.u32 	[%rd60], %r47;
	add.s64 	%rd79, %rd79, 4;
	cvt.u32.u64 	%r52, %rd79;
	setp.ne.s32 	%p5, %r52, 24;
	@%p5 bra 	$L__BB230_6;
	st.local.u32 	[%rd6+24], %r112;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd61, %r7, 4;
	sub.s64 	%rd15, %rd6, %rd61;
	ld.local.u32 	%r113, [%rd15+24];
	ld.local.u32 	%r114, [%rd15+20];
	setp.eq.s32 	%p6, %r10, 0;
	@%p6 bra 	$L__BB230_9;
	shl.b32 	%r53, %r114, %r10;
	shl.b32 	%r54, %r113, %r10;
	mov.b32 	%r55, 32;
	sub.s32 	%r56, %r55, %r10;
	shr.u32 	%r57, %r114, %r56;
	add.s32 	%r113, %r57, %r54;
	ld.local.u32 	%r58, [%rd15+16];
	shr.u32 	%r59, %r58, %r56;
	add.s32 	%r114, %r59, %r53;
$L__BB230_9:
	shr.u32 	%r60, %r113, 30;
	shr.u32 	%r61, %r114, 30;
	shl.b32 	%r62, %r113, 2;
	or.b32  	%r63, %r62, %r61;
	shl.b32 	%r64, %r114, 2;
	bfe.u32 	%r65, %r113, 29, 1;
	add.s32 	%r66, %r65, %r60;
	neg.s32 	%r67, %r66;
	setp.lt.s32 	%p7, %r4, 0;
	selp.b32 	%r115, %r67, %r66, %p7;
	xor.b32  	%r68, %r63, %r4;
	bfe.s32 	%r69, %r113, 29, 1;
	xor.b32  	%r70, %r69, %r63;
	xor.b32  	%r71, %r69, %r64;
	cvt.u64.u32 	%rd62, %r70;
	shl.b64 	%rd63, %rd62, 32;
	cvt.u64.u32 	%rd64, %r71;
	or.b64  	%rd65, %rd63, %rd64;
	cvt.rn.f64.s64 	%fd1, %rd65;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f25, %fd2;
	neg.f32 	%f26, %f25;
	setp.lt.s32 	%p8, %r68, 0;
	selp.f32 	%f97, %f26, %f25, %p8;
$L__BB230_10:
	cvta.to.global.u64 	%rd1, %rd20;
	cvta.to.global.u64 	%rd2, %rd22;
	cvta.to.global.u64 	%rd4, %rd26;
	@%p3 bra 	$L__BB230_18;
	@%p19 bra 	$L__BB230_13;
	mov.f32 	%f30, 0f00000000;
	mul.rn.f32 	%f98, %f5, %f30;
	mov.b32 	%r119, 0;
	bra.uni 	$L__BB230_18;
$L__BB230_13:
	mov.b32 	%r19, %f5;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r74, %r20, 224;
	add.s32 	%r75, %r74, -128;
	shl.b32 	%r76, %r19, 8;
	or.b32  	%r80, %r76, -2147483648;
	shr.u32 	%r22, %r75, 5;
	mov.b32 	%r116, 0;
	mov.u64 	%rd80, 0;
	mov.u64 	%rd67, __cudart_i2opi_f;
$L__BB230_14:
	.pragma "nounroll";
	add.s64 	%rd68, %rd67, %rd80;
	ld.global.nc.u32 	%r79, [%rd68];
	// begin inline asm
	{
	mad.lo.cc.u32   %r77, %r79, %r80, %r116;
	madc.hi.u32     %r116, %r79, %r80,  0;
	}
	// end inline asm
	add.s64 	%rd69, %rd6, %rd80;
	st.local.u32 	[%rd69], %r77;
	add.s64 	%rd80, %rd80, 4;
	cvt.u32.u64 	%r82, %rd80;
	setp.ne.s32 	%p11, %r82, 24;
	@%p11 bra 	$L__BB230_14;
	st.local.u32 	[%rd6+24], %r116;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd70, %r22, 4;
	sub.s64 	%rd18, %rd6, %rd70;
	ld.local.u32 	%r117, [%rd18+24];
	ld.local.u32 	%r118, [%rd18+20];
	setp.eq.s32 	%p12, %r25, 0;
	@%p12 bra 	$L__BB230_17;
	shl.b32 	%r83, %r118, %r25;
	shl.b32 	%r84, %r117, %r25;
	mov.b32 	%r85, 32;
	sub.s32 	%r86, %r85, %r25;
	shr.u32 	%r87, %r118, %r86;
	add.s32 	%r117, %r87, %r84;
	ld.local.u32 	%r88, [%rd18+16];
	shr.u32 	%r89, %r88, %r86;
	add.s32 	%r118, %r89, %r83;
$L__BB230_17:
	shr.u32 	%r90, %r117, 30;
	shr.u32 	%r91, %r118, 30;
	shl.b32 	%r92, %r117, 2;
	or.b32  	%r93, %r92, %r91;
	shl.b32 	%r94, %r118, 2;
	bfe.u32 	%r95, %r117, 29, 1;
	add.s32 	%r96, %r95, %r90;
	neg.s32 	%r97, %r96;
	setp.lt.s32 	%p13, %r19, 0;
	selp.b32 	%r119, %r97, %r96, %p13;
	xor.b32  	%r98, %r93, %r19;
	bfe.s32 	%r99, %r117, 29, 1;
	xor.b32  	%r100, %r99, %r93;
	xor.b32  	%r101, %r99, %r94;
	cvt.u64.u32 	%rd71, %r100;
	shl.b64 	%rd72, %rd71, 32;
	cvt.u64.u32 	%rd73, %r101;
	or.b64  	%rd74, %rd72, %rd73;
	cvt.rn.f64.s64 	%fd3, %rd74;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f28, %fd4;
	neg.f32 	%f29, %f28;
	setp.lt.s32 	%p14, %r98, 0;
	selp.f32 	%f98, %f29, %f28, %p14;
$L__BB230_18:
	add.s32 	%r103, %r115, 1;
	and.b32  	%r104, %r103, 2;
	setp.eq.s32 	%p15, %r104, 0;
	and.b32  	%r105, %r115, 1;
	setp.eq.b32 	%p16, %r105, 1;
	mul.rn.f32 	%f31, %f97, %f97;
	fma.rn.f32 	%f32, %f31, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f33, 0fB94D4153, %f32, %p16;
	selp.f32 	%f34, 0f3C0885E4, 0f3D2AAABB, %p16;
	fma.rn.f32 	%f35, %f33, %f31, %f34;
	selp.f32 	%f36, 0fBE2AAAA8, 0fBEFFFFFF, %p16;
	fma.rn.f32 	%f37, %f35, %f31, %f36;
	selp.f32 	%f38, %f97, 0f3F800000, %p16;
	fma.rn.f32 	%f39, %f31, %f38, 0f00000000;
	fma.rn.f32 	%f40, %f37, %f39, %f38;
	mov.f32 	%f41, 0f00000000;
	sub.rn.f32 	%f42, %f41, %f40;
	selp.f32 	%f43, %f40, %f42, %p15;
	add.rn.f32 	%f44, %f95, %f96;
	mul.rn.f32 	%f45, %f44, %f43;
	fma.rn.f32 	%f46, %f1, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f47, %f46;
	mov.f32 	%f48, 0f4B400001;
	mov.f32 	%f49, 0f437C0000;
	fma.rm.f32 	%f50, %f47, %f49, %f48;
	add.rn.f32 	%f51, %f50, 0fCB40007F;
	neg.f32 	%f52, %f51;
	fma.rn.f32 	%f53, %f1, 0f3FB8AA3B, %f52;
	fma.rn.f32 	%f54, %f1, 0f32A57060, %f53;
	ex2.approx.ftz.f32 	%f55, %f54;
	mov.b32 	%r106, %f50;
	shl.b32 	%r107, %r106, 23;
	mov.b32 	%f56, %r107;
	mul.rn.f32 	%f57, %f55, %f56;
	neg.f32 	%f58, %f57;
	sub.rn.f32 	%f59, %f58, %f57;
	add.rn.f32 	%f60, %f59, %f59;
	add.rn.f32 	%f61, %f60, %f60;
	add.rn.f32 	%f62, %f61, %f61;
	add.rn.f32 	%f63, %f62, %f62;
	add.rn.f32 	%f64, %f63, %f63;
	add.rn.f32 	%f65, %f64, %f64;
	fma.rn.f32 	%f66, %f65, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f67, %f66;
	fma.rm.f32 	%f68, %f67, %f49, %f48;
	add.rn.f32 	%f69, %f68, 0fCB40007F;
	neg.f32 	%f70, %f69;
	fma.rn.f32 	%f71, %f65, 0f3FB8AA3B, %f70;
	fma.rn.f32 	%f72, %f65, 0f32A57060, %f71;
	ex2.approx.ftz.f32 	%f73, %f72;
	mov.b32 	%r108, %f68;
	shl.b32 	%r109, %r108, 23;
	mov.b32 	%f74, %r109;
	mul.rn.f32 	%f75, %f73, %f74;
	mul.rn.f32 	%f76, %f2, %f75;
	mul.rn.f32 	%f77, %f44, %f76;
	mul.rn.f32 	%f78, %f98, %f98;
	and.b32  	%r110, %r119, 1;
	setp.eq.b32 	%p17, %r110, 1;
	selp.f32 	%f79, 0f3F800000, %f98, %p17;
	fma.rn.f32 	%f80, %f78, %f79, 0f00000000;
	fma.rn.f32 	%f81, %f78, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f82, %f81, 0fB94D4153, %p17;
	selp.f32 	%f83, 0f3D2AAABB, 0f3C0885E4, %p17;
	fma.rn.f32 	%f84, %f82, %f78, %f83;
	selp.f32 	%f85, 0fBEFFFFFF, 0fBE2AAAA8, %p17;
	fma.rn.f32 	%f86, %f84, %f78, %f85;
	fma.rn.f32 	%f87, %f86, %f80, %f79;
	and.b32  	%r111, %r119, 2;
	setp.eq.s32 	%p18, %r111, 0;
	sub.rn.f32 	%f88, %f41, %f87;
	selp.f32 	%f89, %f87, %f88, %p18;
	mul.wide.u32 	%rd75, %r1, 4;
	add.s64 	%rd76, %rd4, %rd75;
	ld.global.f32 	%f90, [%rd76];
	mul.rn.f32 	%f91, %f90, %f89;
	add.rn.f32 	%f92, %f45, %f91;
	mul.rn.f32 	%f93, %f2, %f92;
	mul.rn.f32 	%f94, %f90, %f76;
	add.s64 	%rd77, %rd2, %rd75;
	st.global.f32 	[%rd77], %f77;
	st.global.f32 	[%rd76], %f93;
	add.s64 	%rd78, %rd1, %rd75;
	st.global.f32 	[%rd78], %f94;
	ret;

}
	// .globl	loop_reduce_fusion_47
.visible .entry loop_reduce_fusion_47(
	.param .u64 loop_reduce_fusion_47_param_0,
	.param .u64 loop_reduce_fusion_47_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<102>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd1, [loop_reduce_fusion_47_param_0];
	ld.param.u64 	%rd2, [loop_reduce_fusion_47_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 21846;
	mul.lo.s16 	%rs7, %rs6, 3;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 4;
	and.b16  	%rs11, %rs10, 63;
	cvt.u32.u16 	%r5, %rs8;
	mul.wide.u32 	%rd5, %r5, 24;
	cvt.u32.u16 	%r6, %rs11;
	mul.wide.u32 	%rd6, %r6, 3600;
	add.s64 	%rd7, %rd4, %rd6;
	add.s64 	%rd8, %rd7, %rd5;
	cvt.u32.u16 	%r7, %rs5;
	mul.wide.u32 	%rd9, %r7, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	add.rn.f32 	%f2, %f1, 0f00000000;
	ld.global.nc.f32 	%f3, [%rd10+72];
	add.rn.f32 	%f4, %f2, %f3;
	ld.global.nc.f32 	%f5, [%rd10+144];
	add.rn.f32 	%f6, %f4, %f5;
	ld.global.nc.f32 	%f7, [%rd10+216];
	add.rn.f32 	%f8, %f6, %f7;
	ld.global.nc.f32 	%f9, [%rd10+288];
	add.rn.f32 	%f10, %f8, %f9;
	ld.global.nc.f32 	%f11, [%rd10+360];
	add.rn.f32 	%f12, %f10, %f11;
	ld.global.nc.f32 	%f13, [%rd10+432];
	add.rn.f32 	%f14, %f12, %f13;
	ld.global.nc.f32 	%f15, [%rd10+504];
	add.rn.f32 	%f16, %f14, %f15;
	ld.global.nc.f32 	%f17, [%rd10+576];
	add.rn.f32 	%f18, %f16, %f17;
	ld.global.nc.f32 	%f19, [%rd10+648];
	add.rn.f32 	%f20, %f18, %f19;
	ld.global.nc.f32 	%f21, [%rd10+720];
	add.rn.f32 	%f22, %f20, %f21;
	ld.global.nc.f32 	%f23, [%rd10+792];
	add.rn.f32 	%f24, %f22, %f23;
	ld.global.nc.f32 	%f25, [%rd10+864];
	add.rn.f32 	%f26, %f24, %f25;
	ld.global.nc.f32 	%f27, [%rd10+936];
	add.rn.f32 	%f28, %f26, %f27;
	ld.global.nc.f32 	%f29, [%rd10+1008];
	add.rn.f32 	%f30, %f28, %f29;
	ld.global.nc.f32 	%f31, [%rd10+1080];
	add.rn.f32 	%f32, %f30, %f31;
	ld.global.nc.f32 	%f33, [%rd10+1152];
	add.rn.f32 	%f34, %f32, %f33;
	ld.global.nc.f32 	%f35, [%rd10+1224];
	add.rn.f32 	%f36, %f34, %f35;
	ld.global.nc.f32 	%f37, [%rd10+1296];
	add.rn.f32 	%f38, %f36, %f37;
	ld.global.nc.f32 	%f39, [%rd10+1368];
	add.rn.f32 	%f40, %f38, %f39;
	ld.global.nc.f32 	%f41, [%rd10+1440];
	add.rn.f32 	%f42, %f40, %f41;
	ld.global.nc.f32 	%f43, [%rd10+1512];
	add.rn.f32 	%f44, %f42, %f43;
	ld.global.nc.f32 	%f45, [%rd10+1584];
	add.rn.f32 	%f46, %f44, %f45;
	ld.global.nc.f32 	%f47, [%rd10+1656];
	add.rn.f32 	%f48, %f46, %f47;
	ld.global.nc.f32 	%f49, [%rd10+1728];
	add.rn.f32 	%f50, %f48, %f49;
	ld.global.nc.f32 	%f51, [%rd10+1800];
	add.rn.f32 	%f52, %f50, %f51;
	ld.global.nc.f32 	%f53, [%rd10+1872];
	add.rn.f32 	%f54, %f52, %f53;
	ld.global.nc.f32 	%f55, [%rd10+1944];
	add.rn.f32 	%f56, %f54, %f55;
	ld.global.nc.f32 	%f57, [%rd10+2016];
	add.rn.f32 	%f58, %f56, %f57;
	ld.global.nc.f32 	%f59, [%rd10+2088];
	add.rn.f32 	%f60, %f58, %f59;
	ld.global.nc.f32 	%f61, [%rd10+2160];
	add.rn.f32 	%f62, %f60, %f61;
	ld.global.nc.f32 	%f63, [%rd10+2232];
	add.rn.f32 	%f64, %f62, %f63;
	ld.global.nc.f32 	%f65, [%rd10+2304];
	add.rn.f32 	%f66, %f64, %f65;
	ld.global.nc.f32 	%f67, [%rd10+2376];
	add.rn.f32 	%f68, %f66, %f67;
	ld.global.nc.f32 	%f69, [%rd10+2448];
	add.rn.f32 	%f70, %f68, %f69;
	ld.global.nc.f32 	%f71, [%rd10+2520];
	add.rn.f32 	%f72, %f70, %f71;
	ld.global.nc.f32 	%f73, [%rd10+2592];
	add.rn.f32 	%f74, %f72, %f73;
	ld.global.nc.f32 	%f75, [%rd10+2664];
	add.rn.f32 	%f76, %f74, %f75;
	ld.global.nc.f32 	%f77, [%rd10+2736];
	add.rn.f32 	%f78, %f76, %f77;
	ld.global.nc.f32 	%f79, [%rd10+2808];
	add.rn.f32 	%f80, %f78, %f79;
	ld.global.nc.f32 	%f81, [%rd10+2880];
	add.rn.f32 	%f82, %f80, %f81;
	ld.global.nc.f32 	%f83, [%rd10+2952];
	add.rn.f32 	%f84, %f82, %f83;
	ld.global.nc.f32 	%f85, [%rd10+3024];
	add.rn.f32 	%f86, %f84, %f85;
	ld.global.nc.f32 	%f87, [%rd10+3096];
	add.rn.f32 	%f88, %f86, %f87;
	ld.global.nc.f32 	%f89, [%rd10+3168];
	add.rn.f32 	%f90, %f88, %f89;
	ld.global.nc.f32 	%f91, [%rd10+3240];
	add.rn.f32 	%f92, %f90, %f91;
	ld.global.nc.f32 	%f93, [%rd10+3312];
	add.rn.f32 	%f94, %f92, %f93;
	ld.global.nc.f32 	%f95, [%rd10+3384];
	add.rn.f32 	%f96, %f94, %f95;
	ld.global.nc.f32 	%f97, [%rd10+3456];
	add.rn.f32 	%f98, %f96, %f97;
	ld.global.nc.f32 	%f99, [%rd10+3528];
	add.rn.f32 	%f100, %f98, %f99;
	neg.f32 	%f101, %f100;
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd3, %rd11;
	st.global.f32 	[%rd12], %f101;
	ret;

}
	// .globl	input_reduce_fusion_321
.visible .entry input_reduce_fusion_321(
	.param .u64 input_reduce_fusion_321_param_0,
	.param .u64 input_reduce_fusion_321_param_1,
	.param .u64 input_reduce_fusion_321_param_2,
	.param .u64 input_reduce_fusion_321_param_3
)
.reqntid 256, 1, 1
{
	.local .align 4 .b8 	__local_depot232[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<23>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<126>;
	.reg .f32 	%f<161>;
	.reg .b64 	%rd<64>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot232;
	mov.u32 	%r36, %tid.x;
	mov.u32 	%r37, %ctaid.x;
	shr.u32 	%r1, %r36, 1;
	and.b32  	%r2, %r36, 1;
	setp.eq.s32 	%p1, %r37, 4;
	selp.b32 	%r3, 64, 128, %p1;
	shl.b32 	%r4, %r37, 7;
	setp.ge.u32 	%p2, %r1, %r3;
	mov.f32 	%f158, 0f00000000;
	@%p2 bra 	$L__BB232_4;
	ld.param.u64 	%rd16, [input_reduce_fusion_321_param_0];
	ld.param.u64 	%rd18, [input_reduce_fusion_321_param_1];
	ld.param.u64 	%rd19, [input_reduce_fusion_321_param_2];
	cvta.to.global.u64 	%rd2, %rd19;
	cvta.to.global.u64 	%rd3, %rd18;
	cvta.to.global.u64 	%rd4, %rd16;
	add.u64 	%rd5, %SPL, 0;
	or.b32  	%r38, %r1, %r4;
	cvt.u16.u32 	%rs1, %r38;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 21846;
	mul.lo.s16 	%rs7, %rs6, 3;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 3;
	shl.b16 	%rs11, %rs5, 1;
	cvt.u32.u16 	%r39, %rs11;
	or.b32  	%r40, %r2, %r39;
	cvt.u64.u16 	%rd7, %rs10;
	cvt.u64.u16 	%rd8, %rs8;
	cvt.u64.u32 	%rd9, %r40;
	cvt.u32.u16 	%r41, %rs8;
	mul.wide.u32 	%rd22, %r41, 24;
	cvt.u32.u16 	%r42, %rs10;
	mul.wide.u32 	%rd23, %r42, 3600;
	add.s64 	%rd24, %rd2, %rd23;
	add.s64 	%rd25, %rd24, %rd22;
	mul.wide.u32 	%rd26, %r40, 4;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.f32 	%f17, [%rd27];
	add.rn.f32 	%f18, %f17, 0f00000000;
	ld.global.nc.f32 	%f19, [%rd27+72];
	add.rn.f32 	%f20, %f18, %f19;
	ld.global.nc.f32 	%f21, [%rd27+144];
	add.rn.f32 	%f22, %f20, %f21;
	ld.global.nc.f32 	%f23, [%rd27+216];
	add.rn.f32 	%f24, %f22, %f23;
	ld.global.nc.f32 	%f25, [%rd27+288];
	add.rn.f32 	%f26, %f24, %f25;
	ld.global.nc.f32 	%f27, [%rd27+360];
	add.rn.f32 	%f28, %f26, %f27;
	ld.global.nc.f32 	%f29, [%rd27+432];
	add.rn.f32 	%f30, %f28, %f29;
	ld.global.nc.f32 	%f31, [%rd27+504];
	add.rn.f32 	%f32, %f30, %f31;
	ld.global.nc.f32 	%f33, [%rd27+576];
	add.rn.f32 	%f34, %f32, %f33;
	ld.global.nc.f32 	%f35, [%rd27+648];
	add.rn.f32 	%f36, %f34, %f35;
	ld.global.nc.f32 	%f37, [%rd27+720];
	add.rn.f32 	%f38, %f36, %f37;
	ld.global.nc.f32 	%f39, [%rd27+792];
	add.rn.f32 	%f40, %f38, %f39;
	ld.global.nc.f32 	%f41, [%rd27+864];
	add.rn.f32 	%f42, %f40, %f41;
	ld.global.nc.f32 	%f43, [%rd27+936];
	add.rn.f32 	%f44, %f42, %f43;
	ld.global.nc.f32 	%f45, [%rd27+1008];
	add.rn.f32 	%f46, %f44, %f45;
	ld.global.nc.f32 	%f47, [%rd27+1080];
	add.rn.f32 	%f48, %f46, %f47;
	ld.global.nc.f32 	%f49, [%rd27+1152];
	add.rn.f32 	%f50, %f48, %f49;
	ld.global.nc.f32 	%f51, [%rd27+1224];
	add.rn.f32 	%f52, %f50, %f51;
	ld.global.nc.f32 	%f53, [%rd27+1296];
	add.rn.f32 	%f54, %f52, %f53;
	ld.global.nc.f32 	%f55, [%rd27+1368];
	add.rn.f32 	%f56, %f54, %f55;
	ld.global.nc.f32 	%f57, [%rd27+1440];
	add.rn.f32 	%f58, %f56, %f57;
	ld.global.nc.f32 	%f59, [%rd27+1512];
	add.rn.f32 	%f60, %f58, %f59;
	ld.global.nc.f32 	%f61, [%rd27+1584];
	add.rn.f32 	%f62, %f60, %f61;
	ld.global.nc.f32 	%f63, [%rd27+1656];
	add.rn.f32 	%f64, %f62, %f63;
	ld.global.nc.f32 	%f65, [%rd27+1728];
	add.rn.f32 	%f66, %f64, %f65;
	ld.global.nc.f32 	%f67, [%rd27+1800];
	add.rn.f32 	%f68, %f66, %f67;
	ld.global.nc.f32 	%f69, [%rd27+1872];
	add.rn.f32 	%f70, %f68, %f69;
	ld.global.nc.f32 	%f71, [%rd27+1944];
	add.rn.f32 	%f72, %f70, %f71;
	ld.global.nc.f32 	%f73, [%rd27+2016];
	add.rn.f32 	%f74, %f72, %f73;
	ld.global.nc.f32 	%f75, [%rd27+2088];
	add.rn.f32 	%f76, %f74, %f75;
	ld.global.nc.f32 	%f77, [%rd27+2160];
	add.rn.f32 	%f78, %f76, %f77;
	ld.global.nc.f32 	%f79, [%rd27+2232];
	add.rn.f32 	%f80, %f78, %f79;
	ld.global.nc.f32 	%f81, [%rd27+2304];
	add.rn.f32 	%f82, %f80, %f81;
	ld.global.nc.f32 	%f83, [%rd27+2376];
	add.rn.f32 	%f84, %f82, %f83;
	ld.global.nc.f32 	%f85, [%rd27+2448];
	add.rn.f32 	%f86, %f84, %f85;
	ld.global.nc.f32 	%f87, [%rd27+2520];
	add.rn.f32 	%f88, %f86, %f87;
	ld.global.nc.f32 	%f89, [%rd27+2592];
	add.rn.f32 	%f90, %f88, %f89;
	ld.global.nc.f32 	%f91, [%rd27+2664];
	add.rn.f32 	%f92, %f90, %f91;
	ld.global.nc.f32 	%f93, [%rd27+2736];
	add.rn.f32 	%f94, %f92, %f93;
	ld.global.nc.f32 	%f95, [%rd27+2808];
	add.rn.f32 	%f96, %f94, %f95;
	ld.global.nc.f32 	%f97, [%rd27+2880];
	add.rn.f32 	%f98, %f96, %f97;
	ld.global.nc.f32 	%f99, [%rd27+2952];
	add.rn.f32 	%f100, %f98, %f99;
	ld.global.nc.f32 	%f101, [%rd27+3024];
	add.rn.f32 	%f102, %f100, %f101;
	ld.global.nc.f32 	%f103, [%rd27+3096];
	add.rn.f32 	%f104, %f102, %f103;
	ld.global.nc.f32 	%f105, [%rd27+3168];
	add.rn.f32 	%f106, %f104, %f105;
	ld.global.nc.f32 	%f107, [%rd27+3240];
	add.rn.f32 	%f108, %f106, %f107;
	ld.global.nc.f32 	%f109, [%rd27+3312];
	add.rn.f32 	%f110, %f108, %f109;
	ld.global.nc.f32 	%f111, [%rd27+3384];
	add.rn.f32 	%f112, %f110, %f111;
	ld.global.nc.f32 	%f113, [%rd27+3456];
	add.rn.f32 	%f114, %f112, %f113;
	ld.global.nc.f32 	%f115, [%rd27+3528];
	add.rn.f32 	%f1, %f114, %f115;
	cvt.u32.u16 	%r43, %rs5;
	mul.wide.u32 	%rd28, %r43, 4;
	mul.wide.u32 	%rd29, %r42, 12;
	add.s64 	%rd30, %rd3, %rd29;
	add.s64 	%rd31, %rd30, %rd28;
	ld.global.nc.f32 	%f116, [%rd31];
	add.rn.f32 	%f117, %f116, %f116;
	add.rn.f32 	%f118, %f117, %f117;
	add.rn.f32 	%f2, %f118, %f118;
	mul.rn.f32 	%f119, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r125, %f119;
	cvt.rn.f32.s32 	%f120, %r125;
	fma.rn.f32 	%f121, %f120, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f122, %f120, 0fB3A22168, %f121;
	fma.rn.f32 	%f160, %f120, 0fA7C234C5, %f122;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p3, %f4, 0f47CE4780;
	setp.neu.f32 	%p22, %f4, 0f7F800000;
	mov.u32 	%r121, %r125;
	mov.f32 	%f159, %f160;
	@%p3 bra 	$L__BB232_11;
	@%p22 bra 	$L__BB232_6;
	mov.f32 	%f125, 0f00000000;
	mul.rn.f32 	%f159, %f2, %f125;
	mov.b32 	%r121, 0;
	bra.uni 	$L__BB232_11;
$L__BB232_6:
	mov.b32 	%r6, %f2;
	shr.u32 	%r7, %r6, 23;
	and.b32  	%r45, %r7, 224;
	add.s32 	%r46, %r45, -128;
	shl.b32 	%r47, %r6, 8;
	or.b32  	%r51, %r47, -2147483648;
	shr.u32 	%r9, %r46, 5;
	mov.b32 	%r118, 0;
	mov.u64 	%rd62, 0;
	mov.u64 	%rd33, __cudart_i2opi_f;
$L__BB232_7:
	.pragma "nounroll";
	add.s64 	%rd34, %rd33, %rd62;
	ld.global.nc.u32 	%r50, [%rd34];
	// begin inline asm
	{
	mad.lo.cc.u32   %r48, %r50, %r51, %r118;
	madc.hi.u32     %r118, %r50, %r51,  0;
	}
	// end inline asm
	add.s64 	%rd35, %rd5, %rd62;
	st.local.u32 	[%rd35], %r48;
	add.s64 	%rd62, %rd62, 4;
	cvt.u32.u64 	%r53, %rd62;
	setp.ne.s32 	%p5, %r53, 24;
	@%p5 bra 	$L__BB232_7;
	st.local.u32 	[%rd5+24], %r118;
	and.b32  	%r12, %r7, 31;
	mul.wide.u32 	%rd36, %r9, 4;
	sub.s64 	%rd12, %rd5, %rd36;
	ld.local.u32 	%r119, [%rd12+24];
	ld.local.u32 	%r120, [%rd12+20];
	setp.eq.s32 	%p6, %r12, 0;
	@%p6 bra 	$L__BB232_10;
	shl.b32 	%r54, %r120, %r12;
	shl.b32 	%r55, %r119, %r12;
	mov.b32 	%r56, 32;
	sub.s32 	%r57, %r56, %r12;
	shr.u32 	%r58, %r120, %r57;
	add.s32 	%r119, %r58, %r55;
	ld.local.u32 	%r59, [%rd12+16];
	shr.u32 	%r60, %r59, %r57;
	add.s32 	%r120, %r60, %r54;
$L__BB232_10:
	shr.u32 	%r61, %r119, 30;
	shr.u32 	%r62, %r120, 30;
	shl.b32 	%r63, %r119, 2;
	or.b32  	%r64, %r63, %r62;
	shl.b32 	%r65, %r120, 2;
	bfe.u32 	%r66, %r119, 29, 1;
	add.s32 	%r67, %r66, %r61;
	neg.s32 	%r68, %r67;
	setp.lt.s32 	%p7, %r6, 0;
	selp.b32 	%r121, %r68, %r67, %p7;
	xor.b32  	%r69, %r64, %r6;
	bfe.s32 	%r70, %r119, 29, 1;
	xor.b32  	%r71, %r70, %r64;
	xor.b32  	%r72, %r70, %r65;
	cvt.u64.u32 	%rd37, %r71;
	shl.b64 	%rd38, %rd37, 32;
	cvt.u64.u32 	%rd39, %r72;
	or.b64  	%rd40, %rd38, %rd39;
	cvt.rn.f64.s64 	%fd1, %rd40;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f123, %fd2;
	neg.f32 	%f124, %f123;
	setp.lt.s32 	%p8, %r69, 0;
	selp.f32 	%f159, %f124, %f123, %p8;
$L__BB232_11:
	add.s32 	%r74, %r121, 1;
	mul.rn.f32 	%f126, %f159, %f159;
	and.b32  	%r75, %r121, 1;
	setp.eq.b32 	%p10, %r75, 1;
	selp.f32 	%f127, %f159, 0f3F800000, %p10;
	fma.rn.f32 	%f128, %f126, %f127, 0f00000000;
	fma.rn.f32 	%f129, %f126, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f130, 0fB94D4153, %f129, %p10;
	selp.f32 	%f131, 0f3C0885E4, 0f3D2AAABB, %p10;
	fma.rn.f32 	%f132, %f130, %f126, %f131;
	selp.f32 	%f133, 0fBE2AAAA8, 0fBEFFFFFF, %p10;
	fma.rn.f32 	%f134, %f132, %f126, %f133;
	fma.rn.f32 	%f135, %f134, %f128, %f127;
	and.b32  	%r76, %r74, 2;
	setp.eq.s32 	%p11, %r76, 0;
	mov.f32 	%f136, 0f00000000;
	sub.rn.f32 	%f137, %f136, %f135;
	selp.f32 	%f138, %f135, %f137, %p11;
	mul.rn.f32 	%f10, %f1, %f138;
	mul.lo.s64 	%rd41, %rd7, 72;
	add.s64 	%rd42, %rd4, %rd41;
	mul.lo.s64 	%rd43, %rd8, 24;
	add.s64 	%rd44, %rd42, %rd43;
	shl.b64 	%rd45, %rd9, 2;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.nc.f32 	%f11, [%rd46];
	@%p3 bra 	$L__BB232_19;
	@%p22 bra 	$L__BB232_14;
	mul.rn.f32 	%f160, %f2, %f136;
	mov.b32 	%r125, 0;
	bra.uni 	$L__BB232_19;
$L__BB232_14:
	mov.b32 	%r21, %f2;
	shr.u32 	%r22, %r21, 23;
	and.b32  	%r78, %r22, 224;
	add.s32 	%r79, %r78, -128;
	shl.b32 	%r80, %r21, 8;
	or.b32  	%r84, %r80, -2147483648;
	shr.u32 	%r24, %r79, 5;
	mov.b32 	%r122, 0;
	mov.u64 	%rd63, 0;
	mov.u64 	%rd48, __cudart_i2opi_f;
$L__BB232_15:
	.pragma "nounroll";
	add.s64 	%rd49, %rd48, %rd63;
	ld.global.nc.u32 	%r83, [%rd49];
	// begin inline asm
	{
	mad.lo.cc.u32   %r81, %r83, %r84, %r122;
	madc.hi.u32     %r122, %r83, %r84,  0;
	}
	// end inline asm
	add.s64 	%rd50, %rd5, %rd63;
	st.local.u32 	[%rd50], %r81;
	add.s64 	%rd63, %rd63, 4;
	cvt.u32.u64 	%r86, %rd63;
	setp.ne.s32 	%p13, %r86, 24;
	@%p13 bra 	$L__BB232_15;
	st.local.u32 	[%rd5+24], %r122;
	and.b32  	%r27, %r22, 31;
	mul.wide.u32 	%rd51, %r24, 4;
	sub.s64 	%rd15, %rd5, %rd51;
	ld.local.u32 	%r123, [%rd15+24];
	ld.local.u32 	%r124, [%rd15+20];
	setp.eq.s32 	%p14, %r27, 0;
	@%p14 bra 	$L__BB232_18;
	shl.b32 	%r87, %r124, %r27;
	shl.b32 	%r88, %r123, %r27;
	mov.b32 	%r89, 32;
	sub.s32 	%r90, %r89, %r27;
	shr.u32 	%r91, %r124, %r90;
	add.s32 	%r123, %r91, %r88;
	ld.local.u32 	%r92, [%rd15+16];
	shr.u32 	%r93, %r92, %r90;
	add.s32 	%r124, %r93, %r87;
$L__BB232_18:
	shr.u32 	%r94, %r123, 30;
	shr.u32 	%r95, %r124, 30;
	shl.b32 	%r96, %r123, 2;
	or.b32  	%r97, %r96, %r95;
	shl.b32 	%r98, %r124, 2;
	bfe.u32 	%r99, %r123, 29, 1;
	add.s32 	%r100, %r99, %r94;
	neg.s32 	%r101, %r100;
	setp.lt.s32 	%p15, %r21, 0;
	selp.b32 	%r125, %r101, %r100, %p15;
	xor.b32  	%r102, %r97, %r21;
	bfe.s32 	%r103, %r123, 29, 1;
	xor.b32  	%r104, %r103, %r97;
	xor.b32  	%r105, %r103, %r98;
	cvt.u64.u32 	%rd52, %r104;
	shl.b64 	%rd53, %rd52, 32;
	cvt.u64.u32 	%rd54, %r105;
	or.b64  	%rd55, %rd53, %rd54;
	cvt.rn.f64.s64 	%fd3, %rd55;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f139, %fd4;
	neg.f32 	%f140, %f139;
	setp.lt.s32 	%p16, %r102, 0;
	selp.f32 	%f160, %f140, %f139, %p16;
$L__BB232_19:
	mul.rn.f32 	%f142, %f160, %f160;
	and.b32  	%r107, %r125, 1;
	setp.eq.b32 	%p17, %r107, 1;
	selp.f32 	%f143, 0f3F800000, %f160, %p17;
	fma.rn.f32 	%f144, %f142, %f143, 0f00000000;
	fma.rn.f32 	%f145, %f142, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f146, %f145, 0fB94D4153, %p17;
	selp.f32 	%f147, 0f3D2AAABB, 0f3C0885E4, %p17;
	fma.rn.f32 	%f148, %f146, %f142, %f147;
	selp.f32 	%f149, 0fBEFFFFFF, 0fBE2AAAA8, %p17;
	fma.rn.f32 	%f150, %f148, %f142, %f149;
	fma.rn.f32 	%f151, %f150, %f144, %f143;
	and.b32  	%r108, %r125, 2;
	setp.eq.s32 	%p18, %r108, 0;
	sub.rn.f32 	%f153, %f136, %f151;
	selp.f32 	%f154, %f151, %f153, %p18;
	mul.rn.f32 	%f155, %f11, %f154;
	add.rn.f32 	%f156, %f10, %f155;
	add.rn.f32 	%f158, %f156, 0f00000000;
$L__BB232_4:
	setp.lt.u32 	%p19, %r1, %r3;
	shfl.sync.down.b32	%f6, %f158, 1, 31, -1;
	setp.eq.s32 	%p20, %r2, 0;
	and.pred  	%p21, %p20, %p19;
	@%p21 bra 	$L__BB232_20;
	bra.uni 	$L__BB232_5;
$L__BB232_20:
	ld.param.u64 	%rd17, [input_reduce_fusion_321_param_3];
	cvta.to.global.u64 	%rd1, %rd17;
	add.rn.f32 	%f157, %f158, %f6;
	or.b32  	%r109, %r4, %r1;
	mul.hi.u32 	%r110, %r109, 1431655766;
	mul.lo.s32 	%r111, %r110, 3;
	sub.s32 	%r112, %r109, %r111;
	mul.hi.u32 	%r113, %r110, 1431655766;
	mul.lo.s32 	%r114, %r113, 3;
	sub.s32 	%r115, %r110, %r114;
	mul.hi.u32 	%r116, %r109, 954437177;
	shr.u32 	%r117, %r116, 1;
	mul.wide.u32 	%rd56, %r112, 12;
	mul.wide.u32 	%rd57, %r117, 36;
	add.s64 	%rd58, %rd1, %rd57;
	add.s64 	%rd59, %rd58, %rd56;
	mul.wide.u32 	%rd60, %r115, 4;
	add.s64 	%rd61, %rd59, %rd60;
	st.global.f32 	[%rd61], %f157;
$L__BB232_5:
	ret;

}
	// .globl	input_reduce_fusion_322
.visible .entry input_reduce_fusion_322(
	.param .u64 input_reduce_fusion_322_param_0,
	.param .u64 input_reduce_fusion_322_param_1,
	.param .u64 input_reduce_fusion_322_param_2,
	.param .u64 input_reduce_fusion_322_param_3,
	.param .u64 input_reduce_fusion_322_param_4,
	.param .u64 input_reduce_fusion_322_param_5,
	.param .u64 input_reduce_fusion_322_param_6,
	.param .u64 input_reduce_fusion_322_param_7
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<20>;
	.reg .b16 	%rs<21>;
	.reg .b32 	%r<42>;
	.reg .f32 	%f<87>;
	.reg .b64 	%rd<103>;
	// demoted variable
	.shared .align 4 .b8 shared_cache33[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache34[4224];
	ld.param.u64 	%rd22, [input_reduce_fusion_322_param_0];
	ld.param.u64 	%rd23, [input_reduce_fusion_322_param_7];
	cvta.to.global.u64 	%rd1, %rd23;
	ld.param.u64 	%rd24, [input_reduce_fusion_322_param_1];
	ld.param.u64 	%rd25, [input_reduce_fusion_322_param_6];
	cvta.to.global.u64 	%rd2, %rd25;
	ld.param.u64 	%rd26, [input_reduce_fusion_322_param_2];
	ld.param.u64 	%rd27, [input_reduce_fusion_322_param_5];
	cvta.to.global.u64 	%rd28, %rd27;
	ld.param.u64 	%rd29, [input_reduce_fusion_322_param_3];
	ld.param.u64 	%rd30, [input_reduce_fusion_322_param_4];
	cvta.to.global.u64 	%rd31, %rd30;
	cvta.to.global.u64 	%rd32, %rd29;
	cvta.to.global.u64 	%rd33, %rd26;
	cvta.to.global.u64 	%rd34, %rd24;
	cvta.to.global.u64 	%rd35, %rd22;
	mov.u32 	%r9, %tid.x;
	mov.u32 	%r10, %ctaid.x;
	shr.u32 	%r1, %r9, 5;
	and.b32  	%r2, %r9, 31;
	and.b32  	%r11, %r10, 1;
	shr.u32 	%r12, %r10, 1;
	setp.eq.s32 	%p5, %r11, 0;
	selp.b32 	%r3, 32, 10, %p5;
	shl.b32 	%r4, %r11, 5;
	or.b32  	%r13, %r4, %r2;
	cvt.u16.u32 	%rs1, %r13;
	mul.lo.s16 	%rs2, %rs1, 43;
	shr.u16 	%rs3, %rs2, 8;
	cvt.u32.u16 	%r14, %rs3;
	cvt.u64.u32 	%rd3, %r12;
	mul.wide.u32 	%rd36, %r12, 4;
	add.s64 	%rd4, %rd31, %rd36;
	and.b16  	%rs4, %rs3, 1;
	setp.eq.b16 	%p6, %rs4, 1;
	not.pred 	%p7, %p6;
	setp.lt.u32 	%p8, %r13, 48;
	and.pred  	%p1, %p8, %p7;
	add.s32 	%r15, %r14, -1;
	and.b32  	%r16, %r15, 1;
	setp.eq.b32 	%p9, %r16, 1;
	not.pred 	%p10, %p9;
	cvt.s8.s32 	%rs5, %r15;
	cvt.u16.u32 	%rs6, %r15;
	and.b16  	%rs7, %rs6, 128;
	shr.u16 	%rs8, %rs7, 7;
	add.s16 	%rs9, %rs5, %rs8;
	shr.s16 	%rs10, %rs9, 1;
	cvt.s32.s16 	%r17, %rs10;
	add.s32 	%r18, %r13, -6;
	setp.lt.u32 	%p11, %r18, 48;
	and.pred  	%p2, %p11, %p10;
	and.b32  	%r5, %r17, -3;
	shr.u32 	%r19, %r17, 1;
	add.s32 	%r20, %r17, -1;
	setp.gt.u32 	%p12, %r13, 17;
	and.b32  	%r21, %r20, 1;
	setp.eq.b32 	%p13, %r21, 1;
	not.pred 	%p14, %p13;
	and.pred  	%p3, %p12, %p14;
	shr.u32 	%r22, %r20, 1;
	add.s32 	%r41, %r1, -32;
	mul.wide.u32 	%rd37, %r12, 9600;
	cvt.u64.u32 	%rd38, %r9;
	shr.u64 	%rd39, %rd38, 5;
	mul.lo.s64 	%rd40, %rd39, 192;
	add.s64 	%rd41, %rd37, %rd40;
	cvt.u16.u32 	%rs11, %r10;
	and.b16  	%rs12, %rs11, 1;
	shl.b16 	%rs13, %rs12, 5;
	cvt.u16.u32 	%rs14, %r9;
	and.b16  	%rs15, %rs14, 31;
	or.b16  	%rs16, %rs13, %rs15;
	cvt.u32.u16 	%r23, %rs16;
	mul.hi.u32 	%r24, %r23, 715827883;
	mul.wide.u32 	%rd42, %r24, 24;
	add.s64 	%rd43, %rd41, %rd42;
	mul.lo.s16 	%rs17, %rs16, 43;
	shr.u16 	%rs18, %rs17, 8;
	mul.lo.s16 	%rs19, %rs18, 6;
	sub.s16 	%rs20, %rs16, %rs19;
	cvt.u32.u16 	%r25, %rs20;
	and.b32  	%r26, %r25, 255;
	mul.wide.u32 	%rd44, %r26, 4;
	add.s64 	%rd45, %rd43, %rd44;
	add.s64 	%rd46, %rd45, %rd32;
	add.s64 	%rd102, %rd46, 24;
	mul.wide.u32 	%rd47, %r12, 8400;
	mul.lo.s64 	%rd48, %rd39, 168;
	add.s64 	%rd49, %rd47, %rd48;
	add.s64 	%rd50, %rd49, %rd42;
	add.s64 	%rd51, %rd50, %rd44;
	add.s64 	%rd101, %rd28, %rd51;
	mul.wide.u32 	%rd52, %r12, 4800;
	mul.lo.s64 	%rd53, %rd39, 96;
	add.s64 	%rd54, %rd52, %rd53;
	mul.hi.u32 	%r27, %r23, 357913942;
	mul.wide.u32 	%rd55, %r27, 24;
	add.s64 	%rd56, %rd54, %rd55;
	add.s64 	%rd57, %rd56, %rd44;
	add.s64 	%rd100, %rd33, %rd57;
	mul.wide.u32 	%rd58, %r12, 2400;
	mul.lo.s64 	%rd59, %rd39, 48;
	add.s64 	%rd60, %rd58, %rd59;
	mul.wide.u32 	%rd61, %r19, 24;
	add.s64 	%rd62, %rd60, %rd61;
	add.s64 	%rd63, %rd62, %rd44;
	add.s64 	%rd99, %rd34, %rd63;
	mul.wide.u32 	%rd64, %r22, 24;
	add.s64 	%rd65, %rd60, %rd64;
	add.s64 	%rd66, %rd65, %rd44;
	add.s64 	%rd98, %rd35, %rd66;
	mov.f32 	%f1, 0f00000000;
	setp.lt.u32 	%p15, %r2, %r3;
	mov.f32 	%f24, 0f4B400001;
	mov.f32 	%f2, %f1;
	bra.uni 	$L__BB233_1;
$L__BB233_12:
	add.rn.f32 	%f84, %f85, %f86;
$L__BB233_8:
	add.rn.f32 	%f54, %f83, %f84;
	mul.rn.f32 	%f55, %f8, %f54;
	add.rn.f32 	%f2, %f2, %f55;
	ld.global.nc.f32 	%f56, [%rd101];
	mul.rn.f32 	%f57, %f7, %f56;
	add.rn.f32 	%f1, %f1, %f57;
$L__BB233_2:
	add.s32 	%r41, %r41, 32;
	add.s64 	%rd102, %rd102, 6144;
	add.s64 	%rd101, %rd101, 5376;
	add.s64 	%rd100, %rd100, 3072;
	add.s64 	%rd99, %rd99, 1536;
	add.s64 	%rd98, %rd98, 1536;
	setp.lt.u32 	%p17, %r41, 18;
	@%p17 bra 	$L__BB233_1;
	bra.uni 	$L__BB233_3;
$L__BB233_1:
	@%p15 bra 	$L__BB233_6;
	bra.uni 	$L__BB233_2;
$L__BB233_6:
	ld.global.nc.f32 	%f21, [%rd4];
	fma.rn.f32 	%f22, %f21, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f23, %f22;
	mov.f32 	%f25, 0f437C0000;
	fma.rm.f32 	%f26, %f23, %f25, %f24;
	add.rn.f32 	%f27, %f26, 0fCB40007F;
	neg.f32 	%f28, %f27;
	fma.rn.f32 	%f29, %f21, 0f3FB8AA3B, %f28;
	fma.rn.f32 	%f30, %f21, 0f32A57060, %f29;
	mov.b32 	%r28, %f26;
	shl.b32 	%r29, %r28, 23;
	mov.b32 	%f31, %r29;
	ex2.approx.ftz.f32 	%f32, %f30;
	mul.rn.f32 	%f33, %f32, %f31;
	neg.f32 	%f34, %f33;
	sub.rn.f32 	%f35, %f34, %f33;
	add.rn.f32 	%f36, %f35, %f35;
	add.rn.f32 	%f37, %f36, %f36;
	add.rn.f32 	%f38, %f37, %f37;
	add.rn.f32 	%f39, %f38, %f38;
	add.rn.f32 	%f40, %f39, %f39;
	fma.rn.f32 	%f41, %f40, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f42, %f41;
	fma.rm.f32 	%f43, %f42, %f25, %f24;
	add.rn.f32 	%f44, %f43, 0fCB40007F;
	neg.f32 	%f45, %f44;
	fma.rn.f32 	%f46, %f40, 0f3FB8AA3B, %f45;
	fma.rn.f32 	%f47, %f40, 0f32A57060, %f46;
	mov.b32 	%r30, %f43;
	shl.b32 	%r31, %r30, 23;
	mov.b32 	%f48, %r31;
	ex2.approx.ftz.f32 	%f49, %f47;
	mul.rn.f32 	%f50, %f49, %f48;
	ld.global.nc.f32 	%f7, [%rd102];
	mov.f32 	%f84, 0f00000000;
	mov.f32 	%f83, %f84;
	@%p1 bra 	$L__BB233_9;
	bra.uni 	$L__BB233_7;
$L__BB233_9:
	ld.global.nc.f32 	%f83, [%rd100];
$L__BB233_7:
	mul.rn.f32 	%f8, %f7, %f50;
	@%p2 bra 	$L__BB233_10;
	bra.uni 	$L__BB233_8;
$L__BB233_10:
	setp.eq.s32 	%p16, %r5, 0;
	mov.f32 	%f86, 0f00000000;
	mov.f32 	%f85, %f86;
	@%p16 bra 	$L__BB233_13;
	bra.uni 	$L__BB233_11;
$L__BB233_13:
	ld.global.nc.f32 	%f85, [%rd99];
$L__BB233_11:
	@%p3 bra 	$L__BB233_14;
	bra.uni 	$L__BB233_12;
$L__BB233_14:
	ld.global.nc.f32 	%f86, [%rd98];
	bra.uni 	$L__BB233_12;
$L__BB233_3:
	cvt.u64.u32 	%rd20, %r2;
	cvt.u64.u32 	%rd21, %r1;
	mul.wide.u32 	%rd67, %r2, 132;
	mov.u64 	%rd68, shared_cache33;
	add.s64 	%rd69, %rd68, %rd67;
	mul.wide.u32 	%rd70, %r1, 4;
	add.s64 	%rd71, %rd69, %rd70;
	st.shared.f32 	[%rd71], %f2;
	bar.sync 	0;
	mul.wide.u32 	%rd72, %r1, 132;
	add.s64 	%rd73, %rd68, %rd72;
	mul.wide.u32 	%rd74, %r2, 4;
	add.s64 	%rd75, %rd73, %rd74;
	ld.shared.f32 	%f58, [%rd75];
	shfl.sync.down.b32	%f59, %f58, 16, 31, -1;
	add.rn.f32 	%f60, %f58, %f59;
	shfl.sync.down.b32	%f61, %f60, 8, 31, -1;
	add.rn.f32 	%f62, %f60, %f61;
	shfl.sync.down.b32	%f63, %f62, 4, 31, -1;
	add.rn.f32 	%f64, %f62, %f63;
	shfl.sync.down.b32	%f65, %f64, 2, 31, -1;
	add.rn.f32 	%f66, %f64, %f65;
	shfl.sync.down.b32	%f67, %f66, 1, 31, -1;
	add.rn.f32 	%f5, %f66, %f67;
	st.shared.f32 	[%rd75], %f5;
	setp.lt.u32 	%p18, %r1, %r3;
	setp.eq.s32 	%p19, %r2, 0;
	and.pred  	%p4, %p19, %p18;
	or.b32  	%r40, %r4, %r1;
	mul.lo.s64 	%rd97, %rd3, 168;
	@%p4 bra 	$L__BB233_15;
	bra.uni 	$L__BB233_4;
$L__BB233_15:
	mul.hi.u32 	%r33, %r40, 715827883;
	mul.lo.s32 	%r34, %r33, 6;
	sub.s32 	%r35, %r40, %r34;
	add.s64 	%rd77, %rd2, %rd97;
	mul.wide.u32 	%rd78, %r33, 24;
	add.s64 	%rd79, %rd77, %rd78;
	mul.wide.u32 	%rd80, %r35, 4;
	add.s64 	%rd81, %rd79, %rd80;
	neg.f32 	%f68, %f5;
	st.global.f32 	[%rd81], %f68;
$L__BB233_4:
	mul.lo.s64 	%rd82, %rd20, 132;
	mov.u64 	%rd83, shared_cache34;
	add.s64 	%rd84, %rd83, %rd82;
	shl.b64 	%rd85, %rd21, 2;
	add.s64 	%rd86, %rd84, %rd85;
	st.shared.f32 	[%rd86], %f1;
	bar.sync 	0;
	mul.lo.s64 	%rd87, %rd21, 132;
	add.s64 	%rd88, %rd83, %rd87;
	shl.b64 	%rd89, %rd20, 2;
	add.s64 	%rd90, %rd88, %rd89;
	ld.shared.f32 	%f69, [%rd90];
	shfl.sync.down.b32	%f70, %f69, 16, 31, -1;
	add.rn.f32 	%f71, %f69, %f70;
	shfl.sync.down.b32	%f72, %f71, 8, 31, -1;
	add.rn.f32 	%f73, %f71, %f72;
	shfl.sync.down.b32	%f74, %f73, 4, 31, -1;
	add.rn.f32 	%f75, %f73, %f74;
	shfl.sync.down.b32	%f76, %f75, 2, 31, -1;
	add.rn.f32 	%f77, %f75, %f76;
	shfl.sync.down.b32	%f78, %f77, 1, 31, -1;
	add.rn.f32 	%f6, %f77, %f78;
	st.shared.f32 	[%rd90], %f6;
	@%p4 bra 	$L__BB233_16;
	bra.uni 	$L__BB233_5;
$L__BB233_16:
	mul.hi.u32 	%r37, %r40, 715827883;
	mul.lo.s32 	%r38, %r37, 6;
	sub.s32 	%r39, %r40, %r38;
	add.s64 	%rd92, %rd1, %rd97;
	mul.wide.u32 	%rd93, %r37, 24;
	add.s64 	%rd94, %rd92, %rd93;
	mul.wide.u32 	%rd95, %r39, 4;
	add.s64 	%rd96, %rd94, %rd95;
	st.global.f32 	[%rd96], %f6;
$L__BB233_5:
	ret;

}
	// .globl	input_reduce_fusion_323
.visible .entry input_reduce_fusion_323(
	.param .u64 input_reduce_fusion_323_param_0,
	.param .u64 input_reduce_fusion_323_param_1,
	.param .u64 input_reduce_fusion_323_param_2,
	.param .u64 input_reduce_fusion_323_param_3
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<26>;
	.reg .f32 	%f<52>;
	.reg .b64 	%rd<53>;
	// demoted variable
	.shared .align 4 .b8 shared_cache35[4224];
	ld.param.u64 	%rd10, [input_reduce_fusion_323_param_0];
	ld.param.u64 	%rd11, [input_reduce_fusion_323_param_3];
	cvta.to.global.u64 	%rd1, %rd11;
	ld.param.u64 	%rd12, [input_reduce_fusion_323_param_1];
	ld.param.u64 	%rd13, [input_reduce_fusion_323_param_2];
	cvta.to.global.u64 	%rd14, %rd13;
	cvta.to.global.u64 	%rd15, %rd12;
	cvta.to.global.u64 	%rd16, %rd10;
	mov.u32 	%r8, %tid.x;
	mov.u32 	%r9, %ctaid.x;
	shr.u32 	%r1, %r8, 5;
	and.b32  	%r2, %r8, 31;
	and.b32  	%r10, %r9, 1;
	shr.u32 	%r11, %r9, 1;
	setp.eq.s32 	%p1, %r10, 0;
	selp.b32 	%r3, 32, 10, %p1;
	shl.b32 	%r4, %r10, 5;
	cvt.u64.u32 	%rd2, %r11;
	mul.wide.u32 	%rd17, %r11, 4;
	add.s64 	%rd3, %rd14, %rd17;
	add.s32 	%r25, %r1, -32;
	mul.wide.u32 	%rd18, %r11, 9600;
	cvt.u64.u32 	%rd19, %r8;
	shr.u64 	%rd20, %rd19, 5;
	mul.lo.s64 	%rd21, %rd20, 192;
	add.s64 	%rd22, %rd18, %rd21;
	cvt.u16.u32 	%rs1, %r9;
	and.b16  	%rs2, %rs1, 1;
	shl.b16 	%rs3, %rs2, 5;
	cvt.u16.u32 	%rs4, %r8;
	and.b16  	%rs5, %rs4, 31;
	or.b16  	%rs6, %rs3, %rs5;
	cvt.u32.u16 	%r12, %rs6;
	mul.hi.u32 	%r13, %r12, 715827883;
	mul.wide.u32 	%rd23, %r13, 24;
	add.s64 	%rd24, %rd22, %rd23;
	mul.lo.s16 	%rs7, %rs6, 43;
	shr.u16 	%rs8, %rs7, 8;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs6, %rs9;
	cvt.u32.u16 	%r14, %rs10;
	and.b32  	%r15, %r14, 255;
	mul.wide.u32 	%rd25, %r15, 4;
	add.s64 	%rd26, %rd24, %rd25;
	add.s64 	%rd27, %rd26, %rd15;
	add.s64 	%rd52, %rd27, 24;
	mul.wide.u32 	%rd28, %r11, 8400;
	mul.lo.s64 	%rd29, %rd20, 168;
	add.s64 	%rd30, %rd28, %rd29;
	add.s64 	%rd31, %rd30, %rd23;
	and.b64  	%rd32, %rd25, 1016;
	add.s64 	%rd33, %rd31, %rd32;
	and.b32  	%r16, %r8, 1;
	mul.wide.u32 	%rd34, %r16, 4;
	or.b64  	%rd35, %rd33, %rd34;
	add.s64 	%rd51, %rd16, %rd35;
	mov.f32 	%f50, 0f00000000;
	setp.lt.u32 	%p2, %r2, %r3;
	mov.f32 	%f9, 0f4B400001;
	mov.f32 	%f10, 0f437C0000;
	bra.uni 	$L__BB234_1;
$L__BB234_2:
	add.s32 	%r25, %r25, 32;
	add.s64 	%rd52, %rd52, 6144;
	add.s64 	%rd51, %rd51, 5376;
	setp.lt.u32 	%p3, %r25, 18;
	@%p3 bra 	$L__BB234_1;
	bra.uni 	$L__BB234_3;
$L__BB234_1:
	@%p2 bra 	$L__BB234_5;
	bra.uni 	$L__BB234_2;
$L__BB234_5:
	ld.global.nc.f32 	%f6, [%rd3];
	fma.rn.f32 	%f7, %f6, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f8, %f7;
	fma.rm.f32 	%f11, %f8, %f10, %f9;
	add.rn.f32 	%f12, %f11, 0fCB40007F;
	neg.f32 	%f13, %f12;
	fma.rn.f32 	%f14, %f6, 0f3FB8AA3B, %f13;
	fma.rn.f32 	%f15, %f6, 0f32A57060, %f14;
	mov.b32 	%r17, %f11;
	shl.b32 	%r18, %r17, 23;
	mov.b32 	%f16, %r18;
	ex2.approx.ftz.f32 	%f17, %f15;
	mul.rn.f32 	%f18, %f17, %f16;
	neg.f32 	%f19, %f18;
	sub.rn.f32 	%f20, %f19, %f18;
	add.rn.f32 	%f21, %f20, %f20;
	add.rn.f32 	%f22, %f21, %f21;
	add.rn.f32 	%f23, %f22, %f22;
	add.rn.f32 	%f24, %f23, %f23;
	add.rn.f32 	%f25, %f24, %f24;
	fma.rn.f32 	%f26, %f25, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f27, %f26;
	fma.rm.f32 	%f28, %f27, %f10, %f9;
	add.rn.f32 	%f29, %f28, 0fCB40007F;
	neg.f32 	%f30, %f29;
	fma.rn.f32 	%f31, %f25, 0f3FB8AA3B, %f30;
	fma.rn.f32 	%f32, %f25, 0f32A57060, %f31;
	mov.b32 	%r19, %f28;
	shl.b32 	%r20, %r19, 23;
	mov.b32 	%f33, %r20;
	ex2.approx.ftz.f32 	%f34, %f32;
	mul.rn.f32 	%f35, %f34, %f33;
	ld.global.nc.f32 	%f36, [%rd52];
	mul.rn.f32 	%f37, %f36, %f35;
	ld.global.nc.f32 	%f38, [%rd51];
	mul.rn.f32 	%f39, %f38, %f37;
	add.rn.f32 	%f50, %f50, %f39;
	bra.uni 	$L__BB234_2;
$L__BB234_3:
	mul.wide.u32 	%rd36, %r2, 132;
	mov.u64 	%rd37, shared_cache35;
	add.s64 	%rd38, %rd37, %rd36;
	mul.wide.u32 	%rd39, %r1, 4;
	add.s64 	%rd40, %rd38, %rd39;
	st.shared.f32 	[%rd40], %f50;
	bar.sync 	0;
	mul.wide.u32 	%rd41, %r1, 132;
	add.s64 	%rd42, %rd37, %rd41;
	mul.wide.u32 	%rd43, %r2, 4;
	add.s64 	%rd44, %rd42, %rd43;
	ld.shared.f32 	%f40, [%rd44];
	shfl.sync.down.b32	%f41, %f40, 16, 31, -1;
	add.rn.f32 	%f42, %f40, %f41;
	shfl.sync.down.b32	%f43, %f42, 8, 31, -1;
	add.rn.f32 	%f44, %f42, %f43;
	shfl.sync.down.b32	%f45, %f44, 4, 31, -1;
	add.rn.f32 	%f46, %f44, %f45;
	shfl.sync.down.b32	%f47, %f46, 2, 31, -1;
	add.rn.f32 	%f48, %f46, %f47;
	shfl.sync.down.b32	%f49, %f48, 1, 31, -1;
	add.rn.f32 	%f3, %f48, %f49;
	st.shared.f32 	[%rd44], %f3;
	setp.lt.u32 	%p4, %r1, %r3;
	setp.eq.s32 	%p5, %r2, 0;
	and.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB234_6;
	bra.uni 	$L__BB234_4;
$L__BB234_6:
	or.b32  	%r21, %r4, %r1;
	mul.hi.u32 	%r22, %r21, 715827883;
	mul.lo.s32 	%r23, %r22, 6;
	sub.s32 	%r24, %r21, %r23;
	mul.lo.s64 	%rd45, %rd2, 168;
	add.s64 	%rd46, %rd1, %rd45;
	mul.wide.u32 	%rd47, %r22, 24;
	add.s64 	%rd48, %rd46, %rd47;
	mul.wide.u32 	%rd49, %r24, 4;
	add.s64 	%rd50, %rd48, %rd49;
	st.global.f32 	[%rd50], %f3;
$L__BB234_4:
	ret;

}
	// .globl	input_reduce_fusion_324
.visible .entry input_reduce_fusion_324(
	.param .u64 input_reduce_fusion_324_param_0,
	.param .u64 input_reduce_fusion_324_param_1,
	.param .u64 input_reduce_fusion_324_param_2,
	.param .u64 input_reduce_fusion_324_param_3
)
.reqntid 256, 1, 1
{
	.local .align 4 .b8 	__local_depot235[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<23>;
	.reg .b16 	%rs<16>;
	.reg .b32 	%r<126>;
	.reg .f32 	%f<61>;
	.reg .b64 	%rd<64>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot235;
	mov.u32 	%r36, %tid.x;
	mov.u32 	%r37, %ctaid.x;
	shr.u32 	%r1, %r36, 1;
	and.b32  	%r2, %r36, 1;
	setp.eq.s32 	%p1, %r37, 10;
	selp.b32 	%r3, 64, 128, %p1;
	shl.b32 	%r4, %r37, 7;
	setp.ge.u32 	%p2, %r1, %r3;
	mov.f32 	%f60, 0f00000000;
	@%p2 bra 	$L__BB235_18;
	ld.param.u64 	%rd16, [input_reduce_fusion_324_param_0];
	ld.param.u64 	%rd18, [input_reduce_fusion_324_param_1];
	ld.param.u64 	%rd19, [input_reduce_fusion_324_param_2];
	cvta.to.global.u64 	%rd2, %rd19;
	cvta.to.global.u64 	%rd3, %rd18;
	cvta.to.global.u64 	%rd4, %rd16;
	add.u64 	%rd5, %SPL, 0;
	or.b32  	%r38, %r1, %r4;
	cvt.u16.u32 	%rs1, %r38;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 18725;
	shr.u16 	%rs7, %rs6, 1;
	mul.lo.s16 	%rs8, %rs7, 7;
	sub.s16 	%rs9, %rs3, %rs8;
	mul.hi.u16 	%rs10, %rs1, -31207;
	sub.s16 	%rs11, %rs1, %rs10;
	shr.u16 	%rs12, %rs11, 1;
	add.s16 	%rs13, %rs12, %rs10;
	shr.u16 	%rs14, %rs13, 4;
	shl.b16 	%rs15, %rs5, 1;
	cvt.u32.u16 	%r39, %rs15;
	or.b32  	%r40, %r2, %r39;
	cvt.u64.u16 	%rd7, %rs14;
	cvt.u64.u16 	%rd8, %rs9;
	cvt.u64.u32 	%rd9, %r40;
	cvt.u32.u16 	%r41, %rs14;
	mul.wide.u32 	%rd22, %r41, 168;
	add.s64 	%rd23, %rd2, %rd22;
	cvt.u32.u16 	%r42, %rs9;
	mul.wide.u32 	%rd24, %r42, 24;
	add.s64 	%rd25, %rd23, %rd24;
	mul.wide.u32 	%rd26, %r40, 4;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.f32 	%f1, [%rd27];
	mul.wide.u32 	%rd28, %r41, 12;
	add.s64 	%rd29, %rd4, %rd28;
	cvt.u32.u16 	%r43, %rs5;
	mul.wide.u32 	%rd30, %r43, 4;
	add.s64 	%rd31, %rd29, %rd30;
	ld.global.nc.f32 	%f17, [%rd31];
	add.rn.f32 	%f18, %f17, %f17;
	add.rn.f32 	%f2, %f18, %f18;
	mul.rn.f32 	%f19, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r125, %f19;
	cvt.rn.f32.s32 	%f20, %r125;
	fma.rn.f32 	%f21, %f20, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f22, %f20, 0fB3A22168, %f21;
	fma.rn.f32 	%f59, %f20, 0fA7C234C5, %f22;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p3, %f4, 0f47CE4780;
	setp.neu.f32 	%p22, %f4, 0f7F800000;
	mov.u32 	%r121, %r125;
	mov.f32 	%f58, %f59;
	@%p3 bra 	$L__BB235_9;
	@%p22 bra 	$L__BB235_4;
	mov.f32 	%f25, 0f00000000;
	mul.rn.f32 	%f58, %f2, %f25;
	mov.b32 	%r121, 0;
	bra.uni 	$L__BB235_9;
$L__BB235_4:
	mov.b32 	%r6, %f2;
	shr.u32 	%r7, %r6, 23;
	and.b32  	%r45, %r7, 224;
	add.s32 	%r46, %r45, -128;
	shl.b32 	%r47, %r6, 8;
	or.b32  	%r51, %r47, -2147483648;
	shr.u32 	%r9, %r46, 5;
	mov.b32 	%r118, 0;
	mov.u64 	%rd62, 0;
	mov.u64 	%rd33, __cudart_i2opi_f;
$L__BB235_5:
	.pragma "nounroll";
	add.s64 	%rd34, %rd33, %rd62;
	ld.global.nc.u32 	%r50, [%rd34];
	// begin inline asm
	{
	mad.lo.cc.u32   %r48, %r50, %r51, %r118;
	madc.hi.u32     %r118, %r50, %r51,  0;
	}
	// end inline asm
	add.s64 	%rd35, %rd5, %rd62;
	st.local.u32 	[%rd35], %r48;
	add.s64 	%rd62, %rd62, 4;
	cvt.u32.u64 	%r53, %rd62;
	setp.ne.s32 	%p5, %r53, 24;
	@%p5 bra 	$L__BB235_5;
	st.local.u32 	[%rd5+24], %r118;
	and.b32  	%r12, %r7, 31;
	mul.wide.u32 	%rd36, %r9, 4;
	sub.s64 	%rd12, %rd5, %rd36;
	ld.local.u32 	%r119, [%rd12+24];
	ld.local.u32 	%r120, [%rd12+20];
	setp.eq.s32 	%p6, %r12, 0;
	@%p6 bra 	$L__BB235_8;
	shl.b32 	%r54, %r120, %r12;
	shl.b32 	%r55, %r119, %r12;
	mov.b32 	%r56, 32;
	sub.s32 	%r57, %r56, %r12;
	shr.u32 	%r58, %r120, %r57;
	add.s32 	%r119, %r58, %r55;
	ld.local.u32 	%r59, [%rd12+16];
	shr.u32 	%r60, %r59, %r57;
	add.s32 	%r120, %r60, %r54;
$L__BB235_8:
	shr.u32 	%r61, %r119, 30;
	shr.u32 	%r62, %r120, 30;
	shl.b32 	%r63, %r119, 2;
	or.b32  	%r64, %r63, %r62;
	shl.b32 	%r65, %r120, 2;
	bfe.u32 	%r66, %r119, 29, 1;
	add.s32 	%r67, %r66, %r61;
	neg.s32 	%r68, %r67;
	setp.lt.s32 	%p7, %r6, 0;
	selp.b32 	%r121, %r68, %r67, %p7;
	xor.b32  	%r69, %r64, %r6;
	bfe.s32 	%r70, %r119, 29, 1;
	xor.b32  	%r71, %r70, %r64;
	xor.b32  	%r72, %r70, %r65;
	cvt.u64.u32 	%rd37, %r71;
	shl.b64 	%rd38, %rd37, 32;
	cvt.u64.u32 	%rd39, %r72;
	or.b64  	%rd40, %rd38, %rd39;
	cvt.rn.f64.s64 	%fd1, %rd40;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f23, %fd2;
	neg.f32 	%f24, %f23;
	setp.lt.s32 	%p8, %r69, 0;
	selp.f32 	%f58, %f24, %f23, %p8;
$L__BB235_9:
	add.s32 	%r74, %r121, 1;
	mul.rn.f32 	%f26, %f58, %f58;
	and.b32  	%r75, %r121, 1;
	setp.eq.b32 	%p10, %r75, 1;
	selp.f32 	%f27, %f58, 0f3F800000, %p10;
	fma.rn.f32 	%f28, %f26, %f27, 0f00000000;
	fma.rn.f32 	%f29, %f26, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f30, 0fB94D4153, %f29, %p10;
	selp.f32 	%f31, 0f3C0885E4, 0f3D2AAABB, %p10;
	fma.rn.f32 	%f32, %f30, %f26, %f31;
	selp.f32 	%f33, 0fBE2AAAA8, 0fBEFFFFFF, %p10;
	fma.rn.f32 	%f34, %f32, %f26, %f33;
	fma.rn.f32 	%f35, %f34, %f28, %f27;
	and.b32  	%r76, %r74, 2;
	setp.eq.s32 	%p11, %r76, 0;
	mov.f32 	%f36, 0f00000000;
	sub.rn.f32 	%f37, %f36, %f35;
	selp.f32 	%f38, %f35, %f37, %p11;
	mul.rn.f32 	%f8, %f1, %f38;
	mul.lo.s64 	%rd41, %rd7, 168;
	add.s64 	%rd42, %rd3, %rd41;
	mul.lo.s64 	%rd43, %rd8, 24;
	add.s64 	%rd44, %rd42, %rd43;
	shl.b64 	%rd45, %rd9, 2;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.nc.f32 	%f9, [%rd46];
	@%p3 bra 	$L__BB235_17;
	@%p22 bra 	$L__BB235_12;
	mul.rn.f32 	%f59, %f2, %f36;
	mov.b32 	%r125, 0;
	bra.uni 	$L__BB235_17;
$L__BB235_12:
	mov.b32 	%r21, %f2;
	shr.u32 	%r22, %r21, 23;
	and.b32  	%r78, %r22, 224;
	add.s32 	%r79, %r78, -128;
	shl.b32 	%r80, %r21, 8;
	or.b32  	%r84, %r80, -2147483648;
	shr.u32 	%r24, %r79, 5;
	mov.b32 	%r122, 0;
	mov.u64 	%rd63, 0;
	mov.u64 	%rd48, __cudart_i2opi_f;
$L__BB235_13:
	.pragma "nounroll";
	add.s64 	%rd49, %rd48, %rd63;
	ld.global.nc.u32 	%r83, [%rd49];
	// begin inline asm
	{
	mad.lo.cc.u32   %r81, %r83, %r84, %r122;
	madc.hi.u32     %r122, %r83, %r84,  0;
	}
	// end inline asm
	add.s64 	%rd50, %rd5, %rd63;
	st.local.u32 	[%rd50], %r81;
	add.s64 	%rd63, %rd63, 4;
	cvt.u32.u64 	%r86, %rd63;
	setp.ne.s32 	%p13, %r86, 24;
	@%p13 bra 	$L__BB235_13;
	st.local.u32 	[%rd5+24], %r122;
	and.b32  	%r27, %r22, 31;
	mul.wide.u32 	%rd51, %r24, 4;
	sub.s64 	%rd15, %rd5, %rd51;
	ld.local.u32 	%r123, [%rd15+24];
	ld.local.u32 	%r124, [%rd15+20];
	setp.eq.s32 	%p14, %r27, 0;
	@%p14 bra 	$L__BB235_16;
	shl.b32 	%r87, %r124, %r27;
	shl.b32 	%r88, %r123, %r27;
	mov.b32 	%r89, 32;
	sub.s32 	%r90, %r89, %r27;
	shr.u32 	%r91, %r124, %r90;
	add.s32 	%r123, %r91, %r88;
	ld.local.u32 	%r92, [%rd15+16];
	shr.u32 	%r93, %r92, %r90;
	add.s32 	%r124, %r93, %r87;
$L__BB235_16:
	shr.u32 	%r94, %r123, 30;
	shr.u32 	%r95, %r124, 30;
	shl.b32 	%r96, %r123, 2;
	or.b32  	%r97, %r96, %r95;
	shl.b32 	%r98, %r124, 2;
	bfe.u32 	%r99, %r123, 29, 1;
	add.s32 	%r100, %r99, %r94;
	neg.s32 	%r101, %r100;
	setp.lt.s32 	%p15, %r21, 0;
	selp.b32 	%r125, %r101, %r100, %p15;
	xor.b32  	%r102, %r97, %r21;
	bfe.s32 	%r103, %r123, 29, 1;
	xor.b32  	%r104, %r103, %r97;
	xor.b32  	%r105, %r103, %r98;
	cvt.u64.u32 	%rd52, %r104;
	shl.b64 	%rd53, %rd52, 32;
	cvt.u64.u32 	%rd54, %r105;
	or.b64  	%rd55, %rd53, %rd54;
	cvt.rn.f64.s64 	%fd3, %rd55;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f39, %fd4;
	neg.f32 	%f40, %f39;
	setp.lt.s32 	%p16, %r102, 0;
	selp.f32 	%f59, %f40, %f39, %p16;
$L__BB235_17:
	mul.rn.f32 	%f42, %f59, %f59;
	and.b32  	%r107, %r125, 1;
	setp.eq.b32 	%p17, %r107, 1;
	selp.f32 	%f43, 0f3F800000, %f59, %p17;
	fma.rn.f32 	%f44, %f42, %f43, 0f00000000;
	fma.rn.f32 	%f45, %f42, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f46, %f45, 0fB94D4153, %p17;
	selp.f32 	%f47, 0f3D2AAABB, 0f3C0885E4, %p17;
	fma.rn.f32 	%f48, %f46, %f42, %f47;
	selp.f32 	%f49, 0fBEFFFFFF, 0fBE2AAAA8, %p17;
	fma.rn.f32 	%f50, %f48, %f42, %f49;
	fma.rn.f32 	%f51, %f50, %f44, %f43;
	and.b32  	%r108, %r125, 2;
	setp.eq.s32 	%p18, %r108, 0;
	sub.rn.f32 	%f53, %f36, %f51;
	selp.f32 	%f54, %f51, %f53, %p18;
	mul.rn.f32 	%f55, %f9, %f54;
	add.rn.f32 	%f56, %f8, %f55;
	add.rn.f32 	%f60, %f56, 0f00000000;
$L__BB235_18:
	shfl.sync.down.b32	%f15, %f60, 1, 31, -1;
	setp.ne.s32 	%p20, %r2, 0;
	or.pred  	%p21, %p20, %p2;
	@%p21 bra 	$L__BB235_20;
	ld.param.u64 	%rd17, [input_reduce_fusion_324_param_3];
	cvta.to.global.u64 	%rd1, %rd17;
	add.rn.f32 	%f57, %f60, %f15;
	or.b32  	%r109, %r4, %r1;
	mul.hi.u32 	%r110, %r109, 1431655766;
	mul.lo.s32 	%r111, %r110, 3;
	sub.s32 	%r112, %r109, %r111;
	mul.hi.u32 	%r113, %r110, 613566757;
	mul.lo.s32 	%r114, %r113, 7;
	sub.s32 	%r115, %r110, %r114;
	mul.hi.u32 	%r116, %r109, 818089009;
	shr.u32 	%r117, %r116, 2;
	mul.wide.u32 	%rd56, %r112, 28;
	mul.wide.u32 	%rd57, %r117, 84;
	add.s64 	%rd58, %rd1, %rd57;
	add.s64 	%rd59, %rd58, %rd56;
	mul.wide.u32 	%rd60, %r115, 4;
	add.s64 	%rd61, %rd59, %rd60;
	st.global.f32 	[%rd61], %f57;
$L__BB235_20:
	ret;

}
	// .globl	input_reduce_fusion_325
.visible .entry input_reduce_fusion_325(
	.param .u64 input_reduce_fusion_325_param_0,
	.param .u64 input_reduce_fusion_325_param_1,
	.param .u64 input_reduce_fusion_325_param_2,
	.param .u64 input_reduce_fusion_325_param_3
)
.reqntid 256, 1, 1
{
	.local .align 4 .b8 	__local_depot236[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<19>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<122>;
	.reg .f32 	%f<59>;
	.reg .b64 	%rd<64>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot236;
	ld.param.u64 	%rd14, [input_reduce_fusion_325_param_0];
	ld.param.u64 	%rd16, [input_reduce_fusion_325_param_1];
	ld.param.u64 	%rd17, [input_reduce_fusion_325_param_2];
	cvta.to.global.u64 	%rd18, %rd17;
	cvta.to.global.u64 	%rd2, %rd16;
	cvta.to.global.u64 	%rd19, %rd14;
	add.u64 	%rd3, %SPL, 0;
	mov.u32 	%r34, %tid.x;
	mov.u32 	%r35, %ctaid.x;
	shr.u32 	%r36, %r34, 1;
	and.b32  	%r1, %r34, 1;
	shl.b32 	%r37, %r35, 7;
	or.b32  	%r2, %r36, %r37;
	cvt.u16.u32 	%rs1, %r2;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs3, 7;
	shr.u16 	%rs7, %rs2, 4;
	shl.b16 	%rs8, %rs5, 1;
	cvt.u32.u16 	%r38, %rs8;
	or.b32  	%r39, %r1, %r38;
	cvt.u64.u16 	%rd5, %rs7;
	cvt.u64.u16 	%rd6, %rs6;
	cvt.u64.u32 	%rd7, %r39;
	cvt.u32.u16 	%r40, %rs7;
	mul.wide.u32 	%rd22, %r40, 192;
	add.s64 	%rd23, %rd18, %rd22;
	cvt.u32.u16 	%r41, %rs6;
	mul.wide.u32 	%rd24, %r41, 24;
	add.s64 	%rd25, %rd23, %rd24;
	mul.wide.u32 	%rd26, %r39, 4;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.f32 	%f1, [%rd27];
	cvt.u32.u16 	%r42, %rs5;
	mul.wide.u32 	%rd28, %r42, 4;
	mul.wide.u32 	%rd29, %r40, 12;
	add.s64 	%rd30, %rd19, %rd29;
	add.s64 	%rd31, %rd30, %rd28;
	ld.global.nc.f32 	%f15, [%rd31];
	add.rn.f32 	%f16, %f15, %f15;
	add.rn.f32 	%f2, %f16, %f16;
	mul.rn.f32 	%f17, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r121, %f17;
	cvt.rn.f32.s32 	%f18, %r121;
	fma.rn.f32 	%f19, %f18, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f20, %f18, 0fB3A22168, %f19;
	fma.rn.f32 	%f58, %f18, 0fA7C234C5, %f20;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p1, %f4, 0f47CE4780;
	mov.f32 	%f56, 0f00000000;
	setp.neu.f32 	%p18, %f4, 0f7F800000;
	mov.u32 	%r117, %r121;
	mov.f32 	%f57, %f58;
	@%p1 bra 	$L__BB236_8;
	@%p18 bra 	$L__BB236_3;
	mul.rn.f32 	%f57, %f2, %f56;
	mov.b32 	%r117, 0;
	bra.uni 	$L__BB236_8;
$L__BB236_3:
	mov.b32 	%r4, %f2;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r44, %r5, 224;
	add.s32 	%r45, %r44, -128;
	shl.b32 	%r46, %r4, 8;
	or.b32  	%r50, %r46, -2147483648;
	shr.u32 	%r7, %r45, 5;
	mov.b32 	%r114, 0;
	mov.u64 	%rd62, 0;
	mov.u64 	%rd33, __cudart_i2opi_f;
$L__BB236_4:
	.pragma "nounroll";
	add.s64 	%rd34, %rd33, %rd62;
	ld.global.nc.u32 	%r49, [%rd34];
	// begin inline asm
	{
	mad.lo.cc.u32   %r47, %r49, %r50, %r114;
	madc.hi.u32     %r114, %r49, %r50,  0;
	}
	// end inline asm
	add.s64 	%rd35, %rd3, %rd62;
	st.local.u32 	[%rd35], %r47;
	add.s64 	%rd62, %rd62, 4;
	cvt.u32.u64 	%r52, %rd62;
	setp.ne.s32 	%p3, %r52, 24;
	@%p3 bra 	$L__BB236_4;
	st.local.u32 	[%rd3+24], %r114;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd36, %r7, 4;
	sub.s64 	%rd10, %rd3, %rd36;
	ld.local.u32 	%r115, [%rd10+24];
	ld.local.u32 	%r116, [%rd10+20];
	setp.eq.s32 	%p4, %r10, 0;
	@%p4 bra 	$L__BB236_7;
	shl.b32 	%r53, %r116, %r10;
	shl.b32 	%r54, %r115, %r10;
	mov.b32 	%r55, 32;
	sub.s32 	%r56, %r55, %r10;
	shr.u32 	%r57, %r116, %r56;
	add.s32 	%r115, %r57, %r54;
	ld.local.u32 	%r58, [%rd10+16];
	shr.u32 	%r59, %r58, %r56;
	add.s32 	%r116, %r59, %r53;
$L__BB236_7:
	shr.u32 	%r60, %r115, 30;
	shr.u32 	%r61, %r116, 30;
	shl.b32 	%r62, %r115, 2;
	or.b32  	%r63, %r62, %r61;
	shl.b32 	%r64, %r116, 2;
	bfe.u32 	%r65, %r115, 29, 1;
	add.s32 	%r66, %r65, %r60;
	neg.s32 	%r67, %r66;
	setp.lt.s32 	%p5, %r4, 0;
	selp.b32 	%r117, %r67, %r66, %p5;
	xor.b32  	%r68, %r63, %r4;
	bfe.s32 	%r69, %r115, 29, 1;
	xor.b32  	%r70, %r69, %r63;
	xor.b32  	%r71, %r69, %r64;
	cvt.u64.u32 	%rd37, %r70;
	shl.b64 	%rd38, %rd37, 32;
	cvt.u64.u32 	%rd39, %r71;
	or.b64  	%rd40, %rd38, %rd39;
	cvt.rn.f64.s64 	%fd1, %rd40;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f21, %fd2;
	neg.f32 	%f22, %f21;
	setp.lt.s32 	%p6, %r68, 0;
	selp.f32 	%f57, %f22, %f21, %p6;
$L__BB236_8:
	add.s32 	%r73, %r117, 1;
	mul.rn.f32 	%f24, %f57, %f57;
	and.b32  	%r74, %r117, 1;
	setp.eq.b32 	%p8, %r74, 1;
	selp.f32 	%f25, %f57, 0f3F800000, %p8;
	fma.rn.f32 	%f26, %f24, %f25, 0f00000000;
	fma.rn.f32 	%f27, %f24, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f28, 0fB94D4153, %f27, %p8;
	selp.f32 	%f29, 0f3C0885E4, 0f3D2AAABB, %p8;
	fma.rn.f32 	%f30, %f28, %f24, %f29;
	selp.f32 	%f31, 0fBE2AAAA8, 0fBEFFFFFF, %p8;
	fma.rn.f32 	%f32, %f30, %f24, %f31;
	fma.rn.f32 	%f33, %f32, %f26, %f25;
	and.b32  	%r75, %r73, 2;
	setp.eq.s32 	%p9, %r75, 0;
	sub.rn.f32 	%f35, %f56, %f33;
	selp.f32 	%f36, %f33, %f35, %p9;
	mul.rn.f32 	%f8, %f1, %f36;
	mul.lo.s64 	%rd41, %rd5, 192;
	add.s64 	%rd42, %rd2, %rd41;
	mul.lo.s64 	%rd43, %rd6, 24;
	add.s64 	%rd44, %rd42, %rd43;
	shl.b64 	%rd45, %rd7, 2;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.nc.f32 	%f9, [%rd46];
	@%p1 bra 	$L__BB236_16;
	@%p18 bra 	$L__BB236_11;
	mul.rn.f32 	%f58, %f2, %f56;
	mov.b32 	%r121, 0;
	bra.uni 	$L__BB236_16;
$L__BB236_11:
	mov.b32 	%r19, %f2;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r77, %r20, 224;
	add.s32 	%r78, %r77, -128;
	shl.b32 	%r79, %r19, 8;
	or.b32  	%r83, %r79, -2147483648;
	shr.u32 	%r22, %r78, 5;
	mov.b32 	%r118, 0;
	mov.u64 	%rd63, 0;
	mov.u64 	%rd48, __cudart_i2opi_f;
$L__BB236_12:
	.pragma "nounroll";
	add.s64 	%rd49, %rd48, %rd63;
	ld.global.nc.u32 	%r82, [%rd49];
	// begin inline asm
	{
	mad.lo.cc.u32   %r80, %r82, %r83, %r118;
	madc.hi.u32     %r118, %r82, %r83,  0;
	}
	// end inline asm
	add.s64 	%rd50, %rd3, %rd63;
	st.local.u32 	[%rd50], %r80;
	add.s64 	%rd63, %rd63, 4;
	cvt.u32.u64 	%r85, %rd63;
	setp.ne.s32 	%p11, %r85, 24;
	@%p11 bra 	$L__BB236_12;
	st.local.u32 	[%rd3+24], %r118;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd51, %r22, 4;
	sub.s64 	%rd13, %rd3, %rd51;
	ld.local.u32 	%r119, [%rd13+24];
	ld.local.u32 	%r120, [%rd13+20];
	setp.eq.s32 	%p12, %r25, 0;
	@%p12 bra 	$L__BB236_15;
	shl.b32 	%r86, %r120, %r25;
	shl.b32 	%r87, %r119, %r25;
	mov.b32 	%r88, 32;
	sub.s32 	%r89, %r88, %r25;
	shr.u32 	%r90, %r120, %r89;
	add.s32 	%r119, %r90, %r87;
	ld.local.u32 	%r91, [%rd13+16];
	shr.u32 	%r92, %r91, %r89;
	add.s32 	%r120, %r92, %r86;
$L__BB236_15:
	shr.u32 	%r93, %r119, 30;
	shr.u32 	%r94, %r120, 30;
	shl.b32 	%r95, %r119, 2;
	or.b32  	%r96, %r95, %r94;
	shl.b32 	%r97, %r120, 2;
	bfe.u32 	%r98, %r119, 29, 1;
	add.s32 	%r99, %r98, %r93;
	neg.s32 	%r100, %r99;
	setp.lt.s32 	%p13, %r19, 0;
	selp.b32 	%r121, %r100, %r99, %p13;
	xor.b32  	%r101, %r96, %r19;
	bfe.s32 	%r102, %r119, 29, 1;
	xor.b32  	%r103, %r102, %r96;
	xor.b32  	%r104, %r102, %r97;
	cvt.u64.u32 	%rd52, %r103;
	shl.b64 	%rd53, %rd52, 32;
	cvt.u64.u32 	%rd54, %r104;
	or.b64  	%rd55, %rd53, %rd54;
	cvt.rn.f64.s64 	%fd3, %rd55;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f37, %fd4;
	neg.f32 	%f38, %f37;
	setp.lt.s32 	%p14, %r101, 0;
	selp.f32 	%f58, %f38, %f37, %p14;
$L__BB236_16:
	mul.rn.f32 	%f40, %f58, %f58;
	and.b32  	%r106, %r121, 1;
	setp.eq.b32 	%p15, %r106, 1;
	selp.f32 	%f41, 0f3F800000, %f58, %p15;
	fma.rn.f32 	%f42, %f40, %f41, 0f00000000;
	fma.rn.f32 	%f43, %f40, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f44, %f43, 0fB94D4153, %p15;
	selp.f32 	%f45, 0f3D2AAABB, 0f3C0885E4, %p15;
	fma.rn.f32 	%f46, %f44, %f40, %f45;
	selp.f32 	%f47, 0fBEFFFFFF, 0fBE2AAAA8, %p15;
	fma.rn.f32 	%f48, %f46, %f40, %f47;
	fma.rn.f32 	%f49, %f48, %f42, %f41;
	and.b32  	%r107, %r121, 2;
	setp.eq.s32 	%p16, %r107, 0;
	sub.rn.f32 	%f51, %f56, %f49;
	selp.f32 	%f52, %f49, %f51, %p16;
	mul.rn.f32 	%f53, %f9, %f52;
	add.rn.f32 	%f54, %f8, %f53;
	add.rn.f32 	%f13, %f54, 0f00000000;
	shfl.sync.down.b32	%f14, %f13, 1, 31, -1;
	setp.ne.s32 	%p17, %r1, 0;
	@%p17 bra 	$L__BB236_18;
	ld.param.u64 	%rd15, [input_reduce_fusion_325_param_3];
	cvta.to.global.u64 	%rd1, %rd15;
	add.rn.f32 	%f55, %f13, %f14;
	mul.hi.u32 	%r108, %r2, 1431655766;
	mul.lo.s32 	%r109, %r108, 3;
	sub.s32 	%r110, %r2, %r109;
	and.b32  	%r111, %r108, 7;
	mul.hi.u32 	%r112, %r2, 715827883;
	shr.u32 	%r113, %r112, 2;
	mul.wide.u32 	%rd56, %r113, 96;
	add.s64 	%rd57, %rd1, %rd56;
	mul.wide.u32 	%rd58, %r110, 32;
	add.s64 	%rd59, %rd57, %rd58;
	mul.wide.u32 	%rd60, %r111, 4;
	add.s64 	%rd61, %rd59, %rd60;
	st.global.f32 	[%rd61], %f55;
$L__BB236_18:
	ret;

}
	// .globl	loop_reduce_fusion_48
.visible .entry loop_reduce_fusion_48(
	.param .u64 loop_reduce_fusion_48_param_0,
	.param .u64 loop_reduce_fusion_48_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<102>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd1, [loop_reduce_fusion_48_param_0];
	ld.param.u64 	%rd2, [loop_reduce_fusion_48_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs3, 3;
	shr.u16 	%rs7, %rs2, 4;
	and.b16  	%rs8, %rs7, 63;
	cvt.u32.u16 	%r5, %rs8;
	mul.wide.u32 	%rd5, %r5, 4800;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r6, %rs6;
	mul.wide.u32 	%rd7, %r6, 24;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r7, %rs5;
	mul.wide.u32 	%rd9, %r7, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	add.rn.f32 	%f2, %f1, 0f00000000;
	ld.global.nc.f32 	%f3, [%rd10+96];
	add.rn.f32 	%f4, %f2, %f3;
	ld.global.nc.f32 	%f5, [%rd10+192];
	add.rn.f32 	%f6, %f4, %f5;
	ld.global.nc.f32 	%f7, [%rd10+288];
	add.rn.f32 	%f8, %f6, %f7;
	ld.global.nc.f32 	%f9, [%rd10+384];
	add.rn.f32 	%f10, %f8, %f9;
	ld.global.nc.f32 	%f11, [%rd10+480];
	add.rn.f32 	%f12, %f10, %f11;
	ld.global.nc.f32 	%f13, [%rd10+576];
	add.rn.f32 	%f14, %f12, %f13;
	ld.global.nc.f32 	%f15, [%rd10+672];
	add.rn.f32 	%f16, %f14, %f15;
	ld.global.nc.f32 	%f17, [%rd10+768];
	add.rn.f32 	%f18, %f16, %f17;
	ld.global.nc.f32 	%f19, [%rd10+864];
	add.rn.f32 	%f20, %f18, %f19;
	ld.global.nc.f32 	%f21, [%rd10+960];
	add.rn.f32 	%f22, %f20, %f21;
	ld.global.nc.f32 	%f23, [%rd10+1056];
	add.rn.f32 	%f24, %f22, %f23;
	ld.global.nc.f32 	%f25, [%rd10+1152];
	add.rn.f32 	%f26, %f24, %f25;
	ld.global.nc.f32 	%f27, [%rd10+1248];
	add.rn.f32 	%f28, %f26, %f27;
	ld.global.nc.f32 	%f29, [%rd10+1344];
	add.rn.f32 	%f30, %f28, %f29;
	ld.global.nc.f32 	%f31, [%rd10+1440];
	add.rn.f32 	%f32, %f30, %f31;
	ld.global.nc.f32 	%f33, [%rd10+1536];
	add.rn.f32 	%f34, %f32, %f33;
	ld.global.nc.f32 	%f35, [%rd10+1632];
	add.rn.f32 	%f36, %f34, %f35;
	ld.global.nc.f32 	%f37, [%rd10+1728];
	add.rn.f32 	%f38, %f36, %f37;
	ld.global.nc.f32 	%f39, [%rd10+1824];
	add.rn.f32 	%f40, %f38, %f39;
	ld.global.nc.f32 	%f41, [%rd10+1920];
	add.rn.f32 	%f42, %f40, %f41;
	ld.global.nc.f32 	%f43, [%rd10+2016];
	add.rn.f32 	%f44, %f42, %f43;
	ld.global.nc.f32 	%f45, [%rd10+2112];
	add.rn.f32 	%f46, %f44, %f45;
	ld.global.nc.f32 	%f47, [%rd10+2208];
	add.rn.f32 	%f48, %f46, %f47;
	ld.global.nc.f32 	%f49, [%rd10+2304];
	add.rn.f32 	%f50, %f48, %f49;
	ld.global.nc.f32 	%f51, [%rd10+2400];
	add.rn.f32 	%f52, %f50, %f51;
	ld.global.nc.f32 	%f53, [%rd10+2496];
	add.rn.f32 	%f54, %f52, %f53;
	ld.global.nc.f32 	%f55, [%rd10+2592];
	add.rn.f32 	%f56, %f54, %f55;
	ld.global.nc.f32 	%f57, [%rd10+2688];
	add.rn.f32 	%f58, %f56, %f57;
	ld.global.nc.f32 	%f59, [%rd10+2784];
	add.rn.f32 	%f60, %f58, %f59;
	ld.global.nc.f32 	%f61, [%rd10+2880];
	add.rn.f32 	%f62, %f60, %f61;
	ld.global.nc.f32 	%f63, [%rd10+2976];
	add.rn.f32 	%f64, %f62, %f63;
	ld.global.nc.f32 	%f65, [%rd10+3072];
	add.rn.f32 	%f66, %f64, %f65;
	ld.global.nc.f32 	%f67, [%rd10+3168];
	add.rn.f32 	%f68, %f66, %f67;
	ld.global.nc.f32 	%f69, [%rd10+3264];
	add.rn.f32 	%f70, %f68, %f69;
	ld.global.nc.f32 	%f71, [%rd10+3360];
	add.rn.f32 	%f72, %f70, %f71;
	ld.global.nc.f32 	%f73, [%rd10+3456];
	add.rn.f32 	%f74, %f72, %f73;
	ld.global.nc.f32 	%f75, [%rd10+3552];
	add.rn.f32 	%f76, %f74, %f75;
	ld.global.nc.f32 	%f77, [%rd10+3648];
	add.rn.f32 	%f78, %f76, %f77;
	ld.global.nc.f32 	%f79, [%rd10+3744];
	add.rn.f32 	%f80, %f78, %f79;
	ld.global.nc.f32 	%f81, [%rd10+3840];
	add.rn.f32 	%f82, %f80, %f81;
	ld.global.nc.f32 	%f83, [%rd10+3936];
	add.rn.f32 	%f84, %f82, %f83;
	ld.global.nc.f32 	%f85, [%rd10+4032];
	add.rn.f32 	%f86, %f84, %f85;
	ld.global.nc.f32 	%f87, [%rd10+4128];
	add.rn.f32 	%f88, %f86, %f87;
	ld.global.nc.f32 	%f89, [%rd10+4224];
	add.rn.f32 	%f90, %f88, %f89;
	ld.global.nc.f32 	%f91, [%rd10+4320];
	add.rn.f32 	%f92, %f90, %f91;
	ld.global.nc.f32 	%f93, [%rd10+4416];
	add.rn.f32 	%f94, %f92, %f93;
	ld.global.nc.f32 	%f95, [%rd10+4512];
	add.rn.f32 	%f96, %f94, %f95;
	ld.global.nc.f32 	%f97, [%rd10+4608];
	add.rn.f32 	%f98, %f96, %f97;
	ld.global.nc.f32 	%f99, [%rd10+4704];
	add.rn.f32 	%f100, %f98, %f99;
	neg.f32 	%f101, %f100;
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd3, %rd11;
	st.global.f32 	[%rd12], %f101;
	ret;

}
	// .globl	input_reduce_fusion_326
.visible .entry input_reduce_fusion_326(
	.param .u64 input_reduce_fusion_326_param_0,
	.param .u64 input_reduce_fusion_326_param_1,
	.param .u64 input_reduce_fusion_326_param_2,
	.param .u64 input_reduce_fusion_326_param_3
)
.reqntid 256, 1, 1
{
	.local .align 4 .b8 	__local_depot238[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<19>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<122>;
	.reg .f32 	%f<159>;
	.reg .b64 	%rd<64>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot238;
	ld.param.u64 	%rd14, [input_reduce_fusion_326_param_0];
	ld.param.u64 	%rd16, [input_reduce_fusion_326_param_1];
	ld.param.u64 	%rd17, [input_reduce_fusion_326_param_2];
	cvta.to.global.u64 	%rd18, %rd17;
	cvta.to.global.u64 	%rd19, %rd16;
	cvta.to.global.u64 	%rd2, %rd14;
	add.u64 	%rd3, %SPL, 0;
	mov.u32 	%r34, %tid.x;
	mov.u32 	%r35, %ctaid.x;
	shr.u32 	%r36, %r34, 1;
	and.b32  	%r1, %r34, 1;
	shl.b32 	%r37, %r35, 7;
	or.b32  	%r2, %r36, %r37;
	cvt.u16.u32 	%rs1, %r2;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs3, 3;
	shr.u16 	%rs7, %rs2, 3;
	shl.b16 	%rs8, %rs5, 1;
	cvt.u32.u16 	%r38, %rs8;
	or.b32  	%r39, %r1, %r38;
	cvt.u64.u16 	%rd5, %rs7;
	cvt.u64.u16 	%rd6, %rs6;
	cvt.u64.u32 	%rd7, %r39;
	cvt.u32.u16 	%r40, %rs7;
	mul.wide.u32 	%rd22, %r40, 4800;
	add.s64 	%rd23, %rd18, %rd22;
	cvt.u32.u16 	%r41, %rs6;
	mul.wide.u32 	%rd24, %r41, 24;
	add.s64 	%rd25, %rd23, %rd24;
	mul.wide.u32 	%rd26, %r39, 4;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.f32 	%f15, [%rd27];
	add.rn.f32 	%f16, %f15, 0f00000000;
	ld.global.nc.f32 	%f17, [%rd27+96];
	add.rn.f32 	%f18, %f16, %f17;
	ld.global.nc.f32 	%f19, [%rd27+192];
	add.rn.f32 	%f20, %f18, %f19;
	ld.global.nc.f32 	%f21, [%rd27+288];
	add.rn.f32 	%f22, %f20, %f21;
	ld.global.nc.f32 	%f23, [%rd27+384];
	add.rn.f32 	%f24, %f22, %f23;
	ld.global.nc.f32 	%f25, [%rd27+480];
	add.rn.f32 	%f26, %f24, %f25;
	ld.global.nc.f32 	%f27, [%rd27+576];
	add.rn.f32 	%f28, %f26, %f27;
	ld.global.nc.f32 	%f29, [%rd27+672];
	add.rn.f32 	%f30, %f28, %f29;
	ld.global.nc.f32 	%f31, [%rd27+768];
	add.rn.f32 	%f32, %f30, %f31;
	ld.global.nc.f32 	%f33, [%rd27+864];
	add.rn.f32 	%f34, %f32, %f33;
	ld.global.nc.f32 	%f35, [%rd27+960];
	add.rn.f32 	%f36, %f34, %f35;
	ld.global.nc.f32 	%f37, [%rd27+1056];
	add.rn.f32 	%f38, %f36, %f37;
	ld.global.nc.f32 	%f39, [%rd27+1152];
	add.rn.f32 	%f40, %f38, %f39;
	ld.global.nc.f32 	%f41, [%rd27+1248];
	add.rn.f32 	%f42, %f40, %f41;
	ld.global.nc.f32 	%f43, [%rd27+1344];
	add.rn.f32 	%f44, %f42, %f43;
	ld.global.nc.f32 	%f45, [%rd27+1440];
	add.rn.f32 	%f46, %f44, %f45;
	ld.global.nc.f32 	%f47, [%rd27+1536];
	add.rn.f32 	%f48, %f46, %f47;
	ld.global.nc.f32 	%f49, [%rd27+1632];
	add.rn.f32 	%f50, %f48, %f49;
	ld.global.nc.f32 	%f51, [%rd27+1728];
	add.rn.f32 	%f52, %f50, %f51;
	ld.global.nc.f32 	%f53, [%rd27+1824];
	add.rn.f32 	%f54, %f52, %f53;
	ld.global.nc.f32 	%f55, [%rd27+1920];
	add.rn.f32 	%f56, %f54, %f55;
	ld.global.nc.f32 	%f57, [%rd27+2016];
	add.rn.f32 	%f58, %f56, %f57;
	ld.global.nc.f32 	%f59, [%rd27+2112];
	add.rn.f32 	%f60, %f58, %f59;
	ld.global.nc.f32 	%f61, [%rd27+2208];
	add.rn.f32 	%f62, %f60, %f61;
	ld.global.nc.f32 	%f63, [%rd27+2304];
	add.rn.f32 	%f64, %f62, %f63;
	ld.global.nc.f32 	%f65, [%rd27+2400];
	add.rn.f32 	%f66, %f64, %f65;
	ld.global.nc.f32 	%f67, [%rd27+2496];
	add.rn.f32 	%f68, %f66, %f67;
	ld.global.nc.f32 	%f69, [%rd27+2592];
	add.rn.f32 	%f70, %f68, %f69;
	ld.global.nc.f32 	%f71, [%rd27+2688];
	add.rn.f32 	%f72, %f70, %f71;
	ld.global.nc.f32 	%f73, [%rd27+2784];
	add.rn.f32 	%f74, %f72, %f73;
	ld.global.nc.f32 	%f75, [%rd27+2880];
	add.rn.f32 	%f76, %f74, %f75;
	ld.global.nc.f32 	%f77, [%rd27+2976];
	add.rn.f32 	%f78, %f76, %f77;
	ld.global.nc.f32 	%f79, [%rd27+3072];
	add.rn.f32 	%f80, %f78, %f79;
	ld.global.nc.f32 	%f81, [%rd27+3168];
	add.rn.f32 	%f82, %f80, %f81;
	ld.global.nc.f32 	%f83, [%rd27+3264];
	add.rn.f32 	%f84, %f82, %f83;
	ld.global.nc.f32 	%f85, [%rd27+3360];
	add.rn.f32 	%f86, %f84, %f85;
	ld.global.nc.f32 	%f87, [%rd27+3456];
	add.rn.f32 	%f88, %f86, %f87;
	ld.global.nc.f32 	%f89, [%rd27+3552];
	add.rn.f32 	%f90, %f88, %f89;
	ld.global.nc.f32 	%f91, [%rd27+3648];
	add.rn.f32 	%f92, %f90, %f91;
	ld.global.nc.f32 	%f93, [%rd27+3744];
	add.rn.f32 	%f94, %f92, %f93;
	ld.global.nc.f32 	%f95, [%rd27+3840];
	add.rn.f32 	%f96, %f94, %f95;
	ld.global.nc.f32 	%f97, [%rd27+3936];
	add.rn.f32 	%f98, %f96, %f97;
	ld.global.nc.f32 	%f99, [%rd27+4032];
	add.rn.f32 	%f100, %f98, %f99;
	ld.global.nc.f32 	%f101, [%rd27+4128];
	add.rn.f32 	%f102, %f100, %f101;
	ld.global.nc.f32 	%f103, [%rd27+4224];
	add.rn.f32 	%f104, %f102, %f103;
	ld.global.nc.f32 	%f105, [%rd27+4320];
	add.rn.f32 	%f106, %f104, %f105;
	ld.global.nc.f32 	%f107, [%rd27+4416];
	add.rn.f32 	%f108, %f106, %f107;
	ld.global.nc.f32 	%f109, [%rd27+4512];
	add.rn.f32 	%f110, %f108, %f109;
	ld.global.nc.f32 	%f111, [%rd27+4608];
	add.rn.f32 	%f112, %f110, %f111;
	ld.global.nc.f32 	%f113, [%rd27+4704];
	add.rn.f32 	%f1, %f112, %f113;
	cvt.u32.u16 	%r42, %rs5;
	mul.wide.u32 	%rd28, %r42, 4;
	mul.wide.u32 	%rd29, %r40, 12;
	add.s64 	%rd30, %rd19, %rd29;
	add.s64 	%rd31, %rd30, %rd28;
	ld.global.nc.f32 	%f114, [%rd31];
	add.rn.f32 	%f115, %f114, %f114;
	add.rn.f32 	%f116, %f115, %f115;
	add.rn.f32 	%f2, %f116, %f116;
	mul.rn.f32 	%f117, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r121, %f117;
	cvt.rn.f32.s32 	%f118, %r121;
	fma.rn.f32 	%f119, %f118, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f120, %f118, 0fB3A22168, %f119;
	fma.rn.f32 	%f158, %f118, 0fA7C234C5, %f120;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p1, %f4, 0f47CE4780;
	mov.f32 	%f156, 0f00000000;
	setp.neu.f32 	%p18, %f4, 0f7F800000;
	mov.u32 	%r117, %r121;
	mov.f32 	%f157, %f158;
	@%p1 bra 	$L__BB238_8;
	@%p18 bra 	$L__BB238_3;
	mul.rn.f32 	%f157, %f2, %f156;
	mov.b32 	%r117, 0;
	bra.uni 	$L__BB238_8;
$L__BB238_3:
	mov.b32 	%r4, %f2;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r44, %r5, 224;
	add.s32 	%r45, %r44, -128;
	shl.b32 	%r46, %r4, 8;
	or.b32  	%r50, %r46, -2147483648;
	shr.u32 	%r7, %r45, 5;
	mov.b32 	%r114, 0;
	mov.u64 	%rd62, 0;
	mov.u64 	%rd33, __cudart_i2opi_f;
$L__BB238_4:
	.pragma "nounroll";
	add.s64 	%rd34, %rd33, %rd62;
	ld.global.nc.u32 	%r49, [%rd34];
	// begin inline asm
	{
	mad.lo.cc.u32   %r47, %r49, %r50, %r114;
	madc.hi.u32     %r114, %r49, %r50,  0;
	}
	// end inline asm
	add.s64 	%rd35, %rd3, %rd62;
	st.local.u32 	[%rd35], %r47;
	add.s64 	%rd62, %rd62, 4;
	cvt.u32.u64 	%r52, %rd62;
	setp.ne.s32 	%p3, %r52, 24;
	@%p3 bra 	$L__BB238_4;
	st.local.u32 	[%rd3+24], %r114;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd36, %r7, 4;
	sub.s64 	%rd10, %rd3, %rd36;
	ld.local.u32 	%r115, [%rd10+24];
	ld.local.u32 	%r116, [%rd10+20];
	setp.eq.s32 	%p4, %r10, 0;
	@%p4 bra 	$L__BB238_7;
	shl.b32 	%r53, %r116, %r10;
	shl.b32 	%r54, %r115, %r10;
	mov.b32 	%r55, 32;
	sub.s32 	%r56, %r55, %r10;
	shr.u32 	%r57, %r116, %r56;
	add.s32 	%r115, %r57, %r54;
	ld.local.u32 	%r58, [%rd10+16];
	shr.u32 	%r59, %r58, %r56;
	add.s32 	%r116, %r59, %r53;
$L__BB238_7:
	shr.u32 	%r60, %r115, 30;
	shr.u32 	%r61, %r116, 30;
	shl.b32 	%r62, %r115, 2;
	or.b32  	%r63, %r62, %r61;
	shl.b32 	%r64, %r116, 2;
	bfe.u32 	%r65, %r115, 29, 1;
	add.s32 	%r66, %r65, %r60;
	neg.s32 	%r67, %r66;
	setp.lt.s32 	%p5, %r4, 0;
	selp.b32 	%r117, %r67, %r66, %p5;
	xor.b32  	%r68, %r63, %r4;
	bfe.s32 	%r69, %r115, 29, 1;
	xor.b32  	%r70, %r69, %r63;
	xor.b32  	%r71, %r69, %r64;
	cvt.u64.u32 	%rd37, %r70;
	shl.b64 	%rd38, %rd37, 32;
	cvt.u64.u32 	%rd39, %r71;
	or.b64  	%rd40, %rd38, %rd39;
	cvt.rn.f64.s64 	%fd1, %rd40;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f121, %fd2;
	neg.f32 	%f122, %f121;
	setp.lt.s32 	%p6, %r68, 0;
	selp.f32 	%f157, %f122, %f121, %p6;
$L__BB238_8:
	add.s32 	%r73, %r117, 1;
	mul.rn.f32 	%f124, %f157, %f157;
	and.b32  	%r74, %r117, 1;
	setp.eq.b32 	%p8, %r74, 1;
	selp.f32 	%f125, %f157, 0f3F800000, %p8;
	fma.rn.f32 	%f126, %f124, %f125, 0f00000000;
	fma.rn.f32 	%f127, %f124, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f128, 0fB94D4153, %f127, %p8;
	selp.f32 	%f129, 0f3C0885E4, 0f3D2AAABB, %p8;
	fma.rn.f32 	%f130, %f128, %f124, %f129;
	selp.f32 	%f131, 0fBE2AAAA8, 0fBEFFFFFF, %p8;
	fma.rn.f32 	%f132, %f130, %f124, %f131;
	fma.rn.f32 	%f133, %f132, %f126, %f125;
	and.b32  	%r75, %r73, 2;
	setp.eq.s32 	%p9, %r75, 0;
	sub.rn.f32 	%f135, %f156, %f133;
	selp.f32 	%f136, %f133, %f135, %p9;
	mul.rn.f32 	%f8, %f1, %f136;
	mul.lo.s64 	%rd41, %rd5, 96;
	add.s64 	%rd42, %rd2, %rd41;
	mul.lo.s64 	%rd43, %rd6, 24;
	add.s64 	%rd44, %rd42, %rd43;
	shl.b64 	%rd45, %rd7, 2;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.nc.f32 	%f9, [%rd46];
	@%p1 bra 	$L__BB238_16;
	@%p18 bra 	$L__BB238_11;
	mul.rn.f32 	%f158, %f2, %f156;
	mov.b32 	%r121, 0;
	bra.uni 	$L__BB238_16;
$L__BB238_11:
	mov.b32 	%r19, %f2;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r77, %r20, 224;
	add.s32 	%r78, %r77, -128;
	shl.b32 	%r79, %r19, 8;
	or.b32  	%r83, %r79, -2147483648;
	shr.u32 	%r22, %r78, 5;
	mov.b32 	%r118, 0;
	mov.u64 	%rd63, 0;
	mov.u64 	%rd48, __cudart_i2opi_f;
$L__BB238_12:
	.pragma "nounroll";
	add.s64 	%rd49, %rd48, %rd63;
	ld.global.nc.u32 	%r82, [%rd49];
	// begin inline asm
	{
	mad.lo.cc.u32   %r80, %r82, %r83, %r118;
	madc.hi.u32     %r118, %r82, %r83,  0;
	}
	// end inline asm
	add.s64 	%rd50, %rd3, %rd63;
	st.local.u32 	[%rd50], %r80;
	add.s64 	%rd63, %rd63, 4;
	cvt.u32.u64 	%r85, %rd63;
	setp.ne.s32 	%p11, %r85, 24;
	@%p11 bra 	$L__BB238_12;
	st.local.u32 	[%rd3+24], %r118;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd51, %r22, 4;
	sub.s64 	%rd13, %rd3, %rd51;
	ld.local.u32 	%r119, [%rd13+24];
	ld.local.u32 	%r120, [%rd13+20];
	setp.eq.s32 	%p12, %r25, 0;
	@%p12 bra 	$L__BB238_15;
	shl.b32 	%r86, %r120, %r25;
	shl.b32 	%r87, %r119, %r25;
	mov.b32 	%r88, 32;
	sub.s32 	%r89, %r88, %r25;
	shr.u32 	%r90, %r120, %r89;
	add.s32 	%r119, %r90, %r87;
	ld.local.u32 	%r91, [%rd13+16];
	shr.u32 	%r92, %r91, %r89;
	add.s32 	%r120, %r92, %r86;
$L__BB238_15:
	shr.u32 	%r93, %r119, 30;
	shr.u32 	%r94, %r120, 30;
	shl.b32 	%r95, %r119, 2;
	or.b32  	%r96, %r95, %r94;
	shl.b32 	%r97, %r120, 2;
	bfe.u32 	%r98, %r119, 29, 1;
	add.s32 	%r99, %r98, %r93;
	neg.s32 	%r100, %r99;
	setp.lt.s32 	%p13, %r19, 0;
	selp.b32 	%r121, %r100, %r99, %p13;
	xor.b32  	%r101, %r96, %r19;
	bfe.s32 	%r102, %r119, 29, 1;
	xor.b32  	%r103, %r102, %r96;
	xor.b32  	%r104, %r102, %r97;
	cvt.u64.u32 	%rd52, %r103;
	shl.b64 	%rd53, %rd52, 32;
	cvt.u64.u32 	%rd54, %r104;
	or.b64  	%rd55, %rd53, %rd54;
	cvt.rn.f64.s64 	%fd3, %rd55;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f137, %fd4;
	neg.f32 	%f138, %f137;
	setp.lt.s32 	%p14, %r101, 0;
	selp.f32 	%f158, %f138, %f137, %p14;
$L__BB238_16:
	mul.rn.f32 	%f140, %f158, %f158;
	and.b32  	%r106, %r121, 1;
	setp.eq.b32 	%p15, %r106, 1;
	selp.f32 	%f141, 0f3F800000, %f158, %p15;
	fma.rn.f32 	%f142, %f140, %f141, 0f00000000;
	fma.rn.f32 	%f143, %f140, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f144, %f143, 0fB94D4153, %p15;
	selp.f32 	%f145, 0f3D2AAABB, 0f3C0885E4, %p15;
	fma.rn.f32 	%f146, %f144, %f140, %f145;
	selp.f32 	%f147, 0fBEFFFFFF, 0fBE2AAAA8, %p15;
	fma.rn.f32 	%f148, %f146, %f140, %f147;
	fma.rn.f32 	%f149, %f148, %f142, %f141;
	and.b32  	%r107, %r121, 2;
	setp.eq.s32 	%p16, %r107, 0;
	sub.rn.f32 	%f151, %f156, %f149;
	selp.f32 	%f152, %f149, %f151, %p16;
	mul.rn.f32 	%f153, %f9, %f152;
	add.rn.f32 	%f154, %f8, %f153;
	add.rn.f32 	%f13, %f154, 0f00000000;
	shfl.sync.down.b32	%f14, %f13, 1, 31, -1;
	setp.ne.s32 	%p17, %r1, 0;
	@%p17 bra 	$L__BB238_18;
	ld.param.u64 	%rd15, [input_reduce_fusion_326_param_3];
	cvta.to.global.u64 	%rd1, %rd15;
	add.rn.f32 	%f155, %f13, %f14;
	mul.hi.u32 	%r108, %r2, 1431655766;
	mul.lo.s32 	%r109, %r108, 3;
	sub.s32 	%r110, %r2, %r109;
	and.b32  	%r111, %r108, 3;
	mul.hi.u32 	%r112, %r2, 715827883;
	shr.u32 	%r113, %r112, 1;
	mul.wide.u32 	%rd56, %r113, 48;
	add.s64 	%rd57, %rd1, %rd56;
	mul.wide.u32 	%rd58, %r110, 16;
	add.s64 	%rd59, %rd57, %rd58;
	mul.wide.u32 	%rd60, %r111, 4;
	add.s64 	%rd61, %rd59, %rd60;
	st.global.f32 	[%rd61], %f155;
$L__BB238_18:
	ret;

}
	// .globl	loop_add_fusion_375
.visible .entry loop_add_fusion_375(
	.param .u64 loop_add_fusion_375_param_0,
	.param .u64 loop_add_fusion_375_param_1,
	.param .u64 loop_add_fusion_375_param_2,
	.param .u64 loop_add_fusion_375_param_3,
	.param .u64 loop_add_fusion_375_param_4,
	.param .u64 loop_add_fusion_375_param_5,
	.param .u64 loop_add_fusion_375_param_6
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<25>;
	.reg .b16 	%rs<23>;
	.reg .b32 	%r<35>;
	.reg .f32 	%f<41>;
	.reg .b64 	%rd<87>;

	ld.param.u64 	%rd26, [loop_add_fusion_375_param_5];
	cvta.to.global.u64 	%rd2, %rd26;
	ld.param.u64 	%rd27, [loop_add_fusion_375_param_2];
	ld.param.u64 	%rd28, [loop_add_fusion_375_param_4];
	cvta.to.global.u64 	%rd3, %rd28;
	ld.param.u64 	%rd29, [loop_add_fusion_375_param_3];
	cvta.to.global.u64 	%rd4, %rd29;
	cvta.to.global.u64 	%rd5, %rd27;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r8, %r7, 7;
	or.b32  	%r2, %r8, %r1;
	and.b32  	%r3, %r1, 15;
	shr.u32 	%r9, %r2, 4;
	cvt.u16.u32 	%rs5, %r9;
	and.b16  	%rs6, %rs5, 255;
	mul.lo.s16 	%rs7, %rs6, 171;
	shr.u16 	%rs8, %rs7, 9;
	mul.lo.s16 	%rs9, %rs8, 3;
	sub.s16 	%rs1, %rs5, %rs9;
	cvt.u16.u32 	%rs10, %r2;
	mul.hi.u16 	%rs11, %rs10, -21845;
	shr.u16 	%rs2, %rs11, 5;
	and.b32  	%r4, %r1, 1;
	setp.eq.s32 	%p1, %r4, 0;
	mov.f32 	%f34, 0f00000000;
	cvt.u64.u16 	%rd84, %rs1;
	cvt.u32.u16 	%r33, %rs2;
	cvt.u32.u16 	%r34, %rs1;
	setp.gt.u32 	%p24, %r3, 1;
	@%p1 bra 	$L__BB239_5;
	bra.uni 	$L__BB239_1;
$L__BB239_5:
	bfe.u32 	%r5, %r1, 1, 3;
	mul.wide.u32 	%rd31, %r33, 96;
	add.s64 	%rd32, %rd4, %rd31;
	and.b32  	%r12, %r34, 255;
	mul.wide.u32 	%rd33, %r12, 32;
	add.s64 	%rd34, %rd32, %rd33;
	mul.wide.u32 	%rd35, %r5, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.nc.f32 	%f4, [%rd36];
	add.s32 	%r13, %r5, -1;
	and.b32  	%r14, %r13, 1;
	setp.eq.b32 	%p3, %r14, 1;
	not.pred 	%p4, %p3;
	and.pred  	%p5, %p24, %p4;
	mov.f32 	%f38, 0f00000000;
	mov.f32 	%f37, %f38;
	@%p5 bra 	$L__BB239_8;
	bra.uni 	$L__BB239_6;
$L__BB239_8:
	shr.u32 	%r15, %r13, 1;
	mul.wide.u32 	%rd37, %r33, 48;
	add.s64 	%rd38, %rd3, %rd37;
	mul.wide.u32 	%rd39, %r12, 16;
	add.s64 	%rd40, %rd38, %rd39;
	mul.wide.u32 	%rd41, %r15, 4;
	add.s64 	%rd15, %rd40, %rd41;
	add.s64 	%rd42, %rd2, %rd37;
	add.s64 	%rd43, %rd42, %rd39;
	add.s64 	%rd16, %rd43, %rd41;
	ld.global.nc.f32 	%f21, [%rd15];
	ld.global.nc.f32 	%f22, [%rd16];
	add.rn.f32 	%f37, %f21, %f22;
$L__BB239_6:
	add.rn.f32 	%f6, %f4, %f37;
	setp.gt.u32 	%p6, %r3, 3;
	and.b32  	%r16, %r1, 2;
	setp.eq.s32 	%p7, %r16, 0;
	and.pred  	%p8, %p6, %p7;
	@%p8 bra 	$L__BB239_9;
	bra.uni 	$L__BB239_7;
$L__BB239_9:
	cvt.u64.u16 	%rd13, %rs2;
	and.b64  	%rd14, %rd84, 255;
	cvt.u16.u32 	%rs12, %r5;
	add.s16 	%rs13, %rs12, -2;
	shr.s16 	%rs14, %rs13, 1;
	mul.lo.s64 	%rd44, %rd13, 36;
	add.s64 	%rd45, %rd5, %rd44;
	mul.lo.s64 	%rd46, %rd14, 12;
	add.s64 	%rd47, %rd45, %rd46;
	cvt.s32.s16 	%r17, %rs14;
	mul.wide.s32 	%rd48, %r17, 4;
	add.s64 	%rd17, %rd47, %rd48;
	ld.global.nc.f32 	%f38, [%rd17];
$L__BB239_7:
	add.rn.f32 	%f34, %f6, %f38;
$L__BB239_1:
	ld.param.u64 	%rd24, [loop_add_fusion_375_param_6];
	add.s32 	%r18, %r3, -1;
	and.b32  	%r19, %r18, 1;
	setp.eq.b32 	%p9, %r19, 1;
	mov.pred 	%p10, 0;
	xor.pred  	%p11, %p9, %p10;
	not.pred 	%p12, %p11;
	@%p12 bra 	$L__BB239_10;
	bra.uni 	$L__BB239_2;
$L__BB239_10:
	ld.param.u64 	%rd25, [loop_add_fusion_375_param_1];
	cvt.u16.u32 	%rs15, %r18;
	and.b16  	%rs16, %rs15, 128;
	shr.u16 	%rs17, %rs16, 7;
	add.s16 	%rs18, %rs15, %rs17;
	shr.s16 	%rs3, %rs18, 1;
	cvt.u32.u16 	%r20, %rs3;
	and.b32  	%r6, %r20, 255;
	mul.wide.u32 	%rd51, %r33, 96;
	add.s64 	%rd52, %rd4, %rd51;
	and.b32  	%r23, %r34, 255;
	mul.wide.u32 	%rd53, %r23, 32;
	add.s64 	%rd54, %rd52, %rd53;
	mul.wide.u32 	%rd55, %r6, 4;
	add.s64 	%rd56, %rd54, %rd55;
	ld.global.nc.f32 	%f11, [%rd56];
	add.s32 	%r26, %r6, -1;
	setp.gt.u32 	%p13, %r3, 2;
	and.b32  	%r27, %r26, 1;
	setp.eq.b32 	%p14, %r27, 1;
	not.pred 	%p15, %p14;
	and.pred  	%p16, %p13, %p15;
	mov.f32 	%f40, 0f00000000;
	mov.f32 	%f39, %f40;
	@%p16 bra 	$L__BB239_13;
	bra.uni 	$L__BB239_11;
$L__BB239_13:
	shr.u32 	%r28, %r26, 1;
	mul.wide.u32 	%rd57, %r33, 48;
	add.s64 	%rd58, %rd3, %rd57;
	mul.wide.u32 	%rd59, %r23, 16;
	add.s64 	%rd60, %rd58, %rd59;
	mul.wide.u32 	%rd61, %r28, 4;
	add.s64 	%rd21, %rd60, %rd61;
	add.s64 	%rd62, %rd2, %rd57;
	add.s64 	%rd63, %rd62, %rd59;
	add.s64 	%rd22, %rd63, %rd61;
	ld.global.nc.f32 	%f26, [%rd21];
	ld.global.nc.f32 	%f27, [%rd22];
	add.rn.f32 	%f39, %f26, %f27;
$L__BB239_11:
	cvta.to.global.u64 	%rd6, %rd25;
	cvt.u64.u16 	%rd85, %rs2;
	and.b64  	%rd86, %rd84, 255;
	cvt.s64.s16 	%rd20, %rs3;
	add.rn.f32 	%f13, %f11, %f39;
	setp.gt.u32 	%p17, %r3, 4;
	and.b32  	%r29, %r6, 1;
	setp.eq.b32 	%p18, %r29, 1;
	not.pred 	%p19, %p18;
	and.pred  	%p20, %p17, %p19;
	@%p20 bra 	$L__BB239_14;
	bra.uni 	$L__BB239_12;
$L__BB239_14:
	add.s16 	%rs4, %rs3, -2;
	and.b16  	%rs19, %rs4, 128;
	shr.u16 	%rs20, %rs19, 7;
	add.s16 	%rs21, %rs4, %rs20;
	shr.s16 	%rs22, %rs21, 1;
	mul.lo.s64 	%rd64, %rd85, 36;
	add.s64 	%rd65, %rd5, %rd64;
	mul.lo.s64 	%rd66, %rd86, 12;
	add.s64 	%rd67, %rd65, %rd66;
	cvt.s32.s16 	%r30, %rs22;
	mul.wide.s32 	%rd68, %r30, 4;
	add.s64 	%rd69, %rd67, %rd68;
	ld.global.nc.f32 	%f40, [%rd69];
$L__BB239_12:
	add.rn.f32 	%f29, %f13, %f40;
	mul.lo.s64 	%rd70, %rd85, 96;
	add.s64 	%rd71, %rd6, %rd70;
	shl.b64 	%rd72, %rd86, 5;
	add.s64 	%rd73, %rd71, %rd72;
	shl.b64 	%rd74, %rd20, 2;
	add.s64 	%rd75, %rd73, %rd74;
	ld.global.nc.f32 	%f30, [%rd75];
	add.rn.f32 	%f35, %f29, %f30;
	bra.uni 	$L__BB239_3;
$L__BB239_2:
	cvt.u64.u16 	%rd85, %rs2;
	and.b64  	%rd86, %rd84, 255;
	mov.f32 	%f35, 0f00000000;
$L__BB239_3:
	cvta.to.global.u64 	%rd1, %rd24;
	and.pred  	%p23, %p24, %p1;
	mov.f32 	%f36, 0f00000000;
	@%p23 bra 	$L__BB239_15;
	bra.uni 	$L__BB239_4;
$L__BB239_15:
	ld.param.u64 	%rd23, [loop_add_fusion_375_param_0];
	cvta.to.global.u64 	%rd7, %rd23;
	add.s32 	%r31, %r3, 254;
	bfe.u32 	%r32, %r31, 1, 7;
	mul.lo.s64 	%rd76, %rd85, 84;
	add.s64 	%rd77, %rd7, %rd76;
	mul.lo.s64 	%rd78, %rd86, 28;
	add.s64 	%rd79, %rd77, %rd78;
	mul.wide.u32 	%rd80, %r32, 4;
	add.s64 	%rd12, %rd79, %rd80;
	ld.global.nc.f32 	%f36, [%rd12];
$L__BB239_4:
	add.rn.f32 	%f32, %f34, %f35;
	add.rn.f32 	%f33, %f32, %f36;
	mul.wide.u32 	%rd81, %r2, 4;
	add.s64 	%rd82, %rd1, %rd81;
	st.global.f32 	[%rd82], %f33;
	ret;

}
	// .globl	input_reduce_fusion_327
.visible .entry input_reduce_fusion_327(
	.param .u64 input_reduce_fusion_327_param_0,
	.param .u64 input_reduce_fusion_327_param_1,
	.param .u64 input_reduce_fusion_327_param_2,
	.param .u64 input_reduce_fusion_327_param_3,
	.param .u64 input_reduce_fusion_327_param_4,
	.param .u64 input_reduce_fusion_327_param_5,
	.param .u64 input_reduce_fusion_327_param_6
)
.reqntid 1024, 1, 1
{
	.local .align 4 .b8 	__local_depot240[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<24>;
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<138>;
	.reg .f32 	%f<120>;
	.reg .b64 	%rd<118>;
	.reg .f64 	%fd<5>;
	// demoted variable
	.shared .align 4 .b8 shared_cache36[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache37[4224];
	mov.u64 	%SPL, __local_depot240;
	ld.param.u64 	%rd24, [input_reduce_fusion_327_param_0];
	ld.param.u64 	%rd25, [input_reduce_fusion_327_param_6];
	cvta.to.global.u64 	%rd1, %rd25;
	ld.param.u64 	%rd26, [input_reduce_fusion_327_param_1];
	ld.param.u64 	%rd27, [input_reduce_fusion_327_param_5];
	cvta.to.global.u64 	%rd2, %rd27;
	ld.param.u64 	%rd28, [input_reduce_fusion_327_param_2];
	ld.param.u64 	%rd29, [input_reduce_fusion_327_param_4];
	cvta.to.global.u64 	%rd30, %rd29;
	ld.param.u64 	%rd31, [input_reduce_fusion_327_param_3];
	cvta.to.global.u64 	%rd32, %rd31;
	cvta.to.global.u64 	%rd3, %rd28;
	cvta.to.global.u64 	%rd4, %rd26;
	cvta.to.global.u64 	%rd5, %rd24;
	add.u64 	%rd6, %SPL, 0;
	mov.u32 	%r38, %tid.x;
	mov.u32 	%r39, %ctaid.x;
	shr.u32 	%r1, %r38, 5;
	and.b32  	%r2, %r38, 31;
	cvt.u16.u32 	%rs1, %r39;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 9;
	mul.lo.s16 	%rs5, %rs4, 3;
	sub.s16 	%rs6, %rs1, %rs5;
	and.b16  	%rs7, %rs6, 255;
	setp.eq.s16 	%p2, %rs7, 2;
	selp.b32 	%r3, 26, 32, %p2;
	shl.b16 	%rs8, %rs6, 5;
	cvt.u32.u16 	%r40, %rs8;
	and.b32  	%r4, %r40, 224;
	or.b32  	%r41, %r2, %r4;
	cvt.u16.u32 	%rs9, %r41;
	mul.lo.s16 	%rs10, %rs9, 43;
	shr.u16 	%rs11, %rs10, 8;
	mul.lo.s16 	%rs12, %rs11, 6;
	sub.s16 	%rs13, %rs9, %rs12;
	cvt.u32.u16 	%r42, %rs13;
	cvt.u64.u16 	%rd8, %rs4;
	cvt.u64.u16 	%rd35, %rs13;
	and.b64  	%rd9, %rd35, 255;
	bfe.u32 	%r43, %r42, 1, 7;
	cvt.u64.u32 	%rd10, %r43;
	mul.wide.u32 	%rd36, %r43, 4;
	cvt.u32.u16 	%r44, %rs4;
	mul.wide.u32 	%rd37, %r44, 12;
	add.s64 	%rd38, %rd32, %rd37;
	add.s64 	%rd11, %rd38, %rd36;
	cvt.u64.u16 	%rd12, %rs11;
	and.b32  	%r45, %r42, 1;
	cvt.u64.u32 	%rd13, %r45;
	mul.wide.u32 	%rd39, %r44, 4;
	add.s64 	%rd14, %rd30, %rd39;
	mov.f32 	%f114, 0f00000000;
	setp.lt.u32 	%p3, %r2, %r3;
	shl.b64 	%rd80, %rd10, 3;
	shl.b64 	%rd82, %rd13, 2;
	mov.u32 	%r129, %r1;
	mov.f32 	%f115, %f114;
	bra.uni 	$L__BB240_1;
$L__BB240_16:
	mul.rn.f32 	%f119, %f8, %f39;
	mov.b32 	%r137, 0;
$L__BB240_22:
	mul.rn.f32 	%f46, %f119, %f119;
	and.b32  	%r109, %r137, 1;
	setp.eq.b32 	%p18, %r109, 1;
	selp.f32 	%f47, 0f3F800000, %f119, %p18;
	fma.rn.f32 	%f48, %f46, %f47, 0f00000000;
	fma.rn.f32 	%f49, %f46, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f50, %f49, 0fB94D4153, %p18;
	selp.f32 	%f51, 0f3D2AAABB, 0f3C0885E4, %p18;
	fma.rn.f32 	%f52, %f50, %f46, %f51;
	selp.f32 	%f53, 0fBEFFFFFF, 0fBE2AAAA8, %p18;
	fma.rn.f32 	%f54, %f52, %f46, %f53;
	fma.rn.f32 	%f55, %f54, %f48, %f47;
	and.b32  	%r110, %r137, 2;
	setp.eq.s32 	%p19, %r110, 0;
	sub.rn.f32 	%f57, %f39, %f55;
	selp.f32 	%f58, %f55, %f57, %p19;
	mul.lo.s64 	%rd74, %rd8, 18000;
	add.s64 	%rd75, %rd4, %rd74;
	mul.lo.s64 	%rd76, %rd17, 360;
	add.s64 	%rd77, %rd75, %rd76;
	add.s64 	%rd79, %rd77, %rd44;
	add.s64 	%rd81, %rd79, %rd80;
	add.s64 	%rd83, %rd81, %rd82;
	ld.global.nc.f32 	%f59, [%rd83];
	mul.rn.f32 	%f60, %f59, %f58;
	add.rn.f32 	%f61, %f14, %f60;
	mul.rn.f32 	%f62, %f7, %f61;
	add.rn.f32 	%f115, %f115, %f62;
	ld.global.nc.f32 	%f63, [%rd14];
	fma.rn.f32 	%f64, %f63, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f65, %f64;
	mov.f32 	%f66, 0f4B400001;
	mov.f32 	%f67, 0f437C0000;
	fma.rm.f32 	%f68, %f65, %f67, %f66;
	add.rn.f32 	%f69, %f68, 0fCB40007F;
	neg.f32 	%f70, %f69;
	fma.rn.f32 	%f71, %f63, 0f3FB8AA3B, %f70;
	fma.rn.f32 	%f72, %f63, 0f32A57060, %f71;
	mov.b32 	%r111, %f68;
	shl.b32 	%r112, %r111, 23;
	mov.b32 	%f73, %r112;
	ex2.approx.ftz.f32 	%f74, %f72;
	mul.rn.f32 	%f75, %f74, %f73;
	neg.f32 	%f76, %f75;
	sub.rn.f32 	%f77, %f76, %f75;
	add.rn.f32 	%f78, %f77, %f77;
	add.rn.f32 	%f79, %f78, %f78;
	add.rn.f32 	%f80, %f79, %f79;
	add.rn.f32 	%f81, %f80, %f80;
	fma.rn.f32 	%f82, %f81, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f83, %f82;
	fma.rm.f32 	%f84, %f83, %f67, %f66;
	add.rn.f32 	%f85, %f84, 0fCB40007F;
	neg.f32 	%f86, %f85;
	fma.rn.f32 	%f87, %f81, 0f3FB8AA3B, %f86;
	fma.rn.f32 	%f88, %f81, 0f32A57060, %f87;
	mov.b32 	%r113, %f84;
	shl.b32 	%r114, %r113, 23;
	mov.b32 	%f89, %r114;
	ex2.approx.ftz.f32 	%f90, %f88;
	mul.rn.f32 	%f91, %f90, %f89;
	mul.rn.f32 	%f92, %f7, %f91;
	mul.rn.f32 	%f93, %f59, %f92;
	add.rn.f32 	%f114, %f114, %f93;
$L__BB240_2:
	add.s32 	%r6, %r129, 32;
	setp.lt.u32 	%p20, %r129, 18;
	mov.u32 	%r129, %r6;
	@%p20 bra 	$L__BB240_1;
	bra.uni 	$L__BB240_3;
$L__BB240_1:
	@%p3 bra 	$L__BB240_6;
	bra.uni 	$L__BB240_2;
$L__BB240_6:
	mul.lo.s64 	%rd40, %rd8, 19200;
	add.s64 	%rd41, %rd5, %rd40;
	mul.wide.u32 	%rd42, %r129, 384;
	add.s64 	%rd43, %rd41, %rd42;
	mul.lo.s64 	%rd44, %rd12, 24;
	add.s64 	%rd45, %rd43, %rd44;
	shl.b64 	%rd46, %rd9, 2;
	add.s64 	%rd47, %rd45, %rd46;
	ld.global.nc.f32 	%f7, [%rd47+24];
	ld.global.nc.f32 	%f21, [%rd11];
	add.rn.f32 	%f8, %f21, %f21;
	mul.rn.f32 	%f22, %f8, 0f3F22F983;
	cvt.rni.s32.f32 	%r137, %f22;
	cvt.rn.f32.s32 	%f23, %r137;
	fma.rn.f32 	%f24, %f23, 0fBFC90FDA, %f8;
	fma.rn.f32 	%f25, %f23, 0fB3A22168, %f24;
	fma.rn.f32 	%f119, %f23, 0fA7C234C5, %f25;
	abs.f32 	%f10, %f8;
	setp.ltu.f32 	%p4, %f10, 0f47CE4780;
	setp.neu.f32 	%p23, %f10, 0f7F800000;
	mov.u64 	%rd115, __cudart_i2opi_f;
	mov.u32 	%r133, %r137;
	mov.f32 	%f118, %f119;
	@%p4 bra 	$L__BB240_14;
	@%p23 bra 	$L__BB240_9;
	mov.f32 	%f28, 0f00000000;
	mul.rn.f32 	%f118, %f8, %f28;
	mov.b32 	%r133, 0;
	bra.uni 	$L__BB240_14;
$L__BB240_9:
	mov.b32 	%r130, 0;
	mov.b32 	%r8, %f8;
	shr.u32 	%r9, %r8, 23;
	and.b32  	%r47, %r9, 224;
	add.s32 	%r48, %r47, -128;
	shl.b32 	%r49, %r8, 8;
	or.b32  	%r53, %r49, -2147483648;
	shr.u32 	%r11, %r48, 5;
	mov.u64 	%rd116, 0;
$L__BB240_10:
	.pragma "nounroll";
	add.s64 	%rd50, %rd115, %rd116;
	ld.global.nc.u32 	%r52, [%rd50];
	// begin inline asm
	{
	mad.lo.cc.u32   %r50, %r52, %r53, %r130;
	madc.hi.u32     %r130, %r52, %r53,  0;
	}
	// end inline asm
	add.s64 	%rd51, %rd6, %rd116;
	st.local.u32 	[%rd51], %r50;
	add.s64 	%rd116, %rd116, 4;
	cvt.u32.u64 	%r55, %rd116;
	setp.ne.s32 	%p6, %r55, 24;
	@%p6 bra 	$L__BB240_10;
	st.local.u32 	[%rd6+24], %r130;
	and.b32  	%r14, %r9, 31;
	mul.wide.u32 	%rd52, %r11, 4;
	sub.s64 	%rd20, %rd6, %rd52;
	ld.local.u32 	%r131, [%rd20+24];
	ld.local.u32 	%r132, [%rd20+20];
	setp.eq.s32 	%p7, %r14, 0;
	@%p7 bra 	$L__BB240_13;
	shl.b32 	%r56, %r132, %r14;
	shl.b32 	%r57, %r131, %r14;
	mov.b32 	%r58, 32;
	sub.s32 	%r59, %r58, %r14;
	shr.u32 	%r60, %r132, %r59;
	add.s32 	%r131, %r60, %r57;
	ld.local.u32 	%r61, [%rd20+16];
	shr.u32 	%r62, %r61, %r59;
	add.s32 	%r132, %r62, %r56;
$L__BB240_13:
	shr.u32 	%r63, %r131, 30;
	shr.u32 	%r64, %r132, 30;
	shl.b32 	%r65, %r131, 2;
	or.b32  	%r66, %r65, %r64;
	shl.b32 	%r67, %r132, 2;
	bfe.u32 	%r68, %r131, 29, 1;
	add.s32 	%r69, %r68, %r63;
	neg.s32 	%r70, %r69;
	setp.lt.s32 	%p8, %r8, 0;
	selp.b32 	%r133, %r70, %r69, %p8;
	xor.b32  	%r71, %r66, %r8;
	bfe.s32 	%r72, %r131, 29, 1;
	xor.b32  	%r73, %r72, %r66;
	xor.b32  	%r74, %r72, %r67;
	cvt.u64.u32 	%rd53, %r73;
	shl.b64 	%rd54, %rd53, 32;
	cvt.u64.u32 	%rd55, %r74;
	or.b64  	%rd56, %rd54, %rd55;
	cvt.rn.f64.s64 	%fd1, %rd56;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f26, %fd2;
	neg.f32 	%f27, %f26;
	setp.lt.s32 	%p9, %r71, 0;
	selp.f32 	%f118, %f27, %f26, %p9;
$L__BB240_14:
	cvt.u64.u32 	%rd17, %r129;
	add.s32 	%r76, %r133, 1;
	mul.rn.f32 	%f29, %f118, %f118;
	and.b32  	%r77, %r133, 1;
	setp.eq.b32 	%p11, %r77, 1;
	selp.f32 	%f30, %f118, 0f3F800000, %p11;
	fma.rn.f32 	%f31, %f29, %f30, 0f00000000;
	fma.rn.f32 	%f32, %f29, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f33, 0fB94D4153, %f32, %p11;
	selp.f32 	%f34, 0f3C0885E4, 0f3D2AAABB, %p11;
	fma.rn.f32 	%f35, %f33, %f29, %f34;
	selp.f32 	%f36, 0fBE2AAAA8, 0fBEFFFFFF, %p11;
	fma.rn.f32 	%f37, %f35, %f29, %f36;
	fma.rn.f32 	%f38, %f37, %f31, %f30;
	and.b32  	%r78, %r76, 2;
	setp.eq.s32 	%p12, %r78, 0;
	mov.f32 	%f39, 0f00000000;
	sub.rn.f32 	%f40, %f39, %f38;
	selp.f32 	%f41, %f38, %f40, %p12;
	add.s64 	%rd58, %rd3, %rd40;
	mul.lo.s64 	%rd59, %rd17, 384;
	add.s64 	%rd60, %rd58, %rd59;
	add.s64 	%rd62, %rd60, %rd44;
	add.s64 	%rd64, %rd62, %rd46;
	ld.global.nc.f32 	%f42, [%rd64];
	mul.rn.f32 	%f14, %f42, %f41;
	@%p4 bra 	$L__BB240_22;
	@%p23 bra 	$L__BB240_17;
	bra.uni 	$L__BB240_16;
$L__BB240_17:
	mov.b32 	%r23, %f8;
	shr.u32 	%r24, %r23, 23;
	and.b32  	%r80, %r24, 224;
	add.s32 	%r81, %r80, -128;
	shl.b32 	%r82, %r23, 8;
	or.b32  	%r86, %r82, -2147483648;
	shr.u32 	%r26, %r81, 5;
	mov.b32 	%r134, 0;
	mov.u64 	%rd117, 0;
$L__BB240_18:
	.pragma "nounroll";
	add.s64 	%rd67, %rd115, %rd117;
	ld.global.nc.u32 	%r85, [%rd67];
	// begin inline asm
	{
	mad.lo.cc.u32   %r83, %r85, %r86, %r134;
	madc.hi.u32     %r134, %r85, %r86,  0;
	}
	// end inline asm
	add.s64 	%rd68, %rd6, %rd117;
	st.local.u32 	[%rd68], %r83;
	add.s64 	%rd117, %rd117, 4;
	cvt.u32.u64 	%r88, %rd117;
	setp.ne.s32 	%p14, %r88, 24;
	@%p14 bra 	$L__BB240_18;
	st.local.u32 	[%rd6+24], %r134;
	and.b32  	%r29, %r24, 31;
	mul.wide.u32 	%rd69, %r26, 4;
	sub.s64 	%rd23, %rd6, %rd69;
	ld.local.u32 	%r135, [%rd23+24];
	ld.local.u32 	%r136, [%rd23+20];
	setp.eq.s32 	%p15, %r29, 0;
	@%p15 bra 	$L__BB240_21;
	shl.b32 	%r89, %r136, %r29;
	shl.b32 	%r90, %r135, %r29;
	mov.b32 	%r91, 32;
	sub.s32 	%r92, %r91, %r29;
	shr.u32 	%r93, %r136, %r92;
	add.s32 	%r135, %r93, %r90;
	ld.local.u32 	%r94, [%rd23+16];
	shr.u32 	%r95, %r94, %r92;
	add.s32 	%r136, %r95, %r89;
$L__BB240_21:
	shr.u32 	%r96, %r135, 30;
	shr.u32 	%r97, %r136, 30;
	shl.b32 	%r98, %r135, 2;
	or.b32  	%r99, %r98, %r97;
	shl.b32 	%r100, %r136, 2;
	bfe.u32 	%r101, %r135, 29, 1;
	add.s32 	%r102, %r101, %r96;
	neg.s32 	%r103, %r102;
	setp.lt.s32 	%p16, %r23, 0;
	selp.b32 	%r137, %r103, %r102, %p16;
	xor.b32  	%r104, %r99, %r23;
	bfe.s32 	%r105, %r135, 29, 1;
	xor.b32  	%r106, %r105, %r99;
	xor.b32  	%r107, %r105, %r100;
	cvt.u64.u32 	%rd70, %r106;
	shl.b64 	%rd71, %rd70, 32;
	cvt.u64.u32 	%rd72, %r107;
	or.b64  	%rd73, %rd71, %rd72;
	cvt.rn.f64.s64 	%fd3, %rd73;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f43, %fd4;
	neg.f32 	%f44, %f43;
	setp.lt.s32 	%p17, %r104, 0;
	selp.f32 	%f119, %f44, %f43, %p17;
	bra.uni 	$L__BB240_22;
$L__BB240_3:
	cvt.u64.u32 	%rd15, %r2;
	cvt.u64.u32 	%rd16, %r1;
	mul.wide.u32 	%rd84, %r2, 132;
	mov.u64 	%rd85, shared_cache36;
	add.s64 	%rd86, %rd85, %rd84;
	mul.wide.u32 	%rd87, %r1, 4;
	add.s64 	%rd88, %rd86, %rd87;
	st.shared.f32 	[%rd88], %f115;
	bar.sync 	0;
	mul.wide.u32 	%rd89, %r1, 132;
	add.s64 	%rd90, %rd85, %rd89;
	mul.wide.u32 	%rd91, %r2, 4;
	add.s64 	%rd92, %rd90, %rd91;
	ld.shared.f32 	%f94, [%rd92];
	shfl.sync.down.b32	%f95, %f94, 16, 31, -1;
	add.rn.f32 	%f96, %f94, %f95;
	shfl.sync.down.b32	%f97, %f96, 8, 31, -1;
	add.rn.f32 	%f98, %f96, %f97;
	shfl.sync.down.b32	%f99, %f98, 4, 31, -1;
	add.rn.f32 	%f100, %f98, %f99;
	shfl.sync.down.b32	%f101, %f100, 2, 31, -1;
	add.rn.f32 	%f102, %f100, %f101;
	shfl.sync.down.b32	%f103, %f102, 1, 31, -1;
	add.rn.f32 	%f5, %f102, %f103;
	st.shared.f32 	[%rd92], %f5;
	setp.lt.u32 	%p21, %r1, %r3;
	setp.eq.s32 	%p22, %r2, 0;
	and.pred  	%p1, %p22, %p21;
	or.b32  	%r127, %r1, %r4;
	mul.lo.s64 	%rd114, %rd8, 360;
	@%p1 bra 	$L__BB240_23;
	bra.uni 	$L__BB240_4;
$L__BB240_23:
	mul.hi.u32 	%r117, %r127, -1431655765;
	shr.u32 	%r118, %r117, 2;
	mul.lo.s32 	%r119, %r118, 6;
	sub.s32 	%r120, %r127, %r119;
	add.s64 	%rd94, %rd2, %rd114;
	mul.wide.u32 	%rd95, %r118, 24;
	add.s64 	%rd96, %rd94, %rd95;
	mul.wide.u32 	%rd97, %r120, 4;
	add.s64 	%rd98, %rd96, %rd97;
	st.global.f32 	[%rd98], %f5;
$L__BB240_4:
	mul.lo.s64 	%rd99, %rd15, 132;
	mov.u64 	%rd100, shared_cache37;
	add.s64 	%rd101, %rd100, %rd99;
	shl.b64 	%rd102, %rd16, 2;
	add.s64 	%rd103, %rd101, %rd102;
	st.shared.f32 	[%rd103], %f114;
	bar.sync 	0;
	mul.lo.s64 	%rd104, %rd16, 132;
	add.s64 	%rd105, %rd100, %rd104;
	shl.b64 	%rd106, %rd15, 2;
	add.s64 	%rd107, %rd105, %rd106;
	ld.shared.f32 	%f104, [%rd107];
	shfl.sync.down.b32	%f105, %f104, 16, 31, -1;
	add.rn.f32 	%f106, %f104, %f105;
	shfl.sync.down.b32	%f107, %f106, 8, 31, -1;
	add.rn.f32 	%f108, %f106, %f107;
	shfl.sync.down.b32	%f109, %f108, 4, 31, -1;
	add.rn.f32 	%f110, %f108, %f109;
	shfl.sync.down.b32	%f111, %f110, 2, 31, -1;
	add.rn.f32 	%f112, %f110, %f111;
	shfl.sync.down.b32	%f113, %f112, 1, 31, -1;
	add.rn.f32 	%f6, %f112, %f113;
	st.shared.f32 	[%rd107], %f6;
	@%p1 bra 	$L__BB240_24;
	bra.uni 	$L__BB240_5;
$L__BB240_24:
	mul.hi.u32 	%r123, %r127, -1431655765;
	shr.u32 	%r124, %r123, 2;
	mul.lo.s32 	%r125, %r124, 6;
	sub.s32 	%r126, %r127, %r125;
	add.s64 	%rd109, %rd1, %rd114;
	mul.wide.u32 	%rd110, %r124, 24;
	add.s64 	%rd111, %rd109, %rd110;
	mul.wide.u32 	%rd112, %r126, 4;
	add.s64 	%rd113, %rd111, %rd112;
	st.global.f32 	[%rd113], %f6;
$L__BB240_5:
	ret;

}
	// .globl	input_reduce_fusion_328
.visible .entry input_reduce_fusion_328(
	.param .u64 input_reduce_fusion_328_param_0,
	.param .u64 input_reduce_fusion_328_param_1,
	.param .u64 input_reduce_fusion_328_param_2,
	.param .u64 input_reduce_fusion_328_param_3
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<21>;
	.reg .b32 	%r<28>;
	.reg .f32 	%f<52>;
	.reg .b64 	%rd<45>;
	// demoted variable
	.shared .align 4 .b8 shared_cache38[4224];
	ld.param.u64 	%rd10, [input_reduce_fusion_328_param_0];
	ld.param.u64 	%rd11, [input_reduce_fusion_328_param_3];
	cvta.to.global.u64 	%rd1, %rd11;
	ld.param.u64 	%rd12, [input_reduce_fusion_328_param_1];
	ld.param.u64 	%rd13, [input_reduce_fusion_328_param_2];
	cvta.to.global.u64 	%rd14, %rd13;
	cvta.to.global.u64 	%rd15, %rd12;
	cvta.to.global.u64 	%rd16, %rd10;
	mov.u32 	%r8, %tid.x;
	mov.u32 	%r9, %ctaid.x;
	shr.u32 	%r1, %r8, 5;
	and.b32  	%r2, %r8, 31;
	cvt.u16.u32 	%rs1, %r9;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 9;
	mul.lo.s16 	%rs5, %rs4, 3;
	sub.s16 	%rs6, %rs1, %rs5;
	and.b16  	%rs7, %rs6, 255;
	setp.eq.s16 	%p1, %rs7, 2;
	selp.b32 	%r3, 26, 32, %p1;
	shl.b16 	%rs8, %rs6, 5;
	cvt.u32.u16 	%r10, %rs8;
	and.b32  	%r4, %r10, 224;
	cvt.u64.u16 	%rd2, %rs4;
	cvt.u32.u16 	%r11, %rs4;
	mul.wide.u32 	%rd17, %r11, 4;
	add.s64 	%rd3, %rd14, %rd17;
	add.s32 	%r27, %r1, -32;
	mul.wide.u32 	%rd18, %r11, 19200;
	cvt.u64.u32 	%rd19, %r8;
	shr.u64 	%rd20, %rd19, 5;
	mul.lo.s64 	%rd21, %rd20, 384;
	add.s64 	%rd22, %rd18, %rd21;
	shl.b16 	%rs9, %rs1, 5;
	cvt.u16.u32 	%rs10, %r8;
	and.b16  	%rs11, %rs10, 31;
	or.b16  	%rs12, %rs9, %rs11;
	mul.lo.s16 	%rs13, %rs4, 96;
	sub.s16 	%rs14, %rs12, %rs13;
	cvt.u32.u16 	%r12, %rs14;
	and.b32  	%r13, %r12, 255;
	mul.hi.u32 	%r14, %r13, 715827883;
	mul.wide.u32 	%rd23, %r14, 24;
	add.s64 	%rd24, %rd22, %rd23;
	and.b16  	%rs15, %rs14, 255;
	mul.lo.s16 	%rs16, %rs15, 171;
	shr.u16 	%rs17, %rs16, 10;
	mul.lo.s16 	%rs18, %rs17, 6;
	sub.s16 	%rs19, %rs12, %rs18;
	sub.s16 	%rs20, %rs19, %rs13;
	cvt.u32.u16 	%r15, %rs20;
	and.b32  	%r16, %r15, 255;
	mul.wide.u32 	%rd25, %r16, 4;
	add.s64 	%rd26, %rd24, %rd25;
	add.s64 	%rd27, %rd26, %rd15;
	add.s64 	%rd44, %rd27, 24;
	add.s64 	%rd43, %rd16, %rd26;
	mov.f32 	%f50, 0f00000000;
	setp.lt.u32 	%p2, %r2, %r3;
	mov.f32 	%f9, 0f4B400001;
	mov.f32 	%f10, 0f437C0000;
	bra.uni 	$L__BB241_1;
$L__BB241_2:
	add.s32 	%r27, %r27, 32;
	add.s64 	%rd44, %rd44, 12288;
	add.s64 	%rd43, %rd43, 12288;
	setp.lt.u32 	%p3, %r27, 18;
	@%p3 bra 	$L__BB241_1;
	bra.uni 	$L__BB241_3;
$L__BB241_1:
	@%p2 bra 	$L__BB241_5;
	bra.uni 	$L__BB241_2;
$L__BB241_5:
	ld.global.nc.f32 	%f6, [%rd3];
	fma.rn.f32 	%f7, %f6, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f8, %f7;
	fma.rm.f32 	%f11, %f8, %f10, %f9;
	add.rn.f32 	%f12, %f11, 0fCB40007F;
	neg.f32 	%f13, %f12;
	fma.rn.f32 	%f14, %f6, 0f3FB8AA3B, %f13;
	fma.rn.f32 	%f15, %f6, 0f32A57060, %f14;
	mov.b32 	%r17, %f11;
	shl.b32 	%r18, %r17, 23;
	mov.b32 	%f16, %r18;
	ex2.approx.ftz.f32 	%f17, %f15;
	mul.rn.f32 	%f18, %f17, %f16;
	neg.f32 	%f19, %f18;
	sub.rn.f32 	%f20, %f19, %f18;
	add.rn.f32 	%f21, %f20, %f20;
	add.rn.f32 	%f22, %f21, %f21;
	add.rn.f32 	%f23, %f22, %f22;
	add.rn.f32 	%f24, %f23, %f23;
	fma.rn.f32 	%f25, %f24, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f26, %f25;
	fma.rm.f32 	%f27, %f26, %f10, %f9;
	add.rn.f32 	%f28, %f27, 0fCB40007F;
	neg.f32 	%f29, %f28;
	fma.rn.f32 	%f30, %f24, 0f3FB8AA3B, %f29;
	fma.rn.f32 	%f31, %f24, 0f32A57060, %f30;
	mov.b32 	%r19, %f27;
	shl.b32 	%r20, %r19, 23;
	mov.b32 	%f32, %r20;
	ex2.approx.ftz.f32 	%f33, %f31;
	mul.rn.f32 	%f34, %f33, %f32;
	ld.global.nc.f32 	%f35, [%rd44];
	mul.rn.f32 	%f36, %f35, %f34;
	ld.global.nc.f32 	%f37, [%rd43];
	mul.rn.f32 	%f38, %f37, %f36;
	add.rn.f32 	%f50, %f50, %f38;
	bra.uni 	$L__BB241_2;
$L__BB241_3:
	mul.wide.u32 	%rd28, %r2, 132;
	mov.u64 	%rd29, shared_cache38;
	add.s64 	%rd30, %rd29, %rd28;
	mul.wide.u32 	%rd31, %r1, 4;
	add.s64 	%rd32, %rd30, %rd31;
	st.shared.f32 	[%rd32], %f50;
	bar.sync 	0;
	mul.wide.u32 	%rd33, %r1, 132;
	add.s64 	%rd34, %rd29, %rd33;
	mul.wide.u32 	%rd35, %r2, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.shared.f32 	%f39, [%rd36];
	shfl.sync.down.b32	%f40, %f39, 16, 31, -1;
	add.rn.f32 	%f41, %f39, %f40;
	shfl.sync.down.b32	%f42, %f41, 8, 31, -1;
	add.rn.f32 	%f43, %f41, %f42;
	shfl.sync.down.b32	%f44, %f43, 4, 31, -1;
	add.rn.f32 	%f45, %f43, %f44;
	shfl.sync.down.b32	%f46, %f45, 2, 31, -1;
	add.rn.f32 	%f47, %f45, %f46;
	shfl.sync.down.b32	%f48, %f47, 1, 31, -1;
	add.rn.f32 	%f3, %f47, %f48;
	st.shared.f32 	[%rd36], %f3;
	setp.lt.u32 	%p4, %r1, %r3;
	setp.eq.s32 	%p5, %r2, 0;
	and.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB241_6;
	bra.uni 	$L__BB241_4;
$L__BB241_6:
	or.b32  	%r21, %r1, %r4;
	mul.hi.u32 	%r23, %r21, -1431655765;
	shr.u32 	%r24, %r23, 2;
	mul.lo.s32 	%r25, %r24, 6;
	sub.s32 	%r26, %r21, %r25;
	mul.lo.s64 	%rd37, %rd2, 360;
	add.s64 	%rd38, %rd1, %rd37;
	mul.wide.u32 	%rd39, %r24, 24;
	add.s64 	%rd40, %rd38, %rd39;
	mul.wide.u32 	%rd41, %r26, 4;
	add.s64 	%rd42, %rd40, %rd41;
	neg.f32 	%f49, %f3;
	st.global.f32 	[%rd42], %f49;
$L__BB241_4:
	ret;

}
	// .globl	input_reduce_fusion_329
.visible .entry input_reduce_fusion_329(
	.param .u64 input_reduce_fusion_329_param_0,
	.param .u64 input_reduce_fusion_329_param_1,
	.param .u64 input_reduce_fusion_329_param_2,
	.param .u64 input_reduce_fusion_329_param_3
)
.reqntid 256, 1, 1
{
	.local .align 4 .b8 	__local_depot242[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<23>;
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<127>;
	.reg .f32 	%f<60>;
	.reg .b64 	%rd<64>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot242;
	mov.u32 	%r36, %tid.x;
	mov.u32 	%r37, %ctaid.x;
	shr.u32 	%r1, %r36, 1;
	and.b32  	%r2, %r36, 1;
	setp.eq.s32 	%p1, %r37, 22;
	selp.b32 	%r3, 64, 128, %p1;
	shl.b32 	%r4, %r37, 7;
	setp.ge.u32 	%p2, %r1, %r3;
	mov.f32 	%f59, 0f00000000;
	@%p2 bra 	$L__BB242_18;
	ld.param.u64 	%rd16, [input_reduce_fusion_329_param_0];
	ld.param.u64 	%rd18, [input_reduce_fusion_329_param_1];
	ld.param.u64 	%rd19, [input_reduce_fusion_329_param_2];
	cvta.to.global.u64 	%rd2, %rd19;
	cvta.to.global.u64 	%rd3, %rd18;
	cvta.to.global.u64 	%rd4, %rd16;
	add.u64 	%rd5, %SPL, 0;
	or.b32  	%r38, %r1, %r4;
	cvt.u16.u32 	%rs1, %r38;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, -30583;
	shr.u16 	%rs7, %rs6, 3;
	mul.lo.s16 	%rs8, %rs7, 15;
	sub.s16 	%rs9, %rs3, %rs8;
	mul.hi.u16 	%rs10, %rs1, 11651;
	shr.u16 	%rs11, %rs10, 3;
	shl.b16 	%rs12, %rs5, 1;
	cvt.u32.u16 	%r39, %rs12;
	or.b32  	%r40, %r2, %r39;
	cvt.u64.u16 	%rd7, %rs11;
	cvt.u64.u16 	%rd8, %rs9;
	cvt.u64.u32 	%rd9, %r40;
	cvt.u32.u16 	%r41, %rs9;
	mul.wide.u32 	%rd22, %r41, 24;
	cvt.u32.u16 	%r42, %rs11;
	mul.wide.u32 	%rd23, %r42, 360;
	add.s64 	%rd24, %rd3, %rd23;
	add.s64 	%rd25, %rd24, %rd22;
	mul.wide.u32 	%rd26, %r40, 4;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.f32 	%f1, [%rd27];
	cvt.u32.u16 	%r43, %rs5;
	mul.wide.u32 	%rd28, %r43, 4;
	mul.wide.u32 	%rd29, %r42, 12;
	add.s64 	%rd30, %rd2, %rd29;
	add.s64 	%rd31, %rd30, %rd28;
	ld.global.nc.f32 	%f17, [%rd31];
	add.rn.f32 	%f2, %f17, %f17;
	mul.rn.f32 	%f18, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r126, %f18;
	cvt.rn.f32.s32 	%f19, %r126;
	fma.rn.f32 	%f20, %f19, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f21, %f19, 0fB3A22168, %f20;
	fma.rn.f32 	%f58, %f19, 0fA7C234C5, %f21;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p3, %f4, 0f47CE4780;
	setp.neu.f32 	%p22, %f4, 0f7F800000;
	mov.u32 	%r122, %r126;
	mov.f32 	%f57, %f58;
	@%p3 bra 	$L__BB242_9;
	@%p22 bra 	$L__BB242_4;
	mov.f32 	%f24, 0f00000000;
	mul.rn.f32 	%f57, %f2, %f24;
	mov.b32 	%r122, 0;
	bra.uni 	$L__BB242_9;
$L__BB242_4:
	mov.b32 	%r6, %f2;
	shr.u32 	%r7, %r6, 23;
	and.b32  	%r45, %r7, 224;
	add.s32 	%r46, %r45, -128;
	shl.b32 	%r47, %r6, 8;
	or.b32  	%r51, %r47, -2147483648;
	shr.u32 	%r9, %r46, 5;
	mov.b32 	%r119, 0;
	mov.u64 	%rd62, 0;
	mov.u64 	%rd33, __cudart_i2opi_f;
$L__BB242_5:
	.pragma "nounroll";
	add.s64 	%rd34, %rd33, %rd62;
	ld.global.nc.u32 	%r50, [%rd34];
	// begin inline asm
	{
	mad.lo.cc.u32   %r48, %r50, %r51, %r119;
	madc.hi.u32     %r119, %r50, %r51,  0;
	}
	// end inline asm
	add.s64 	%rd35, %rd5, %rd62;
	st.local.u32 	[%rd35], %r48;
	add.s64 	%rd62, %rd62, 4;
	cvt.u32.u64 	%r53, %rd62;
	setp.ne.s32 	%p5, %r53, 24;
	@%p5 bra 	$L__BB242_5;
	st.local.u32 	[%rd5+24], %r119;
	and.b32  	%r12, %r7, 31;
	mul.wide.u32 	%rd36, %r9, 4;
	sub.s64 	%rd12, %rd5, %rd36;
	ld.local.u32 	%r120, [%rd12+24];
	ld.local.u32 	%r121, [%rd12+20];
	setp.eq.s32 	%p6, %r12, 0;
	@%p6 bra 	$L__BB242_8;
	shl.b32 	%r54, %r121, %r12;
	shl.b32 	%r55, %r120, %r12;
	mov.b32 	%r56, 32;
	sub.s32 	%r57, %r56, %r12;
	shr.u32 	%r58, %r121, %r57;
	add.s32 	%r120, %r58, %r55;
	ld.local.u32 	%r59, [%rd12+16];
	shr.u32 	%r60, %r59, %r57;
	add.s32 	%r121, %r60, %r54;
$L__BB242_8:
	shr.u32 	%r61, %r120, 30;
	shr.u32 	%r62, %r121, 30;
	shl.b32 	%r63, %r120, 2;
	or.b32  	%r64, %r63, %r62;
	shl.b32 	%r65, %r121, 2;
	bfe.u32 	%r66, %r120, 29, 1;
	add.s32 	%r67, %r66, %r61;
	neg.s32 	%r68, %r67;
	setp.lt.s32 	%p7, %r6, 0;
	selp.b32 	%r122, %r68, %r67, %p7;
	xor.b32  	%r69, %r64, %r6;
	bfe.s32 	%r70, %r120, 29, 1;
	xor.b32  	%r71, %r70, %r64;
	xor.b32  	%r72, %r70, %r65;
	cvt.u64.u32 	%rd37, %r71;
	shl.b64 	%rd38, %rd37, 32;
	cvt.u64.u32 	%rd39, %r72;
	or.b64  	%rd40, %rd38, %rd39;
	cvt.rn.f64.s64 	%fd1, %rd40;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f22, %fd2;
	neg.f32 	%f23, %f22;
	setp.lt.s32 	%p8, %r69, 0;
	selp.f32 	%f57, %f23, %f22, %p8;
$L__BB242_9:
	add.s32 	%r74, %r122, 1;
	mul.rn.f32 	%f25, %f57, %f57;
	and.b32  	%r75, %r122, 1;
	setp.eq.b32 	%p10, %r75, 1;
	selp.f32 	%f26, %f57, 0f3F800000, %p10;
	fma.rn.f32 	%f27, %f25, %f26, 0f00000000;
	fma.rn.f32 	%f28, %f25, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f29, 0fB94D4153, %f28, %p10;
	selp.f32 	%f30, 0f3C0885E4, 0f3D2AAABB, %p10;
	fma.rn.f32 	%f31, %f29, %f25, %f30;
	selp.f32 	%f32, 0fBE2AAAA8, 0fBEFFFFFF, %p10;
	fma.rn.f32 	%f33, %f31, %f25, %f32;
	fma.rn.f32 	%f34, %f33, %f27, %f26;
	and.b32  	%r76, %r74, 2;
	setp.eq.s32 	%p11, %r76, 0;
	mov.f32 	%f35, 0f00000000;
	sub.rn.f32 	%f36, %f35, %f34;
	selp.f32 	%f37, %f34, %f36, %p11;
	mul.rn.f32 	%f8, %f1, %f37;
	mul.lo.s64 	%rd41, %rd7, 360;
	add.s64 	%rd42, %rd4, %rd41;
	mul.lo.s64 	%rd43, %rd8, 24;
	add.s64 	%rd44, %rd42, %rd43;
	shl.b64 	%rd45, %rd9, 2;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.nc.f32 	%f9, [%rd46];
	@%p3 bra 	$L__BB242_17;
	@%p22 bra 	$L__BB242_12;
	mul.rn.f32 	%f58, %f2, %f35;
	mov.b32 	%r126, 0;
	bra.uni 	$L__BB242_17;
$L__BB242_12:
	mov.b32 	%r21, %f2;
	shr.u32 	%r22, %r21, 23;
	and.b32  	%r78, %r22, 224;
	add.s32 	%r79, %r78, -128;
	shl.b32 	%r80, %r21, 8;
	or.b32  	%r84, %r80, -2147483648;
	shr.u32 	%r24, %r79, 5;
	mov.b32 	%r123, 0;
	mov.u64 	%rd63, 0;
	mov.u64 	%rd48, __cudart_i2opi_f;
$L__BB242_13:
	.pragma "nounroll";
	add.s64 	%rd49, %rd48, %rd63;
	ld.global.nc.u32 	%r83, [%rd49];
	// begin inline asm
	{
	mad.lo.cc.u32   %r81, %r83, %r84, %r123;
	madc.hi.u32     %r123, %r83, %r84,  0;
	}
	// end inline asm
	add.s64 	%rd50, %rd5, %rd63;
	st.local.u32 	[%rd50], %r81;
	add.s64 	%rd63, %rd63, 4;
	cvt.u32.u64 	%r86, %rd63;
	setp.ne.s32 	%p13, %r86, 24;
	@%p13 bra 	$L__BB242_13;
	st.local.u32 	[%rd5+24], %r123;
	and.b32  	%r27, %r22, 31;
	mul.wide.u32 	%rd51, %r24, 4;
	sub.s64 	%rd15, %rd5, %rd51;
	ld.local.u32 	%r124, [%rd15+24];
	ld.local.u32 	%r125, [%rd15+20];
	setp.eq.s32 	%p14, %r27, 0;
	@%p14 bra 	$L__BB242_16;
	shl.b32 	%r87, %r125, %r27;
	shl.b32 	%r88, %r124, %r27;
	mov.b32 	%r89, 32;
	sub.s32 	%r90, %r89, %r27;
	shr.u32 	%r91, %r125, %r90;
	add.s32 	%r124, %r91, %r88;
	ld.local.u32 	%r92, [%rd15+16];
	shr.u32 	%r93, %r92, %r90;
	add.s32 	%r125, %r93, %r87;
$L__BB242_16:
	shr.u32 	%r94, %r124, 30;
	shr.u32 	%r95, %r125, 30;
	shl.b32 	%r96, %r124, 2;
	or.b32  	%r97, %r96, %r95;
	shl.b32 	%r98, %r125, 2;
	bfe.u32 	%r99, %r124, 29, 1;
	add.s32 	%r100, %r99, %r94;
	neg.s32 	%r101, %r100;
	setp.lt.s32 	%p15, %r21, 0;
	selp.b32 	%r126, %r101, %r100, %p15;
	xor.b32  	%r102, %r97, %r21;
	bfe.s32 	%r103, %r124, 29, 1;
	xor.b32  	%r104, %r103, %r97;
	xor.b32  	%r105, %r103, %r98;
	cvt.u64.u32 	%rd52, %r104;
	shl.b64 	%rd53, %rd52, 32;
	cvt.u64.u32 	%rd54, %r105;
	or.b64  	%rd55, %rd53, %rd54;
	cvt.rn.f64.s64 	%fd3, %rd55;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f38, %fd4;
	neg.f32 	%f39, %f38;
	setp.lt.s32 	%p16, %r102, 0;
	selp.f32 	%f58, %f39, %f38, %p16;
$L__BB242_17:
	mul.rn.f32 	%f41, %f58, %f58;
	and.b32  	%r107, %r126, 1;
	setp.eq.b32 	%p17, %r107, 1;
	selp.f32 	%f42, 0f3F800000, %f58, %p17;
	fma.rn.f32 	%f43, %f41, %f42, 0f00000000;
	fma.rn.f32 	%f44, %f41, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f45, %f44, 0fB94D4153, %p17;
	selp.f32 	%f46, 0f3D2AAABB, 0f3C0885E4, %p17;
	fma.rn.f32 	%f47, %f45, %f41, %f46;
	selp.f32 	%f48, 0fBEFFFFFF, 0fBE2AAAA8, %p17;
	fma.rn.f32 	%f49, %f47, %f41, %f48;
	fma.rn.f32 	%f50, %f49, %f43, %f42;
	and.b32  	%r108, %r126, 2;
	setp.eq.s32 	%p18, %r108, 0;
	sub.rn.f32 	%f52, %f35, %f50;
	selp.f32 	%f53, %f50, %f52, %p18;
	mul.rn.f32 	%f54, %f9, %f53;
	add.rn.f32 	%f55, %f8, %f54;
	add.rn.f32 	%f59, %f55, 0f00000000;
$L__BB242_18:
	shfl.sync.down.b32	%f15, %f59, 1, 31, -1;
	setp.ne.s32 	%p20, %r2, 0;
	or.pred  	%p21, %p20, %p2;
	@%p21 bra 	$L__BB242_20;
	ld.param.u64 	%rd17, [input_reduce_fusion_329_param_3];
	cvta.to.global.u64 	%rd1, %rd17;
	add.rn.f32 	%f56, %f59, %f15;
	or.b32  	%r109, %r4, %r1;
	mul.hi.u32 	%r110, %r109, 1431655766;
	mul.lo.s32 	%r111, %r110, 3;
	sub.s32 	%r112, %r109, %r111;
	mul.hi.u32 	%r113, %r110, 1145324613;
	shr.u32 	%r114, %r113, 2;
	mul.lo.s32 	%r115, %r114, 15;
	sub.s32 	%r116, %r110, %r115;
	mul.hi.u32 	%r117, %r109, -1240768329;
	shr.u32 	%r118, %r117, 5;
	mul.wide.u32 	%rd56, %r112, 60;
	mul.wide.u32 	%rd57, %r118, 180;
	add.s64 	%rd58, %rd1, %rd57;
	add.s64 	%rd59, %rd58, %rd56;
	mul.wide.u32 	%rd60, %r116, 4;
	add.s64 	%rd61, %rd59, %rd60;
	st.global.f32 	[%rd61], %f56;
$L__BB242_20:
	ret;

}
	// .globl	input_reduce_fusion_330
.visible .entry input_reduce_fusion_330(
	.param .u64 input_reduce_fusion_330_param_0,
	.param .u64 input_reduce_fusion_330_param_1,
	.param .u64 input_reduce_fusion_330_param_2,
	.param .u64 input_reduce_fusion_330_param_3
)
.reqntid 256, 1, 1
{
	.local .align 4 .b8 	__local_depot243[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<19>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<122>;
	.reg .f32 	%f<58>;
	.reg .b64 	%rd<64>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot243;
	ld.param.u64 	%rd14, [input_reduce_fusion_330_param_0];
	ld.param.u64 	%rd16, [input_reduce_fusion_330_param_1];
	ld.param.u64 	%rd17, [input_reduce_fusion_330_param_2];
	cvta.to.global.u64 	%rd18, %rd17;
	cvta.to.global.u64 	%rd19, %rd16;
	cvta.to.global.u64 	%rd2, %rd14;
	add.u64 	%rd3, %SPL, 0;
	mov.u32 	%r34, %tid.x;
	mov.u32 	%r35, %ctaid.x;
	shr.u32 	%r36, %r34, 1;
	and.b32  	%r1, %r34, 1;
	shl.b32 	%r37, %r35, 7;
	or.b32  	%r2, %r36, %r37;
	cvt.u16.u32 	%rs1, %r2;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs3, 15;
	shr.u16 	%rs7, %rs2, 5;
	shl.b16 	%rs8, %rs5, 1;
	cvt.u32.u16 	%r38, %rs8;
	or.b32  	%r39, %r1, %r38;
	cvt.u64.u16 	%rd5, %rs7;
	cvt.u64.u16 	%rd6, %rs6;
	cvt.u64.u32 	%rd7, %r39;
	cvt.u32.u16 	%r40, %rs7;
	mul.wide.u32 	%rd22, %r40, 384;
	add.s64 	%rd23, %rd19, %rd22;
	cvt.u32.u16 	%r41, %rs6;
	mul.wide.u32 	%rd24, %r41, 24;
	add.s64 	%rd25, %rd23, %rd24;
	mul.wide.u32 	%rd26, %r39, 4;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.f32 	%f1, [%rd27];
	cvt.u32.u16 	%r42, %rs5;
	mul.wide.u32 	%rd28, %r42, 4;
	mul.wide.u32 	%rd29, %r40, 12;
	add.s64 	%rd30, %rd18, %rd29;
	add.s64 	%rd31, %rd30, %rd28;
	ld.global.nc.f32 	%f15, [%rd31];
	add.rn.f32 	%f2, %f15, %f15;
	mul.rn.f32 	%f16, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r121, %f16;
	cvt.rn.f32.s32 	%f17, %r121;
	fma.rn.f32 	%f18, %f17, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f19, %f17, 0fB3A22168, %f18;
	fma.rn.f32 	%f57, %f17, 0fA7C234C5, %f19;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p1, %f4, 0f47CE4780;
	mov.f32 	%f55, 0f00000000;
	setp.neu.f32 	%p18, %f4, 0f7F800000;
	mov.u32 	%r117, %r121;
	mov.f32 	%f56, %f57;
	@%p1 bra 	$L__BB243_8;
	@%p18 bra 	$L__BB243_3;
	mul.rn.f32 	%f56, %f2, %f55;
	mov.b32 	%r117, 0;
	bra.uni 	$L__BB243_8;
$L__BB243_3:
	mov.b32 	%r4, %f2;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r44, %r5, 224;
	add.s32 	%r45, %r44, -128;
	shl.b32 	%r46, %r4, 8;
	or.b32  	%r50, %r46, -2147483648;
	shr.u32 	%r7, %r45, 5;
	mov.b32 	%r114, 0;
	mov.u64 	%rd62, 0;
	mov.u64 	%rd33, __cudart_i2opi_f;
$L__BB243_4:
	.pragma "nounroll";
	add.s64 	%rd34, %rd33, %rd62;
	ld.global.nc.u32 	%r49, [%rd34];
	// begin inline asm
	{
	mad.lo.cc.u32   %r47, %r49, %r50, %r114;
	madc.hi.u32     %r114, %r49, %r50,  0;
	}
	// end inline asm
	add.s64 	%rd35, %rd3, %rd62;
	st.local.u32 	[%rd35], %r47;
	add.s64 	%rd62, %rd62, 4;
	cvt.u32.u64 	%r52, %rd62;
	setp.ne.s32 	%p3, %r52, 24;
	@%p3 bra 	$L__BB243_4;
	st.local.u32 	[%rd3+24], %r114;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd36, %r7, 4;
	sub.s64 	%rd10, %rd3, %rd36;
	ld.local.u32 	%r115, [%rd10+24];
	ld.local.u32 	%r116, [%rd10+20];
	setp.eq.s32 	%p4, %r10, 0;
	@%p4 bra 	$L__BB243_7;
	shl.b32 	%r53, %r116, %r10;
	shl.b32 	%r54, %r115, %r10;
	mov.b32 	%r55, 32;
	sub.s32 	%r56, %r55, %r10;
	shr.u32 	%r57, %r116, %r56;
	add.s32 	%r115, %r57, %r54;
	ld.local.u32 	%r58, [%rd10+16];
	shr.u32 	%r59, %r58, %r56;
	add.s32 	%r116, %r59, %r53;
$L__BB243_7:
	shr.u32 	%r60, %r115, 30;
	shr.u32 	%r61, %r116, 30;
	shl.b32 	%r62, %r115, 2;
	or.b32  	%r63, %r62, %r61;
	shl.b32 	%r64, %r116, 2;
	bfe.u32 	%r65, %r115, 29, 1;
	add.s32 	%r66, %r65, %r60;
	neg.s32 	%r67, %r66;
	setp.lt.s32 	%p5, %r4, 0;
	selp.b32 	%r117, %r67, %r66, %p5;
	xor.b32  	%r68, %r63, %r4;
	bfe.s32 	%r69, %r115, 29, 1;
	xor.b32  	%r70, %r69, %r63;
	xor.b32  	%r71, %r69, %r64;
	cvt.u64.u32 	%rd37, %r70;
	shl.b64 	%rd38, %rd37, 32;
	cvt.u64.u32 	%rd39, %r71;
	or.b64  	%rd40, %rd38, %rd39;
	cvt.rn.f64.s64 	%fd1, %rd40;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f20, %fd2;
	neg.f32 	%f21, %f20;
	setp.lt.s32 	%p6, %r68, 0;
	selp.f32 	%f56, %f21, %f20, %p6;
$L__BB243_8:
	add.s32 	%r73, %r117, 1;
	mul.rn.f32 	%f23, %f56, %f56;
	and.b32  	%r74, %r117, 1;
	setp.eq.b32 	%p8, %r74, 1;
	selp.f32 	%f24, %f56, 0f3F800000, %p8;
	fma.rn.f32 	%f25, %f23, %f24, 0f00000000;
	fma.rn.f32 	%f26, %f23, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f27, 0fB94D4153, %f26, %p8;
	selp.f32 	%f28, 0f3C0885E4, 0f3D2AAABB, %p8;
	fma.rn.f32 	%f29, %f27, %f23, %f28;
	selp.f32 	%f30, 0fBE2AAAA8, 0fBEFFFFFF, %p8;
	fma.rn.f32 	%f31, %f29, %f23, %f30;
	fma.rn.f32 	%f32, %f31, %f25, %f24;
	and.b32  	%r75, %r73, 2;
	setp.eq.s32 	%p9, %r75, 0;
	sub.rn.f32 	%f34, %f55, %f32;
	selp.f32 	%f35, %f32, %f34, %p9;
	mul.rn.f32 	%f8, %f1, %f35;
	mul.lo.s64 	%rd41, %rd5, 384;
	add.s64 	%rd42, %rd2, %rd41;
	mul.lo.s64 	%rd43, %rd6, 24;
	add.s64 	%rd44, %rd42, %rd43;
	shl.b64 	%rd45, %rd7, 2;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.nc.f32 	%f9, [%rd46];
	@%p1 bra 	$L__BB243_16;
	@%p18 bra 	$L__BB243_11;
	mul.rn.f32 	%f57, %f2, %f55;
	mov.b32 	%r121, 0;
	bra.uni 	$L__BB243_16;
$L__BB243_11:
	mov.b32 	%r19, %f2;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r77, %r20, 224;
	add.s32 	%r78, %r77, -128;
	shl.b32 	%r79, %r19, 8;
	or.b32  	%r83, %r79, -2147483648;
	shr.u32 	%r22, %r78, 5;
	mov.b32 	%r118, 0;
	mov.u64 	%rd63, 0;
	mov.u64 	%rd48, __cudart_i2opi_f;
$L__BB243_12:
	.pragma "nounroll";
	add.s64 	%rd49, %rd48, %rd63;
	ld.global.nc.u32 	%r82, [%rd49];
	// begin inline asm
	{
	mad.lo.cc.u32   %r80, %r82, %r83, %r118;
	madc.hi.u32     %r118, %r82, %r83,  0;
	}
	// end inline asm
	add.s64 	%rd50, %rd3, %rd63;
	st.local.u32 	[%rd50], %r80;
	add.s64 	%rd63, %rd63, 4;
	cvt.u32.u64 	%r85, %rd63;
	setp.ne.s32 	%p11, %r85, 24;
	@%p11 bra 	$L__BB243_12;
	st.local.u32 	[%rd3+24], %r118;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd51, %r22, 4;
	sub.s64 	%rd13, %rd3, %rd51;
	ld.local.u32 	%r119, [%rd13+24];
	ld.local.u32 	%r120, [%rd13+20];
	setp.eq.s32 	%p12, %r25, 0;
	@%p12 bra 	$L__BB243_15;
	shl.b32 	%r86, %r120, %r25;
	shl.b32 	%r87, %r119, %r25;
	mov.b32 	%r88, 32;
	sub.s32 	%r89, %r88, %r25;
	shr.u32 	%r90, %r120, %r89;
	add.s32 	%r119, %r90, %r87;
	ld.local.u32 	%r91, [%rd13+16];
	shr.u32 	%r92, %r91, %r89;
	add.s32 	%r120, %r92, %r86;
$L__BB243_15:
	shr.u32 	%r93, %r119, 30;
	shr.u32 	%r94, %r120, 30;
	shl.b32 	%r95, %r119, 2;
	or.b32  	%r96, %r95, %r94;
	shl.b32 	%r97, %r120, 2;
	bfe.u32 	%r98, %r119, 29, 1;
	add.s32 	%r99, %r98, %r93;
	neg.s32 	%r100, %r99;
	setp.lt.s32 	%p13, %r19, 0;
	selp.b32 	%r121, %r100, %r99, %p13;
	xor.b32  	%r101, %r96, %r19;
	bfe.s32 	%r102, %r119, 29, 1;
	xor.b32  	%r103, %r102, %r96;
	xor.b32  	%r104, %r102, %r97;
	cvt.u64.u32 	%rd52, %r103;
	shl.b64 	%rd53, %rd52, 32;
	cvt.u64.u32 	%rd54, %r104;
	or.b64  	%rd55, %rd53, %rd54;
	cvt.rn.f64.s64 	%fd3, %rd55;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f36, %fd4;
	neg.f32 	%f37, %f36;
	setp.lt.s32 	%p14, %r101, 0;
	selp.f32 	%f57, %f37, %f36, %p14;
$L__BB243_16:
	mul.rn.f32 	%f39, %f57, %f57;
	and.b32  	%r106, %r121, 1;
	setp.eq.b32 	%p15, %r106, 1;
	selp.f32 	%f40, 0f3F800000, %f57, %p15;
	fma.rn.f32 	%f41, %f39, %f40, 0f00000000;
	fma.rn.f32 	%f42, %f39, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f43, %f42, 0fB94D4153, %p15;
	selp.f32 	%f44, 0f3D2AAABB, 0f3C0885E4, %p15;
	fma.rn.f32 	%f45, %f43, %f39, %f44;
	selp.f32 	%f46, 0fBEFFFFFF, 0fBE2AAAA8, %p15;
	fma.rn.f32 	%f47, %f45, %f39, %f46;
	fma.rn.f32 	%f48, %f47, %f41, %f40;
	and.b32  	%r107, %r121, 2;
	setp.eq.s32 	%p16, %r107, 0;
	sub.rn.f32 	%f50, %f55, %f48;
	selp.f32 	%f51, %f48, %f50, %p16;
	mul.rn.f32 	%f52, %f9, %f51;
	add.rn.f32 	%f53, %f8, %f52;
	add.rn.f32 	%f13, %f53, 0f00000000;
	shfl.sync.down.b32	%f14, %f13, 1, 31, -1;
	setp.ne.s32 	%p17, %r1, 0;
	@%p17 bra 	$L__BB243_18;
	ld.param.u64 	%rd15, [input_reduce_fusion_330_param_3];
	cvta.to.global.u64 	%rd1, %rd15;
	add.rn.f32 	%f54, %f13, %f14;
	mul.hi.u32 	%r108, %r2, 1431655766;
	mul.lo.s32 	%r109, %r108, 3;
	sub.s32 	%r110, %r2, %r109;
	and.b32  	%r111, %r108, 15;
	mul.hi.u32 	%r112, %r2, 715827883;
	shr.u32 	%r113, %r112, 3;
	mul.wide.u32 	%rd56, %r113, 192;
	add.s64 	%rd57, %rd1, %rd56;
	mul.wide.u32 	%rd58, %r110, 64;
	add.s64 	%rd59, %rd57, %rd58;
	mul.wide.u32 	%rd60, %r111, 4;
	add.s64 	%rd61, %rd59, %rd60;
	st.global.f32 	[%rd61], %f54;
$L__BB243_18:
	ret;

}
	// .globl	loop_add_fusion_376
.visible .entry loop_add_fusion_376(
	.param .u64 loop_add_fusion_376_param_0,
	.param .u64 loop_add_fusion_376_param_1,
	.param .u64 loop_add_fusion_376_param_2,
	.param .u64 loop_add_fusion_376_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<10>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<17>;
	.reg .b64 	%rd<35>;

	ld.param.u64 	%rd13, [loop_add_fusion_376_param_1];
	cvta.to.global.u64 	%rd3, %rd13;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	shl.b32 	%r6, %r4, 7;
	or.b32  	%r1, %r6, %r5;
	and.b32  	%r2, %r5, 31;
	shr.u32 	%r7, %r1, 5;
	cvt.u16.u32 	%rs1, %r7;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 9;
	mul.lo.s16 	%rs5, %rs4, 3;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, -21845;
	shr.u16 	%rs9, %rs8, 6;
	and.b32  	%r3, %r5, 1;
	setp.eq.s32 	%p1, %r3, 0;
	cvt.u64.u16 	%rd15, %rs6;
	mov.f32 	%f16, 0f00000000;
	mov.f32 	%f14, %f16;
	@%p1 bra 	$L__BB244_4;
	bra.uni 	$L__BB244_1;
$L__BB244_4:
	bfe.u32 	%r8, %r5, 1, 4;
	cvt.u32.u16 	%r9, %rs6;
	and.b32  	%r10, %r9, 255;
	mul.wide.u32 	%rd16, %r10, 64;
	cvt.u32.u16 	%r11, %rs9;
	mul.wide.u32 	%rd17, %r11, 192;
	add.s64 	%rd18, %rd3, %rd17;
	add.s64 	%rd19, %rd18, %rd16;
	mul.wide.u32 	%rd20, %r8, 4;
	add.s64 	%rd7, %rd19, %rd20;
	ld.global.nc.f32 	%f14, [%rd7];
$L__BB244_1:
	ld.param.u64 	%rd12, [loop_add_fusion_376_param_3];
	cvt.u64.u16 	%rd5, %rs9;
	and.b64  	%rd6, %rd15, 255;
	add.s32 	%r12, %r2, -1;
	and.b32  	%r13, %r12, 1;
	setp.eq.b32 	%p2, %r13, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f32 	%f15, %f16;
	@%p5 bra 	$L__BB244_5;
	bra.uni 	$L__BB244_2;
$L__BB244_5:
	ld.param.u64 	%rd14, [loop_add_fusion_376_param_2];
	cvta.to.global.u64 	%rd2, %rd14;
	shr.u32 	%r14, %r12, 1;
	mul.lo.s64 	%rd21, %rd5, 192;
	add.s64 	%rd22, %rd3, %rd21;
	shl.b64 	%rd23, %rd6, 6;
	add.s64 	%rd24, %rd22, %rd23;
	mul.wide.u32 	%rd25, %r14, 4;
	add.s64 	%rd8, %rd24, %rd25;
	add.s64 	%rd26, %rd2, %rd21;
	add.s64 	%rd27, %rd26, %rd23;
	add.s64 	%rd9, %rd27, %rd25;
	ld.global.nc.f32 	%f9, [%rd8];
	ld.global.nc.f32 	%f10, [%rd9];
	add.rn.f32 	%f15, %f9, %f10;
$L__BB244_2:
	cvta.to.global.u64 	%rd1, %rd12;
	setp.gt.u32 	%p7, %r2, 1;
	and.pred  	%p8, %p7, %p1;
	@%p8 bra 	$L__BB244_6;
	bra.uni 	$L__BB244_3;
$L__BB244_6:
	ld.param.u64 	%rd11, [loop_add_fusion_376_param_0];
	cvta.to.global.u64 	%rd4, %rd11;
	add.s32 	%r15, %r2, 254;
	bfe.u32 	%r16, %r15, 1, 7;
	mul.lo.s64 	%rd28, %rd5, 180;
	add.s64 	%rd29, %rd4, %rd28;
	mul.lo.s64 	%rd30, %rd6, 60;
	add.s64 	%rd31, %rd29, %rd30;
	mul.wide.u32 	%rd32, %r16, 4;
	add.s64 	%rd10, %rd31, %rd32;
	ld.global.nc.f32 	%f16, [%rd10];
$L__BB244_3:
	add.rn.f32 	%f12, %f14, %f15;
	add.rn.f32 	%f13, %f12, %f16;
	mul.wide.u32 	%rd33, %r1, 4;
	add.s64 	%rd34, %rd1, %rd33;
	st.global.f32 	[%rd34], %f13;
	ret;

}
	// .globl	input_reduce_fusion_331
.visible .entry input_reduce_fusion_331(
	.param .u64 input_reduce_fusion_331_param_0,
	.param .u64 input_reduce_fusion_331_param_1,
	.param .u64 input_reduce_fusion_331_param_2,
	.param .u64 input_reduce_fusion_331_param_3,
	.param .u64 input_reduce_fusion_331_param_4
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<11>;
	.reg .b16 	%rs<23>;
	.reg .b32 	%r<28>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<62>;
	// demoted variable
	.shared .align 4 .b8 shared_cache39[4224];
	ld.param.u64 	%rd13, [input_reduce_fusion_331_param_0];
	ld.param.u64 	%rd14, [input_reduce_fusion_331_param_4];
	cvta.to.global.u64 	%rd1, %rd14;
	ld.param.u64 	%rd15, [input_reduce_fusion_331_param_1];
	ld.param.u64 	%rd16, [input_reduce_fusion_331_param_3];
	cvta.to.global.u64 	%rd17, %rd16;
	ld.param.u64 	%rd18, [input_reduce_fusion_331_param_2];
	cvta.to.global.u64 	%rd19, %rd18;
	cvta.to.global.u64 	%rd20, %rd15;
	cvta.to.global.u64 	%rd21, %rd13;
	mov.u32 	%r9, %tid.x;
	mov.u32 	%r10, %ctaid.x;
	shr.u32 	%r1, %r9, 5;
	and.b32  	%r2, %r9, 31;
	cvt.u16.u32 	%rs1, %r10;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	setp.eq.s16 	%p2, %rs5, 5;
	selp.b32 	%r3, 26, 32, %p2;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r4, %rs6;
	or.b32  	%r11, %r2, %r4;
	cvt.u16.u32 	%rs7, %r11;
	and.b16  	%rs8, %rs7, 255;
	mul.lo.s16 	%rs9, %rs8, 171;
	shr.u16 	%rs10, %rs9, 10;
	cvt.u32.u16 	%r12, %rs10;
	cvt.u64.u16 	%rd2, %rs3;
	cvt.u32.u16 	%r13, %rs3;
	mul.wide.u32 	%rd22, %r13, 4;
	add.s64 	%rd3, %rd17, %rd22;
	and.b32  	%r5, %r12, 1;
	setp.gt.u32 	%p3, %r11, 5;
	and.b16  	%rs11, %rs10, 1;
	setp.eq.b16 	%p4, %rs11, 1;
	and.pred  	%p1, %p3, %p4;
	add.s32 	%r27, %r1, -32;
	mul.wide.u32 	%rd23, %r13, 38400;
	cvt.u64.u32 	%rd24, %r9;
	shr.u64 	%rd25, %rd24, 5;
	mul.lo.s64 	%rd26, %rd25, 768;
	add.s64 	%rd27, %rd23, %rd26;
	shl.b16 	%rs12, %rs3, 6;
	shl.b16 	%rs13, %rs1, 5;
	add.s16 	%rs14, %rs12, %rs13;
	cvt.u16.u32 	%rs15, %r9;
	and.b16  	%rs16, %rs15, 31;
	or.b16  	%rs17, %rs14, %rs16;
	cvt.u32.u16 	%r14, %rs17;
	and.b32  	%r15, %r14, 255;
	mul.hi.u32 	%r16, %r15, 715827883;
	mul.wide.u32 	%rd28, %r16, 24;
	add.s64 	%rd29, %rd27, %rd28;
	and.b16  	%rs18, %rs17, 255;
	mul.lo.s16 	%rs19, %rs18, 171;
	shr.u16 	%rs20, %rs19, 10;
	mul.lo.s16 	%rs21, %rs20, 6;
	sub.s16 	%rs22, %rs17, %rs21;
	cvt.u32.u16 	%r17, %rs22;
	and.b32  	%r18, %r17, 255;
	mul.wide.u32 	%rd30, %r18, 4;
	add.s64 	%rd31, %rd29, %rd30;
	add.s64 	%rd32, %rd31, %rd19;
	add.s64 	%rd61, %rd32, 24;
	mul.wide.u32 	%rd33, %r13, 19200;
	mul.lo.s64 	%rd34, %rd25, 384;
	add.s64 	%rd35, %rd33, %rd34;
	mul.hi.u32 	%r19, %r15, 357913942;
	mul.wide.u32 	%rd36, %r19, 24;
	add.s64 	%rd37, %rd35, %rd36;
	add.s64 	%rd38, %rd37, %rd30;
	add.s64 	%rd60, %rd20, %rd38;
	add.s32 	%r20, %r16, -1;
	cvt.u64.u32 	%rd39, %r20;
	shr.u64 	%rd40, %rd39, 1;
	mul.lo.s64 	%rd41, %rd40, 24;
	add.s64 	%rd42, %rd35, %rd41;
	add.s64 	%rd43, %rd42, %rd30;
	add.s64 	%rd59, %rd21, %rd43;
	mov.f32 	%f10, 0f00000000;
	setp.lt.u32 	%p5, %r2, %r3;
	setp.eq.s32 	%p6, %r5, 0;
	mov.f32 	%f1, %f10;
	bra.uni 	$L__BB245_1;
$L__BB245_7:
	add.rn.f32 	%f15, %f30, %f31;
	mul.rn.f32 	%f16, %f4, %f15;
	add.rn.f32 	%f1, %f1, %f16;
$L__BB245_2:
	add.s32 	%r27, %r27, 32;
	add.s64 	%rd61, %rd61, 24576;
	add.s64 	%rd60, %rd60, 12288;
	add.s64 	%rd59, %rd59, 12288;
	setp.lt.u32 	%p7, %r27, 18;
	@%p7 bra 	$L__BB245_1;
	bra.uni 	$L__BB245_3;
$L__BB245_1:
	@%p5 bra 	$L__BB245_5;
	bra.uni 	$L__BB245_2;
$L__BB245_5:
	ld.global.nc.f32 	%f12, [%rd3];
	ld.global.nc.f32 	%f13, [%rd61];
	mov.f32 	%f30, %f10;
	@%p6 bra 	$L__BB245_8;
	bra.uni 	$L__BB245_6;
$L__BB245_8:
	ld.global.nc.f32 	%f30, [%rd60];
$L__BB245_6:
	mul.rn.f32 	%f4, %f12, %f13;
	mov.f32 	%f31, %f10;
	@%p1 bra 	$L__BB245_9;
	bra.uni 	$L__BB245_7;
$L__BB245_9:
	ld.global.nc.f32 	%f31, [%rd59];
	bra.uni 	$L__BB245_7;
$L__BB245_3:
	mul.wide.u32 	%rd44, %r2, 132;
	mov.u64 	%rd45, shared_cache39;
	add.s64 	%rd46, %rd45, %rd44;
	mul.wide.u32 	%rd47, %r1, 4;
	add.s64 	%rd48, %rd46, %rd47;
	st.shared.f32 	[%rd48], %f1;
	bar.sync 	0;
	mul.wide.u32 	%rd49, %r1, 132;
	add.s64 	%rd50, %rd45, %rd49;
	mul.wide.u32 	%rd51, %r2, 4;
	add.s64 	%rd52, %rd50, %rd51;
	ld.shared.f32 	%f17, [%rd52];
	shfl.sync.down.b32	%f18, %f17, 16, 31, -1;
	add.rn.f32 	%f19, %f17, %f18;
	shfl.sync.down.b32	%f20, %f19, 8, 31, -1;
	add.rn.f32 	%f21, %f19, %f20;
	shfl.sync.down.b32	%f22, %f21, 4, 31, -1;
	add.rn.f32 	%f23, %f21, %f22;
	shfl.sync.down.b32	%f24, %f23, 2, 31, -1;
	add.rn.f32 	%f25, %f23, %f24;
	shfl.sync.down.b32	%f26, %f25, 1, 31, -1;
	add.rn.f32 	%f3, %f25, %f26;
	st.shared.f32 	[%rd52], %f3;
	setp.lt.u32 	%p8, %r1, %r3;
	setp.eq.s32 	%p9, %r2, 0;
	and.pred  	%p10, %p9, %p8;
	@%p10 bra 	$L__BB245_10;
	bra.uni 	$L__BB245_4;
$L__BB245_10:
	or.b32  	%r21, %r1, %r4;
	mul.hi.u32 	%r23, %r21, -1431655765;
	shr.u32 	%r24, %r23, 2;
	mul.lo.s32 	%r25, %r24, 6;
	sub.s32 	%r26, %r21, %r25;
	mul.lo.s64 	%rd53, %rd2, 744;
	add.s64 	%rd54, %rd1, %rd53;
	mul.wide.u32 	%rd55, %r24, 24;
	add.s64 	%rd56, %rd54, %rd55;
	mul.wide.u32 	%rd57, %r26, 4;
	add.s64 	%rd58, %rd56, %rd57;
	neg.f32 	%f27, %f3;
	st.global.f32 	[%rd58], %f27;
$L__BB245_4:
	ret;

}
	// .globl	input_reduce_fusion_332
.visible .entry input_reduce_fusion_332(
	.param .u64 input_reduce_fusion_332_param_0,
	.param .u64 input_reduce_fusion_332_param_1,
	.param .u64 input_reduce_fusion_332_param_2,
	.param .u64 input_reduce_fusion_332_param_3,
	.param .u64 input_reduce_fusion_332_param_4,
	.param .u64 input_reduce_fusion_332_param_5,
	.param .u64 input_reduce_fusion_332_param_6,
	.param .u64 input_reduce_fusion_332_param_7
)
.reqntid 1024, 1, 1
{
	.local .align 4 .b8 	__local_depot246[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<29>;
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<138>;
	.reg .f32 	%f<98>;
	.reg .b64 	%rd<130>;
	.reg .f64 	%fd<5>;
	// demoted variable
	.shared .align 4 .b8 shared_cache40[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache41[4224];
	mov.u64 	%SPL, __local_depot246;
	ld.param.u64 	%rd29, [input_reduce_fusion_332_param_0];
	ld.param.u64 	%rd30, [input_reduce_fusion_332_param_7];
	cvta.to.global.u64 	%rd1, %rd30;
	ld.param.u64 	%rd31, [input_reduce_fusion_332_param_1];
	ld.param.u64 	%rd32, [input_reduce_fusion_332_param_6];
	cvta.to.global.u64 	%rd2, %rd32;
	ld.param.u64 	%rd33, [input_reduce_fusion_332_param_2];
	ld.param.u64 	%rd34, [input_reduce_fusion_332_param_5];
	cvta.to.global.u64 	%rd35, %rd34;
	ld.param.u64 	%rd36, [input_reduce_fusion_332_param_3];
	ld.param.u64 	%rd37, [input_reduce_fusion_332_param_4];
	cvta.to.global.u64 	%rd38, %rd37;
	cvta.to.global.u64 	%rd3, %rd36;
	cvta.to.global.u64 	%rd4, %rd33;
	cvta.to.global.u64 	%rd5, %rd31;
	cvta.to.global.u64 	%rd6, %rd29;
	add.u64 	%rd7, %SPL, 0;
	mov.u32 	%r40, %tid.x;
	mov.u32 	%r41, %ctaid.x;
	shr.u32 	%r1, %r40, 5;
	and.b32  	%r2, %r40, 31;
	cvt.u16.u32 	%rs1, %r41;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	setp.eq.s16 	%p3, %rs5, 5;
	selp.b32 	%r3, 26, 32, %p3;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r4, %rs6;
	or.b32  	%r42, %r2, %r4;
	cvt.u16.u32 	%rs7, %r42;
	and.b16  	%rs8, %rs7, 255;
	mul.lo.s16 	%rs9, %rs8, 171;
	shr.u16 	%rs10, %rs9, 10;
	mul.lo.s16 	%rs11, %rs10, 6;
	sub.s16 	%rs12, %rs7, %rs11;
	cvt.u32.u16 	%r43, %rs12;
	cvt.u32.u16 	%r5, %rs10;
	cvt.u64.u16 	%rd9, %rs3;
	cvt.u64.u16 	%rd41, %rs12;
	and.b64  	%rd10, %rd41, 255;
	bfe.u32 	%r44, %r43, 1, 7;
	cvt.u64.u32 	%rd11, %r44;
	mul.wide.u32 	%rd42, %r44, 4;
	cvt.u32.u16 	%r45, %rs3;
	mul.wide.u32 	%rd43, %r45, 12;
	add.s64 	%rd44, %rd38, %rd43;
	add.s64 	%rd12, %rd44, %rd42;
	and.b32  	%r6, %r5, 1;
	shr.u16 	%rs13, %rs9, 11;
	cvt.u64.u16 	%rd13, %rs13;
	add.s32 	%r46, %r5, -1;
	setp.gt.u32 	%p4, %r42, 5;
	and.b32  	%r47, %r46, 1;
	setp.eq.b32 	%p5, %r47, 1;
	not.pred 	%p6, %p5;
	and.pred  	%p1, %p4, %p6;
	shr.s32 	%r48, %r46, 1;
	cvt.s64.s32 	%rd14, %r48;
	and.b32  	%r49, %r43, 1;
	cvt.u64.u16 	%rd15, %rs10;
	cvt.u64.u32 	%rd16, %r49;
	mul.wide.u32 	%rd45, %r45, 4;
	add.s64 	%rd17, %rd35, %rd45;
	mov.f32 	%f1, 0f00000000;
	setp.lt.u32 	%p7, %r2, %r3;
	setp.eq.s32 	%p14, %r6, 0;
	mul.lo.s64 	%rd67, %rd13, 24;
	mul.lo.s64 	%rd74, %rd14, 24;
	mul.lo.s64 	%rd90, %rd15, 24;
	shl.b64 	%rd92, %rd11, 3;
	shl.b64 	%rd94, %rd16, 2;
	mov.u32 	%r129, %r1;
	mov.f32 	%f2, %f1;
	bra.uni 	$L__BB246_1;
$L__BB246_18:
	mov.f32 	%f49, 0f00000000;
	mul.rn.f32 	%f97, %f8, %f49;
	mov.b32 	%r137, 0;
$L__BB246_24:
	mul.rn.f32 	%f50, %f97, %f97;
	and.b32  	%r113, %r137, 1;
	setp.eq.b32 	%p23, %r113, 1;
	selp.f32 	%f51, 0f3F800000, %f97, %p23;
	fma.rn.f32 	%f52, %f50, %f51, 0f00000000;
	fma.rn.f32 	%f53, %f50, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f54, %f53, 0fB94D4153, %p23;
	selp.f32 	%f55, 0f3D2AAABB, 0f3C0885E4, %p23;
	fma.rn.f32 	%f56, %f54, %f50, %f55;
	selp.f32 	%f57, 0fBEFFFFFF, 0fBE2AAAA8, %p23;
	fma.rn.f32 	%f58, %f56, %f50, %f57;
	fma.rn.f32 	%f59, %f58, %f52, %f51;
	and.b32  	%r114, %r137, 2;
	setp.eq.s32 	%p24, %r114, 0;
	mov.f32 	%f60, 0f00000000;
	sub.rn.f32 	%f61, %f60, %f59;
	selp.f32 	%f62, %f59, %f61, %p24;
	mul.lo.s64 	%rd86, %rd9, 37200;
	add.s64 	%rd87, %rd5, %rd86;
	mul.lo.s64 	%rd88, %rd20, 744;
	add.s64 	%rd89, %rd87, %rd88;
	add.s64 	%rd91, %rd89, %rd90;
	add.s64 	%rd93, %rd91, %rd92;
	add.s64 	%rd95, %rd93, %rd94;
	ld.global.nc.f32 	%f63, [%rd95];
	mul.rn.f32 	%f64, %f63, %f62;
	add.rn.f32 	%f65, %f17, %f64;
	mul.rn.f32 	%f66, %f7, %f65;
	add.rn.f32 	%f2, %f2, %f66;
	ld.global.nc.f32 	%f67, [%rd17];
	mul.rn.f32 	%f68, %f7, %f67;
	mul.rn.f32 	%f69, %f63, %f68;
	add.rn.f32 	%f1, %f1, %f69;
$L__BB246_2:
	add.s32 	%r8, %r129, 32;
	setp.lt.u32 	%p25, %r129, 18;
	mov.u32 	%r129, %r8;
	@%p25 bra 	$L__BB246_1;
	bra.uni 	$L__BB246_3;
$L__BB246_1:
	@%p7 bra 	$L__BB246_6;
	bra.uni 	$L__BB246_2;
$L__BB246_6:
	mul.lo.s64 	%rd46, %rd9, 38400;
	add.s64 	%rd47, %rd6, %rd46;
	mul.wide.u32 	%rd48, %r129, 768;
	add.s64 	%rd49, %rd47, %rd48;
	mul.wide.u32 	%rd50, %r5, 24;
	add.s64 	%rd51, %rd49, %rd50;
	shl.b64 	%rd52, %rd10, 2;
	add.s64 	%rd53, %rd51, %rd52;
	ld.global.nc.f32 	%f7, [%rd53+24];
	ld.global.nc.f32 	%f8, [%rd12];
	mul.rn.f32 	%f26, %f8, 0f3F22F983;
	cvt.rni.s32.f32 	%r137, %f26;
	cvt.rn.f32.s32 	%f27, %r137;
	fma.rn.f32 	%f28, %f27, 0fBFC90FDA, %f8;
	fma.rn.f32 	%f29, %f27, 0fB3A22168, %f28;
	fma.rn.f32 	%f97, %f27, 0fA7C234C5, %f29;
	abs.f32 	%f10, %f8;
	setp.ltu.f32 	%p8, %f10, 0f47CE4780;
	setp.neu.f32 	%p28, %f10, 0f7F800000;
	mov.u64 	%rd127, __cudart_i2opi_f;
	mov.u32 	%r133, %r137;
	mov.f32 	%f94, %f97;
	@%p8 bra 	$L__BB246_14;
	@%p28 bra 	$L__BB246_9;
	mov.f32 	%f32, 0f00000000;
	mul.rn.f32 	%f94, %f8, %f32;
	mov.b32 	%r133, 0;
	bra.uni 	$L__BB246_14;
$L__BB246_9:
	mov.b32 	%r130, 0;
	mov.b32 	%r10, %f8;
	shr.u32 	%r11, %r10, 23;
	and.b32  	%r51, %r11, 224;
	add.s32 	%r52, %r51, -128;
	shl.b32 	%r53, %r10, 8;
	or.b32  	%r57, %r53, -2147483648;
	shr.u32 	%r13, %r52, 5;
	mov.u64 	%rd128, 0;
$L__BB246_10:
	.pragma "nounroll";
	add.s64 	%rd56, %rd127, %rd128;
	ld.global.nc.u32 	%r56, [%rd56];
	// begin inline asm
	{
	mad.lo.cc.u32   %r54, %r56, %r57, %r130;
	madc.hi.u32     %r130, %r56, %r57,  0;
	}
	// end inline asm
	add.s64 	%rd57, %rd7, %rd128;
	st.local.u32 	[%rd57], %r54;
	add.s64 	%rd128, %rd128, 4;
	cvt.u32.u64 	%r59, %rd128;
	setp.ne.s32 	%p10, %r59, 24;
	@%p10 bra 	$L__BB246_10;
	st.local.u32 	[%rd7+24], %r130;
	and.b32  	%r16, %r11, 31;
	mul.wide.u32 	%rd58, %r13, 4;
	sub.s64 	%rd23, %rd7, %rd58;
	ld.local.u32 	%r131, [%rd23+24];
	ld.local.u32 	%r132, [%rd23+20];
	setp.eq.s32 	%p11, %r16, 0;
	@%p11 bra 	$L__BB246_13;
	shl.b32 	%r60, %r132, %r16;
	shl.b32 	%r61, %r131, %r16;
	mov.b32 	%r62, 32;
	sub.s32 	%r63, %r62, %r16;
	shr.u32 	%r64, %r132, %r63;
	add.s32 	%r131, %r64, %r61;
	ld.local.u32 	%r65, [%rd23+16];
	shr.u32 	%r66, %r65, %r63;
	add.s32 	%r132, %r66, %r60;
$L__BB246_13:
	shr.u32 	%r67, %r131, 30;
	shr.u32 	%r68, %r132, 30;
	shl.b32 	%r69, %r131, 2;
	or.b32  	%r70, %r69, %r68;
	shl.b32 	%r71, %r132, 2;
	bfe.u32 	%r72, %r131, 29, 1;
	add.s32 	%r73, %r72, %r67;
	neg.s32 	%r74, %r73;
	setp.lt.s32 	%p12, %r10, 0;
	selp.b32 	%r133, %r74, %r73, %p12;
	xor.b32  	%r75, %r70, %r10;
	bfe.s32 	%r76, %r131, 29, 1;
	xor.b32  	%r77, %r76, %r70;
	xor.b32  	%r78, %r76, %r71;
	cvt.u64.u32 	%rd59, %r77;
	shl.b64 	%rd60, %rd59, 32;
	cvt.u64.u32 	%rd61, %r78;
	or.b64  	%rd62, %rd60, %rd61;
	cvt.rn.f64.s64 	%fd1, %rd62;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f30, %fd2;
	neg.f32 	%f31, %f30;
	setp.lt.s32 	%p13, %r75, 0;
	selp.f32 	%f94, %f31, %f30, %p13;
$L__BB246_14:
	cvt.u64.u32 	%rd20, %r129;
	mul.rn.f32 	%f34, %f94, %f94;
	and.b32  	%r81, %r133, 1;
	setp.eq.b32 	%p15, %r81, 1;
	selp.f32 	%f35, %f94, 0f3F800000, %p15;
	fma.rn.f32 	%f36, %f34, %f35, 0f00000000;
	fma.rn.f32 	%f37, %f34, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f38, 0fB94D4153, %f37, %p15;
	selp.f32 	%f39, 0f3C0885E4, 0f3D2AAABB, %p15;
	fma.rn.f32 	%f40, %f38, %f34, %f39;
	selp.f32 	%f41, 0fBE2AAAA8, 0fBEFFFFFF, %p15;
	fma.rn.f32 	%f42, %f40, %f34, %f41;
	fma.rn.f32 	%f43, %f42, %f36, %f35;
	mov.f32 	%f96, 0f00000000;
	sub.rn.f32 	%f44, %f96, %f43;
	mul.lo.s64 	%rd63, %rd9, 19200;
	mul.lo.s64 	%rd65, %rd20, 384;
	mov.f32 	%f95, %f96;
	@%p14 bra 	$L__BB246_25;
	bra.uni 	$L__BB246_15;
$L__BB246_25:
	add.s64 	%rd64, %rd3, %rd63;
	add.s64 	%rd66, %rd64, %rd65;
	add.s64 	%rd68, %rd66, %rd67;
	add.s64 	%rd24, %rd68, %rd52;
	ld.global.nc.f32 	%f95, [%rd24];
$L__BB246_15:
	add.s32 	%r80, %r133, 1;
	and.b32  	%r82, %r80, 2;
	setp.eq.s32 	%p16, %r82, 0;
	selp.f32 	%f14, %f43, %f44, %p16;
	@%p1 bra 	$L__BB246_26;
	bra.uni 	$L__BB246_16;
$L__BB246_26:
	add.s64 	%rd71, %rd4, %rd63;
	add.s64 	%rd73, %rd71, %rd65;
	add.s64 	%rd75, %rd73, %rd74;
	add.s64 	%rd25, %rd75, %rd52;
	ld.global.nc.f32 	%f96, [%rd25];
$L__BB246_16:
	add.rn.f32 	%f46, %f95, %f96;
	mul.rn.f32 	%f17, %f14, %f46;
	@%p8 bra 	$L__BB246_24;
	@%p28 bra 	$L__BB246_19;
	bra.uni 	$L__BB246_18;
$L__BB246_19:
	mov.b32 	%r25, %f8;
	shr.u32 	%r26, %r25, 23;
	and.b32  	%r84, %r26, 224;
	add.s32 	%r85, %r84, -128;
	shl.b32 	%r86, %r25, 8;
	or.b32  	%r90, %r86, -2147483648;
	shr.u32 	%r28, %r85, 5;
	mov.b32 	%r134, 0;
	mov.u64 	%rd129, 0;
$L__BB246_20:
	.pragma "nounroll";
	add.s64 	%rd79, %rd127, %rd129;
	ld.global.nc.u32 	%r89, [%rd79];
	// begin inline asm
	{
	mad.lo.cc.u32   %r87, %r89, %r90, %r134;
	madc.hi.u32     %r134, %r89, %r90,  0;
	}
	// end inline asm
	add.s64 	%rd80, %rd7, %rd129;
	st.local.u32 	[%rd80], %r87;
	add.s64 	%rd129, %rd129, 4;
	cvt.u32.u64 	%r92, %rd129;
	setp.ne.s32 	%p19, %r92, 24;
	@%p19 bra 	$L__BB246_20;
	st.local.u32 	[%rd7+24], %r134;
	and.b32  	%r31, %r26, 31;
	mul.wide.u32 	%rd81, %r28, 4;
	sub.s64 	%rd28, %rd7, %rd81;
	ld.local.u32 	%r135, [%rd28+24];
	ld.local.u32 	%r136, [%rd28+20];
	setp.eq.s32 	%p20, %r31, 0;
	@%p20 bra 	$L__BB246_23;
	shl.b32 	%r93, %r136, %r31;
	shl.b32 	%r94, %r135, %r31;
	mov.b32 	%r95, 32;
	sub.s32 	%r96, %r95, %r31;
	shr.u32 	%r97, %r136, %r96;
	add.s32 	%r135, %r97, %r94;
	ld.local.u32 	%r98, [%rd28+16];
	shr.u32 	%r99, %r98, %r96;
	add.s32 	%r136, %r99, %r93;
$L__BB246_23:
	shr.u32 	%r100, %r135, 30;
	shr.u32 	%r101, %r136, 30;
	shl.b32 	%r102, %r135, 2;
	or.b32  	%r103, %r102, %r101;
	shl.b32 	%r104, %r136, 2;
	bfe.u32 	%r105, %r135, 29, 1;
	add.s32 	%r106, %r105, %r100;
	neg.s32 	%r107, %r106;
	setp.lt.s32 	%p21, %r25, 0;
	selp.b32 	%r137, %r107, %r106, %p21;
	xor.b32  	%r108, %r103, %r25;
	bfe.s32 	%r109, %r135, 29, 1;
	xor.b32  	%r110, %r109, %r103;
	xor.b32  	%r111, %r109, %r104;
	cvt.u64.u32 	%rd82, %r110;
	shl.b64 	%rd83, %rd82, 32;
	cvt.u64.u32 	%rd84, %r111;
	or.b64  	%rd85, %rd83, %rd84;
	cvt.rn.f64.s64 	%fd3, %rd85;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f47, %fd4;
	neg.f32 	%f48, %f47;
	setp.lt.s32 	%p22, %r108, 0;
	selp.f32 	%f97, %f48, %f47, %p22;
	bra.uni 	$L__BB246_24;
$L__BB246_3:
	cvt.u64.u32 	%rd18, %r2;
	cvt.u64.u32 	%rd19, %r1;
	mul.wide.u32 	%rd96, %r2, 132;
	mov.u64 	%rd97, shared_cache40;
	add.s64 	%rd98, %rd97, %rd96;
	mul.wide.u32 	%rd99, %r1, 4;
	add.s64 	%rd100, %rd98, %rd99;
	st.shared.f32 	[%rd100], %f2;
	bar.sync 	0;
	mul.wide.u32 	%rd101, %r1, 132;
	add.s64 	%rd102, %rd97, %rd101;
	mul.wide.u32 	%rd103, %r2, 4;
	add.s64 	%rd104, %rd102, %rd103;
	ld.shared.f32 	%f70, [%rd104];
	shfl.sync.down.b32	%f71, %f70, 16, 31, -1;
	add.rn.f32 	%f72, %f70, %f71;
	shfl.sync.down.b32	%f73, %f72, 8, 31, -1;
	add.rn.f32 	%f74, %f72, %f73;
	shfl.sync.down.b32	%f75, %f74, 4, 31, -1;
	add.rn.f32 	%f76, %f74, %f75;
	shfl.sync.down.b32	%f77, %f76, 2, 31, -1;
	add.rn.f32 	%f78, %f76, %f77;
	shfl.sync.down.b32	%f79, %f78, 1, 31, -1;
	add.rn.f32 	%f5, %f78, %f79;
	st.shared.f32 	[%rd104], %f5;
	setp.lt.u32 	%p26, %r1, %r3;
	setp.eq.s32 	%p27, %r2, 0;
	and.pred  	%p2, %p27, %p26;
	or.b32  	%r127, %r1, %r4;
	mul.lo.s64 	%rd126, %rd9, 744;
	@%p2 bra 	$L__BB246_27;
	bra.uni 	$L__BB246_4;
$L__BB246_27:
	mul.hi.u32 	%r117, %r127, -1431655765;
	shr.u32 	%r118, %r117, 2;
	mul.lo.s32 	%r119, %r118, 6;
	sub.s32 	%r120, %r127, %r119;
	add.s64 	%rd106, %rd2, %rd126;
	mul.wide.u32 	%rd107, %r118, 24;
	add.s64 	%rd108, %rd106, %rd107;
	mul.wide.u32 	%rd109, %r120, 4;
	add.s64 	%rd110, %rd108, %rd109;
	st.global.f32 	[%rd110], %f5;
$L__BB246_4:
	mul.lo.s64 	%rd111, %rd18, 132;
	mov.u64 	%rd112, shared_cache41;
	add.s64 	%rd113, %rd112, %rd111;
	shl.b64 	%rd114, %rd19, 2;
	add.s64 	%rd115, %rd113, %rd114;
	st.shared.f32 	[%rd115], %f1;
	bar.sync 	0;
	mul.lo.s64 	%rd116, %rd19, 132;
	add.s64 	%rd117, %rd112, %rd116;
	shl.b64 	%rd118, %rd18, 2;
	add.s64 	%rd119, %rd117, %rd118;
	ld.shared.f32 	%f80, [%rd119];
	shfl.sync.down.b32	%f81, %f80, 16, 31, -1;
	add.rn.f32 	%f82, %f80, %f81;
	shfl.sync.down.b32	%f83, %f82, 8, 31, -1;
	add.rn.f32 	%f84, %f82, %f83;
	shfl.sync.down.b32	%f85, %f84, 4, 31, -1;
	add.rn.f32 	%f86, %f84, %f85;
	shfl.sync.down.b32	%f87, %f86, 2, 31, -1;
	add.rn.f32 	%f88, %f86, %f87;
	shfl.sync.down.b32	%f89, %f88, 1, 31, -1;
	add.rn.f32 	%f6, %f88, %f89;
	st.shared.f32 	[%rd119], %f6;
	@%p2 bra 	$L__BB246_28;
	bra.uni 	$L__BB246_5;
$L__BB246_28:
	mul.hi.u32 	%r123, %r127, -1431655765;
	shr.u32 	%r124, %r123, 2;
	mul.lo.s32 	%r125, %r124, 6;
	sub.s32 	%r126, %r127, %r125;
	add.s64 	%rd121, %rd1, %rd126;
	mul.wide.u32 	%rd122, %r124, 24;
	add.s64 	%rd123, %rd121, %rd122;
	mul.wide.u32 	%rd124, %r126, 4;
	add.s64 	%rd125, %rd123, %rd124;
	st.global.f32 	[%rd125], %f6;
$L__BB246_5:
	ret;

}
	// .globl	input_reduce_fusion_333
.visible .entry input_reduce_fusion_333(
	.param .u64 input_reduce_fusion_333_param_0,
	.param .u64 input_reduce_fusion_333_param_1,
	.param .u64 input_reduce_fusion_333_param_2,
	.param .u64 input_reduce_fusion_333_param_3
)
.reqntid 256, 1, 1
{
	.local .align 4 .b8 	__local_depot247[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<23>;
	.reg .b16 	%rs<16>;
	.reg .b32 	%r<127>;
	.reg .f32 	%f<59>;
	.reg .b64 	%rd<64>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot247;
	mov.u32 	%r36, %tid.x;
	mov.u32 	%r37, %ctaid.x;
	shr.u32 	%r1, %r36, 1;
	and.b32  	%r2, %r36, 1;
	setp.eq.s32 	%p1, %r37, 46;
	selp.b32 	%r3, 64, 128, %p1;
	shl.b32 	%r4, %r37, 7;
	setp.ge.u32 	%p2, %r1, %r3;
	mov.f32 	%f58, 0f00000000;
	@%p2 bra 	$L__BB247_18;
	ld.param.u64 	%rd16, [input_reduce_fusion_333_param_0];
	ld.param.u64 	%rd18, [input_reduce_fusion_333_param_1];
	ld.param.u64 	%rd19, [input_reduce_fusion_333_param_2];
	cvta.to.global.u64 	%rd2, %rd19;
	cvta.to.global.u64 	%rd3, %rd18;
	cvta.to.global.u64 	%rd4, %rd16;
	add.u64 	%rd5, %SPL, 0;
	or.b32  	%r38, %r1, %r4;
	cvt.u16.u32 	%rs1, %r38;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 16913;
	shr.u16 	%rs7, %rs6, 3;
	mul.lo.s16 	%rs8, %rs7, 31;
	sub.s16 	%rs9, %rs3, %rs8;
	mul.hi.u16 	%rs10, %rs1, 24665;
	sub.s16 	%rs11, %rs1, %rs10;
	shr.u16 	%rs12, %rs11, 1;
	add.s16 	%rs13, %rs12, %rs10;
	shr.u16 	%rs14, %rs13, 6;
	shl.b16 	%rs15, %rs5, 1;
	cvt.u32.u16 	%r39, %rs15;
	or.b32  	%r40, %r2, %r39;
	cvt.u64.u16 	%rd7, %rs14;
	cvt.u64.u16 	%rd8, %rs9;
	cvt.u64.u32 	%rd9, %r40;
	cvt.u32.u16 	%r41, %rs14;
	mul.wide.u32 	%rd22, %r41, 744;
	add.s64 	%rd23, %rd3, %rd22;
	cvt.u32.u16 	%r42, %rs9;
	mul.wide.u32 	%rd24, %r42, 24;
	add.s64 	%rd25, %rd23, %rd24;
	mul.wide.u32 	%rd26, %r40, 4;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.f32 	%f1, [%rd27];
	mul.wide.u32 	%rd28, %r41, 12;
	add.s64 	%rd29, %rd2, %rd28;
	cvt.u32.u16 	%r43, %rs5;
	mul.wide.u32 	%rd30, %r43, 4;
	add.s64 	%rd31, %rd29, %rd30;
	ld.global.nc.f32 	%f2, [%rd31];
	mul.rn.f32 	%f17, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r126, %f17;
	cvt.rn.f32.s32 	%f18, %r126;
	fma.rn.f32 	%f19, %f18, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f20, %f18, 0fB3A22168, %f19;
	fma.rn.f32 	%f57, %f18, 0fA7C234C5, %f20;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p3, %f4, 0f47CE4780;
	setp.neu.f32 	%p22, %f4, 0f7F800000;
	mov.u32 	%r122, %r126;
	mov.f32 	%f56, %f57;
	@%p3 bra 	$L__BB247_9;
	@%p22 bra 	$L__BB247_4;
	mov.f32 	%f23, 0f00000000;
	mul.rn.f32 	%f56, %f2, %f23;
	mov.b32 	%r122, 0;
	bra.uni 	$L__BB247_9;
$L__BB247_4:
	mov.b32 	%r6, %f2;
	shr.u32 	%r7, %r6, 23;
	and.b32  	%r45, %r7, 224;
	add.s32 	%r46, %r45, -128;
	shl.b32 	%r47, %r6, 8;
	or.b32  	%r51, %r47, -2147483648;
	shr.u32 	%r9, %r46, 5;
	mov.b32 	%r119, 0;
	mov.u64 	%rd62, 0;
	mov.u64 	%rd33, __cudart_i2opi_f;
$L__BB247_5:
	.pragma "nounroll";
	add.s64 	%rd34, %rd33, %rd62;
	ld.global.nc.u32 	%r50, [%rd34];
	// begin inline asm
	{
	mad.lo.cc.u32   %r48, %r50, %r51, %r119;
	madc.hi.u32     %r119, %r50, %r51,  0;
	}
	// end inline asm
	add.s64 	%rd35, %rd5, %rd62;
	st.local.u32 	[%rd35], %r48;
	add.s64 	%rd62, %rd62, 4;
	cvt.u32.u64 	%r53, %rd62;
	setp.ne.s32 	%p5, %r53, 24;
	@%p5 bra 	$L__BB247_5;
	st.local.u32 	[%rd5+24], %r119;
	and.b32  	%r12, %r7, 31;
	mul.wide.u32 	%rd36, %r9, 4;
	sub.s64 	%rd12, %rd5, %rd36;
	ld.local.u32 	%r120, [%rd12+24];
	ld.local.u32 	%r121, [%rd12+20];
	setp.eq.s32 	%p6, %r12, 0;
	@%p6 bra 	$L__BB247_8;
	shl.b32 	%r54, %r121, %r12;
	shl.b32 	%r55, %r120, %r12;
	mov.b32 	%r56, 32;
	sub.s32 	%r57, %r56, %r12;
	shr.u32 	%r58, %r121, %r57;
	add.s32 	%r120, %r58, %r55;
	ld.local.u32 	%r59, [%rd12+16];
	shr.u32 	%r60, %r59, %r57;
	add.s32 	%r121, %r60, %r54;
$L__BB247_8:
	shr.u32 	%r61, %r120, 30;
	shr.u32 	%r62, %r121, 30;
	shl.b32 	%r63, %r120, 2;
	or.b32  	%r64, %r63, %r62;
	shl.b32 	%r65, %r121, 2;
	bfe.u32 	%r66, %r120, 29, 1;
	add.s32 	%r67, %r66, %r61;
	neg.s32 	%r68, %r67;
	setp.lt.s32 	%p7, %r6, 0;
	selp.b32 	%r122, %r68, %r67, %p7;
	xor.b32  	%r69, %r64, %r6;
	bfe.s32 	%r70, %r120, 29, 1;
	xor.b32  	%r71, %r70, %r64;
	xor.b32  	%r72, %r70, %r65;
	cvt.u64.u32 	%rd37, %r71;
	shl.b64 	%rd38, %rd37, 32;
	cvt.u64.u32 	%rd39, %r72;
	or.b64  	%rd40, %rd38, %rd39;
	cvt.rn.f64.s64 	%fd1, %rd40;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f21, %fd2;
	neg.f32 	%f22, %f21;
	setp.lt.s32 	%p8, %r69, 0;
	selp.f32 	%f56, %f22, %f21, %p8;
$L__BB247_9:
	add.s32 	%r74, %r122, 1;
	mul.rn.f32 	%f24, %f56, %f56;
	and.b32  	%r75, %r122, 1;
	setp.eq.b32 	%p10, %r75, 1;
	selp.f32 	%f25, %f56, 0f3F800000, %p10;
	fma.rn.f32 	%f26, %f24, %f25, 0f00000000;
	fma.rn.f32 	%f27, %f24, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f28, 0fB94D4153, %f27, %p10;
	selp.f32 	%f29, 0f3C0885E4, 0f3D2AAABB, %p10;
	fma.rn.f32 	%f30, %f28, %f24, %f29;
	selp.f32 	%f31, 0fBE2AAAA8, 0fBEFFFFFF, %p10;
	fma.rn.f32 	%f32, %f30, %f24, %f31;
	fma.rn.f32 	%f33, %f32, %f26, %f25;
	and.b32  	%r76, %r74, 2;
	setp.eq.s32 	%p11, %r76, 0;
	mov.f32 	%f34, 0f00000000;
	sub.rn.f32 	%f35, %f34, %f33;
	selp.f32 	%f36, %f33, %f35, %p11;
	mul.rn.f32 	%f8, %f1, %f36;
	mul.lo.s64 	%rd41, %rd7, 744;
	add.s64 	%rd42, %rd4, %rd41;
	mul.lo.s64 	%rd43, %rd8, 24;
	add.s64 	%rd44, %rd42, %rd43;
	shl.b64 	%rd45, %rd9, 2;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.nc.f32 	%f9, [%rd46];
	@%p3 bra 	$L__BB247_17;
	@%p22 bra 	$L__BB247_12;
	mul.rn.f32 	%f57, %f2, %f34;
	mov.b32 	%r126, 0;
	bra.uni 	$L__BB247_17;
$L__BB247_12:
	mov.b32 	%r21, %f2;
	shr.u32 	%r22, %r21, 23;
	and.b32  	%r78, %r22, 224;
	add.s32 	%r79, %r78, -128;
	shl.b32 	%r80, %r21, 8;
	or.b32  	%r84, %r80, -2147483648;
	shr.u32 	%r24, %r79, 5;
	mov.b32 	%r123, 0;
	mov.u64 	%rd63, 0;
	mov.u64 	%rd48, __cudart_i2opi_f;
$L__BB247_13:
	.pragma "nounroll";
	add.s64 	%rd49, %rd48, %rd63;
	ld.global.nc.u32 	%r83, [%rd49];
	// begin inline asm
	{
	mad.lo.cc.u32   %r81, %r83, %r84, %r123;
	madc.hi.u32     %r123, %r83, %r84,  0;
	}
	// end inline asm
	add.s64 	%rd50, %rd5, %rd63;
	st.local.u32 	[%rd50], %r81;
	add.s64 	%rd63, %rd63, 4;
	cvt.u32.u64 	%r86, %rd63;
	setp.ne.s32 	%p13, %r86, 24;
	@%p13 bra 	$L__BB247_13;
	st.local.u32 	[%rd5+24], %r123;
	and.b32  	%r27, %r22, 31;
	mul.wide.u32 	%rd51, %r24, 4;
	sub.s64 	%rd15, %rd5, %rd51;
	ld.local.u32 	%r124, [%rd15+24];
	ld.local.u32 	%r125, [%rd15+20];
	setp.eq.s32 	%p14, %r27, 0;
	@%p14 bra 	$L__BB247_16;
	shl.b32 	%r87, %r125, %r27;
	shl.b32 	%r88, %r124, %r27;
	mov.b32 	%r89, 32;
	sub.s32 	%r90, %r89, %r27;
	shr.u32 	%r91, %r125, %r90;
	add.s32 	%r124, %r91, %r88;
	ld.local.u32 	%r92, [%rd15+16];
	shr.u32 	%r93, %r92, %r90;
	add.s32 	%r125, %r93, %r87;
$L__BB247_16:
	shr.u32 	%r94, %r124, 30;
	shr.u32 	%r95, %r125, 30;
	shl.b32 	%r96, %r124, 2;
	or.b32  	%r97, %r96, %r95;
	shl.b32 	%r98, %r125, 2;
	bfe.u32 	%r99, %r124, 29, 1;
	add.s32 	%r100, %r99, %r94;
	neg.s32 	%r101, %r100;
	setp.lt.s32 	%p15, %r21, 0;
	selp.b32 	%r126, %r101, %r100, %p15;
	xor.b32  	%r102, %r97, %r21;
	bfe.s32 	%r103, %r124, 29, 1;
	xor.b32  	%r104, %r103, %r97;
	xor.b32  	%r105, %r103, %r98;
	cvt.u64.u32 	%rd52, %r104;
	shl.b64 	%rd53, %rd52, 32;
	cvt.u64.u32 	%rd54, %r105;
	or.b64  	%rd55, %rd53, %rd54;
	cvt.rn.f64.s64 	%fd3, %rd55;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f37, %fd4;
	neg.f32 	%f38, %f37;
	setp.lt.s32 	%p16, %r102, 0;
	selp.f32 	%f57, %f38, %f37, %p16;
$L__BB247_17:
	mul.rn.f32 	%f40, %f57, %f57;
	and.b32  	%r107, %r126, 1;
	setp.eq.b32 	%p17, %r107, 1;
	selp.f32 	%f41, 0f3F800000, %f57, %p17;
	fma.rn.f32 	%f42, %f40, %f41, 0f00000000;
	fma.rn.f32 	%f43, %f40, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f44, %f43, 0fB94D4153, %p17;
	selp.f32 	%f45, 0f3D2AAABB, 0f3C0885E4, %p17;
	fma.rn.f32 	%f46, %f44, %f40, %f45;
	selp.f32 	%f47, 0fBEFFFFFF, 0fBE2AAAA8, %p17;
	fma.rn.f32 	%f48, %f46, %f40, %f47;
	fma.rn.f32 	%f49, %f48, %f42, %f41;
	and.b32  	%r108, %r126, 2;
	setp.eq.s32 	%p18, %r108, 0;
	sub.rn.f32 	%f51, %f34, %f49;
	selp.f32 	%f52, %f49, %f51, %p18;
	mul.rn.f32 	%f53, %f9, %f52;
	add.rn.f32 	%f54, %f8, %f53;
	add.rn.f32 	%f58, %f54, 0f00000000;
$L__BB247_18:
	shfl.sync.down.b32	%f15, %f58, 1, 31, -1;
	setp.ne.s32 	%p20, %r2, 0;
	or.pred  	%p21, %p20, %p2;
	@%p21 bra 	$L__BB247_20;
	ld.param.u64 	%rd17, [input_reduce_fusion_333_param_3];
	cvta.to.global.u64 	%rd1, %rd17;
	add.rn.f32 	%f55, %f58, %f15;
	or.b32  	%r109, %r4, %r1;
	mul.hi.u32 	%r110, %r109, 1431655766;
	mul.lo.s32 	%r111, %r110, 3;
	sub.s32 	%r112, %r109, %r111;
	mul.hi.u32 	%r113, %r110, 554189329;
	shr.u32 	%r114, %r113, 2;
	mul.lo.s32 	%r115, %r114, 31;
	sub.s32 	%r116, %r110, %r115;
	mul.hi.u32 	%r117, %r109, 738919105;
	shr.u32 	%r118, %r117, 4;
	mul.wide.u32 	%rd56, %r112, 124;
	mul.wide.u32 	%rd57, %r118, 372;
	add.s64 	%rd58, %rd1, %rd57;
	add.s64 	%rd59, %rd58, %rd56;
	mul.wide.u32 	%rd60, %r116, 4;
	add.s64 	%rd61, %rd59, %rd60;
	st.global.f32 	[%rd61], %f55;
$L__BB247_20:
	ret;

}
	// .globl	loop_add_fusion_377
.visible .entry loop_add_fusion_377(
	.param .u64 loop_add_fusion_377_param_0,
	.param .u64 loop_add_fusion_377_param_1,
	.param .u64 loop_add_fusion_377_param_2,
	.param .u64 loop_add_fusion_377_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<10>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<17>;
	.reg .b64 	%rd<35>;

	ld.param.u64 	%rd13, [loop_add_fusion_377_param_1];
	cvta.to.global.u64 	%rd3, %rd13;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	shl.b32 	%r6, %r4, 7;
	or.b32  	%r1, %r6, %r5;
	and.b32  	%r2, %r5, 63;
	shr.u32 	%r7, %r1, 6;
	cvt.u16.u32 	%rs1, %r7;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 9;
	mul.lo.s16 	%rs5, %rs4, 3;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r1;
	mul.hi.u16 	%rs8, %rs7, -21845;
	shr.u16 	%rs9, %rs8, 7;
	and.b32  	%r3, %r5, 1;
	setp.eq.s32 	%p1, %r3, 0;
	cvt.u64.u16 	%rd15, %rs6;
	mov.f32 	%f16, 0f00000000;
	mov.f32 	%f14, %f16;
	@%p1 bra 	$L__BB248_4;
	bra.uni 	$L__BB248_1;
$L__BB248_4:
	bfe.u32 	%r8, %r5, 1, 5;
	cvt.u32.u16 	%r9, %rs6;
	and.b32  	%r10, %r9, 255;
	mul.wide.u32 	%rd16, %r10, 128;
	cvt.u32.u16 	%r11, %rs9;
	mul.wide.u32 	%rd17, %r11, 384;
	add.s64 	%rd18, %rd3, %rd17;
	add.s64 	%rd19, %rd18, %rd16;
	mul.wide.u32 	%rd20, %r8, 4;
	add.s64 	%rd7, %rd19, %rd20;
	ld.global.nc.f32 	%f14, [%rd7];
$L__BB248_1:
	ld.param.u64 	%rd12, [loop_add_fusion_377_param_3];
	cvt.u64.u16 	%rd5, %rs9;
	and.b64  	%rd6, %rd15, 255;
	add.s32 	%r12, %r2, -1;
	and.b32  	%r13, %r12, 1;
	setp.eq.b32 	%p2, %r13, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f32 	%f15, %f16;
	@%p5 bra 	$L__BB248_5;
	bra.uni 	$L__BB248_2;
$L__BB248_5:
	ld.param.u64 	%rd14, [loop_add_fusion_377_param_2];
	cvta.to.global.u64 	%rd2, %rd14;
	shr.u32 	%r14, %r12, 1;
	mul.lo.s64 	%rd21, %rd5, 384;
	add.s64 	%rd22, %rd3, %rd21;
	shl.b64 	%rd23, %rd6, 7;
	add.s64 	%rd24, %rd22, %rd23;
	mul.wide.u32 	%rd25, %r14, 4;
	add.s64 	%rd8, %rd24, %rd25;
	add.s64 	%rd26, %rd2, %rd21;
	add.s64 	%rd27, %rd26, %rd23;
	add.s64 	%rd9, %rd27, %rd25;
	ld.global.nc.f32 	%f9, [%rd8];
	ld.global.nc.f32 	%f10, [%rd9];
	add.rn.f32 	%f15, %f9, %f10;
$L__BB248_2:
	cvta.to.global.u64 	%rd1, %rd12;
	setp.gt.u32 	%p7, %r2, 1;
	and.pred  	%p8, %p7, %p1;
	@%p8 bra 	$L__BB248_6;
	bra.uni 	$L__BB248_3;
$L__BB248_6:
	ld.param.u64 	%rd11, [loop_add_fusion_377_param_0];
	cvta.to.global.u64 	%rd4, %rd11;
	add.s32 	%r15, %r2, 254;
	bfe.u32 	%r16, %r15, 1, 7;
	mul.lo.s64 	%rd28, %rd5, 372;
	add.s64 	%rd29, %rd4, %rd28;
	mul.lo.s64 	%rd30, %rd6, 124;
	add.s64 	%rd31, %rd29, %rd30;
	mul.wide.u32 	%rd32, %r16, 4;
	add.s64 	%rd10, %rd31, %rd32;
	ld.global.nc.f32 	%f16, [%rd10];
$L__BB248_3:
	add.rn.f32 	%f12, %f14, %f15;
	add.rn.f32 	%f13, %f12, %f16;
	mul.wide.u32 	%rd33, %r1, 4;
	add.s64 	%rd34, %rd1, %rd33;
	st.global.f32 	[%rd34], %f13;
	ret;

}
	// .globl	input_reduce_fusion_334
.visible .entry input_reduce_fusion_334(
	.param .u64 input_reduce_fusion_334_param_0,
	.param .u64 input_reduce_fusion_334_param_1,
	.param .u64 input_reduce_fusion_334_param_2,
	.param .u64 input_reduce_fusion_334_param_3,
	.param .u64 input_reduce_fusion_334_param_4,
	.param .u64 input_reduce_fusion_334_param_5,
	.param .u64 input_reduce_fusion_334_param_6,
	.param .u64 input_reduce_fusion_334_param_7
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<22>;
	.reg .b32 	%r<32>;
	.reg .f32 	%f<46>;
	.reg .b64 	%rd<89>;
	// demoted variable
	.shared .align 4 .b8 shared_cache42[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache43[4224];
	ld.param.u64 	%rd18, [input_reduce_fusion_334_param_0];
	ld.param.u64 	%rd19, [input_reduce_fusion_334_param_7];
	cvta.to.global.u64 	%rd1, %rd19;
	ld.param.u64 	%rd20, [input_reduce_fusion_334_param_1];
	ld.param.u64 	%rd21, [input_reduce_fusion_334_param_6];
	cvta.to.global.u64 	%rd2, %rd21;
	ld.param.u64 	%rd22, [input_reduce_fusion_334_param_2];
	ld.param.u64 	%rd23, [input_reduce_fusion_334_param_5];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [input_reduce_fusion_334_param_3];
	ld.param.u64 	%rd26, [input_reduce_fusion_334_param_4];
	cvta.to.global.u64 	%rd27, %rd26;
	cvta.to.global.u64 	%rd28, %rd25;
	cvta.to.global.u64 	%rd29, %rd22;
	cvta.to.global.u64 	%rd30, %rd20;
	cvta.to.global.u64 	%rd31, %rd18;
	mov.u32 	%r8, %tid.x;
	mov.u32 	%r9, %ctaid.x;
	shr.u32 	%r1, %r8, 5;
	and.b32  	%r2, %r8, 31;
	cvt.u16.u32 	%rs1, %r9;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 3;
	mul.lo.s16 	%rs4, %rs3, 12;
	sub.s16 	%rs5, %rs1, %rs4;
	setp.eq.s16 	%p2, %rs5, 11;
	selp.b32 	%r3, 26, 32, %p2;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r4, %rs6;
	or.b32  	%r10, %r2, %r4;
	cvt.u16.u32 	%rs7, %r10;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r11, %rs10;
	cvt.u64.u16 	%rd3, %rs3;
	shr.u32 	%r12, %r11, 1;
	mul.wide.u32 	%rd32, %r12, 4;
	cvt.u32.u16 	%r13, %rs3;
	mul.wide.u32 	%rd33, %r13, 12;
	add.s64 	%rd34, %rd27, %rd33;
	add.s64 	%rd4, %rd34, %rd32;
	add.s64 	%rd35, %rd28, %rd33;
	add.s64 	%rd5, %rd35, %rd32;
	mul.wide.u32 	%rd36, %r13, 4;
	add.s64 	%rd6, %rd24, %rd36;
	add.s32 	%r31, %r1, -32;
	mul.wide.u32 	%rd37, %r13, 76800;
	cvt.u64.u32 	%rd38, %r8;
	shr.u64 	%rd39, %rd38, 5;
	mul.lo.s64 	%rd40, %rd39, 1536;
	add.s64 	%rd41, %rd37, %rd40;
	shl.b16 	%rs11, %rs1, 5;
	cvt.u16.u32 	%rs12, %r8;
	and.b16  	%rs13, %rs12, 31;
	or.b16  	%rs14, %rs11, %rs13;
	mul.lo.s16 	%rs15, %rs3, 384;
	sub.s16 	%rs16, %rs14, %rs15;
	cvt.u32.u16 	%r14, %rs16;
	mul.hi.u32 	%r15, %r14, 715827883;
	mul.wide.u32 	%rd42, %r15, 24;
	add.s64 	%rd43, %rd41, %rd42;
	mul.hi.u16 	%rs17, %rs16, -21845;
	shr.u16 	%rs18, %rs17, 2;
	mul.lo.s16 	%rs19, %rs18, 6;
	sub.s16 	%rs20, %rs14, %rs19;
	sub.s16 	%rs21, %rs20, %rs15;
	cvt.u32.u16 	%r16, %rs21;
	mul.wide.u32 	%rd44, %r16, 4;
	add.s64 	%rd45, %rd43, %rd44;
	add.s64 	%rd46, %rd45, %rd31;
	add.s64 	%rd88, %rd46, 24;
	add.s64 	%rd87, %rd29, %rd45;
	mul.wide.u32 	%rd47, %r13, 75600;
	mul.lo.s64 	%rd48, %rd39, 1512;
	add.s64 	%rd49, %rd47, %rd48;
	add.s64 	%rd50, %rd49, %rd42;
	and.b64  	%rd51, %rd44, 262136;
	add.s64 	%rd52, %rd50, %rd51;
	and.b32  	%r17, %r8, 1;
	mul.wide.u32 	%rd53, %r17, 4;
	or.b64  	%rd54, %rd52, %rd53;
	add.s64 	%rd86, %rd30, %rd54;
	mov.f32 	%f42, 0f00000000;
	setp.lt.u32 	%p3, %r2, %r3;
	mov.f32 	%f43, %f42;
	bra.uni 	$L__BB249_1;
$L__BB249_2:
	add.s32 	%r31, %r31, 32;
	add.s64 	%rd88, %rd88, 49152;
	add.s64 	%rd87, %rd87, 49152;
	add.s64 	%rd86, %rd86, 48384;
	setp.lt.u32 	%p4, %r31, 18;
	@%p4 bra 	$L__BB249_1;
	bra.uni 	$L__BB249_3;
$L__BB249_1:
	@%p3 bra 	$L__BB249_6;
	bra.uni 	$L__BB249_2;
$L__BB249_6:
	ld.global.nc.f32 	%f10, [%rd88];
	ld.global.nc.f32 	%f11, [%rd4];
	ld.global.nc.f32 	%f12, [%rd87];
	mul.rn.f32 	%f13, %f11, %f12;
	ld.global.nc.f32 	%f14, [%rd5];
	ld.global.nc.f32 	%f15, [%rd86];
	mul.rn.f32 	%f16, %f14, %f15;
	add.rn.f32 	%f17, %f13, %f16;
	mul.rn.f32 	%f18, %f10, %f17;
	add.rn.f32 	%f43, %f43, %f18;
	ld.global.nc.f32 	%f19, [%rd6];
	mul.rn.f32 	%f20, %f10, %f19;
	mul.rn.f32 	%f21, %f15, %f20;
	add.rn.f32 	%f42, %f42, %f21;
	bra.uni 	$L__BB249_2;
$L__BB249_3:
	cvt.u64.u32 	%rd16, %r2;
	cvt.u64.u32 	%rd17, %r1;
	mul.wide.u32 	%rd55, %r2, 132;
	mov.u64 	%rd56, shared_cache42;
	add.s64 	%rd57, %rd56, %rd55;
	mul.wide.u32 	%rd58, %r1, 4;
	add.s64 	%rd59, %rd57, %rd58;
	st.shared.f32 	[%rd59], %f43;
	bar.sync 	0;
	mul.wide.u32 	%rd60, %r1, 132;
	add.s64 	%rd61, %rd56, %rd60;
	mul.wide.u32 	%rd62, %r2, 4;
	add.s64 	%rd63, %rd61, %rd62;
	ld.shared.f32 	%f22, [%rd63];
	shfl.sync.down.b32	%f23, %f22, 16, 31, -1;
	add.rn.f32 	%f24, %f22, %f23;
	shfl.sync.down.b32	%f25, %f24, 8, 31, -1;
	add.rn.f32 	%f26, %f24, %f25;
	shfl.sync.down.b32	%f27, %f26, 4, 31, -1;
	add.rn.f32 	%f28, %f26, %f27;
	shfl.sync.down.b32	%f29, %f28, 2, 31, -1;
	add.rn.f32 	%f30, %f28, %f29;
	shfl.sync.down.b32	%f31, %f30, 1, 31, -1;
	add.rn.f32 	%f5, %f30, %f31;
	st.shared.f32 	[%rd63], %f5;
	setp.lt.u32 	%p5, %r1, %r3;
	setp.eq.s32 	%p6, %r2, 0;
	and.pred  	%p1, %p6, %p5;
	or.b32  	%r30, %r1, %r4;
	mul.lo.s64 	%rd85, %rd3, 1512;
	@%p1 bra 	$L__BB249_7;
	bra.uni 	$L__BB249_4;
$L__BB249_7:
	mul.hi.u32 	%r20, %r30, -1431655765;
	shr.u32 	%r21, %r20, 2;
	mul.lo.s32 	%r22, %r21, 6;
	sub.s32 	%r23, %r30, %r22;
	add.s64 	%rd65, %rd2, %rd85;
	mul.wide.u32 	%rd66, %r21, 24;
	add.s64 	%rd67, %rd65, %rd66;
	mul.wide.u32 	%rd68, %r23, 4;
	add.s64 	%rd69, %rd67, %rd68;
	st.global.f32 	[%rd69], %f5;
$L__BB249_4:
	mul.lo.s64 	%rd70, %rd16, 132;
	mov.u64 	%rd71, shared_cache43;
	add.s64 	%rd72, %rd71, %rd70;
	shl.b64 	%rd73, %rd17, 2;
	add.s64 	%rd74, %rd72, %rd73;
	st.shared.f32 	[%rd74], %f42;
	bar.sync 	0;
	mul.lo.s64 	%rd75, %rd17, 132;
	add.s64 	%rd76, %rd71, %rd75;
	shl.b64 	%rd77, %rd16, 2;
	add.s64 	%rd78, %rd76, %rd77;
	ld.shared.f32 	%f32, [%rd78];
	shfl.sync.down.b32	%f33, %f32, 16, 31, -1;
	add.rn.f32 	%f34, %f32, %f33;
	shfl.sync.down.b32	%f35, %f34, 8, 31, -1;
	add.rn.f32 	%f36, %f34, %f35;
	shfl.sync.down.b32	%f37, %f36, 4, 31, -1;
	add.rn.f32 	%f38, %f36, %f37;
	shfl.sync.down.b32	%f39, %f38, 2, 31, -1;
	add.rn.f32 	%f40, %f38, %f39;
	shfl.sync.down.b32	%f41, %f40, 1, 31, -1;
	add.rn.f32 	%f6, %f40, %f41;
	st.shared.f32 	[%rd78], %f6;
	@%p1 bra 	$L__BB249_8;
	bra.uni 	$L__BB249_5;
$L__BB249_8:
	mul.hi.u32 	%r26, %r30, -1431655765;
	shr.u32 	%r27, %r26, 2;
	mul.lo.s32 	%r28, %r27, 6;
	sub.s32 	%r29, %r30, %r28;
	add.s64 	%rd80, %rd1, %rd85;
	mul.wide.u32 	%rd81, %r27, 24;
	add.s64 	%rd82, %rd80, %rd81;
	mul.wide.u32 	%rd83, %r29, 4;
	add.s64 	%rd84, %rd82, %rd83;
	st.global.f32 	[%rd84], %f6;
$L__BB249_5:
	ret;

}
	// .globl	input_reduce_fusion_335
.visible .entry input_reduce_fusion_335(
	.param .u64 input_reduce_fusion_335_param_0,
	.param .u64 input_reduce_fusion_335_param_1,
	.param .u64 input_reduce_fusion_335_param_2,
	.param .u64 input_reduce_fusion_335_param_3
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<18>;
	.reg .b32 	%r<21>;
	.reg .f32 	%f<24>;
	.reg .b64 	%rd<45>;
	// demoted variable
	.shared .align 4 .b8 shared_cache44[4224];
	ld.param.u64 	%rd10, [input_reduce_fusion_335_param_0];
	ld.param.u64 	%rd11, [input_reduce_fusion_335_param_3];
	cvta.to.global.u64 	%rd1, %rd11;
	ld.param.u64 	%rd12, [input_reduce_fusion_335_param_1];
	ld.param.u64 	%rd13, [input_reduce_fusion_335_param_2];
	cvta.to.global.u64 	%rd14, %rd13;
	cvta.to.global.u64 	%rd15, %rd12;
	cvta.to.global.u64 	%rd16, %rd10;
	mov.u32 	%r8, %tid.x;
	mov.u32 	%r9, %ctaid.x;
	shr.u32 	%r1, %r8, 5;
	and.b32  	%r2, %r8, 31;
	cvt.u16.u32 	%rs1, %r9;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 3;
	mul.lo.s16 	%rs4, %rs3, 12;
	sub.s16 	%rs5, %rs1, %rs4;
	setp.eq.s16 	%p1, %rs5, 11;
	selp.b32 	%r3, 26, 32, %p1;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r4, %rs6;
	cvt.u64.u16 	%rd2, %rs3;
	cvt.u32.u16 	%r10, %rs3;
	mul.wide.u32 	%rd17, %r10, 4;
	add.s64 	%rd3, %rd14, %rd17;
	add.s32 	%r20, %r1, -32;
	mul.wide.u32 	%rd18, %r10, 76800;
	cvt.u64.u32 	%rd19, %r8;
	shr.u64 	%rd20, %rd19, 5;
	mul.lo.s64 	%rd21, %rd20, 1536;
	add.s64 	%rd22, %rd18, %rd21;
	shl.b16 	%rs7, %rs1, 5;
	cvt.u16.u32 	%rs8, %r8;
	and.b16  	%rs9, %rs8, 31;
	or.b16  	%rs10, %rs7, %rs9;
	mul.lo.s16 	%rs11, %rs3, 384;
	sub.s16 	%rs12, %rs10, %rs11;
	cvt.u32.u16 	%r11, %rs12;
	mul.hi.u32 	%r12, %r11, 715827883;
	mul.wide.u32 	%rd23, %r12, 24;
	add.s64 	%rd24, %rd22, %rd23;
	mul.hi.u16 	%rs13, %rs12, -21845;
	shr.u16 	%rs14, %rs13, 2;
	mul.lo.s16 	%rs15, %rs14, 6;
	sub.s16 	%rs16, %rs10, %rs15;
	sub.s16 	%rs17, %rs16, %rs11;
	cvt.u32.u16 	%r13, %rs17;
	mul.wide.u32 	%rd25, %r13, 4;
	add.s64 	%rd26, %rd24, %rd25;
	add.s64 	%rd27, %rd26, %rd15;
	add.s64 	%rd44, %rd27, 24;
	add.s64 	%rd43, %rd16, %rd26;
	mov.f32 	%f22, 0f00000000;
	setp.lt.u32 	%p2, %r2, %r3;
	bra.uni 	$L__BB250_1;
$L__BB250_2:
	add.s32 	%r20, %r20, 32;
	add.s64 	%rd44, %rd44, 49152;
	add.s64 	%rd43, %rd43, 49152;
	setp.lt.u32 	%p3, %r20, 18;
	@%p3 bra 	$L__BB250_1;
	bra.uni 	$L__BB250_3;
$L__BB250_1:
	@%p2 bra 	$L__BB250_5;
	bra.uni 	$L__BB250_2;
$L__BB250_5:
	ld.global.nc.f32 	%f6, [%rd3];
	ld.global.nc.f32 	%f7, [%rd44];
	mul.rn.f32 	%f8, %f6, %f7;
	ld.global.nc.f32 	%f9, [%rd43];
	mul.rn.f32 	%f10, %f8, %f9;
	add.rn.f32 	%f22, %f22, %f10;
	bra.uni 	$L__BB250_2;
$L__BB250_3:
	mul.wide.u32 	%rd28, %r2, 132;
	mov.u64 	%rd29, shared_cache44;
	add.s64 	%rd30, %rd29, %rd28;
	mul.wide.u32 	%rd31, %r1, 4;
	add.s64 	%rd32, %rd30, %rd31;
	st.shared.f32 	[%rd32], %f22;
	bar.sync 	0;
	mul.wide.u32 	%rd33, %r1, 132;
	add.s64 	%rd34, %rd29, %rd33;
	mul.wide.u32 	%rd35, %r2, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.shared.f32 	%f11, [%rd36];
	shfl.sync.down.b32	%f12, %f11, 16, 31, -1;
	add.rn.f32 	%f13, %f11, %f12;
	shfl.sync.down.b32	%f14, %f13, 8, 31, -1;
	add.rn.f32 	%f15, %f13, %f14;
	shfl.sync.down.b32	%f16, %f15, 4, 31, -1;
	add.rn.f32 	%f17, %f15, %f16;
	shfl.sync.down.b32	%f18, %f17, 2, 31, -1;
	add.rn.f32 	%f19, %f17, %f18;
	shfl.sync.down.b32	%f20, %f19, 1, 31, -1;
	add.rn.f32 	%f3, %f19, %f20;
	st.shared.f32 	[%rd36], %f3;
	setp.lt.u32 	%p4, %r1, %r3;
	setp.eq.s32 	%p5, %r2, 0;
	and.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB250_6;
	bra.uni 	$L__BB250_4;
$L__BB250_6:
	or.b32  	%r14, %r1, %r4;
	mul.hi.u32 	%r16, %r14, -1431655765;
	shr.u32 	%r17, %r16, 2;
	mul.lo.s32 	%r18, %r17, 6;
	sub.s32 	%r19, %r14, %r18;
	mul.lo.s64 	%rd37, %rd2, 1512;
	add.s64 	%rd38, %rd1, %rd37;
	mul.wide.u32 	%rd39, %r17, 24;
	add.s64 	%rd40, %rd38, %rd39;
	mul.wide.u32 	%rd41, %r19, 4;
	add.s64 	%rd42, %rd40, %rd41;
	neg.f32 	%f21, %f3;
	st.global.f32 	[%rd42], %f21;
$L__BB250_4:
	ret;

}
	// .globl	input_reduce_fusion_336
.visible .entry input_reduce_fusion_336(
	.param .u64 input_reduce_fusion_336_param_0,
	.param .u64 input_reduce_fusion_336_param_1,
	.param .u64 input_reduce_fusion_336_param_2,
	.param .u64 input_reduce_fusion_336_param_3,
	.param .u64 input_reduce_fusion_336_param_4
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<30>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<14>;
	.reg .b64 	%rd<32>;

	mov.u32 	%r5, %tid.x;
	mov.u32 	%r6, %ctaid.x;
	shr.u32 	%r1, %r5, 1;
	and.b32  	%r2, %r5, 1;
	setp.eq.s32 	%p1, %r6, 94;
	selp.b32 	%r3, 64, 128, %p1;
	shl.b32 	%r4, %r6, 7;
	setp.ge.u32 	%p2, %r1, %r3;
	mov.f32 	%f13, 0f00000000;
	@%p2 bra 	$L__BB251_2;
	ld.param.u64 	%rd6, [input_reduce_fusion_336_param_0];
	ld.param.u64 	%rd8, [input_reduce_fusion_336_param_1];
	ld.param.u64 	%rd9, [input_reduce_fusion_336_param_3];
	cvta.to.global.u64 	%rd2, %rd9;
	ld.param.u64 	%rd10, [input_reduce_fusion_336_param_2];
	cvta.to.global.u64 	%rd3, %rd10;
	cvta.to.global.u64 	%rd4, %rd8;
	cvta.to.global.u64 	%rd5, %rd6;
	or.b32  	%r7, %r1, %r4;
	cvt.u16.u32 	%rs1, %r7;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, -32247;
	shr.u16 	%rs7, %rs6, 5;
	mul.lo.s16 	%rs8, %rs7, 63;
	sub.s16 	%rs9, %rs3, %rs8;
	mul.hi.u16 	%rs10, %rs1, 23233;
	sub.s16 	%rs11, %rs1, %rs10;
	shr.u16 	%rs12, %rs11, 1;
	add.s16 	%rs13, %rs12, %rs10;
	shr.u16 	%rs14, %rs13, 7;
	shl.b16 	%rs15, %rs5, 1;
	cvt.u32.u16 	%r8, %rs15;
	or.b32  	%r9, %r2, %r8;
	cvt.u32.u16 	%r10, %rs14;
	mul.wide.u32 	%rd11, %r10, 1512;
	add.s64 	%rd12, %rd3, %rd11;
	cvt.u32.u16 	%r11, %rs9;
	mul.wide.u32 	%rd13, %r11, 24;
	add.s64 	%rd14, %rd12, %rd13;
	mul.wide.u32 	%rd15, %r9, 4;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.nc.f32 	%f5, [%rd16];
	mul.wide.u32 	%rd17, %r10, 12;
	add.s64 	%rd18, %rd2, %rd17;
	cvt.u32.u16 	%r12, %rs5;
	mul.wide.u32 	%rd19, %r12, 4;
	add.s64 	%rd20, %rd18, %rd19;
	ld.global.nc.f32 	%f6, [%rd20];
	mul.rn.f32 	%f7, %f5, %f6;
	add.s64 	%rd21, %rd4, %rd11;
	add.s64 	%rd22, %rd21, %rd13;
	add.s64 	%rd23, %rd22, %rd15;
	ld.global.nc.f32 	%f8, [%rd23];
	add.s64 	%rd24, %rd5, %rd17;
	add.s64 	%rd25, %rd24, %rd19;
	ld.global.nc.f32 	%f9, [%rd25];
	mul.rn.f32 	%f10, %f8, %f9;
	add.rn.f32 	%f11, %f7, %f10;
	add.rn.f32 	%f13, %f11, 0f00000000;
$L__BB251_2:
	shfl.sync.down.b32	%f3, %f13, 1, 31, -1;
	setp.ne.s32 	%p4, %r2, 0;
	or.pred  	%p5, %p4, %p2;
	@%p5 bra 	$L__BB251_4;
	ld.param.u64 	%rd7, [input_reduce_fusion_336_param_4];
	cvta.to.global.u64 	%rd1, %rd7;
	add.rn.f32 	%f12, %f13, %f3;
	or.b32  	%r13, %r4, %r1;
	cvt.u16.u32 	%rs16, %r13;
	mul.hi.u16 	%rs17, %rs16, -21845;
	shr.u16 	%rs18, %rs17, 1;
	mul.lo.s16 	%rs19, %rs18, 3;
	sub.s16 	%rs20, %rs16, %rs19;
	mul.hi.u16 	%rs21, %rs18, -32247;
	shr.u16 	%rs22, %rs21, 5;
	mul.lo.s16 	%rs23, %rs22, 63;
	sub.s16 	%rs24, %rs18, %rs23;
	mul.hi.u16 	%rs25, %rs16, 23233;
	sub.s16 	%rs26, %rs16, %rs25;
	shr.u16 	%rs27, %rs26, 1;
	add.s16 	%rs28, %rs27, %rs25;
	shr.u16 	%rs29, %rs28, 7;
	cvt.u32.u16 	%r14, %rs29;
	mul.wide.u32 	%rd26, %r14, 756;
	add.s64 	%rd27, %rd1, %rd26;
	cvt.u32.u16 	%r15, %rs20;
	mul.wide.u32 	%rd28, %r15, 252;
	add.s64 	%rd29, %rd27, %rd28;
	cvt.u32.u16 	%r16, %rs24;
	mul.wide.u32 	%rd30, %r16, 4;
	add.s64 	%rd31, %rd29, %rd30;
	st.global.f32 	[%rd31], %f12;
$L__BB251_4:
	ret;

}
	// .globl	loop_add_fusion_378
.visible .entry loop_add_fusion_378(
	.param .u64 loop_add_fusion_378_param_0,
	.param .u64 loop_add_fusion_378_param_1,
	.param .u64 loop_add_fusion_378_param_2,
	.param .u64 loop_add_fusion_378_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<15>;
	.reg .f32 	%f<17>;
	.reg .b64 	%rd<35>;

	ld.param.u64 	%rd13, [loop_add_fusion_378_param_1];
	cvta.to.global.u64 	%rd3, %rd13;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	cvt.u16.u32 	%rs1, %r1;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 9;
	mul.lo.s16 	%rs5, %rs4, 3;
	sub.s16 	%rs6, %rs1, %rs5;
	and.b32  	%r3, %r2, 1;
	setp.eq.s32 	%p1, %r3, 0;
	cvt.u64.u16 	%rd15, %rs6;
	mov.f32 	%f16, 0f00000000;
	mov.f32 	%f14, %f16;
	@%p1 bra 	$L__BB252_4;
	bra.uni 	$L__BB252_1;
$L__BB252_4:
	shr.u32 	%r4, %r2, 1;
	cvt.u32.u16 	%r5, %rs4;
	mul.wide.u32 	%rd16, %r5, 768;
	add.s64 	%rd17, %rd3, %rd16;
	cvt.u32.u16 	%r6, %rs6;
	and.b32  	%r7, %r6, 255;
	mul.wide.u32 	%rd18, %r7, 256;
	add.s64 	%rd19, %rd17, %rd18;
	mul.wide.u32 	%rd20, %r4, 4;
	add.s64 	%rd7, %rd19, %rd20;
	ld.global.nc.f32 	%f14, [%rd7];
$L__BB252_1:
	ld.param.u64 	%rd12, [loop_add_fusion_378_param_3];
	cvt.u64.u16 	%rd5, %rs4;
	and.b64  	%rd6, %rd15, 255;
	add.s32 	%r8, %r2, -1;
	and.b32  	%r9, %r8, 1;
	setp.eq.b32 	%p2, %r9, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f32 	%f15, %f16;
	@%p5 bra 	$L__BB252_5;
	bra.uni 	$L__BB252_2;
$L__BB252_5:
	ld.param.u64 	%rd14, [loop_add_fusion_378_param_2];
	cvta.to.global.u64 	%rd2, %rd14;
	shr.u32 	%r10, %r8, 1;
	mul.lo.s64 	%rd21, %rd5, 768;
	add.s64 	%rd22, %rd3, %rd21;
	shl.b64 	%rd23, %rd6, 8;
	add.s64 	%rd24, %rd22, %rd23;
	mul.wide.u32 	%rd25, %r10, 4;
	add.s64 	%rd8, %rd24, %rd25;
	add.s64 	%rd26, %rd2, %rd21;
	add.s64 	%rd27, %rd26, %rd23;
	add.s64 	%rd9, %rd27, %rd25;
	ld.global.nc.f32 	%f9, [%rd8];
	ld.global.nc.f32 	%f10, [%rd9];
	add.rn.f32 	%f15, %f9, %f10;
$L__BB252_2:
	cvta.to.global.u64 	%rd1, %rd12;
	setp.gt.u32 	%p7, %r2, 1;
	and.pred  	%p8, %p7, %p1;
	@%p8 bra 	$L__BB252_6;
	bra.uni 	$L__BB252_3;
$L__BB252_6:
	ld.param.u64 	%rd11, [loop_add_fusion_378_param_0];
	cvta.to.global.u64 	%rd4, %rd11;
	add.s32 	%r11, %r2, 254;
	bfe.u32 	%r12, %r11, 1, 7;
	mul.lo.s64 	%rd28, %rd5, 756;
	add.s64 	%rd29, %rd4, %rd28;
	mul.lo.s64 	%rd30, %rd6, 252;
	add.s64 	%rd31, %rd29, %rd30;
	mul.wide.u32 	%rd32, %r12, 4;
	add.s64 	%rd10, %rd31, %rd32;
	ld.global.nc.f32 	%f16, [%rd10];
$L__BB252_3:
	add.rn.f32 	%f12, %f14, %f15;
	shl.b32 	%r13, %r1, 7;
	or.b32  	%r14, %r13, %r2;
	add.rn.f32 	%f13, %f12, %f16;
	mul.wide.u32 	%rd33, %r14, 4;
	add.s64 	%rd34, %rd1, %rd33;
	st.global.f32 	[%rd34], %f13;
	ret;

}
	// .globl	input_reduce_fusion_337
.visible .entry input_reduce_fusion_337(
	.param .u64 input_reduce_fusion_337_param_0,
	.param .u64 input_reduce_fusion_337_param_1,
	.param .u64 input_reduce_fusion_337_param_2,
	.param .u64 input_reduce_fusion_337_param_3,
	.param .u64 input_reduce_fusion_337_param_4,
	.param .u64 input_reduce_fusion_337_param_5,
	.param .u64 input_reduce_fusion_337_param_6,
	.param .u64 input_reduce_fusion_337_param_7,
	.param .u64 input_reduce_fusion_337_param_8
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<11>;
	.reg .b16 	%rs<23>;
	.reg .b32 	%r<36>;
	.reg .f32 	%f<54>;
	.reg .b64 	%rd<101>;
	// demoted variable
	.shared .align 4 .b8 shared_cache45[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache46[4224];
	ld.param.u64 	%rd21, [input_reduce_fusion_337_param_0];
	ld.param.u64 	%rd22, [input_reduce_fusion_337_param_8];
	cvta.to.global.u64 	%rd1, %rd22;
	ld.param.u64 	%rd23, [input_reduce_fusion_337_param_1];
	ld.param.u64 	%rd24, [input_reduce_fusion_337_param_7];
	cvta.to.global.u64 	%rd2, %rd24;
	ld.param.u64 	%rd25, [input_reduce_fusion_337_param_2];
	ld.param.u64 	%rd26, [input_reduce_fusion_337_param_6];
	cvta.to.global.u64 	%rd27, %rd26;
	ld.param.u64 	%rd28, [input_reduce_fusion_337_param_3];
	ld.param.u64 	%rd29, [input_reduce_fusion_337_param_5];
	cvta.to.global.u64 	%rd30, %rd29;
	ld.param.u64 	%rd31, [input_reduce_fusion_337_param_4];
	cvta.to.global.u64 	%rd32, %rd31;
	cvta.to.global.u64 	%rd33, %rd28;
	cvta.to.global.u64 	%rd34, %rd25;
	cvta.to.global.u64 	%rd35, %rd23;
	cvta.to.global.u64 	%rd36, %rd21;
	mov.u32 	%r9, %tid.x;
	mov.u32 	%r10, %ctaid.x;
	shr.u32 	%r1, %r9, 5;
	and.b32  	%r2, %r9, 31;
	cvt.u16.u32 	%rs1, %r10;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 4;
	mul.lo.s16 	%rs4, %rs3, 24;
	sub.s16 	%rs5, %rs1, %rs4;
	setp.eq.s16 	%p3, %rs5, 23;
	selp.b32 	%r3, 26, 32, %p3;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r4, %rs6;
	or.b32  	%r11, %r2, %r4;
	cvt.u16.u32 	%rs7, %r11;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r12, %rs10;
	cvt.u32.u16 	%r13, %rs8;
	cvt.u64.u16 	%rd3, %rs3;
	shr.u32 	%r14, %r12, 1;
	mul.wide.u32 	%rd37, %r14, 4;
	cvt.u32.u16 	%r15, %rs3;
	mul.wide.u32 	%rd38, %r15, 12;
	add.s64 	%rd39, %rd30, %rd38;
	add.s64 	%rd4, %rd39, %rd37;
	and.b32  	%r5, %r13, 1;
	setp.gt.u32 	%p4, %r11, 5;
	and.b16  	%rs11, %rs8, 1;
	setp.eq.b16 	%p5, %rs11, 1;
	and.pred  	%p1, %p4, %p5;
	add.s64 	%rd40, %rd32, %rd38;
	add.s64 	%rd5, %rd40, %rd37;
	mul.wide.u32 	%rd41, %r15, 4;
	add.s64 	%rd6, %rd27, %rd41;
	add.s32 	%r35, %r1, -32;
	mul.wide.u32 	%rd42, %r15, 152400;
	cvt.u64.u32 	%rd43, %r9;
	shr.u64 	%rd44, %rd43, 5;
	mul.lo.s64 	%rd45, %rd44, 3048;
	add.s64 	%rd46, %rd42, %rd45;
	shl.b16 	%rs12, %rs1, 5;
	cvt.u16.u32 	%rs13, %r9;
	and.b16  	%rs14, %rs13, 31;
	or.b16  	%rs15, %rs12, %rs14;
	mul.lo.s16 	%rs16, %rs3, 768;
	sub.s16 	%rs17, %rs15, %rs16;
	cvt.u32.u16 	%r16, %rs17;
	mul.hi.u32 	%r17, %r16, 715827883;
	mul.wide.u32 	%rd47, %r17, 24;
	add.s64 	%rd48, %rd46, %rd47;
	mul.hi.u16 	%rs18, %rs17, -21845;
	shr.u16 	%rs19, %rs18, 2;
	mul.lo.s16 	%rs20, %rs19, 6;
	sub.s16 	%rs21, %rs15, %rs20;
	sub.s16 	%rs22, %rs21, %rs16;
	cvt.u32.u16 	%r18, %rs22;
	mul.wide.u32 	%rd49, %r18, 4;
	add.s64 	%rd50, %rd48, %rd49;
	add.s64 	%rd100, %rd36, %rd50;
	and.b64  	%rd51, %rd49, 262136;
	add.s64 	%rd52, %rd48, %rd51;
	and.b32  	%r19, %r9, 1;
	mul.wide.u32 	%rd53, %r19, 4;
	or.b64  	%rd54, %rd52, %rd53;
	add.s64 	%rd99, %rd35, %rd54;
	mul.wide.u32 	%rd55, %r15, 76800;
	mul.lo.s64 	%rd56, %rd44, 1536;
	add.s64 	%rd57, %rd55, %rd56;
	mul.hi.u32 	%r20, %r16, 357913942;
	mul.wide.u32 	%rd58, %r20, 24;
	add.s64 	%rd59, %rd57, %rd58;
	add.s64 	%rd60, %rd59, %rd49;
	add.s64 	%rd98, %rd33, %rd60;
	add.s32 	%r21, %r17, -1;
	cvt.u64.u32 	%rd61, %r21;
	shr.u64 	%rd62, %rd61, 1;
	mul.lo.s64 	%rd63, %rd62, 24;
	add.s64 	%rd64, %rd57, %rd63;
	add.s64 	%rd65, %rd64, %rd49;
	add.s64 	%rd97, %rd34, %rd65;
	mov.f32 	%f15, 0f00000000;
	setp.lt.u32 	%p6, %r2, %r3;
	setp.eq.s32 	%p7, %r5, 0;
	mov.f32 	%f1, %f15;
	mov.f32 	%f2, %f15;
	bra.uni 	$L__BB253_1;
$L__BB253_8:
	add.rn.f32 	%f18, %f52, %f53;
	mul.rn.f32 	%f19, %f8, %f18;
	ld.global.nc.f32 	%f20, [%rd5];
	ld.global.nc.f32 	%f21, [%rd99];
	mul.rn.f32 	%f22, %f20, %f21;
	add.rn.f32 	%f23, %f19, %f22;
	mul.rn.f32 	%f24, %f7, %f23;
	add.rn.f32 	%f2, %f2, %f24;
	ld.global.nc.f32 	%f25, [%rd6];
	mul.rn.f32 	%f26, %f7, %f25;
	mul.rn.f32 	%f27, %f21, %f26;
	add.rn.f32 	%f1, %f1, %f27;
$L__BB253_2:
	add.s32 	%r35, %r35, 32;
	add.s64 	%rd100, %rd100, 97536;
	add.s64 	%rd99, %rd99, 97536;
	add.s64 	%rd98, %rd98, 49152;
	add.s64 	%rd97, %rd97, 49152;
	setp.lt.u32 	%p8, %r35, 18;
	@%p8 bra 	$L__BB253_1;
	bra.uni 	$L__BB253_3;
$L__BB253_1:
	@%p6 bra 	$L__BB253_6;
	bra.uni 	$L__BB253_2;
$L__BB253_6:
	ld.global.nc.f32 	%f7, [%rd100];
	ld.global.nc.f32 	%f8, [%rd4];
	mov.f32 	%f52, %f15;
	@%p7 bra 	$L__BB253_9;
	bra.uni 	$L__BB253_7;
$L__BB253_9:
	ld.global.nc.f32 	%f52, [%rd98];
$L__BB253_7:
	mov.f32 	%f53, %f15;
	@%p1 bra 	$L__BB253_10;
	bra.uni 	$L__BB253_8;
$L__BB253_10:
	ld.global.nc.f32 	%f53, [%rd97];
	bra.uni 	$L__BB253_8;
$L__BB253_3:
	cvt.u64.u32 	%rd19, %r2;
	cvt.u64.u32 	%rd20, %r1;
	mul.wide.u32 	%rd66, %r2, 132;
	mov.u64 	%rd67, shared_cache45;
	add.s64 	%rd68, %rd67, %rd66;
	mul.wide.u32 	%rd69, %r1, 4;
	add.s64 	%rd70, %rd68, %rd69;
	st.shared.f32 	[%rd70], %f2;
	bar.sync 	0;
	mul.wide.u32 	%rd71, %r1, 132;
	add.s64 	%rd72, %rd67, %rd71;
	mul.wide.u32 	%rd73, %r2, 4;
	add.s64 	%rd74, %rd72, %rd73;
	ld.shared.f32 	%f28, [%rd74];
	shfl.sync.down.b32	%f29, %f28, 16, 31, -1;
	add.rn.f32 	%f30, %f28, %f29;
	shfl.sync.down.b32	%f31, %f30, 8, 31, -1;
	add.rn.f32 	%f32, %f30, %f31;
	shfl.sync.down.b32	%f33, %f32, 4, 31, -1;
	add.rn.f32 	%f34, %f32, %f33;
	shfl.sync.down.b32	%f35, %f34, 2, 31, -1;
	add.rn.f32 	%f36, %f34, %f35;
	shfl.sync.down.b32	%f37, %f36, 1, 31, -1;
	add.rn.f32 	%f5, %f36, %f37;
	st.shared.f32 	[%rd74], %f5;
	setp.lt.u32 	%p9, %r1, %r3;
	setp.eq.s32 	%p10, %r2, 0;
	and.pred  	%p2, %p10, %p9;
	or.b32  	%r34, %r1, %r4;
	mul.lo.s64 	%rd96, %rd3, 3048;
	@%p2 bra 	$L__BB253_11;
	bra.uni 	$L__BB253_4;
$L__BB253_11:
	mul.hi.u32 	%r24, %r34, -1431655765;
	shr.u32 	%r25, %r24, 2;
	mul.lo.s32 	%r26, %r25, 6;
	sub.s32 	%r27, %r34, %r26;
	add.s64 	%rd76, %rd2, %rd96;
	mul.wide.u32 	%rd77, %r25, 24;
	add.s64 	%rd78, %rd76, %rd77;
	mul.wide.u32 	%rd79, %r27, 4;
	add.s64 	%rd80, %rd78, %rd79;
	st.global.f32 	[%rd80], %f5;
$L__BB253_4:
	mul.lo.s64 	%rd81, %rd19, 132;
	mov.u64 	%rd82, shared_cache46;
	add.s64 	%rd83, %rd82, %rd81;
	shl.b64 	%rd84, %rd20, 2;
	add.s64 	%rd85, %rd83, %rd84;
	st.shared.f32 	[%rd85], %f1;
	bar.sync 	0;
	mul.lo.s64 	%rd86, %rd20, 132;
	add.s64 	%rd87, %rd82, %rd86;
	shl.b64 	%rd88, %rd19, 2;
	add.s64 	%rd89, %rd87, %rd88;
	ld.shared.f32 	%f38, [%rd89];
	shfl.sync.down.b32	%f39, %f38, 16, 31, -1;
	add.rn.f32 	%f40, %f38, %f39;
	shfl.sync.down.b32	%f41, %f40, 8, 31, -1;
	add.rn.f32 	%f42, %f40, %f41;
	shfl.sync.down.b32	%f43, %f42, 4, 31, -1;
	add.rn.f32 	%f44, %f42, %f43;
	shfl.sync.down.b32	%f45, %f44, 2, 31, -1;
	add.rn.f32 	%f46, %f44, %f45;
	shfl.sync.down.b32	%f47, %f46, 1, 31, -1;
	add.rn.f32 	%f6, %f46, %f47;
	st.shared.f32 	[%rd89], %f6;
	@%p2 bra 	$L__BB253_12;
	bra.uni 	$L__BB253_5;
$L__BB253_12:
	mul.hi.u32 	%r30, %r34, -1431655765;
	shr.u32 	%r31, %r30, 2;
	mul.lo.s32 	%r32, %r31, 6;
	sub.s32 	%r33, %r34, %r32;
	add.s64 	%rd91, %rd1, %rd96;
	mul.wide.u32 	%rd92, %r31, 24;
	add.s64 	%rd93, %rd91, %rd92;
	mul.wide.u32 	%rd94, %r33, 4;
	add.s64 	%rd95, %rd93, %rd94;
	st.global.f32 	[%rd95], %f6;
$L__BB253_5:
	ret;

}
	// .globl	input_reduce_fusion_338
.visible .entry input_reduce_fusion_338(
	.param .u64 input_reduce_fusion_338_param_0,
	.param .u64 input_reduce_fusion_338_param_1,
	.param .u64 input_reduce_fusion_338_param_2,
	.param .u64 input_reduce_fusion_338_param_3,
	.param .u64 input_reduce_fusion_338_param_4
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<24>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<14>;
	.reg .b64 	%rd<32>;

	mov.u32 	%r5, %tid.x;
	mov.u32 	%r6, %ctaid.x;
	shr.u32 	%r1, %r5, 1;
	and.b32  	%r2, %r5, 1;
	setp.eq.s32 	%p1, %r6, 190;
	selp.b32 	%r3, 64, 128, %p1;
	shl.b32 	%r4, %r6, 7;
	setp.ge.u32 	%p2, %r1, %r3;
	mov.f32 	%f13, 0f00000000;
	@%p2 bra 	$L__BB254_2;
	ld.param.u64 	%rd6, [input_reduce_fusion_338_param_0];
	ld.param.u64 	%rd8, [input_reduce_fusion_338_param_1];
	ld.param.u64 	%rd9, [input_reduce_fusion_338_param_3];
	cvta.to.global.u64 	%rd2, %rd9;
	ld.param.u64 	%rd10, [input_reduce_fusion_338_param_2];
	cvta.to.global.u64 	%rd3, %rd10;
	cvta.to.global.u64 	%rd4, %rd8;
	cvta.to.global.u64 	%rd5, %rd6;
	or.b32  	%r7, %r1, %r4;
	cvt.u16.u32 	%rs1, %r7;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, -32509;
	shr.u16 	%rs7, %rs6, 6;
	mul.lo.s16 	%rs8, %rs7, 127;
	sub.s16 	%rs9, %rs3, %rs8;
	mul.hi.u16 	%rs10, %rs1, -21501;
	shr.u16 	%rs11, %rs10, 8;
	shl.b16 	%rs12, %rs5, 1;
	cvt.u32.u16 	%r8, %rs12;
	or.b32  	%r9, %r2, %r8;
	cvt.u32.u16 	%r10, %rs9;
	mul.wide.u32 	%rd11, %r10, 24;
	cvt.u32.u16 	%r11, %rs11;
	mul.wide.u32 	%rd12, %r11, 3048;
	add.s64 	%rd13, %rd3, %rd12;
	add.s64 	%rd14, %rd13, %rd11;
	mul.wide.u32 	%rd15, %r9, 4;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.nc.f32 	%f5, [%rd16];
	cvt.u32.u16 	%r12, %rs5;
	mul.wide.u32 	%rd17, %r12, 4;
	mul.wide.u32 	%rd18, %r11, 12;
	add.s64 	%rd19, %rd2, %rd18;
	add.s64 	%rd20, %rd19, %rd17;
	ld.global.nc.f32 	%f6, [%rd20];
	mul.rn.f32 	%f7, %f5, %f6;
	add.s64 	%rd21, %rd4, %rd12;
	add.s64 	%rd22, %rd21, %rd11;
	add.s64 	%rd23, %rd22, %rd15;
	ld.global.nc.f32 	%f8, [%rd23];
	add.s64 	%rd24, %rd5, %rd18;
	add.s64 	%rd25, %rd24, %rd17;
	ld.global.nc.f32 	%f9, [%rd25];
	mul.rn.f32 	%f10, %f8, %f9;
	add.rn.f32 	%f11, %f7, %f10;
	add.rn.f32 	%f13, %f11, 0f00000000;
$L__BB254_2:
	shfl.sync.down.b32	%f3, %f13, 1, 31, -1;
	setp.ne.s32 	%p4, %r2, 0;
	or.pred  	%p5, %p4, %p2;
	@%p5 bra 	$L__BB254_4;
	ld.param.u64 	%rd7, [input_reduce_fusion_338_param_4];
	cvta.to.global.u64 	%rd1, %rd7;
	add.rn.f32 	%f12, %f13, %f3;
	or.b32  	%r13, %r4, %r1;
	cvt.u16.u32 	%rs13, %r13;
	mul.hi.u16 	%rs14, %rs13, -21845;
	shr.u16 	%rs15, %rs14, 1;
	mul.lo.s16 	%rs16, %rs15, 3;
	sub.s16 	%rs17, %rs13, %rs16;
	mul.hi.u16 	%rs18, %rs15, -32509;
	shr.u16 	%rs19, %rs18, 6;
	mul.lo.s16 	%rs20, %rs19, 127;
	sub.s16 	%rs21, %rs15, %rs20;
	mul.hi.u16 	%rs22, %rs13, -21501;
	shr.u16 	%rs23, %rs22, 8;
	cvt.u32.u16 	%r14, %rs17;
	mul.wide.u32 	%rd26, %r14, 508;
	cvt.u32.u16 	%r15, %rs23;
	mul.wide.u32 	%rd27, %r15, 1524;
	add.s64 	%rd28, %rd1, %rd27;
	add.s64 	%rd29, %rd28, %rd26;
	cvt.u32.u16 	%r16, %rs21;
	mul.wide.u32 	%rd30, %r16, 4;
	add.s64 	%rd31, %rd29, %rd30;
	st.global.f32 	[%rd31], %f12;
$L__BB254_4:
	ret;

}
	// .globl	loop_add_fusion_379
.visible .entry loop_add_fusion_379(
	.param .u64 loop_add_fusion_379_param_0,
	.param .u64 loop_add_fusion_379_param_1,
	.param .u64 loop_add_fusion_379_param_2,
	.param .u64 loop_add_fusion_379_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<10>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<17>;
	.reg .b64 	%rd<35>;

	ld.param.u64 	%rd13, [loop_add_fusion_379_param_1];
	cvta.to.global.u64 	%rd3, %rd13;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	shl.b32 	%r6, %r4, 7;
	or.b32  	%r1, %r6, %r5;
	and.b32  	%r2, %r1, 255;
	shr.u32 	%r7, %r4, 1;
	cvt.u16.u32 	%rs1, %r7;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 9;
	mul.lo.s16 	%rs5, %rs4, 3;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r4;
	mul.hi.u16 	%rs8, %rs7, -21845;
	shr.u16 	%rs9, %rs8, 2;
	and.b32  	%r3, %r5, 1;
	setp.eq.s32 	%p1, %r3, 0;
	cvt.u64.u16 	%rd15, %rs6;
	mov.f32 	%f16, 0f00000000;
	mov.f32 	%f14, %f16;
	@%p1 bra 	$L__BB255_4;
	bra.uni 	$L__BB255_1;
$L__BB255_4:
	bfe.u32 	%r8, %r1, 1, 7;
	cvt.u32.u16 	%r9, %rs9;
	mul.wide.u32 	%rd16, %r9, 1536;
	add.s64 	%rd17, %rd3, %rd16;
	cvt.u32.u16 	%r10, %rs6;
	and.b32  	%r11, %r10, 255;
	mul.wide.u32 	%rd18, %r11, 512;
	add.s64 	%rd19, %rd17, %rd18;
	mul.wide.u32 	%rd20, %r8, 4;
	add.s64 	%rd7, %rd19, %rd20;
	ld.global.nc.f32 	%f14, [%rd7];
$L__BB255_1:
	ld.param.u64 	%rd12, [loop_add_fusion_379_param_3];
	cvt.u64.u16 	%rd5, %rs9;
	and.b64  	%rd6, %rd15, 255;
	add.s32 	%r12, %r2, -1;
	and.b32  	%r13, %r12, 1;
	setp.eq.b32 	%p2, %r13, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f32 	%f15, %f16;
	@%p5 bra 	$L__BB255_5;
	bra.uni 	$L__BB255_2;
$L__BB255_5:
	ld.param.u64 	%rd14, [loop_add_fusion_379_param_2];
	cvta.to.global.u64 	%rd2, %rd14;
	shr.u32 	%r14, %r12, 1;
	mul.lo.s64 	%rd21, %rd5, 1536;
	add.s64 	%rd22, %rd3, %rd21;
	shl.b64 	%rd23, %rd6, 9;
	add.s64 	%rd24, %rd22, %rd23;
	mul.wide.u32 	%rd25, %r14, 4;
	add.s64 	%rd8, %rd24, %rd25;
	add.s64 	%rd26, %rd2, %rd21;
	add.s64 	%rd27, %rd26, %rd23;
	add.s64 	%rd9, %rd27, %rd25;
	ld.global.nc.f32 	%f9, [%rd8];
	ld.global.nc.f32 	%f10, [%rd9];
	add.rn.f32 	%f15, %f9, %f10;
$L__BB255_2:
	cvta.to.global.u64 	%rd1, %rd12;
	setp.gt.u32 	%p7, %r2, 1;
	and.pred  	%p8, %p1, %p7;
	@%p8 bra 	$L__BB255_6;
	bra.uni 	$L__BB255_3;
$L__BB255_6:
	ld.param.u64 	%rd11, [loop_add_fusion_379_param_0];
	cvta.to.global.u64 	%rd4, %rd11;
	add.s32 	%r15, %r1, 254;
	bfe.u32 	%r16, %r15, 1, 7;
	mul.lo.s64 	%rd28, %rd5, 1524;
	add.s64 	%rd29, %rd4, %rd28;
	mul.lo.s64 	%rd30, %rd6, 508;
	add.s64 	%rd31, %rd29, %rd30;
	mul.wide.u32 	%rd32, %r16, 4;
	add.s64 	%rd10, %rd31, %rd32;
	ld.global.nc.f32 	%f16, [%rd10];
$L__BB255_3:
	add.rn.f32 	%f12, %f14, %f15;
	add.rn.f32 	%f13, %f12, %f16;
	mul.wide.u32 	%rd33, %r1, 4;
	add.s64 	%rd34, %rd1, %rd33;
	st.global.f32 	[%rd34], %f13;
	ret;

}
	// .globl	input_reduce_fusion_339
.visible .entry input_reduce_fusion_339(
	.param .u64 input_reduce_fusion_339_param_0,
	.param .u64 input_reduce_fusion_339_param_1,
	.param .u64 input_reduce_fusion_339_param_2,
	.param .u64 input_reduce_fusion_339_param_3
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<18>;
	.reg .b32 	%r<21>;
	.reg .f32 	%f<24>;
	.reg .b64 	%rd<49>;
	// demoted variable
	.shared .align 4 .b8 shared_cache47[4224];
	ld.param.u64 	%rd10, [input_reduce_fusion_339_param_0];
	ld.param.u64 	%rd11, [input_reduce_fusion_339_param_3];
	cvta.to.global.u64 	%rd1, %rd11;
	ld.param.u64 	%rd12, [input_reduce_fusion_339_param_1];
	ld.param.u64 	%rd13, [input_reduce_fusion_339_param_2];
	cvta.to.global.u64 	%rd14, %rd13;
	cvta.to.global.u64 	%rd15, %rd12;
	cvta.to.global.u64 	%rd16, %rd10;
	mov.u32 	%r8, %tid.x;
	mov.u32 	%r9, %ctaid.x;
	shr.u32 	%r1, %r8, 5;
	and.b32  	%r2, %r8, 31;
	cvt.u16.u32 	%rs1, %r9;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 5;
	mul.lo.s16 	%rs4, %rs3, 48;
	sub.s16 	%rs5, %rs1, %rs4;
	setp.eq.s16 	%p1, %rs5, 47;
	selp.b32 	%r3, 26, 32, %p1;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r4, %rs6;
	cvt.u64.u16 	%rd2, %rs3;
	cvt.u32.u16 	%r10, %rs3;
	mul.wide.u32 	%rd17, %r10, 4;
	add.s64 	%rd3, %rd14, %rd17;
	add.s32 	%r20, %r1, -32;
	mul.wide.u32 	%rd18, %r10, 306000;
	cvt.u64.u32 	%rd19, %r8;
	shr.u64 	%rd20, %rd19, 5;
	mul.lo.s64 	%rd21, %rd20, 6120;
	add.s64 	%rd22, %rd18, %rd21;
	shl.b16 	%rs7, %rs1, 5;
	cvt.u16.u32 	%rs8, %r8;
	and.b16  	%rs9, %rs8, 31;
	or.b16  	%rs10, %rs7, %rs9;
	mul.lo.s16 	%rs11, %rs3, 1536;
	sub.s16 	%rs12, %rs10, %rs11;
	cvt.u32.u16 	%r11, %rs12;
	mul.hi.u32 	%r12, %r11, 715827883;
	mul.wide.u32 	%rd23, %r12, 24;
	add.s64 	%rd24, %rd22, %rd23;
	mul.hi.u16 	%rs13, %rs12, -21845;
	shr.u16 	%rs14, %rs13, 2;
	mul.lo.s16 	%rs15, %rs14, 6;
	sub.s16 	%rs16, %rs10, %rs15;
	sub.s16 	%rs17, %rs16, %rs11;
	cvt.u32.u16 	%r13, %rs17;
	mul.wide.u32 	%rd25, %r13, 4;
	add.s64 	%rd26, %rd24, %rd25;
	add.s64 	%rd48, %rd15, %rd26;
	mul.wide.u32 	%rd27, %r10, 307200;
	mul.lo.s64 	%rd28, %rd20, 6144;
	add.s64 	%rd29, %rd27, %rd28;
	add.s64 	%rd30, %rd29, %rd23;
	add.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd47, %rd16, %rd31;
	mov.f32 	%f22, 0f00000000;
	setp.lt.u32 	%p2, %r2, %r3;
	bra.uni 	$L__BB256_1;
$L__BB256_2:
	add.s32 	%r20, %r20, 32;
	add.s64 	%rd48, %rd48, 195840;
	add.s64 	%rd47, %rd47, 196608;
	setp.lt.u32 	%p3, %r20, 18;
	@%p3 bra 	$L__BB256_1;
	bra.uni 	$L__BB256_3;
$L__BB256_1:
	@%p2 bra 	$L__BB256_5;
	bra.uni 	$L__BB256_2;
$L__BB256_5:
	ld.global.nc.f32 	%f6, [%rd3];
	ld.global.nc.f32 	%f7, [%rd48];
	mul.rn.f32 	%f8, %f6, %f7;
	ld.global.nc.f32 	%f9, [%rd47];
	mul.rn.f32 	%f10, %f8, %f9;
	add.rn.f32 	%f22, %f22, %f10;
	bra.uni 	$L__BB256_2;
$L__BB256_3:
	mul.wide.u32 	%rd32, %r2, 132;
	mov.u64 	%rd33, shared_cache47;
	add.s64 	%rd34, %rd33, %rd32;
	mul.wide.u32 	%rd35, %r1, 4;
	add.s64 	%rd36, %rd34, %rd35;
	st.shared.f32 	[%rd36], %f22;
	bar.sync 	0;
	mul.wide.u32 	%rd37, %r1, 132;
	add.s64 	%rd38, %rd33, %rd37;
	mul.wide.u32 	%rd39, %r2, 4;
	add.s64 	%rd40, %rd38, %rd39;
	ld.shared.f32 	%f11, [%rd40];
	shfl.sync.down.b32	%f12, %f11, 16, 31, -1;
	add.rn.f32 	%f13, %f11, %f12;
	shfl.sync.down.b32	%f14, %f13, 8, 31, -1;
	add.rn.f32 	%f15, %f13, %f14;
	shfl.sync.down.b32	%f16, %f15, 4, 31, -1;
	add.rn.f32 	%f17, %f15, %f16;
	shfl.sync.down.b32	%f18, %f17, 2, 31, -1;
	add.rn.f32 	%f19, %f17, %f18;
	shfl.sync.down.b32	%f20, %f19, 1, 31, -1;
	add.rn.f32 	%f3, %f19, %f20;
	st.shared.f32 	[%rd40], %f3;
	setp.lt.u32 	%p4, %r1, %r3;
	setp.eq.s32 	%p5, %r2, 0;
	and.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB256_6;
	bra.uni 	$L__BB256_4;
$L__BB256_6:
	or.b32  	%r14, %r1, %r4;
	mul.hi.u32 	%r16, %r14, -1431655765;
	shr.u32 	%r17, %r16, 2;
	mul.lo.s32 	%r18, %r17, 6;
	sub.s32 	%r19, %r14, %r18;
	mul.lo.s64 	%rd41, %rd2, 6120;
	add.s64 	%rd42, %rd1, %rd41;
	mul.wide.u32 	%rd43, %r17, 24;
	add.s64 	%rd44, %rd42, %rd43;
	mul.wide.u32 	%rd45, %r19, 4;
	add.s64 	%rd46, %rd44, %rd45;
	neg.f32 	%f21, %f3;
	st.global.f32 	[%rd46], %f21;
$L__BB256_4:
	ret;

}
	// .globl	input_reduce_fusion_340
.visible .entry input_reduce_fusion_340(
	.param .u64 input_reduce_fusion_340_param_0,
	.param .u64 input_reduce_fusion_340_param_1,
	.param .u64 input_reduce_fusion_340_param_2,
	.param .u64 input_reduce_fusion_340_param_3,
	.param .u64 input_reduce_fusion_340_param_4
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<30>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<14>;
	.reg .b64 	%rd<32>;

	mov.u32 	%r5, %tid.x;
	mov.u32 	%r6, %ctaid.x;
	shr.u32 	%r1, %r5, 1;
	and.b32  	%r2, %r5, 1;
	setp.eq.s32 	%p1, %r6, 382;
	selp.b32 	%r3, 64, 128, %p1;
	shl.b32 	%r4, %r6, 7;
	setp.ge.u32 	%p2, %r1, %r3;
	mov.f32 	%f13, 0f00000000;
	@%p2 bra 	$L__BB257_2;
	ld.param.u64 	%rd6, [input_reduce_fusion_340_param_0];
	ld.param.u64 	%rd8, [input_reduce_fusion_340_param_1];
	ld.param.u64 	%rd9, [input_reduce_fusion_340_param_3];
	cvta.to.global.u64 	%rd2, %rd9;
	ld.param.u64 	%rd10, [input_reduce_fusion_340_param_2];
	cvta.to.global.u64 	%rd3, %rd10;
	cvta.to.global.u64 	%rd4, %rd8;
	cvta.to.global.u64 	%rd5, %rd6;
	or.b32  	%r7, %r1, %r4;
	cvt.u16.u32 	%rs1, %r7;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 1;
	mul.lo.s16 	%rs4, %rs3, 3;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, -32639;
	shr.u16 	%rs7, %rs6, 7;
	mul.lo.s16 	%rs8, %rs7, 255;
	sub.s16 	%rs9, %rs3, %rs8;
	mul.hi.u16 	%rs10, %rs1, 22189;
	sub.s16 	%rs11, %rs1, %rs10;
	shr.u16 	%rs12, %rs11, 1;
	add.s16 	%rs13, %rs12, %rs10;
	shr.u16 	%rs14, %rs13, 9;
	shl.b16 	%rs15, %rs5, 1;
	cvt.u32.u16 	%r8, %rs15;
	or.b32  	%r9, %r2, %r8;
	cvt.u32.u16 	%r10, %rs14;
	mul.wide.u32 	%rd11, %r10, 6120;
	add.s64 	%rd12, %rd3, %rd11;
	cvt.u32.u16 	%r11, %rs9;
	mul.wide.u32 	%rd13, %r11, 24;
	add.s64 	%rd14, %rd12, %rd13;
	mul.wide.u32 	%rd15, %r9, 4;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.nc.f32 	%f5, [%rd16];
	mul.wide.u32 	%rd17, %r10, 12;
	add.s64 	%rd18, %rd2, %rd17;
	cvt.u32.u16 	%r12, %rs5;
	mul.wide.u32 	%rd19, %r12, 4;
	add.s64 	%rd20, %rd18, %rd19;
	ld.global.nc.f32 	%f6, [%rd20];
	mul.rn.f32 	%f7, %f5, %f6;
	add.s64 	%rd21, %rd4, %rd11;
	add.s64 	%rd22, %rd21, %rd13;
	add.s64 	%rd23, %rd22, %rd15;
	ld.global.nc.f32 	%f8, [%rd23];
	add.s64 	%rd24, %rd5, %rd17;
	add.s64 	%rd25, %rd24, %rd19;
	ld.global.nc.f32 	%f9, [%rd25];
	mul.rn.f32 	%f10, %f8, %f9;
	add.rn.f32 	%f11, %f7, %f10;
	add.rn.f32 	%f13, %f11, 0f00000000;
$L__BB257_2:
	shfl.sync.down.b32	%f3, %f13, 1, 31, -1;
	setp.ne.s32 	%p4, %r2, 0;
	or.pred  	%p5, %p4, %p2;
	@%p5 bra 	$L__BB257_4;
	ld.param.u64 	%rd7, [input_reduce_fusion_340_param_4];
	cvta.to.global.u64 	%rd1, %rd7;
	add.rn.f32 	%f12, %f13, %f3;
	or.b32  	%r13, %r4, %r1;
	cvt.u16.u32 	%rs16, %r13;
	mul.hi.u16 	%rs17, %rs16, -21845;
	shr.u16 	%rs18, %rs17, 1;
	mul.lo.s16 	%rs19, %rs18, 3;
	sub.s16 	%rs20, %rs16, %rs19;
	mul.hi.u16 	%rs21, %rs18, -32639;
	shr.u16 	%rs22, %rs21, 7;
	mul.lo.s16 	%rs23, %rs22, 255;
	sub.s16 	%rs24, %rs18, %rs23;
	mul.hi.u16 	%rs25, %rs16, 22189;
	sub.s16 	%rs26, %rs16, %rs25;
	shr.u16 	%rs27, %rs26, 1;
	add.s16 	%rs28, %rs27, %rs25;
	shr.u16 	%rs29, %rs28, 9;
	cvt.u32.u16 	%r14, %rs29;
	mul.wide.u32 	%rd26, %r14, 3060;
	add.s64 	%rd27, %rd1, %rd26;
	cvt.u32.u16 	%r15, %rs20;
	mul.wide.u32 	%rd28, %r15, 1020;
	add.s64 	%rd29, %rd27, %rd28;
	cvt.u32.u16 	%r16, %rs24;
	mul.wide.u32 	%rd30, %r16, 4;
	add.s64 	%rd31, %rd29, %rd30;
	st.global.f32 	[%rd31], %f12;
$L__BB257_4:
	ret;

}
	// .globl	loop_add_fusion_380
.visible .entry loop_add_fusion_380(
	.param .u64 loop_add_fusion_380_param_0,
	.param .u64 loop_add_fusion_380_param_1,
	.param .u64 loop_add_fusion_380_param_2,
	.param .u64 loop_add_fusion_380_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<10>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<17>;
	.reg .b64 	%rd<35>;

	ld.param.u64 	%rd13, [loop_add_fusion_380_param_1];
	cvta.to.global.u64 	%rd3, %rd13;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	shl.b32 	%r6, %r4, 7;
	or.b32  	%r1, %r6, %r5;
	and.b32  	%r2, %r1, 511;
	shr.u32 	%r7, %r4, 2;
	cvt.u16.u32 	%rs1, %r7;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 9;
	mul.lo.s16 	%rs5, %rs4, 3;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r4;
	mul.hi.u16 	%rs8, %rs7, -21845;
	shr.u16 	%rs9, %rs8, 3;
	and.b32  	%r3, %r5, 1;
	setp.eq.s32 	%p1, %r3, 0;
	cvt.u64.u16 	%rd15, %rs6;
	mov.f32 	%f16, 0f00000000;
	mov.f32 	%f14, %f16;
	@%p1 bra 	$L__BB258_4;
	bra.uni 	$L__BB258_1;
$L__BB258_4:
	bfe.u32 	%r8, %r1, 1, 8;
	cvt.u32.u16 	%r9, %rs9;
	mul.wide.u32 	%rd16, %r9, 3072;
	add.s64 	%rd17, %rd3, %rd16;
	cvt.u32.u16 	%r10, %rs6;
	and.b32  	%r11, %r10, 255;
	mul.wide.u32 	%rd18, %r11, 1024;
	add.s64 	%rd19, %rd17, %rd18;
	mul.wide.u32 	%rd20, %r8, 4;
	add.s64 	%rd7, %rd19, %rd20;
	ld.global.nc.f32 	%f14, [%rd7];
$L__BB258_1:
	ld.param.u64 	%rd12, [loop_add_fusion_380_param_3];
	cvt.u64.u16 	%rd5, %rs9;
	and.b64  	%rd6, %rd15, 255;
	add.s32 	%r12, %r2, -1;
	and.b32  	%r13, %r12, 1;
	setp.eq.b32 	%p2, %r13, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f32 	%f15, %f16;
	@%p5 bra 	$L__BB258_5;
	bra.uni 	$L__BB258_2;
$L__BB258_5:
	ld.param.u64 	%rd14, [loop_add_fusion_380_param_2];
	cvta.to.global.u64 	%rd2, %rd14;
	shr.u32 	%r14, %r12, 1;
	mul.lo.s64 	%rd21, %rd5, 3072;
	add.s64 	%rd22, %rd3, %rd21;
	shl.b64 	%rd23, %rd6, 10;
	add.s64 	%rd24, %rd22, %rd23;
	mul.wide.u32 	%rd25, %r14, 4;
	add.s64 	%rd8, %rd24, %rd25;
	add.s64 	%rd26, %rd2, %rd21;
	add.s64 	%rd27, %rd26, %rd23;
	add.s64 	%rd9, %rd27, %rd25;
	ld.global.nc.f32 	%f9, [%rd8];
	ld.global.nc.f32 	%f10, [%rd9];
	add.rn.f32 	%f15, %f9, %f10;
$L__BB258_2:
	cvta.to.global.u64 	%rd1, %rd12;
	setp.gt.u32 	%p7, %r2, 1;
	and.pred  	%p8, %p1, %p7;
	@%p8 bra 	$L__BB258_6;
	bra.uni 	$L__BB258_3;
$L__BB258_6:
	ld.param.u64 	%rd11, [loop_add_fusion_380_param_0];
	cvta.to.global.u64 	%rd4, %rd11;
	add.s32 	%r15, %r2, 65534;
	bfe.u32 	%r16, %r15, 1, 15;
	mul.lo.s64 	%rd28, %rd5, 3060;
	add.s64 	%rd29, %rd4, %rd28;
	mul.lo.s64 	%rd30, %rd6, 1020;
	add.s64 	%rd31, %rd29, %rd30;
	mul.wide.u32 	%rd32, %r16, 4;
	add.s64 	%rd10, %rd31, %rd32;
	ld.global.nc.f32 	%f16, [%rd10];
$L__BB258_3:
	add.rn.f32 	%f12, %f14, %f15;
	add.rn.f32 	%f13, %f12, %f16;
	mul.wide.u32 	%rd33, %r1, 4;
	add.s64 	%rd34, %rd1, %rd33;
	st.global.f32 	[%rd34], %f13;
	ret;

}
	// .globl	input_reduce_fusion_341
.visible .entry input_reduce_fusion_341(
	.param .u64 input_reduce_fusion_341_param_0,
	.param .u64 input_reduce_fusion_341_param_1,
	.param .u64 input_reduce_fusion_341_param_2,
	.param .u64 input_reduce_fusion_341_param_3,
	.param .u64 input_reduce_fusion_341_param_4,
	.param .u64 input_reduce_fusion_341_param_5,
	.param .u64 input_reduce_fusion_341_param_6,
	.param .u64 input_reduce_fusion_341_param_7,
	.param .u64 input_reduce_fusion_341_param_8
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<11>;
	.reg .b16 	%rs<23>;
	.reg .b32 	%r<36>;
	.reg .f32 	%f<54>;
	.reg .b64 	%rd<107>;
	// demoted variable
	.shared .align 4 .b8 shared_cache48[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache49[4224];
	ld.param.u64 	%rd21, [input_reduce_fusion_341_param_0];
	ld.param.u64 	%rd22, [input_reduce_fusion_341_param_8];
	cvta.to.global.u64 	%rd1, %rd22;
	ld.param.u64 	%rd23, [input_reduce_fusion_341_param_1];
	ld.param.u64 	%rd24, [input_reduce_fusion_341_param_7];
	cvta.to.global.u64 	%rd2, %rd24;
	ld.param.u64 	%rd25, [input_reduce_fusion_341_param_2];
	ld.param.u64 	%rd26, [input_reduce_fusion_341_param_6];
	cvta.to.global.u64 	%rd27, %rd26;
	ld.param.u64 	%rd28, [input_reduce_fusion_341_param_3];
	ld.param.u64 	%rd29, [input_reduce_fusion_341_param_5];
	cvta.to.global.u64 	%rd30, %rd29;
	ld.param.u64 	%rd31, [input_reduce_fusion_341_param_4];
	cvta.to.global.u64 	%rd32, %rd31;
	cvta.to.global.u64 	%rd33, %rd28;
	cvta.to.global.u64 	%rd34, %rd25;
	cvta.to.global.u64 	%rd35, %rd23;
	cvta.to.global.u64 	%rd36, %rd21;
	mov.u32 	%r9, %tid.x;
	mov.u32 	%r10, %ctaid.x;
	shr.u32 	%r1, %r9, 5;
	and.b32  	%r2, %r9, 31;
	cvt.u16.u32 	%rs1, %r10;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 6;
	mul.lo.s16 	%rs4, %rs3, 96;
	sub.s16 	%rs5, %rs1, %rs4;
	setp.eq.s16 	%p3, %rs5, 95;
	selp.b32 	%r3, 26, 32, %p3;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r4, %rs6;
	or.b32  	%r11, %r2, %r4;
	cvt.u16.u32 	%rs7, %r11;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r12, %rs10;
	cvt.u32.u16 	%r13, %rs8;
	cvt.u64.u16 	%rd3, %rs3;
	cvt.u32.u16 	%r14, %rs3;
	mul.wide.u32 	%rd37, %r14, 4;
	add.s64 	%rd4, %rd34, %rd37;
	shr.u32 	%r15, %r12, 1;
	mul.wide.u32 	%rd38, %r15, 4;
	mul.wide.u32 	%rd39, %r14, 12;
	add.s64 	%rd40, %rd27, %rd39;
	add.s64 	%rd5, %rd40, %rd38;
	and.b32  	%r5, %r13, 1;
	setp.gt.u32 	%p4, %r11, 5;
	and.b16  	%rs11, %rs8, 1;
	setp.eq.b16 	%p5, %rs11, 1;
	and.pred  	%p1, %p4, %p5;
	add.s64 	%rd41, %rd33, %rd39;
	add.s64 	%rd6, %rd41, %rd38;
	add.s32 	%r35, %r1, -32;
	mul.wide.u32 	%rd42, %r14, 1228800;
	cvt.u64.u32 	%rd43, %r9;
	shr.u64 	%rd44, %rd43, 5;
	mul.lo.s64 	%rd45, %rd44, 24576;
	add.s64 	%rd46, %rd42, %rd45;
	shl.b16 	%rs12, %rs1, 5;
	cvt.u16.u32 	%rs13, %r9;
	and.b16  	%rs14, %rs13, 31;
	or.b16  	%rs15, %rs12, %rs14;
	mul.lo.s16 	%rs16, %rs3, 3072;
	sub.s16 	%rs17, %rs15, %rs16;
	cvt.u32.u16 	%r16, %rs17;
	mul.hi.u32 	%r17, %r16, 715827883;
	mul.wide.u32 	%rd47, %r17, 48;
	add.s64 	%rd48, %rd46, %rd47;
	mul.hi.u16 	%rs18, %rs17, -21845;
	shr.u16 	%rs19, %rs18, 2;
	mul.lo.s16 	%rs20, %rs19, 6;
	sub.s16 	%rs21, %rs15, %rs20;
	sub.s16 	%rs22, %rs21, %rs16;
	cvt.u32.u16 	%r18, %rs22;
	mul.wide.u32 	%rd49, %r18, 4;
	add.s64 	%rd50, %rd48, %rd49;
	add.s64 	%rd51, %rd50, %rd35;
	add.s64 	%rd106, %rd51, 48;
	mul.wide.u32 	%rd52, %r14, 613200;
	mul.lo.s64 	%rd53, %rd44, 12264;
	add.s64 	%rd54, %rd52, %rd53;
	mul.wide.u32 	%rd55, %r17, 24;
	add.s64 	%rd56, %rd54, %rd55;
	and.b64  	%rd57, %rd49, 262136;
	add.s64 	%rd58, %rd56, %rd57;
	and.b32  	%r19, %r9, 1;
	mul.wide.u32 	%rd59, %r19, 4;
	or.b64  	%rd60, %rd58, %rd59;
	add.s64 	%rd105, %rd36, %rd60;
	mul.wide.u32 	%rd61, %r14, 307200;
	mul.lo.s64 	%rd62, %rd44, 6144;
	add.s64 	%rd63, %rd61, %rd62;
	mul.hi.u32 	%r20, %r16, 357913942;
	mul.wide.u32 	%rd64, %r20, 24;
	add.s64 	%rd65, %rd63, %rd64;
	add.s64 	%rd66, %rd65, %rd49;
	add.s64 	%rd104, %rd30, %rd66;
	add.s32 	%r21, %r17, -1;
	cvt.u64.u32 	%rd67, %r21;
	shr.u64 	%rd68, %rd67, 1;
	mul.lo.s64 	%rd69, %rd68, 24;
	add.s64 	%rd70, %rd63, %rd69;
	add.s64 	%rd71, %rd70, %rd49;
	add.s64 	%rd103, %rd32, %rd71;
	mov.f32 	%f16, 0f00000000;
	setp.lt.u32 	%p6, %r2, %r3;
	setp.eq.s32 	%p7, %r5, 0;
	mov.f32 	%f1, %f16;
	mov.f32 	%f2, %f16;
	bra.uni 	$L__BB259_1;
$L__BB259_8:
	add.rn.f32 	%f2, %f2, %f20;
	add.rn.f32 	%f22, %f52, %f53;
	mul.rn.f32 	%f23, %f10, %f22;
	ld.global.nc.f32 	%f24, [%rd6];
	mul.rn.f32 	%f25, %f8, %f24;
	add.rn.f32 	%f26, %f23, %f25;
	mul.rn.f32 	%f27, %f7, %f26;
	add.rn.f32 	%f1, %f1, %f27;
$L__BB259_2:
	add.s32 	%r35, %r35, 32;
	add.s64 	%rd106, %rd106, 786432;
	add.s64 	%rd105, %rd105, 392448;
	add.s64 	%rd104, %rd104, 196608;
	add.s64 	%rd103, %rd103, 196608;
	setp.lt.u32 	%p8, %r35, 18;
	@%p8 bra 	$L__BB259_1;
	bra.uni 	$L__BB259_3;
$L__BB259_1:
	@%p6 bra 	$L__BB259_6;
	bra.uni 	$L__BB259_2;
$L__BB259_6:
	ld.global.nc.f32 	%f18, [%rd4];
	ld.global.nc.f32 	%f7, [%rd106];
	mul.rn.f32 	%f19, %f18, %f7;
	ld.global.nc.f32 	%f8, [%rd105];
	ld.global.nc.f32 	%f10, [%rd5];
	mov.f32 	%f52, %f16;
	@%p7 bra 	$L__BB259_9;
	bra.uni 	$L__BB259_7;
$L__BB259_9:
	ld.global.nc.f32 	%f52, [%rd104];
$L__BB259_7:
	mul.rn.f32 	%f20, %f19, %f8;
	mov.f32 	%f53, %f16;
	@%p1 bra 	$L__BB259_10;
	bra.uni 	$L__BB259_8;
$L__BB259_10:
	ld.global.nc.f32 	%f53, [%rd103];
	bra.uni 	$L__BB259_8;
$L__BB259_3:
	cvt.u64.u32 	%rd19, %r2;
	cvt.u64.u32 	%rd20, %r1;
	mul.wide.u32 	%rd72, %r2, 132;
	mov.u64 	%rd73, shared_cache48;
	add.s64 	%rd74, %rd73, %rd72;
	mul.wide.u32 	%rd75, %r1, 4;
	add.s64 	%rd76, %rd74, %rd75;
	st.shared.f32 	[%rd76], %f2;
	bar.sync 	0;
	mul.wide.u32 	%rd77, %r1, 132;
	add.s64 	%rd78, %rd73, %rd77;
	mul.wide.u32 	%rd79, %r2, 4;
	add.s64 	%rd80, %rd78, %rd79;
	ld.shared.f32 	%f28, [%rd80];
	shfl.sync.down.b32	%f29, %f28, 16, 31, -1;
	add.rn.f32 	%f30, %f28, %f29;
	shfl.sync.down.b32	%f31, %f30, 8, 31, -1;
	add.rn.f32 	%f32, %f30, %f31;
	shfl.sync.down.b32	%f33, %f32, 4, 31, -1;
	add.rn.f32 	%f34, %f32, %f33;
	shfl.sync.down.b32	%f35, %f34, 2, 31, -1;
	add.rn.f32 	%f36, %f34, %f35;
	shfl.sync.down.b32	%f37, %f36, 1, 31, -1;
	add.rn.f32 	%f5, %f36, %f37;
	st.shared.f32 	[%rd80], %f5;
	setp.lt.u32 	%p9, %r1, %r3;
	setp.eq.s32 	%p10, %r2, 0;
	and.pred  	%p2, %p10, %p9;
	or.b32  	%r34, %r1, %r4;
	mul.lo.s64 	%rd102, %rd3, 12264;
	@%p2 bra 	$L__BB259_11;
	bra.uni 	$L__BB259_4;
$L__BB259_11:
	mul.hi.u32 	%r24, %r34, -1431655765;
	shr.u32 	%r25, %r24, 2;
	mul.lo.s32 	%r26, %r25, 6;
	sub.s32 	%r27, %r34, %r26;
	add.s64 	%rd82, %rd2, %rd102;
	mul.wide.u32 	%rd83, %r25, 24;
	add.s64 	%rd84, %rd82, %rd83;
	mul.wide.u32 	%rd85, %r27, 4;
	add.s64 	%rd86, %rd84, %rd85;
	st.global.f32 	[%rd86], %f5;
$L__BB259_4:
	mul.lo.s64 	%rd87, %rd19, 132;
	mov.u64 	%rd88, shared_cache49;
	add.s64 	%rd89, %rd88, %rd87;
	shl.b64 	%rd90, %rd20, 2;
	add.s64 	%rd91, %rd89, %rd90;
	st.shared.f32 	[%rd91], %f1;
	bar.sync 	0;
	mul.lo.s64 	%rd92, %rd20, 132;
	add.s64 	%rd93, %rd88, %rd92;
	shl.b64 	%rd94, %rd19, 2;
	add.s64 	%rd95, %rd93, %rd94;
	ld.shared.f32 	%f38, [%rd95];
	shfl.sync.down.b32	%f39, %f38, 16, 31, -1;
	add.rn.f32 	%f40, %f38, %f39;
	shfl.sync.down.b32	%f41, %f40, 8, 31, -1;
	add.rn.f32 	%f42, %f40, %f41;
	shfl.sync.down.b32	%f43, %f42, 4, 31, -1;
	add.rn.f32 	%f44, %f42, %f43;
	shfl.sync.down.b32	%f45, %f44, 2, 31, -1;
	add.rn.f32 	%f46, %f44, %f45;
	shfl.sync.down.b32	%f47, %f46, 1, 31, -1;
	add.rn.f32 	%f6, %f46, %f47;
	st.shared.f32 	[%rd95], %f6;
	@%p2 bra 	$L__BB259_12;
	bra.uni 	$L__BB259_5;
$L__BB259_12:
	mul.hi.u32 	%r30, %r34, -1431655765;
	shr.u32 	%r31, %r30, 2;
	mul.lo.s32 	%r32, %r31, 6;
	sub.s32 	%r33, %r34, %r32;
	add.s64 	%rd97, %rd1, %rd102;
	mul.wide.u32 	%rd98, %r31, 24;
	add.s64 	%rd99, %rd97, %rd98;
	mul.wide.u32 	%rd100, %r33, 4;
	add.s64 	%rd101, %rd99, %rd100;
	st.global.f32 	[%rd101], %f6;
$L__BB259_5:
	ret;

}
	// .globl	input_reduce_fusion_342
.visible .entry input_reduce_fusion_342(
	.param .u64 input_reduce_fusion_342_param_0,
	.param .u64 input_reduce_fusion_342_param_1,
	.param .u64 input_reduce_fusion_342_param_2,
	.param .u64 input_reduce_fusion_342_param_3,
	.param .u64 input_reduce_fusion_342_param_4
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<11>;
	.reg .b16 	%rs<21>;
	.reg .b32 	%r<26>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<62>;
	// demoted variable
	.shared .align 4 .b8 shared_cache50[4224];
	ld.param.u64 	%rd13, [input_reduce_fusion_342_param_0];
	ld.param.u64 	%rd14, [input_reduce_fusion_342_param_4];
	cvta.to.global.u64 	%rd1, %rd14;
	ld.param.u64 	%rd15, [input_reduce_fusion_342_param_1];
	ld.param.u64 	%rd16, [input_reduce_fusion_342_param_3];
	cvta.to.global.u64 	%rd17, %rd16;
	ld.param.u64 	%rd18, [input_reduce_fusion_342_param_2];
	cvta.to.global.u64 	%rd19, %rd18;
	cvta.to.global.u64 	%rd20, %rd15;
	cvta.to.global.u64 	%rd21, %rd13;
	mov.u32 	%r9, %tid.x;
	mov.u32 	%r10, %ctaid.x;
	shr.u32 	%r1, %r9, 5;
	and.b32  	%r2, %r9, 31;
	cvt.u16.u32 	%rs1, %r10;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 6;
	mul.lo.s16 	%rs4, %rs3, 96;
	sub.s16 	%rs5, %rs1, %rs4;
	setp.eq.s16 	%p2, %rs5, 95;
	selp.b32 	%r3, 26, 32, %p2;
	shl.b16 	%rs6, %rs5, 5;
	cvt.u32.u16 	%r4, %rs6;
	or.b32  	%r11, %r2, %r4;
	cvt.u16.u32 	%rs7, %r11;
	mul.hi.u16 	%rs8, %rs7, 10923;
	cvt.u32.u16 	%r12, %rs8;
	cvt.u64.u16 	%rd2, %rs3;
	cvt.u32.u16 	%r13, %rs3;
	mul.wide.u32 	%rd22, %r13, 4;
	add.s64 	%rd3, %rd17, %rd22;
	and.b32  	%r5, %r12, 1;
	setp.gt.u32 	%p3, %r11, 5;
	and.b16  	%rs9, %rs8, 1;
	setp.eq.b16 	%p4, %rs9, 1;
	and.pred  	%p1, %p3, %p4;
	add.s32 	%r25, %r1, -32;
	mul.wide.u32 	%rd23, %r13, 1228800;
	cvt.u64.u32 	%rd24, %r9;
	shr.u64 	%rd25, %rd24, 5;
	mul.lo.s64 	%rd26, %rd25, 24576;
	add.s64 	%rd27, %rd23, %rd26;
	shl.b16 	%rs10, %rs1, 5;
	cvt.u16.u32 	%rs11, %r9;
	and.b16  	%rs12, %rs11, 31;
	or.b16  	%rs13, %rs10, %rs12;
	mul.lo.s16 	%rs14, %rs3, 3072;
	sub.s16 	%rs15, %rs13, %rs14;
	cvt.u32.u16 	%r14, %rs15;
	mul.hi.u32 	%r15, %r14, 715827883;
	mul.wide.u32 	%rd28, %r15, 48;
	add.s64 	%rd29, %rd27, %rd28;
	mul.hi.u16 	%rs16, %rs15, -21845;
	shr.u16 	%rs17, %rs16, 2;
	mul.lo.s16 	%rs18, %rs17, 6;
	sub.s16 	%rs19, %rs13, %rs18;
	sub.s16 	%rs20, %rs19, %rs14;
	cvt.u32.u16 	%r16, %rs20;
	mul.wide.u32 	%rd30, %r16, 4;
	add.s64 	%rd31, %rd29, %rd30;
	add.s64 	%rd32, %rd31, %rd19;
	add.s64 	%rd61, %rd32, 48;
	mul.wide.u32 	%rd33, %r13, 307200;
	mul.lo.s64 	%rd34, %rd25, 6144;
	add.s64 	%rd35, %rd33, %rd34;
	add.s32 	%r17, %r15, -1;
	cvt.u64.u32 	%rd36, %r17;
	shr.u64 	%rd37, %rd36, 1;
	mul.lo.s64 	%rd38, %rd37, 24;
	add.s64 	%rd39, %rd35, %rd38;
	add.s64 	%rd40, %rd39, %rd30;
	add.s64 	%rd60, %rd21, %rd40;
	mul.hi.u32 	%r18, %r14, 357913942;
	mul.wide.u32 	%rd41, %r18, 24;
	add.s64 	%rd42, %rd35, %rd41;
	add.s64 	%rd43, %rd42, %rd30;
	add.s64 	%rd59, %rd20, %rd43;
	mov.f32 	%f10, 0f00000000;
	setp.lt.u32 	%p5, %r2, %r3;
	setp.eq.s32 	%p6, %r5, 0;
	mov.f32 	%f1, %f10;
	bra.uni 	$L__BB260_1;
$L__BB260_7:
	add.rn.f32 	%f15, %f30, %f31;
	mul.rn.f32 	%f16, %f4, %f15;
	add.rn.f32 	%f1, %f1, %f16;
$L__BB260_2:
	add.s32 	%r25, %r25, 32;
	add.s64 	%rd61, %rd61, 786432;
	add.s64 	%rd60, %rd60, 196608;
	add.s64 	%rd59, %rd59, 196608;
	setp.lt.u32 	%p7, %r25, 18;
	@%p7 bra 	$L__BB260_1;
	bra.uni 	$L__BB260_3;
$L__BB260_1:
	@%p5 bra 	$L__BB260_5;
	bra.uni 	$L__BB260_2;
$L__BB260_5:
	ld.global.nc.f32 	%f12, [%rd3];
	ld.global.nc.f32 	%f13, [%rd61];
	mov.f32 	%f30, %f10;
	@%p6 bra 	$L__BB260_8;
	bra.uni 	$L__BB260_6;
$L__BB260_8:
	ld.global.nc.f32 	%f30, [%rd59];
$L__BB260_6:
	mul.rn.f32 	%f4, %f12, %f13;
	mov.f32 	%f31, %f10;
	@%p1 bra 	$L__BB260_9;
	bra.uni 	$L__BB260_7;
$L__BB260_9:
	ld.global.nc.f32 	%f31, [%rd60];
	bra.uni 	$L__BB260_7;
$L__BB260_3:
	mul.wide.u32 	%rd44, %r2, 132;
	mov.u64 	%rd45, shared_cache50;
	add.s64 	%rd46, %rd45, %rd44;
	mul.wide.u32 	%rd47, %r1, 4;
	add.s64 	%rd48, %rd46, %rd47;
	st.shared.f32 	[%rd48], %f1;
	bar.sync 	0;
	mul.wide.u32 	%rd49, %r1, 132;
	add.s64 	%rd50, %rd45, %rd49;
	mul.wide.u32 	%rd51, %r2, 4;
	add.s64 	%rd52, %rd50, %rd51;
	ld.shared.f32 	%f17, [%rd52];
	shfl.sync.down.b32	%f18, %f17, 16, 31, -1;
	add.rn.f32 	%f19, %f17, %f18;
	shfl.sync.down.b32	%f20, %f19, 8, 31, -1;
	add.rn.f32 	%f21, %f19, %f20;
	shfl.sync.down.b32	%f22, %f21, 4, 31, -1;
	add.rn.f32 	%f23, %f21, %f22;
	shfl.sync.down.b32	%f24, %f23, 2, 31, -1;
	add.rn.f32 	%f25, %f23, %f24;
	shfl.sync.down.b32	%f26, %f25, 1, 31, -1;
	add.rn.f32 	%f3, %f25, %f26;
	st.shared.f32 	[%rd52], %f3;
	setp.lt.u32 	%p8, %r1, %r3;
	setp.eq.s32 	%p9, %r2, 0;
	and.pred  	%p10, %p9, %p8;
	@%p10 bra 	$L__BB260_10;
	bra.uni 	$L__BB260_4;
$L__BB260_10:
	or.b32  	%r19, %r1, %r4;
	mul.hi.u32 	%r21, %r19, -1431655765;
	shr.u32 	%r22, %r21, 2;
	mul.lo.s32 	%r23, %r22, 6;
	sub.s32 	%r24, %r19, %r23;
	mul.lo.s64 	%rd53, %rd2, 12264;
	add.s64 	%rd54, %rd1, %rd53;
	mul.wide.u32 	%rd55, %r22, 24;
	add.s64 	%rd56, %rd54, %rd55;
	mul.wide.u32 	%rd57, %r24, 4;
	add.s64 	%rd58, %rd56, %rd57;
	neg.f32 	%f27, %f3;
	st.global.f32 	[%rd58], %f27;
$L__BB260_4:
	ret;

}
	// .globl	input_reduce_fusion_343
.visible .entry input_reduce_fusion_343(
	.param .u64 input_reduce_fusion_343_param_0,
	.param .u64 input_reduce_fusion_343_param_1,
	.param .u64 input_reduce_fusion_343_param_2,
	.param .u64 input_reduce_fusion_343_param_3,
	.param .u64 input_reduce_fusion_343_param_4
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<17>;
	.reg .b32 	%r<23>;
	.reg .f32 	%f<14>;
	.reg .b64 	%rd<32>;

	mov.u32 	%r5, %tid.x;
	mov.u32 	%r6, %ctaid.x;
	shr.u32 	%r1, %r5, 1;
	and.b32  	%r2, %r5, 1;
	setp.eq.s32 	%p1, %r6, 766;
	selp.b32 	%r3, 64, 128, %p1;
	shl.b32 	%r4, %r6, 7;
	setp.ge.u32 	%p2, %r1, %r3;
	mov.f32 	%f13, 0f00000000;
	@%p2 bra 	$L__BB261_2;
	ld.param.u64 	%rd6, [input_reduce_fusion_343_param_0];
	ld.param.u64 	%rd8, [input_reduce_fusion_343_param_1];
	ld.param.u64 	%rd9, [input_reduce_fusion_343_param_3];
	cvta.to.global.u64 	%rd2, %rd9;
	ld.param.u64 	%rd10, [input_reduce_fusion_343_param_2];
	cvta.to.global.u64 	%rd3, %rd10;
	cvta.to.global.u64 	%rd4, %rd8;
	cvta.to.global.u64 	%rd5, %rd6;
	or.b32  	%r7, %r1, %r4;
	mul.hi.u32 	%r8, %r7, 1431655766;
	mul.lo.s32 	%r9, %r8, 3;
	sub.s32 	%r10, %r7, %r9;
	cvt.u16.u32 	%rs1, %r8;
	mul.hi.u16 	%rs2, %rs1, 129;
	sub.s16 	%rs3, %rs1, %rs2;
	shr.u16 	%rs4, %rs3, 1;
	add.s16 	%rs5, %rs4, %rs2;
	shr.u16 	%rs6, %rs5, 8;
	mul.lo.s16 	%rs7, %rs6, 511;
	sub.s16 	%rs8, %rs1, %rs7;
	mul.hi.u32 	%r11, %r7, -1426052415;
	shr.u32 	%r12, %r11, 10;
	shl.b32 	%r13, %r10, 1;
	or.b32  	%r14, %r13, %r2;
	cvt.u32.u16 	%r15, %rs8;
	mul.wide.u32 	%rd11, %r15, 24;
	mul.wide.u32 	%rd12, %r12, 12264;
	add.s64 	%rd13, %rd3, %rd12;
	add.s64 	%rd14, %rd13, %rd11;
	mul.wide.u32 	%rd15, %r14, 4;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.nc.f32 	%f5, [%rd16];
	mul.wide.u32 	%rd17, %r10, 4;
	mul.wide.u32 	%rd18, %r12, 12;
	add.s64 	%rd19, %rd2, %rd18;
	add.s64 	%rd20, %rd19, %rd17;
	ld.global.nc.f32 	%f6, [%rd20];
	mul.rn.f32 	%f7, %f5, %f6;
	add.s64 	%rd21, %rd4, %rd12;
	add.s64 	%rd22, %rd21, %rd11;
	add.s64 	%rd23, %rd22, %rd15;
	ld.global.nc.f32 	%f8, [%rd23];
	add.s64 	%rd24, %rd5, %rd18;
	add.s64 	%rd25, %rd24, %rd17;
	ld.global.nc.f32 	%f9, [%rd25];
	mul.rn.f32 	%f10, %f8, %f9;
	add.rn.f32 	%f11, %f7, %f10;
	add.rn.f32 	%f13, %f11, 0f00000000;
$L__BB261_2:
	shfl.sync.down.b32	%f3, %f13, 1, 31, -1;
	setp.ne.s32 	%p4, %r2, 0;
	or.pred  	%p5, %p4, %p2;
	@%p5 bra 	$L__BB261_4;
	ld.param.u64 	%rd7, [input_reduce_fusion_343_param_4];
	cvta.to.global.u64 	%rd1, %rd7;
	add.rn.f32 	%f12, %f13, %f3;
	or.b32  	%r16, %r4, %r1;
	mul.hi.u32 	%r17, %r16, 1431655766;
	mul.lo.s32 	%r18, %r17, 3;
	sub.s32 	%r19, %r16, %r18;
	cvt.u16.u32 	%rs9, %r17;
	mul.hi.u16 	%rs10, %rs9, 129;
	sub.s16 	%rs11, %rs9, %rs10;
	shr.u16 	%rs12, %rs11, 1;
	add.s16 	%rs13, %rs12, %rs10;
	shr.u16 	%rs14, %rs13, 8;
	mul.lo.s16 	%rs15, %rs14, 511;
	sub.s16 	%rs16, %rs9, %rs15;
	mul.hi.u32 	%r20, %r16, -1426052415;
	shr.u32 	%r21, %r20, 10;
	mul.wide.u32 	%rd26, %r19, 2044;
	mul.wide.u32 	%rd27, %r21, 6132;
	add.s64 	%rd28, %rd1, %rd27;
	add.s64 	%rd29, %rd28, %rd26;
	cvt.u32.u16 	%r22, %rs16;
	mul.wide.u32 	%rd30, %r22, 4;
	add.s64 	%rd31, %rd29, %rd30;
	st.global.f32 	[%rd31], %f12;
$L__BB261_4:
	ret;

}
	// .globl	input_reduce_fusion_344
.visible .entry input_reduce_fusion_344(
	.param .u64 input_reduce_fusion_344_param_0,
	.param .u64 input_reduce_fusion_344_param_1,
	.param .u64 input_reduce_fusion_344_param_2,
	.param .u64 input_reduce_fusion_344_param_3
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<35>;
	.reg .f32 	%f<124>;
	.reg .b64 	%rd<63>;
	// demoted variable
	.shared .align 4 .b8 shared_cache51[32];
	ld.param.u64 	%rd13, [input_reduce_fusion_344_param_0];
	ld.param.u64 	%rd15, [input_reduce_fusion_344_param_1];
	ld.param.u64 	%rd16, [input_reduce_fusion_344_param_2];
	cvta.to.global.u64 	%rd2, %rd16;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd13;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r4, %ctaid.x;
	shr.u32 	%r2, %r1, 6;
	and.b32  	%r5, %r1, 63;
	and.b32  	%r3, %r1, 31;
	shl.b32 	%r6, %r4, 2;
	or.b32  	%r7, %r2, %r6;
	cvt.u16.u32 	%rs1, %r7;
	and.b16  	%rs2, %rs1, 255;
	mul.lo.s16 	%rs3, %rs2, 171;
	shr.u16 	%rs4, %rs3, 9;
	mul.lo.s16 	%rs5, %rs4, 3;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u64.u16 	%rd5, %rs4;
	cvt.u64.u16 	%rd17, %rs6;
	and.b64  	%rd6, %rd17, 255;
	shl.b32 	%r8, %r5, 1;
	cvt.u64.u32 	%rd7, %r5;
	cvt.u32.u16 	%r9, %rs6;
	and.b32  	%r10, %r9, 255;
	mul.wide.u32 	%rd18, %r10, 2048;
	cvt.u32.u16 	%r11, %rs4;
	mul.wide.u32 	%rd19, %r11, 6144;
	add.s64 	%rd20, %rd3, %rd19;
	add.s64 	%rd21, %rd20, %rd18;
	mul.wide.u32 	%rd22, %r5, 4;
	add.s64 	%rd8, %rd21, %rd22;
	ld.global.nc.f32 	%f1, [%rd8];
	add.rn.f32 	%f2, %f1, 0f00000000;
	add.s32 	%r12, %r8, -2;
	setp.lt.u32 	%p1, %r12, 1022;
	mov.f32 	%f113, 0f00000000;
	@%p1 bra 	$L__BB262_29;
	bra.uni 	$L__BB262_1;
$L__BB262_29:
	shr.u32 	%r13, %r12, 1;
	mul.wide.u32 	%rd23, %r10, 2044;
	mul.wide.u32 	%rd24, %r11, 6132;
	add.s64 	%rd25, %rd4, %rd24;
	add.s64 	%rd26, %rd25, %rd23;
	mul.wide.u32 	%rd27, %r13, 4;
	add.s64 	%rd9, %rd26, %rd27;
	ld.global.nc.f32 	%f113, [%rd9];
$L__BB262_1:
	cvt.u32.u64 	%r14, %rd7;
	add.rn.f32 	%f33, %f2, %f113;
	mul.lo.s64 	%rd28, %rd5, 6144;
	add.s64 	%rd29, %rd2, %rd28;
	shl.b64 	%rd30, %rd6, 11;
	add.s64 	%rd31, %rd29, %rd30;
	shl.b64 	%rd32, %rd7, 2;
	add.s64 	%rd33, %rd31, %rd32;
	ld.global.nc.f32 	%f34, [%rd33];
	add.rn.f32 	%f35, %f1, %f34;
	add.rn.f32 	%f36, %f35, 0f00000000;
	add.rn.f32 	%f37, %f33, %f36;
	ld.global.nc.f32 	%f38, [%rd8+256];
	add.rn.f32 	%f39, %f38, 0f00000000;
	mul.lo.s64 	%rd34, %rd5, 6132;
	add.s64 	%rd35, %rd4, %rd34;
	mul.lo.s64 	%rd36, %rd6, 2044;
	add.s64 	%rd37, %rd35, %rd36;
	add.s64 	%rd38, %rd37, %rd32;
	ld.global.nc.f32 	%f40, [%rd38+252];
	add.rn.f32 	%f41, %f39, %f40;
	add.rn.f32 	%f42, %f37, %f41;
	ld.global.nc.f32 	%f43, [%rd33+256];
	add.rn.f32 	%f44, %f38, %f43;
	add.rn.f32 	%f45, %f44, 0f00000000;
	add.rn.f32 	%f46, %f42, %f45;
	ld.global.nc.f32 	%f47, [%rd8+512];
	add.rn.f32 	%f48, %f47, 0f00000000;
	ld.global.nc.f32 	%f49, [%rd38+508];
	add.rn.f32 	%f50, %f48, %f49;
	add.rn.f32 	%f51, %f46, %f50;
	ld.global.nc.f32 	%f52, [%rd33+512];
	add.rn.f32 	%f53, %f47, %f52;
	add.rn.f32 	%f54, %f53, 0f00000000;
	add.rn.f32 	%f55, %f51, %f54;
	or.b32  	%r15, %r1, 192;
	add.s64 	%rd39, %rd3, %rd28;
	add.s64 	%rd40, %rd39, %rd30;
	mul.wide.u32 	%rd41, %r15, 4;
	add.s64 	%rd42, %rd40, %rd41;
	ld.global.nc.f32 	%f56, [%rd42];
	add.rn.f32 	%f57, %f56, 0f00000000;
	add.s32 	%r16, %r15, -1;
	and.b32  	%r17, %r16, 255;
	mul.wide.u32 	%rd43, %r17, 4;
	add.s64 	%rd44, %rd37, %rd43;
	ld.global.nc.f32 	%f58, [%rd44];
	add.rn.f32 	%f59, %f57, %f58;
	add.rn.f32 	%f60, %f55, %f59;
	add.s64 	%rd45, %rd31, %rd41;
	ld.global.nc.f32 	%f61, [%rd45];
	add.rn.f32 	%f62, %f56, %f61;
	add.rn.f32 	%f63, %f62, 0f00000000;
	add.rn.f32 	%f64, %f60, %f63;
	ld.global.nc.f32 	%f65, [%rd8+1024];
	add.rn.f32 	%f66, %f65, 0f00000000;
	ld.global.nc.f32 	%f67, [%rd38+1020];
	add.rn.f32 	%f68, %f66, %f67;
	add.rn.f32 	%f69, %f64, %f68;
	ld.global.nc.f32 	%f70, [%rd33+1024];
	add.rn.f32 	%f71, %f65, %f70;
	add.rn.f32 	%f72, %f71, 0f00000000;
	add.rn.f32 	%f73, %f69, %f72;
	ld.global.nc.f32 	%f74, [%rd8+1280];
	add.rn.f32 	%f75, %f74, 0f00000000;
	ld.global.nc.f32 	%f76, [%rd38+1276];
	add.rn.f32 	%f77, %f75, %f76;
	add.rn.f32 	%f78, %f73, %f77;
	ld.global.nc.f32 	%f79, [%rd33+1280];
	add.rn.f32 	%f80, %f74, %f79;
	add.rn.f32 	%f81, %f80, 0f00000000;
	add.rn.f32 	%f82, %f78, %f81;
	ld.global.nc.f32 	%f83, [%rd8+1536];
	add.rn.f32 	%f84, %f83, 0f00000000;
	ld.global.nc.f32 	%f85, [%rd38+1532];
	add.rn.f32 	%f86, %f84, %f85;
	add.rn.f32 	%f87, %f82, %f86;
	ld.global.nc.f32 	%f88, [%rd33+1536];
	add.rn.f32 	%f89, %f83, %f88;
	add.rn.f32 	%f90, %f89, 0f00000000;
	add.rn.f32 	%f91, %f87, %f90;
	or.b32  	%r18, %r1, 448;
	mul.wide.u32 	%rd46, %r18, 4;
	add.s64 	%rd47, %rd40, %rd46;
	ld.global.nc.f32 	%f92, [%rd47];
	add.rn.f32 	%f93, %f92, 0f00000000;
	add.s32 	%r19, %r18, -1;
	and.b32  	%r20, %r19, 511;
	mul.wide.u32 	%rd48, %r20, 4;
	add.s64 	%rd49, %rd37, %rd48;
	ld.global.nc.f32 	%f94, [%rd49];
	add.rn.f32 	%f95, %f93, %f94;
	add.rn.f32 	%f96, %f91, %f95;
	add.s64 	%rd50, %rd31, %rd46;
	ld.global.nc.f32 	%f97, [%rd50];
	add.rn.f32 	%f98, %f92, %f97;
	add.rn.f32 	%f99, %f98, 0f00000000;
	add.rn.f32 	%f100, %f96, %f99;
	shfl.sync.down.b32	%f101, %f100, 16, 31, -1;
	add.rn.f32 	%f102, %f100, %f101;
	shfl.sync.down.b32	%f103, %f102, 8, 31, -1;
	add.rn.f32 	%f104, %f102, %f103;
	shfl.sync.down.b32	%f105, %f104, 4, 31, -1;
	add.rn.f32 	%f106, %f104, %f105;
	shfl.sync.down.b32	%f107, %f106, 2, 31, -1;
	add.rn.f32 	%f108, %f106, %f107;
	shfl.sync.down.b32	%f109, %f108, 1, 31, -1;
	setp.eq.s32 	%p2, %r3, 0;
	mov.u64 	%rd52, shared_cache51;
	@%p2 bra 	$L__BB262_4;
	bra.uni 	$L__BB262_2;
$L__BB262_4:
	shr.u32 	%r21, %r14, 5;
	mul.wide.u32 	%rd51, %r2, 8;
	add.s64 	%rd53, %rd52, %rd51;
	mul.wide.u32 	%rd54, %r21, 4;
	add.s64 	%rd11, %rd53, %rd54;
	add.rn.f32 	%f4, %f108, %f109;
	st.shared.f32 	[%rd11], %f4;
$L__BB262_2:
	bar.sync 	0;
	setp.lt.u32 	%p3, %r14, 32;
	@%p3 bra 	$L__BB262_5;
	bra.uni 	$L__BB262_3;
$L__BB262_5:
	cvt.u64.u32 	%rd10, %r2;
	shl.b64 	%rd55, %rd10, 3;
	add.s64 	%rd57, %rd52, %rd55;
	mul.wide.u32 	%rd58, %r3, 4;
	add.s64 	%rd12, %rd57, %rd58;
	setp.gt.u32 	%p4, %r14, 1;
	mov.f32 	%f115, 0f00000000;
	mov.f32 	%f114, %f115;
	@%p4 bra 	$L__BB262_7;
	ld.shared.f32 	%f114, [%rd12];
$L__BB262_7:
	shfl.sync.down.b32	%f8, %f114, 16, 31, -1;
	@%p4 bra 	$L__BB262_9;
	ld.shared.f32 	%f115, [%rd12];
$L__BB262_9:
	add.rn.f32 	%f11, %f8, %f115;
	mov.f32 	%f116, %f11;
	@%p4 bra 	$L__BB262_11;
	st.shared.f32 	[%rd12], %f11;
	mov.f32 	%f116, 0f00000000;
$L__BB262_11:
	shfl.sync.down.b32	%f13, %f11, 8, 31, -1;
	mov.f32 	%f117, %f116;
	@%p4 bra 	$L__BB262_13;
	ld.shared.f32 	%f117, [%rd12];
$L__BB262_13:
	add.rn.f32 	%f16, %f13, %f117;
	mov.f32 	%f118, %f16;
	@%p4 bra 	$L__BB262_15;
	st.shared.f32 	[%rd12], %f16;
	mov.f32 	%f118, %f116;
$L__BB262_15:
	shfl.sync.down.b32	%f18, %f16, 4, 31, -1;
	mov.f32 	%f119, %f118;
	@%p4 bra 	$L__BB262_17;
	ld.shared.f32 	%f119, [%rd12];
$L__BB262_17:
	add.rn.f32 	%f21, %f18, %f119;
	mov.f32 	%f120, %f21;
	@%p4 bra 	$L__BB262_19;
	st.shared.f32 	[%rd12], %f21;
	mov.f32 	%f120, %f118;
$L__BB262_19:
	shfl.sync.down.b32	%f23, %f21, 2, 31, -1;
	mov.f32 	%f121, %f120;
	@%p4 bra 	$L__BB262_21;
	ld.shared.f32 	%f121, [%rd12];
$L__BB262_21:
	add.rn.f32 	%f26, %f23, %f121;
	mov.f32 	%f123, %f26;
	@%p4 bra 	$L__BB262_23;
	st.shared.f32 	[%rd12], %f26;
	mov.f32 	%f123, %f120;
$L__BB262_23:
	shfl.sync.down.b32	%f28, %f26, 1, 31, -1;
	@%p4 bra 	$L__BB262_25;
	ld.shared.f32 	%f123, [%rd12];
$L__BB262_25:
	add.rn.f32 	%f31, %f28, %f123;
	@%p4 bra 	$L__BB262_27;
	st.shared.f32 	[%rd12], %f31;
$L__BB262_27:
	setp.ne.s32 	%p15, %r14, 0;
	@%p15 bra 	$L__BB262_3;
	ld.param.u64 	%rd14, [input_reduce_fusion_344_param_3];
	cvta.to.global.u64 	%rd1, %rd14;
	mul.lo.s64 	%rd59, %rd5, 12;
	add.s64 	%rd60, %rd1, %rd59;
	shl.b64 	%rd61, %rd6, 2;
	add.s64 	%rd62, %rd60, %rd61;
	st.global.f32 	[%rd62], %f31;
$L__BB262_3:
	ret;

}
	// .globl	loop_select_subtract_fusion_1
.visible .entry loop_select_subtract_fusion_1(
	.param .u64 loop_select_subtract_fusion_1_param_0,
	.param .u64 loop_select_subtract_fusion_1_param_1,
	.param .u64 loop_select_subtract_fusion_1_param_2,
	.param .u64 loop_select_subtract_fusion_1_param_3
)
.reqntid 1, 1, 1
{
	.reg .pred 	%p<21>;
	.reg .b32 	%r<18>;
	.reg .f32 	%f<75>;
	.reg .b64 	%rd<9>;

	ld.param.u64 	%rd3, [loop_select_subtract_fusion_1_param_0];
	ld.param.u64 	%rd4, [loop_select_subtract_fusion_1_param_3];
	cvta.to.global.u64 	%rd1, %rd4;
	ld.param.u64 	%rd5, [loop_select_subtract_fusion_1_param_1];
	ld.param.u64 	%rd6, [loop_select_subtract_fusion_1_param_2];
	cvta.to.global.u64 	%rd2, %rd6;
	cvta.to.global.u64 	%rd7, %rd5;
	cvta.to.global.u64 	%rd8, %rd3;
	ld.global.nc.f32 	%f1, [%rd8];
	ld.global.nc.u32 	%r2, [%rd7];
	setp.eq.s32 	%p1, %r2, 2147483647;
	add.s32 	%r3, %r2, 1;
	selp.b32 	%r1, 2147483647, %r3, %p1;
	setp.eq.f32 	%p6, %f1, 0f3F800000;
	setp.eq.s32 	%p7, %r1, 0;
	or.pred  	%p8, %p6, %p7;
	mov.f32 	%f13, 0f3F800000;
	mov.f32 	%f74, %f13;
	@%p8 bra 	$L__BB263_9;
	cvt.rn.f32.s32 	%f2, %r1;
	abs.f32 	%f4, %f1;
	setp.nan.f32 	%p9, %f4, %f4;
	@%p9 bra 	$L__BB263_3;
	abs.f32 	%f6, %f2;
	setp.num.f32 	%p10, %f6, %f6;
	@%p10 bra 	$L__BB263_4;
	bra.uni 	$L__BB263_3;
$L__BB263_4:
	mul.rn.f32 	%f14, %f2, 0f3F000000;
	cvt.rzi.f32.f32 	%f15, %f14;
	add.rn.f32 	%f16, %f15, %f15;
	sub.rn.f32 	%f17, %f2, %f16;
	abs.f32 	%f3, %f17;
	setp.eq.f32 	%p11, %f1, 0f00000000;
	setp.eq.f32 	%p12, %f4, 0f7F800000;
	or.pred  	%p13, %p11, %p12;
	@!%p13 bra 	$L__BB263_6;
	bra.uni 	$L__BB263_5;
$L__BB263_5:
	setp.neu.f32 	%p19, %f3, 0f3F800000;
	add.rn.f32 	%f71, %f1, %f1;
	mov.b32 	%r13, %f71;
	setp.lt.s32 	%p20, %r1, 0;
	xor.b32  	%r14, %r13, 2139095040;
	selp.b32 	%r15, %r14, %r13, %p20;
	and.b32  	%r16, %r15, 2147483647;
	selp.b32 	%r17, %r16, %r15, %p19;
	mov.b32 	%f74, %r17;
	bra.uni 	$L__BB263_9;
$L__BB263_6:
	setp.eq.f32 	%p14, %f1, 0fBF800000;
	setp.eq.f32 	%p15, %f6, 0f7F800000;
	and.pred  	%p16, %p14, %p15;
	mov.f32 	%f74, %f13;
	@%p16 bra 	$L__BB263_9;
	setp.lt.f32 	%p2, %f4, 0f00800000;
	mul.rn.f32 	%f18, %f4, 0f4B800000;
	selp.f32 	%f19, %f18, %f4, %p2;
	selp.f32 	%f20, 0fC1C00000, 0f00000000, %p2;
	mov.b32 	%r4, %f19;
	add.s32 	%r5, %r4, -1060439283;
	and.b32  	%r6, %r5, -8388608;
	sub.s32 	%r7, %r4, %r6;
	mov.b32 	%f21, %r7;
	cvt.rn.f32.s32 	%f22, %r6;
	fma.rn.f32 	%f23, %f22, 0f34000000, %f20;
	add.rn.f32 	%f24, %f21, 0fBF800000;
	add.rn.f32 	%f12, %f21, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f11,%f12;
	// end inline asm
	add.rn.f32 	%f25, %f24, %f24;
	mul.rn.f32 	%f26, %f11, %f25;
	mul.rn.f32 	%f27, %f26, %f26;
	sub.rn.f32 	%f28, %f24, %f26;
	add.rn.f32 	%f29, %f28, %f28;
	neg.f32 	%f30, %f26;
	fma.rn.f32 	%f31, %f30, %f24, %f29;
	mul.rn.f32 	%f32, %f11, %f31;
	fma.rn.f32 	%f33, %f27, 0f3A2C32E4, 0f3B52E7DB;
	fma.rn.f32 	%f34, %f33, %f27, 0f3C93BB73;
	fma.rn.f32 	%f35, %f34, %f27, 0f3DF6384F;
	mul.rn.f32 	%f36, %f35, %f27;
	fma.rn.f32 	%f37, %f26, 0f3FB8AA3B, %f23;
	sub.rn.f32 	%f38, %f23, %f37;
	fma.rn.f32 	%f39, %f26, 0f3FB8AA3B, %f38;
	fma.rn.f32 	%f40, %f32, 0f3FB8AA3B, %f39;
	fma.rn.f32 	%f41, %f26, 0f32A55E34, %f40;
	mul.rn.f32 	%f42, %f36, 0f40400000;
	fma.rn.f32 	%f43, %f42, %f32, %f41;
	fma.rn.f32 	%f44, %f36, %f26, %f43;
	add.rn.f32 	%f45, %f37, %f44;
	neg.f32 	%f46, %f37;
	add.rn.f32 	%f47, %f45, %f46;
	neg.f32 	%f48, %f47;
	add.rn.f32 	%f49, %f44, %f48;
	mul.rn.f32 	%f50, %f45, %f2;
	neg.f32 	%f51, %f50;
	fma.rn.f32 	%f52, %f45, %f2, %f51;
	fma.rn.f32 	%f53, %f49, %f2, %f52;
	cvt.rni.f32.f32 	%f54, %f50;
	sub.rn.f32 	%f55, %f50, %f54;
	add.rn.f32 	%f56, %f55, %f53;
	fma.rn.f32 	%f57, %f56, 0f391FCB8E, 0f3AAF85ED;
	fma.rn.f32 	%f58, %f57, %f56, 0f3C1D9856;
	fma.rn.f32 	%f59, %f58, %f56, 0f3D6357BB;
	fma.rn.f32 	%f60, %f59, %f56, 0f3E75FDEC;
	fma.rn.f32 	%f61, %f60, %f56, 0f3F317218;
	fma.rn.f32 	%f62, %f61, %f56, 0f3F800000;
	cvt.rzi.s32.f32 	%r8, %f54;
	setp.gt.f32 	%p3, %f54, 0f00000000;
	selp.b32 	%r9, 0, -2097152000, %p3;
	add.s32 	%r10, %r9, 2130706432;
	mov.b32 	%f63, %r10;
	mul.rn.f32 	%f64, %f62, %f63;
	shl.b32 	%r11, %r8, 23;
	sub.s32 	%r12, %r11, %r9;
	mov.b32 	%f65, %r12;
	mul.rn.f32 	%f66, %f64, %f65;
	abs.f32 	%f67, %f50;
	setp.gt.f32 	%p4, %f67, 0f43180000;
	setp.lt.f32 	%p5, %f50, 0f00000000;
	selp.f32 	%f68, 0f00000000, 0f7F800000, %p5;
	selp.f32 	%f74, %f68, %f66, %p4;
	setp.geu.f32 	%p18, %f1, 0f00000000;
	@%p18 bra 	$L__BB263_9;
	setp.neu.f32 	%p17, %f3, 0f3F800000;
	neg.f32 	%f70, %f74;
	selp.f32 	%f74, %f74, %f70, %p17;
$L__BB263_9:
	sub.rn.f32 	%f73, %f13, %f74;
	st.global.f32 	[%rd2], %f73;
	st.global.u32 	[%rd1], %r1;
	ret;
$L__BB263_3:
	add.rn.f32 	%f74, %f1, %f2;
	bra.uni 	$L__BB263_9;

}
	// .globl	loop_subtract_fusion_3
.visible .entry loop_subtract_fusion_3(
	.param .u64 loop_subtract_fusion_3_param_0,
	.param .u64 loop_subtract_fusion_3_param_1,
	.param .u64 loop_subtract_fusion_3_param_2
)
.reqntid 1, 1, 1
{
	.reg .pred 	%p<20>;
	.reg .b32 	%r<16>;
	.reg .f32 	%f<75>;
	.reg .b64 	%rd<7>;

	ld.param.u64 	%rd2, [loop_subtract_fusion_3_param_0];
	ld.param.u64 	%rd3, [loop_subtract_fusion_3_param_2];
	cvta.to.global.u64 	%rd1, %rd3;
	ld.param.u64 	%rd4, [loop_subtract_fusion_3_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd2;
	ld.global.nc.f32 	%f1, [%rd6];
	ld.global.nc.u32 	%r1, [%rd5];
	setp.eq.f32 	%p5, %f1, 0f3F800000;
	setp.eq.s32 	%p6, %r1, 0;
	or.pred  	%p7, %p5, %p6;
	mov.f32 	%f13, 0f3F800000;
	mov.f32 	%f74, %f13;
	@%p7 bra 	$L__BB264_9;
	cvt.rn.f32.s32 	%f2, %r1;
	abs.f32 	%f4, %f1;
	setp.nan.f32 	%p8, %f4, %f4;
	@%p8 bra 	$L__BB264_3;
	abs.f32 	%f6, %f2;
	setp.num.f32 	%p9, %f6, %f6;
	@%p9 bra 	$L__BB264_4;
	bra.uni 	$L__BB264_3;
$L__BB264_4:
	mul.rn.f32 	%f14, %f2, 0f3F000000;
	cvt.rzi.f32.f32 	%f15, %f14;
	add.rn.f32 	%f16, %f15, %f15;
	sub.rn.f32 	%f17, %f2, %f16;
	abs.f32 	%f3, %f17;
	setp.eq.f32 	%p10, %f1, 0f00000000;
	setp.eq.f32 	%p11, %f4, 0f7F800000;
	or.pred  	%p12, %p10, %p11;
	@!%p12 bra 	$L__BB264_6;
	bra.uni 	$L__BB264_5;
$L__BB264_5:
	setp.neu.f32 	%p18, %f3, 0f3F800000;
	add.rn.f32 	%f71, %f1, %f1;
	mov.b32 	%r11, %f71;
	setp.lt.s32 	%p19, %r1, 0;
	xor.b32  	%r12, %r11, 2139095040;
	selp.b32 	%r13, %r12, %r11, %p19;
	and.b32  	%r14, %r13, 2147483647;
	selp.b32 	%r15, %r14, %r13, %p18;
	mov.b32 	%f74, %r15;
	bra.uni 	$L__BB264_9;
$L__BB264_6:
	setp.eq.f32 	%p13, %f1, 0fBF800000;
	setp.eq.f32 	%p14, %f6, 0f7F800000;
	and.pred  	%p15, %p13, %p14;
	mov.f32 	%f74, %f13;
	@%p15 bra 	$L__BB264_9;
	setp.lt.f32 	%p1, %f4, 0f00800000;
	mul.rn.f32 	%f18, %f4, 0f4B800000;
	selp.f32 	%f19, %f18, %f4, %p1;
	selp.f32 	%f20, 0fC1C00000, 0f00000000, %p1;
	mov.b32 	%r2, %f19;
	add.s32 	%r3, %r2, -1060439283;
	and.b32  	%r4, %r3, -8388608;
	sub.s32 	%r5, %r2, %r4;
	mov.b32 	%f21, %r5;
	cvt.rn.f32.s32 	%f22, %r4;
	fma.rn.f32 	%f23, %f22, 0f34000000, %f20;
	add.rn.f32 	%f24, %f21, 0fBF800000;
	add.rn.f32 	%f12, %f21, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f11,%f12;
	// end inline asm
	add.rn.f32 	%f25, %f24, %f24;
	mul.rn.f32 	%f26, %f11, %f25;
	mul.rn.f32 	%f27, %f26, %f26;
	sub.rn.f32 	%f28, %f24, %f26;
	add.rn.f32 	%f29, %f28, %f28;
	neg.f32 	%f30, %f26;
	fma.rn.f32 	%f31, %f30, %f24, %f29;
	mul.rn.f32 	%f32, %f11, %f31;
	fma.rn.f32 	%f33, %f27, 0f3A2C32E4, 0f3B52E7DB;
	fma.rn.f32 	%f34, %f33, %f27, 0f3C93BB73;
	fma.rn.f32 	%f35, %f34, %f27, 0f3DF6384F;
	mul.rn.f32 	%f36, %f35, %f27;
	fma.rn.f32 	%f37, %f26, 0f3FB8AA3B, %f23;
	sub.rn.f32 	%f38, %f23, %f37;
	fma.rn.f32 	%f39, %f26, 0f3FB8AA3B, %f38;
	fma.rn.f32 	%f40, %f32, 0f3FB8AA3B, %f39;
	fma.rn.f32 	%f41, %f26, 0f32A55E34, %f40;
	mul.rn.f32 	%f42, %f36, 0f40400000;
	fma.rn.f32 	%f43, %f42, %f32, %f41;
	fma.rn.f32 	%f44, %f36, %f26, %f43;
	add.rn.f32 	%f45, %f37, %f44;
	neg.f32 	%f46, %f37;
	add.rn.f32 	%f47, %f45, %f46;
	neg.f32 	%f48, %f47;
	add.rn.f32 	%f49, %f44, %f48;
	mul.rn.f32 	%f50, %f45, %f2;
	neg.f32 	%f51, %f50;
	fma.rn.f32 	%f52, %f45, %f2, %f51;
	fma.rn.f32 	%f53, %f49, %f2, %f52;
	cvt.rni.f32.f32 	%f54, %f50;
	sub.rn.f32 	%f55, %f50, %f54;
	add.rn.f32 	%f56, %f55, %f53;
	fma.rn.f32 	%f57, %f56, 0f391FCB8E, 0f3AAF85ED;
	fma.rn.f32 	%f58, %f57, %f56, 0f3C1D9856;
	fma.rn.f32 	%f59, %f58, %f56, 0f3D6357BB;
	fma.rn.f32 	%f60, %f59, %f56, 0f3E75FDEC;
	fma.rn.f32 	%f61, %f60, %f56, 0f3F317218;
	fma.rn.f32 	%f62, %f61, %f56, 0f3F800000;
	cvt.rzi.s32.f32 	%r6, %f54;
	setp.gt.f32 	%p2, %f54, 0f00000000;
	selp.b32 	%r7, 0, -2097152000, %p2;
	add.s32 	%r8, %r7, 2130706432;
	mov.b32 	%f63, %r8;
	mul.rn.f32 	%f64, %f62, %f63;
	shl.b32 	%r9, %r6, 23;
	sub.s32 	%r10, %r9, %r7;
	mov.b32 	%f65, %r10;
	mul.rn.f32 	%f66, %f64, %f65;
	abs.f32 	%f67, %f50;
	setp.gt.f32 	%p3, %f67, 0f43180000;
	setp.lt.f32 	%p4, %f50, 0f00000000;
	selp.f32 	%f68, 0f00000000, 0f7F800000, %p4;
	selp.f32 	%f74, %f68, %f66, %p3;
	setp.geu.f32 	%p17, %f1, 0f00000000;
	@%p17 bra 	$L__BB264_9;
	setp.neu.f32 	%p16, %f3, 0f3F800000;
	neg.f32 	%f70, %f74;
	selp.f32 	%f74, %f74, %f70, %p16;
$L__BB264_9:
	sub.rn.f32 	%f73, %f13, %f74;
	st.global.f32 	[%rd1], %f73;
	ret;
$L__BB264_3:
	add.rn.f32 	%f74, %f1, %f2;
	bra.uni 	$L__BB264_9;

}
	// .globl	loop_multiply_fusion_99
.visible .entry loop_multiply_fusion_99(
	.param .u64 loop_multiply_fusion_99_param_0,
	.param .u64 loop_multiply_fusion_99_param_1
)
.reqntid 1, 1, 1
{
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [loop_multiply_fusion_99_param_0];
	ld.param.u64 	%rd2, [loop_multiply_fusion_99_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	ld.global.nc.f32 	%f1, [%rd4];
	neg.f32 	%f2, %f1;
	st.global.f32 	[%rd3], %f2;
	ret;

}
	// .globl	loop_subtract_fusion_4
.visible .entry loop_subtract_fusion_4(
	.param .u64 loop_subtract_fusion_4_param_0,
	.param .u64 loop_subtract_fusion_4_param_1
)
.reqntid 1, 1, 1
{
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [loop_subtract_fusion_4_param_0];
	ld.param.u64 	%rd2, [loop_subtract_fusion_4_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	ld.global.nc.f32 	%f1, [%rd4];
	mov.f32 	%f2, 0f3F800000;
	sub.rn.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd3], %f3;
	ret;

}
	// .globl	loop_add_fusion_381
.visible .entry loop_add_fusion_381(
	.param .u64 loop_add_fusion_381_param_0,
	.param .u64 loop_add_fusion_381_param_1,
	.param .u64 loop_add_fusion_381_param_2,
	.param .u64 loop_add_fusion_381_param_3,
	.param .u64 loop_add_fusion_381_param_4,
	.param .u64 loop_add_fusion_381_param_5,
	.param .u64 loop_add_fusion_381_param_6,
	.param .u64 loop_add_fusion_381_param_7,
	.param .u64 loop_add_fusion_381_param_8,
	.param .u64 loop_add_fusion_381_param_9,
	.param .u64 loop_add_fusion_381_param_10,
	.param .u64 loop_add_fusion_381_param_11,
	.param .u64 loop_add_fusion_381_param_12,
	.param .u64 loop_add_fusion_381_param_13,
	.param .u64 loop_add_fusion_381_param_14,
	.param .u64 loop_add_fusion_381_param_15
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .f32 	%f<45>;
	.reg .b64 	%rd<40>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 7;
	or.b32  	%r1, %r4, %r3;
	setp.lt.u32 	%p1, %r1, 192;
	@%p1 bra 	$L__BB267_2;
	bra.uni 	$L__BB267_1;
$L__BB267_2:
	ld.param.u64 	%rd17, [loop_add_fusion_381_param_0];
	ld.param.u64 	%rd18, [loop_add_fusion_381_param_15];
	cvta.to.global.u64 	%rd1, %rd18;
	ld.param.u64 	%rd19, [loop_add_fusion_381_param_1];
	ld.param.u64 	%rd20, [loop_add_fusion_381_param_14];
	cvta.to.global.u64 	%rd2, %rd20;
	ld.param.u64 	%rd21, [loop_add_fusion_381_param_2];
	ld.param.u64 	%rd22, [loop_add_fusion_381_param_13];
	cvta.to.global.u64 	%rd3, %rd22;
	ld.param.u64 	%rd23, [loop_add_fusion_381_param_3];
	ld.param.u64 	%rd24, [loop_add_fusion_381_param_12];
	cvta.to.global.u64 	%rd4, %rd24;
	ld.param.u64 	%rd25, [loop_add_fusion_381_param_4];
	ld.param.u64 	%rd26, [loop_add_fusion_381_param_11];
	cvta.to.global.u64 	%rd5, %rd26;
	ld.param.u64 	%rd27, [loop_add_fusion_381_param_5];
	ld.param.u64 	%rd28, [loop_add_fusion_381_param_10];
	cvta.to.global.u64 	%rd6, %rd28;
	ld.param.u64 	%rd29, [loop_add_fusion_381_param_6];
	ld.param.u64 	%rd30, [loop_add_fusion_381_param_9];
	cvta.to.global.u64 	%rd7, %rd30;
	ld.param.u64 	%rd31, [loop_add_fusion_381_param_7];
	ld.param.u64 	%rd32, [loop_add_fusion_381_param_8];
	cvta.to.global.u64 	%rd8, %rd32;
	cvta.to.global.u64 	%rd9, %rd31;
	cvta.to.global.u64 	%rd10, %rd29;
	cvta.to.global.u64 	%rd11, %rd27;
	cvta.to.global.u64 	%rd12, %rd25;
	cvta.to.global.u64 	%rd13, %rd23;
	cvta.to.global.u64 	%rd14, %rd21;
	cvta.to.global.u64 	%rd15, %rd19;
	cvta.to.global.u64 	%rd16, %rd17;
	mul.wide.u32 	%rd33, %r1, 4;
	add.s64 	%rd34, %rd16, %rd33;
	ld.global.nc.f32 	%f1, [%rd34];
	ld.global.nc.f32 	%f2, [%rd10];
	ld.global.nc.f32 	%f3, [%rd3];
	add.s64 	%rd35, %rd7, %rd33;
	ld.global.f32 	%f4, [%rd35];
	fma.rn.f32 	%f5, %f1, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f6, %f5;
	mov.f32 	%f7, 0f4B400001;
	mov.f32 	%f8, 0f437C0000;
	fma.rm.f32 	%f9, %f6, %f8, %f7;
	add.rn.f32 	%f10, %f9, 0fCB40007F;
	neg.f32 	%f11, %f10;
	fma.rn.f32 	%f12, %f1, 0f3FB8AA3B, %f11;
	fma.rn.f32 	%f13, %f1, 0f32A57060, %f12;
	mov.b32 	%r5, %f9;
	shl.b32 	%r6, %r5, 23;
	mov.b32 	%f14, %r6;
	ex2.approx.ftz.f32 	%f15, %f13;
	mul.rn.f32 	%f16, %f15, %f14;
	mul.rn.f32 	%f17, %f4, %f16;
	mul.rn.f32 	%f18, %f3, %f17;
	ld.global.nc.f32 	%f19, [%rd4];
	add.s64 	%rd36, %rd5, %rd33;
	ld.global.nc.f32 	%f20, [%rd36];
	mul.rn.f32 	%f21, %f19, %f20;
	add.rn.f32 	%f22, %f21, %f18;
	ld.global.nc.f32 	%f23, [%rd11];
	ld.global.nc.f32 	%f24, [%rd6];
	mul.rn.f32 	%f25, %f17, %f17;
	mul.rn.f32 	%f26, %f24, %f25;
	ld.global.nc.f32 	%f27, [%rd8];
	add.s64 	%rd37, %rd9, %rd33;
	ld.global.nc.f32 	%f28, [%rd37];
	mul.rn.f32 	%f29, %f27, %f28;
	add.rn.f32 	%f30, %f26, %f29;
	ld.global.nc.f32 	%f31, [%rd12];
	div.full.f32 	%f32, %f30, %f31;
	ld.global.nc.f32 	%f33, [%rd13];
	add.rn.f32 	%f34, %f33, %f32;
	sqrt.approx.f32 	%f35, %f34;
	ld.global.nc.f32 	%f36, [%rd14];
	add.rn.f32 	%f37, %f35, %f36;
	mul.rn.f32 	%f38, %f23, %f37;
	div.full.f32 	%f39, %f22, %f38;
	ld.global.nc.f32 	%f40, [%rd15];
	mul.rn.f32 	%f41, %f1, %f40;
	add.rn.f32 	%f42, %f41, %f39;
	mul.rn.f32 	%f43, %f2, %f42;
	add.rn.f32 	%f44, %f1, %f43;
	add.s64 	%rd38, %rd2, %rd33;
	st.global.f32 	[%rd38], %f44;
	add.s64 	%rd39, %rd1, %rd33;
	st.global.f32 	[%rd39], %f30;
	st.global.f32 	[%rd35], %f22;
$L__BB267_1:
	ret;

}
	// .globl	input_concatenate_fusion_326
.visible .entry input_concatenate_fusion_326(
	.param .u64 input_concatenate_fusion_326_param_0,
	.param .u64 input_concatenate_fusion_326_param_1,
	.param .u64 input_concatenate_fusion_326_param_2,
	.param .u64 input_concatenate_fusion_326_param_3,
	.param .u64 input_concatenate_fusion_326_param_4,
	.param .u64 input_concatenate_fusion_326_param_5
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot268[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<101>;
	.reg .b16 	%rs<18>;
	.reg .b32 	%r<637>;
	.reg .f32 	%f<337>;
	.reg .b64 	%rd<244>;
	.reg .f64 	%fd<25>;

	mov.u64 	%SPL, __local_depot268;
	ld.param.u64 	%rd64, [input_concatenate_fusion_326_param_0];
	ld.param.u64 	%rd66, [input_concatenate_fusion_326_param_1];
	ld.param.u64 	%rd67, [input_concatenate_fusion_326_param_4];
	cvta.to.global.u64 	%rd2, %rd67;
	ld.param.u64 	%rd68, [input_concatenate_fusion_326_param_2];
	cvta.to.global.u64 	%rd5, %rd66;
	cvta.to.global.u64 	%rd70, %rd64;
	add.u64 	%rd6, %SPL, 0;
	mov.u32 	%r184, %ctaid.x;
	mov.u32 	%r185, %tid.x;
	shl.b32 	%r186, %r184, 7;
	or.b32  	%r187, %r186, %r185;
	cvt.u16.u32 	%rs4, %r187;
	mul.hi.u16 	%rs5, %rs4, -21845;
	shr.u16 	%rs6, %rs5, 1;
	mul.lo.s16 	%rs7, %rs6, 3;
	sub.s16 	%rs1, %rs4, %rs7;
	mul.hi.u16 	%rs8, %rs6, 5243;
	shr.u16 	%rs9, %rs8, 2;
	mul.lo.s16 	%rs10, %rs9, 50;
	sub.s16 	%rs11, %rs6, %rs10;
	shr.u16 	%rs12, %rs4, 1;
	mul.hi.u16 	%rs13, %rs12, -9611;
	shr.u16 	%rs14, %rs13, 6;
	and.b16  	%rs15, %rs14, 63;
	shl.b16 	%rs2, %rs1, 1;
	cvt.u64.u16 	%rd18, %rs15;
	cvt.u32.u16 	%r188, %rs11;
	mul.wide.u32 	%rd83, %r188, 48;
	cvt.u32.u16 	%r189, %rs15;
	mul.wide.u32 	%rd84, %r189, 2400;
	add.s64 	%rd85, %rd70, %rd84;
	add.s64 	%rd86, %rd85, %rd83;
	cvt.u32.u16 	%r190, %rs2;
	mul.wide.u32 	%rd87, %r190, 4;
	add.s64 	%rd21, %rd86, %rd87;
	ld.global.nc.f32 	%f1, [%rd21+24];
	cvt.u32.u16 	%r191, %rs1;
	mul.wide.u32 	%rd88, %r191, 4;
	mul.wide.u32 	%rd89, %r189, 12;
	add.s64 	%rd90, %rd5, %rd89;
	add.s64 	%rd91, %rd90, %rd88;
	ld.global.nc.f32 	%f60, [%rd91];
	add.rn.f32 	%f61, %f60, %f60;
	add.rn.f32 	%f62, %f61, %f61;
	add.rn.f32 	%f63, %f62, %f62;
	add.rn.f32 	%f2, %f63, %f63;
	add.rn.f32 	%f3, %f2, %f2;
	mul.rn.f32 	%f64, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r628, %f64;
	cvt.rn.f32.s32 	%f65, %r628;
	fma.rn.f32 	%f66, %f65, 0fBFC90FDA, %f3;
	fma.rn.f32 	%f67, %f65, 0fB3A22168, %f66;
	fma.rn.f32 	%f334, %f65, 0fA7C234C5, %f67;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p1, %f5, 0f47CE4780;
	mov.f32 	%f324, 0f00000000;
	setp.neu.f32 	%p99, %f5, 0f7F800000;
	mov.u32 	%r592, %r628;
	mov.f32 	%f325, %f334;
	@%p1 bra 	$L__BB268_8;
	@%p99 bra 	$L__BB268_3;
	mul.rn.f32 	%f325, %f3, %f324;
	mov.b32 	%r592, 0;
	bra.uni 	$L__BB268_8;
$L__BB268_3:
	mov.b32 	%r589, 0;
	mov.b32 	%r2, %f3;
	shr.u32 	%r3, %r2, 23;
	and.b32  	%r193, %r3, 224;
	add.s32 	%r194, %r193, -128;
	shl.b32 	%r195, %r2, 8;
	or.b32  	%r199, %r195, -2147483648;
	shr.u32 	%r5, %r194, 5;
	mov.u64 	%rd232, 0;
	mov.u64 	%rd93, __cudart_i2opi_f;
$L__BB268_4:
	.pragma "nounroll";
	add.s64 	%rd94, %rd93, %rd232;
	ld.global.nc.u32 	%r198, [%rd94];
	// begin inline asm
	{
	mad.lo.cc.u32   %r196, %r198, %r199, %r589;
	madc.hi.u32     %r589, %r198, %r199,  0;
	}
	// end inline asm
	add.s64 	%rd95, %rd6, %rd232;
	st.local.u32 	[%rd95], %r196;
	add.s64 	%rd232, %rd232, 4;
	cvt.u32.u64 	%r201, %rd232;
	setp.ne.s32 	%p3, %r201, 24;
	@%p3 bra 	$L__BB268_4;
	st.local.u32 	[%rd6+24], %r589;
	and.b32  	%r8, %r3, 31;
	mul.wide.u32 	%rd96, %r5, 4;
	sub.s64 	%rd25, %rd6, %rd96;
	ld.local.u32 	%r590, [%rd25+24];
	ld.local.u32 	%r591, [%rd25+20];
	setp.eq.s32 	%p4, %r8, 0;
	@%p4 bra 	$L__BB268_7;
	shl.b32 	%r202, %r591, %r8;
	shl.b32 	%r203, %r590, %r8;
	mov.b32 	%r204, 32;
	sub.s32 	%r205, %r204, %r8;
	shr.u32 	%r206, %r591, %r205;
	add.s32 	%r590, %r206, %r203;
	ld.local.u32 	%r207, [%rd25+16];
	shr.u32 	%r208, %r207, %r205;
	add.s32 	%r591, %r208, %r202;
$L__BB268_7:
	shr.u32 	%r209, %r590, 30;
	shr.u32 	%r210, %r591, 30;
	shl.b32 	%r211, %r590, 2;
	or.b32  	%r212, %r211, %r210;
	shl.b32 	%r213, %r591, 2;
	bfe.u32 	%r214, %r590, 29, 1;
	add.s32 	%r215, %r214, %r209;
	neg.s32 	%r216, %r215;
	setp.lt.s32 	%p5, %r2, 0;
	selp.b32 	%r592, %r216, %r215, %p5;
	xor.b32  	%r217, %r212, %r2;
	bfe.s32 	%r218, %r590, 29, 1;
	xor.b32  	%r219, %r218, %r212;
	xor.b32  	%r220, %r218, %r213;
	cvt.u64.u32 	%rd97, %r219;
	shl.b64 	%rd98, %rd97, 32;
	cvt.u64.u32 	%rd99, %r220;
	or.b64  	%rd100, %rd98, %rd99;
	cvt.rn.f64.s64 	%fd1, %rd100;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f68, %fd2;
	neg.f32 	%f69, %f68;
	setp.lt.s32 	%p6, %r217, 0;
	selp.f32 	%f325, %f69, %f68, %p6;
$L__BB268_8:
	ld.param.u64 	%rd69, [input_concatenate_fusion_326_param_3];
	cvta.to.global.u64 	%rd4, %rd68;
	cvt.u64.u16 	%rd19, %rs11;
	cvt.u64.u16 	%rd20, %rs2;
	add.s32 	%r222, %r592, 1;
	mul.rn.f32 	%f71, %f325, %f325;
	and.b32  	%r223, %r592, 1;
	setp.eq.b32 	%p7, %r223, 1;
	selp.f32 	%f72, %f325, 0f3F800000, %p7;
	fma.rn.f32 	%f73, %f71, %f72, 0f00000000;
	fma.rn.f32 	%f74, %f71, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f75, 0fB94D4153, %f74, %p7;
	selp.f32 	%f76, 0f3C0885E4, 0f3D2AAABB, %p7;
	fma.rn.f32 	%f77, %f75, %f71, %f76;
	selp.f32 	%f78, 0fBE2AAAA8, 0fBEFFFFFF, %p7;
	fma.rn.f32 	%f79, %f77, %f71, %f78;
	shl.b64 	%rd101, %rd18, 2;
	add.s64 	%rd102, %rd2, %rd101;
	ld.global.nc.f32 	%f83, [%rd102];
	fma.rn.f32 	%f84, %f83, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f85, %f84;
	mov.f32 	%f86, 0f4B400001;
	mov.f32 	%f87, 0f437C0000;
	fma.rm.f32 	%f88, %f85, %f87, %f86;
	add.rn.f32 	%f89, %f88, 0fCB40007F;
	neg.f32 	%f90, %f89;
	fma.rn.f32 	%f91, %f83, 0f3FB8AA3B, %f90;
	fma.rn.f32 	%f92, %f83, 0f32A57060, %f91;
	mov.b32 	%r225, %f88;
	shl.b32 	%r226, %r225, 23;
	mov.b32 	%f93, %r226;
	ex2.approx.ftz.f32 	%f94, %f92;
	mul.rn.f32 	%f95, %f94, %f93;
	neg.f32 	%f96, %f95;
	sub.rn.f32 	%f97, %f96, %f95;
	add.rn.f32 	%f98, %f97, %f97;
	add.rn.f32 	%f99, %f98, %f98;
	add.rn.f32 	%f100, %f99, %f99;
	add.rn.f32 	%f101, %f100, %f100;
	add.rn.f32 	%f102, %f101, %f101;
	add.rn.f32 	%f103, %f102, %f102;
	add.rn.f32 	%f104, %f103, %f103;
	fma.rn.f32 	%f105, %f104, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f106, %f105;
	fma.rm.f32 	%f107, %f106, %f87, %f86;
	add.rn.f32 	%f108, %f107, 0fCB40007F;
	neg.f32 	%f109, %f108;
	fma.rn.f32 	%f110, %f104, 0f3FB8AA3B, %f109;
	fma.rn.f32 	%f111, %f104, 0f32A57060, %f110;
	mov.b32 	%r227, %f107;
	shl.b32 	%r228, %r227, 23;
	mov.b32 	%f112, %r228;
	ex2.approx.ftz.f32 	%f113, %f111;
	mul.rn.f32 	%f114, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r636, %f114;
	cvt.rn.f32.s32 	%f115, %r636;
	fma.rn.f32 	%f116, %f115, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f117, %f115, 0fB3A22168, %f116;
	fma.rn.f32 	%f336, %f115, 0fA7C234C5, %f117;
	abs.f32 	%f12, %f2;
	setp.ltu.f32 	%p9, %f12, 0f47CE4780;
	setp.neu.f32 	%p98, %f12, 0f7F800000;
	mov.u32 	%r596, %r636;
	mov.f32 	%f326, %f336;
	@%p9 bra 	$L__BB268_16;
	@%p98 bra 	$L__BB268_11;
	mul.rn.f32 	%f326, %f2, %f324;
	mov.b32 	%r596, 0;
	bra.uni 	$L__BB268_16;
$L__BB268_11:
	mov.b32 	%r18, %f2;
	shr.u32 	%r19, %r18, 23;
	and.b32  	%r230, %r19, 224;
	add.s32 	%r231, %r230, -128;
	shl.b32 	%r232, %r18, 8;
	or.b32  	%r236, %r232, -2147483648;
	shr.u32 	%r21, %r231, 5;
	mov.b32 	%r593, 0;
	mov.u64 	%rd233, 0;
	mov.u64 	%rd104, __cudart_i2opi_f;
$L__BB268_12:
	.pragma "nounroll";
	add.s64 	%rd105, %rd104, %rd233;
	ld.global.nc.u32 	%r235, [%rd105];
	// begin inline asm
	{
	mad.lo.cc.u32   %r233, %r235, %r236, %r593;
	madc.hi.u32     %r593, %r235, %r236,  0;
	}
	// end inline asm
	add.s64 	%rd106, %rd6, %rd233;
	st.local.u32 	[%rd106], %r233;
	add.s64 	%rd233, %rd233, 4;
	cvt.u32.u64 	%r238, %rd233;
	setp.ne.s32 	%p11, %r238, 24;
	@%p11 bra 	$L__BB268_12;
	st.local.u32 	[%rd6+24], %r593;
	and.b32  	%r24, %r19, 31;
	mul.wide.u32 	%rd107, %r21, 4;
	sub.s64 	%rd28, %rd6, %rd107;
	ld.local.u32 	%r594, [%rd28+24];
	ld.local.u32 	%r595, [%rd28+20];
	setp.eq.s32 	%p12, %r24, 0;
	@%p12 bra 	$L__BB268_15;
	shl.b32 	%r239, %r595, %r24;
	shl.b32 	%r240, %r594, %r24;
	mov.b32 	%r241, 32;
	sub.s32 	%r242, %r241, %r24;
	shr.u32 	%r243, %r595, %r242;
	add.s32 	%r594, %r243, %r240;
	ld.local.u32 	%r244, [%rd28+16];
	shr.u32 	%r245, %r244, %r242;
	add.s32 	%r595, %r245, %r239;
$L__BB268_15:
	shr.u32 	%r246, %r594, 30;
	shr.u32 	%r247, %r595, 30;
	shl.b32 	%r248, %r594, 2;
	or.b32  	%r249, %r248, %r247;
	shl.b32 	%r250, %r595, 2;
	bfe.u32 	%r251, %r594, 29, 1;
	add.s32 	%r252, %r251, %r246;
	neg.s32 	%r253, %r252;
	setp.lt.s32 	%p13, %r18, 0;
	selp.b32 	%r596, %r253, %r252, %p13;
	xor.b32  	%r254, %r249, %r18;
	bfe.s32 	%r255, %r594, 29, 1;
	xor.b32  	%r256, %r255, %r249;
	xor.b32  	%r257, %r255, %r250;
	cvt.u64.u32 	%rd108, %r256;
	shl.b64 	%rd109, %rd108, 32;
	cvt.u64.u32 	%rd110, %r257;
	or.b64  	%rd111, %rd109, %rd110;
	cvt.rn.f64.s64 	%fd3, %rd111;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f118, %fd4;
	neg.f32 	%f119, %f118;
	setp.lt.s32 	%p14, %r254, 0;
	selp.f32 	%f326, %f119, %f118, %p14;
$L__BB268_16:
	fma.rn.f32 	%f80, %f79, %f73, %f72;
	and.b32  	%r224, %r222, 2;
	cvta.to.global.u64 	%rd3, %rd69;
	cvt.u64.u16 	%rd22, %rs1;
	mul.rn.f32 	%f10, %f113, %f112;
	add.s32 	%r259, %r596, 1;
	mul.rn.f32 	%f121, %f326, %f326;
	and.b32  	%r260, %r596, 1;
	setp.eq.b32 	%p16, %r260, 1;
	selp.f32 	%f122, %f326, 0f3F800000, %p16;
	fma.rn.f32 	%f123, %f121, %f122, 0f00000000;
	fma.rn.f32 	%f124, %f121, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f125, 0fB94D4153, %f124, %p16;
	selp.f32 	%f126, 0f3C0885E4, 0f3D2AAABB, %p16;
	fma.rn.f32 	%f127, %f125, %f121, %f126;
	selp.f32 	%f128, 0fBE2AAAA8, 0fBEFFFFFF, %p16;
	fma.rn.f32 	%f129, %f127, %f121, %f128;
	fma.rn.f32 	%f130, %f129, %f123, %f122;
	and.b32  	%r261, %r259, 2;
	setp.eq.s32 	%p17, %r261, 0;
	sub.rn.f32 	%f132, %f324, %f130;
	selp.f32 	%f133, %f130, %f132, %p17;
	mul.lo.s64 	%rd112, %rd18, 4800;
	add.s64 	%rd113, %rd4, %rd112;
	mul.lo.s64 	%rd114, %rd19, 96;
	add.s64 	%rd115, %rd113, %rd114;
	shl.b64 	%rd116, %rd20, 2;
	add.s64 	%rd29, %rd115, %rd116;
	ld.global.nc.f32 	%f16, [%rd29];
	mul.rn.f32 	%f17, %f16, %f133;
	mov.u32 	%r600, %r636;
	mov.f32 	%f327, %f336;
	@%p9 bra 	$L__BB268_24;
	@%p98 bra 	$L__BB268_19;
	mul.rn.f32 	%f327, %f2, %f324;
	mov.b32 	%r600, 0;
	bra.uni 	$L__BB268_24;
$L__BB268_19:
	mov.b32 	%r33, %f2;
	shr.u32 	%r34, %r33, 23;
	and.b32  	%r263, %r34, 224;
	add.s32 	%r264, %r263, -128;
	shl.b32 	%r265, %r33, 8;
	or.b32  	%r269, %r265, -2147483648;
	shr.u32 	%r36, %r264, 5;
	mov.b32 	%r597, 0;
	mov.u64 	%rd234, 0;
	mov.u64 	%rd118, __cudart_i2opi_f;
$L__BB268_20:
	.pragma "nounroll";
	add.s64 	%rd119, %rd118, %rd234;
	ld.global.nc.u32 	%r268, [%rd119];
	// begin inline asm
	{
	mad.lo.cc.u32   %r266, %r268, %r269, %r597;
	madc.hi.u32     %r597, %r268, %r269,  0;
	}
	// end inline asm
	add.s64 	%rd120, %rd6, %rd234;
	st.local.u32 	[%rd120], %r266;
	add.s64 	%rd234, %rd234, 4;
	cvt.u32.u64 	%r271, %rd234;
	setp.ne.s32 	%p19, %r271, 24;
	@%p19 bra 	$L__BB268_20;
	st.local.u32 	[%rd6+24], %r597;
	and.b32  	%r39, %r34, 31;
	mul.wide.u32 	%rd121, %r36, 4;
	sub.s64 	%rd32, %rd6, %rd121;
	ld.local.u32 	%r598, [%rd32+24];
	ld.local.u32 	%r599, [%rd32+20];
	setp.eq.s32 	%p20, %r39, 0;
	@%p20 bra 	$L__BB268_23;
	shl.b32 	%r272, %r599, %r39;
	shl.b32 	%r273, %r598, %r39;
	mov.b32 	%r274, 32;
	sub.s32 	%r275, %r274, %r39;
	shr.u32 	%r276, %r599, %r275;
	add.s32 	%r598, %r276, %r273;
	ld.local.u32 	%r277, [%rd32+16];
	shr.u32 	%r278, %r277, %r275;
	add.s32 	%r599, %r278, %r272;
$L__BB268_23:
	shr.u32 	%r279, %r598, 30;
	shr.u32 	%r280, %r599, 30;
	shl.b32 	%r281, %r598, 2;
	or.b32  	%r282, %r281, %r280;
	shl.b32 	%r283, %r599, 2;
	bfe.u32 	%r284, %r598, 29, 1;
	add.s32 	%r285, %r284, %r279;
	neg.s32 	%r286, %r285;
	setp.lt.s32 	%p21, %r33, 0;
	selp.b32 	%r600, %r286, %r285, %p21;
	xor.b32  	%r287, %r282, %r33;
	bfe.s32 	%r288, %r598, 29, 1;
	xor.b32  	%r289, %r288, %r282;
	xor.b32  	%r290, %r288, %r283;
	cvt.u64.u32 	%rd122, %r289;
	shl.b64 	%rd123, %rd122, 32;
	cvt.u64.u32 	%rd124, %r290;
	or.b64  	%rd125, %rd123, %rd124;
	cvt.rn.f64.s64 	%fd5, %rd125;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f134, %fd6;
	neg.f32 	%f135, %f134;
	setp.lt.s32 	%p22, %r287, 0;
	selp.f32 	%f327, %f135, %f134, %p22;
$L__BB268_24:
	setp.eq.s32 	%p8, %r224, 0;
	sub.rn.f32 	%f82, %f324, %f80;
	mul.rn.f32 	%f137, %f327, %f327;
	and.b32  	%r292, %r600, 1;
	setp.eq.b32 	%p24, %r292, 1;
	selp.f32 	%f138, 0f3F800000, %f327, %p24;
	fma.rn.f32 	%f139, %f137, %f138, 0f00000000;
	fma.rn.f32 	%f140, %f137, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f141, %f140, 0fB94D4153, %p24;
	selp.f32 	%f142, 0f3D2AAABB, 0f3C0885E4, %p24;
	fma.rn.f32 	%f143, %f141, %f137, %f142;
	selp.f32 	%f144, 0fBEFFFFFF, 0fBE2AAAA8, %p24;
	fma.rn.f32 	%f145, %f143, %f137, %f144;
	fma.rn.f32 	%f146, %f145, %f139, %f138;
	and.b32  	%r293, %r600, 2;
	setp.eq.s32 	%p25, %r293, 0;
	sub.rn.f32 	%f148, %f324, %f146;
	selp.f32 	%f149, %f146, %f148, %p25;
	mul.lo.s64 	%rd126, %rd18, 2400;
	add.s64 	%rd127, %rd3, %rd126;
	mul.lo.s64 	%rd128, %rd19, 48;
	add.s64 	%rd129, %rd127, %rd128;
	shl.b64 	%rd130, %rd22, 3;
	add.s64 	%rd33, %rd129, %rd130;
	ld.global.nc.f32 	%f21, [%rd33];
	mul.rn.f32 	%f150, %f21, %f149;
	add.rn.f32 	%f151, %f17, %f150;
	mul.rn.f32 	%f152, %f10, %f151;
	ld.global.nc.f32 	%f22, [%rd29+24];
	mov.u32 	%r604, %r628;
	mov.f32 	%f328, %f334;
	@%p1 bra 	$L__BB268_32;
	@%p99 bra 	$L__BB268_27;
	mul.rn.f32 	%f328, %f3, %f324;
	mov.b32 	%r604, 0;
	bra.uni 	$L__BB268_32;
$L__BB268_27:
	mov.b32 	%r48, %f3;
	shr.u32 	%r49, %r48, 23;
	and.b32  	%r295, %r49, 224;
	add.s32 	%r296, %r295, -128;
	shl.b32 	%r297, %r48, 8;
	or.b32  	%r301, %r297, -2147483648;
	shr.u32 	%r51, %r296, 5;
	mov.b32 	%r601, 0;
	mov.u64 	%rd235, 0;
	mov.u64 	%rd132, __cudart_i2opi_f;
$L__BB268_28:
	.pragma "nounroll";
	add.s64 	%rd133, %rd132, %rd235;
	ld.global.nc.u32 	%r300, [%rd133];
	// begin inline asm
	{
	mad.lo.cc.u32   %r298, %r300, %r301, %r601;
	madc.hi.u32     %r601, %r300, %r301,  0;
	}
	// end inline asm
	add.s64 	%rd134, %rd6, %rd235;
	st.local.u32 	[%rd134], %r298;
	add.s64 	%rd235, %rd235, 4;
	cvt.u32.u64 	%r303, %rd235;
	setp.ne.s32 	%p27, %r303, 24;
	@%p27 bra 	$L__BB268_28;
	st.local.u32 	[%rd6+24], %r601;
	and.b32  	%r54, %r49, 31;
	mul.wide.u32 	%rd135, %r51, 4;
	sub.s64 	%rd36, %rd6, %rd135;
	ld.local.u32 	%r602, [%rd36+24];
	ld.local.u32 	%r603, [%rd36+20];
	setp.eq.s32 	%p28, %r54, 0;
	@%p28 bra 	$L__BB268_31;
	shl.b32 	%r304, %r603, %r54;
	shl.b32 	%r305, %r602, %r54;
	mov.b32 	%r306, 32;
	sub.s32 	%r307, %r306, %r54;
	shr.u32 	%r308, %r603, %r307;
	add.s32 	%r602, %r308, %r305;
	ld.local.u32 	%r309, [%rd36+16];
	shr.u32 	%r310, %r309, %r307;
	add.s32 	%r603, %r310, %r304;
$L__BB268_31:
	shr.u32 	%r311, %r602, 30;
	shr.u32 	%r312, %r603, 30;
	shl.b32 	%r313, %r602, 2;
	or.b32  	%r314, %r313, %r312;
	shl.b32 	%r315, %r603, 2;
	bfe.u32 	%r316, %r602, 29, 1;
	add.s32 	%r317, %r316, %r311;
	neg.s32 	%r318, %r317;
	setp.lt.s32 	%p29, %r48, 0;
	selp.b32 	%r604, %r318, %r317, %p29;
	xor.b32  	%r319, %r314, %r48;
	bfe.s32 	%r320, %r602, 29, 1;
	xor.b32  	%r321, %r320, %r314;
	xor.b32  	%r322, %r320, %r315;
	cvt.u64.u32 	%rd136, %r321;
	shl.b64 	%rd137, %rd136, 32;
	cvt.u64.u32 	%rd138, %r322;
	or.b64  	%rd139, %rd137, %rd138;
	cvt.rn.f64.s64 	%fd7, %rd139;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f154, %fd8;
	neg.f32 	%f155, %f154;
	setp.lt.s32 	%p30, %r319, 0;
	selp.f32 	%f328, %f155, %f154, %p30;
$L__BB268_32:
	ld.param.u64 	%rd65, [input_concatenate_fusion_326_param_5];
	selp.f32 	%f9, %f80, %f82, %p8;
	add.rn.f32 	%f153, %f22, %f152;
	mul.rn.f32 	%f157, %f328, %f328;
	and.b32  	%r324, %r604, 1;
	setp.eq.b32 	%p31, %r324, 1;
	selp.f32 	%f158, 0f3F800000, %f328, %p31;
	fma.rn.f32 	%f159, %f157, %f158, 0f00000000;
	fma.rn.f32 	%f160, %f157, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f161, %f160, 0fB94D4153, %p31;
	selp.f32 	%f162, 0f3D2AAABB, 0f3C0885E4, %p31;
	fma.rn.f32 	%f163, %f161, %f157, %f162;
	selp.f32 	%f164, 0fBEFFFFFF, 0fBE2AAAA8, %p31;
	fma.rn.f32 	%f165, %f163, %f157, %f164;
	fma.rn.f32 	%f166, %f165, %f159, %f158;
	and.b32  	%r325, %r604, 2;
	setp.eq.s32 	%p32, %r325, 0;
	sub.rn.f32 	%f168, %f324, %f166;
	or.b16  	%rs16, %rs2, 1;
	setp.gt.u16 	%p33, %rs1, 1;
	selp.b16 	%rs3, 5, %rs16, %p33;
	shr.u16 	%rs17, %rs3, 1;
	mul.lo.s64 	%rd140, %rd18, 12;
	add.s64 	%rd141, %rd5, %rd140;
	cvt.u32.u16 	%r326, %rs17;
	mul.wide.u32 	%rd142, %r326, 4;
	add.s64 	%rd143, %rd141, %rd142;
	ld.global.nc.f32 	%f169, [%rd143];
	add.rn.f32 	%f170, %f169, %f169;
	add.rn.f32 	%f171, %f170, %f170;
	add.rn.f32 	%f172, %f171, %f171;
	add.rn.f32 	%f28, %f172, %f172;
	mul.rn.f32 	%f173, %f28, 0f3F22F983;
	cvt.rni.s32.f32 	%r612, %f173;
	cvt.rn.f32.s32 	%f174, %r612;
	fma.rn.f32 	%f175, %f174, 0fBFC90FDA, %f28;
	fma.rn.f32 	%f176, %f174, 0fB3A22168, %f175;
	fma.rn.f32 	%f330, %f174, 0fA7C234C5, %f176;
	abs.f32 	%f30, %f28;
	setp.ltu.f32 	%p34, %f30, 0f47CE4780;
	setp.neu.f32 	%p100, %f30, 0f7F800000;
	mov.u32 	%r608, %r612;
	mov.f32 	%f329, %f330;
	@%p34 bra 	$L__BB268_40;
	@%p100 bra 	$L__BB268_35;
	mul.rn.f32 	%f329, %f28, %f324;
	mov.b32 	%r608, 0;
	bra.uni 	$L__BB268_40;
$L__BB268_35:
	mov.b32 	%r64, %f28;
	shr.u32 	%r65, %r64, 23;
	and.b32  	%r328, %r65, 224;
	add.s32 	%r329, %r328, -128;
	shl.b32 	%r330, %r64, 8;
	or.b32  	%r334, %r330, -2147483648;
	shr.u32 	%r67, %r329, 5;
	mov.b32 	%r605, 0;
	mov.u64 	%rd236, 0;
	mov.u64 	%rd145, __cudart_i2opi_f;
$L__BB268_36:
	.pragma "nounroll";
	add.s64 	%rd146, %rd145, %rd236;
	ld.global.nc.u32 	%r333, [%rd146];
	// begin inline asm
	{
	mad.lo.cc.u32   %r331, %r333, %r334, %r605;
	madc.hi.u32     %r605, %r333, %r334,  0;
	}
	// end inline asm
	add.s64 	%rd147, %rd6, %rd236;
	st.local.u32 	[%rd147], %r331;
	add.s64 	%rd236, %rd236, 4;
	cvt.u32.u64 	%r336, %rd236;
	setp.ne.s32 	%p36, %r336, 24;
	@%p36 bra 	$L__BB268_36;
	st.local.u32 	[%rd6+24], %r605;
	and.b32  	%r70, %r65, 31;
	mul.wide.u32 	%rd148, %r67, 4;
	sub.s64 	%rd40, %rd6, %rd148;
	ld.local.u32 	%r606, [%rd40+24];
	ld.local.u32 	%r607, [%rd40+20];
	setp.eq.s32 	%p37, %r70, 0;
	@%p37 bra 	$L__BB268_39;
	shl.b32 	%r337, %r607, %r70;
	shl.b32 	%r338, %r606, %r70;
	mov.b32 	%r339, 32;
	sub.s32 	%r340, %r339, %r70;
	shr.u32 	%r341, %r607, %r340;
	add.s32 	%r606, %r341, %r338;
	ld.local.u32 	%r342, [%rd40+16];
	shr.u32 	%r343, %r342, %r340;
	add.s32 	%r607, %r343, %r337;
$L__BB268_39:
	shr.u32 	%r344, %r606, 30;
	shr.u32 	%r345, %r607, 30;
	shl.b32 	%r346, %r606, 2;
	or.b32  	%r347, %r346, %r345;
	shl.b32 	%r348, %r607, 2;
	bfe.u32 	%r349, %r606, 29, 1;
	add.s32 	%r350, %r349, %r344;
	neg.s32 	%r351, %r350;
	setp.lt.s32 	%p38, %r64, 0;
	selp.b32 	%r608, %r351, %r350, %p38;
	xor.b32  	%r352, %r347, %r64;
	bfe.s32 	%r353, %r606, 29, 1;
	xor.b32  	%r354, %r353, %r347;
	xor.b32  	%r355, %r353, %r348;
	cvt.u64.u32 	%rd149, %r354;
	shl.b64 	%rd150, %rd149, 32;
	cvt.u64.u32 	%rd151, %r355;
	or.b64  	%rd152, %rd150, %rd151;
	cvt.rn.f64.s64 	%fd9, %rd152;
	mul.rn.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f177, %fd10;
	neg.f32 	%f178, %f177;
	setp.lt.s32 	%p39, %r352, 0;
	selp.f32 	%f329, %f178, %f177, %p39;
$L__BB268_40:
	cvta.to.global.u64 	%rd1, %rd65;
	mul.rn.f32 	%f23, %f9, %f153;
	selp.f32 	%f27, %f166, %f168, %p32;
	cvt.u64.u16 	%rd37, %rs17;
	add.s32 	%r357, %r608, 1;
	mul.rn.f32 	%f180, %f329, %f329;
	and.b32  	%r358, %r608, 1;
	setp.eq.b32 	%p41, %r358, 1;
	selp.f32 	%f181, %f329, 0f3F800000, %p41;
	fma.rn.f32 	%f182, %f180, %f181, 0f00000000;
	fma.rn.f32 	%f183, %f180, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f184, 0fB94D4153, %f183, %p41;
	selp.f32 	%f185, 0f3C0885E4, 0f3D2AAABB, %p41;
	fma.rn.f32 	%f186, %f184, %f180, %f185;
	selp.f32 	%f187, 0fBE2AAAA8, 0fBEFFFFFF, %p41;
	fma.rn.f32 	%f188, %f186, %f180, %f187;
	fma.rn.f32 	%f189, %f188, %f182, %f181;
	and.b32  	%r359, %r357, 2;
	setp.eq.s32 	%p42, %r359, 0;
	sub.rn.f32 	%f191, %f324, %f189;
	selp.f32 	%f192, %f189, %f191, %p42;
	cvt.u32.u16 	%r360, %rs3;
	mul.wide.u32 	%rd157, %r360, 4;
	add.s64 	%rd41, %rd115, %rd157;
	ld.global.nc.f32 	%f193, [%rd41];
	mul.rn.f32 	%f34, %f193, %f192;
	@%p34 bra 	$L__BB268_48;
	@%p100 bra 	$L__BB268_43;
	mul.rn.f32 	%f330, %f28, %f324;
	mov.b32 	%r612, 0;
	bra.uni 	$L__BB268_48;
$L__BB268_43:
	mov.b32 	%r79, %f28;
	shr.u32 	%r80, %r79, 23;
	and.b32  	%r362, %r80, 224;
	add.s32 	%r363, %r362, -128;
	shl.b32 	%r364, %r79, 8;
	or.b32  	%r368, %r364, -2147483648;
	shr.u32 	%r82, %r363, 5;
	mov.b32 	%r609, 0;
	mov.u64 	%rd237, 0;
	mov.u64 	%rd159, __cudart_i2opi_f;
$L__BB268_44:
	.pragma "nounroll";
	add.s64 	%rd160, %rd159, %rd237;
	ld.global.nc.u32 	%r367, [%rd160];
	// begin inline asm
	{
	mad.lo.cc.u32   %r365, %r367, %r368, %r609;
	madc.hi.u32     %r609, %r367, %r368,  0;
	}
	// end inline asm
	add.s64 	%rd161, %rd6, %rd237;
	st.local.u32 	[%rd161], %r365;
	add.s64 	%rd237, %rd237, 4;
	cvt.u32.u64 	%r370, %rd237;
	setp.ne.s32 	%p44, %r370, 24;
	@%p44 bra 	$L__BB268_44;
	st.local.u32 	[%rd6+24], %r609;
	and.b32  	%r85, %r80, 31;
	mul.wide.u32 	%rd162, %r82, 4;
	sub.s64 	%rd44, %rd6, %rd162;
	ld.local.u32 	%r610, [%rd44+24];
	ld.local.u32 	%r611, [%rd44+20];
	setp.eq.s32 	%p45, %r85, 0;
	@%p45 bra 	$L__BB268_47;
	shl.b32 	%r371, %r611, %r85;
	shl.b32 	%r372, %r610, %r85;
	mov.b32 	%r373, 32;
	sub.s32 	%r374, %r373, %r85;
	shr.u32 	%r375, %r611, %r374;
	add.s32 	%r610, %r375, %r372;
	ld.local.u32 	%r376, [%rd44+16];
	shr.u32 	%r377, %r376, %r374;
	add.s32 	%r611, %r377, %r371;
$L__BB268_47:
	shr.u32 	%r378, %r610, 30;
	shr.u32 	%r379, %r611, 30;
	shl.b32 	%r380, %r610, 2;
	or.b32  	%r381, %r380, %r379;
	shl.b32 	%r382, %r611, 2;
	bfe.u32 	%r383, %r610, 29, 1;
	add.s32 	%r384, %r383, %r378;
	neg.s32 	%r385, %r384;
	setp.lt.s32 	%p46, %r79, 0;
	selp.b32 	%r612, %r385, %r384, %p46;
	xor.b32  	%r386, %r381, %r79;
	bfe.s32 	%r387, %r610, 29, 1;
	xor.b32  	%r388, %r387, %r381;
	xor.b32  	%r389, %r387, %r382;
	cvt.u64.u32 	%rd163, %r388;
	shl.b64 	%rd164, %rd163, 32;
	cvt.u64.u32 	%rd165, %r389;
	or.b64  	%rd166, %rd164, %rd165;
	cvt.rn.f64.s64 	%fd11, %rd166;
	mul.rn.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f194, %fd12;
	neg.f32 	%f195, %f194;
	setp.lt.s32 	%p47, %r386, 0;
	selp.f32 	%f330, %f195, %f194, %p47;
$L__BB268_48:
	mul.rn.f32 	%f197, %f330, %f330;
	and.b32  	%r391, %r612, 1;
	setp.eq.b32 	%p49, %r391, 1;
	selp.f32 	%f198, 0f3F800000, %f330, %p49;
	fma.rn.f32 	%f199, %f197, %f198, 0f00000000;
	fma.rn.f32 	%f200, %f197, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f201, %f200, 0fB94D4153, %p49;
	selp.f32 	%f202, 0f3D2AAABB, 0f3C0885E4, %p49;
	fma.rn.f32 	%f203, %f201, %f197, %f202;
	selp.f32 	%f204, 0fBEFFFFFF, 0fBE2AAAA8, %p49;
	fma.rn.f32 	%f205, %f203, %f197, %f204;
	fma.rn.f32 	%f206, %f205, %f199, %f198;
	and.b32  	%r392, %r612, 2;
	setp.eq.s32 	%p50, %r392, 0;
	sub.rn.f32 	%f208, %f324, %f206;
	selp.f32 	%f209, %f206, %f208, %p50;
	shl.b64 	%rd171, %rd37, 3;
	add.s64 	%rd172, %rd129, %rd171;
	ld.global.nc.f32 	%f210, [%rd172+4];
	mul.rn.f32 	%f211, %f210, %f209;
	add.rn.f32 	%f212, %f34, %f211;
	mul.rn.f32 	%f213, %f10, %f212;
	ld.global.nc.f32 	%f214, [%rd41+24];
	add.rn.f32 	%f215, %f214, %f213;
	mul.rn.f32 	%f216, %f27, %f215;
	sub.rn.f32 	%f217, %f23, %f216;
	mul.rn.f32 	%f218, %f1, %f217;
	mul.lo.s64 	%rd173, %rd18, 1200;
	add.s64 	%rd174, %rd1, %rd173;
	mul.lo.s64 	%rd175, %rd19, 24;
	add.s64 	%rd176, %rd174, %rd175;
	add.s64 	%rd45, %rd176, %rd116;
	st.global.f32 	[%rd45], %f218;
	ld.global.nc.f32 	%f38, [%rd21+28];
	mov.u32 	%r616, %r628;
	mov.f32 	%f331, %f334;
	@%p1 bra 	$L__BB268_56;
	@%p99 bra 	$L__BB268_51;
	mul.rn.f32 	%f331, %f3, %f324;
	mov.b32 	%r616, 0;
	bra.uni 	$L__BB268_56;
$L__BB268_51:
	mov.b32 	%r94, %f3;
	shr.u32 	%r95, %r94, 23;
	and.b32  	%r394, %r95, 224;
	add.s32 	%r395, %r394, -128;
	shl.b32 	%r396, %r94, 8;
	or.b32  	%r400, %r396, -2147483648;
	shr.u32 	%r97, %r395, 5;
	mov.b32 	%r613, 0;
	mov.u64 	%rd238, 0;
	mov.u64 	%rd179, __cudart_i2opi_f;
$L__BB268_52:
	.pragma "nounroll";
	add.s64 	%rd180, %rd179, %rd238;
	ld.global.nc.u32 	%r399, [%rd180];
	// begin inline asm
	{
	mad.lo.cc.u32   %r397, %r399, %r400, %r613;
	madc.hi.u32     %r613, %r399, %r400,  0;
	}
	// end inline asm
	add.s64 	%rd181, %rd6, %rd238;
	st.local.u32 	[%rd181], %r397;
	add.s64 	%rd238, %rd238, 4;
	cvt.u32.u64 	%r402, %rd238;
	setp.ne.s32 	%p52, %r402, 24;
	@%p52 bra 	$L__BB268_52;
	st.local.u32 	[%rd6+24], %r613;
	and.b32  	%r100, %r95, 31;
	mul.wide.u32 	%rd182, %r97, 4;
	sub.s64 	%rd48, %rd6, %rd182;
	ld.local.u32 	%r614, [%rd48+24];
	ld.local.u32 	%r615, [%rd48+20];
	setp.eq.s32 	%p53, %r100, 0;
	@%p53 bra 	$L__BB268_55;
	shl.b32 	%r403, %r615, %r100;
	shl.b32 	%r404, %r614, %r100;
	mov.b32 	%r405, 32;
	sub.s32 	%r406, %r405, %r100;
	shr.u32 	%r407, %r615, %r406;
	add.s32 	%r614, %r407, %r404;
	ld.local.u32 	%r408, [%rd48+16];
	shr.u32 	%r409, %r408, %r406;
	add.s32 	%r615, %r409, %r403;
$L__BB268_55:
	shr.u32 	%r410, %r614, 30;
	shr.u32 	%r411, %r615, 30;
	shl.b32 	%r412, %r614, 2;
	or.b32  	%r413, %r412, %r411;
	shl.b32 	%r414, %r615, 2;
	bfe.u32 	%r415, %r614, 29, 1;
	add.s32 	%r416, %r415, %r410;
	neg.s32 	%r417, %r416;
	setp.lt.s32 	%p54, %r94, 0;
	selp.b32 	%r616, %r417, %r416, %p54;
	xor.b32  	%r418, %r413, %r94;
	bfe.s32 	%r419, %r614, 29, 1;
	xor.b32  	%r420, %r419, %r413;
	xor.b32  	%r421, %r419, %r414;
	cvt.u64.u32 	%rd183, %r420;
	shl.b64 	%rd184, %rd183, 32;
	cvt.u64.u32 	%rd185, %r421;
	or.b64  	%rd186, %rd184, %rd185;
	cvt.rn.f64.s64 	%fd13, %rd186;
	mul.rn.f64 	%fd14, %fd13, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f219, %fd14;
	neg.f32 	%f220, %f219;
	setp.lt.s32 	%p55, %r418, 0;
	selp.f32 	%f331, %f220, %f219, %p55;
$L__BB268_56:
	mov.u32 	%r620, %r636;
	mov.f32 	%f332, %f336;
	@%p9 bra 	$L__BB268_64;
	@%p98 bra 	$L__BB268_59;
	mul.rn.f32 	%f332, %f2, %f324;
	mov.b32 	%r620, 0;
	bra.uni 	$L__BB268_64;
$L__BB268_59:
	mov.b32 	%r109, %f2;
	shr.u32 	%r110, %r109, 23;
	and.b32  	%r424, %r110, 224;
	add.s32 	%r425, %r424, -128;
	shl.b32 	%r426, %r109, 8;
	or.b32  	%r430, %r426, -2147483648;
	shr.u32 	%r112, %r425, 5;
	mov.b32 	%r617, 0;
	mov.u64 	%rd239, 0;
	mov.u64 	%rd188, __cudart_i2opi_f;
$L__BB268_60:
	.pragma "nounroll";
	add.s64 	%rd189, %rd188, %rd239;
	ld.global.nc.u32 	%r429, [%rd189];
	// begin inline asm
	{
	mad.lo.cc.u32   %r427, %r429, %r430, %r617;
	madc.hi.u32     %r617, %r429, %r430,  0;
	}
	// end inline asm
	add.s64 	%rd190, %rd6, %rd239;
	st.local.u32 	[%rd190], %r427;
	add.s64 	%rd239, %rd239, 4;
	cvt.u32.u64 	%r432, %rd239;
	setp.ne.s32 	%p58, %r432, 24;
	@%p58 bra 	$L__BB268_60;
	st.local.u32 	[%rd6+24], %r617;
	and.b32  	%r115, %r110, 31;
	mul.wide.u32 	%rd191, %r112, 4;
	sub.s64 	%rd51, %rd6, %rd191;
	ld.local.u32 	%r618, [%rd51+24];
	ld.local.u32 	%r619, [%rd51+20];
	setp.eq.s32 	%p59, %r115, 0;
	@%p59 bra 	$L__BB268_63;
	shl.b32 	%r433, %r619, %r115;
	shl.b32 	%r434, %r618, %r115;
	mov.b32 	%r435, 32;
	sub.s32 	%r436, %r435, %r115;
	shr.u32 	%r437, %r619, %r436;
	add.s32 	%r618, %r437, %r434;
	ld.local.u32 	%r438, [%rd51+16];
	shr.u32 	%r439, %r438, %r436;
	add.s32 	%r619, %r439, %r433;
$L__BB268_63:
	shr.u32 	%r440, %r618, 30;
	shr.u32 	%r441, %r619, 30;
	shl.b32 	%r442, %r618, 2;
	or.b32  	%r443, %r442, %r441;
	shl.b32 	%r444, %r619, 2;
	bfe.u32 	%r445, %r618, 29, 1;
	add.s32 	%r446, %r445, %r440;
	neg.s32 	%r447, %r446;
	setp.lt.s32 	%p60, %r109, 0;
	selp.b32 	%r620, %r447, %r446, %p60;
	xor.b32  	%r448, %r443, %r109;
	bfe.s32 	%r449, %r618, 29, 1;
	xor.b32  	%r450, %r449, %r443;
	xor.b32  	%r451, %r449, %r444;
	cvt.u64.u32 	%rd192, %r450;
	shl.b64 	%rd193, %rd192, 32;
	cvt.u64.u32 	%rd194, %r451;
	or.b64  	%rd195, %rd193, %rd194;
	cvt.rn.f64.s64 	%fd15, %rd195;
	mul.rn.f64 	%fd16, %fd15, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f222, %fd16;
	neg.f32 	%f223, %f222;
	setp.lt.s32 	%p61, %r448, 0;
	selp.f32 	%f332, %f223, %f222, %p61;
$L__BB268_64:
	ld.global.nc.f32 	%f45, [%rd29+4];
	mov.u32 	%r624, %r636;
	mov.f32 	%f333, %f336;
	@%p9 bra 	$L__BB268_72;
	@%p98 bra 	$L__BB268_67;
	mul.rn.f32 	%f333, %f2, %f324;
	mov.b32 	%r624, 0;
	bra.uni 	$L__BB268_72;
$L__BB268_67:
	mov.b32 	%r124, %f2;
	shr.u32 	%r125, %r124, 23;
	and.b32  	%r454, %r125, 224;
	add.s32 	%r455, %r454, -128;
	shl.b32 	%r456, %r124, 8;
	or.b32  	%r460, %r456, -2147483648;
	shr.u32 	%r127, %r455, 5;
	mov.b32 	%r621, 0;
	mov.u64 	%rd240, 0;
	mov.u64 	%rd197, __cudart_i2opi_f;
$L__BB268_68:
	.pragma "nounroll";
	add.s64 	%rd198, %rd197, %rd240;
	ld.global.nc.u32 	%r459, [%rd198];
	// begin inline asm
	{
	mad.lo.cc.u32   %r457, %r459, %r460, %r621;
	madc.hi.u32     %r621, %r459, %r460,  0;
	}
	// end inline asm
	add.s64 	%rd199, %rd6, %rd240;
	st.local.u32 	[%rd199], %r457;
	add.s64 	%rd240, %rd240, 4;
	cvt.u32.u64 	%r462, %rd240;
	setp.ne.s32 	%p64, %r462, 24;
	@%p64 bra 	$L__BB268_68;
	st.local.u32 	[%rd6+24], %r621;
	and.b32  	%r130, %r125, 31;
	mul.wide.u32 	%rd200, %r127, 4;
	sub.s64 	%rd54, %rd6, %rd200;
	ld.local.u32 	%r622, [%rd54+24];
	ld.local.u32 	%r623, [%rd54+20];
	setp.eq.s32 	%p65, %r130, 0;
	@%p65 bra 	$L__BB268_71;
	shl.b32 	%r463, %r623, %r130;
	shl.b32 	%r464, %r622, %r130;
	mov.b32 	%r465, 32;
	sub.s32 	%r466, %r465, %r130;
	shr.u32 	%r467, %r623, %r466;
	add.s32 	%r622, %r467, %r464;
	ld.local.u32 	%r468, [%rd54+16];
	shr.u32 	%r469, %r468, %r466;
	add.s32 	%r623, %r469, %r463;
$L__BB268_71:
	shr.u32 	%r470, %r622, 30;
	shr.u32 	%r471, %r623, 30;
	shl.b32 	%r472, %r622, 2;
	or.b32  	%r473, %r472, %r471;
	shl.b32 	%r474, %r623, 2;
	bfe.u32 	%r475, %r622, 29, 1;
	add.s32 	%r476, %r475, %r470;
	neg.s32 	%r477, %r476;
	setp.lt.s32 	%p66, %r124, 0;
	selp.b32 	%r624, %r477, %r476, %p66;
	xor.b32  	%r478, %r473, %r124;
	bfe.s32 	%r479, %r622, 29, 1;
	xor.b32  	%r480, %r479, %r473;
	xor.b32  	%r481, %r479, %r474;
	cvt.u64.u32 	%rd201, %r480;
	shl.b64 	%rd202, %rd201, 32;
	cvt.u64.u32 	%rd203, %r481;
	or.b64  	%rd204, %rd202, %rd203;
	cvt.rn.f64.s64 	%fd17, %rd204;
	mul.rn.f64 	%fd18, %fd17, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f225, %fd18;
	neg.f32 	%f226, %f225;
	setp.lt.s32 	%p67, %r478, 0;
	selp.f32 	%f333, %f226, %f225, %p67;
$L__BB268_72:
	ld.global.nc.f32 	%f49, [%rd33+4];
	ld.global.nc.f32 	%f50, [%rd29+28];
	@%p1 bra 	$L__BB268_80;
	@%p99 bra 	$L__BB268_75;
	mul.rn.f32 	%f334, %f3, %f324;
	mov.b32 	%r628, 0;
	bra.uni 	$L__BB268_80;
$L__BB268_75:
	mov.b32 	%r139, %f3;
	shr.u32 	%r140, %r139, 23;
	and.b32  	%r484, %r140, 224;
	add.s32 	%r485, %r484, -128;
	shl.b32 	%r486, %r139, 8;
	or.b32  	%r490, %r486, -2147483648;
	shr.u32 	%r142, %r485, 5;
	mov.b32 	%r625, 0;
	mov.u64 	%rd241, 0;
	mov.u64 	%rd206, __cudart_i2opi_f;
$L__BB268_76:
	.pragma "nounroll";
	add.s64 	%rd207, %rd206, %rd241;
	ld.global.nc.u32 	%r489, [%rd207];
	// begin inline asm
	{
	mad.lo.cc.u32   %r487, %r489, %r490, %r625;
	madc.hi.u32     %r625, %r489, %r490,  0;
	}
	// end inline asm
	add.s64 	%rd208, %rd6, %rd241;
	st.local.u32 	[%rd208], %r487;
	add.s64 	%rd241, %rd241, 4;
	cvt.u32.u64 	%r492, %rd241;
	setp.ne.s32 	%p70, %r492, 24;
	@%p70 bra 	$L__BB268_76;
	st.local.u32 	[%rd6+24], %r625;
	and.b32  	%r145, %r140, 31;
	mul.wide.u32 	%rd209, %r142, 4;
	sub.s64 	%rd57, %rd6, %rd209;
	ld.local.u32 	%r626, [%rd57+24];
	ld.local.u32 	%r627, [%rd57+20];
	setp.eq.s32 	%p71, %r145, 0;
	@%p71 bra 	$L__BB268_79;
	shl.b32 	%r493, %r627, %r145;
	shl.b32 	%r494, %r626, %r145;
	mov.b32 	%r495, 32;
	sub.s32 	%r496, %r495, %r145;
	shr.u32 	%r497, %r627, %r496;
	add.s32 	%r626, %r497, %r494;
	ld.local.u32 	%r498, [%rd57+16];
	shr.u32 	%r499, %r498, %r496;
	add.s32 	%r627, %r499, %r493;
$L__BB268_79:
	shr.u32 	%r500, %r626, 30;
	shr.u32 	%r501, %r627, 30;
	shl.b32 	%r502, %r626, 2;
	or.b32  	%r503, %r502, %r501;
	shl.b32 	%r504, %r627, 2;
	bfe.u32 	%r505, %r626, 29, 1;
	add.s32 	%r506, %r505, %r500;
	neg.s32 	%r507, %r506;
	setp.lt.s32 	%p72, %r139, 0;
	selp.b32 	%r628, %r507, %r506, %p72;
	xor.b32  	%r508, %r503, %r139;
	bfe.s32 	%r509, %r626, 29, 1;
	xor.b32  	%r510, %r509, %r503;
	xor.b32  	%r511, %r509, %r504;
	cvt.u64.u32 	%rd210, %r510;
	shl.b64 	%rd211, %rd210, 32;
	cvt.u64.u32 	%rd212, %r511;
	or.b64  	%rd213, %rd211, %rd212;
	cvt.rn.f64.s64 	%fd19, %rd213;
	mul.rn.f64 	%fd20, %fd19, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f228, %fd20;
	neg.f32 	%f229, %f228;
	setp.lt.s32 	%p73, %r508, 0;
	selp.f32 	%f334, %f229, %f228, %p73;
$L__BB268_80:
	mov.u32 	%r632, %r636;
	mov.f32 	%f335, %f336;
	@%p9 bra 	$L__BB268_88;
	@%p98 bra 	$L__BB268_83;
	mul.rn.f32 	%f335, %f2, %f324;
	mov.b32 	%r632, 0;
	bra.uni 	$L__BB268_88;
$L__BB268_83:
	mov.b32 	%r154, %f2;
	shr.u32 	%r155, %r154, 23;
	and.b32  	%r514, %r155, 224;
	add.s32 	%r515, %r514, -128;
	shl.b32 	%r516, %r154, 8;
	or.b32  	%r520, %r516, -2147483648;
	shr.u32 	%r157, %r515, 5;
	mov.b32 	%r629, 0;
	mov.u64 	%rd242, 0;
	mov.u64 	%rd215, __cudart_i2opi_f;
$L__BB268_84:
	.pragma "nounroll";
	add.s64 	%rd216, %rd215, %rd242;
	ld.global.nc.u32 	%r519, [%rd216];
	// begin inline asm
	{
	mad.lo.cc.u32   %r517, %r519, %r520, %r629;
	madc.hi.u32     %r629, %r519, %r520,  0;
	}
	// end inline asm
	add.s64 	%rd217, %rd6, %rd242;
	st.local.u32 	[%rd217], %r517;
	add.s64 	%rd242, %rd242, 4;
	cvt.u32.u64 	%r522, %rd242;
	setp.ne.s32 	%p76, %r522, 24;
	@%p76 bra 	$L__BB268_84;
	st.local.u32 	[%rd6+24], %r629;
	and.b32  	%r160, %r155, 31;
	mul.wide.u32 	%rd218, %r157, 4;
	sub.s64 	%rd60, %rd6, %rd218;
	ld.local.u32 	%r630, [%rd60+24];
	ld.local.u32 	%r631, [%rd60+20];
	setp.eq.s32 	%p77, %r160, 0;
	@%p77 bra 	$L__BB268_87;
	shl.b32 	%r523, %r631, %r160;
	shl.b32 	%r524, %r630, %r160;
	mov.b32 	%r525, 32;
	sub.s32 	%r526, %r525, %r160;
	shr.u32 	%r527, %r631, %r526;
	add.s32 	%r630, %r527, %r524;
	ld.local.u32 	%r528, [%rd60+16];
	shr.u32 	%r529, %r528, %r526;
	add.s32 	%r631, %r529, %r523;
$L__BB268_87:
	shr.u32 	%r530, %r630, 30;
	shr.u32 	%r531, %r631, 30;
	shl.b32 	%r532, %r630, 2;
	or.b32  	%r533, %r532, %r531;
	shl.b32 	%r534, %r631, 2;
	bfe.u32 	%r535, %r630, 29, 1;
	add.s32 	%r536, %r535, %r530;
	neg.s32 	%r537, %r536;
	setp.lt.s32 	%p78, %r154, 0;
	selp.b32 	%r632, %r537, %r536, %p78;
	xor.b32  	%r538, %r533, %r154;
	bfe.s32 	%r539, %r630, 29, 1;
	xor.b32  	%r540, %r539, %r533;
	xor.b32  	%r541, %r539, %r534;
	cvt.u64.u32 	%rd219, %r540;
	shl.b64 	%rd220, %rd219, 32;
	cvt.u64.u32 	%rd221, %r541;
	or.b64  	%rd222, %rd220, %rd221;
	cvt.rn.f64.s64 	%fd21, %rd222;
	mul.rn.f64 	%fd22, %fd21, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f231, %fd22;
	neg.f32 	%f232, %f231;
	setp.lt.s32 	%p79, %r538, 0;
	selp.f32 	%f335, %f232, %f231, %p79;
$L__BB268_88:
	@%p9 bra 	$L__BB268_96;
	@%p98 bra 	$L__BB268_91;
	mul.rn.f32 	%f336, %f2, %f324;
	mov.b32 	%r636, 0;
	bra.uni 	$L__BB268_96;
$L__BB268_91:
	mov.b32 	%r169, %f2;
	shr.u32 	%r170, %r169, 23;
	and.b32  	%r544, %r170, 224;
	add.s32 	%r545, %r544, -128;
	shl.b32 	%r546, %r169, 8;
	or.b32  	%r550, %r546, -2147483648;
	shr.u32 	%r172, %r545, 5;
	mov.b32 	%r633, 0;
	mov.u64 	%rd243, 0;
	mov.u64 	%rd224, __cudart_i2opi_f;
$L__BB268_92:
	.pragma "nounroll";
	add.s64 	%rd225, %rd224, %rd243;
	ld.global.nc.u32 	%r549, [%rd225];
	// begin inline asm
	{
	mad.lo.cc.u32   %r547, %r549, %r550, %r633;
	madc.hi.u32     %r633, %r549, %r550,  0;
	}
	// end inline asm
	add.s64 	%rd226, %rd6, %rd243;
	st.local.u32 	[%rd226], %r547;
	add.s64 	%rd243, %rd243, 4;
	cvt.u32.u64 	%r552, %rd243;
	setp.ne.s32 	%p82, %r552, 24;
	@%p82 bra 	$L__BB268_92;
	st.local.u32 	[%rd6+24], %r633;
	and.b32  	%r175, %r170, 31;
	mul.wide.u32 	%rd227, %r172, 4;
	sub.s64 	%rd63, %rd6, %rd227;
	ld.local.u32 	%r634, [%rd63+24];
	ld.local.u32 	%r635, [%rd63+20];
	setp.eq.s32 	%p83, %r175, 0;
	@%p83 bra 	$L__BB268_95;
	shl.b32 	%r553, %r635, %r175;
	shl.b32 	%r554, %r634, %r175;
	mov.b32 	%r555, 32;
	sub.s32 	%r556, %r555, %r175;
	shr.u32 	%r557, %r635, %r556;
	add.s32 	%r634, %r557, %r554;
	ld.local.u32 	%r558, [%rd63+16];
	shr.u32 	%r559, %r558, %r556;
	add.s32 	%r635, %r559, %r553;
$L__BB268_95:
	shr.u32 	%r560, %r634, 30;
	shr.u32 	%r561, %r635, 30;
	shl.b32 	%r562, %r634, 2;
	or.b32  	%r563, %r562, %r561;
	shl.b32 	%r564, %r635, 2;
	bfe.u32 	%r565, %r634, 29, 1;
	add.s32 	%r566, %r565, %r560;
	neg.s32 	%r567, %r566;
	setp.lt.s32 	%p84, %r169, 0;
	selp.b32 	%r636, %r567, %r566, %p84;
	xor.b32  	%r568, %r563, %r169;
	bfe.s32 	%r569, %r634, 29, 1;
	xor.b32  	%r570, %r569, %r563;
	xor.b32  	%r571, %r569, %r564;
	cvt.u64.u32 	%rd228, %r570;
	shl.b64 	%rd229, %rd228, 32;
	cvt.u64.u32 	%rd230, %r571;
	or.b64  	%rd231, %rd229, %rd230;
	cvt.rn.f64.s64 	%fd23, %rd231;
	mul.rn.f64 	%fd24, %fd23, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f234, %fd24;
	neg.f32 	%f235, %f234;
	setp.lt.s32 	%p85, %r568, 0;
	selp.f32 	%f336, %f235, %f234, %p85;
$L__BB268_96:
	add.s32 	%r573, %r632, 1;
	and.b32  	%r574, %r573, 2;
	setp.eq.s32 	%p86, %r574, 0;
	and.b32  	%r575, %r632, 1;
	setp.eq.b32 	%p87, %r575, 1;
	mul.rn.f32 	%f237, %f335, %f335;
	fma.rn.f32 	%f238, %f237, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f239, 0fB94D4153, %f238, %p87;
	selp.f32 	%f240, 0f3C0885E4, 0f3D2AAABB, %p87;
	fma.rn.f32 	%f241, %f239, %f237, %f240;
	selp.f32 	%f242, 0fBE2AAAA8, 0fBEFFFFFF, %p87;
	fma.rn.f32 	%f243, %f241, %f237, %f242;
	selp.f32 	%f244, %f335, 0f3F800000, %p87;
	fma.rn.f32 	%f245, %f237, %f244, 0f00000000;
	fma.rn.f32 	%f246, %f243, %f245, %f244;
	sub.rn.f32 	%f248, %f324, %f246;
	selp.f32 	%f249, %f246, %f248, %p86;
	mul.rn.f32 	%f250, %f16, %f249;
	and.b32  	%r576, %r628, 2;
	setp.eq.s32 	%p88, %r576, 0;
	and.b32  	%r577, %r628, 1;
	setp.eq.b32 	%p89, %r577, 1;
	mul.rn.f32 	%f251, %f334, %f334;
	fma.rn.f32 	%f252, %f251, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f253, %f252, 0fB94D4153, %p89;
	selp.f32 	%f254, 0f3D2AAABB, 0f3C0885E4, %p89;
	fma.rn.f32 	%f255, %f253, %f251, %f254;
	selp.f32 	%f256, 0fBEFFFFFF, 0fBE2AAAA8, %p89;
	fma.rn.f32 	%f257, %f255, %f251, %f256;
	selp.f32 	%f258, 0f3F800000, %f334, %p89;
	fma.rn.f32 	%f259, %f251, %f258, 0f00000000;
	fma.rn.f32 	%f260, %f257, %f259, %f258;
	sub.rn.f32 	%f261, %f324, %f260;
	selp.f32 	%f262, %f260, %f261, %p88;
	add.s32 	%r578, %r616, 1;
	and.b32  	%r579, %r578, 2;
	setp.eq.s32 	%p90, %r579, 0;
	and.b32  	%r580, %r616, 1;
	setp.eq.b32 	%p91, %r580, 1;
	mul.rn.f32 	%f263, %f331, %f331;
	fma.rn.f32 	%f264, %f263, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f265, 0fB94D4153, %f264, %p91;
	selp.f32 	%f266, 0f3C0885E4, 0f3D2AAABB, %p91;
	fma.rn.f32 	%f267, %f265, %f263, %f266;
	selp.f32 	%f268, 0fBE2AAAA8, 0fBEFFFFFF, %p91;
	fma.rn.f32 	%f269, %f267, %f263, %f268;
	selp.f32 	%f270, %f331, 0f3F800000, %p91;
	fma.rn.f32 	%f271, %f263, %f270, 0f00000000;
	fma.rn.f32 	%f272, %f269, %f271, %f270;
	sub.rn.f32 	%f273, %f324, %f272;
	selp.f32 	%f274, %f272, %f273, %p90;
	add.s32 	%r581, %r620, 1;
	and.b32  	%r582, %r581, 2;
	setp.eq.s32 	%p92, %r582, 0;
	and.b32  	%r583, %r620, 1;
	setp.eq.b32 	%p93, %r583, 1;
	mul.rn.f32 	%f275, %f332, %f332;
	fma.rn.f32 	%f276, %f275, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f277, 0fB94D4153, %f276, %p93;
	selp.f32 	%f278, 0f3C0885E4, 0f3D2AAABB, %p93;
	fma.rn.f32 	%f279, %f277, %f275, %f278;
	selp.f32 	%f280, 0fBE2AAAA8, 0fBEFFFFFF, %p93;
	fma.rn.f32 	%f281, %f279, %f275, %f280;
	selp.f32 	%f282, %f332, 0f3F800000, %p93;
	fma.rn.f32 	%f283, %f275, %f282, 0f00000000;
	fma.rn.f32 	%f284, %f281, %f283, %f282;
	sub.rn.f32 	%f285, %f324, %f284;
	selp.f32 	%f286, %f284, %f285, %p92;
	mul.rn.f32 	%f287, %f45, %f286;
	and.b32  	%r584, %r624, 2;
	setp.eq.s32 	%p94, %r584, 0;
	and.b32  	%r585, %r624, 1;
	setp.eq.b32 	%p95, %r585, 1;
	mul.rn.f32 	%f288, %f333, %f333;
	fma.rn.f32 	%f289, %f288, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f290, %f289, 0fB94D4153, %p95;
	selp.f32 	%f291, 0f3D2AAABB, 0f3C0885E4, %p95;
	fma.rn.f32 	%f292, %f290, %f288, %f291;
	selp.f32 	%f293, 0fBEFFFFFF, 0fBE2AAAA8, %p95;
	fma.rn.f32 	%f294, %f292, %f288, %f293;
	selp.f32 	%f295, 0f3F800000, %f333, %p95;
	fma.rn.f32 	%f296, %f288, %f295, 0f00000000;
	fma.rn.f32 	%f297, %f294, %f296, %f295;
	sub.rn.f32 	%f298, %f324, %f297;
	selp.f32 	%f299, %f297, %f298, %p94;
	mul.rn.f32 	%f300, %f49, %f299;
	add.rn.f32 	%f301, %f287, %f300;
	mul.rn.f32 	%f302, %f10, %f301;
	add.rn.f32 	%f303, %f50, %f302;
	mul.rn.f32 	%f304, %f274, %f303;
	mul.rn.f32 	%f305, %f336, %f336;
	and.b32  	%r586, %r636, 1;
	setp.eq.b32 	%p96, %r586, 1;
	selp.f32 	%f306, 0f3F800000, %f336, %p96;
	fma.rn.f32 	%f307, %f305, %f306, 0f00000000;
	fma.rn.f32 	%f308, %f305, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f309, %f308, 0fB94D4153, %p96;
	selp.f32 	%f310, 0f3D2AAABB, 0f3C0885E4, %p96;
	fma.rn.f32 	%f311, %f309, %f305, %f310;
	selp.f32 	%f312, 0fBEFFFFFF, 0fBE2AAAA8, %p96;
	fma.rn.f32 	%f313, %f311, %f305, %f312;
	fma.rn.f32 	%f314, %f313, %f307, %f306;
	and.b32  	%r587, %r636, 2;
	setp.eq.s32 	%p97, %r587, 0;
	sub.rn.f32 	%f315, %f324, %f314;
	selp.f32 	%f316, %f314, %f315, %p97;
	mul.rn.f32 	%f317, %f21, %f316;
	add.rn.f32 	%f318, %f250, %f317;
	mul.rn.f32 	%f319, %f10, %f318;
	add.rn.f32 	%f320, %f22, %f319;
	mul.rn.f32 	%f321, %f262, %f320;
	add.rn.f32 	%f322, %f304, %f321;
	mul.rn.f32 	%f323, %f38, %f322;
	st.global.f32 	[%rd45+4], %f323;
	ret;

}
	// .globl	input_concatenate_fusion_327
.visible .entry input_concatenate_fusion_327(
	.param .u64 input_concatenate_fusion_327_param_0,
	.param .u64 input_concatenate_fusion_327_param_1,
	.param .u64 input_concatenate_fusion_327_param_2,
	.param .u64 input_concatenate_fusion_327_param_3
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot269[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<35>;
	.reg .b16 	%rs<17>;
	.reg .b32 	%r<217>;
	.reg .f32 	%f<105>;
	.reg .b64 	%rd<100>;
	.reg .f64 	%fd<9>;

	mov.u64 	%SPL, __local_depot269;
	ld.param.u64 	%rd25, [input_concatenate_fusion_327_param_0];
	ld.param.u64 	%rd26, [input_concatenate_fusion_327_param_3];
	ld.param.u64 	%rd27, [input_concatenate_fusion_327_param_1];
	ld.param.u64 	%rd28, [input_concatenate_fusion_327_param_2];
	cvta.to.global.u64 	%rd29, %rd28;
	cvta.to.global.u64 	%rd2, %rd27;
	cvta.to.global.u64 	%rd30, %rd25;
	add.u64 	%rd3, %SPL, 0;
	mov.u32 	%r62, %ctaid.x;
	mov.u32 	%r63, %tid.x;
	shl.b32 	%r64, %r62, 7;
	or.b32  	%r65, %r64, %r63;
	cvt.u16.u32 	%rs3, %r65;
	mul.hi.u16 	%rs4, %rs3, -21845;
	shr.u16 	%rs5, %rs4, 1;
	mul.lo.s16 	%rs6, %rs5, 3;
	sub.s16 	%rs1, %rs3, %rs6;
	mul.hi.u16 	%rs7, %rs5, 5243;
	shr.u16 	%rs8, %rs7, 2;
	mul.lo.s16 	%rs9, %rs8, 50;
	sub.s16 	%rs10, %rs5, %rs9;
	shr.u16 	%rs11, %rs3, 1;
	mul.hi.u16 	%rs12, %rs11, -9611;
	shr.u16 	%rs13, %rs12, 6;
	and.b16  	%rs14, %rs13, 63;
	shl.b16 	%rs2, %rs1, 1;
	cvt.u64.u16 	%rd7, %rs14;
	cvt.u64.u16 	%rd8, %rs10;
	cvt.u64.u16 	%rd9, %rs2;
	cvt.u32.u16 	%r66, %rs10;
	mul.wide.u32 	%rd35, %r66, 48;
	cvt.u32.u16 	%r67, %rs14;
	mul.wide.u32 	%rd36, %r67, 2400;
	add.s64 	%rd37, %rd30, %rd36;
	add.s64 	%rd38, %rd37, %rd35;
	cvt.u32.u16 	%r68, %rs2;
	mul.wide.u32 	%rd39, %r68, 4;
	add.s64 	%rd10, %rd38, %rd39;
	ld.global.nc.f32 	%f1, [%rd10+24];
	cvt.u32.u16 	%r69, %rs1;
	mul.wide.u32 	%rd40, %r69, 4;
	mul.wide.u32 	%rd41, %r67, 12;
	add.s64 	%rd42, %rd29, %rd41;
	add.s64 	%rd43, %rd42, %rd40;
	ld.global.nc.f32 	%f21, [%rd43];
	add.rn.f32 	%f22, %f21, %f21;
	add.rn.f32 	%f23, %f22, %f22;
	add.rn.f32 	%f24, %f23, %f23;
	add.rn.f32 	%f2, %f24, %f24;
	mul.rn.f32 	%f25, %f2, 0f3F22F983;
	cvt.rni.s32.f32 	%r216, %f25;
	cvt.rn.f32.s32 	%f26, %r216;
	fma.rn.f32 	%f27, %f26, 0fBFC90FDA, %f2;
	fma.rn.f32 	%f28, %f26, 0fB3A22168, %f27;
	fma.rn.f32 	%f104, %f26, 0fA7C234C5, %f28;
	abs.f32 	%f4, %f2;
	setp.ltu.f32 	%p1, %f4, 0f47CE4780;
	mov.f32 	%f100, 0f00000000;
	setp.neu.f32 	%p34, %f4, 0f7F800000;
	mov.u32 	%r204, %r216;
	mov.f32 	%f101, %f104;
	@%p1 bra 	$L__BB269_8;
	@%p34 bra 	$L__BB269_3;
	mul.rn.f32 	%f101, %f2, %f100;
	mov.b32 	%r204, 0;
	bra.uni 	$L__BB269_8;
$L__BB269_3:
	mov.b32 	%r2, %f2;
	shr.u32 	%r3, %r2, 23;
	and.b32  	%r71, %r3, 224;
	add.s32 	%r72, %r71, -128;
	shl.b32 	%r73, %r2, 8;
	or.b32  	%r77, %r73, -2147483648;
	shr.u32 	%r5, %r72, 5;
	mov.b32 	%r201, 0;
	mov.u64 	%rd96, 0;
	mov.u64 	%rd45, __cudart_i2opi_f;
$L__BB269_4:
	.pragma "nounroll";
	add.s64 	%rd46, %rd45, %rd96;
	ld.global.nc.u32 	%r76, [%rd46];
	// begin inline asm
	{
	mad.lo.cc.u32   %r74, %r76, %r77, %r201;
	madc.hi.u32     %r201, %r76, %r77,  0;
	}
	// end inline asm
	add.s64 	%rd47, %rd3, %rd96;
	st.local.u32 	[%rd47], %r74;
	add.s64 	%rd96, %rd96, 4;
	cvt.u32.u64 	%r79, %rd96;
	setp.ne.s32 	%p3, %r79, 24;
	@%p3 bra 	$L__BB269_4;
	st.local.u32 	[%rd3+24], %r201;
	and.b32  	%r8, %r3, 31;
	mul.wide.u32 	%rd48, %r5, 4;
	sub.s64 	%rd13, %rd3, %rd48;
	ld.local.u32 	%r202, [%rd13+24];
	ld.local.u32 	%r203, [%rd13+20];
	setp.eq.s32 	%p4, %r8, 0;
	@%p4 bra 	$L__BB269_7;
	shl.b32 	%r80, %r203, %r8;
	shl.b32 	%r81, %r202, %r8;
	mov.b32 	%r82, 32;
	sub.s32 	%r83, %r82, %r8;
	shr.u32 	%r84, %r203, %r83;
	add.s32 	%r202, %r84, %r81;
	ld.local.u32 	%r85, [%rd13+16];
	shr.u32 	%r86, %r85, %r83;
	add.s32 	%r203, %r86, %r80;
$L__BB269_7:
	shr.u32 	%r87, %r202, 30;
	shr.u32 	%r88, %r203, 30;
	shl.b32 	%r89, %r202, 2;
	or.b32  	%r90, %r89, %r88;
	shl.b32 	%r91, %r203, 2;
	bfe.u32 	%r92, %r202, 29, 1;
	add.s32 	%r93, %r92, %r87;
	neg.s32 	%r94, %r93;
	setp.lt.s32 	%p5, %r2, 0;
	selp.b32 	%r204, %r94, %r93, %p5;
	xor.b32  	%r95, %r90, %r2;
	bfe.s32 	%r96, %r202, 29, 1;
	xor.b32  	%r97, %r96, %r90;
	xor.b32  	%r98, %r96, %r91;
	cvt.u64.u32 	%rd49, %r97;
	shl.b64 	%rd50, %rd49, 32;
	cvt.u64.u32 	%rd51, %r98;
	or.b64  	%rd52, %rd50, %rd51;
	cvt.rn.f64.s64 	%fd1, %rd52;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f29, %fd2;
	neg.f32 	%f30, %f29;
	setp.lt.s32 	%p6, %r95, 0;
	selp.f32 	%f101, %f30, %f29, %p6;
$L__BB269_8:
	cvta.to.global.u64 	%rd1, %rd26;
	add.s32 	%r100, %r204, 1;
	mul.rn.f32 	%f32, %f101, %f101;
	and.b32  	%r101, %r204, 1;
	setp.eq.b32 	%p8, %r101, 1;
	selp.f32 	%f33, %f101, 0f3F800000, %p8;
	fma.rn.f32 	%f34, %f32, %f33, 0f00000000;
	fma.rn.f32 	%f35, %f32, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f36, 0fB94D4153, %f35, %p8;
	selp.f32 	%f37, 0f3C0885E4, 0f3D2AAABB, %p8;
	fma.rn.f32 	%f38, %f36, %f32, %f37;
	selp.f32 	%f39, 0fBE2AAAA8, 0fBEFFFFFF, %p8;
	fma.rn.f32 	%f40, %f38, %f32, %f39;
	fma.rn.f32 	%f41, %f40, %f34, %f33;
	and.b32  	%r102, %r100, 2;
	setp.eq.s32 	%p9, %r102, 0;
	sub.rn.f32 	%f43, %f100, %f41;
	selp.f32 	%f44, %f41, %f43, %p9;
	mul.lo.s64 	%rd53, %rd7, 2400;
	add.s64 	%rd54, %rd2, %rd53;
	mul.lo.s64 	%rd55, %rd8, 48;
	add.s64 	%rd56, %rd54, %rd55;
	shl.b64 	%rd57, %rd9, 2;
	add.s64 	%rd14, %rd56, %rd57;
	ld.global.nc.f32 	%f8, [%rd14];
	mul.rn.f32 	%f9, %f8, %f44;
	mov.u32 	%r208, %r216;
	mov.f32 	%f102, %f104;
	@%p1 bra 	$L__BB269_16;
	@%p34 bra 	$L__BB269_11;
	mul.rn.f32 	%f102, %f2, %f100;
	mov.b32 	%r208, 0;
	bra.uni 	$L__BB269_16;
$L__BB269_11:
	mov.b32 	%r17, %f2;
	shr.u32 	%r18, %r17, 23;
	and.b32  	%r104, %r18, 224;
	add.s32 	%r105, %r104, -128;
	shl.b32 	%r106, %r17, 8;
	or.b32  	%r110, %r106, -2147483648;
	shr.u32 	%r20, %r105, 5;
	mov.b32 	%r205, 0;
	mov.u64 	%rd97, 0;
	mov.u64 	%rd59, __cudart_i2opi_f;
$L__BB269_12:
	.pragma "nounroll";
	add.s64 	%rd60, %rd59, %rd97;
	ld.global.nc.u32 	%r109, [%rd60];
	// begin inline asm
	{
	mad.lo.cc.u32   %r107, %r109, %r110, %r205;
	madc.hi.u32     %r205, %r109, %r110,  0;
	}
	// end inline asm
	add.s64 	%rd61, %rd3, %rd97;
	st.local.u32 	[%rd61], %r107;
	add.s64 	%rd97, %rd97, 4;
	cvt.u32.u64 	%r112, %rd97;
	setp.ne.s32 	%p11, %r112, 24;
	@%p11 bra 	$L__BB269_12;
	st.local.u32 	[%rd3+24], %r205;
	and.b32  	%r23, %r18, 31;
	mul.wide.u32 	%rd62, %r20, 4;
	sub.s64 	%rd17, %rd3, %rd62;
	ld.local.u32 	%r206, [%rd17+24];
	ld.local.u32 	%r207, [%rd17+20];
	setp.eq.s32 	%p12, %r23, 0;
	@%p12 bra 	$L__BB269_15;
	shl.b32 	%r113, %r207, %r23;
	shl.b32 	%r114, %r206, %r23;
	mov.b32 	%r115, 32;
	sub.s32 	%r116, %r115, %r23;
	shr.u32 	%r117, %r207, %r116;
	add.s32 	%r206, %r117, %r114;
	ld.local.u32 	%r118, [%rd17+16];
	shr.u32 	%r119, %r118, %r116;
	add.s32 	%r207, %r119, %r113;
$L__BB269_15:
	shr.u32 	%r120, %r206, 30;
	shr.u32 	%r121, %r207, 30;
	shl.b32 	%r122, %r206, 2;
	or.b32  	%r123, %r122, %r121;
	shl.b32 	%r124, %r207, 2;
	bfe.u32 	%r125, %r206, 29, 1;
	add.s32 	%r126, %r125, %r120;
	neg.s32 	%r127, %r126;
	setp.lt.s32 	%p13, %r17, 0;
	selp.b32 	%r208, %r127, %r126, %p13;
	xor.b32  	%r128, %r123, %r17;
	bfe.s32 	%r129, %r206, 29, 1;
	xor.b32  	%r130, %r129, %r123;
	xor.b32  	%r131, %r129, %r124;
	cvt.u64.u32 	%rd63, %r130;
	shl.b64 	%rd64, %rd63, 32;
	cvt.u64.u32 	%rd65, %r131;
	or.b64  	%rd66, %rd64, %rd65;
	cvt.rn.f64.s64 	%fd3, %rd66;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f45, %fd4;
	neg.f32 	%f46, %f45;
	setp.lt.s32 	%p14, %r128, 0;
	selp.f32 	%f102, %f46, %f45, %p14;
$L__BB269_16:
	mul.rn.f32 	%f48, %f102, %f102;
	and.b32  	%r133, %r208, 1;
	setp.eq.b32 	%p16, %r133, 1;
	selp.f32 	%f49, 0f3F800000, %f102, %p16;
	fma.rn.f32 	%f50, %f48, %f49, 0f00000000;
	fma.rn.f32 	%f51, %f48, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f52, %f51, 0fB94D4153, %p16;
	selp.f32 	%f53, 0f3D2AAABB, 0f3C0885E4, %p16;
	fma.rn.f32 	%f54, %f52, %f48, %f53;
	selp.f32 	%f55, 0fBEFFFFFF, 0fBE2AAAA8, %p16;
	fma.rn.f32 	%f56, %f54, %f48, %f55;
	fma.rn.f32 	%f57, %f56, %f50, %f49;
	and.b32  	%r134, %r208, 2;
	setp.eq.s32 	%p17, %r134, 0;
	sub.rn.f32 	%f59, %f100, %f57;
	selp.f32 	%f60, %f57, %f59, %p17;
	or.b16  	%rs15, %rs2, 1;
	setp.gt.u16 	%p18, %rs1, 1;
	selp.b16 	%rs16, 5, %rs15, %p18;
	cvt.u32.u16 	%r135, %rs16;
	mul.wide.u32 	%rd71, %r135, 4;
	add.s64 	%rd72, %rd56, %rd71;
	ld.global.nc.f32 	%f61, [%rd72];
	mul.rn.f32 	%f62, %f61, %f60;
	sub.rn.f32 	%f63, %f9, %f62;
	mul.rn.f32 	%f64, %f1, %f63;
	mul.lo.s64 	%rd73, %rd7, 1200;
	add.s64 	%rd74, %rd1, %rd73;
	mul.lo.s64 	%rd75, %rd8, 24;
	add.s64 	%rd76, %rd74, %rd75;
	add.s64 	%rd18, %rd76, %rd57;
	st.global.f32 	[%rd18], %f64;
	ld.global.nc.f32 	%f13, [%rd10+28];
	mov.u32 	%r212, %r216;
	mov.f32 	%f103, %f104;
	@%p1 bra 	$L__BB269_24;
	@%p34 bra 	$L__BB269_19;
	mul.rn.f32 	%f103, %f2, %f100;
	mov.b32 	%r212, 0;
	bra.uni 	$L__BB269_24;
$L__BB269_19:
	mov.b32 	%r32, %f2;
	shr.u32 	%r33, %r32, 23;
	and.b32  	%r137, %r33, 224;
	add.s32 	%r138, %r137, -128;
	shl.b32 	%r139, %r32, 8;
	or.b32  	%r143, %r139, -2147483648;
	shr.u32 	%r35, %r138, 5;
	mov.b32 	%r209, 0;
	mov.u64 	%rd98, 0;
	mov.u64 	%rd79, __cudart_i2opi_f;
$L__BB269_20:
	.pragma "nounroll";
	add.s64 	%rd80, %rd79, %rd98;
	ld.global.nc.u32 	%r142, [%rd80];
	// begin inline asm
	{
	mad.lo.cc.u32   %r140, %r142, %r143, %r209;
	madc.hi.u32     %r209, %r142, %r143,  0;
	}
	// end inline asm
	add.s64 	%rd81, %rd3, %rd98;
	st.local.u32 	[%rd81], %r140;
	add.s64 	%rd98, %rd98, 4;
	cvt.u32.u64 	%r145, %rd98;
	setp.ne.s32 	%p20, %r145, 24;
	@%p20 bra 	$L__BB269_20;
	st.local.u32 	[%rd3+24], %r209;
	and.b32  	%r38, %r33, 31;
	mul.wide.u32 	%rd82, %r35, 4;
	sub.s64 	%rd21, %rd3, %rd82;
	ld.local.u32 	%r210, [%rd21+24];
	ld.local.u32 	%r211, [%rd21+20];
	setp.eq.s32 	%p21, %r38, 0;
	@%p21 bra 	$L__BB269_23;
	shl.b32 	%r146, %r211, %r38;
	shl.b32 	%r147, %r210, %r38;
	mov.b32 	%r148, 32;
	sub.s32 	%r149, %r148, %r38;
	shr.u32 	%r150, %r211, %r149;
	add.s32 	%r210, %r150, %r147;
	ld.local.u32 	%r151, [%rd21+16];
	shr.u32 	%r152, %r151, %r149;
	add.s32 	%r211, %r152, %r146;
$L__BB269_23:
	shr.u32 	%r153, %r210, 30;
	shr.u32 	%r154, %r211, 30;
	shl.b32 	%r155, %r210, 2;
	or.b32  	%r156, %r155, %r154;
	shl.b32 	%r157, %r211, 2;
	bfe.u32 	%r158, %r210, 29, 1;
	add.s32 	%r159, %r158, %r153;
	neg.s32 	%r160, %r159;
	setp.lt.s32 	%p22, %r32, 0;
	selp.b32 	%r212, %r160, %r159, %p22;
	xor.b32  	%r161, %r156, %r32;
	bfe.s32 	%r162, %r210, 29, 1;
	xor.b32  	%r163, %r162, %r156;
	xor.b32  	%r164, %r162, %r157;
	cvt.u64.u32 	%rd83, %r163;
	shl.b64 	%rd84, %rd83, 32;
	cvt.u64.u32 	%rd85, %r164;
	or.b64  	%rd86, %rd84, %rd85;
	cvt.rn.f64.s64 	%fd5, %rd86;
	mul.rn.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f65, %fd6;
	neg.f32 	%f66, %f65;
	setp.lt.s32 	%p23, %r161, 0;
	selp.f32 	%f103, %f66, %f65, %p23;
$L__BB269_24:
	ld.global.nc.f32 	%f17, [%rd14+4];
	@%p1 bra 	$L__BB269_32;
	@%p34 bra 	$L__BB269_27;
	mul.rn.f32 	%f104, %f2, %f100;
	mov.b32 	%r216, 0;
	bra.uni 	$L__BB269_32;
$L__BB269_27:
	mov.b32 	%r47, %f2;
	shr.u32 	%r48, %r47, 23;
	and.b32  	%r167, %r48, 224;
	add.s32 	%r168, %r167, -128;
	shl.b32 	%r169, %r47, 8;
	or.b32  	%r173, %r169, -2147483648;
	shr.u32 	%r50, %r168, 5;
	mov.b32 	%r213, 0;
	mov.u64 	%rd99, 0;
	mov.u64 	%rd88, __cudart_i2opi_f;
$L__BB269_28:
	.pragma "nounroll";
	add.s64 	%rd89, %rd88, %rd99;
	ld.global.nc.u32 	%r172, [%rd89];
	// begin inline asm
	{
	mad.lo.cc.u32   %r170, %r172, %r173, %r213;
	madc.hi.u32     %r213, %r172, %r173,  0;
	}
	// end inline asm
	add.s64 	%rd90, %rd3, %rd99;
	st.local.u32 	[%rd90], %r170;
	add.s64 	%rd99, %rd99, 4;
	cvt.u32.u64 	%r175, %rd99;
	setp.ne.s32 	%p26, %r175, 24;
	@%p26 bra 	$L__BB269_28;
	st.local.u32 	[%rd3+24], %r213;
	and.b32  	%r53, %r48, 31;
	mul.wide.u32 	%rd91, %r50, 4;
	sub.s64 	%rd24, %rd3, %rd91;
	ld.local.u32 	%r214, [%rd24+24];
	ld.local.u32 	%r215, [%rd24+20];
	setp.eq.s32 	%p27, %r53, 0;
	@%p27 bra 	$L__BB269_31;
	shl.b32 	%r176, %r215, %r53;
	shl.b32 	%r177, %r214, %r53;
	mov.b32 	%r178, 32;
	sub.s32 	%r179, %r178, %r53;
	shr.u32 	%r180, %r215, %r179;
	add.s32 	%r214, %r180, %r177;
	ld.local.u32 	%r181, [%rd24+16];
	shr.u32 	%r182, %r181, %r179;
	add.s32 	%r215, %r182, %r176;
$L__BB269_31:
	shr.u32 	%r183, %r214, 30;
	shr.u32 	%r184, %r215, 30;
	shl.b32 	%r185, %r214, 2;
	or.b32  	%r186, %r185, %r184;
	shl.b32 	%r187, %r215, 2;
	bfe.u32 	%r188, %r214, 29, 1;
	add.s32 	%r189, %r188, %r183;
	neg.s32 	%r190, %r189;
	setp.lt.s32 	%p28, %r47, 0;
	selp.b32 	%r216, %r190, %r189, %p28;
	xor.b32  	%r191, %r186, %r47;
	bfe.s32 	%r192, %r214, 29, 1;
	xor.b32  	%r193, %r192, %r186;
	xor.b32  	%r194, %r192, %r187;
	cvt.u64.u32 	%rd92, %r193;
	shl.b64 	%rd93, %rd92, 32;
	cvt.u64.u32 	%rd94, %r194;
	or.b64  	%rd95, %rd93, %rd94;
	cvt.rn.f64.s64 	%fd7, %rd95;
	mul.rn.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f68, %fd8;
	neg.f32 	%f69, %f68;
	setp.lt.s32 	%p29, %r191, 0;
	selp.f32 	%f104, %f69, %f68, %p29;
$L__BB269_32:
	add.s32 	%r196, %r212, 1;
	and.b32  	%r197, %r196, 2;
	setp.eq.s32 	%p30, %r197, 0;
	and.b32  	%r198, %r212, 1;
	setp.eq.b32 	%p31, %r198, 1;
	mul.rn.f32 	%f71, %f103, %f103;
	fma.rn.f32 	%f72, %f71, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f73, 0fB94D4153, %f72, %p31;
	selp.f32 	%f74, 0f3C0885E4, 0f3D2AAABB, %p31;
	fma.rn.f32 	%f75, %f73, %f71, %f74;
	selp.f32 	%f76, 0fBE2AAAA8, 0fBEFFFFFF, %p31;
	fma.rn.f32 	%f77, %f75, %f71, %f76;
	selp.f32 	%f78, %f103, 0f3F800000, %p31;
	fma.rn.f32 	%f79, %f71, %f78, 0f00000000;
	fma.rn.f32 	%f80, %f77, %f79, %f78;
	sub.rn.f32 	%f82, %f100, %f80;
	selp.f32 	%f83, %f80, %f82, %p30;
	mul.rn.f32 	%f84, %f17, %f83;
	mul.rn.f32 	%f85, %f104, %f104;
	and.b32  	%r199, %r216, 1;
	setp.eq.b32 	%p32, %r199, 1;
	selp.f32 	%f86, 0f3F800000, %f104, %p32;
	fma.rn.f32 	%f87, %f85, %f86, 0f00000000;
	fma.rn.f32 	%f88, %f85, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f89, %f88, 0fB94D4153, %p32;
	selp.f32 	%f90, 0f3D2AAABB, 0f3C0885E4, %p32;
	fma.rn.f32 	%f91, %f89, %f85, %f90;
	selp.f32 	%f92, 0fBEFFFFFF, 0fBE2AAAA8, %p32;
	fma.rn.f32 	%f93, %f91, %f85, %f92;
	fma.rn.f32 	%f94, %f93, %f87, %f86;
	and.b32  	%r200, %r216, 2;
	setp.eq.s32 	%p33, %r200, 0;
	sub.rn.f32 	%f95, %f100, %f94;
	selp.f32 	%f96, %f94, %f95, %p33;
	mul.rn.f32 	%f97, %f8, %f96;
	add.rn.f32 	%f98, %f84, %f97;
	mul.rn.f32 	%f99, %f13, %f98;
	st.global.f32 	[%rd18+4], %f99;
	ret;

}
	// .globl	input_reduce_fusion_345
.visible .entry input_reduce_fusion_345(
	.param .u64 input_reduce_fusion_345_param_0,
	.param .u64 input_reduce_fusion_345_param_1,
	.param .u64 input_reduce_fusion_345_param_2,
	.param .u64 input_reduce_fusion_345_param_3
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<8>;
	.reg .b16 	%rs<76>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<66>;
	.reg .b64 	%rd<116>;
	// demoted variable
	.shared .align 4 .b8 shared_cache52[32];
	// demoted variable
	.shared .align 4 .b8 shared_cache53[32];
	mov.u32 	%r5, %ctaid.y;
	and.b32  	%r6, %r5, 1;
	setp.eq.b32 	%p1, %r6, 1;
	mov.u32 	%r7, %tid.x;
	mov.u32 	%r8, %ctaid.x;
	shr.u32 	%r1, %r7, 5;
	and.b32  	%r2, %r7, 31;
	shl.b32 	%r9, %r8, 3;
	or.b32  	%r10, %r1, %r9;
	cvt.u64.u32 	%rd5, %r10;
	cvt.u16.u32 	%rs2, %r2;
	mul.lo.s16 	%rs3, %rs2, 86;
	shr.u16 	%rs4, %rs3, 8;
	cvt.u64.u16 	%rd6, %rs4;
	shl.b16 	%rs5, %rs2, 1;
	mul.lo.s16 	%rs6, %rs4, 6;
	sub.s16 	%rs7, %rs5, %rs6;
	cvt.u64.u16 	%rd28, %rs7;
	and.b64  	%rd7, %rd28, 254;
	or.b16  	%rs8, %rs5, 1;
	mul.lo.s16 	%rs9, %rs8, 43;
	shr.u16 	%rs10, %rs9, 8;
	mul.lo.s16 	%rs11, %rs10, 6;
	sub.s16 	%rs12, %rs8, %rs11;
	cvt.u64.u16 	%rd29, %rs12;
	and.b64  	%rd8, %rd29, 255;
	or.b32  	%r11, %r2, 32;
	cvt.u16.u32 	%rs13, %r11;
	mul.lo.s16 	%rs14, %rs13, 86;
	shr.u16 	%rs15, %rs14, 8;
	cvt.u64.u16 	%rd9, %rs15;
	shl.b16 	%rs16, %rs13, 1;
	mul.lo.s16 	%rs17, %rs15, 6;
	sub.s16 	%rs18, %rs16, %rs17;
	cvt.u64.u16 	%rd30, %rs18;
	and.b64  	%rd10, %rd30, 254;
	or.b16  	%rs19, %rs16, 1;
	mul.lo.s16 	%rs20, %rs19, 43;
	shr.u16 	%rs21, %rs20, 8;
	mul.lo.s16 	%rs22, %rs21, 6;
	sub.s16 	%rs23, %rs19, %rs22;
	cvt.u64.u16 	%rd31, %rs23;
	and.b64  	%rd11, %rd31, 255;
	or.b32  	%r12, %r2, 64;
	cvt.u16.u32 	%rs24, %r12;
	mul.lo.s16 	%rs25, %rs24, 86;
	shr.u16 	%rs26, %rs25, 8;
	cvt.u64.u16 	%rd12, %rs26;
	shl.b16 	%rs27, %rs24, 1;
	mul.lo.s16 	%rs28, %rs24, 342;
	shr.u16 	%rs29, %rs28, 10;
	mul.lo.s16 	%rs30, %rs29, 6;
	sub.s16 	%rs31, %rs27, %rs30;
	cvt.u64.u16 	%rd32, %rs31;
	and.b64  	%rd13, %rd32, 254;
	or.b16  	%rs32, %rs27, 1;
	mul.lo.s16 	%rs33, %rs32, 171;
	shr.u16 	%rs34, %rs33, 10;
	mul.lo.s16 	%rs35, %rs34, 6;
	sub.s16 	%rs36, %rs32, %rs35;
	cvt.u64.u16 	%rd33, %rs36;
	and.b64  	%rd14, %rd33, 255;
	or.b32  	%r13, %r2, 96;
	cvt.u16.u32 	%rs37, %r13;
	mul.lo.s16 	%rs38, %rs37, 86;
	shr.u16 	%rs39, %rs38, 8;
	cvt.u64.u16 	%rd15, %rs39;
	shl.b16 	%rs1, %rs37, 1;
	mul.lo.s16 	%rs40, %rs37, 342;
	shr.u16 	%rs41, %rs40, 10;
	mul.lo.s16 	%rs42, %rs41, 6;
	sub.s16 	%rs43, %rs1, %rs42;
	cvt.u64.u16 	%rd34, %rs43;
	and.b64  	%rd16, %rd34, 254;
	@%p1 bra 	$L__BB270_8;
	bra.uni 	$L__BB270_1;
$L__BB270_8:
	ld.param.u64 	%rd26, [input_reduce_fusion_345_param_1];
	cvta.to.global.u64 	%rd3, %rd26;
	mul.lo.s64 	%rd72, %rd5, 1200;
	add.s64 	%rd73, %rd3, %rd72;
	mul.lo.s64 	%rd74, %rd6, 24;
	add.s64 	%rd75, %rd73, %rd74;
	shl.b64 	%rd76, %rd7, 2;
	add.s64 	%rd77, %rd75, %rd76;
	ld.global.nc.f32 	%f36, [%rd77];
	add.rn.f32 	%f37, %f36, 0f00000000;
	shl.b64 	%rd78, %rd8, 2;
	add.s64 	%rd79, %rd75, %rd78;
	ld.global.nc.f32 	%f38, [%rd79];
	add.rn.f32 	%f39, %f37, %f38;
	mul.lo.s64 	%rd80, %rd9, 24;
	add.s64 	%rd81, %rd73, %rd80;
	shl.b64 	%rd82, %rd10, 2;
	add.s64 	%rd83, %rd81, %rd82;
	ld.global.nc.f32 	%f40, [%rd83];
	add.rn.f32 	%f41, %f39, %f40;
	shl.b64 	%rd84, %rd11, 2;
	add.s64 	%rd85, %rd81, %rd84;
	ld.global.nc.f32 	%f42, [%rd85];
	add.rn.f32 	%f43, %f41, %f42;
	mul.lo.s64 	%rd86, %rd12, 24;
	add.s64 	%rd87, %rd73, %rd86;
	shl.b64 	%rd88, %rd13, 2;
	add.s64 	%rd89, %rd87, %rd88;
	ld.global.nc.f32 	%f44, [%rd89];
	add.rn.f32 	%f45, %f43, %f44;
	shl.b64 	%rd90, %rd14, 2;
	add.s64 	%rd91, %rd87, %rd90;
	ld.global.nc.f32 	%f46, [%rd91];
	add.rn.f32 	%f47, %f45, %f46;
	mul.lo.s64 	%rd92, %rd15, 24;
	add.s64 	%rd93, %rd73, %rd92;
	shl.b64 	%rd94, %rd16, 2;
	add.s64 	%rd95, %rd93, %rd94;
	ld.global.nc.f32 	%f48, [%rd95];
	add.rn.f32 	%f49, %f47, %f48;
	or.b16  	%rs60, %rs1, 1;
	mul.lo.s16 	%rs61, %rs60, 171;
	shr.u16 	%rs62, %rs61, 10;
	mul.lo.s16 	%rs63, %rs62, 6;
	sub.s16 	%rs64, %rs60, %rs63;
	cvt.u32.u16 	%r19, %rs64;
	and.b32  	%r20, %r19, 255;
	mul.wide.u32 	%rd96, %r20, 4;
	add.s64 	%rd97, %rd93, %rd96;
	ld.global.nc.f32 	%f50, [%rd97];
	add.rn.f32 	%f65, %f49, %f50;
	or.b32  	%r4, %r2, 128;
	setp.gt.u32 	%p5, %r4, 149;
	@%p5 bra 	$L__BB270_10;
	cvt.u16.u32 	%rs65, %r4;
	mul.lo.s16 	%rs66, %rs65, 171;
	shr.u16 	%rs67, %rs66, 9;
	shl.b16 	%rs68, %rs65, 1;
	mul.hi.u16 	%rs69, %rs68, 10923;
	mul.lo.s16 	%rs70, %rs69, 6;
	sub.s16 	%rs71, %rs68, %rs70;
	cvt.u32.u16 	%r21, %rs67;
	mul.wide.u32 	%rd100, %r21, 24;
	add.s64 	%rd101, %rd73, %rd100;
	cvt.u32.u16 	%r22, %rs71;
	mul.wide.u32 	%rd102, %r22, 4;
	add.s64 	%rd103, %rd101, %rd102;
	ld.global.nc.f32 	%f51, [%rd103];
	add.rn.f32 	%f52, %f65, %f51;
	or.b16  	%rs72, %rs68, 1;
	mul.hi.u16 	%rs73, %rs72, 10923;
	mul.lo.s16 	%rs74, %rs73, 6;
	sub.s16 	%rs75, %rs72, %rs74;
	cvt.u32.u16 	%r23, %rs75;
	mul.wide.u32 	%rd104, %r23, 4;
	add.s64 	%rd105, %rd101, %rd104;
	ld.global.nc.f32 	%f53, [%rd105];
	add.rn.f32 	%f65, %f52, %f53;
$L__BB270_10:
	ld.param.u64 	%rd25, [input_reduce_fusion_345_param_3];
	shfl.sync.down.b32	%f54, %f65, 16, 31, -1;
	add.rn.f32 	%f55, %f65, %f54;
	shfl.sync.down.b32	%f56, %f55, 8, 31, -1;
	add.rn.f32 	%f57, %f55, %f56;
	shfl.sync.down.b32	%f58, %f57, 4, 31, -1;
	add.rn.f32 	%f59, %f57, %f58;
	shfl.sync.down.b32	%f60, %f59, 2, 31, -1;
	add.rn.f32 	%f61, %f59, %f60;
	shfl.sync.down.b32	%f62, %f61, 1, 31, -1;
	setp.eq.s32 	%p6, %r2, 0;
	mov.u64 	%rd115, shared_cache53;
	@%p6 bra 	$L__BB270_12;
	bra.uni 	$L__BB270_11;
$L__BB270_12:
	mul.wide.u32 	%rd106, %r1, 4;
	add.s64 	%rd23, %rd115, %rd106;
	add.rn.f32 	%f8, %f61, %f62;
	st.shared.f32 	[%rd23], %f8;
$L__BB270_11:
	cvta.to.global.u64 	%rd114, %rd25;
	cvt.u64.u32 	%rd113, %r1;
	bar.sync 	0;
	@%p6 bra 	$L__BB270_5;
	bra.uni 	$L__BB270_6;
$L__BB270_1:
	ld.param.u64 	%rd24, [input_reduce_fusion_345_param_0];
	cvta.to.global.u64 	%rd4, %rd24;
	mul.lo.s64 	%rd35, %rd5, 1200;
	add.s64 	%rd36, %rd4, %rd35;
	mul.lo.s64 	%rd37, %rd6, 24;
	add.s64 	%rd38, %rd36, %rd37;
	shl.b64 	%rd39, %rd7, 2;
	add.s64 	%rd40, %rd38, %rd39;
	ld.global.nc.f32 	%f9, [%rd40];
	add.rn.f32 	%f10, %f9, 0f00000000;
	shl.b64 	%rd41, %rd8, 2;
	add.s64 	%rd42, %rd38, %rd41;
	ld.global.nc.f32 	%f11, [%rd42];
	add.rn.f32 	%f12, %f10, %f11;
	mul.lo.s64 	%rd43, %rd9, 24;
	add.s64 	%rd44, %rd36, %rd43;
	shl.b64 	%rd45, %rd10, 2;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.nc.f32 	%f13, [%rd46];
	add.rn.f32 	%f14, %f12, %f13;
	shl.b64 	%rd47, %rd11, 2;
	add.s64 	%rd48, %rd44, %rd47;
	ld.global.nc.f32 	%f15, [%rd48];
	add.rn.f32 	%f16, %f14, %f15;
	mul.lo.s64 	%rd49, %rd12, 24;
	add.s64 	%rd50, %rd36, %rd49;
	shl.b64 	%rd51, %rd13, 2;
	add.s64 	%rd52, %rd50, %rd51;
	ld.global.nc.f32 	%f17, [%rd52];
	add.rn.f32 	%f18, %f16, %f17;
	shl.b64 	%rd53, %rd14, 2;
	add.s64 	%rd54, %rd50, %rd53;
	ld.global.nc.f32 	%f19, [%rd54];
	add.rn.f32 	%f20, %f18, %f19;
	mul.lo.s64 	%rd55, %rd15, 24;
	add.s64 	%rd56, %rd36, %rd55;
	shl.b64 	%rd57, %rd16, 2;
	add.s64 	%rd58, %rd56, %rd57;
	ld.global.nc.f32 	%f21, [%rd58];
	add.rn.f32 	%f22, %f20, %f21;
	or.b16  	%rs44, %rs1, 1;
	mul.lo.s16 	%rs45, %rs44, 171;
	shr.u16 	%rs46, %rs45, 10;
	mul.lo.s16 	%rs47, %rs46, 6;
	sub.s16 	%rs48, %rs44, %rs47;
	cvt.u32.u16 	%r14, %rs48;
	and.b32  	%r15, %r14, 255;
	mul.wide.u32 	%rd59, %r15, 4;
	add.s64 	%rd60, %rd56, %rd59;
	ld.global.nc.f32 	%f23, [%rd60];
	add.rn.f32 	%f64, %f22, %f23;
	or.b32  	%r3, %r2, 128;
	setp.gt.u32 	%p2, %r3, 149;
	@%p2 bra 	$L__BB270_3;
	cvt.u16.u32 	%rs49, %r3;
	mul.lo.s16 	%rs50, %rs49, 171;
	shr.u16 	%rs51, %rs50, 9;
	shl.b16 	%rs52, %rs49, 1;
	mul.hi.u16 	%rs53, %rs52, 10923;
	mul.lo.s16 	%rs54, %rs53, 6;
	sub.s16 	%rs55, %rs52, %rs54;
	cvt.u32.u16 	%r16, %rs51;
	mul.wide.u32 	%rd63, %r16, 24;
	add.s64 	%rd64, %rd36, %rd63;
	cvt.u32.u16 	%r17, %rs55;
	mul.wide.u32 	%rd65, %r17, 4;
	add.s64 	%rd66, %rd64, %rd65;
	ld.global.nc.f32 	%f24, [%rd66];
	add.rn.f32 	%f25, %f64, %f24;
	or.b16  	%rs56, %rs52, 1;
	mul.hi.u16 	%rs57, %rs56, 10923;
	mul.lo.s16 	%rs58, %rs57, 6;
	sub.s16 	%rs59, %rs56, %rs58;
	cvt.u32.u16 	%r18, %rs59;
	mul.wide.u32 	%rd67, %r18, 4;
	add.s64 	%rd68, %rd64, %rd67;
	ld.global.nc.f32 	%f26, [%rd68];
	add.rn.f32 	%f64, %f25, %f26;
$L__BB270_3:
	ld.param.u64 	%rd27, [input_reduce_fusion_345_param_2];
	shfl.sync.down.b32	%f27, %f64, 16, 31, -1;
	add.rn.f32 	%f28, %f64, %f27;
	shfl.sync.down.b32	%f29, %f28, 8, 31, -1;
	add.rn.f32 	%f30, %f28, %f29;
	shfl.sync.down.b32	%f31, %f30, 4, 31, -1;
	add.rn.f32 	%f32, %f30, %f31;
	shfl.sync.down.b32	%f33, %f32, 2, 31, -1;
	add.rn.f32 	%f34, %f32, %f33;
	shfl.sync.down.b32	%f35, %f34, 1, 31, -1;
	setp.eq.s32 	%p3, %r2, 0;
	mov.u64 	%rd115, shared_cache52;
	@%p3 bra 	$L__BB270_7;
	bra.uni 	$L__BB270_4;
$L__BB270_7:
	mul.wide.u32 	%rd69, %r1, 4;
	add.s64 	%rd21, %rd115, %rd69;
	add.rn.f32 	%f4, %f34, %f35;
	st.shared.f32 	[%rd21], %f4;
$L__BB270_4:
	cvta.to.global.u64 	%rd114, %rd27;
	cvt.u64.u32 	%rd113, %r1;
	bar.sync 	0;
	@%p3 bra 	$L__BB270_5;
	bra.uni 	$L__BB270_6;
$L__BB270_5:
	shl.b64 	%rd109, %rd5, 2;
	add.s64 	%rd110, %rd114, %rd109;
	shl.b64 	%rd111, %rd113, 2;
	add.s64 	%rd112, %rd115, %rd111;
	ld.shared.f32 	%f63, [%rd112];
	st.global.f32 	[%rd110], %f63;
$L__BB270_6:
	ret;

}
	// .globl	loop_multiply_fusion_100
.visible .entry loop_multiply_fusion_100(
	.param .u64 loop_multiply_fusion_100_param_0,
	.param .u64 loop_multiply_fusion_100_param_1,
	.param .u64 loop_multiply_fusion_100_param_2,
	.param .u64 loop_multiply_fusion_100_param_3,
	.param .u64 loop_multiply_fusion_100_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<12>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<136>;
	.reg .b64 	%rd<36>;

	ld.param.u64 	%rd16, [loop_multiply_fusion_100_param_3];
	cvta.to.global.u64 	%rd2, %rd16;
	ld.param.u64 	%rd17, [loop_multiply_fusion_100_param_2];
	cvta.to.global.u64 	%rd3, %rd17;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	shl.b32 	%r6, %r4, 7;
	or.b32  	%r1, %r6, %r5;
	and.b32  	%r2, %r5, 3;
	shr.u32 	%r3, %r1, 2;
	and.b32  	%r7, %r5, 1;
	setp.eq.b32 	%p1, %r7, 1;
	mov.pred 	%p2, 0;
	xor.pred  	%p3, %p1, %p2;
	not.pred 	%p4, %p3;
	mov.f32 	%f131, 0f00000000;
	mul.wide.u32 	%rd34, %r3, 4;
	mov.f32 	%f129, 0f4B400001;
	mov.f32 	%f130, 0f437C0000;
	@%p4 bra 	$L__BB271_5;
	bra.uni 	$L__BB271_1;
$L__BB271_5:
	setp.ne.s32 	%p5, %r2, 0;
	cvt.u64.u32 	%rd9, %r3;
	mov.f32 	%f134, 0f00000000;
	@%p5 bra 	$L__BB271_7;
	bra.uni 	$L__BB271_6;
$L__BB271_7:
	add.s64 	%rd10, %rd3, %rd34;
	ld.global.nc.f32 	%f134, [%rd10];
$L__BB271_6:
	shl.b64 	%rd19, %rd9, 2;
	add.s64 	%rd20, %rd2, %rd19;
	ld.global.nc.f32 	%f13, [%rd20];
	fma.rn.f32 	%f14, %f13, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f15, %f14;
	fma.rm.f32 	%f18, %f15, %f130, %f129;
	add.rn.f32 	%f19, %f18, 0fCB40007F;
	neg.f32 	%f20, %f19;
	fma.rn.f32 	%f21, %f13, 0f3FB8AA3B, %f20;
	fma.rn.f32 	%f22, %f13, 0f32A57060, %f21;
	mov.b32 	%r8, %f18;
	shl.b32 	%r9, %r8, 23;
	mov.b32 	%f23, %r9;
	ex2.approx.ftz.f32 	%f24, %f22;
	mul.rn.f32 	%f25, %f24, %f23;
	neg.f32 	%f26, %f25;
	sub.rn.f32 	%f27, %f26, %f25;
	add.rn.f32 	%f28, %f27, %f27;
	add.rn.f32 	%f29, %f28, %f28;
	add.rn.f32 	%f30, %f29, %f29;
	add.rn.f32 	%f31, %f30, %f30;
	add.rn.f32 	%f32, %f31, %f31;
	add.rn.f32 	%f33, %f32, %f32;
	add.rn.f32 	%f34, %f33, %f33;
	fma.rn.f32 	%f35, %f34, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f36, %f35;
	fma.rm.f32 	%f37, %f36, %f130, %f129;
	add.rn.f32 	%f38, %f37, 0fCB40007F;
	neg.f32 	%f39, %f38;
	fma.rn.f32 	%f40, %f34, 0f3FB8AA3B, %f39;
	fma.rn.f32 	%f41, %f34, 0f32A57060, %f40;
	mov.b32 	%r10, %f37;
	shl.b32 	%r11, %r10, 23;
	mov.b32 	%f42, %r11;
	ex2.approx.ftz.f32 	%f43, %f41;
	mul.rn.f32 	%f44, %f43, %f42;
	mul.rn.f32 	%f131, %f134, %f44;
$L__BB271_1:
	ld.param.u64 	%rd14, [loop_multiply_fusion_100_param_4];
	add.s32 	%r12, %r2, -1;
	and.b32  	%r13, %r12, 1;
	setp.eq.b32 	%p6, %r13, 1;
	xor.pred  	%p8, %p6, %p2;
	not.pred 	%p9, %p8;
	@%p9 bra 	$L__BB271_8;
	bra.uni 	$L__BB271_2;
$L__BB271_8:
	ld.param.u64 	%rd15, [loop_multiply_fusion_100_param_1];
	cvta.to.global.u64 	%rd4, %rd15;
	cvt.u16.u32 	%rs2, %r12;
	and.b16  	%rs3, %rs2, 128;
	shr.u16 	%rs4, %rs3, 7;
	add.s16 	%rs5, %rs2, %rs4;
	shr.s16 	%rs1, %rs5, 1;
	setp.eq.s32 	%p10, %r2, 3;
	cvt.u64.u32 	%rd35, %r3;
	mov.f32 	%f135, 0f00000000;
	@%p10 bra 	$L__BB271_10;
	bra.uni 	$L__BB271_9;
$L__BB271_10:
	add.s64 	%rd12, %rd3, %rd34;
	ld.global.nc.f32 	%f135, [%rd12];
$L__BB271_9:
	shl.b64 	%rd22, %rd35, 2;
	add.s64 	%rd23, %rd2, %rd22;
	ld.global.nc.f32 	%f47, [%rd23];
	fma.rn.f32 	%f48, %f47, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f49, %f48;
	fma.rm.f32 	%f52, %f49, %f130, %f129;
	add.rn.f32 	%f53, %f52, 0fCB40007F;
	neg.f32 	%f54, %f53;
	fma.rn.f32 	%f55, %f47, 0f3FB8AA3B, %f54;
	fma.rn.f32 	%f56, %f47, 0f32A57060, %f55;
	mov.b32 	%r14, %f52;
	shl.b32 	%r15, %r14, 23;
	mov.b32 	%f57, %r15;
	ex2.approx.ftz.f32 	%f58, %f56;
	mul.rn.f32 	%f59, %f58, %f57;
	neg.f32 	%f60, %f59;
	sub.rn.f32 	%f61, %f60, %f59;
	add.rn.f32 	%f62, %f61, %f61;
	add.rn.f32 	%f63, %f62, %f62;
	add.rn.f32 	%f64, %f63, %f63;
	add.rn.f32 	%f65, %f64, %f64;
	add.rn.f32 	%f66, %f65, %f65;
	add.rn.f32 	%f67, %f66, %f66;
	add.rn.f32 	%f68, %f67, %f67;
	fma.rn.f32 	%f69, %f68, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f70, %f69;
	fma.rm.f32 	%f71, %f70, %f130, %f129;
	add.rn.f32 	%f72, %f71, 0fCB40007F;
	neg.f32 	%f73, %f72;
	fma.rn.f32 	%f74, %f68, 0f3FB8AA3B, %f73;
	fma.rn.f32 	%f75, %f68, 0f32A57060, %f74;
	mov.b32 	%r16, %f71;
	shl.b32 	%r17, %r16, 23;
	mov.b32 	%f76, %r17;
	ex2.approx.ftz.f32 	%f77, %f75;
	mul.rn.f32 	%f78, %f77, %f76;
	mul.lo.s64 	%rd24, %rd35, 48;
	add.s64 	%rd25, %rd4, %rd24;
	cvt.u32.u16 	%r18, %rs1;
	and.b32  	%r19, %r18, 255;
	mul.wide.u32 	%rd26, %r19, 24;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.v2.f32 	{%f79, %f80}, [%rd27];
	add.rn.f32 	%f81, %f79, 0f00000000;
	add.rn.f32 	%f82, %f81, %f80;
	ld.global.nc.v2.f32 	{%f83, %f84}, [%rd27+8];
	add.rn.f32 	%f85, %f82, %f83;
	add.rn.f32 	%f86, %f85, %f84;
	ld.global.nc.v2.f32 	{%f87, %f88}, [%rd27+16];
	add.rn.f32 	%f89, %f86, %f87;
	add.rn.f32 	%f90, %f89, %f88;
	mul.rn.f32 	%f91, %f135, %f78;
	add.rn.f32 	%f132, %f91, %f90;
	bra.uni 	$L__BB271_3;
$L__BB271_2:
	cvt.u64.u32 	%rd35, %r3;
	mov.f32 	%f132, 0f00000000;
$L__BB271_3:
	cvta.to.global.u64 	%rd1, %rd14;
	setp.eq.s32 	%p11, %r2, 2;
	shl.b64 	%rd28, %rd35, 2;
	mov.f32 	%f133, 0f00000000;
	@%p11 bra 	$L__BB271_11;
	bra.uni 	$L__BB271_4;
$L__BB271_11:
	ld.param.u64 	%rd13, [loop_multiply_fusion_100_param_0];
	cvta.to.global.u64 	%rd5, %rd13;
	add.s64 	%rd8, %rd5, %rd28;
	ld.global.nc.f32 	%f133, [%rd8];
$L__BB271_4:
	add.rn.f32 	%f93, %f131, %f132;
	add.rn.f32 	%f94, %f93, %f133;
	add.s64 	%rd30, %rd2, %rd28;
	ld.global.nc.f32 	%f95, [%rd30];
	fma.rn.f32 	%f96, %f95, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f97, %f96;
	fma.rm.f32 	%f100, %f97, %f130, %f129;
	add.rn.f32 	%f101, %f100, 0fCB40007F;
	neg.f32 	%f102, %f101;
	fma.rn.f32 	%f103, %f95, 0f3FB8AA3B, %f102;
	fma.rn.f32 	%f104, %f95, 0f32A57060, %f103;
	mov.b32 	%r20, %f100;
	shl.b32 	%r21, %r20, 23;
	mov.b32 	%f105, %r21;
	ex2.approx.ftz.f32 	%f106, %f104;
	mul.rn.f32 	%f107, %f106, %f105;
	neg.f32 	%f108, %f107;
	sub.rn.f32 	%f109, %f108, %f107;
	add.rn.f32 	%f110, %f109, %f109;
	add.rn.f32 	%f111, %f110, %f110;
	add.rn.f32 	%f112, %f111, %f111;
	add.rn.f32 	%f113, %f112, %f112;
	add.rn.f32 	%f114, %f113, %f113;
	add.rn.f32 	%f115, %f114, %f114;
	fma.rn.f32 	%f116, %f115, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f117, %f116;
	fma.rm.f32 	%f118, %f117, %f130, %f129;
	add.rn.f32 	%f119, %f118, 0fCB40007F;
	neg.f32 	%f120, %f119;
	fma.rn.f32 	%f121, %f115, 0f3FB8AA3B, %f120;
	fma.rn.f32 	%f122, %f115, 0f32A57060, %f121;
	mov.b32 	%r22, %f118;
	shl.b32 	%r23, %r22, 23;
	mov.b32 	%f123, %r23;
	ex2.approx.ftz.f32 	%f124, %f122;
	mul.rn.f32 	%f125, %f124, %f123;
	mul.rn.f32 	%f126, %f94, %f125;
	mul.wide.u32 	%rd31, %r1, 4;
	add.s64 	%rd32, %rd1, %rd31;
	st.global.f32 	[%rd32], %f126;
	ret;

}
	// .globl	loop_reduce_fusion_50
.visible .entry loop_reduce_fusion_50(
	.param .u64 loop_reduce_fusion_50_param_0,
	.param .u64 loop_reduce_fusion_50_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<101>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd1, [loop_reduce_fusion_50_param_0];
	ld.param.u64 	%rd2, [loop_reduce_fusion_50_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs3, 3;
	shr.u16 	%rs7, %rs2, 4;
	cvt.u32.u16 	%r5, %rs7;
	mul.wide.u32 	%rd5, %r5, 4800;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r6, %rs6;
	mul.wide.u32 	%rd7, %r6, 24;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r7, %rs5;
	mul.wide.u32 	%rd9, %r7, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	add.rn.f32 	%f2, %f1, 0f00000000;
	ld.global.nc.f32 	%f3, [%rd10+96];
	add.rn.f32 	%f4, %f2, %f3;
	ld.global.nc.f32 	%f5, [%rd10+192];
	add.rn.f32 	%f6, %f4, %f5;
	ld.global.nc.f32 	%f7, [%rd10+288];
	add.rn.f32 	%f8, %f6, %f7;
	ld.global.nc.f32 	%f9, [%rd10+384];
	add.rn.f32 	%f10, %f8, %f9;
	ld.global.nc.f32 	%f11, [%rd10+480];
	add.rn.f32 	%f12, %f10, %f11;
	ld.global.nc.f32 	%f13, [%rd10+576];
	add.rn.f32 	%f14, %f12, %f13;
	ld.global.nc.f32 	%f15, [%rd10+672];
	add.rn.f32 	%f16, %f14, %f15;
	ld.global.nc.f32 	%f17, [%rd10+768];
	add.rn.f32 	%f18, %f16, %f17;
	ld.global.nc.f32 	%f19, [%rd10+864];
	add.rn.f32 	%f20, %f18, %f19;
	ld.global.nc.f32 	%f21, [%rd10+960];
	add.rn.f32 	%f22, %f20, %f21;
	ld.global.nc.f32 	%f23, [%rd10+1056];
	add.rn.f32 	%f24, %f22, %f23;
	ld.global.nc.f32 	%f25, [%rd10+1152];
	add.rn.f32 	%f26, %f24, %f25;
	ld.global.nc.f32 	%f27, [%rd10+1248];
	add.rn.f32 	%f28, %f26, %f27;
	ld.global.nc.f32 	%f29, [%rd10+1344];
	add.rn.f32 	%f30, %f28, %f29;
	ld.global.nc.f32 	%f31, [%rd10+1440];
	add.rn.f32 	%f32, %f30, %f31;
	ld.global.nc.f32 	%f33, [%rd10+1536];
	add.rn.f32 	%f34, %f32, %f33;
	ld.global.nc.f32 	%f35, [%rd10+1632];
	add.rn.f32 	%f36, %f34, %f35;
	ld.global.nc.f32 	%f37, [%rd10+1728];
	add.rn.f32 	%f38, %f36, %f37;
	ld.global.nc.f32 	%f39, [%rd10+1824];
	add.rn.f32 	%f40, %f38, %f39;
	ld.global.nc.f32 	%f41, [%rd10+1920];
	add.rn.f32 	%f42, %f40, %f41;
	ld.global.nc.f32 	%f43, [%rd10+2016];
	add.rn.f32 	%f44, %f42, %f43;
	ld.global.nc.f32 	%f45, [%rd10+2112];
	add.rn.f32 	%f46, %f44, %f45;
	ld.global.nc.f32 	%f47, [%rd10+2208];
	add.rn.f32 	%f48, %f46, %f47;
	ld.global.nc.f32 	%f49, [%rd10+2304];
	add.rn.f32 	%f50, %f48, %f49;
	ld.global.nc.f32 	%f51, [%rd10+2400];
	add.rn.f32 	%f52, %f50, %f51;
	ld.global.nc.f32 	%f53, [%rd10+2496];
	add.rn.f32 	%f54, %f52, %f53;
	ld.global.nc.f32 	%f55, [%rd10+2592];
	add.rn.f32 	%f56, %f54, %f55;
	ld.global.nc.f32 	%f57, [%rd10+2688];
	add.rn.f32 	%f58, %f56, %f57;
	ld.global.nc.f32 	%f59, [%rd10+2784];
	add.rn.f32 	%f60, %f58, %f59;
	ld.global.nc.f32 	%f61, [%rd10+2880];
	add.rn.f32 	%f62, %f60, %f61;
	ld.global.nc.f32 	%f63, [%rd10+2976];
	add.rn.f32 	%f64, %f62, %f63;
	ld.global.nc.f32 	%f65, [%rd10+3072];
	add.rn.f32 	%f66, %f64, %f65;
	ld.global.nc.f32 	%f67, [%rd10+3168];
	add.rn.f32 	%f68, %f66, %f67;
	ld.global.nc.f32 	%f69, [%rd10+3264];
	add.rn.f32 	%f70, %f68, %f69;
	ld.global.nc.f32 	%f71, [%rd10+3360];
	add.rn.f32 	%f72, %f70, %f71;
	ld.global.nc.f32 	%f73, [%rd10+3456];
	add.rn.f32 	%f74, %f72, %f73;
	ld.global.nc.f32 	%f75, [%rd10+3552];
	add.rn.f32 	%f76, %f74, %f75;
	ld.global.nc.f32 	%f77, [%rd10+3648];
	add.rn.f32 	%f78, %f76, %f77;
	ld.global.nc.f32 	%f79, [%rd10+3744];
	add.rn.f32 	%f80, %f78, %f79;
	ld.global.nc.f32 	%f81, [%rd10+3840];
	add.rn.f32 	%f82, %f80, %f81;
	ld.global.nc.f32 	%f83, [%rd10+3936];
	add.rn.f32 	%f84, %f82, %f83;
	ld.global.nc.f32 	%f85, [%rd10+4032];
	add.rn.f32 	%f86, %f84, %f85;
	ld.global.nc.f32 	%f87, [%rd10+4128];
	add.rn.f32 	%f88, %f86, %f87;
	ld.global.nc.f32 	%f89, [%rd10+4224];
	add.rn.f32 	%f90, %f88, %f89;
	ld.global.nc.f32 	%f91, [%rd10+4320];
	add.rn.f32 	%f92, %f90, %f91;
	ld.global.nc.f32 	%f93, [%rd10+4416];
	add.rn.f32 	%f94, %f92, %f93;
	ld.global.nc.f32 	%f95, [%rd10+4512];
	add.rn.f32 	%f96, %f94, %f95;
	ld.global.nc.f32 	%f97, [%rd10+4608];
	add.rn.f32 	%f98, %f96, %f97;
	ld.global.nc.f32 	%f99, [%rd10+4704];
	add.rn.f32 	%f100, %f98, %f99;
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd3, %rd11;
	st.global.f32 	[%rd12], %f100;
	ret;

}
	// .globl	loop_multiply_fusion_101
.visible .entry loop_multiply_fusion_101(
	.param .u64 loop_multiply_fusion_101_param_0,
	.param .u64 loop_multiply_fusion_101_param_1,
	.param .u64 loop_multiply_fusion_101_param_2,
	.param .u64 loop_multiply_fusion_101_param_3,
	.param .u64 loop_multiply_fusion_101_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<10>;
	.reg .b32 	%r<20>;
	.reg .f32 	%f<162>;
	.reg .b64 	%rd<40>;

	ld.param.u64 	%rd11, [loop_multiply_fusion_101_param_0];
	cvta.to.global.u64 	%rd5, %rd11;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r2, %r7, 7;
	or.b32  	%r3, %r2, %r1;
	and.b32  	%r4, %r1, 7;
	shr.u32 	%r8, %r3, 3;
	and.b32  	%r5, %r1, 1;
	setp.eq.s32 	%p1, %r5, 0;
	mov.f32 	%f161, 0f00000000;
	mov.f32 	%f158, %f161;
	@%p1 bra 	$L__BB273_4;
	bra.uni 	$L__BB273_1;
$L__BB273_4:
	bfe.u32 	%r9, %r1, 1, 2;
	mul.wide.u32 	%rd16, %r8, 16;
	add.s64 	%rd17, %rd5, %rd16;
	mul.wide.u32 	%rd18, %r9, 4;
	add.s64 	%rd7, %rd17, %rd18;
	ld.global.nc.f32 	%f158, [%rd7];
$L__BB273_1:
	ld.param.u64 	%rd12, [loop_multiply_fusion_101_param_4];
	ld.param.u64 	%rd15, [loop_multiply_fusion_101_param_2];
	cvt.u64.u32 	%rd6, %r8;
	add.s32 	%r6, %r4, -1;
	and.b32  	%r10, %r6, 1;
	setp.eq.b32 	%p2, %r10, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f32 	%f159, %f161;
	@%p5 bra 	$L__BB273_5;
	bra.uni 	$L__BB273_2;
$L__BB273_5:
	ld.param.u64 	%rd13, [loop_multiply_fusion_101_param_1];
	cvta.to.global.u64 	%rd4, %rd13;
	bfe.u32 	%r11, %r6, 1, 7;
	shl.b64 	%rd19, %rd6, 4;
	add.s64 	%rd20, %rd5, %rd19;
	mul.wide.u32 	%rd21, %r11, 4;
	add.s64 	%rd22, %rd20, %rd21;
	ld.global.nc.f32 	%f10, [%rd22];
	mul.lo.s64 	%rd23, %rd6, 96;
	add.s64 	%rd24, %rd4, %rd23;
	mul.wide.u32 	%rd25, %r11, 24;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.v2.f32 	{%f11, %f12}, [%rd26];
	add.rn.f32 	%f13, %f11, 0f00000000;
	add.rn.f32 	%f14, %f13, %f12;
	ld.global.nc.v2.f32 	{%f15, %f16}, [%rd26+8];
	add.rn.f32 	%f17, %f14, %f15;
	add.rn.f32 	%f18, %f17, %f16;
	ld.global.nc.v2.f32 	{%f19, %f20}, [%rd26+16];
	add.rn.f32 	%f21, %f18, %f19;
	add.rn.f32 	%f22, %f21, %f20;
	add.rn.f32 	%f159, %f10, %f22;
$L__BB273_2:
	cvta.to.global.u64 	%rd1, %rd12;
	cvta.to.global.u64 	%rd3, %rd15;
	setp.ne.s32 	%p6, %r5, 0;
	setp.lt.u32 	%p7, %r4, 2;
	or.pred  	%p8, %p7, %p6;
	@%p8 bra 	$L__BB273_7;
	ld.param.u64 	%rd14, [loop_multiply_fusion_101_param_3];
	cvta.to.global.u64 	%rd2, %rd14;
	add.s32 	%r12, %r4, -2;
	shr.u32 	%r13, %r12, 1;
	add.s32 	%r14, %r1, %r2;
	cvt.u64.u32 	%rd28, %r14;
	shr.u64 	%rd29, %rd28, 3;
	mul.lo.s64 	%rd30, %rd29, 3600;
	mul.wide.u32 	%rd31, %r13, 24;
	add.s64 	%rd32, %rd30, %rd31;
	add.s64 	%rd33, %rd32, %rd2;
	add.s64 	%rd8, %rd33, 1800;
	mov.f32 	%f161, 0f00000000;
	mov.u64 	%rd39, 0;
$L__BB273_6:
	add.s64 	%rd34, %rd8, %rd39;
	ld.global.nc.f32 	%f25, [%rd34+-1800];
	add.rn.f32 	%f26, %f25, 0f00000000;
	ld.global.nc.f32 	%f27, [%rd34+-1728];
	add.rn.f32 	%f28, %f26, %f27;
	ld.global.nc.f32 	%f29, [%rd34+-1656];
	add.rn.f32 	%f30, %f28, %f29;
	ld.global.nc.f32 	%f31, [%rd34+-1584];
	add.rn.f32 	%f32, %f30, %f31;
	ld.global.nc.f32 	%f33, [%rd34+-1512];
	add.rn.f32 	%f34, %f32, %f33;
	ld.global.nc.f32 	%f35, [%rd34+-1440];
	add.rn.f32 	%f36, %f34, %f35;
	ld.global.nc.f32 	%f37, [%rd34+-1368];
	add.rn.f32 	%f38, %f36, %f37;
	ld.global.nc.f32 	%f39, [%rd34+-1296];
	add.rn.f32 	%f40, %f38, %f39;
	ld.global.nc.f32 	%f41, [%rd34+-1224];
	add.rn.f32 	%f42, %f40, %f41;
	ld.global.nc.f32 	%f43, [%rd34+-1152];
	add.rn.f32 	%f44, %f42, %f43;
	ld.global.nc.f32 	%f45, [%rd34+-1080];
	add.rn.f32 	%f46, %f44, %f45;
	ld.global.nc.f32 	%f47, [%rd34+-1008];
	add.rn.f32 	%f48, %f46, %f47;
	ld.global.nc.f32 	%f49, [%rd34+-936];
	add.rn.f32 	%f50, %f48, %f49;
	ld.global.nc.f32 	%f51, [%rd34+-864];
	add.rn.f32 	%f52, %f50, %f51;
	ld.global.nc.f32 	%f53, [%rd34+-792];
	add.rn.f32 	%f54, %f52, %f53;
	ld.global.nc.f32 	%f55, [%rd34+-720];
	add.rn.f32 	%f56, %f54, %f55;
	ld.global.nc.f32 	%f57, [%rd34+-648];
	add.rn.f32 	%f58, %f56, %f57;
	ld.global.nc.f32 	%f59, [%rd34+-576];
	add.rn.f32 	%f60, %f58, %f59;
	ld.global.nc.f32 	%f61, [%rd34+-504];
	add.rn.f32 	%f62, %f60, %f61;
	ld.global.nc.f32 	%f63, [%rd34+-432];
	add.rn.f32 	%f64, %f62, %f63;
	ld.global.nc.f32 	%f65, [%rd34+-360];
	add.rn.f32 	%f66, %f64, %f65;
	ld.global.nc.f32 	%f67, [%rd34+-288];
	add.rn.f32 	%f68, %f66, %f67;
	ld.global.nc.f32 	%f69, [%rd34+-216];
	add.rn.f32 	%f70, %f68, %f69;
	ld.global.nc.f32 	%f71, [%rd34+-144];
	add.rn.f32 	%f72, %f70, %f71;
	ld.global.nc.f32 	%f73, [%rd34+-72];
	add.rn.f32 	%f74, %f72, %f73;
	ld.global.nc.f32 	%f75, [%rd34];
	add.rn.f32 	%f76, %f74, %f75;
	ld.global.nc.f32 	%f77, [%rd34+72];
	add.rn.f32 	%f78, %f76, %f77;
	ld.global.nc.f32 	%f79, [%rd34+144];
	add.rn.f32 	%f80, %f78, %f79;
	ld.global.nc.f32 	%f81, [%rd34+216];
	add.rn.f32 	%f82, %f80, %f81;
	ld.global.nc.f32 	%f83, [%rd34+288];
	add.rn.f32 	%f84, %f82, %f83;
	ld.global.nc.f32 	%f85, [%rd34+360];
	add.rn.f32 	%f86, %f84, %f85;
	ld.global.nc.f32 	%f87, [%rd34+432];
	add.rn.f32 	%f88, %f86, %f87;
	ld.global.nc.f32 	%f89, [%rd34+504];
	add.rn.f32 	%f90, %f88, %f89;
	ld.global.nc.f32 	%f91, [%rd34+576];
	add.rn.f32 	%f92, %f90, %f91;
	ld.global.nc.f32 	%f93, [%rd34+648];
	add.rn.f32 	%f94, %f92, %f93;
	ld.global.nc.f32 	%f95, [%rd34+720];
	add.rn.f32 	%f96, %f94, %f95;
	ld.global.nc.f32 	%f97, [%rd34+792];
	add.rn.f32 	%f98, %f96, %f97;
	ld.global.nc.f32 	%f99, [%rd34+864];
	add.rn.f32 	%f100, %f98, %f99;
	ld.global.nc.f32 	%f101, [%rd34+936];
	add.rn.f32 	%f102, %f100, %f101;
	ld.global.nc.f32 	%f103, [%rd34+1008];
	add.rn.f32 	%f104, %f102, %f103;
	ld.global.nc.f32 	%f105, [%rd34+1080];
	add.rn.f32 	%f106, %f104, %f105;
	ld.global.nc.f32 	%f107, [%rd34+1152];
	add.rn.f32 	%f108, %f106, %f107;
	ld.global.nc.f32 	%f109, [%rd34+1224];
	add.rn.f32 	%f110, %f108, %f109;
	ld.global.nc.f32 	%f111, [%rd34+1296];
	add.rn.f32 	%f112, %f110, %f111;
	ld.global.nc.f32 	%f113, [%rd34+1368];
	add.rn.f32 	%f114, %f112, %f113;
	ld.global.nc.f32 	%f115, [%rd34+1440];
	add.rn.f32 	%f116, %f114, %f115;
	ld.global.nc.f32 	%f117, [%rd34+1512];
	add.rn.f32 	%f118, %f116, %f117;
	ld.global.nc.f32 	%f119, [%rd34+1584];
	add.rn.f32 	%f120, %f118, %f119;
	ld.global.nc.f32 	%f121, [%rd34+1656];
	add.rn.f32 	%f122, %f120, %f121;
	ld.global.nc.f32 	%f123, [%rd34+1728];
	add.rn.f32 	%f124, %f122, %f123;
	add.rn.f32 	%f161, %f161, %f124;
	add.s64 	%rd39, %rd39, 4;
	cvt.u32.u64 	%r15, %rd39;
	setp.eq.s32 	%p9, %r15, 24;
	@%p9 bra 	$L__BB273_7;
	bra.uni 	$L__BB273_6;
$L__BB273_7:
	add.rn.f32 	%f125, %f158, %f159;
	add.rn.f32 	%f126, %f125, %f161;
	shl.b64 	%rd35, %rd6, 2;
	add.s64 	%rd36, %rd3, %rd35;
	ld.global.nc.f32 	%f127, [%rd36];
	fma.rn.f32 	%f128, %f127, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f129, %f128;
	mov.f32 	%f130, 0f4B400001;
	mov.f32 	%f131, 0f437C0000;
	fma.rm.f32 	%f132, %f129, %f131, %f130;
	add.rn.f32 	%f133, %f132, 0fCB40007F;
	neg.f32 	%f134, %f133;
	fma.rn.f32 	%f135, %f127, 0f3FB8AA3B, %f134;
	fma.rn.f32 	%f136, %f127, 0f32A57060, %f135;
	mov.b32 	%r16, %f132;
	shl.b32 	%r17, %r16, 23;
	mov.b32 	%f137, %r17;
	ex2.approx.ftz.f32 	%f138, %f136;
	mul.rn.f32 	%f139, %f138, %f137;
	neg.f32 	%f140, %f139;
	sub.rn.f32 	%f141, %f140, %f139;
	add.rn.f32 	%f142, %f141, %f141;
	add.rn.f32 	%f143, %f142, %f142;
	add.rn.f32 	%f144, %f143, %f143;
	add.rn.f32 	%f145, %f144, %f144;
	add.rn.f32 	%f146, %f145, %f145;
	fma.rn.f32 	%f147, %f146, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f148, %f147;
	fma.rm.f32 	%f149, %f148, %f131, %f130;
	add.rn.f32 	%f150, %f149, 0fCB40007F;
	neg.f32 	%f151, %f150;
	fma.rn.f32 	%f152, %f146, 0f3FB8AA3B, %f151;
	fma.rn.f32 	%f153, %f146, 0f32A57060, %f152;
	mov.b32 	%r18, %f149;
	shl.b32 	%r19, %r18, 23;
	mov.b32 	%f154, %r19;
	ex2.approx.ftz.f32 	%f155, %f153;
	mul.rn.f32 	%f156, %f155, %f154;
	mul.rn.f32 	%f157, %f126, %f156;
	mul.wide.u32 	%rd37, %r3, 4;
	add.s64 	%rd38, %rd1, %rd37;
	st.global.f32 	[%rd38], %f157;
	ret;

}
	// .globl	loop_add_fusion_382
.visible .entry loop_add_fusion_382(
	.param .u64 loop_add_fusion_382_param_0,
	.param .u64 loop_add_fusion_382_param_1,
	.param .u64 loop_add_fusion_382_param_2,
	.param .u64 loop_add_fusion_382_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<39>;
	.reg .b64 	%rd<28>;

	ld.param.u64 	%rd9, [loop_add_fusion_382_param_1];
	cvta.to.global.u64 	%rd3, %rd9;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	shl.b32 	%r7, %r5, 7;
	or.b32  	%r1, %r7, %r6;
	and.b32  	%r2, %r6, 15;
	shr.u32 	%r8, %r1, 4;
	and.b32  	%r3, %r6, 1;
	setp.eq.s32 	%p1, %r3, 0;
	mov.f32 	%f38, 0f00000000;
	mov.f32 	%f36, %f38;
	@%p1 bra 	$L__BB274_5;
	bra.uni 	$L__BB274_1;
$L__BB274_5:
	bfe.u32 	%r9, %r6, 1, 3;
	mul.wide.u32 	%rd11, %r8, 32;
	add.s64 	%rd12, %rd3, %rd11;
	mul.wide.u32 	%rd13, %r9, 4;
	add.s64 	%rd6, %rd12, %rd13;
	ld.global.nc.f32 	%f36, [%rd6];
$L__BB274_1:
	ld.param.u64 	%rd8, [loop_add_fusion_382_param_3];
	cvt.u64.u32 	%rd5, %r8;
	add.s32 	%r4, %r2, -1;
	and.b32  	%r10, %r4, 1;
	setp.eq.b32 	%p2, %r10, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f32 	%f37, %f38;
	@%p5 bra 	$L__BB274_6;
	bra.uni 	$L__BB274_2;
$L__BB274_6:
	ld.param.u64 	%rd10, [loop_add_fusion_382_param_2];
	cvta.to.global.u64 	%rd2, %rd10;
	bfe.u32 	%r11, %r4, 1, 7;
	shl.b64 	%rd14, %rd5, 5;
	add.s64 	%rd15, %rd3, %rd14;
	mul.wide.u32 	%rd16, %r11, 4;
	add.s64 	%rd17, %rd15, %rd16;
	ld.global.nc.f32 	%f9, [%rd17];
	mul.lo.s64 	%rd18, %rd5, 192;
	add.s64 	%rd19, %rd2, %rd18;
	mul.wide.u32 	%rd20, %r11, 24;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd21];
	add.rn.f32 	%f12, %f10, 0f00000000;
	add.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.v2.f32 	{%f14, %f15}, [%rd21+8];
	add.rn.f32 	%f16, %f13, %f14;
	add.rn.f32 	%f17, %f16, %f15;
	ld.global.nc.v2.f32 	{%f18, %f19}, [%rd21+16];
	add.rn.f32 	%f20, %f17, %f18;
	add.rn.f32 	%f21, %f20, %f19;
	add.rn.f32 	%f37, %f9, %f21;
$L__BB274_2:
	cvta.to.global.u64 	%rd1, %rd8;
	setp.ne.s32 	%p6, %r3, 0;
	setp.lt.u32 	%p7, %r2, 2;
	or.pred  	%p8, %p7, %p6;
	@%p8 bra 	$L__BB274_4;
	ld.param.u64 	%rd7, [loop_add_fusion_382_param_0];
	cvta.to.global.u64 	%rd4, %rd7;
	add.s32 	%r12, %r2, -2;
	shr.u32 	%r13, %r12, 1;
	mul.lo.s64 	%rd22, %rd5, 168;
	add.s64 	%rd23, %rd4, %rd22;
	mul.wide.u32 	%rd24, %r13, 24;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.nc.v2.f32 	{%f23, %f24}, [%rd25];
	add.rn.f32 	%f25, %f23, 0f00000000;
	add.rn.f32 	%f26, %f25, %f24;
	ld.global.nc.v2.f32 	{%f27, %f28}, [%rd25+8];
	add.rn.f32 	%f29, %f26, %f27;
	add.rn.f32 	%f30, %f29, %f28;
	ld.global.nc.v2.f32 	{%f31, %f32}, [%rd25+16];
	add.rn.f32 	%f33, %f30, %f31;
	add.rn.f32 	%f38, %f33, %f32;
$L__BB274_4:
	add.rn.f32 	%f34, %f36, %f37;
	add.rn.f32 	%f35, %f34, %f38;
	mul.wide.u32 	%rd26, %r1, 4;
	add.s64 	%rd27, %rd1, %rd26;
	st.global.f32 	[%rd27], %f35;
	ret;

}
	// .globl	loop_multiply_fusion_102
.visible .entry loop_multiply_fusion_102(
	.param .u64 loop_multiply_fusion_102_param_0,
	.param .u64 loop_multiply_fusion_102_param_1,
	.param .u64 loop_multiply_fusion_102_param_2,
	.param .u64 loop_multiply_fusion_102_param_3,
	.param .u64 loop_multiply_fusion_102_param_4,
	.param .u64 loop_multiply_fusion_102_param_5
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .f32 	%f<103>;
	.reg .b64 	%rd<43>;

	ld.param.u64 	%rd10, [loop_multiply_fusion_102_param_0];
	ld.param.u64 	%rd13, [loop_multiply_fusion_102_param_4];
	cvta.to.global.u64 	%rd2, %rd13;
	cvta.to.global.u64 	%rd6, %rd10;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	shl.b32 	%r8, %r6, 7;
	or.b32  	%r1, %r8, %r7;
	and.b32  	%r2, %r7, 31;
	shr.u32 	%r3, %r1, 5;
	and.b32  	%r4, %r7, 1;
	setp.eq.s32 	%p1, %r4, 0;
	mov.f32 	%f101, 0f00000000;
	mul.wide.u32 	%rd40, %r3, 64;
	mul.wide.u32 	%rd41, %r3, 4;
	mov.f32 	%f98, 0f4B400001;
	mov.f32 	%f99, 0f437C0000;
	mov.f32 	%f100, %f101;
	@%p1 bra 	$L__BB275_6;
	bra.uni 	$L__BB275_1;
$L__BB275_6:
	shr.u32 	%r9, %r2, 1;
	add.s64 	%rd17, %rd6, %rd40;
	mul.wide.u32 	%rd18, %r9, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.nc.f32 	%f8, [%rd19];
	add.s64 	%rd21, %rd2, %rd41;
	ld.global.nc.f32 	%f9, [%rd21];
	fma.rn.f32 	%f10, %f9, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f11, %f10;
	fma.rm.f32 	%f14, %f11, %f99, %f98;
	add.rn.f32 	%f15, %f14, 0fCB40007F;
	neg.f32 	%f16, %f15;
	fma.rn.f32 	%f17, %f9, 0f3FB8AA3B, %f16;
	fma.rn.f32 	%f18, %f9, 0f32A57060, %f17;
	mov.b32 	%r10, %f14;
	shl.b32 	%r11, %r10, 23;
	mov.b32 	%f19, %r11;
	ex2.approx.ftz.f32 	%f20, %f18;
	mul.rn.f32 	%f21, %f20, %f19;
	neg.f32 	%f22, %f21;
	sub.rn.f32 	%f23, %f22, %f21;
	add.rn.f32 	%f24, %f23, %f23;
	add.rn.f32 	%f25, %f24, %f24;
	add.rn.f32 	%f26, %f25, %f25;
	add.rn.f32 	%f27, %f26, %f26;
	fma.rn.f32 	%f28, %f27, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f29, %f28;
	fma.rm.f32 	%f30, %f29, %f99, %f98;
	add.rn.f32 	%f31, %f30, 0fCB40007F;
	neg.f32 	%f32, %f31;
	fma.rn.f32 	%f33, %f27, 0f3FB8AA3B, %f32;
	fma.rn.f32 	%f34, %f27, 0f32A57060, %f33;
	mov.b32 	%r12, %f30;
	shl.b32 	%r13, %r12, 23;
	mov.b32 	%f35, %r13;
	ex2.approx.ftz.f32 	%f36, %f34;
	mul.rn.f32 	%f37, %f36, %f35;
	mul.rn.f32 	%f100, %f8, %f37;
$L__BB275_1:
	ld.param.u64 	%rd11, [loop_multiply_fusion_102_param_5];
	ld.param.u64 	%rd15, [loop_multiply_fusion_102_param_3];
	add.s32 	%r5, %r2, -1;
	and.b32  	%r14, %r5, 1;
	setp.eq.b32 	%p2, %r14, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	@%p5 bra 	$L__BB275_7;
	bra.uni 	$L__BB275_2;
$L__BB275_7:
	ld.param.u64 	%rd12, [loop_multiply_fusion_102_param_1];
	cvta.to.global.u64 	%rd5, %rd12;
	bfe.u32 	%r15, %r5, 1, 7;
	add.s64 	%rd23, %rd6, %rd40;
	mul.wide.u32 	%rd24, %r15, 4;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.nc.f32 	%f39, [%rd25];
	add.s64 	%rd27, %rd2, %rd41;
	ld.global.nc.f32 	%f40, [%rd27];
	fma.rn.f32 	%f41, %f40, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f42, %f41;
	fma.rm.f32 	%f45, %f42, %f99, %f98;
	add.rn.f32 	%f46, %f45, 0fCB40007F;
	neg.f32 	%f47, %f46;
	fma.rn.f32 	%f48, %f40, 0f3FB8AA3B, %f47;
	fma.rn.f32 	%f49, %f40, 0f32A57060, %f48;
	mov.b32 	%r16, %f45;
	shl.b32 	%r17, %r16, 23;
	mov.b32 	%f50, %r17;
	ex2.approx.ftz.f32 	%f51, %f49;
	mul.rn.f32 	%f52, %f51, %f50;
	neg.f32 	%f53, %f52;
	sub.rn.f32 	%f54, %f53, %f52;
	add.rn.f32 	%f55, %f54, %f54;
	add.rn.f32 	%f56, %f55, %f55;
	add.rn.f32 	%f57, %f56, %f56;
	add.rn.f32 	%f58, %f57, %f57;
	fma.rn.f32 	%f59, %f58, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f60, %f59;
	fma.rm.f32 	%f61, %f60, %f99, %f98;
	add.rn.f32 	%f62, %f61, 0fCB40007F;
	neg.f32 	%f63, %f62;
	fma.rn.f32 	%f64, %f58, 0f3FB8AA3B, %f63;
	fma.rn.f32 	%f65, %f58, 0f32A57060, %f64;
	mov.b32 	%r18, %f61;
	shl.b32 	%r19, %r18, 23;
	mov.b32 	%f66, %r19;
	ex2.approx.ftz.f32 	%f67, %f65;
	mul.rn.f32 	%f68, %f67, %f66;
	mul.wide.u32 	%rd28, %r3, 384;
	add.s64 	%rd29, %rd5, %rd28;
	mul.wide.u32 	%rd30, %r15, 24;
	add.s64 	%rd31, %rd29, %rd30;
	ld.global.nc.v2.f32 	{%f69, %f70}, [%rd31];
	add.rn.f32 	%f71, %f69, 0f00000000;
	add.rn.f32 	%f72, %f71, %f70;
	ld.global.nc.v2.f32 	{%f73, %f74}, [%rd31+8];
	add.rn.f32 	%f75, %f72, %f73;
	add.rn.f32 	%f76, %f75, %f74;
	ld.global.nc.v2.f32 	{%f77, %f78}, [%rd31+16];
	add.rn.f32 	%f79, %f76, %f77;
	add.rn.f32 	%f80, %f79, %f78;
	mul.rn.f32 	%f81, %f39, %f68;
	add.rn.f32 	%f101, %f81, %f80;
$L__BB275_2:
	cvta.to.global.u64 	%rd1, %rd11;
	cvta.to.global.u64 	%rd3, %rd15;
	setp.gt.u32 	%p7, %r2, 1;
	and.pred  	%p8, %p7, %p1;
	@%p8 bra 	$L__BB275_4;
	bra.uni 	$L__BB275_3;
$L__BB275_4:
	ld.param.u64 	%rd14, [loop_multiply_fusion_102_param_2];
	cvta.to.global.u64 	%rd4, %rd14;
	add.s32 	%r20, %r2, -2;
	shr.u32 	%r21, %r20, 1;
	cvt.u64.u32 	%rd42, %r3;
	mul.wide.u32 	%rd32, %r3, 360;
	add.s64 	%rd33, %rd4, %rd32;
	mul.wide.u32 	%rd34, %r21, 24;
	add.s64 	%rd35, %rd33, %rd34;
	ld.global.nc.v2.f32 	{%f83, %f84}, [%rd35];
	add.rn.f32 	%f85, %f83, 0f00000000;
	add.rn.f32 	%f86, %f85, %f84;
	ld.global.nc.v2.f32 	{%f87, %f88}, [%rd35+8];
	add.rn.f32 	%f89, %f86, %f87;
	add.rn.f32 	%f90, %f89, %f88;
	ld.global.nc.v2.f32 	{%f91, %f92}, [%rd35+16];
	add.rn.f32 	%f93, %f90, %f91;
	add.rn.f32 	%f102, %f93, %f92;
	bra.uni 	$L__BB275_5;
$L__BB275_3:
	cvt.u64.u32 	%rd42, %r3;
	mov.f32 	%f102, 0f00000000;
$L__BB275_5:
	add.rn.f32 	%f94, %f100, %f101;
	add.rn.f32 	%f95, %f94, %f102;
	shl.b64 	%rd36, %rd42, 2;
	add.s64 	%rd37, %rd3, %rd36;
	ld.global.nc.f32 	%f96, [%rd37];
	mul.rn.f32 	%f97, %f95, %f96;
	mul.wide.u32 	%rd38, %r1, 4;
	add.s64 	%rd39, %rd1, %rd38;
	st.global.f32 	[%rd39], %f97;
	ret;

}
	// .globl	loop_multiply_fusion_103
.visible .entry loop_multiply_fusion_103(
	.param .u64 loop_multiply_fusion_103_param_0,
	.param .u64 loop_multiply_fusion_103_param_1,
	.param .u64 loop_multiply_fusion_103_param_2,
	.param .u64 loop_multiply_fusion_103_param_3,
	.param .u64 loop_multiply_fusion_103_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<41>;
	.reg .b64 	%rd<32>;

	ld.param.u64 	%rd8, [loop_multiply_fusion_103_param_0];
	cvta.to.global.u64 	%rd5, %rd8;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	shl.b32 	%r7, %r5, 7;
	or.b32  	%r1, %r7, %r6;
	and.b32  	%r2, %r6, 63;
	shr.u32 	%r8, %r1, 6;
	and.b32  	%r3, %r6, 1;
	setp.eq.s32 	%p1, %r3, 0;
	mov.f32 	%f40, 0f00000000;
	mov.f32 	%f38, %f40;
	@%p1 bra 	$L__BB276_5;
	bra.uni 	$L__BB276_1;
$L__BB276_5:
	bfe.u32 	%r9, %r6, 1, 5;
	mul.wide.u32 	%rd13, %r8, 128;
	add.s64 	%rd14, %rd5, %rd13;
	mul.wide.u32 	%rd15, %r9, 4;
	add.s64 	%rd7, %rd14, %rd15;
	ld.global.nc.f32 	%f38, [%rd7];
$L__BB276_1:
	ld.param.u64 	%rd9, [loop_multiply_fusion_103_param_4];
	ld.param.u64 	%rd11, [loop_multiply_fusion_103_param_3];
	cvt.u64.u32 	%rd6, %r8;
	add.s32 	%r4, %r2, -1;
	and.b32  	%r10, %r4, 1;
	setp.eq.b32 	%p2, %r10, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f32 	%f39, %f40;
	@%p5 bra 	$L__BB276_6;
	bra.uni 	$L__BB276_2;
$L__BB276_6:
	ld.param.u64 	%rd10, [loop_multiply_fusion_103_param_1];
	cvta.to.global.u64 	%rd4, %rd10;
	bfe.u32 	%r11, %r4, 1, 7;
	shl.b64 	%rd16, %rd6, 7;
	add.s64 	%rd17, %rd5, %rd16;
	mul.wide.u32 	%rd18, %r11, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.nc.f32 	%f9, [%rd19];
	mul.lo.s64 	%rd20, %rd6, 768;
	add.s64 	%rd21, %rd4, %rd20;
	mul.wide.u32 	%rd22, %r11, 24;
	add.s64 	%rd23, %rd21, %rd22;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd23];
	add.rn.f32 	%f12, %f10, 0f00000000;
	add.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.v2.f32 	{%f14, %f15}, [%rd23+8];
	add.rn.f32 	%f16, %f13, %f14;
	add.rn.f32 	%f17, %f16, %f15;
	ld.global.nc.v2.f32 	{%f18, %f19}, [%rd23+16];
	add.rn.f32 	%f20, %f17, %f18;
	add.rn.f32 	%f21, %f20, %f19;
	add.rn.f32 	%f39, %f9, %f21;
$L__BB276_2:
	cvta.to.global.u64 	%rd1, %rd9;
	cvta.to.global.u64 	%rd2, %rd11;
	setp.ne.s32 	%p6, %r3, 0;
	setp.lt.u32 	%p7, %r2, 2;
	or.pred  	%p8, %p7, %p6;
	@%p8 bra 	$L__BB276_4;
	ld.param.u64 	%rd12, [loop_multiply_fusion_103_param_2];
	cvta.to.global.u64 	%rd3, %rd12;
	add.s32 	%r12, %r2, -2;
	shr.u32 	%r13, %r12, 1;
	mul.lo.s64 	%rd24, %rd6, 744;
	add.s64 	%rd25, %rd3, %rd24;
	mul.wide.u32 	%rd26, %r13, 24;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.v2.f32 	{%f23, %f24}, [%rd27];
	add.rn.f32 	%f25, %f23, 0f00000000;
	add.rn.f32 	%f26, %f25, %f24;
	ld.global.nc.v2.f32 	{%f27, %f28}, [%rd27+8];
	add.rn.f32 	%f29, %f26, %f27;
	add.rn.f32 	%f30, %f29, %f28;
	ld.global.nc.v2.f32 	{%f31, %f32}, [%rd27+16];
	add.rn.f32 	%f33, %f30, %f31;
	add.rn.f32 	%f40, %f33, %f32;
$L__BB276_4:
	add.rn.f32 	%f34, %f38, %f39;
	add.rn.f32 	%f35, %f34, %f40;
	shl.b64 	%rd28, %rd6, 2;
	add.s64 	%rd29, %rd2, %rd28;
	ld.global.nc.f32 	%f36, [%rd29];
	mul.rn.f32 	%f37, %f35, %f36;
	mul.wide.u32 	%rd30, %r1, 4;
	add.s64 	%rd31, %rd1, %rd30;
	st.global.f32 	[%rd31], %f37;
	ret;

}
	// .globl	loop_multiply_fusion_104
.visible .entry loop_multiply_fusion_104(
	.param .u64 loop_multiply_fusion_104_param_0,
	.param .u64 loop_multiply_fusion_104_param_1,
	.param .u64 loop_multiply_fusion_104_param_2,
	.param .u64 loop_multiply_fusion_104_param_3,
	.param .u64 loop_multiply_fusion_104_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<13>;
	.reg .f32 	%f<41>;
	.reg .b64 	%rd<32>;

	ld.param.u64 	%rd12, [loop_multiply_fusion_104_param_2];
	cvta.to.global.u64 	%rd3, %rd12;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r1, %tid.x;
	and.b32  	%r2, %r1, 1;
	setp.eq.s32 	%p1, %r2, 0;
	mov.f32 	%f40, 0f00000000;
	mov.f32 	%f38, %f40;
	@%p1 bra 	$L__BB277_5;
	bra.uni 	$L__BB277_1;
$L__BB277_5:
	shr.u32 	%r5, %r1, 1;
	mul.wide.u32 	%rd13, %r4, 256;
	add.s64 	%rd14, %rd3, %rd13;
	mul.wide.u32 	%rd15, %r5, 4;
	add.s64 	%rd7, %rd14, %rd15;
	ld.global.nc.f32 	%f38, [%rd7];
$L__BB277_1:
	ld.param.u64 	%rd8, [loop_multiply_fusion_104_param_0];
	ld.param.u64 	%rd9, [loop_multiply_fusion_104_param_4];
	cvt.u64.u32 	%rd6, %r4;
	add.s32 	%r3, %r1, -1;
	and.b32  	%r6, %r3, 1;
	setp.eq.b32 	%p2, %r6, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f32 	%f39, %f40;
	@%p5 bra 	$L__BB277_6;
	bra.uni 	$L__BB277_2;
$L__BB277_6:
	ld.param.u64 	%rd11, [loop_multiply_fusion_104_param_3];
	cvta.to.global.u64 	%rd2, %rd11;
	bfe.u32 	%r7, %r3, 1, 7;
	shl.b64 	%rd16, %rd6, 8;
	add.s64 	%rd17, %rd3, %rd16;
	mul.wide.u32 	%rd18, %r7, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.nc.f32 	%f9, [%rd19];
	mul.lo.s64 	%rd20, %rd6, 1536;
	add.s64 	%rd21, %rd2, %rd20;
	mul.wide.u32 	%rd22, %r7, 24;
	add.s64 	%rd23, %rd21, %rd22;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd23];
	add.rn.f32 	%f12, %f10, 0f00000000;
	add.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.v2.f32 	{%f14, %f15}, [%rd23+8];
	add.rn.f32 	%f16, %f13, %f14;
	add.rn.f32 	%f17, %f16, %f15;
	ld.global.nc.v2.f32 	{%f18, %f19}, [%rd23+16];
	add.rn.f32 	%f20, %f17, %f18;
	add.rn.f32 	%f21, %f20, %f19;
	add.rn.f32 	%f39, %f9, %f21;
$L__BB277_2:
	cvta.to.global.u64 	%rd1, %rd9;
	cvta.to.global.u64 	%rd5, %rd8;
	setp.ne.s32 	%p6, %r2, 0;
	setp.lt.u32 	%p7, %r1, 2;
	or.pred  	%p8, %p7, %p6;
	@%p8 bra 	$L__BB277_4;
	ld.param.u64 	%rd10, [loop_multiply_fusion_104_param_1];
	cvta.to.global.u64 	%rd4, %rd10;
	add.s32 	%r8, %r1, -2;
	shr.u32 	%r9, %r8, 1;
	mul.lo.s64 	%rd24, %rd6, 1512;
	add.s64 	%rd25, %rd4, %rd24;
	mul.wide.u32 	%rd26, %r9, 24;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.v2.f32 	{%f23, %f24}, [%rd27];
	add.rn.f32 	%f25, %f23, 0f00000000;
	add.rn.f32 	%f26, %f25, %f24;
	ld.global.nc.v2.f32 	{%f27, %f28}, [%rd27+8];
	add.rn.f32 	%f29, %f26, %f27;
	add.rn.f32 	%f30, %f29, %f28;
	ld.global.nc.v2.f32 	{%f31, %f32}, [%rd27+16];
	add.rn.f32 	%f33, %f30, %f31;
	add.rn.f32 	%f40, %f33, %f32;
$L__BB277_4:
	cvt.u32.u64 	%r10, %rd6;
	add.rn.f32 	%f34, %f38, %f39;
	shl.b32 	%r11, %r10, 7;
	or.b32  	%r12, %r11, %r1;
	add.rn.f32 	%f35, %f34, %f40;
	shl.b64 	%rd28, %rd6, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.nc.f32 	%f36, [%rd29];
	mul.rn.f32 	%f37, %f35, %f36;
	mul.wide.u32 	%rd30, %r12, 4;
	add.s64 	%rd31, %rd1, %rd30;
	st.global.f32 	[%rd31], %f37;
	ret;

}
	// .globl	loop_multiply_fusion_105
.visible .entry loop_multiply_fusion_105(
	.param .u64 loop_multiply_fusion_105_param_0,
	.param .u64 loop_multiply_fusion_105_param_1,
	.param .u64 loop_multiply_fusion_105_param_2,
	.param .u64 loop_multiply_fusion_105_param_3,
	.param .u64 loop_multiply_fusion_105_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<41>;
	.reg .b64 	%rd<32>;

	ld.param.u64 	%rd10, [loop_multiply_fusion_105_param_1];
	cvta.to.global.u64 	%rd4, %rd10;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	shl.b32 	%r7, %r5, 7;
	or.b32  	%r1, %r7, %r6;
	and.b32  	%r2, %r1, 255;
	shr.u32 	%r8, %r5, 1;
	and.b32  	%r3, %r6, 1;
	setp.eq.s32 	%p1, %r3, 0;
	mov.f32 	%f40, 0f00000000;
	mov.f32 	%f38, %f40;
	@%p1 bra 	$L__BB278_5;
	bra.uni 	$L__BB278_1;
$L__BB278_5:
	bfe.u32 	%r9, %r1, 1, 7;
	mul.wide.u32 	%rd13, %r8, 512;
	add.s64 	%rd14, %rd4, %rd13;
	mul.wide.u32 	%rd15, %r9, 4;
	add.s64 	%rd7, %rd14, %rd15;
	ld.global.nc.f32 	%f38, [%rd7];
$L__BB278_1:
	ld.param.u64 	%rd8, [loop_multiply_fusion_105_param_0];
	ld.param.u64 	%rd9, [loop_multiply_fusion_105_param_4];
	cvt.u64.u32 	%rd6, %r8;
	add.s32 	%r4, %r2, -1;
	and.b32  	%r10, %r4, 1;
	setp.eq.b32 	%p2, %r10, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f32 	%f39, %f40;
	@%p5 bra 	$L__BB278_6;
	bra.uni 	$L__BB278_2;
$L__BB278_6:
	ld.param.u64 	%rd12, [loop_multiply_fusion_105_param_2];
	cvta.to.global.u64 	%rd3, %rd12;
	bfe.u32 	%r11, %r4, 1, 15;
	shl.b64 	%rd16, %rd6, 9;
	add.s64 	%rd17, %rd4, %rd16;
	mul.wide.u32 	%rd18, %r11, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.nc.f32 	%f9, [%rd19];
	mul.lo.s64 	%rd20, %rd6, 3072;
	add.s64 	%rd21, %rd3, %rd20;
	mul.wide.u32 	%rd22, %r11, 24;
	add.s64 	%rd23, %rd21, %rd22;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd23];
	add.rn.f32 	%f12, %f10, 0f00000000;
	add.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.v2.f32 	{%f14, %f15}, [%rd23+8];
	add.rn.f32 	%f16, %f13, %f14;
	add.rn.f32 	%f17, %f16, %f15;
	ld.global.nc.v2.f32 	{%f18, %f19}, [%rd23+16];
	add.rn.f32 	%f20, %f17, %f18;
	add.rn.f32 	%f21, %f20, %f19;
	add.rn.f32 	%f39, %f9, %f21;
$L__BB278_2:
	cvta.to.global.u64 	%rd1, %rd9;
	cvta.to.global.u64 	%rd5, %rd8;
	setp.ne.s32 	%p6, %r3, 0;
	setp.lt.u32 	%p7, %r2, 2;
	or.pred  	%p8, %p6, %p7;
	@%p8 bra 	$L__BB278_4;
	ld.param.u64 	%rd11, [loop_multiply_fusion_105_param_3];
	cvta.to.global.u64 	%rd2, %rd11;
	add.s32 	%r12, %r2, -2;
	shr.u32 	%r13, %r12, 1;
	mul.lo.s64 	%rd24, %rd6, 3048;
	add.s64 	%rd25, %rd2, %rd24;
	mul.wide.u32 	%rd26, %r13, 24;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.v2.f32 	{%f23, %f24}, [%rd27];
	add.rn.f32 	%f25, %f23, 0f00000000;
	add.rn.f32 	%f26, %f25, %f24;
	ld.global.nc.v2.f32 	{%f27, %f28}, [%rd27+8];
	add.rn.f32 	%f29, %f26, %f27;
	add.rn.f32 	%f30, %f29, %f28;
	ld.global.nc.v2.f32 	{%f31, %f32}, [%rd27+16];
	add.rn.f32 	%f33, %f30, %f31;
	add.rn.f32 	%f40, %f33, %f32;
$L__BB278_4:
	add.rn.f32 	%f34, %f38, %f39;
	add.rn.f32 	%f35, %f34, %f40;
	shl.b64 	%rd28, %rd6, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.nc.f32 	%f36, [%rd29];
	mul.rn.f32 	%f37, %f35, %f36;
	mul.wide.u32 	%rd30, %r1, 4;
	add.s64 	%rd31, %rd1, %rd30;
	st.global.f32 	[%rd31], %f37;
	ret;

}
	// .globl	loop_multiply_fusion_106
.visible .entry loop_multiply_fusion_106(
	.param .u64 loop_multiply_fusion_106_param_0,
	.param .u64 loop_multiply_fusion_106_param_1,
	.param .u64 loop_multiply_fusion_106_param_2,
	.param .u64 loop_multiply_fusion_106_param_3,
	.param .u64 loop_multiply_fusion_106_param_4
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<41>;
	.reg .b64 	%rd<32>;

	ld.param.u64 	%rd10, [loop_multiply_fusion_106_param_1];
	cvta.to.global.u64 	%rd4, %rd10;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	shl.b32 	%r7, %r5, 7;
	or.b32  	%r1, %r7, %r6;
	and.b32  	%r2, %r1, 511;
	shr.u32 	%r8, %r5, 2;
	and.b32  	%r3, %r6, 1;
	setp.eq.s32 	%p1, %r3, 0;
	mov.f32 	%f40, 0f00000000;
	mov.f32 	%f38, %f40;
	@%p1 bra 	$L__BB279_5;
	bra.uni 	$L__BB279_1;
$L__BB279_5:
	bfe.u32 	%r9, %r1, 1, 8;
	mul.wide.u32 	%rd13, %r8, 1024;
	add.s64 	%rd14, %rd4, %rd13;
	mul.wide.u32 	%rd15, %r9, 4;
	add.s64 	%rd7, %rd14, %rd15;
	ld.global.nc.f32 	%f38, [%rd7];
$L__BB279_1:
	ld.param.u64 	%rd8, [loop_multiply_fusion_106_param_0];
	ld.param.u64 	%rd9, [loop_multiply_fusion_106_param_4];
	cvt.u64.u32 	%rd6, %r8;
	add.s32 	%r4, %r2, -1;
	and.b32  	%r10, %r4, 1;
	setp.eq.b32 	%p2, %r10, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f32 	%f39, %f40;
	@%p5 bra 	$L__BB279_6;
	bra.uni 	$L__BB279_2;
$L__BB279_6:
	ld.param.u64 	%rd12, [loop_multiply_fusion_106_param_2];
	cvta.to.global.u64 	%rd3, %rd12;
	bfe.u32 	%r11, %r4, 1, 15;
	shl.b64 	%rd16, %rd6, 10;
	add.s64 	%rd17, %rd4, %rd16;
	mul.wide.u32 	%rd18, %r11, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.nc.f32 	%f9, [%rd19];
	mul.lo.s64 	%rd20, %rd6, 6144;
	add.s64 	%rd21, %rd3, %rd20;
	mul.wide.u32 	%rd22, %r11, 24;
	add.s64 	%rd23, %rd21, %rd22;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd23];
	add.rn.f32 	%f12, %f10, 0f00000000;
	add.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.v2.f32 	{%f14, %f15}, [%rd23+8];
	add.rn.f32 	%f16, %f13, %f14;
	add.rn.f32 	%f17, %f16, %f15;
	ld.global.nc.v2.f32 	{%f18, %f19}, [%rd23+16];
	add.rn.f32 	%f20, %f17, %f18;
	add.rn.f32 	%f21, %f20, %f19;
	add.rn.f32 	%f39, %f9, %f21;
$L__BB279_2:
	cvta.to.global.u64 	%rd1, %rd9;
	cvta.to.global.u64 	%rd5, %rd8;
	setp.ne.s32 	%p6, %r3, 0;
	setp.lt.u32 	%p7, %r2, 2;
	or.pred  	%p8, %p6, %p7;
	@%p8 bra 	$L__BB279_4;
	ld.param.u64 	%rd11, [loop_multiply_fusion_106_param_3];
	cvta.to.global.u64 	%rd2, %rd11;
	add.s32 	%r12, %r2, -2;
	shr.u32 	%r13, %r12, 1;
	mul.lo.s64 	%rd24, %rd6, 6120;
	add.s64 	%rd25, %rd2, %rd24;
	mul.wide.u32 	%rd26, %r13, 24;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.v2.f32 	{%f23, %f24}, [%rd27];
	add.rn.f32 	%f25, %f23, 0f00000000;
	add.rn.f32 	%f26, %f25, %f24;
	ld.global.nc.v2.f32 	{%f27, %f28}, [%rd27+8];
	add.rn.f32 	%f29, %f26, %f27;
	add.rn.f32 	%f30, %f29, %f28;
	ld.global.nc.v2.f32 	{%f31, %f32}, [%rd27+16];
	add.rn.f32 	%f33, %f30, %f31;
	add.rn.f32 	%f40, %f33, %f32;
$L__BB279_4:
	add.rn.f32 	%f34, %f38, %f39;
	add.rn.f32 	%f35, %f34, %f40;
	shl.b64 	%rd28, %rd6, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.nc.f32 	%f36, [%rd29];
	mul.rn.f32 	%f37, %f35, %f36;
	mul.wide.u32 	%rd30, %r1, 4;
	add.s64 	%rd31, %rd1, %rd30;
	st.global.f32 	[%rd31], %f37;
	ret;

}
	// .globl	loop_add_fusion_383
.visible .entry loop_add_fusion_383(
	.param .u64 loop_add_fusion_383_param_0,
	.param .u64 loop_add_fusion_383_param_1,
	.param .u64 loop_add_fusion_383_param_2,
	.param .u64 loop_add_fusion_383_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<39>;
	.reg .b64 	%rd<28>;

	ld.param.u64 	%rd7, [loop_add_fusion_383_param_0];
	cvta.to.global.u64 	%rd4, %rd7;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	shl.b32 	%r7, %r5, 7;
	or.b32  	%r1, %r7, %r6;
	and.b32  	%r2, %r1, 1023;
	shr.u32 	%r8, %r5, 3;
	and.b32  	%r3, %r6, 1;
	setp.eq.s32 	%p1, %r3, 0;
	mov.f32 	%f38, 0f00000000;
	mov.f32 	%f36, %f38;
	@%p1 bra 	$L__BB280_5;
	bra.uni 	$L__BB280_1;
$L__BB280_5:
	bfe.u32 	%r9, %r1, 1, 9;
	mul.wide.u32 	%rd11, %r8, 2048;
	add.s64 	%rd12, %rd4, %rd11;
	mul.wide.u32 	%rd13, %r9, 4;
	add.s64 	%rd6, %rd12, %rd13;
	ld.global.nc.f32 	%f36, [%rd6];
$L__BB280_1:
	ld.param.u64 	%rd8, [loop_add_fusion_383_param_3];
	cvt.u64.u32 	%rd5, %r8;
	add.s32 	%r4, %r2, -1;
	and.b32  	%r10, %r4, 1;
	setp.eq.b32 	%p2, %r10, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f32 	%f37, %f38;
	@%p5 bra 	$L__BB280_6;
	bra.uni 	$L__BB280_2;
$L__BB280_6:
	ld.param.u64 	%rd10, [loop_add_fusion_383_param_2];
	cvta.to.global.u64 	%rd2, %rd10;
	bfe.u32 	%r11, %r4, 1, 15;
	shl.b64 	%rd14, %rd5, 11;
	add.s64 	%rd15, %rd4, %rd14;
	mul.wide.u32 	%rd16, %r11, 4;
	add.s64 	%rd17, %rd15, %rd16;
	ld.global.nc.f32 	%f9, [%rd17];
	mul.lo.s64 	%rd18, %rd5, 12288;
	add.s64 	%rd19, %rd2, %rd18;
	mul.wide.u32 	%rd20, %r11, 24;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd21];
	add.rn.f32 	%f12, %f10, 0f00000000;
	add.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.v2.f32 	{%f14, %f15}, [%rd21+8];
	add.rn.f32 	%f16, %f13, %f14;
	add.rn.f32 	%f17, %f16, %f15;
	ld.global.nc.v2.f32 	{%f18, %f19}, [%rd21+16];
	add.rn.f32 	%f20, %f17, %f18;
	add.rn.f32 	%f21, %f20, %f19;
	add.rn.f32 	%f37, %f9, %f21;
$L__BB280_2:
	cvta.to.global.u64 	%rd1, %rd8;
	setp.ne.s32 	%p6, %r3, 0;
	setp.lt.u32 	%p7, %r2, 2;
	or.pred  	%p8, %p6, %p7;
	@%p8 bra 	$L__BB280_4;
	ld.param.u64 	%rd9, [loop_add_fusion_383_param_1];
	cvta.to.global.u64 	%rd3, %rd9;
	add.s32 	%r12, %r2, -2;
	shr.u32 	%r13, %r12, 1;
	mul.lo.s64 	%rd22, %rd5, 12264;
	add.s64 	%rd23, %rd3, %rd22;
	mul.wide.u32 	%rd24, %r13, 24;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.nc.v2.f32 	{%f23, %f24}, [%rd25];
	add.rn.f32 	%f25, %f23, 0f00000000;
	add.rn.f32 	%f26, %f25, %f24;
	ld.global.nc.v2.f32 	{%f27, %f28}, [%rd25+8];
	add.rn.f32 	%f29, %f26, %f27;
	add.rn.f32 	%f30, %f29, %f28;
	ld.global.nc.v2.f32 	{%f31, %f32}, [%rd25+16];
	add.rn.f32 	%f33, %f30, %f31;
	add.rn.f32 	%f38, %f33, %f32;
$L__BB280_4:
	add.rn.f32 	%f34, %f36, %f37;
	add.rn.f32 	%f35, %f34, %f38;
	mul.wide.u32 	%rd26, %r1, 4;
	add.s64 	%rd27, %rd1, %rd26;
	st.global.f32 	[%rd27], %f35;
	ret;

}
	// .globl	input_reduce_fusion_346
.visible .entry input_reduce_fusion_346(
	.param .u64 input_reduce_fusion_346_param_0,
	.param .u64 input_reduce_fusion_346_param_1
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<15>;
	.reg .b32 	%r<15>;
	.reg .f32 	%f<82>;
	.reg .b64 	%rd<31>;
	// demoted variable
	.shared .align 4 .b8 shared_cache54[32];
	ld.param.u64 	%rd7, [input_reduce_fusion_346_param_0];
	cvta.to.global.u64 	%rd9, %rd7;
	mov.u32 	%r3, %tid.x;
	mov.u32 	%r4, %ctaid.x;
	shr.u32 	%r5, %r3, 6;
	and.b32  	%r1, %r3, 63;
	and.b32  	%r2, %r3, 31;
	shl.b32 	%r6, %r4, 2;
	or.b32  	%r7, %r5, %r6;
	shl.b32 	%r8, %r1, 1;
	mul.wide.u32 	%rd10, %r7, 4096;
	add.s64 	%rd11, %rd9, %rd10;
	mul.wide.u32 	%rd12, %r8, 4;
	add.s64 	%rd13, %rd11, %rd12;
	ld.global.nc.v2.f32 	{%f28, %f29}, [%rd13];
	add.rn.f32 	%f30, %f28, 0f00000000;
	add.rn.f32 	%f31, %f30, %f29;
	ld.global.nc.v2.f32 	{%f32, %f33}, [%rd13+512];
	add.rn.f32 	%f34, %f31, %f32;
	add.rn.f32 	%f35, %f34, %f33;
	ld.global.nc.v2.f32 	{%f36, %f37}, [%rd13+1024];
	add.rn.f32 	%f38, %f35, %f36;
	add.rn.f32 	%f39, %f38, %f37;
	shl.b32 	%r9, %r3, 1;
	or.b32  	%r10, %r9, 384;
	mul.wide.u32 	%rd14, %r10, 4;
	add.s64 	%rd15, %rd11, %rd14;
	ld.global.nc.f32 	%f40, [%rd15];
	add.rn.f32 	%f41, %f39, %f40;
	or.b32  	%r11, %r9, 385;
	mul.wide.u32 	%rd16, %r11, 4;
	add.s64 	%rd17, %rd11, %rd16;
	ld.global.nc.f32 	%f42, [%rd17];
	add.rn.f32 	%f43, %f41, %f42;
	ld.global.nc.v2.f32 	{%f44, %f45}, [%rd13+2048];
	add.rn.f32 	%f46, %f43, %f44;
	add.rn.f32 	%f47, %f46, %f45;
	ld.global.nc.v2.f32 	{%f48, %f49}, [%rd13+2560];
	add.rn.f32 	%f50, %f47, %f48;
	add.rn.f32 	%f51, %f50, %f49;
	ld.global.nc.v2.f32 	{%f52, %f53}, [%rd13+3072];
	add.rn.f32 	%f54, %f51, %f52;
	add.rn.f32 	%f55, %f54, %f53;
	or.b32  	%r12, %r9, 896;
	mul.wide.u32 	%rd18, %r12, 4;
	add.s64 	%rd19, %rd11, %rd18;
	ld.global.nc.f32 	%f56, [%rd19];
	add.rn.f32 	%f57, %f55, %f56;
	or.b32  	%r13, %r9, 897;
	mul.wide.u32 	%rd20, %r13, 4;
	add.s64 	%rd21, %rd11, %rd20;
	ld.global.nc.f32 	%f58, [%rd21];
	add.rn.f32 	%f59, %f57, %f58;
	shfl.sync.down.b32	%f60, %f59, 16, 31, -1;
	add.rn.f32 	%f61, %f59, %f60;
	shfl.sync.down.b32	%f62, %f61, 8, 31, -1;
	add.rn.f32 	%f63, %f61, %f62;
	shfl.sync.down.b32	%f64, %f63, 4, 31, -1;
	add.rn.f32 	%f65, %f63, %f64;
	shfl.sync.down.b32	%f66, %f65, 2, 31, -1;
	add.rn.f32 	%f67, %f65, %f66;
	shfl.sync.down.b32	%f68, %f67, 1, 31, -1;
	setp.eq.s32 	%p1, %r2, 0;
	mov.u64 	%rd23, shared_cache54;
	@%p1 bra 	$L__BB281_3;
	bra.uni 	$L__BB281_1;
$L__BB281_3:
	bfe.u32 	%r14, %r3, 5, 1;
	mul.wide.u32 	%rd22, %r5, 8;
	add.s64 	%rd24, %rd23, %rd22;
	mul.wide.u32 	%rd25, %r14, 4;
	add.s64 	%rd4, %rd24, %rd25;
	add.rn.f32 	%f1, %f67, %f68;
	st.shared.f32 	[%rd4], %f1;
$L__BB281_1:
	bar.sync 	0;
	setp.lt.u32 	%p2, %r1, 32;
	@%p2 bra 	$L__BB281_4;
	bra.uni 	$L__BB281_2;
$L__BB281_4:
	cvt.u64.u32 	%rd3, %r5;
	shl.b64 	%rd26, %rd3, 3;
	add.s64 	%rd28, %rd23, %rd26;
	mul.wide.u32 	%rd29, %r2, 4;
	add.s64 	%rd5, %rd28, %rd29;
	setp.gt.u32 	%p3, %r1, 1;
	mov.f32 	%f73, 0f00000000;
	mov.f32 	%f72, %f73;
	@%p3 bra 	$L__BB281_6;
	ld.shared.f32 	%f72, [%rd5];
$L__BB281_6:
	shfl.sync.down.b32	%f4, %f72, 16, 31, -1;
	@%p3 bra 	$L__BB281_8;
	ld.shared.f32 	%f73, [%rd5];
$L__BB281_8:
	add.rn.f32 	%f7, %f4, %f73;
	mov.f32 	%f74, %f7;
	@%p3 bra 	$L__BB281_10;
	st.shared.f32 	[%rd5], %f7;
	mov.f32 	%f74, 0f00000000;
$L__BB281_10:
	shfl.sync.down.b32	%f9, %f7, 8, 31, -1;
	mov.f32 	%f75, %f74;
	@%p3 bra 	$L__BB281_12;
	ld.shared.f32 	%f75, [%rd5];
$L__BB281_12:
	add.rn.f32 	%f12, %f9, %f75;
	mov.f32 	%f76, %f12;
	@%p3 bra 	$L__BB281_14;
	st.shared.f32 	[%rd5], %f12;
	mov.f32 	%f76, %f74;
$L__BB281_14:
	shfl.sync.down.b32	%f14, %f12, 4, 31, -1;
	mov.f32 	%f77, %f76;
	@%p3 bra 	$L__BB281_16;
	ld.shared.f32 	%f77, [%rd5];
$L__BB281_16:
	add.rn.f32 	%f17, %f14, %f77;
	mov.f32 	%f78, %f17;
	@%p3 bra 	$L__BB281_18;
	st.shared.f32 	[%rd5], %f17;
	mov.f32 	%f78, %f76;
$L__BB281_18:
	shfl.sync.down.b32	%f19, %f17, 2, 31, -1;
	mov.f32 	%f79, %f78;
	@%p3 bra 	$L__BB281_20;
	ld.shared.f32 	%f79, [%rd5];
$L__BB281_20:
	add.rn.f32 	%f22, %f19, %f79;
	mov.f32 	%f81, %f22;
	@%p3 bra 	$L__BB281_22;
	st.shared.f32 	[%rd5], %f22;
	mov.f32 	%f81, %f78;
$L__BB281_22:
	shfl.sync.down.b32	%f24, %f22, 1, 31, -1;
	@%p3 bra 	$L__BB281_24;
	ld.shared.f32 	%f81, [%rd5];
$L__BB281_24:
	add.rn.f32 	%f27, %f24, %f81;
	@%p3 bra 	$L__BB281_26;
	st.shared.f32 	[%rd5], %f27;
$L__BB281_26:
	setp.ne.s32 	%p14, %r1, 0;
	@%p14 bra 	$L__BB281_2;
	ld.param.u64 	%rd8, [input_reduce_fusion_346_param_1];
	cvta.to.global.u64 	%rd1, %rd8;
	cvt.u64.u32 	%rd2, %r7;
	shl.b64 	%rd30, %rd2, 2;
	add.s64 	%rd6, %rd1, %rd30;
	st.global.f32 	[%rd6], %f27;
$L__BB281_2:
	ret;

}
	// .globl	input_add_multiply_reduce_fusion_6
.visible .entry input_add_multiply_reduce_fusion_6(
	.param .u64 input_add_multiply_reduce_fusion_6_param_0,
	.param .u64 input_add_multiply_reduce_fusion_6_param_1,
	.param .u64 input_add_multiply_reduce_fusion_6_param_2,
	.param .u64 input_add_multiply_reduce_fusion_6_param_3,
	.param .u64 input_add_multiply_reduce_fusion_6_param_4,
	.param .u64 input_add_multiply_reduce_fusion_6_param_5,
	.param .u64 input_add_multiply_reduce_fusion_6_param_6
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<43>;
	.reg .f32 	%f<52>;
	.reg .b64 	%rd<116>;
	// demoted variable
	.shared .align 4 .b8 shared_cache55[4224];
	ld.param.u64 	%rd18, [input_add_multiply_reduce_fusion_6_param_0];
	ld.param.u64 	%rd19, [input_add_multiply_reduce_fusion_6_param_6];
	cvta.to.global.u64 	%rd1, %rd19;
	ld.param.u64 	%rd20, [input_add_multiply_reduce_fusion_6_param_1];
	ld.param.u64 	%rd21, [input_add_multiply_reduce_fusion_6_param_5];
	cvta.to.global.u64 	%rd2, %rd21;
	ld.param.u64 	%rd22, [input_add_multiply_reduce_fusion_6_param_2];
	ld.param.u64 	%rd23, [input_add_multiply_reduce_fusion_6_param_4];
	ld.param.u64 	%rd24, [input_add_multiply_reduce_fusion_6_param_3];
	cvta.to.global.u64 	%rd25, %rd24;
	cvta.to.global.u64 	%rd26, %rd22;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	mov.u32 	%r12, %tid.x;
	mov.u32 	%r13, %ctaid.x;
	shr.u32 	%r1, %r12, 5;
	and.b32  	%r2, %r12, 31;
	shr.u32 	%r3, %r13, 4;
	shl.b32 	%r14, %r13, 5;
	and.b32  	%r4, %r14, 480;
	or.b32  	%r15, %r4, %r2;
	mul.lo.s32 	%r5, %r3, 400;
	cvt.u64.u32 	%rd6, %r15;
	mul.wide.u32 	%rd27, %r15, 4;
	add.s64 	%rd28, %rd26, %rd27;
	ld.global.nc.f32 	%f1, [%rd28];
	add.s64 	%rd29, %rd25, %rd27;
	ld.global.nc.f32 	%f2, [%rd29];
	mov.b32 	%r16, 399;
	sub.s32 	%r17, %r16, %r1;
	shr.u32 	%r6, %r17, 5;
	add.s32 	%r18, %r6, 1;
	and.b32  	%r19, %r18, 3;
	setp.eq.s32 	%p1, %r19, 0;
	mov.f32 	%f50, 0f00000000;
	shl.b64 	%rd113, %rd6, 2;
	mov.u32 	%r41, %r1;
	@%p1 bra 	$L__BB282_3;
	cvt.u16.u32 	%rs1, %r3;
	mul.lo.s16 	%rs2, %rs1, 400;
	cvt.u16.u32 	%rs3, %r1;
	add.s16 	%rs4, %rs2, %rs3;
	cvt.u32.u16 	%r20, %rs4;
	and.b32  	%r21, %r20, 1023;
	mul.wide.u32 	%rd31, %r21, 2048;
	or.b64  	%rd33, %rd31, %rd113;
	add.s64 	%rd7, %rd5, %rd33;
	add.s32 	%r22, %r1, %r5;
	cvt.u64.u32 	%rd115, %r22;
	add.s64 	%rd9, %rd4, %rd33;
	add.s64 	%rd10, %rd1, %rd33;
	add.s64 	%rd11, %rd2, %rd33;
	cvt.u16.u32 	%rs5, %r6;
	add.s16 	%rs6, %rs5, 1;
	cvt.u32.u16 	%r23, %rs6;
	and.b32  	%r24, %r23, 3;
	mul.wide.u32 	%rd12, %r24, 65536;
	mov.f32 	%f50, 0f00000000;
	mov.u64 	%rd114, 0;
	mov.u32 	%r41, %r1;
$L__BB282_2:
	.pragma "nounroll";
	add.s32 	%r41, %r41, 32;
	shl.b64 	%rd34, %rd115, 11;
	and.b64  	%rd35, %rd34, -2097152;
	add.s64 	%rd36, %rd7, %rd35;
	add.s64 	%rd37, %rd9, %rd35;
	add.s64 	%rd38, %rd10, %rd35;
	add.s64 	%rd39, %rd11, %rd35;
	add.s64 	%rd40, %rd36, %rd114;
	ld.global.nc.f32 	%f11, [%rd40];
	add.s64 	%rd41, %rd37, %rd114;
	ld.global.nc.f32 	%f12, [%rd41];
	add.rn.f32 	%f13, %f12, %f1;
	mul.rn.f32 	%f14, %f11, %f13;
	add.rn.f32 	%f50, %f50, %f14;
	mul.rn.f32 	%f15, %f11, %f2;
	add.s64 	%rd42, %rd38, %rd114;
	st.global.f32 	[%rd42], %f13;
	add.s64 	%rd43, %rd39, %rd114;
	st.global.f32 	[%rd43], %f15;
	add.s64 	%rd115, %rd115, 32;
	add.s64 	%rd114, %rd114, 65536;
	cvt.u32.u64 	%r25, %rd114;
	cvt.u32.u64 	%r26, %rd12;
	setp.ne.s32 	%p2, %r26, %r25;
	@%p2 bra 	$L__BB282_2;
$L__BB282_3:
	cvta.to.global.u64 	%rd3, %rd23;
$L__BB282_4:
	add.s32 	%r27, %r5, %r41;
	and.b32  	%r28, %r27, 1023;
	shr.u32 	%r29, %r27, 10;
	mul.wide.u32 	%rd44, %r29, 2097152;
	add.s64 	%rd45, %rd5, %rd44;
	mul.wide.u32 	%rd46, %r28, 2048;
	add.s64 	%rd47, %rd45, %rd46;
	add.s64 	%rd49, %rd47, %rd113;
	ld.global.nc.f32 	%f16, [%rd49];
	add.s64 	%rd50, %rd4, %rd44;
	add.s64 	%rd51, %rd50, %rd46;
	add.s64 	%rd52, %rd51, %rd113;
	ld.global.nc.f32 	%f17, [%rd52];
	add.rn.f32 	%f18, %f17, %f1;
	mul.rn.f32 	%f19, %f16, %f18;
	add.rn.f32 	%f20, %f50, %f19;
	mul.rn.f32 	%f21, %f16, %f2;
	add.s64 	%rd53, %rd1, %rd44;
	add.s64 	%rd54, %rd53, %rd46;
	add.s64 	%rd55, %rd54, %rd113;
	st.global.f32 	[%rd55], %f18;
	add.s64 	%rd56, %rd2, %rd44;
	add.s64 	%rd57, %rd56, %rd46;
	add.s64 	%rd58, %rd57, %rd113;
	st.global.f32 	[%rd58], %f21;
	add.s32 	%r30, %r27, 32;
	and.b32  	%r31, %r30, 1023;
	shr.u32 	%r32, %r30, 10;
	mul.wide.u32 	%rd59, %r32, 2097152;
	add.s64 	%rd60, %rd5, %rd59;
	mul.wide.u32 	%rd61, %r31, 2048;
	add.s64 	%rd62, %rd60, %rd61;
	add.s64 	%rd63, %rd62, %rd113;
	ld.global.nc.f32 	%f22, [%rd63];
	add.s64 	%rd64, %rd4, %rd59;
	add.s64 	%rd65, %rd64, %rd61;
	add.s64 	%rd66, %rd65, %rd113;
	ld.global.nc.f32 	%f23, [%rd66];
	add.rn.f32 	%f24, %f23, %f1;
	mul.rn.f32 	%f25, %f22, %f24;
	add.rn.f32 	%f26, %f20, %f25;
	mul.rn.f32 	%f27, %f22, %f2;
	add.s64 	%rd67, %rd1, %rd59;
	add.s64 	%rd68, %rd67, %rd61;
	add.s64 	%rd69, %rd68, %rd113;
	st.global.f32 	[%rd69], %f24;
	add.s64 	%rd70, %rd2, %rd59;
	add.s64 	%rd71, %rd70, %rd61;
	add.s64 	%rd72, %rd71, %rd113;
	st.global.f32 	[%rd72], %f27;
	add.s32 	%r33, %r27, 64;
	and.b32  	%r34, %r33, 1023;
	shr.u32 	%r35, %r33, 10;
	mul.wide.u32 	%rd73, %r35, 2097152;
	add.s64 	%rd74, %rd5, %rd73;
	mul.wide.u32 	%rd75, %r34, 2048;
	add.s64 	%rd76, %rd74, %rd75;
	add.s64 	%rd77, %rd76, %rd113;
	ld.global.nc.f32 	%f28, [%rd77];
	add.s64 	%rd78, %rd4, %rd73;
	add.s64 	%rd79, %rd78, %rd75;
	add.s64 	%rd80, %rd79, %rd113;
	ld.global.nc.f32 	%f29, [%rd80];
	add.rn.f32 	%f30, %f29, %f1;
	mul.rn.f32 	%f31, %f28, %f30;
	add.rn.f32 	%f32, %f26, %f31;
	mul.rn.f32 	%f33, %f28, %f2;
	add.s64 	%rd81, %rd1, %rd73;
	add.s64 	%rd82, %rd81, %rd75;
	add.s64 	%rd83, %rd82, %rd113;
	st.global.f32 	[%rd83], %f30;
	add.s64 	%rd84, %rd2, %rd73;
	add.s64 	%rd85, %rd84, %rd75;
	add.s64 	%rd86, %rd85, %rd113;
	st.global.f32 	[%rd86], %f33;
	add.s32 	%r11, %r41, 128;
	add.s32 	%r36, %r27, 96;
	and.b32  	%r37, %r36, 1023;
	shr.u32 	%r38, %r36, 10;
	mul.wide.u32 	%rd87, %r38, 2097152;
	add.s64 	%rd88, %rd5, %rd87;
	mul.wide.u32 	%rd89, %r37, 2048;
	add.s64 	%rd90, %rd88, %rd89;
	add.s64 	%rd91, %rd90, %rd113;
	ld.global.nc.f32 	%f34, [%rd91];
	add.s64 	%rd92, %rd4, %rd87;
	add.s64 	%rd93, %rd92, %rd89;
	add.s64 	%rd94, %rd93, %rd113;
	ld.global.nc.f32 	%f35, [%rd94];
	add.rn.f32 	%f36, %f35, %f1;
	mul.rn.f32 	%f37, %f34, %f36;
	add.rn.f32 	%f50, %f32, %f37;
	mul.rn.f32 	%f38, %f34, %f2;
	add.s64 	%rd95, %rd1, %rd87;
	add.s64 	%rd96, %rd95, %rd89;
	add.s64 	%rd97, %rd96, %rd113;
	st.global.f32 	[%rd97], %f36;
	add.s64 	%rd98, %rd2, %rd87;
	add.s64 	%rd99, %rd98, %rd89;
	add.s64 	%rd100, %rd99, %rd113;
	st.global.f32 	[%rd100], %f38;
	setp.lt.u32 	%p3, %r41, 272;
	mov.u32 	%r41, %r11;
	@%p3 bra 	$L__BB282_4;
	mul.wide.u32 	%rd101, %r2, 132;
	mov.u64 	%rd102, shared_cache55;
	add.s64 	%rd103, %rd102, %rd101;
	mul.wide.u32 	%rd104, %r1, 4;
	add.s64 	%rd105, %rd103, %rd104;
	st.shared.f32 	[%rd105], %f50;
	bar.sync 	0;
	mul.wide.u32 	%rd106, %r1, 132;
	add.s64 	%rd107, %rd102, %rd106;
	mul.wide.u32 	%rd108, %r2, 4;
	add.s64 	%rd109, %rd107, %rd108;
	ld.shared.f32 	%f39, [%rd109];
	shfl.sync.down.b32	%f40, %f39, 16, 31, -1;
	add.rn.f32 	%f41, %f39, %f40;
	shfl.sync.down.b32	%f42, %f41, 8, 31, -1;
	add.rn.f32 	%f43, %f41, %f42;
	shfl.sync.down.b32	%f44, %f43, 4, 31, -1;
	add.rn.f32 	%f45, %f43, %f44;
	shfl.sync.down.b32	%f46, %f45, 2, 31, -1;
	add.rn.f32 	%f47, %f45, %f46;
	shfl.sync.down.b32	%f48, %f47, 1, 31, -1;
	add.rn.f32 	%f8, %f47, %f48;
	st.shared.f32 	[%rd109], %f8;
	setp.ne.s32 	%p4, %r2, 0;
	@%p4 bra 	$L__BB282_7;
	or.b32  	%r39, %r4, %r1;
	mul.wide.u32 	%rd110, %r3, 2048;
	add.s64 	%rd111, %rd3, %rd110;
	mul.wide.u32 	%rd112, %r39, 4;
	add.s64 	%rd17, %rd111, %rd112;
	st.global.f32 	[%rd17], %f8;
$L__BB282_7:
	ret;

}
	// .globl	loop_transpose_fusion_116
.visible .entry loop_transpose_fusion_116(
	.param .u64 loop_transpose_fusion_116_param_0,
	.param .u64 loop_transpose_fusion_116_param_1,
	.param .u64 loop_transpose_fusion_116_param_2,
	.param .u64 loop_transpose_fusion_116_param_3,
	.param .u64 loop_transpose_fusion_116_param_4
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<10>;
	.reg .f32 	%f<28>;
	.reg .b64 	%rd<28>;

	ld.param.u64 	%rd1, [loop_transpose_fusion_116_param_0];
	ld.param.u64 	%rd2, [loop_transpose_fusion_116_param_4];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_transpose_fusion_116_param_1];
	ld.param.u64 	%rd5, [loop_transpose_fusion_116_param_3];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_transpose_fusion_116_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	cvta.to.global.u64 	%rd9, %rd4;
	cvta.to.global.u64 	%rd10, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	cvt.u16.u32 	%rs1, %r1;
	shr.u16 	%rs2, %rs1, 7;
	mul.hi.u16 	%rs3, %rs2, 2622;
	shr.u16 	%rs4, %rs1, 1;
	mul.hi.u16 	%rs5, %rs4, 5243;
	shr.u16 	%rs6, %rs5, 1;
	and.b16  	%rs7, %rs6, 63;
	mul.lo.s16 	%rs8, %rs6, 50;
	sub.s16 	%rs9, %rs1, %rs8;
	shl.b16 	%rs10, %rs3, 1;
	cvt.u32.u16 	%r6, %rs7;
	mul.wide.u32 	%rd11, %r6, 12;
	add.s64 	%rd12, %rd8, %rd11;
	cvt.u32.u16 	%r7, %rs3;
	mul.wide.u32 	%rd13, %r7, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	mul.wide.u32 	%rd15, %r6, 4;
	add.s64 	%rd16, %rd9, %rd15;
	ld.global.nc.f32 	%f2, [%rd16];
	mul.wide.u32 	%rd17, %r6, 614400;
	add.s64 	%rd18, %rd10, %rd17;
	cvt.u32.u16 	%r8, %rs9;
	mul.wide.u32 	%rd19, %r8, 12288;
	add.s64 	%rd20, %rd18, %rd19;
	mul.wide.u32 	%rd21, %r4, 24;
	add.s64 	%rd22, %rd20, %rd21;
	cvt.u32.u16 	%r9, %rs10;
	mul.wide.u32 	%rd23, %r9, 4;
	add.s64 	%rd24, %rd22, %rd23;
	ld.global.nc.v2.f32 	{%f3, %f4}, [%rd24];
	mul.rn.f32 	%f5, %f2, %f4;
	mul.rn.f32 	%f6, %f1, %f5;
	mul.rn.f32 	%f7, %f2, %f3;
	neg.f32 	%f8, %f1;
	mul.rn.f32 	%f9, %f7, %f8;
	mul.wide.u32 	%rd25, %r5, 4;
	add.s64 	%rd26, %rd6, %rd25;
	add.s64 	%rd27, %rd3, %rd25;
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd24+24];
	mul.rn.f32 	%f12, %f2, %f11;
	mul.rn.f32 	%f13, %f1, %f12;
	mul.rn.f32 	%f14, %f2, %f10;
	mul.rn.f32 	%f15, %f14, %f8;
	ld.global.nc.v2.f32 	{%f16, %f17}, [%rd24+48];
	mul.rn.f32 	%f18, %f2, %f17;
	mul.rn.f32 	%f19, %f1, %f18;
	mul.rn.f32 	%f20, %f2, %f16;
	mul.rn.f32 	%f21, %f20, %f8;
	ld.global.nc.v2.f32 	{%f22, %f23}, [%rd24+72];
	mul.rn.f32 	%f24, %f2, %f23;
	mul.rn.f32 	%f25, %f1, %f24;
	mul.rn.f32 	%f26, %f2, %f22;
	mul.rn.f32 	%f27, %f26, %f8;
	st.global.v4.f32 	[%rd26], {%f6, %f13, %f19, %f25};
	st.global.v4.f32 	[%rd27], {%f9, %f15, %f21, %f27};
	ret;

}
	// .globl	loop_broadcast_fusion_45
.visible .entry loop_broadcast_fusion_45(
	.param .u64 loop_broadcast_fusion_45_param_0
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd2, [loop_broadcast_fusion_45_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 9;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	mul.wide.u32 	%rd4, %r1, 4;
	add.s64 	%rd1, %rd3, %rd4;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd1], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+3538944], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+7077888], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+10616832], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+14155776], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+17694720], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+21233664], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+24772608], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+28311552], {%f1, %f1, %f1, %f1};
	st.global.v4.f32 	[%rd1+31850496], {%f1, %f1, %f1, %f1};
	setp.gt.u32 	%p1, %r1, 983039;
	@%p1 bra 	$L__BB284_2;
	st.global.v4.f32 	[%rd1+35389440], {%f1, %f1, %f1, %f1};
$L__BB284_2:
	setp.gt.u32 	%p2, %r1, 98303;
	@%p2 bra 	$L__BB284_4;
	st.global.v4.f32 	[%rd1+38928384], {%f1, %f1, %f1, %f1};
$L__BB284_4:
	ret;

}
	// .globl	input_scatter_fusion_264
.visible .entry input_scatter_fusion_264(
	.param .u64 input_scatter_fusion_264_param_0,
	.param .u64 input_scatter_fusion_264_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<15>;
	.reg .b32 	%r<10>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_264_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_264_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r4, 511;
	shr.u32 	%r6, %r1, 2;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r1;
	shr.u16 	%rs8, %rs7, 3;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	and.b16  	%rs11, %rs10, 63;
	shr.u16 	%rs12, %rs7, 9;
	mul.hi.u16 	%rs13, %rs12, 2622;
	shl.b16 	%rs14, %rs13, 1;
	cvt.u32.u16 	%r7, %rs14;
	mul.wide.u32 	%rd5, %r7, 6553600;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r8, %rs11;
	mul.wide.u32 	%rd7, %r8, 102400;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r9, %rs6;
	mul.wide.u32 	%rd9, %r9, 2048;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12+6553600];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12+6553600], %f3;
	ret;

}
	// .globl	wrapped_transpose_270
.visible .entry wrapped_transpose_270(
	.param .u64 wrapped_transpose_270_param_0,
	.param .u64 wrapped_transpose_270_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<26>;
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<32>;

	ld.param.u64 	%rd1, [wrapped_transpose_270_param_0];
	ld.param.u64 	%rd2, [wrapped_transpose_270_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	cvt.u16.u32 	%rs1, %r1;
	shr.u16 	%rs2, %rs1, 2;
	mul.hi.u16 	%rs3, %rs2, 27963;
	shr.u16 	%rs4, %rs3, 5;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	or.b32  	%r6, %r5, 3;
	mul.hi.u16 	%rs5, %rs1, -21845;
	shr.u16 	%rs6, %rs5, 2;
	mul.hi.u16 	%rs7, %rs6, 5243;
	shr.u16 	%rs8, %rs7, 2;
	mul.lo.s16 	%rs9, %rs8, 50;
	sub.s16 	%rs10, %rs6, %rs9;
	mul.hi.u32 	%r7, %r6, 715827883;
	and.b32  	%r8, %r7, 511;
	mul.lo.s32 	%r9, %r7, 6;
	sub.s32 	%r10, %r6, %r9;
	or.b32  	%r11, %r5, 2;
	mul.hi.u32 	%r12, %r11, 715827883;
	and.b32  	%r13, %r12, 511;
	mul.lo.s32 	%r14, %r12, 6;
	sub.s32 	%r15, %r11, %r14;
	or.b32  	%r16, %r5, 1;
	mul.hi.u32 	%r17, %r5, 715827883;
	and.b32  	%r18, %r17, 511;
	mul.hi.u32 	%r19, %r16, 715827883;
	mul.lo.s32 	%r20, %r19, 6;
	sub.s32 	%r21, %r16, %r20;
	mul.lo.s32 	%r22, %r17, 6;
	sub.s32 	%r23, %r5, %r22;
	mul.wide.u32 	%rd5, %r23, 6553600;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r24, %rs4;
	mul.wide.u32 	%rd7, %r24, 102400;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r25, %rs10;
	mul.wide.u32 	%rd9, %r25, 2048;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r18, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.wide.u32 	%rd13, %r5, 4;
	add.s64 	%rd14, %rd3, %rd13;
	mul.wide.u32 	%rd15, %r21, 6553600;
	add.s64 	%rd16, %rd4, %rd15;
	add.s64 	%rd17, %rd16, %rd7;
	add.s64 	%rd18, %rd17, %rd9;
	add.s64 	%rd19, %rd18, %rd11;
	ld.global.nc.f32 	%f2, [%rd19];
	mul.wide.u32 	%rd20, %r15, 6553600;
	add.s64 	%rd21, %rd4, %rd20;
	add.s64 	%rd22, %rd21, %rd7;
	add.s64 	%rd23, %rd22, %rd9;
	mul.wide.u32 	%rd24, %r13, 4;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.nc.f32 	%f3, [%rd25];
	mul.wide.u32 	%rd26, %r10, 6553600;
	add.s64 	%rd27, %rd4, %rd26;
	add.s64 	%rd28, %rd27, %rd7;
	add.s64 	%rd29, %rd28, %rd9;
	mul.wide.u32 	%rd30, %r8, 4;
	add.s64 	%rd31, %rd29, %rd30;
	ld.global.nc.f32 	%f4, [%rd31];
	st.global.v4.f32 	[%rd14], {%f1, %f2, %f3, %f4};
	ret;

}
	// .globl	input_scatter_fusion_265
.visible .entry input_scatter_fusion_265(
	.param .u64 input_scatter_fusion_265_param_0,
	.param .u64 input_scatter_fusion_265_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<15>;
	.reg .b32 	%r<10>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [input_scatter_fusion_265_param_0];
	ld.param.u64 	%rd2, [input_scatter_fusion_265_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	and.b32  	%r5, %r4, 511;
	shr.u32 	%r6, %r1, 2;
	cvt.u16.u32 	%rs1, %r6;
	shr.u16 	%rs2, %rs1, 1;
	mul.hi.u16 	%rs3, %rs2, 5243;
	shr.u16 	%rs4, %rs3, 1;
	mul.lo.s16 	%rs5, %rs4, 50;
	sub.s16 	%rs6, %rs1, %rs5;
	cvt.u16.u32 	%rs7, %r1;
	shr.u16 	%rs8, %rs7, 3;
	mul.hi.u16 	%rs9, %rs8, 5243;
	shr.u16 	%rs10, %rs9, 1;
	and.b16  	%rs11, %rs10, 63;
	shr.u16 	%rs12, %rs7, 9;
	mul.hi.u16 	%rs13, %rs12, 2622;
	shl.b16 	%rs14, %rs13, 1;
	cvt.u32.u16 	%r7, %rs14;
	mul.wide.u32 	%rd5, %r7, 6553600;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u32.u16 	%r8, %rs11;
	mul.wide.u32 	%rd7, %r8, 102400;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r9, %rs6;
	mul.wide.u32 	%rd9, %r9, 2048;
	add.s64 	%rd10, %rd8, %rd9;
	mul.wide.u32 	%rd11, %r5, 4;
	add.s64 	%rd12, %rd10, %rd11;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	ld.global.f32 	%f2, [%rd12];
	add.rn.f32 	%f3, %f1, %f2;
	st.global.f32 	[%rd12], %f3;
	ret;

}
	// .globl	loop_add_fusion_384
.visible .entry loop_add_fusion_384(
	.param .u64 loop_add_fusion_384_param_0,
	.param .u64 loop_add_fusion_384_param_1,
	.param .u64 loop_add_fusion_384_param_2,
	.param .u64 loop_add_fusion_384_param_3,
	.param .u64 loop_add_fusion_384_param_4,
	.param .u64 loop_add_fusion_384_param_5,
	.param .u64 loop_add_fusion_384_param_6
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<52>;
	.reg .f32 	%f<109>;
	.reg .b64 	%rd<201>;

	ld.param.u64 	%rd30, [loop_add_fusion_384_param_0];
	ld.param.u64 	%rd35, [loop_add_fusion_384_param_4];
	cvta.to.global.u64 	%rd3, %rd35;
	cvta.to.global.u64 	%rd7, %rd30;
	mov.u32 	%r15, %ctaid.x;
	mov.u32 	%r16, %tid.x;
	shl.b32 	%r17, %r15, 9;
	shl.b32 	%r18, %r16, 2;
	or.b32  	%r1, %r17, %r18;
	mul.hi.u32 	%r19, %r1, 715827883;
	mul.lo.s32 	%r20, %r19, 6;
	sub.s32 	%r21, %r1, %r20;
	and.b32  	%r2, %r19, 1023;
	cvt.u16.u32 	%rs2, %r15;
	mul.hi.u16 	%rs3, %rs2, -21845;
	shr.u16 	%rs4, %rs3, 3;
	mul.hi.u16 	%rs5, %rs4, 5243;
	shr.u16 	%rs6, %rs5, 2;
	mul.lo.s16 	%rs7, %rs6, 50;
	sub.s16 	%rs1, %rs4, %rs7;
	shr.u16 	%rs8, %rs2, 3;
	mul.hi.u16 	%rs9, %rs8, 6991;
	shr.u16 	%rs10, %rs9, 3;
	or.b32  	%r22, %r1, 1;
	setp.gt.u32 	%p2, %r2, 1;
	and.b32  	%r10, %r19, 1;
	setp.eq.s32 	%p3, %r10, 0;
	and.pred  	%p1, %p2, %p3;
	cvt.u64.u16 	%rd8, %rs10;
	mul.wide.u16 	%r11, %rs1, 1024;
	or.b32  	%r29, %r11, %r2;
	cvt.u64.u32 	%rd10, %r21;
	mov.f32 	%f108, 0f00000000;
	mov.f32 	%f93, %f108;
	@%p1 bra 	$L__BB288_17;
	bra.uni 	$L__BB288_1;
$L__BB288_17:
	mul.wide.u32 	%rd37, %r29, 24;
	cvt.u32.u16 	%r30, %rs10;
	mul.wide.u32 	%rd38, %r30, 1228800;
	add.s64 	%rd39, %rd3, %rd38;
	add.s64 	%rd40, %rd39, %rd37;
	mul.wide.u32 	%rd41, %r21, 4;
	add.s64 	%rd11, %rd40, %rd41;
	ld.global.nc.f32 	%f93, [%rd11];
$L__BB288_1:
	mul.hi.u32 	%r23, %r22, 715827883;
	ld.param.u64 	%rd32, [loop_add_fusion_384_param_1];
	ld.param.u64 	%rd33, [loop_add_fusion_384_param_5];
	ld.param.u64 	%rd34, [loop_add_fusion_384_param_2];
	ld.param.u64 	%rd36, [loop_add_fusion_384_param_3];
	add.s32 	%r31, %r2, -1;
	and.b32  	%r12, %r31, 1;
	setp.eq.s32 	%p4, %r12, 0;
	cvt.u64.u16 	%rd12, %rs1;
	shr.u32 	%r32, %r31, 1;
	mul.lo.s64 	%rd42, %rd8, 614400;
	add.s64 	%rd43, %rd7, %rd42;
	shl.b64 	%rd48, %rd10, 2;
	mov.f32 	%f94, %f108;
	@%p4 bra 	$L__BB288_18;
	bra.uni 	$L__BB288_2;
$L__BB288_18:
	cvt.u32.u16 	%r33, %rs1;
	mul.wide.u32 	%rd44, %r33, 12288;
	add.s64 	%rd45, %rd43, %rd44;
	mul.wide.u32 	%rd46, %r32, 24;
	add.s64 	%rd47, %rd45, %rd46;
	add.s64 	%rd14, %rd47, %rd48;
	ld.global.nc.f32 	%f94, [%rd14];
$L__BB288_2:
	ld.param.u64 	%rd31, [loop_add_fusion_384_param_6];
	mul.lo.s32 	%r24, %r23, 6;
	cvta.to.global.u64 	%rd2, %rd33;
	cvta.to.global.u64 	%rd4, %rd36;
	cvta.to.global.u64 	%rd5, %rd34;
	cvta.to.global.u64 	%rd6, %rd32;
	add.rn.f32 	%f3, %f93, %f94;
	shr.u32 	%r51, %r2, 1;
	mul.lo.s64 	%rd198, %rd12, 12288;
	mul.lo.s64 	%rd199, %rd8, 12;
	shl.b64 	%rd200, %rd8, 2;
	mov.f32 	%f95, %f108;
	@%p3 bra 	$L__BB288_19;
	bra.uni 	$L__BB288_3;
$L__BB288_19:
	cvt.u32.u64 	%r34, %rd10;
	add.s64 	%rd50, %rd5, %rd42;
	add.s64 	%rd52, %rd50, %rd198;
	mul.wide.u32 	%rd53, %r51, 24;
	add.s64 	%rd54, %rd52, %rd53;
	add.s64 	%rd56, %rd54, %rd48;
	ld.global.nc.f32 	%f42, [%rd56];
	add.s64 	%rd57, %rd4, %rd42;
	add.s64 	%rd58, %rd57, %rd198;
	add.s64 	%rd59, %rd58, %rd53;
	add.s64 	%rd60, %rd59, %rd48;
	ld.global.nc.f32 	%f43, [%rd60];
	add.rn.f32 	%f44, %f42, %f43;
	shr.u32 	%r36, %r34, 1;
	add.s64 	%rd62, %rd2, %rd199;
	mul.wide.u32 	%rd63, %r36, 4;
	add.s64 	%rd64, %rd62, %rd63;
	ld.global.nc.f32 	%f45, [%rd64];
	add.s64 	%rd66, %rd6, %rd200;
	ld.global.nc.f32 	%f46, [%rd66];
	add.s64 	%rd68, %rd43, %rd198;
	add.s64 	%rd69, %rd68, %rd53;
	add.s64 	%rd70, %rd69, %rd48;
	ld.global.nc.f32 	%f47, [%rd70];
	mul.rn.f32 	%f48, %f46, %f47;
	mul.rn.f32 	%f49, %f45, %f48;
	add.rn.f32 	%f95, %f44, %f49;
$L__BB288_3:
	cvta.to.global.u64 	%rd1, %rd31;
	sub.s32 	%r3, %r22, %r24;
	add.rn.f32 	%f5, %f3, %f95;
	setp.eq.s32 	%p6, %r2, 0;
	mul.lo.s64 	%rd71, %rd8, 1228800;
	add.s64 	%rd72, %rd3, %rd71;
	mov.f32 	%f96, %f108;
	@%p6 bra 	$L__BB288_20;
	bra.uni 	$L__BB288_4;
$L__BB288_20:
	mul.wide.u32 	%rd73, %r11, 24;
	add.s64 	%rd74, %rd72, %rd73;
	add.s64 	%rd16, %rd74, %rd48;
	ld.global.nc.f32 	%f96, [%rd16];
$L__BB288_4:
	or.b32  	%r25, %r1, 2;
	add.rn.f32 	%f52, %f5, %f96;
	mul.wide.u32 	%rd76, %r1, 4;
	add.s64 	%rd17, %rd1, %rd76;
	st.global.f32 	[%rd17], %f52;
	cvt.u64.u32 	%rd18, %r3;
	mov.f32 	%f97, %f108;
	@%p1 bra 	$L__BB288_21;
	bra.uni 	$L__BB288_5;
$L__BB288_21:
	cvt.u64.u32 	%rd9, %r29;
	mul.lo.s64 	%rd79, %rd9, 24;
	add.s64 	%rd80, %rd72, %rd79;
	mul.wide.u32 	%rd81, %r3, 4;
	add.s64 	%rd19, %rd80, %rd81;
	ld.global.nc.f32 	%f97, [%rd19];
$L__BB288_5:
	mul.hi.u32 	%r4, %r25, 715827883;
	add.s64 	%rd85, %rd43, %rd198;
	shl.b64 	%rd88, %rd18, 2;
	mov.f32 	%f98, %f108;
	@%p4 bra 	$L__BB288_22;
	bra.uni 	$L__BB288_6;
$L__BB288_22:
	cvt.u64.u32 	%rd13, %r32;
	mul.lo.s64 	%rd86, %rd13, 24;
	add.s64 	%rd87, %rd85, %rd86;
	add.s64 	%rd20, %rd87, %rd88;
	ld.global.nc.f32 	%f98, [%rd20];
$L__BB288_6:
	mul.lo.s32 	%r26, %r4, 6;
	cvt.u64.u32 	%rd15, %r11;
	add.rn.f32 	%f9, %f97, %f98;
	mov.f32 	%f99, %f108;
	@%p3 bra 	$L__BB288_23;
	bra.uni 	$L__BB288_7;
$L__BB288_23:
	add.s64 	%rd90, %rd5, %rd42;
	add.s64 	%rd92, %rd90, %rd198;
	mul.wide.u32 	%rd93, %r51, 24;
	add.s64 	%rd94, %rd92, %rd93;
	add.s64 	%rd96, %rd94, %rd88;
	ld.global.nc.f32 	%f55, [%rd96];
	add.s64 	%rd97, %rd4, %rd42;
	add.s64 	%rd98, %rd97, %rd198;
	add.s64 	%rd99, %rd98, %rd93;
	add.s64 	%rd100, %rd99, %rd88;
	ld.global.nc.f32 	%f56, [%rd100];
	add.rn.f32 	%f57, %f55, %f56;
	shr.u32 	%r38, %r3, 1;
	add.s64 	%rd102, %rd2, %rd199;
	mul.wide.u32 	%rd103, %r38, 4;
	add.s64 	%rd104, %rd102, %rd103;
	ld.global.nc.f32 	%f58, [%rd104];
	add.s64 	%rd106, %rd6, %rd200;
	ld.global.nc.f32 	%f59, [%rd106];
	add.s64 	%rd109, %rd85, %rd93;
	add.s64 	%rd110, %rd109, %rd88;
	ld.global.nc.f32 	%f60, [%rd110];
	mul.rn.f32 	%f61, %f59, %f60;
	mul.rn.f32 	%f62, %f58, %f61;
	add.rn.f32 	%f99, %f57, %f62;
$L__BB288_7:
	sub.s32 	%r5, %r25, %r26;
	and.b32  	%r6, %r4, 1023;
	add.rn.f32 	%f11, %f9, %f99;
	mul.lo.s64 	%rd113, %rd15, 24;
	add.s64 	%rd114, %rd72, %rd113;
	mov.f32 	%f100, %f108;
	@%p6 bra 	$L__BB288_24;
	bra.uni 	$L__BB288_8;
$L__BB288_24:
	add.s64 	%rd21, %rd114, %rd88;
	ld.global.nc.f32 	%f100, [%rd21];
$L__BB288_8:
	or.b32  	%r27, %r1, 3;
	add.rn.f32 	%f65, %f11, %f100;
	st.global.f32 	[%rd17+4], %f65;
	setp.gt.u32 	%p10, %r6, 1;
	and.b32  	%r13, %r4, 1;
	setp.eq.s32 	%p11, %r13, 0;
	and.pred  	%p12, %p10, %p11;
	cvt.u64.u32 	%rd22, %r5;
	mov.f32 	%f101, %f108;
	@%p12 bra 	$L__BB288_25;
	bra.uni 	$L__BB288_9;
$L__BB288_25:
	or.b32  	%r39, %r6, %r11;
	mul.wide.u32 	%rd118, %r39, 24;
	add.s64 	%rd119, %rd72, %rd118;
	mul.wide.u32 	%rd120, %r5, 4;
	add.s64 	%rd23, %rd119, %rd120;
	ld.global.nc.f32 	%f101, [%rd23];
$L__BB288_9:
	mul.hi.u32 	%r7, %r27, 715827883;
	add.s32 	%r40, %r6, -1;
	and.b32  	%r41, %r40, 1;
	setp.eq.b32 	%p13, %r41, 1;
	mov.pred 	%p14, 0;
	xor.pred  	%p15, %p13, %p14;
	not.pred 	%p16, %p15;
	shl.b64 	%rd127, %rd22, 2;
	mov.f32 	%f102, %f108;
	@%p16 bra 	$L__BB288_26;
	bra.uni 	$L__BB288_10;
$L__BB288_26:
	shr.u32 	%r42, %r40, 1;
	mul.wide.u32 	%rd125, %r42, 24;
	add.s64 	%rd126, %rd85, %rd125;
	add.s64 	%rd24, %rd126, %rd127;
	ld.global.nc.f32 	%f102, [%rd24];
$L__BB288_10:
	mul.lo.s32 	%r28, %r7, 6;
	add.rn.f32 	%f15, %f101, %f102;
	mov.f32 	%f103, %f108;
	@%p11 bra 	$L__BB288_27;
	bra.uni 	$L__BB288_11;
$L__BB288_27:
	shr.u32 	%r43, %r6, 1;
	add.s64 	%rd129, %rd5, %rd42;
	add.s64 	%rd131, %rd129, %rd198;
	mul.wide.u32 	%rd132, %r43, 24;
	add.s64 	%rd133, %rd131, %rd132;
	add.s64 	%rd135, %rd133, %rd127;
	ld.global.nc.f32 	%f68, [%rd135];
	add.s64 	%rd136, %rd4, %rd42;
	add.s64 	%rd137, %rd136, %rd198;
	add.s64 	%rd138, %rd137, %rd132;
	add.s64 	%rd139, %rd138, %rd127;
	ld.global.nc.f32 	%f69, [%rd139];
	add.rn.f32 	%f70, %f68, %f69;
	shr.u32 	%r44, %r5, 1;
	add.s64 	%rd141, %rd2, %rd199;
	mul.wide.u32 	%rd142, %r44, 4;
	add.s64 	%rd143, %rd141, %rd142;
	ld.global.nc.f32 	%f71, [%rd143];
	add.s64 	%rd145, %rd6, %rd200;
	ld.global.nc.f32 	%f72, [%rd145];
	add.s64 	%rd148, %rd85, %rd132;
	add.s64 	%rd149, %rd148, %rd127;
	ld.global.nc.f32 	%f73, [%rd149];
	mul.rn.f32 	%f74, %f72, %f73;
	mul.rn.f32 	%f75, %f71, %f74;
	add.rn.f32 	%f103, %f70, %f75;
$L__BB288_11:
	sub.s32 	%r8, %r27, %r28;
	and.b32  	%r9, %r7, 1023;
	add.rn.f32 	%f17, %f15, %f103;
	setp.eq.s32 	%p18, %r6, 0;
	mov.f32 	%f104, %f108;
	@%p18 bra 	$L__BB288_28;
	bra.uni 	$L__BB288_12;
$L__BB288_28:
	add.s64 	%rd25, %rd114, %rd127;
	ld.global.nc.f32 	%f104, [%rd25];
$L__BB288_12:
	add.rn.f32 	%f78, %f17, %f104;
	st.global.f32 	[%rd17+8], %f78;
	setp.gt.u32 	%p19, %r9, 1;
	and.b32  	%r14, %r7, 1;
	setp.eq.s32 	%p20, %r14, 0;
	and.pred  	%p21, %p19, %p20;
	cvt.u64.u32 	%rd26, %r8;
	mov.f32 	%f105, %f108;
	@%p21 bra 	$L__BB288_29;
	bra.uni 	$L__BB288_13;
$L__BB288_29:
	or.b32  	%r45, %r9, %r11;
	mul.wide.u32 	%rd157, %r45, 24;
	add.s64 	%rd158, %rd72, %rd157;
	mul.wide.u32 	%rd159, %r8, 4;
	add.s64 	%rd27, %rd158, %rd159;
	ld.global.nc.f32 	%f105, [%rd27];
$L__BB288_13:
	add.s32 	%r46, %r9, -1;
	and.b32  	%r47, %r46, 1;
	setp.eq.b32 	%p22, %r47, 1;
	xor.pred  	%p24, %p22, %p14;
	not.pred 	%p25, %p24;
	shl.b64 	%rd166, %rd26, 2;
	mov.f32 	%f106, %f108;
	@%p25 bra 	$L__BB288_30;
	bra.uni 	$L__BB288_14;
$L__BB288_30:
	shr.u32 	%r48, %r46, 1;
	mul.wide.u32 	%rd164, %r48, 24;
	add.s64 	%rd165, %rd85, %rd164;
	add.s64 	%rd28, %rd165, %rd166;
	ld.global.nc.f32 	%f106, [%rd28];
$L__BB288_14:
	mov.f32 	%f107, %f108;
	@%p20 bra 	$L__BB288_31;
	bra.uni 	$L__BB288_15;
$L__BB288_31:
	shr.u32 	%r49, %r9, 1;
	add.s64 	%rd168, %rd5, %rd42;
	add.s64 	%rd170, %rd168, %rd198;
	mul.wide.u32 	%rd171, %r49, 24;
	add.s64 	%rd172, %rd170, %rd171;
	add.s64 	%rd174, %rd172, %rd166;
	ld.global.nc.f32 	%f81, [%rd174];
	add.s64 	%rd175, %rd4, %rd42;
	add.s64 	%rd176, %rd175, %rd198;
	add.s64 	%rd177, %rd176, %rd171;
	add.s64 	%rd178, %rd177, %rd166;
	ld.global.nc.f32 	%f82, [%rd178];
	add.rn.f32 	%f83, %f81, %f82;
	shr.u32 	%r50, %r8, 1;
	add.s64 	%rd180, %rd2, %rd199;
	mul.wide.u32 	%rd181, %r50, 4;
	add.s64 	%rd182, %rd180, %rd181;
	ld.global.nc.f32 	%f84, [%rd182];
	add.s64 	%rd184, %rd6, %rd200;
	ld.global.nc.f32 	%f85, [%rd184];
	add.s64 	%rd187, %rd85, %rd171;
	add.s64 	%rd188, %rd187, %rd166;
	ld.global.nc.f32 	%f86, [%rd188];
	mul.rn.f32 	%f87, %f85, %f86;
	mul.rn.f32 	%f88, %f84, %f87;
	add.rn.f32 	%f107, %f83, %f88;
$L__BB288_15:
	setp.eq.s32 	%p27, %r9, 0;
	@%p27 bra 	$L__BB288_32;
	bra.uni 	$L__BB288_16;
$L__BB288_32:
	add.s64 	%rd29, %rd114, %rd166;
	ld.global.nc.f32 	%f108, [%rd29];
$L__BB288_16:
	add.rn.f32 	%f90, %f105, %f106;
	add.rn.f32 	%f91, %f90, %f107;
	add.rn.f32 	%f92, %f91, %f108;
	st.global.f32 	[%rd17+12], %f92;
	ret;

}
	// .globl	loop_transpose_fusion_117
.visible .entry loop_transpose_fusion_117(
	.param .u64 loop_transpose_fusion_117_param_0,
	.param .u64 loop_transpose_fusion_117_param_1,
	.param .u64 loop_transpose_fusion_117_param_2
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<18>;
	.reg .b32 	%r<50>;
	.reg .f32 	%f<9>;
	.reg .b64 	%rd<40>;

	ld.param.u64 	%rd1, [loop_transpose_fusion_117_param_0];
	ld.param.u64 	%rd2, [loop_transpose_fusion_117_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_transpose_fusion_117_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %ctaid.x;
	cvt.u16.u32 	%rs1, %r1;
	shr.u16 	%rs2, %rs1, 3;
	mul.hi.u16 	%rs3, %rs2, 6991;
	shr.u16 	%rs4, %rs3, 3;
	cvt.u32.u16 	%r2, %rs4;
	shl.b32 	%r3, %r1, 9;
	mov.u32 	%r4, %tid.x;
	shl.b32 	%r5, %r4, 2;
	or.b32  	%r6, %r3, %r5;
	shr.u16 	%rs5, %rs1, 2;
	mul.hi.u16 	%rs6, %rs5, 5243;
	shr.u16 	%rs7, %rs6, 1;
	mul.hi.u16 	%rs8, %rs7, 10923;
	mul.lo.s16 	%rs9, %rs8, 6;
	sub.s16 	%rs10, %rs7, %rs9;
	cvt.u32.u16 	%r7, %rs10;
	shr.u32 	%r8, %r1, 1;
	cvt.u16.u32 	%rs11, %r8;
	shr.u16 	%rs12, %rs11, 1;
	mul.hi.u16 	%rs13, %rs12, 5243;
	shr.u16 	%rs14, %rs13, 1;
	mul.lo.s16 	%rs15, %rs14, 50;
	sub.s16 	%rs16, %rs11, %rs15;
	and.b32  	%r9, %r6, 1020;
	shl.b16 	%rs17, %rs16, 10;
	cvt.u32.u16 	%r10, %rs17;
	or.b32  	%r11, %r9, %r10;
	mul.wide.u32 	%rd7, %r11, 24;
	mul.wide.u32 	%rd8, %r2, 1228800;
	add.s64 	%rd9, %rd6, %rd8;
	add.s64 	%rd10, %rd9, %rd7;
	mul.wide.u32 	%rd11, %r7, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	mul.lo.s32 	%r12, %r2, 307200;
	mad.lo.s32 	%r13, %r7, 51200, %r12;
	add.s32 	%r14, %r13, %r11;
	mul.hi.u32 	%r16, %r14, -1431655765;
	shr.u32 	%r17, %r16, 2;
	mul.lo.s32 	%r18, %r17, 6;
	sub.s32 	%r19, %r14, %r18;
	bfe.u32 	%r20, %r16, 2, 6;
	mul.hi.u32 	%r21, %r14, 178956971;
	shr.u32 	%r22, %r21, 4;
	mul.wide.u32 	%rd13, %r20, 1228800;
	add.s64 	%rd14, %rd6, %rd13;
	mul.wide.u32 	%rd15, %r22, 24;
	add.s64 	%rd16, %rd14, %rd15;
	mul.wide.u32 	%rd17, %r19, 4;
	add.s64 	%rd18, %rd16, %rd17;
	ld.global.nc.f32 	%f2, [%rd18];
	mul.wide.u32 	%rd19, %r6, 4;
	add.s64 	%rd20, %rd5, %rd19;
	add.s64 	%rd21, %rd3, %rd19;
	ld.global.nc.f32 	%f3, [%rd12+24];
	or.b32  	%r23, %r14, 1;
	mul.hi.u32 	%r25, %r23, -1431655765;
	shr.u32 	%r26, %r25, 2;
	mul.lo.s32 	%r27, %r26, 6;
	sub.s32 	%r28, %r23, %r27;
	bfe.u32 	%r29, %r25, 2, 6;
	mul.hi.u32 	%r30, %r23, 178956971;
	shr.u32 	%r31, %r30, 4;
	mul.wide.u32 	%rd22, %r29, 1228800;
	add.s64 	%rd23, %rd6, %rd22;
	mul.wide.u32 	%rd24, %r31, 24;
	add.s64 	%rd25, %rd23, %rd24;
	mul.wide.u32 	%rd26, %r28, 4;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.nc.f32 	%f4, [%rd27];
	ld.global.nc.f32 	%f5, [%rd12+48];
	or.b32  	%r32, %r14, 2;
	mul.hi.u32 	%r34, %r32, -1431655765;
	shr.u32 	%r35, %r34, 2;
	mul.lo.s32 	%r36, %r35, 6;
	sub.s32 	%r37, %r32, %r36;
	bfe.u32 	%r38, %r34, 2, 6;
	mul.hi.u32 	%r39, %r32, 178956971;
	shr.u32 	%r40, %r39, 4;
	mul.wide.u32 	%rd28, %r38, 1228800;
	add.s64 	%rd29, %rd6, %rd28;
	mul.wide.u32 	%rd30, %r40, 24;
	add.s64 	%rd31, %rd29, %rd30;
	mul.wide.u32 	%rd32, %r37, 4;
	add.s64 	%rd33, %rd31, %rd32;
	ld.global.nc.f32 	%f6, [%rd33];
	ld.global.nc.f32 	%f7, [%rd12+72];
	or.b32  	%r41, %r14, 3;
	mul.hi.u32 	%r43, %r41, -1431655765;
	shr.u32 	%r44, %r43, 2;
	mul.lo.s32 	%r45, %r44, 6;
	sub.s32 	%r46, %r41, %r45;
	bfe.u32 	%r47, %r43, 2, 6;
	mul.hi.u32 	%r48, %r41, 178956971;
	shr.u32 	%r49, %r48, 4;
	mul.wide.u32 	%rd34, %r47, 1228800;
	add.s64 	%rd35, %rd6, %rd34;
	mul.wide.u32 	%rd36, %r49, 24;
	add.s64 	%rd37, %rd35, %rd36;
	mul.wide.u32 	%rd38, %r46, 4;
	add.s64 	%rd39, %rd37, %rd38;
	ld.global.nc.f32 	%f8, [%rd39];
	st.global.v4.f32 	[%rd20], {%f1, %f3, %f5, %f7};
	st.global.v4.f32 	[%rd21], {%f2, %f4, %f6, %f8};
	ret;

}
	// .globl	input_multiply_reduce_fusion_13
.visible .entry input_multiply_reduce_fusion_13(
	.param .u64 input_multiply_reduce_fusion_13_param_0,
	.param .u64 input_multiply_reduce_fusion_13_param_1,
	.param .u64 input_multiply_reduce_fusion_13_param_2,
	.param .u64 input_multiply_reduce_fusion_13_param_3,
	.param .u64 input_multiply_reduce_fusion_13_param_4
)
.reqntid 192, 1, 1
{
	.reg .pred 	%p<15>;
	.reg .b32 	%r<47>;
	.reg .f32 	%f<166>;
	.reg .b64 	%rd<88>;
	// demoted variable
	.shared .align 4 .b8 shared_cache56[24];
	ld.param.u64 	%rd6, [input_multiply_reduce_fusion_13_param_0];
	ld.param.u64 	%rd8, [input_multiply_reduce_fusion_13_param_1];
	ld.param.u64 	%rd9, [input_multiply_reduce_fusion_13_param_3];
	cvta.to.global.u64 	%rd10, %rd9;
	ld.param.u64 	%rd11, [input_multiply_reduce_fusion_13_param_2];
	cvta.to.global.u64 	%rd12, %rd11;
	cvta.to.global.u64 	%rd13, %rd8;
	cvta.to.global.u64 	%rd14, %rd6;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r3, %ctaid.x;
	mul.lo.s32 	%r4, %r3, 3072;
	shl.b32 	%r5, %r1, 1;
	shr.u32 	%r6, %r4, 9;
	mul.wide.u32 	%rd15, %r3, 4;
	add.s64 	%rd16, %rd10, %rd15;
	ld.global.nc.f32 	%f28, [%rd16];
	mov.f32 	%f29, 0f3F800000;
	sub.rn.f32 	%f30, %f29, %f28;
	add.s64 	%rd17, %rd12, %rd15;
	ld.global.nc.f32 	%f31, [%rd17];
	div.full.f32 	%f32, %f30, %f31;
	sqrt.approx.f32 	%f33, %f32;
	mul.wide.u32 	%rd18, %r6, 2048;
	add.s64 	%rd19, %rd14, %rd18;
	mul.wide.u32 	%rd20, %r5, 4;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.v2.f32 	{%f34, %f35}, [%rd21];
	add.s64 	%rd22, %rd13, %rd18;
	add.s64 	%rd23, %rd22, %rd20;
	ld.global.nc.v2.f32 	{%f36, %f37}, [%rd23];
	mul.rn.f32 	%f38, %f34, %f36;
	add.rn.f32 	%f39, %f38, 0f00000000;
	mul.rn.f32 	%f40, %f34, %f33;
	mul.rn.f32 	%f41, %f35, %f37;
	add.rn.f32 	%f42, %f39, %f41;
	mul.rn.f32 	%f43, %f35, %f33;
	st.global.v2.f32 	[%rd21], {%f40, %f43};
	add.s32 	%r7, %r5, 384;
	or.b32  	%r8, %r7, %r4;
	and.b32  	%r9, %r7, 510;
	shr.u32 	%r10, %r8, 9;
	mul.wide.u32 	%rd24, %r10, 2048;
	add.s64 	%rd25, %rd14, %rd24;
	mul.wide.u32 	%rd26, %r9, 4;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.v2.f32 	{%f44, %f45}, [%rd27];
	add.s64 	%rd28, %rd13, %rd24;
	add.s64 	%rd29, %rd28, %rd26;
	ld.global.nc.v2.f32 	{%f46, %f47}, [%rd29];
	mul.rn.f32 	%f48, %f44, %f46;
	add.rn.f32 	%f49, %f42, %f48;
	mul.rn.f32 	%f50, %f44, %f33;
	mul.rn.f32 	%f51, %f45, %f47;
	add.rn.f32 	%f52, %f49, %f51;
	mul.rn.f32 	%f53, %f45, %f33;
	st.global.v2.f32 	[%rd27], {%f50, %f53};
	add.s32 	%r11, %r5, 768;
	add.s32 	%r12, %r11, %r4;
	and.b32  	%r13, %r11, 510;
	shr.u32 	%r14, %r12, 9;
	mul.hi.u32 	%r15, %r12, -1431655765;
	shr.u32 	%r16, %r15, 11;
	mul.wide.u32 	%rd30, %r16, 4;
	add.s64 	%rd31, %rd10, %rd30;
	ld.global.nc.f32 	%f54, [%rd31];
	sub.rn.f32 	%f55, %f29, %f54;
	add.s64 	%rd32, %rd12, %rd30;
	ld.global.nc.f32 	%f56, [%rd32];
	div.full.f32 	%f57, %f55, %f56;
	sqrt.approx.f32 	%f58, %f57;
	mul.wide.u32 	%rd33, %r14, 2048;
	add.s64 	%rd34, %rd14, %rd33;
	mul.wide.u32 	%rd35, %r13, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.v2.f32 	{%f59, %f60}, [%rd36];
	add.s64 	%rd37, %rd13, %rd33;
	add.s64 	%rd38, %rd37, %rd35;
	ld.global.nc.v2.f32 	{%f61, %f62}, [%rd38];
	mul.rn.f32 	%f63, %f59, %f61;
	add.rn.f32 	%f64, %f52, %f63;
	mul.rn.f32 	%f65, %f59, %f58;
	mul.rn.f32 	%f66, %f60, %f62;
	add.rn.f32 	%f67, %f64, %f66;
	mul.rn.f32 	%f68, %f60, %f58;
	st.global.v2.f32 	[%rd36], {%f65, %f68};
	add.s32 	%r17, %r5, 1152;
	add.s32 	%r18, %r17, %r4;
	and.b32  	%r19, %r17, 510;
	shr.u32 	%r20, %r18, 9;
	mul.hi.u32 	%r21, %r18, -1431655765;
	shr.u32 	%r22, %r21, 11;
	mul.wide.u32 	%rd39, %r22, 4;
	add.s64 	%rd40, %rd10, %rd39;
	ld.global.nc.f32 	%f69, [%rd40];
	sub.rn.f32 	%f70, %f29, %f69;
	add.s64 	%rd41, %rd12, %rd39;
	ld.global.nc.f32 	%f71, [%rd41];
	div.full.f32 	%f72, %f70, %f71;
	sqrt.approx.f32 	%f73, %f72;
	mul.wide.u32 	%rd42, %r20, 2048;
	add.s64 	%rd43, %rd14, %rd42;
	mul.wide.u32 	%rd44, %r19, 4;
	add.s64 	%rd45, %rd43, %rd44;
	ld.global.v2.f32 	{%f74, %f75}, [%rd45];
	add.s64 	%rd46, %rd13, %rd42;
	add.s64 	%rd47, %rd46, %rd44;
	ld.global.nc.v2.f32 	{%f76, %f77}, [%rd47];
	mul.rn.f32 	%f78, %f74, %f76;
	add.rn.f32 	%f79, %f67, %f78;
	mul.rn.f32 	%f80, %f74, %f73;
	mul.rn.f32 	%f81, %f75, %f77;
	add.rn.f32 	%f82, %f79, %f81;
	mul.rn.f32 	%f83, %f75, %f73;
	st.global.v2.f32 	[%rd45], {%f80, %f83};
	add.s32 	%r23, %r4, %r5;
	add.s32 	%r24, %r23, 1536;
	shr.u32 	%r25, %r24, 9;
	mul.hi.u32 	%r26, %r24, -1431655765;
	shr.u32 	%r27, %r26, 11;
	mul.wide.u32 	%rd48, %r27, 4;
	add.s64 	%rd49, %rd10, %rd48;
	ld.global.nc.f32 	%f84, [%rd49];
	sub.rn.f32 	%f85, %f29, %f84;
	add.s64 	%rd50, %rd12, %rd48;
	ld.global.nc.f32 	%f86, [%rd50];
	div.full.f32 	%f87, %f85, %f86;
	sqrt.approx.f32 	%f88, %f87;
	mul.wide.u32 	%rd51, %r25, 2048;
	add.s64 	%rd52, %rd14, %rd51;
	add.s64 	%rd53, %rd52, %rd20;
	ld.global.v2.f32 	{%f89, %f90}, [%rd53];
	add.s64 	%rd54, %rd13, %rd51;
	add.s64 	%rd55, %rd54, %rd20;
	ld.global.nc.v2.f32 	{%f91, %f92}, [%rd55];
	mul.rn.f32 	%f93, %f89, %f91;
	add.rn.f32 	%f94, %f82, %f93;
	mul.rn.f32 	%f95, %f89, %f88;
	mul.rn.f32 	%f96, %f90, %f92;
	add.rn.f32 	%f97, %f94, %f96;
	mul.rn.f32 	%f98, %f90, %f88;
	st.global.v2.f32 	[%rd53], {%f95, %f98};
	add.s32 	%r28, %r5, 1920;
	add.s32 	%r29, %r28, %r4;
	and.b32  	%r30, %r28, 510;
	shr.u32 	%r31, %r29, 9;
	mul.hi.u32 	%r32, %r29, -1431655765;
	shr.u32 	%r33, %r32, 11;
	mul.wide.u32 	%rd56, %r33, 4;
	add.s64 	%rd57, %rd10, %rd56;
	ld.global.nc.f32 	%f99, [%rd57];
	sub.rn.f32 	%f100, %f29, %f99;
	add.s64 	%rd58, %rd12, %rd56;
	ld.global.nc.f32 	%f101, [%rd58];
	div.full.f32 	%f102, %f100, %f101;
	sqrt.approx.f32 	%f103, %f102;
	mul.wide.u32 	%rd59, %r31, 2048;
	add.s64 	%rd60, %rd14, %rd59;
	mul.wide.u32 	%rd61, %r30, 4;
	add.s64 	%rd62, %rd60, %rd61;
	ld.global.v2.f32 	{%f104, %f105}, [%rd62];
	add.s64 	%rd63, %rd13, %rd59;
	add.s64 	%rd64, %rd63, %rd61;
	ld.global.nc.v2.f32 	{%f106, %f107}, [%rd64];
	mul.rn.f32 	%f108, %f104, %f106;
	add.rn.f32 	%f109, %f97, %f108;
	mul.rn.f32 	%f110, %f104, %f103;
	mul.rn.f32 	%f111, %f105, %f107;
	add.rn.f32 	%f112, %f109, %f111;
	mul.rn.f32 	%f113, %f105, %f103;
	st.global.v2.f32 	[%rd62], {%f110, %f113};
	add.s32 	%r34, %r5, 2304;
	add.s32 	%r35, %r34, %r4;
	and.b32  	%r36, %r34, 510;
	shr.u32 	%r37, %r35, 9;
	mul.hi.u32 	%r38, %r35, -1431655765;
	shr.u32 	%r39, %r38, 11;
	mul.wide.u32 	%rd65, %r39, 4;
	add.s64 	%rd66, %rd10, %rd65;
	ld.global.nc.f32 	%f114, [%rd66];
	sub.rn.f32 	%f115, %f29, %f114;
	add.s64 	%rd67, %rd12, %rd65;
	ld.global.nc.f32 	%f116, [%rd67];
	div.full.f32 	%f117, %f115, %f116;
	sqrt.approx.f32 	%f118, %f117;
	mul.wide.u32 	%rd68, %r37, 2048;
	add.s64 	%rd69, %rd14, %rd68;
	mul.wide.u32 	%rd70, %r36, 4;
	add.s64 	%rd71, %rd69, %rd70;
	ld.global.v2.f32 	{%f119, %f120}, [%rd71];
	add.s64 	%rd72, %rd13, %rd68;
	add.s64 	%rd73, %rd72, %rd70;
	ld.global.nc.v2.f32 	{%f121, %f122}, [%rd73];
	mul.rn.f32 	%f123, %f119, %f121;
	add.rn.f32 	%f124, %f112, %f123;
	mul.rn.f32 	%f125, %f119, %f118;
	mul.rn.f32 	%f126, %f120, %f122;
	add.rn.f32 	%f127, %f124, %f126;
	mul.rn.f32 	%f128, %f120, %f118;
	st.global.v2.f32 	[%rd71], {%f125, %f128};
	add.s32 	%r40, %r5, 2688;
	add.s32 	%r41, %r40, %r4;
	and.b32  	%r42, %r40, 510;
	shr.u32 	%r43, %r41, 9;
	mul.hi.u32 	%r44, %r41, -1431655765;
	shr.u32 	%r45, %r44, 11;
	mul.wide.u32 	%rd74, %r45, 4;
	add.s64 	%rd75, %rd10, %rd74;
	ld.global.nc.f32 	%f129, [%rd75];
	sub.rn.f32 	%f130, %f29, %f129;
	add.s64 	%rd76, %rd12, %rd74;
	ld.global.nc.f32 	%f131, [%rd76];
	div.full.f32 	%f132, %f130, %f131;
	sqrt.approx.f32 	%f133, %f132;
	mul.wide.u32 	%rd77, %r43, 2048;
	add.s64 	%rd78, %rd14, %rd77;
	mul.wide.u32 	%rd79, %r42, 4;
	add.s64 	%rd80, %rd78, %rd79;
	ld.global.v2.f32 	{%f134, %f135}, [%rd80];
	add.s64 	%rd81, %rd13, %rd77;
	add.s64 	%rd82, %rd81, %rd79;
	ld.global.nc.v2.f32 	{%f136, %f137}, [%rd82];
	mul.rn.f32 	%f138, %f134, %f136;
	add.rn.f32 	%f139, %f127, %f138;
	mul.rn.f32 	%f140, %f134, %f133;
	mul.rn.f32 	%f141, %f135, %f137;
	add.rn.f32 	%f142, %f139, %f141;
	mul.rn.f32 	%f143, %f135, %f133;
	st.global.v2.f32 	[%rd80], {%f140, %f143};
	and.b32  	%r2, %r1, 31;
	shfl.sync.down.b32	%f144, %f142, 16, 31, -1;
	add.rn.f32 	%f145, %f142, %f144;
	shfl.sync.down.b32	%f146, %f145, 8, 31, -1;
	add.rn.f32 	%f147, %f145, %f146;
	shfl.sync.down.b32	%f148, %f147, 4, 31, -1;
	add.rn.f32 	%f149, %f147, %f148;
	shfl.sync.down.b32	%f150, %f149, 2, 31, -1;
	add.rn.f32 	%f151, %f149, %f150;
	shfl.sync.down.b32	%f152, %f151, 1, 31, -1;
	setp.eq.s32 	%p1, %r2, 0;
	mov.u64 	%rd84, shared_cache56;
	@%p1 bra 	$L__BB290_3;
	bra.uni 	$L__BB290_1;
$L__BB290_3:
	shr.u32 	%r46, %r1, 5;
	mul.wide.u32 	%rd83, %r46, 4;
	add.s64 	%rd3, %rd84, %rd83;
	add.rn.f32 	%f1, %f151, %f152;
	st.shared.f32 	[%rd3], %f1;
$L__BB290_1:
	bar.sync 	0;
	setp.lt.u32 	%p2, %r1, 32;
	@%p2 bra 	$L__BB290_4;
	bra.uni 	$L__BB290_2;
$L__BB290_4:
	mul.wide.u32 	%rd85, %r2, 4;
	add.s64 	%rd4, %rd84, %rd85;
	setp.gt.u32 	%p3, %r1, 5;
	mov.f32 	%f157, 0f00000000;
	mov.f32 	%f156, %f157;
	@%p3 bra 	$L__BB290_6;
	ld.shared.f32 	%f156, [%rd4];
$L__BB290_6:
	shfl.sync.down.b32	%f4, %f156, 16, 31, -1;
	@%p3 bra 	$L__BB290_8;
	ld.shared.f32 	%f157, [%rd4];
$L__BB290_8:
	add.rn.f32 	%f7, %f4, %f157;
	mov.f32 	%f158, %f7;
	@%p3 bra 	$L__BB290_10;
	st.shared.f32 	[%rd4], %f7;
	mov.f32 	%f158, 0f00000000;
$L__BB290_10:
	shfl.sync.down.b32	%f9, %f7, 8, 31, -1;
	mov.f32 	%f159, %f158;
	@%p3 bra 	$L__BB290_12;
	ld.shared.f32 	%f159, [%rd4];
$L__BB290_12:
	add.rn.f32 	%f12, %f9, %f159;
	mov.f32 	%f160, %f12;
	@%p3 bra 	$L__BB290_14;
	st.shared.f32 	[%rd4], %f12;
	mov.f32 	%f160, %f158;
$L__BB290_14:
	shfl.sync.down.b32	%f14, %f12, 4, 31, -1;
	mov.f32 	%f161, %f160;
	@%p3 bra 	$L__BB290_16;
	ld.shared.f32 	%f161, [%rd4];
$L__BB290_16:
	add.rn.f32 	%f17, %f14, %f161;
	mov.f32 	%f162, %f17;
	@%p3 bra 	$L__BB290_18;
	st.shared.f32 	[%rd4], %f17;
	mov.f32 	%f162, %f160;
$L__BB290_18:
	shfl.sync.down.b32	%f19, %f17, 2, 31, -1;
	mov.f32 	%f163, %f162;
	@%p3 bra 	$L__BB290_20;
	ld.shared.f32 	%f163, [%rd4];
$L__BB290_20:
	add.rn.f32 	%f22, %f19, %f163;
	mov.f32 	%f165, %f22;
	@%p3 bra 	$L__BB290_22;
	st.shared.f32 	[%rd4], %f22;
	mov.f32 	%f165, %f162;
$L__BB290_22:
	shfl.sync.down.b32	%f24, %f22, 1, 31, -1;
	@%p3 bra 	$L__BB290_24;
	ld.shared.f32 	%f165, [%rd4];
$L__BB290_24:
	add.rn.f32 	%f27, %f24, %f165;
	@%p3 bra 	$L__BB290_26;
	st.shared.f32 	[%rd4], %f27;
$L__BB290_26:
	setp.ne.s32 	%p14, %r1, 0;
	@%p14 bra 	$L__BB290_2;
	ld.param.u64 	%rd7, [input_multiply_reduce_fusion_13_param_4];
	cvta.to.global.u64 	%rd1, %rd7;
	cvt.u64.u32 	%rd2, %r3;
	shl.b64 	%rd87, %rd2, 2;
	add.s64 	%rd5, %rd1, %rd87;
	st.global.f32 	[%rd5], %f27;
$L__BB290_2:
	ret;

}
	// .globl	loop_add_fusion_385
.visible .entry loop_add_fusion_385(
	.param .u64 loop_add_fusion_385_param_0,
	.param .u64 loop_add_fusion_385_param_1,
	.param .u64 loop_add_fusion_385_param_2,
	.param .u64 loop_add_fusion_385_param_3,
	.param .u64 loop_add_fusion_385_param_4,
	.param .u64 loop_add_fusion_385_param_5,
	.param .u64 loop_add_fusion_385_param_6,
	.param .u64 loop_add_fusion_385_param_7,
	.param .u64 loop_add_fusion_385_param_8,
	.param .u64 loop_add_fusion_385_param_9,
	.param .u64 loop_add_fusion_385_param_10,
	.param .u64 loop_add_fusion_385_param_11,
	.param .u64 loop_add_fusion_385_param_12,
	.param .u64 loop_add_fusion_385_param_13,
	.param .u64 loop_add_fusion_385_param_14,
	.param .u64 loop_add_fusion_385_param_15,
	.param .u64 loop_add_fusion_385_param_16,
	.param .u64 loop_add_fusion_385_param_17,
	.param .u64 loop_add_fusion_385_param_18,
	.param .u64 loop_add_fusion_385_param_19
)
.reqntid 64, 1, 1
{
	.reg .b32 	%r<4>;
	.reg .f32 	%f<62>;
	.reg .b64 	%rd<52>;

	ld.param.u64 	%rd1, [loop_add_fusion_385_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_385_param_19];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_385_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_385_param_18];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_385_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_385_param_17];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_385_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_385_param_16];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_385_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_385_param_15];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_385_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_385_param_14];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_385_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_385_param_13];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_385_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_385_param_12];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_add_fusion_385_param_8];
	ld.param.u64 	%rd26, [loop_add_fusion_385_param_11];
	cvta.to.global.u64 	%rd27, %rd26;
	ld.param.u64 	%rd28, [loop_add_fusion_385_param_9];
	ld.param.u64 	%rd29, [loop_add_fusion_385_param_10];
	cvta.to.global.u64 	%rd30, %rd29;
	cvta.to.global.u64 	%rd31, %rd28;
	cvta.to.global.u64 	%rd32, %rd25;
	cvta.to.global.u64 	%rd33, %rd22;
	cvta.to.global.u64 	%rd34, %rd19;
	cvta.to.global.u64 	%rd35, %rd16;
	cvta.to.global.u64 	%rd36, %rd13;
	cvta.to.global.u64 	%rd37, %rd10;
	cvta.to.global.u64 	%rd38, %rd7;
	cvta.to.global.u64 	%rd39, %rd4;
	cvta.to.global.u64 	%rd40, %rd1;
	mov.u32 	%r1, %tid.x;
	mul.wide.u32 	%rd41, %r1, 4;
	add.s64 	%rd42, %rd40, %rd41;
	ld.global.nc.f32 	%f1, [%rd42];
	ld.global.nc.f32 	%f2, [%rd39];
	ld.global.nc.f32 	%f3, [%rd9];
	add.s64 	%rd43, %rd30, %rd41;
	ld.global.f32 	%f4, [%rd43];
	add.s64 	%rd44, %rd24, %rd41;
	ld.global.nc.f32 	%f5, [%rd44];
	add.s64 	%rd45, %rd21, %rd41;
	ld.global.nc.f32 	%f6, [%rd45];
	mov.f32 	%f7, 0f3F800000;
	sub.rn.f32 	%f8, %f7, %f6;
	add.s64 	%rd46, %rd27, %rd41;
	ld.global.nc.f32 	%f9, [%rd46];
	div.full.f32 	%f10, %f8, %f9;
	sqrt.approx.f32 	%f11, %f10;
	mov.f32 	%f12, 0f3F000000;
	div.full.f32 	%f13, %f12, %f11;
	mul.rn.f32 	%f14, %f13, %f5;
	div.full.f32 	%f15, %f14, %f9;
	add.s64 	%rd47, %rd31, %rd41;
	ld.global.nc.f32 	%f16, [%rd47];
	add.rn.f32 	%f17, %f16, %f16;
	mul.rn.f32 	%f18, %f17, %f15;
	sub.rn.f32 	%f19, %f4, %f18;
	neg.f32 	%f20, %f19;
	mul.rn.f32 	%f21, %f16, %f20;
	fma.rn.f32 	%f22, %f1, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f23, %f22;
	mov.f32 	%f24, 0f4B400001;
	mov.f32 	%f25, 0f437C0000;
	fma.rm.f32 	%f26, %f23, %f25, %f24;
	add.rn.f32 	%f27, %f26, 0fCB40007F;
	neg.f32 	%f28, %f27;
	fma.rn.f32 	%f29, %f1, 0f3FB8AA3B, %f28;
	fma.rn.f32 	%f30, %f1, 0f32A57060, %f29;
	mov.b32 	%r2, %f26;
	shl.b32 	%r3, %r2, 23;
	mov.b32 	%f31, %r3;
	ex2.approx.ftz.f32 	%f32, %f30;
	mul.rn.f32 	%f33, %f32, %f31;
	mul.rn.f32 	%f34, %f33, %f21;
	mul.rn.f32 	%f35, %f3, %f34;
	ld.global.nc.f32 	%f36, [%rd12];
	add.s64 	%rd48, %rd15, %rd41;
	ld.global.nc.f32 	%f37, [%rd48];
	mul.rn.f32 	%f38, %f36, %f37;
	add.rn.f32 	%f39, %f38, %f35;
	ld.global.nc.f32 	%f40, [%rd37];
	ld.global.nc.f32 	%f41, [%rd18];
	mul.rn.f32 	%f42, %f34, %f34;
	mul.rn.f32 	%f43, %f41, %f42;
	ld.global.nc.f32 	%f44, [%rd32];
	add.s64 	%rd49, %rd33, %rd41;
	ld.global.nc.f32 	%f45, [%rd49];
	mul.rn.f32 	%f46, %f44, %f45;
	add.rn.f32 	%f47, %f43, %f46;
	ld.global.nc.f32 	%f48, [%rd34];
	div.full.f32 	%f49, %f47, %f48;
	ld.global.nc.f32 	%f50, [%rd35];
	add.rn.f32 	%f51, %f50, %f49;
	sqrt.approx.f32 	%f52, %f51;
	ld.global.nc.f32 	%f53, [%rd36];
	add.rn.f32 	%f54, %f52, %f53;
	mul.rn.f32 	%f55, %f40, %f54;
	div.full.f32 	%f56, %f39, %f55;
	ld.global.nc.f32 	%f57, [%rd38];
	mul.rn.f32 	%f58, %f1, %f57;
	add.rn.f32 	%f59, %f58, %f56;
	mul.rn.f32 	%f60, %f2, %f59;
	add.rn.f32 	%f61, %f1, %f60;
	add.s64 	%rd50, %rd6, %rd41;
	st.global.f32 	[%rd50], %f61;
	add.s64 	%rd51, %rd3, %rd41;
	st.global.f32 	[%rd51], %f47;
	st.global.f32 	[%rd43], %f39;
	ret;

}
	// .globl	input_reduce_fusion_347
.visible .entry input_reduce_fusion_347(
	.param .u64 input_reduce_fusion_347_param_0,
	.param .u64 input_reduce_fusion_347_param_1,
	.param .u64 input_reduce_fusion_347_param_2
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<29>;
	.reg .f32 	%f<48>;
	.reg .b64 	%rd<44>;
	// demoted variable
	.shared .align 4 .b8 shared_cache57[4224];
	ld.param.u64 	%rd14, [input_reduce_fusion_347_param_0];
	ld.param.u64 	%rd15, [input_reduce_fusion_347_param_2];
	ld.param.u64 	%rd16, [input_reduce_fusion_347_param_1];
	cvta.to.global.u64 	%rd2, %rd16;
	cvta.to.global.u64 	%rd17, %rd14;
	mov.u32 	%r16, %tid.x;
	mov.u32 	%r1, %ctaid.x;
	shr.u32 	%r2, %r16, 5;
	and.b32  	%r3, %r16, 31;
	shr.u32 	%r4, %r1, 4;
	shl.b32 	%r17, %r1, 5;
	and.b32  	%r5, %r17, 480;
	or.b32  	%r18, %r5, %r3;
	cvt.u64.u32 	%rd3, %r18;
	mul.wide.u32 	%rd18, %r18, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.nc.f32 	%f1, [%rd19];
	mov.b32 	%r19, 399;
	sub.s32 	%r20, %r19, %r2;
	shr.u32 	%r21, %r20, 5;
	add.s32 	%r22, %r21, 1;
	and.b32  	%r25, %r22, 7;
	setp.ne.s32 	%p1, %r25, 0;
	@%p1 bra 	$L__BB292_2;
	bra.uni 	$L__BB292_1;
$L__BB292_2:
	mul.lo.s32 	%r6, %r4, 400;
	add.s32 	%r23, %r2, %r6;
	mul.wide.u32 	%rd20, %r23, 2048;
	shl.b64 	%rd42, %rd3, 2;
	or.b64  	%rd21, %rd20, %rd42;
	add.s64 	%rd41, %rd2, %rd21;
	mov.f32 	%f46, 0f00000000;
	mov.u32 	%r27, %r2;
$L__BB292_3:
	.pragma "nounroll";
	add.s32 	%r27, %r27, 32;
	ld.global.nc.f32 	%f9, [%rd41];
	mul.rn.f32 	%f10, %f9, %f1;
	add.rn.f32 	%f46, %f46, %f10;
	add.s64 	%rd41, %rd41, 65536;
	add.s32 	%r25, %r25, -1;
	setp.ne.s32 	%p2, %r25, 0;
	@%p2 bra 	$L__BB292_3;
	bra.uni 	$L__BB292_4;
$L__BB292_1:
	shl.b64 	%rd42, %rd3, 2;
	mov.f32 	%f46, 0f00000000;
	mov.u32 	%r27, %r2;
$L__BB292_4:
	cvta.to.global.u64 	%rd1, %rd15;
	add.s32 	%r28, %r27, -256;
	cvt.u64.u32 	%rd22, %r1;
	shr.u64 	%rd23, %rd22, 4;
	mul.lo.s64 	%rd24, %rd23, 819200;
	mul.wide.u32 	%rd25, %r27, 2048;
	add.s64 	%rd26, %rd24, %rd25;
	or.b64  	%rd27, %rd26, %rd42;
	add.s64 	%rd28, %rd27, %rd2;
	add.s64 	%rd43, %rd28, 262144;
$L__BB292_5:
	ld.global.nc.f32 	%f12, [%rd43+-262144];
	mul.rn.f32 	%f13, %f12, %f1;
	add.rn.f32 	%f14, %f46, %f13;
	ld.global.nc.f32 	%f15, [%rd43+-196608];
	mul.rn.f32 	%f16, %f15, %f1;
	add.rn.f32 	%f17, %f14, %f16;
	ld.global.nc.f32 	%f18, [%rd43+-131072];
	mul.rn.f32 	%f19, %f18, %f1;
	add.rn.f32 	%f20, %f17, %f19;
	ld.global.nc.f32 	%f21, [%rd43+-65536];
	mul.rn.f32 	%f22, %f21, %f1;
	add.rn.f32 	%f23, %f20, %f22;
	ld.global.nc.f32 	%f24, [%rd43];
	mul.rn.f32 	%f25, %f24, %f1;
	add.rn.f32 	%f26, %f23, %f25;
	ld.global.nc.f32 	%f27, [%rd43+65536];
	mul.rn.f32 	%f28, %f27, %f1;
	add.rn.f32 	%f29, %f26, %f28;
	ld.global.nc.f32 	%f30, [%rd43+131072];
	mul.rn.f32 	%f31, %f30, %f1;
	add.rn.f32 	%f32, %f29, %f31;
	ld.global.nc.f32 	%f33, [%rd43+196608];
	mul.rn.f32 	%f34, %f33, %f1;
	add.rn.f32 	%f46, %f32, %f34;
	add.s32 	%r28, %r28, 256;
	add.s64 	%rd43, %rd43, 524288;
	setp.lt.u32 	%p3, %r28, 144;
	@%p3 bra 	$L__BB292_5;
	mul.wide.u32 	%rd29, %r3, 132;
	mov.u64 	%rd30, shared_cache57;
	add.s64 	%rd31, %rd30, %rd29;
	mul.wide.u32 	%rd32, %r2, 4;
	add.s64 	%rd33, %rd31, %rd32;
	st.shared.f32 	[%rd33], %f46;
	bar.sync 	0;
	mul.wide.u32 	%rd34, %r2, 132;
	add.s64 	%rd35, %rd30, %rd34;
	mul.wide.u32 	%rd36, %r3, 4;
	add.s64 	%rd37, %rd35, %rd36;
	ld.shared.f32 	%f35, [%rd37];
	shfl.sync.down.b32	%f36, %f35, 16, 31, -1;
	add.rn.f32 	%f37, %f35, %f36;
	shfl.sync.down.b32	%f38, %f37, 8, 31, -1;
	add.rn.f32 	%f39, %f37, %f38;
	shfl.sync.down.b32	%f40, %f39, 4, 31, -1;
	add.rn.f32 	%f41, %f39, %f40;
	shfl.sync.down.b32	%f42, %f41, 2, 31, -1;
	add.rn.f32 	%f43, %f41, %f42;
	shfl.sync.down.b32	%f44, %f43, 1, 31, -1;
	add.rn.f32 	%f7, %f43, %f44;
	st.shared.f32 	[%rd37], %f7;
	setp.ne.s32 	%p4, %r3, 0;
	@%p4 bra 	$L__BB292_8;
	or.b32  	%r24, %r5, %r2;
	mul.wide.u32 	%rd38, %r4, 2048;
	add.s64 	%rd39, %rd1, %rd38;
	mul.wide.u32 	%rd40, %r24, 4;
	add.s64 	%rd13, %rd39, %rd40;
	st.global.f32 	[%rd13], %f7;
$L__BB292_8:
	ret;

}
	// .globl	input_reduce_fusion_348
.visible .entry input_reduce_fusion_348(
	.param .u64 input_reduce_fusion_348_param_0,
	.param .u64 input_reduce_fusion_348_param_1,
	.param .u64 input_reduce_fusion_348_param_2,
	.param .u64 input_reduce_fusion_348_param_3,
	.param .u64 input_reduce_fusion_348_param_4
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<5>;
	.reg .b32 	%r<42>;
	.reg .f32 	%f<68>;
	.reg .b64 	%rd<100>;
	// demoted variable
	.shared .align 4 .b8 shared_cache58[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache59[4224];
	ld.param.u64 	%rd27, [input_reduce_fusion_348_param_0];
	ld.param.u64 	%rd28, [input_reduce_fusion_348_param_4];
	ld.param.u64 	%rd29, [input_reduce_fusion_348_param_1];
	ld.param.u64 	%rd30, [input_reduce_fusion_348_param_3];
	ld.param.u64 	%rd31, [input_reduce_fusion_348_param_2];
	cvta.to.global.u64 	%rd32, %rd31;
	cvta.to.global.u64 	%rd3, %rd29;
	cvta.to.global.u64 	%rd4, %rd27;
	mov.u32 	%r15, %tid.x;
	mov.u32 	%r1, %ctaid.x;
	shr.u32 	%r2, %r15, 5;
	and.b32  	%r3, %r15, 31;
	shr.u32 	%r4, %r1, 4;
	shl.b32 	%r16, %r1, 5;
	and.b32  	%r5, %r16, 480;
	or.b32  	%r17, %r5, %r3;
	mul.lo.s32 	%r6, %r4, 400;
	cvt.u64.u32 	%rd5, %r17;
	mul.wide.u32 	%rd33, %r17, 4;
	add.s64 	%rd34, %rd32, %rd33;
	ld.global.nc.f32 	%f1, [%rd34];
	mov.b32 	%r18, 399;
	sub.s32 	%r19, %r18, %r2;
	shr.u32 	%r20, %r19, 5;
	add.s32 	%r21, %r20, 1;
	and.b32  	%r38, %r21, 3;
	setp.ne.s32 	%p1, %r38, 0;
	shl.b64 	%rd98, %rd5, 2;
	@%p1 bra 	$L__BB293_2;
	bra.uni 	$L__BB293_1;
$L__BB293_2:
	cvt.u16.u32 	%rs1, %r4;
	mul.lo.s16 	%rs2, %rs1, 400;
	cvt.u16.u32 	%rs3, %r2;
	add.s16 	%rs4, %rs2, %rs3;
	cvt.u32.u16 	%r22, %rs4;
	and.b32  	%r23, %r22, 1023;
	mul.wide.u32 	%rd35, %r23, 2048;
	or.b64  	%rd36, %rd35, %rd98;
	add.s64 	%rd97, %rd3, %rd36;
	add.s32 	%r24, %r2, %r6;
	cvt.u64.u32 	%rd96, %r24;
	mul.wide.u32 	%rd37, %r24, 2048;
	or.b64  	%rd38, %rd37, %rd98;
	add.s64 	%rd95, %rd4, %rd38;
	mov.f32 	%f64, 0f00000000;
	mov.u32 	%r40, %r2;
	mov.f32 	%f65, %f64;
$L__BB293_3:
	.pragma "nounroll";
	add.s32 	%r40, %r40, 32;
	shl.b64 	%rd39, %rd96, 11;
	and.b64  	%rd40, %rd39, -2097152;
	add.s64 	%rd41, %rd97, %rd40;
	ld.global.nc.f32 	%f15, [%rd95];
	add.rn.f32 	%f65, %f65, %f15;
	ld.global.nc.f32 	%f16, [%rd41];
	sub.rn.f32 	%f17, %f16, %f1;
	mul.rn.f32 	%f18, %f15, %f17;
	add.rn.f32 	%f64, %f64, %f18;
	add.s64 	%rd97, %rd97, 65536;
	add.s64 	%rd96, %rd96, 32;
	add.s64 	%rd95, %rd95, 65536;
	add.s32 	%r38, %r38, -1;
	setp.ne.s32 	%p2, %r38, 0;
	@%p2 bra 	$L__BB293_3;
	bra.uni 	$L__BB293_4;
$L__BB293_1:
	mov.f32 	%f64, 0f00000000;
	mov.u32 	%r40, %r2;
	mov.f32 	%f65, %f64;
$L__BB293_4:
	cvta.to.global.u64 	%rd1, %rd28;
	cvta.to.global.u64 	%rd2, %rd30;
	cvt.u64.u32 	%rd42, %r1;
	shr.u64 	%rd43, %rd42, 4;
	mul.lo.s64 	%rd44, %rd43, 819200;
	mul.wide.u32 	%rd45, %r40, 2048;
	add.s64 	%rd46, %rd44, %rd45;
	or.b64  	%rd47, %rd46, %rd98;
	add.s64 	%rd48, %rd47, %rd4;
	add.s64 	%rd99, %rd48, 131072;
$L__BB293_5:
	add.s32 	%r25, %r6, %r40;
	ld.global.nc.f32 	%f20, [%rd99+-131072];
	add.rn.f32 	%f21, %f65, %f20;
	and.b32  	%r26, %r25, 1023;
	shr.u32 	%r27, %r25, 10;
	mul.wide.u32 	%rd49, %r27, 2097152;
	add.s64 	%rd50, %rd3, %rd49;
	mul.wide.u32 	%rd51, %r26, 2048;
	add.s64 	%rd52, %rd50, %rd51;
	add.s64 	%rd54, %rd52, %rd98;
	ld.global.nc.f32 	%f22, [%rd54];
	sub.rn.f32 	%f23, %f22, %f1;
	mul.rn.f32 	%f24, %f20, %f23;
	add.rn.f32 	%f25, %f64, %f24;
	add.s32 	%r28, %r25, 32;
	ld.global.nc.f32 	%f26, [%rd99+-65536];
	add.rn.f32 	%f27, %f21, %f26;
	and.b32  	%r29, %r28, 1023;
	shr.u32 	%r30, %r28, 10;
	mul.wide.u32 	%rd55, %r30, 2097152;
	add.s64 	%rd56, %rd3, %rd55;
	mul.wide.u32 	%rd57, %r29, 2048;
	add.s64 	%rd58, %rd56, %rd57;
	add.s64 	%rd59, %rd58, %rd98;
	ld.global.nc.f32 	%f28, [%rd59];
	sub.rn.f32 	%f29, %f28, %f1;
	mul.rn.f32 	%f30, %f26, %f29;
	add.rn.f32 	%f31, %f25, %f30;
	add.s32 	%r31, %r25, 64;
	ld.global.nc.f32 	%f32, [%rd99];
	add.rn.f32 	%f33, %f27, %f32;
	and.b32  	%r32, %r31, 1023;
	shr.u32 	%r33, %r31, 10;
	mul.wide.u32 	%rd60, %r33, 2097152;
	add.s64 	%rd61, %rd3, %rd60;
	mul.wide.u32 	%rd62, %r32, 2048;
	add.s64 	%rd63, %rd61, %rd62;
	add.s64 	%rd64, %rd63, %rd98;
	ld.global.nc.f32 	%f34, [%rd64];
	sub.rn.f32 	%f35, %f34, %f1;
	mul.rn.f32 	%f36, %f32, %f35;
	add.rn.f32 	%f37, %f31, %f36;
	add.s32 	%r14, %r40, 128;
	add.s32 	%r34, %r25, 96;
	ld.global.nc.f32 	%f38, [%rd99+65536];
	add.rn.f32 	%f65, %f33, %f38;
	and.b32  	%r35, %r34, 1023;
	shr.u32 	%r36, %r34, 10;
	mul.wide.u32 	%rd65, %r36, 2097152;
	add.s64 	%rd66, %rd3, %rd65;
	mul.wide.u32 	%rd67, %r35, 2048;
	add.s64 	%rd68, %rd66, %rd67;
	add.s64 	%rd69, %rd68, %rd98;
	ld.global.nc.f32 	%f39, [%rd69];
	sub.rn.f32 	%f40, %f39, %f1;
	mul.rn.f32 	%f41, %f38, %f40;
	add.rn.f32 	%f64, %f37, %f41;
	add.s64 	%rd99, %rd99, 262144;
	setp.lt.u32 	%p3, %r40, 272;
	mov.u32 	%r40, %r14;
	@%p3 bra 	$L__BB293_5;
	cvt.u64.u32 	%rd21, %r3;
	cvt.u64.u32 	%rd22, %r2;
	mul.wide.u32 	%rd70, %r3, 132;
	mov.u64 	%rd71, shared_cache58;
	add.s64 	%rd72, %rd71, %rd70;
	mul.wide.u32 	%rd73, %r2, 4;
	add.s64 	%rd74, %rd72, %rd73;
	st.shared.f32 	[%rd74], %f65;
	bar.sync 	0;
	mul.wide.u32 	%rd75, %r2, 132;
	add.s64 	%rd76, %rd71, %rd75;
	mul.wide.u32 	%rd77, %r3, 4;
	add.s64 	%rd78, %rd76, %rd77;
	ld.shared.f32 	%f42, [%rd78];
	shfl.sync.down.b32	%f43, %f42, 16, 31, -1;
	add.rn.f32 	%f44, %f42, %f43;
	shfl.sync.down.b32	%f45, %f44, 8, 31, -1;
	add.rn.f32 	%f46, %f44, %f45;
	shfl.sync.down.b32	%f47, %f46, 4, 31, -1;
	add.rn.f32 	%f48, %f46, %f47;
	shfl.sync.down.b32	%f49, %f48, 2, 31, -1;
	add.rn.f32 	%f50, %f48, %f49;
	shfl.sync.down.b32	%f51, %f50, 1, 31, -1;
	add.rn.f32 	%f12, %f50, %f51;
	st.shared.f32 	[%rd78], %f12;
	setp.eq.s32 	%p4, %r3, 0;
	or.b32  	%r37, %r5, %r2;
	@%p4 bra 	$L__BB293_9;
	bra.uni 	$L__BB293_7;
$L__BB293_9:
	mul.wide.u32 	%rd79, %r4, 2048;
	add.s64 	%rd80, %rd2, %rd79;
	mul.wide.u32 	%rd81, %r37, 4;
	add.s64 	%rd25, %rd80, %rd81;
	st.global.f32 	[%rd25], %f12;
$L__BB293_7:
	mul.lo.s64 	%rd82, %rd21, 132;
	mov.u64 	%rd83, shared_cache59;
	add.s64 	%rd84, %rd83, %rd82;
	shl.b64 	%rd85, %rd22, 2;
	add.s64 	%rd86, %rd84, %rd85;
	st.shared.f32 	[%rd86], %f64;
	bar.sync 	0;
	mul.lo.s64 	%rd87, %rd22, 132;
	add.s64 	%rd88, %rd83, %rd87;
	shl.b64 	%rd89, %rd21, 2;
	add.s64 	%rd90, %rd88, %rd89;
	ld.shared.f32 	%f52, [%rd90];
	shfl.sync.down.b32	%f53, %f52, 16, 31, -1;
	add.rn.f32 	%f54, %f52, %f53;
	shfl.sync.down.b32	%f55, %f54, 8, 31, -1;
	add.rn.f32 	%f56, %f54, %f55;
	shfl.sync.down.b32	%f57, %f56, 4, 31, -1;
	add.rn.f32 	%f58, %f56, %f57;
	shfl.sync.down.b32	%f59, %f58, 2, 31, -1;
	add.rn.f32 	%f60, %f58, %f59;
	shfl.sync.down.b32	%f61, %f60, 1, 31, -1;
	add.rn.f32 	%f13, %f60, %f61;
	st.shared.f32 	[%rd90], %f13;
	@%p4 bra 	$L__BB293_10;
	bra.uni 	$L__BB293_8;
$L__BB293_10:
	cvt.u64.u32 	%rd23, %r4;
	cvt.u64.u32 	%rd24, %r37;
	shl.b64 	%rd91, %rd23, 11;
	add.s64 	%rd92, %rd1, %rd91;
	shl.b64 	%rd93, %rd24, 2;
	add.s64 	%rd26, %rd92, %rd93;
	st.global.f32 	[%rd26], %f13;
$L__BB293_8:
	ret;

}
	// .globl	input_reduce_fusion_349
.visible .entry input_reduce_fusion_349(
	.param .u64 input_reduce_fusion_349_param_0,
	.param .u64 input_reduce_fusion_349_param_1,
	.param .u64 input_reduce_fusion_349_param_2,
	.param .u64 input_reduce_fusion_349_param_3
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<19>;
	.reg .f32 	%f<36>;
	.reg .b64 	%rd<49>;
	// demoted variable
	.shared .align 4 .b8 shared_cache60[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache61[4224];
	mov.u32 	%r11, %ctaid.y;
	and.b32  	%r12, %r11, 1;
	setp.eq.b32 	%p1, %r12, 1;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r13, %ctaid.x;
	shr.u32 	%r2, %r1, 5;
	and.b32  	%r3, %r1, 31;
	shl.b32 	%r4, %r13, 5;
	@%p1 bra 	$L__BB294_6;
	bra.uni 	$L__BB294_1;
$L__BB294_6:
	ld.param.u64 	%rd13, [input_reduce_fusion_349_param_3];
	cvta.to.global.u64 	%rd46, %rd13;
	ld.param.u64 	%rd14, [input_reduce_fusion_349_param_1];
	cvta.to.global.u64 	%rd3, %rd14;
	add.s32 	%r18, %r2, -32;
	cvt.u64.u32 	%rd30, %r1;
	shl.b64 	%rd31, %rd30, 6;
	and.b64  	%rd32, %rd31, 274877904896;
	add.s32 	%r15, %r4, %r3;
	mul.wide.u32 	%rd33, %r15, 4;
	add.s64 	%rd34, %rd32, %rd33;
	add.s64 	%rd48, %rd3, %rd34;
	mov.f32 	%f35, 0f00000000;
$L__BB294_7:
	ld.global.nc.f32 	%f22, [%rd48];
	add.rn.f32 	%f35, %f35, %f22;
	add.s32 	%r18, %r18, 32;
	add.s64 	%rd48, %rd48, 65536;
	setp.lt.u32 	%p4, %r18, 96;
	@%p4 bra 	$L__BB294_7;
	mul.wide.u32 	%rd35, %r3, 132;
	mov.u64 	%rd36, shared_cache61;
	add.s64 	%rd37, %rd36, %rd35;
	mul.wide.u32 	%rd38, %r2, 4;
	add.s64 	%rd39, %rd37, %rd38;
	st.shared.f32 	[%rd39], %f35;
	bar.sync 	0;
	mul.wide.u32 	%rd40, %r2, 132;
	add.s64 	%rd41, %rd36, %rd40;
	mul.wide.u32 	%rd42, %r3, 4;
	add.s64 	%rd43, %rd41, %rd42;
	ld.shared.f32 	%f23, [%rd43];
	shfl.sync.down.b32	%f24, %f23, 16, 31, -1;
	add.rn.f32 	%f25, %f23, %f24;
	shfl.sync.down.b32	%f26, %f25, 8, 31, -1;
	add.rn.f32 	%f27, %f25, %f26;
	shfl.sync.down.b32	%f28, %f27, 4, 31, -1;
	add.rn.f32 	%f29, %f27, %f28;
	shfl.sync.down.b32	%f30, %f29, 2, 31, -1;
	add.rn.f32 	%f31, %f29, %f30;
	shfl.sync.down.b32	%f32, %f31, 1, 31, -1;
	add.rn.f32 	%f7, %f31, %f32;
	st.shared.f32 	[%rd43], %f7;
	setp.ne.s32 	%p5, %r3, 0;
	@%p5 bra 	$L__BB294_5;
	neg.f32 	%f33, %f7;
	bra.uni 	$L__BB294_4;
$L__BB294_1:
	ld.param.u64 	%rd12, [input_reduce_fusion_349_param_0];
	ld.param.u64 	%rd15, [input_reduce_fusion_349_param_2];
	cvta.to.global.u64 	%rd46, %rd15;
	cvta.to.global.u64 	%rd4, %rd12;
	add.s32 	%r17, %r2, -32;
	cvt.u64.u32 	%rd16, %r1;
	shl.b64 	%rd17, %rd16, 6;
	and.b64  	%rd18, %rd17, 274877904896;
	add.s32 	%r14, %r4, %r3;
	mul.wide.u32 	%rd19, %r14, 4;
	add.s64 	%rd20, %rd18, %rd19;
	add.s64 	%rd47, %rd4, %rd20;
	mov.f32 	%f34, 0f00000000;
$L__BB294_2:
	ld.global.nc.f32 	%f10, [%rd47];
	add.rn.f32 	%f34, %f34, %f10;
	add.s32 	%r17, %r17, 32;
	add.s64 	%rd47, %rd47, 65536;
	setp.lt.u32 	%p2, %r17, 96;
	@%p2 bra 	$L__BB294_2;
	mul.wide.u32 	%rd21, %r3, 132;
	mov.u64 	%rd22, shared_cache60;
	add.s64 	%rd23, %rd22, %rd21;
	mul.wide.u32 	%rd24, %r2, 4;
	add.s64 	%rd25, %rd23, %rd24;
	st.shared.f32 	[%rd25], %f34;
	bar.sync 	0;
	mul.wide.u32 	%rd26, %r2, 132;
	add.s64 	%rd27, %rd22, %rd26;
	mul.wide.u32 	%rd28, %r3, 4;
	add.s64 	%rd29, %rd27, %rd28;
	ld.shared.f32 	%f11, [%rd29];
	shfl.sync.down.b32	%f12, %f11, 16, 31, -1;
	add.rn.f32 	%f13, %f11, %f12;
	shfl.sync.down.b32	%f14, %f13, 8, 31, -1;
	add.rn.f32 	%f15, %f13, %f14;
	shfl.sync.down.b32	%f16, %f15, 4, 31, -1;
	add.rn.f32 	%f17, %f15, %f16;
	shfl.sync.down.b32	%f18, %f17, 2, 31, -1;
	add.rn.f32 	%f19, %f17, %f18;
	shfl.sync.down.b32	%f20, %f19, 1, 31, -1;
	add.rn.f32 	%f33, %f19, %f20;
	st.shared.f32 	[%rd29], %f33;
	setp.eq.s32 	%p3, %r3, 0;
	@%p3 bra 	$L__BB294_4;
	bra.uni 	$L__BB294_5;
$L__BB294_4:
	or.b32  	%r16, %r4, %r2;
	mul.wide.u32 	%rd44, %r16, 4;
	add.s64 	%rd45, %rd46, %rd44;
	st.global.f32 	[%rd45], %f33;
$L__BB294_5:
	ret;

}
	// .globl	loop_add_multiply_fusion_20
.visible .entry loop_add_multiply_fusion_20(
	.param .u64 loop_add_multiply_fusion_20_param_0,
	.param .u64 loop_add_multiply_fusion_20_param_1,
	.param .u64 loop_add_multiply_fusion_20_param_2,
	.param .u64 loop_add_multiply_fusion_20_param_3,
	.param .u64 loop_add_multiply_fusion_20_param_4,
	.param .u64 loop_add_multiply_fusion_20_param_5,
	.param .u64 loop_add_multiply_fusion_20_param_6,
	.param .u64 loop_add_multiply_fusion_20_param_7,
	.param .u64 loop_add_multiply_fusion_20_param_8,
	.param .u64 loop_add_multiply_fusion_20_param_9,
	.param .u64 loop_add_multiply_fusion_20_param_10,
	.param .u64 loop_add_multiply_fusion_20_param_11,
	.param .u64 loop_add_multiply_fusion_20_param_12,
	.param .u64 loop_add_multiply_fusion_20_param_13,
	.param .u64 loop_add_multiply_fusion_20_param_14,
	.param .u64 loop_add_multiply_fusion_20_param_15,
	.param .u64 loop_add_multiply_fusion_20_param_16,
	.param .u64 loop_add_multiply_fusion_20_param_17,
	.param .u64 loop_add_multiply_fusion_20_param_18,
	.param .u64 loop_add_multiply_fusion_20_param_19,
	.param .u64 loop_add_multiply_fusion_20_param_20,
	.param .u64 loop_add_multiply_fusion_20_param_21,
	.param .u64 loop_add_multiply_fusion_20_param_22,
	.param .u64 loop_add_multiply_fusion_20_param_23,
	.param .u64 loop_add_multiply_fusion_20_param_24
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f32 	%f<66>;
	.reg .b64 	%rd<67>;

	ld.param.u64 	%rd1, [loop_add_multiply_fusion_20_param_0];
	ld.param.u64 	%rd2, [loop_add_multiply_fusion_20_param_24];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_multiply_fusion_20_param_1];
	ld.param.u64 	%rd5, [loop_add_multiply_fusion_20_param_23];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_multiply_fusion_20_param_2];
	ld.param.u64 	%rd8, [loop_add_multiply_fusion_20_param_22];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_multiply_fusion_20_param_3];
	ld.param.u64 	%rd11, [loop_add_multiply_fusion_20_param_21];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_multiply_fusion_20_param_4];
	ld.param.u64 	%rd14, [loop_add_multiply_fusion_20_param_20];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_multiply_fusion_20_param_5];
	ld.param.u64 	%rd17, [loop_add_multiply_fusion_20_param_19];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_multiply_fusion_20_param_6];
	ld.param.u64 	%rd20, [loop_add_multiply_fusion_20_param_18];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_multiply_fusion_20_param_7];
	ld.param.u64 	%rd23, [loop_add_multiply_fusion_20_param_17];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_add_multiply_fusion_20_param_8];
	ld.param.u64 	%rd26, [loop_add_multiply_fusion_20_param_16];
	cvta.to.global.u64 	%rd27, %rd26;
	ld.param.u64 	%rd28, [loop_add_multiply_fusion_20_param_9];
	ld.param.u64 	%rd29, [loop_add_multiply_fusion_20_param_15];
	cvta.to.global.u64 	%rd30, %rd29;
	ld.param.u64 	%rd31, [loop_add_multiply_fusion_20_param_10];
	ld.param.u64 	%rd32, [loop_add_multiply_fusion_20_param_14];
	cvta.to.global.u64 	%rd33, %rd32;
	ld.param.u64 	%rd34, [loop_add_multiply_fusion_20_param_11];
	ld.param.u64 	%rd35, [loop_add_multiply_fusion_20_param_13];
	cvta.to.global.u64 	%rd36, %rd35;
	ld.param.u64 	%rd37, [loop_add_multiply_fusion_20_param_12];
	cvta.to.global.u64 	%rd38, %rd37;
	cvta.to.global.u64 	%rd39, %rd34;
	cvta.to.global.u64 	%rd40, %rd31;
	cvta.to.global.u64 	%rd41, %rd28;
	cvta.to.global.u64 	%rd42, %rd25;
	cvta.to.global.u64 	%rd43, %rd22;
	cvta.to.global.u64 	%rd44, %rd19;
	cvta.to.global.u64 	%rd45, %rd16;
	cvta.to.global.u64 	%rd46, %rd13;
	cvta.to.global.u64 	%rd47, %rd10;
	cvta.to.global.u64 	%rd48, %rd7;
	cvta.to.global.u64 	%rd49, %rd4;
	cvta.to.global.u64 	%rd50, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	mul.wide.u32 	%rd51, %r4, 4;
	add.s64 	%rd52, %rd50, %rd51;
	ld.global.nc.f32 	%f1, [%rd52];
	ld.global.nc.f32 	%f2, [%rd49];
	ld.global.nc.f32 	%f3, [%rd33];
	add.s64 	%rd53, %rd40, %rd51;
	ld.global.nc.f32 	%f4, [%rd53+2048];
	ld.global.nc.f32 	%f5, [%rd53];
	mul.rn.f32 	%f6, %f5, %f5;
	sub.rn.f32 	%f7, %f4, %f6;
	max.NaN.f32 	%f8, %f7, 0f00000000;
	add.rn.f32 	%f9, %f8, 0f3727C5AC;
	rsqrt.approx.f32 	%f10, %f9;
	add.s64 	%rd54, %rd41, %rd51;
	ld.global.nc.f32 	%f11, [%rd54];
	mul.rn.f32 	%f12, %f10, %f11;
	mul.rn.f32 	%f13, %f3, %f12;
	ld.global.nc.f32 	%f14, [%rd36];
	add.s64 	%rd55, %rd38, %rd51;
	ld.global.nc.f32 	%f15, [%rd55];
	mul.rn.f32 	%f16, %f14, %f15;
	add.rn.f32 	%f17, %f13, %f16;
	ld.global.nc.f32 	%f18, [%rd48];
	ld.global.nc.f32 	%f19, [%rd39];
	mul.rn.f32 	%f20, %f12, %f12;
	mul.rn.f32 	%f21, %f20, %f19;
	ld.global.nc.f32 	%f22, [%rd42];
	add.s64 	%rd56, %rd43, %rd51;
	ld.global.nc.f32 	%f23, [%rd56];
	mul.rn.f32 	%f24, %f22, %f23;
	add.rn.f32 	%f25, %f21, %f24;
	ld.global.nc.f32 	%f26, [%rd44];
	div.full.f32 	%f27, %f25, %f26;
	ld.global.nc.f32 	%f28, [%rd45];
	add.rn.f32 	%f29, %f28, %f27;
	sqrt.approx.f32 	%f30, %f29;
	ld.global.nc.f32 	%f31, [%rd46];
	add.rn.f32 	%f32, %f30, %f31;
	mul.rn.f32 	%f33, %f18, %f32;
	div.full.f32 	%f34, %f17, %f33;
	ld.global.nc.f32 	%f35, [%rd47];
	mul.rn.f32 	%f36, %f1, %f35;
	add.rn.f32 	%f37, %f36, %f34;
	mul.rn.f32 	%f38, %f2, %f37;
	add.rn.f32 	%f39, %f1, %f38;
	div.full.f32 	%f40, %f10, %f9;
	mul.rn.f32 	%f41, %f40, 0fBF000000;
	setp.eq.f32 	%p1, %f7, %f8;
	selp.f32 	%f42, 0f3F800000, 0f00000000, %p1;
	setp.eq.f32 	%p2, %f8, 0f00000000;
	selp.f32 	%f43, 0f40000000, 0f3F800000, %p2;
	div.full.f32 	%f44, %f42, %f43;
	add.rn.f32 	%f45, %f5, %f5;
	mul.rn.f32 	%f46, %f11, %f1;
	mul.rn.f32 	%f47, %f41, %f46;
	mul.rn.f32 	%f48, %f44, %f47;
	mul.rn.f32 	%f49, %f45, %f48;
	add.s64 	%rd57, %rd30, %rd51;
	ld.global.nc.f32 	%f50, [%rd57];
	sub.rn.f32 	%f51, %f50, %f49;
	add.rn.f32 	%f52, %f51, 0f00000000;
	mul.rn.f32 	%f53, %f52, 0f3CA3D70A;
	mul.rn.f32 	%f54, %f53, 0f3A800000;
	add.rn.f32 	%f55, %f48, 0f00000000;
	mul.rn.f32 	%f56, %f55, 0f3CA3D70A;
	mul.rn.f32 	%f57, %f56, 0f3B000000;
	add.s64 	%rd58, %rd27, %rd51;
	ld.global.nc.f32 	%f58, [%rd58];
	mul.rn.f32 	%f59, %f58, 0f3F733333;
	mul.rn.f32 	%f60, %f5, 0f3D4CCCCD;
	add.rn.f32 	%f61, %f60, %f59;
	add.s64 	%rd59, %rd24, %rd51;
	ld.global.nc.f32 	%f62, [%rd59];
	mul.rn.f32 	%f63, %f62, 0f3F733333;
	mul.rn.f32 	%f64, %f8, 0f3D4CCCCD;
	add.rn.f32 	%f65, %f64, %f63;
	add.s64 	%rd60, %rd21, %rd51;
	st.global.f32 	[%rd60], %f39;
	add.s64 	%rd61, %rd18, %rd51;
	st.global.f32 	[%rd61], %f25;
	add.s64 	%rd62, %rd15, %rd51;
	st.global.f32 	[%rd62], %f17;
	add.s64 	%rd63, %rd12, %rd51;
	st.global.f32 	[%rd63], %f54;
	add.s64 	%rd64, %rd9, %rd51;
	st.global.f32 	[%rd64], %f57;
	add.s64 	%rd65, %rd6, %rd51;
	st.global.f32 	[%rd65], %f61;
	add.s64 	%rd66, %rd3, %rd51;
	st.global.f32 	[%rd66], %f65;
	ret;

}
	// .globl	loop_add_fusion_386
.visible .entry loop_add_fusion_386(
	.param .u64 loop_add_fusion_386_param_0,
	.param .u64 loop_add_fusion_386_param_1,
	.param .u64 loop_add_fusion_386_param_2,
	.param .u64 loop_add_fusion_386_param_3,
	.param .u64 loop_add_fusion_386_param_4,
	.param .u64 loop_add_fusion_386_param_5,
	.param .u64 loop_add_fusion_386_param_6
)
.reqntid 128, 1, 1
{
	.reg .b32 	%r<7>;
	.reg .f32 	%f<45>;
	.reg .b64 	%rd<26>;

	ld.param.u64 	%rd1, [loop_add_fusion_386_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_386_param_6];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_386_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_386_param_5];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_386_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_386_param_4];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_386_param_3];
	cvta.to.global.u64 	%rd11, %rd10;
	cvta.to.global.u64 	%rd12, %rd7;
	cvta.to.global.u64 	%rd13, %rd4;
	cvta.to.global.u64 	%rd14, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r3, 2;
	or.b32  	%r5, %r2, %r4;
	shr.u32 	%r6, %r1, 10;
	mul.wide.u32 	%rd15, %r6, 2048;
	add.s64 	%rd16, %rd14, %rd15;
	mul.wide.u32 	%rd17, %r4, 4;
	add.s64 	%rd18, %rd16, %rd17;
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd18];
	mul.wide.u32 	%rd19, %r5, 4;
	add.s64 	%rd20, %rd6, %rd19;
	ld.global.nc.v4.f32 	{%f5, %f6, %f7, %f8}, [%rd20];
	add.s64 	%rd21, %rd9, %rd17;
	ld.global.nc.v4.f32 	{%f9, %f10, %f11, %f12}, [%rd21];
	mul.rn.f32 	%f13, %f5, %f9;
	add.rn.f32 	%f14, %f1, %f13;
	add.s64 	%rd22, %rd13, %rd19;
	ld.global.nc.v4.f32 	{%f15, %f16, %f17, %f18}, [%rd22];
	add.s64 	%rd23, %rd12, %rd17;
	ld.global.nc.v4.f32 	{%f19, %f20, %f21, %f22}, [%rd23];
	mul.rn.f32 	%f23, %f15, %f19;
	add.rn.f32 	%f24, %f14, %f23;
	add.s64 	%rd24, %rd11, %rd17;
	ld.global.nc.v4.f32 	{%f25, %f26, %f27, %f28}, [%rd24];
	add.rn.f32 	%f29, %f25, %f24;
	add.s64 	%rd25, %rd3, %rd19;
	mul.rn.f32 	%f30, %f6, %f10;
	add.rn.f32 	%f31, %f2, %f30;
	mul.rn.f32 	%f32, %f16, %f20;
	add.rn.f32 	%f33, %f31, %f32;
	add.rn.f32 	%f34, %f26, %f33;
	mul.rn.f32 	%f35, %f7, %f11;
	add.rn.f32 	%f36, %f3, %f35;
	mul.rn.f32 	%f37, %f17, %f21;
	add.rn.f32 	%f38, %f36, %f37;
	add.rn.f32 	%f39, %f27, %f38;
	mul.rn.f32 	%f40, %f8, %f12;
	add.rn.f32 	%f41, %f4, %f40;
	mul.rn.f32 	%f42, %f18, %f22;
	add.rn.f32 	%f43, %f41, %f42;
	add.rn.f32 	%f44, %f28, %f43;
	st.global.v4.f32 	[%rd25], {%f29, %f34, %f39, %f44};
	ret;

}
	// .globl	input_multiply_reduce_fusion_14
.visible .entry input_multiply_reduce_fusion_14(
	.param .u64 input_multiply_reduce_fusion_14_param_0,
	.param .u64 input_multiply_reduce_fusion_14_param_1,
	.param .u64 input_multiply_reduce_fusion_14_param_2,
	.param .u64 input_multiply_reduce_fusion_14_param_3,
	.param .u64 input_multiply_reduce_fusion_14_param_4,
	.param .u64 input_multiply_reduce_fusion_14_param_5,
	.param .u64 input_multiply_reduce_fusion_14_param_6,
	.param .u64 input_multiply_reduce_fusion_14_param_7
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<19>;
	.reg .f32 	%f<43>;
	.reg .b64 	%rd<63>;
	// demoted variable
	.shared .align 4 .b8 shared_cache62[4224];
	ld.param.u64 	%rd12, [input_multiply_reduce_fusion_14_param_0];
	ld.param.u64 	%rd13, [input_multiply_reduce_fusion_14_param_7];
	cvta.to.global.u64 	%rd1, %rd13;
	ld.param.u64 	%rd14, [input_multiply_reduce_fusion_14_param_1];
	ld.param.u64 	%rd15, [input_multiply_reduce_fusion_14_param_6];
	cvta.to.global.u64 	%rd2, %rd15;
	ld.param.u64 	%rd16, [input_multiply_reduce_fusion_14_param_2];
	ld.param.u64 	%rd17, [input_multiply_reduce_fusion_14_param_5];
	cvta.to.global.u64 	%rd3, %rd17;
	ld.param.u64 	%rd18, [input_multiply_reduce_fusion_14_param_3];
	ld.param.u64 	%rd19, [input_multiply_reduce_fusion_14_param_4];
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvta.to.global.u64 	%rd6, %rd16;
	cvta.to.global.u64 	%rd20, %rd14;
	cvta.to.global.u64 	%rd21, %rd12;
	mov.u32 	%r8, %tid.x;
	mov.u32 	%r9, %ctaid.x;
	shr.u32 	%r1, %r8, 5;
	and.b32  	%r2, %r8, 31;
	shr.u32 	%r3, %r9, 4;
	shl.b32 	%r10, %r9, 5;
	and.b32  	%r4, %r10, 480;
	or.b32  	%r11, %r4, %r2;
	mul.lo.s32 	%r5, %r3, 400;
	cvt.u64.u32 	%rd7, %r11;
	mul.wide.u32 	%rd22, %r11, 4;
	add.s64 	%rd23, %rd20, %rd22;
	ld.global.nc.f32 	%f1, [%rd23];
	cvt.u64.u32 	%rd24, %r9;
	shr.u64 	%rd25, %rd24, 4;
	mul.lo.s64 	%rd26, %rd25, 819200;
	cvt.u64.u32 	%rd27, %r8;
	shl.b64 	%rd28, %rd27, 6;
	and.b64  	%rd29, %rd28, 274877904896;
	add.s64 	%rd30, %rd26, %rd29;
	or.b64  	%rd31, %rd30, %rd22;
	add.s64 	%rd62, %rd21, %rd31;
	mov.f32 	%f42, 0f00000000;
	mov.f32 	%f15, 0f4B400001;
	mov.f32 	%f16, 0f437C0000;
	mov.u32 	%r18, %r1;
$L__BB297_1:
	add.s32 	%r7, %r18, 32;
	add.s32 	%r12, %r5, %r18;
	and.b32  	%r13, %r12, 1023;
	shr.u32 	%r14, %r12, 10;
	mul.wide.u32 	%rd32, %r14, 2097152;
	add.s64 	%rd33, %rd6, %rd32;
	mul.wide.u32 	%rd34, %r13, 2048;
	add.s64 	%rd35, %rd33, %rd34;
	shl.b64 	%rd36, %rd7, 2;
	add.s64 	%rd37, %rd35, %rd36;
	ld.global.nc.f32 	%f6, [%rd37];
	mul.wide.u32 	%rd38, %r14, 512;
	add.s64 	%rd39, %rd4, %rd38;
	add.s64 	%rd40, %rd39, %rd7;
	ld.global.nc.u8 	%rs1, [%rd40];
	cvt.u16.u8 	%rs2, %rs1;
	add.s64 	%rd41, %rd5, %rd32;
	add.s64 	%rd42, %rd41, %rd34;
	add.s64 	%rd43, %rd42, %rd36;
	ld.global.nc.f32 	%f7, [%rd43];
	and.b16  	%rs3, %rs2, 1;
	setp.eq.b16 	%p1, %rs3, 1;
	mul.rn.f32 	%f8, %f7, 0f3F8E38E4;
	selp.f32 	%f9, %f8, 0f00000000, %p1;
	mul.rn.f32 	%f10, %f6, %f9;
	ld.global.nc.f32 	%f11, [%rd62];
	add.rn.f32 	%f12, %f11, %f1;
	fma.rn.f32 	%f13, %f12, 0fBBBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f14, %f13;
	fma.rm.f32 	%f17, %f14, %f16, %f15;
	add.rn.f32 	%f18, %f17, 0fCB40007F;
	neg.f32 	%f19, %f18;
	fma.rn.f32 	%f20, %f12, 0fBFB8AA3B, %f19;
	fma.rn.f32 	%f21, %f12, 0fB2A57060, %f20;
	mov.b32 	%r15, %f17;
	shl.b32 	%r16, %r15, 23;
	mov.b32 	%f22, %r16;
	ex2.approx.ftz.f32 	%f23, %f21;
	mul.rn.f32 	%f24, %f23, %f22;
	add.rn.f32 	%f25, %f24, 0f3F800000;
	rcp.approx.f32 	%f26, %f25;
	mov.f32 	%f27, 0f3F800000;
	sub.rn.f32 	%f28, %f27, %f26;
	mul.rn.f32 	%f29, %f26, %f28;
	mul.rn.f32 	%f30, %f10, %f29;
	add.rn.f32 	%f42, %f42, %f30;
	mul.rn.f32 	%f31, %f9, %f26;
	add.s64 	%rd44, %rd2, %rd32;
	add.s64 	%rd45, %rd44, %rd34;
	add.s64 	%rd46, %rd45, %rd36;
	st.global.f32 	[%rd46], %f30;
	add.s64 	%rd47, %rd1, %rd32;
	add.s64 	%rd48, %rd47, %rd34;
	add.s64 	%rd49, %rd48, %rd36;
	st.global.f32 	[%rd49], %f31;
	add.s64 	%rd62, %rd62, 65536;
	setp.lt.u32 	%p2, %r18, 368;
	mov.u32 	%r18, %r7;
	@%p2 bra 	$L__BB297_1;
	mul.wide.u32 	%rd50, %r2, 132;
	mov.u64 	%rd51, shared_cache62;
	add.s64 	%rd52, %rd51, %rd50;
	mul.wide.u32 	%rd53, %r1, 4;
	add.s64 	%rd54, %rd52, %rd53;
	st.shared.f32 	[%rd54], %f42;
	bar.sync 	0;
	mul.wide.u32 	%rd55, %r1, 132;
	add.s64 	%rd56, %rd51, %rd55;
	mul.wide.u32 	%rd57, %r2, 4;
	add.s64 	%rd58, %rd56, %rd57;
	ld.shared.f32 	%f32, [%rd58];
	shfl.sync.down.b32	%f33, %f32, 16, 31, -1;
	add.rn.f32 	%f34, %f32, %f33;
	shfl.sync.down.b32	%f35, %f34, 8, 31, -1;
	add.rn.f32 	%f36, %f34, %f35;
	shfl.sync.down.b32	%f37, %f36, 4, 31, -1;
	add.rn.f32 	%f38, %f36, %f37;
	shfl.sync.down.b32	%f39, %f38, 2, 31, -1;
	add.rn.f32 	%f40, %f38, %f39;
	shfl.sync.down.b32	%f41, %f40, 1, 31, -1;
	add.rn.f32 	%f4, %f40, %f41;
	st.shared.f32 	[%rd58], %f4;
	setp.ne.s32 	%p3, %r2, 0;
	@%p3 bra 	$L__BB297_4;
	or.b32  	%r17, %r4, %r1;
	mul.wide.u32 	%rd59, %r3, 2048;
	add.s64 	%rd60, %rd3, %rd59;
	mul.wide.u32 	%rd61, %r17, 4;
	add.s64 	%rd11, %rd60, %rd61;
	st.global.f32 	[%rd11], %f4;
$L__BB297_4:
	ret;

}
	// .globl	loop_add_fusion_391
.visible .entry loop_add_fusion_391(
	.param .u64 loop_add_fusion_391_param_0,
	.param .u64 loop_add_fusion_391_param_1,
	.param .u64 loop_add_fusion_391_param_2,
	.param .u64 loop_add_fusion_391_param_3,
	.param .u64 loop_add_fusion_391_param_4,
	.param .u64 loop_add_fusion_391_param_5
)
.reqntid 128, 1, 1
{
	.reg .b32 	%r<6>;
	.reg .f32 	%f<45>;
	.reg .b64 	%rd<21>;

	ld.param.u64 	%rd1, [loop_add_fusion_391_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_391_param_5];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_391_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_391_param_4];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_391_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_391_param_3];
	cvta.to.global.u64 	%rd9, %rd8;
	cvta.to.global.u64 	%rd10, %rd7;
	cvta.to.global.u64 	%rd11, %rd4;
	cvta.to.global.u64 	%rd12, %rd1;
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r2, %r1, 2;
	mov.u32 	%r3, %ctaid.x;
	shl.b32 	%r4, %r3, 9;
	or.b32  	%r5, %r4, %r2;
	mul.wide.u32 	%rd13, %r5, 4;
	add.s64 	%rd14, %rd9, %rd13;
	ld.global.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd14];
	add.s64 	%rd15, %rd3, %rd13;
	ld.global.nc.v4.f32 	{%f5, %f6, %f7, %f8}, [%rd15];
	mul.wide.u32 	%rd16, %r2, 4;
	add.s64 	%rd17, %rd6, %rd16;
	ld.global.nc.v4.f32 	{%f9, %f10, %f11, %f12}, [%rd17];
	mul.rn.f32 	%f13, %f5, %f9;
	add.rn.f32 	%f14, %f1, %f13;
	add.s64 	%rd18, %rd12, %rd13;
	ld.global.nc.v4.f32 	{%f15, %f16, %f17, %f18}, [%rd18];
	add.s64 	%rd19, %rd11, %rd16;
	ld.global.nc.v4.f32 	{%f19, %f20, %f21, %f22}, [%rd19];
	mul.rn.f32 	%f23, %f15, %f19;
	add.rn.f32 	%f24, %f14, %f23;
	add.s64 	%rd20, %rd10, %rd16;
	ld.global.nc.v4.f32 	{%f25, %f26, %f27, %f28}, [%rd20];
	add.rn.f32 	%f29, %f25, %f24;
	mul.rn.f32 	%f30, %f6, %f10;
	add.rn.f32 	%f31, %f2, %f30;
	mul.rn.f32 	%f32, %f16, %f20;
	add.rn.f32 	%f33, %f31, %f32;
	add.rn.f32 	%f34, %f26, %f33;
	mul.rn.f32 	%f35, %f7, %f11;
	add.rn.f32 	%f36, %f3, %f35;
	mul.rn.f32 	%f37, %f17, %f21;
	add.rn.f32 	%f38, %f36, %f37;
	add.rn.f32 	%f39, %f27, %f38;
	mul.rn.f32 	%f40, %f8, %f12;
	add.rn.f32 	%f41, %f4, %f40;
	mul.rn.f32 	%f42, %f18, %f22;
	add.rn.f32 	%f43, %f41, %f42;
	add.rn.f32 	%f44, %f28, %f43;
	st.global.v4.f32 	[%rd14], {%f29, %f34, %f39, %f44};
	ret;

}
	// .globl	gemm_fusion_dot_617_1
.visible .entry gemm_fusion_dot_617_1(
	.param .u64 gemm_fusion_dot_617_1_param_0,
	.param .u64 gemm_fusion_dot_617_1_param_1,
	.param .u64 gemm_fusion_dot_617_1_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<195>;
	.reg .b32 	%r<731>;
	.reg .f32 	%f<533>;
	.reg .b64 	%rd<213>;

	ld.param.u64 	%rd80, [gemm_fusion_dot_617_1_param_0];
	ld.param.u64 	%rd81, [gemm_fusion_dot_617_1_param_2];
	cvta.to.global.u64 	%rd1, %rd81;
	ld.param.u64 	%rd82, [gemm_fusion_dot_617_1_param_1];
	cvta.to.global.u64 	%rd83, %rd82;
	cvta.to.global.u64 	%rd84, %rd80;
	// begin inline asm
	mov.u32 %r9, %ctaid.x;
	// end inline asm
	shr.s32 	%r12, %r9, 31;
	shr.u32 	%r13, %r12, 29;
	add.s32 	%r14, %r9, %r13;
	and.b32  	%r15, %r14, -8;
	mov.b32 	%r16, 1;
	sub.s32 	%r17, %r16, %r15;
	min.s32 	%r18, %r17, 8;
	rem.s32 	%r19, %r9, %r18;
	add.s32 	%r20, %r15, %r19;
	sub.s32 	%r21, %r9, %r15;
	div.s32 	%r22, %r21, %r18;
	shl.b32 	%r23, %r20, 4;
	// begin inline asm
	mov.u32 %r10, %ctaid.y;
	// end inline asm
	mul.lo.s32 	%r24, %r10, 307200;
	cvt.s64.s32 	%rd2, %r23;
	shl.b32 	%r25, %r22, 4;
	mul.lo.s32 	%r26, %r10, 6;
	cvt.s64.s32 	%rd85, %r25;
	mov.u32 	%r27, %tid.x;
	and.b32  	%r2, %r27, 31;
	shl.b32 	%r3, %r27, 1;
	and.b32  	%r4, %r3, 14;
	cvt.u64.u32 	%rd86, %r4;
	or.b64  	%rd3, %rd2, %rd86;
	shr.u32 	%r5, %r27, 5;
	shr.u32 	%r28, %r27, 3;
	cvt.u64.u32 	%rd4, %r28;
	or.b64  	%rd5, %rd85, %rd86;
	shr.u32 	%r29, %r27, 1;
	and.b32  	%r30, %r29, 8;
	xor.b32  	%r31, %r4, %r30;
	shl.b32 	%r32, %r28, 4;
	or.b32  	%r33, %r31, %r32;
	mul.wide.u32 	%rd87, %r33, 4;
	mov.u64 	%rd88, global_smem;
	add.s64 	%rd6, %rd88, %rd87;
	or.b32  	%r34, %r33, 256;
	mul.wide.u32 	%rd89, %r34, 4;
	add.s64 	%rd7, %rd88, %rd89;
	or.b32  	%r35, %r33, 512;
	mul.wide.u32 	%rd90, %r35, 4;
	add.s64 	%rd8, %rd88, %rd90;
	or.b32  	%r36, %r33, 768;
	mul.wide.u32 	%rd91, %r36, 4;
	add.s64 	%rd9, %rd88, %rd91;
	or.b32  	%r37, %r33, 1024;
	mul.wide.u32 	%rd92, %r37, 4;
	add.s64 	%rd10, %rd88, %rd92;
	or.b32  	%r38, %r33, 1280;
	mul.wide.u32 	%rd93, %r38, 4;
	add.s64 	%rd11, %rd88, %rd93;
	or.b32  	%r39, %r33, 1536;
	mul.wide.u32 	%rd94, %r39, 4;
	add.s64 	%rd12, %rd88, %rd94;
	or.b32  	%r40, %r33, 1792;
	mul.wide.u32 	%rd95, %r40, 4;
	add.s64 	%rd13, %rd88, %rd95;
	or.b32  	%r41, %r33, 2048;
	mul.wide.u32 	%rd96, %r41, 4;
	add.s64 	%rd14, %rd88, %rd96;
	or.b32  	%r42, %r33, 2304;
	mul.wide.u32 	%rd97, %r42, 4;
	add.s64 	%rd15, %rd88, %rd97;
	or.b32  	%r43, %r33, 2560;
	mul.wide.u32 	%rd98, %r43, 4;
	add.s64 	%rd16, %rd88, %rd98;
	or.b32  	%r44, %r33, 2816;
	mul.wide.u32 	%rd99, %r44, 4;
	add.s64 	%rd17, %rd88, %rd99;
	or.b32  	%r45, %r33, 3072;
	mul.wide.u32 	%rd100, %r45, 4;
	add.s64 	%rd18, %rd88, %rd100;
	or.b32  	%r46, %r33, 3328;
	mul.wide.u32 	%rd101, %r46, 4;
	add.s64 	%rd19, %rd88, %rd101;
	or.b32  	%r47, %r33, 3584;
	mul.wide.u32 	%rd102, %r47, 4;
	add.s64 	%rd20, %rd88, %rd102;
	or.b32  	%r48, %r33, 3840;
	mul.wide.u32 	%rd103, %r48, 4;
	add.s64 	%rd21, %rd88, %rd103;
	or.b32  	%r49, %r33, 4096;
	mul.wide.u32 	%rd104, %r49, 4;
	add.s64 	%rd22, %rd88, %rd104;
	or.b32  	%r50, %r33, 4352;
	mul.wide.u32 	%rd105, %r50, 4;
	add.s64 	%rd23, %rd88, %rd105;
	or.b32  	%r51, %r33, 4608;
	mul.wide.u32 	%rd106, %r51, 4;
	add.s64 	%rd24, %rd88, %rd106;
	or.b32  	%r52, %r33, 4864;
	mul.wide.u32 	%rd107, %r52, 4;
	add.s64 	%rd25, %rd88, %rd107;
	or.b32  	%r53, %r33, 5120;
	mul.wide.u32 	%rd108, %r53, 4;
	add.s64 	%rd26, %rd88, %rd108;
	or.b32  	%r54, %r33, 5376;
	mul.wide.u32 	%rd109, %r54, 4;
	add.s64 	%rd27, %rd88, %rd109;
	or.b32  	%r55, %r33, 5632;
	mul.wide.u32 	%rd110, %r55, 4;
	add.s64 	%rd28, %rd88, %rd110;
	or.b32  	%r56, %r33, 5888;
	mul.wide.u32 	%rd111, %r56, 4;
	add.s64 	%rd29, %rd88, %rd111;
	or.b32  	%r57, %r33, 6144;
	mul.wide.u32 	%rd112, %r57, 4;
	add.s64 	%rd30, %rd88, %rd112;
	or.b32  	%r58, %r33, 6400;
	mul.wide.u32 	%rd113, %r58, 4;
	add.s64 	%rd31, %rd88, %rd113;
	or.b32  	%r59, %r33, 6656;
	mul.wide.u32 	%rd114, %r59, 4;
	add.s64 	%rd32, %rd88, %rd114;
	or.b32  	%r60, %r33, 6912;
	mul.wide.u32 	%rd115, %r60, 4;
	add.s64 	%rd33, %rd88, %rd115;
	or.b32  	%r61, %r33, 7168;
	mul.wide.u32 	%rd116, %r61, 4;
	add.s64 	%rd34, %rd88, %rd116;
	or.b32  	%r62, %r33, 7424;
	mul.wide.u32 	%rd117, %r62, 4;
	add.s64 	%rd35, %rd88, %rd117;
	or.b32  	%r63, %r33, 7680;
	mul.wide.u32 	%rd118, %r63, 4;
	add.s64 	%rd36, %rd88, %rd118;
	or.b32  	%r64, %r33, 7936;
	mul.wide.u32 	%rd119, %r64, 4;
	add.s64 	%rd37, %rd88, %rd119;
	add.s64 	%rd120, %rd88, 32768;
	add.s64 	%rd38, %rd120, %rd87;
	add.s64 	%rd39, %rd120, %rd89;
	add.s64 	%rd40, %rd120, %rd90;
	add.s64 	%rd41, %rd120, %rd91;
	add.s64 	%rd42, %rd120, %rd92;
	add.s64 	%rd43, %rd120, %rd93;
	add.s64 	%rd44, %rd120, %rd94;
	add.s64 	%rd45, %rd120, %rd95;
	add.s64 	%rd46, %rd120, %rd96;
	add.s64 	%rd47, %rd120, %rd97;
	add.s64 	%rd48, %rd120, %rd98;
	add.s64 	%rd49, %rd120, %rd99;
	add.s64 	%rd50, %rd120, %rd100;
	add.s64 	%rd51, %rd120, %rd101;
	add.s64 	%rd52, %rd120, %rd102;
	add.s64 	%rd53, %rd120, %rd103;
	add.s64 	%rd54, %rd120, %rd104;
	add.s64 	%rd55, %rd120, %rd105;
	add.s64 	%rd56, %rd120, %rd106;
	add.s64 	%rd57, %rd120, %rd107;
	add.s64 	%rd58, %rd120, %rd108;
	add.s64 	%rd59, %rd120, %rd109;
	add.s64 	%rd60, %rd120, %rd110;
	add.s64 	%rd61, %rd120, %rd111;
	add.s64 	%rd62, %rd120, %rd112;
	add.s64 	%rd63, %rd120, %rd113;
	add.s64 	%rd64, %rd120, %rd114;
	add.s64 	%rd65, %rd120, %rd115;
	add.s64 	%rd66, %rd120, %rd116;
	add.s64 	%rd67, %rd120, %rd117;
	add.s64 	%rd68, %rd120, %rd118;
	add.s64 	%rd69, %rd120, %rd119;
	bfe.u32 	%r6, %r27, 2, 3;
	and.b32  	%r65, %r27, 3;
	bfe.u32 	%r66, %r27, 1, 1;
	shl.b32 	%r67, %r66, 3;
	or.b32  	%r68, %r67, %r6;
	shl.b32 	%r69, %r65, 4;
	or.b32  	%r70, %r68, %r69;
	xor.b32  	%r71, %r70, 8;
	mul.wide.u32 	%rd121, %r70, 4;
	add.s64 	%rd70, %rd88, %rd121;
	mul.wide.u32 	%rd122, %r71, 4;
	add.s64 	%rd71, %rd88, %rd122;
	bfe.u32 	%r72, %r27, 5, 1;
	xor.b32  	%r73, %r72, %r66;
	shl.b32 	%r74, %r73, 3;
	or.b32  	%r75, %r74, %r6;
	or.b32  	%r76, %r75, %r69;
	mul.wide.u32 	%rd123, %r76, 4;
	add.s64 	%rd72, %rd120, %rd123;
	and.b32  	%r77, %r27, 7;
	mul.wide.u32 	%rd73, %r77, 8;
	mul.wide.u32 	%rd124, %r28, 1536;
	mul.wide.s32 	%rd125, %r25, 4;
	add.s64 	%rd126, %rd124, %rd125;
	mul.wide.s32 	%rd127, %r26, 4;
	add.s64 	%rd128, %rd126, %rd127;
	add.s64 	%rd212, %rd83, %rd128;
	mul.wide.u32 	%rd129, %r28, 24;
	mul.wide.s32 	%rd130, %r24, 4;
	or.b64  	%rd131, %rd129, %rd130;
	mul.wide.s32 	%rd132, %r23, 4;
	add.s64 	%rd133, %rd131, %rd132;
	add.s64 	%rd211, %rd84, %rd133;
	mov.f32 	%f529, 0f00000000;
	mov.b32 	%r730, -512;
	setp.lt.u64 	%p97, %rd5, 6;
	setp.lt.u64 	%p1, %rd3, 6;
	mov.f32 	%f530, %f529;
	mov.f32 	%f531, %f529;
	mov.f32 	%f532, %f529;
$L__BB299_1:
	add.s64 	%rd134, %rd211, %rd73;
	add.s64 	%rd135, %rd134, 384;
	add.s64 	%rd136, %rd134, 768;
	add.s64 	%rd137, %rd134, 1152;
	add.s64 	%rd138, %rd134, 1536;
	add.s64 	%rd139, %rd134, 1920;
	add.s64 	%rd140, %rd134, 2304;
	add.s64 	%rd141, %rd134, 2688;
	add.s64 	%rd142, %rd134, 3072;
	add.s64 	%rd143, %rd134, 3456;
	add.s64 	%rd144, %rd134, 3840;
	add.s64 	%rd145, %rd134, 4224;
	add.s64 	%rd146, %rd134, 4608;
	add.s64 	%rd147, %rd134, 4992;
	add.s64 	%rd148, %rd134, 5376;
	add.s64 	%rd149, %rd134, 5760;
	add.s64 	%rd150, %rd134, 6144;
	add.s64 	%rd151, %rd134, 6528;
	add.s64 	%rd152, %rd134, 6912;
	add.s64 	%rd153, %rd134, 7296;
	add.s64 	%rd154, %rd134, 7680;
	add.s64 	%rd155, %rd134, 8064;
	add.s64 	%rd156, %rd134, 8448;
	add.s64 	%rd157, %rd134, 8832;
	add.s64 	%rd158, %rd134, 9216;
	add.s64 	%rd159, %rd134, 9600;
	add.s64 	%rd160, %rd134, 9984;
	add.s64 	%rd161, %rd134, 10368;
	add.s64 	%rd162, %rd134, 10752;
	add.s64 	%rd163, %rd134, 11136;
	add.s64 	%rd164, %rd134, 11520;
	add.s64 	%rd165, %rd134, 11904;
	mov.b32 	%r80, 0;
	// begin inline asm
	mov.u32 %r78, 0x0;
	mov.u32 %r79, 0x0;
	@%p1 ld.global.v2.b32 { %r78, %r79 }, [ %rd134 + 0 ];
	@!%p1 mov.u32 %r78, %r80;
	@!%p1 mov.u32 %r79, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r82, 0x0;
	mov.u32 %r83, 0x0;
	@%p1 ld.global.v2.b32 { %r82, %r83 }, [ %rd135 + 0 ];
	@!%p1 mov.u32 %r82, %r80;
	@!%p1 mov.u32 %r83, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r86, 0x0;
	mov.u32 %r87, 0x0;
	@%p1 ld.global.v2.b32 { %r86, %r87 }, [ %rd136 + 0 ];
	@!%p1 mov.u32 %r86, %r80;
	@!%p1 mov.u32 %r87, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r90, 0x0;
	mov.u32 %r91, 0x0;
	@%p1 ld.global.v2.b32 { %r90, %r91 }, [ %rd137 + 0 ];
	@!%p1 mov.u32 %r90, %r80;
	@!%p1 mov.u32 %r91, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r94, 0x0;
	mov.u32 %r95, 0x0;
	@%p1 ld.global.v2.b32 { %r94, %r95 }, [ %rd138 + 0 ];
	@!%p1 mov.u32 %r94, %r80;
	@!%p1 mov.u32 %r95, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r98, 0x0;
	mov.u32 %r99, 0x0;
	@%p1 ld.global.v2.b32 { %r98, %r99 }, [ %rd139 + 0 ];
	@!%p1 mov.u32 %r98, %r80;
	@!%p1 mov.u32 %r99, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r102, 0x0;
	mov.u32 %r103, 0x0;
	@%p1 ld.global.v2.b32 { %r102, %r103 }, [ %rd140 + 0 ];
	@!%p1 mov.u32 %r102, %r80;
	@!%p1 mov.u32 %r103, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r106, 0x0;
	mov.u32 %r107, 0x0;
	@%p1 ld.global.v2.b32 { %r106, %r107 }, [ %rd141 + 0 ];
	@!%p1 mov.u32 %r106, %r80;
	@!%p1 mov.u32 %r107, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r110, 0x0;
	mov.u32 %r111, 0x0;
	@%p1 ld.global.v2.b32 { %r110, %r111 }, [ %rd142 + 0 ];
	@!%p1 mov.u32 %r110, %r80;
	@!%p1 mov.u32 %r111, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r114, 0x0;
	mov.u32 %r115, 0x0;
	@%p1 ld.global.v2.b32 { %r114, %r115 }, [ %rd143 + 0 ];
	@!%p1 mov.u32 %r114, %r80;
	@!%p1 mov.u32 %r115, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r118, 0x0;
	mov.u32 %r119, 0x0;
	@%p1 ld.global.v2.b32 { %r118, %r119 }, [ %rd144 + 0 ];
	@!%p1 mov.u32 %r118, %r80;
	@!%p1 mov.u32 %r119, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r122, 0x0;
	mov.u32 %r123, 0x0;
	@%p1 ld.global.v2.b32 { %r122, %r123 }, [ %rd145 + 0 ];
	@!%p1 mov.u32 %r122, %r80;
	@!%p1 mov.u32 %r123, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r126, 0x0;
	mov.u32 %r127, 0x0;
	@%p1 ld.global.v2.b32 { %r126, %r127 }, [ %rd146 + 0 ];
	@!%p1 mov.u32 %r126, %r80;
	@!%p1 mov.u32 %r127, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r130, 0x0;
	mov.u32 %r131, 0x0;
	@%p1 ld.global.v2.b32 { %r130, %r131 }, [ %rd147 + 0 ];
	@!%p1 mov.u32 %r130, %r80;
	@!%p1 mov.u32 %r131, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r134, 0x0;
	mov.u32 %r135, 0x0;
	@%p1 ld.global.v2.b32 { %r134, %r135 }, [ %rd148 + 0 ];
	@!%p1 mov.u32 %r134, %r80;
	@!%p1 mov.u32 %r135, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r138, 0x0;
	mov.u32 %r139, 0x0;
	@%p1 ld.global.v2.b32 { %r138, %r139 }, [ %rd149 + 0 ];
	@!%p1 mov.u32 %r138, %r80;
	@!%p1 mov.u32 %r139, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r142, 0x0;
	mov.u32 %r143, 0x0;
	@%p1 ld.global.v2.b32 { %r142, %r143 }, [ %rd150 + 0 ];
	@!%p1 mov.u32 %r142, %r80;
	@!%p1 mov.u32 %r143, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r146, 0x0;
	mov.u32 %r147, 0x0;
	@%p1 ld.global.v2.b32 { %r146, %r147 }, [ %rd151 + 0 ];
	@!%p1 mov.u32 %r146, %r80;
	@!%p1 mov.u32 %r147, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r150, 0x0;
	mov.u32 %r151, 0x0;
	@%p1 ld.global.v2.b32 { %r150, %r151 }, [ %rd152 + 0 ];
	@!%p1 mov.u32 %r150, %r80;
	@!%p1 mov.u32 %r151, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r154, 0x0;
	mov.u32 %r155, 0x0;
	@%p1 ld.global.v2.b32 { %r154, %r155 }, [ %rd153 + 0 ];
	@!%p1 mov.u32 %r154, %r80;
	@!%p1 mov.u32 %r155, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r158, 0x0;
	mov.u32 %r159, 0x0;
	@%p1 ld.global.v2.b32 { %r158, %r159 }, [ %rd154 + 0 ];
	@!%p1 mov.u32 %r158, %r80;
	@!%p1 mov.u32 %r159, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r162, 0x0;
	mov.u32 %r163, 0x0;
	@%p1 ld.global.v2.b32 { %r162, %r163 }, [ %rd155 + 0 ];
	@!%p1 mov.u32 %r162, %r80;
	@!%p1 mov.u32 %r163, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r166, 0x0;
	mov.u32 %r167, 0x0;
	@%p1 ld.global.v2.b32 { %r166, %r167 }, [ %rd156 + 0 ];
	@!%p1 mov.u32 %r166, %r80;
	@!%p1 mov.u32 %r167, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r170, 0x0;
	mov.u32 %r171, 0x0;
	@%p1 ld.global.v2.b32 { %r170, %r171 }, [ %rd157 + 0 ];
	@!%p1 mov.u32 %r170, %r80;
	@!%p1 mov.u32 %r171, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r174, 0x0;
	mov.u32 %r175, 0x0;
	@%p1 ld.global.v2.b32 { %r174, %r175 }, [ %rd158 + 0 ];
	@!%p1 mov.u32 %r174, %r80;
	@!%p1 mov.u32 %r175, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r178, 0x0;
	mov.u32 %r179, 0x0;
	@%p1 ld.global.v2.b32 { %r178, %r179 }, [ %rd159 + 0 ];
	@!%p1 mov.u32 %r178, %r80;
	@!%p1 mov.u32 %r179, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r182, 0x0;
	mov.u32 %r183, 0x0;
	@%p1 ld.global.v2.b32 { %r182, %r183 }, [ %rd160 + 0 ];
	@!%p1 mov.u32 %r182, %r80;
	@!%p1 mov.u32 %r183, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r186, 0x0;
	mov.u32 %r187, 0x0;
	@%p1 ld.global.v2.b32 { %r186, %r187 }, [ %rd161 + 0 ];
	@!%p1 mov.u32 %r186, %r80;
	@!%p1 mov.u32 %r187, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r190, 0x0;
	mov.u32 %r191, 0x0;
	@%p1 ld.global.v2.b32 { %r190, %r191 }, [ %rd162 + 0 ];
	@!%p1 mov.u32 %r190, %r80;
	@!%p1 mov.u32 %r191, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r194, 0x0;
	mov.u32 %r195, 0x0;
	@%p1 ld.global.v2.b32 { %r194, %r195 }, [ %rd163 + 0 ];
	@!%p1 mov.u32 %r194, %r80;
	@!%p1 mov.u32 %r195, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r198, 0x0;
	mov.u32 %r199, 0x0;
	@%p1 ld.global.v2.b32 { %r198, %r199 }, [ %rd164 + 0 ];
	@!%p1 mov.u32 %r198, %r80;
	@!%p1 mov.u32 %r199, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r202, 0x0;
	mov.u32 %r203, 0x0;
	@%p1 ld.global.v2.b32 { %r202, %r203 }, [ %rd165 + 0 ];
	@!%p1 mov.u32 %r202, %r80;
	@!%p1 mov.u32 %r203, %r80;
	// end inline asm
	bar.sync 	0;
	st.shared.v2.u32 	[%rd6], {%r78, %r79};
	st.shared.v2.u32 	[%rd7], {%r82, %r83};
	st.shared.v2.u32 	[%rd8], {%r86, %r87};
	st.shared.v2.u32 	[%rd9], {%r90, %r91};
	st.shared.v2.u32 	[%rd10], {%r94, %r95};
	st.shared.v2.u32 	[%rd11], {%r98, %r99};
	st.shared.v2.u32 	[%rd12], {%r102, %r103};
	st.shared.v2.u32 	[%rd13], {%r106, %r107};
	st.shared.v2.u32 	[%rd14], {%r110, %r111};
	st.shared.v2.u32 	[%rd15], {%r114, %r115};
	st.shared.v2.u32 	[%rd16], {%r118, %r119};
	st.shared.v2.u32 	[%rd17], {%r122, %r123};
	st.shared.v2.u32 	[%rd18], {%r126, %r127};
	st.shared.v2.u32 	[%rd19], {%r130, %r131};
	st.shared.v2.u32 	[%rd20], {%r134, %r135};
	st.shared.v2.u32 	[%rd21], {%r138, %r139};
	st.shared.v2.u32 	[%rd22], {%r142, %r143};
	st.shared.v2.u32 	[%rd23], {%r146, %r147};
	st.shared.v2.u32 	[%rd24], {%r150, %r151};
	st.shared.v2.u32 	[%rd25], {%r154, %r155};
	st.shared.v2.u32 	[%rd26], {%r158, %r159};
	st.shared.v2.u32 	[%rd27], {%r162, %r163};
	st.shared.v2.u32 	[%rd28], {%r166, %r167};
	st.shared.v2.u32 	[%rd29], {%r170, %r171};
	st.shared.v2.u32 	[%rd30], {%r174, %r175};
	st.shared.v2.u32 	[%rd31], {%r178, %r179};
	st.shared.v2.u32 	[%rd32], {%r182, %r183};
	st.shared.v2.u32 	[%rd33], {%r186, %r187};
	st.shared.v2.u32 	[%rd34], {%r190, %r191};
	st.shared.v2.u32 	[%rd35], {%r194, %r195};
	st.shared.v2.u32 	[%rd36], {%r198, %r199};
	st.shared.v2.u32 	[%rd37], {%r202, %r203};
	add.s64 	%rd166, %rd212, %rd73;
	add.s64 	%rd167, %rd166, 24576;
	add.s64 	%rd168, %rd166, 49152;
	add.s64 	%rd169, %rd166, 73728;
	add.s64 	%rd170, %rd166, 98304;
	add.s64 	%rd171, %rd166, 122880;
	add.s64 	%rd172, %rd166, 147456;
	add.s64 	%rd173, %rd166, 172032;
	add.s64 	%rd174, %rd166, 196608;
	add.s64 	%rd175, %rd166, 221184;
	add.s64 	%rd176, %rd166, 245760;
	add.s64 	%rd177, %rd166, 270336;
	add.s64 	%rd178, %rd166, 294912;
	add.s64 	%rd179, %rd166, 319488;
	add.s64 	%rd180, %rd166, 344064;
	add.s64 	%rd181, %rd166, 368640;
	add.s64 	%rd182, %rd166, 393216;
	add.s64 	%rd183, %rd166, 417792;
	add.s64 	%rd184, %rd166, 442368;
	add.s64 	%rd185, %rd166, 466944;
	add.s64 	%rd186, %rd166, 491520;
	add.s64 	%rd187, %rd166, 516096;
	add.s64 	%rd188, %rd166, 540672;
	add.s64 	%rd189, %rd166, 565248;
	add.s64 	%rd190, %rd166, 589824;
	add.s64 	%rd191, %rd166, 614400;
	add.s64 	%rd192, %rd166, 638976;
	add.s64 	%rd193, %rd166, 663552;
	add.s64 	%rd194, %rd166, 688128;
	add.s64 	%rd195, %rd166, 712704;
	add.s64 	%rd196, %rd166, 737280;
	add.s64 	%rd197, %rd166, 761856;
	// begin inline asm
	mov.u32 %r206, 0x0;
	mov.u32 %r207, 0x0;
	@%p97 ld.global.v2.b32 { %r206, %r207 }, [ %rd166 + 0 ];
	@!%p97 mov.u32 %r206, %r80;
	@!%p97 mov.u32 %r207, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r210, 0x0;
	mov.u32 %r211, 0x0;
	@%p97 ld.global.v2.b32 { %r210, %r211 }, [ %rd167 + 0 ];
	@!%p97 mov.u32 %r210, %r80;
	@!%p97 mov.u32 %r211, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r214, 0x0;
	mov.u32 %r215, 0x0;
	@%p97 ld.global.v2.b32 { %r214, %r215 }, [ %rd168 + 0 ];
	@!%p97 mov.u32 %r214, %r80;
	@!%p97 mov.u32 %r215, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r218, 0x0;
	mov.u32 %r219, 0x0;
	@%p97 ld.global.v2.b32 { %r218, %r219 }, [ %rd169 + 0 ];
	@!%p97 mov.u32 %r218, %r80;
	@!%p97 mov.u32 %r219, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r222, 0x0;
	mov.u32 %r223, 0x0;
	@%p97 ld.global.v2.b32 { %r222, %r223 }, [ %rd170 + 0 ];
	@!%p97 mov.u32 %r222, %r80;
	@!%p97 mov.u32 %r223, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r226, 0x0;
	mov.u32 %r227, 0x0;
	@%p97 ld.global.v2.b32 { %r226, %r227 }, [ %rd171 + 0 ];
	@!%p97 mov.u32 %r226, %r80;
	@!%p97 mov.u32 %r227, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r230, 0x0;
	mov.u32 %r231, 0x0;
	@%p97 ld.global.v2.b32 { %r230, %r231 }, [ %rd172 + 0 ];
	@!%p97 mov.u32 %r230, %r80;
	@!%p97 mov.u32 %r231, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r234, 0x0;
	mov.u32 %r235, 0x0;
	@%p97 ld.global.v2.b32 { %r234, %r235 }, [ %rd173 + 0 ];
	@!%p97 mov.u32 %r234, %r80;
	@!%p97 mov.u32 %r235, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r238, 0x0;
	mov.u32 %r239, 0x0;
	@%p97 ld.global.v2.b32 { %r238, %r239 }, [ %rd174 + 0 ];
	@!%p97 mov.u32 %r238, %r80;
	@!%p97 mov.u32 %r239, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r242, 0x0;
	mov.u32 %r243, 0x0;
	@%p97 ld.global.v2.b32 { %r242, %r243 }, [ %rd175 + 0 ];
	@!%p97 mov.u32 %r242, %r80;
	@!%p97 mov.u32 %r243, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r246, 0x0;
	mov.u32 %r247, 0x0;
	@%p97 ld.global.v2.b32 { %r246, %r247 }, [ %rd176 + 0 ];
	@!%p97 mov.u32 %r246, %r80;
	@!%p97 mov.u32 %r247, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r250, 0x0;
	mov.u32 %r251, 0x0;
	@%p97 ld.global.v2.b32 { %r250, %r251 }, [ %rd177 + 0 ];
	@!%p97 mov.u32 %r250, %r80;
	@!%p97 mov.u32 %r251, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r254, 0x0;
	mov.u32 %r255, 0x0;
	@%p97 ld.global.v2.b32 { %r254, %r255 }, [ %rd178 + 0 ];
	@!%p97 mov.u32 %r254, %r80;
	@!%p97 mov.u32 %r255, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r258, 0x0;
	mov.u32 %r259, 0x0;
	@%p97 ld.global.v2.b32 { %r258, %r259 }, [ %rd179 + 0 ];
	@!%p97 mov.u32 %r258, %r80;
	@!%p97 mov.u32 %r259, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r262, 0x0;
	mov.u32 %r263, 0x0;
	@%p97 ld.global.v2.b32 { %r262, %r263 }, [ %rd180 + 0 ];
	@!%p97 mov.u32 %r262, %r80;
	@!%p97 mov.u32 %r263, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r266, 0x0;
	mov.u32 %r267, 0x0;
	@%p97 ld.global.v2.b32 { %r266, %r267 }, [ %rd181 + 0 ];
	@!%p97 mov.u32 %r266, %r80;
	@!%p97 mov.u32 %r267, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r270, 0x0;
	mov.u32 %r271, 0x0;
	@%p97 ld.global.v2.b32 { %r270, %r271 }, [ %rd182 + 0 ];
	@!%p97 mov.u32 %r270, %r80;
	@!%p97 mov.u32 %r271, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r274, 0x0;
	mov.u32 %r275, 0x0;
	@%p97 ld.global.v2.b32 { %r274, %r275 }, [ %rd183 + 0 ];
	@!%p97 mov.u32 %r274, %r80;
	@!%p97 mov.u32 %r275, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r278, 0x0;
	mov.u32 %r279, 0x0;
	@%p97 ld.global.v2.b32 { %r278, %r279 }, [ %rd184 + 0 ];
	@!%p97 mov.u32 %r278, %r80;
	@!%p97 mov.u32 %r279, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r282, 0x0;
	mov.u32 %r283, 0x0;
	@%p97 ld.global.v2.b32 { %r282, %r283 }, [ %rd185 + 0 ];
	@!%p97 mov.u32 %r282, %r80;
	@!%p97 mov.u32 %r283, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r286, 0x0;
	mov.u32 %r287, 0x0;
	@%p97 ld.global.v2.b32 { %r286, %r287 }, [ %rd186 + 0 ];
	@!%p97 mov.u32 %r286, %r80;
	@!%p97 mov.u32 %r287, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r290, 0x0;
	mov.u32 %r291, 0x0;
	@%p97 ld.global.v2.b32 { %r290, %r291 }, [ %rd187 + 0 ];
	@!%p97 mov.u32 %r290, %r80;
	@!%p97 mov.u32 %r291, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r294, 0x0;
	mov.u32 %r295, 0x0;
	@%p97 ld.global.v2.b32 { %r294, %r295 }, [ %rd188 + 0 ];
	@!%p97 mov.u32 %r294, %r80;
	@!%p97 mov.u32 %r295, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r298, 0x0;
	mov.u32 %r299, 0x0;
	@%p97 ld.global.v2.b32 { %r298, %r299 }, [ %rd189 + 0 ];
	@!%p97 mov.u32 %r298, %r80;
	@!%p97 mov.u32 %r299, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r302, 0x0;
	mov.u32 %r303, 0x0;
	@%p97 ld.global.v2.b32 { %r302, %r303 }, [ %rd190 + 0 ];
	@!%p97 mov.u32 %r302, %r80;
	@!%p97 mov.u32 %r303, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r306, 0x0;
	mov.u32 %r307, 0x0;
	@%p97 ld.global.v2.b32 { %r306, %r307 }, [ %rd191 + 0 ];
	@!%p97 mov.u32 %r306, %r80;
	@!%p97 mov.u32 %r307, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r310, 0x0;
	mov.u32 %r311, 0x0;
	@%p97 ld.global.v2.b32 { %r310, %r311 }, [ %rd192 + 0 ];
	@!%p97 mov.u32 %r310, %r80;
	@!%p97 mov.u32 %r311, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r314, 0x0;
	mov.u32 %r315, 0x0;
	@%p97 ld.global.v2.b32 { %r314, %r315 }, [ %rd193 + 0 ];
	@!%p97 mov.u32 %r314, %r80;
	@!%p97 mov.u32 %r315, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r318, 0x0;
	mov.u32 %r319, 0x0;
	@%p97 ld.global.v2.b32 { %r318, %r319 }, [ %rd194 + 0 ];
	@!%p97 mov.u32 %r318, %r80;
	@!%p97 mov.u32 %r319, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r322, 0x0;
	mov.u32 %r323, 0x0;
	@%p97 ld.global.v2.b32 { %r322, %r323 }, [ %rd195 + 0 ];
	@!%p97 mov.u32 %r322, %r80;
	@!%p97 mov.u32 %r323, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r326, 0x0;
	mov.u32 %r327, 0x0;
	@%p97 ld.global.v2.b32 { %r326, %r327 }, [ %rd196 + 0 ];
	@!%p97 mov.u32 %r326, %r80;
	@!%p97 mov.u32 %r327, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r330, 0x0;
	mov.u32 %r331, 0x0;
	@%p97 ld.global.v2.b32 { %r330, %r331 }, [ %rd197 + 0 ];
	@!%p97 mov.u32 %r330, %r80;
	@!%p97 mov.u32 %r331, %r80;
	// end inline asm
	st.shared.v2.u32 	[%rd38], {%r206, %r207};
	st.shared.v2.u32 	[%rd39], {%r210, %r211};
	st.shared.v2.u32 	[%rd40], {%r214, %r215};
	st.shared.v2.u32 	[%rd41], {%r218, %r219};
	st.shared.v2.u32 	[%rd42], {%r222, %r223};
	st.shared.v2.u32 	[%rd43], {%r226, %r227};
	st.shared.v2.u32 	[%rd44], {%r230, %r231};
	st.shared.v2.u32 	[%rd45], {%r234, %r235};
	st.shared.v2.u32 	[%rd46], {%r238, %r239};
	st.shared.v2.u32 	[%rd47], {%r242, %r243};
	st.shared.v2.u32 	[%rd48], {%r246, %r247};
	st.shared.v2.u32 	[%rd49], {%r250, %r251};
	st.shared.v2.u32 	[%rd50], {%r254, %r255};
	st.shared.v2.u32 	[%rd51], {%r258, %r259};
	st.shared.v2.u32 	[%rd52], {%r262, %r263};
	st.shared.v2.u32 	[%rd53], {%r266, %r267};
	st.shared.v2.u32 	[%rd54], {%r270, %r271};
	st.shared.v2.u32 	[%rd55], {%r274, %r275};
	st.shared.v2.u32 	[%rd56], {%r278, %r279};
	st.shared.v2.u32 	[%rd57], {%r282, %r283};
	st.shared.v2.u32 	[%rd58], {%r286, %r287};
	st.shared.v2.u32 	[%rd59], {%r290, %r291};
	st.shared.v2.u32 	[%rd60], {%r294, %r295};
	st.shared.v2.u32 	[%rd61], {%r298, %r299};
	st.shared.v2.u32 	[%rd62], {%r302, %r303};
	st.shared.v2.u32 	[%rd63], {%r306, %r307};
	st.shared.v2.u32 	[%rd64], {%r310, %r311};
	st.shared.v2.u32 	[%rd65], {%r314, %r315};
	st.shared.v2.u32 	[%rd66], {%r318, %r319};
	st.shared.v2.u32 	[%rd67], {%r322, %r323};
	st.shared.v2.u32 	[%rd68], {%r326, %r327};
	st.shared.v2.u32 	[%rd69], {%r330, %r331};
	bar.sync 	0;
	ld.shared.u32 	%r334, [%rd70];
	ld.shared.u32 	%r335, [%rd71];
	ld.shared.u32 	%r336, [%rd70+256];
	ld.shared.u32 	%r337, [%rd71+256];
	ld.shared.u32 	%r340, [%rd70+512];
	ld.shared.u32 	%r341, [%rd71+512];
	ld.shared.u32 	%r342, [%rd70+768];
	ld.shared.u32 	%r343, [%rd71+768];
	ld.shared.u32 	%r346, [%rd70+1024];
	ld.shared.u32 	%r347, [%rd71+1024];
	ld.shared.u32 	%r348, [%rd70+1280];
	ld.shared.u32 	%r349, [%rd71+1280];
	ld.shared.u32 	%r352, [%rd70+1536];
	ld.shared.u32 	%r353, [%rd71+1536];
	ld.shared.u32 	%r354, [%rd70+1792];
	ld.shared.u32 	%r355, [%rd71+1792];
	ld.shared.u32 	%r358, [%rd70+2048];
	ld.shared.u32 	%r359, [%rd71+2048];
	ld.shared.u32 	%r360, [%rd70+2304];
	ld.shared.u32 	%r361, [%rd71+2304];
	ld.shared.u32 	%r364, [%rd70+2560];
	ld.shared.u32 	%r365, [%rd71+2560];
	ld.shared.u32 	%r366, [%rd70+2816];
	ld.shared.u32 	%r367, [%rd71+2816];
	ld.shared.u32 	%r370, [%rd70+3072];
	ld.shared.u32 	%r371, [%rd71+3072];
	ld.shared.u32 	%r372, [%rd70+3328];
	ld.shared.u32 	%r373, [%rd71+3328];
	ld.shared.u32 	%r376, [%rd70+3584];
	ld.shared.u32 	%r377, [%rd71+3584];
	ld.shared.u32 	%r378, [%rd70+3840];
	ld.shared.u32 	%r379, [%rd71+3840];
	ld.shared.u32 	%r382, [%rd70+4096];
	ld.shared.u32 	%r383, [%rd71+4096];
	ld.shared.u32 	%r384, [%rd70+4352];
	ld.shared.u32 	%r385, [%rd71+4352];
	ld.shared.u32 	%r388, [%rd70+4608];
	ld.shared.u32 	%r389, [%rd71+4608];
	ld.shared.u32 	%r390, [%rd70+4864];
	ld.shared.u32 	%r391, [%rd71+4864];
	ld.shared.u32 	%r394, [%rd70+5120];
	ld.shared.u32 	%r395, [%rd71+5120];
	ld.shared.u32 	%r396, [%rd70+5376];
	ld.shared.u32 	%r397, [%rd71+5376];
	ld.shared.u32 	%r400, [%rd70+5632];
	ld.shared.u32 	%r401, [%rd71+5632];
	ld.shared.u32 	%r402, [%rd70+5888];
	ld.shared.u32 	%r403, [%rd71+5888];
	ld.shared.u32 	%r406, [%rd70+6144];
	ld.shared.u32 	%r407, [%rd71+6144];
	ld.shared.u32 	%r408, [%rd70+6400];
	ld.shared.u32 	%r409, [%rd71+6400];
	ld.shared.u32 	%r412, [%rd70+6656];
	ld.shared.u32 	%r413, [%rd71+6656];
	ld.shared.u32 	%r414, [%rd70+6912];
	ld.shared.u32 	%r415, [%rd71+6912];
	ld.shared.u32 	%r418, [%rd70+7168];
	ld.shared.u32 	%r419, [%rd71+7168];
	ld.shared.u32 	%r420, [%rd70+7424];
	ld.shared.u32 	%r421, [%rd71+7424];
	ld.shared.u32 	%r424, [%rd70+7680];
	ld.shared.u32 	%r425, [%rd71+7680];
	ld.shared.u32 	%r426, [%rd70+7936];
	ld.shared.u32 	%r427, [%rd71+7936];
	ld.shared.u32 	%r430, [%rd70+8192];
	ld.shared.u32 	%r431, [%rd71+8192];
	ld.shared.u32 	%r432, [%rd70+8448];
	ld.shared.u32 	%r433, [%rd71+8448];
	ld.shared.u32 	%r436, [%rd70+8704];
	ld.shared.u32 	%r437, [%rd71+8704];
	ld.shared.u32 	%r438, [%rd70+8960];
	ld.shared.u32 	%r439, [%rd71+8960];
	ld.shared.u32 	%r442, [%rd70+9216];
	ld.shared.u32 	%r443, [%rd71+9216];
	ld.shared.u32 	%r444, [%rd70+9472];
	ld.shared.u32 	%r445, [%rd71+9472];
	ld.shared.u32 	%r448, [%rd70+9728];
	ld.shared.u32 	%r449, [%rd71+9728];
	ld.shared.u32 	%r450, [%rd70+9984];
	ld.shared.u32 	%r451, [%rd71+9984];
	ld.shared.u32 	%r454, [%rd70+10240];
	ld.shared.u32 	%r455, [%rd71+10240];
	ld.shared.u32 	%r456, [%rd70+10496];
	ld.shared.u32 	%r457, [%rd71+10496];
	ld.shared.u32 	%r460, [%rd70+10752];
	ld.shared.u32 	%r461, [%rd71+10752];
	ld.shared.u32 	%r462, [%rd70+11008];
	ld.shared.u32 	%r463, [%rd71+11008];
	ld.shared.u32 	%r466, [%rd70+11264];
	ld.shared.u32 	%r467, [%rd71+11264];
	ld.shared.u32 	%r468, [%rd70+11520];
	ld.shared.u32 	%r469, [%rd71+11520];
	ld.shared.u32 	%r472, [%rd70+11776];
	ld.shared.u32 	%r473, [%rd71+11776];
	ld.shared.u32 	%r474, [%rd70+12032];
	ld.shared.u32 	%r475, [%rd71+12032];
	ld.shared.u32 	%r478, [%rd70+12288];
	ld.shared.u32 	%r479, [%rd71+12288];
	ld.shared.u32 	%r480, [%rd70+12544];
	ld.shared.u32 	%r481, [%rd71+12544];
	ld.shared.u32 	%r484, [%rd70+12800];
	ld.shared.u32 	%r485, [%rd71+12800];
	ld.shared.u32 	%r486, [%rd70+13056];
	ld.shared.u32 	%r487, [%rd71+13056];
	ld.shared.u32 	%r490, [%rd70+13312];
	ld.shared.u32 	%r491, [%rd71+13312];
	ld.shared.u32 	%r492, [%rd70+13568];
	ld.shared.u32 	%r493, [%rd71+13568];
	ld.shared.u32 	%r496, [%rd70+13824];
	ld.shared.u32 	%r497, [%rd71+13824];
	ld.shared.u32 	%r498, [%rd70+14080];
	ld.shared.u32 	%r499, [%rd71+14080];
	ld.shared.u32 	%r502, [%rd70+14336];
	ld.shared.u32 	%r503, [%rd71+14336];
	ld.shared.u32 	%r504, [%rd70+14592];
	ld.shared.u32 	%r505, [%rd71+14592];
	ld.shared.u32 	%r508, [%rd70+14848];
	ld.shared.u32 	%r509, [%rd71+14848];
	ld.shared.u32 	%r510, [%rd70+15104];
	ld.shared.u32 	%r511, [%rd71+15104];
	ld.shared.u32 	%r514, [%rd70+15360];
	ld.shared.u32 	%r515, [%rd71+15360];
	ld.shared.u32 	%r516, [%rd70+15616];
	ld.shared.u32 	%r517, [%rd71+15616];
	ld.shared.u32 	%r520, [%rd70+15872];
	ld.shared.u32 	%r521, [%rd71+15872];
	ld.shared.u32 	%r522, [%rd70+16128];
	ld.shared.u32 	%r523, [%rd71+16128];
	ld.shared.u32 	%r526, [%rd70+16384];
	ld.shared.u32 	%r527, [%rd71+16384];
	ld.shared.u32 	%r528, [%rd70+16640];
	ld.shared.u32 	%r529, [%rd71+16640];
	ld.shared.u32 	%r532, [%rd70+16896];
	ld.shared.u32 	%r533, [%rd71+16896];
	ld.shared.u32 	%r534, [%rd70+17152];
	ld.shared.u32 	%r535, [%rd71+17152];
	ld.shared.u32 	%r538, [%rd70+17408];
	ld.shared.u32 	%r539, [%rd71+17408];
	ld.shared.u32 	%r540, [%rd70+17664];
	ld.shared.u32 	%r541, [%rd71+17664];
	ld.shared.u32 	%r544, [%rd70+17920];
	ld.shared.u32 	%r545, [%rd71+17920];
	ld.shared.u32 	%r546, [%rd70+18176];
	ld.shared.u32 	%r547, [%rd71+18176];
	ld.shared.u32 	%r550, [%rd70+18432];
	ld.shared.u32 	%r551, [%rd71+18432];
	ld.shared.u32 	%r552, [%rd70+18688];
	ld.shared.u32 	%r553, [%rd71+18688];
	ld.shared.u32 	%r556, [%rd70+18944];
	ld.shared.u32 	%r557, [%rd71+18944];
	ld.shared.u32 	%r558, [%rd70+19200];
	ld.shared.u32 	%r559, [%rd71+19200];
	ld.shared.u32 	%r562, [%rd70+19456];
	ld.shared.u32 	%r563, [%rd71+19456];
	ld.shared.u32 	%r564, [%rd70+19712];
	ld.shared.u32 	%r565, [%rd71+19712];
	ld.shared.u32 	%r568, [%rd70+19968];
	ld.shared.u32 	%r569, [%rd71+19968];
	ld.shared.u32 	%r570, [%rd70+20224];
	ld.shared.u32 	%r571, [%rd71+20224];
	ld.shared.u32 	%r574, [%rd70+20480];
	ld.shared.u32 	%r575, [%rd71+20480];
	ld.shared.u32 	%r576, [%rd70+20736];
	ld.shared.u32 	%r577, [%rd71+20736];
	ld.shared.u32 	%r580, [%rd70+20992];
	ld.shared.u32 	%r581, [%rd71+20992];
	ld.shared.u32 	%r582, [%rd70+21248];
	ld.shared.u32 	%r583, [%rd71+21248];
	ld.shared.u32 	%r586, [%rd70+21504];
	ld.shared.u32 	%r587, [%rd71+21504];
	ld.shared.u32 	%r588, [%rd70+21760];
	ld.shared.u32 	%r589, [%rd71+21760];
	ld.shared.u32 	%r592, [%rd70+22016];
	ld.shared.u32 	%r593, [%rd71+22016];
	ld.shared.u32 	%r594, [%rd70+22272];
	ld.shared.u32 	%r595, [%rd71+22272];
	ld.shared.u32 	%r598, [%rd70+22528];
	ld.shared.u32 	%r599, [%rd71+22528];
	ld.shared.u32 	%r600, [%rd70+22784];
	ld.shared.u32 	%r601, [%rd71+22784];
	ld.shared.u32 	%r604, [%rd70+23040];
	ld.shared.u32 	%r605, [%rd71+23040];
	ld.shared.u32 	%r606, [%rd70+23296];
	ld.shared.u32 	%r607, [%rd71+23296];
	ld.shared.u32 	%r610, [%rd70+23552];
	ld.shared.u32 	%r611, [%rd71+23552];
	ld.shared.u32 	%r612, [%rd70+23808];
	ld.shared.u32 	%r613, [%rd71+23808];
	ld.shared.u32 	%r616, [%rd70+24064];
	ld.shared.u32 	%r617, [%rd71+24064];
	ld.shared.u32 	%r618, [%rd70+24320];
	ld.shared.u32 	%r619, [%rd71+24320];
	ld.shared.u32 	%r622, [%rd70+24576];
	ld.shared.u32 	%r623, [%rd71+24576];
	ld.shared.u32 	%r624, [%rd70+24832];
	ld.shared.u32 	%r625, [%rd71+24832];
	ld.shared.u32 	%r628, [%rd70+25088];
	ld.shared.u32 	%r629, [%rd71+25088];
	ld.shared.u32 	%r630, [%rd70+25344];
	ld.shared.u32 	%r631, [%rd71+25344];
	ld.shared.u32 	%r634, [%rd70+25600];
	ld.shared.u32 	%r635, [%rd71+25600];
	ld.shared.u32 	%r636, [%rd70+25856];
	ld.shared.u32 	%r637, [%rd71+25856];
	ld.shared.u32 	%r640, [%rd70+26112];
	ld.shared.u32 	%r641, [%rd71+26112];
	ld.shared.u32 	%r642, [%rd70+26368];
	ld.shared.u32 	%r643, [%rd71+26368];
	ld.shared.u32 	%r646, [%rd70+26624];
	ld.shared.u32 	%r647, [%rd71+26624];
	ld.shared.u32 	%r648, [%rd70+26880];
	ld.shared.u32 	%r649, [%rd71+26880];
	ld.shared.u32 	%r652, [%rd70+27136];
	ld.shared.u32 	%r653, [%rd71+27136];
	ld.shared.u32 	%r654, [%rd70+27392];
	ld.shared.u32 	%r655, [%rd71+27392];
	ld.shared.u32 	%r658, [%rd70+27648];
	ld.shared.u32 	%r659, [%rd71+27648];
	ld.shared.u32 	%r660, [%rd70+27904];
	ld.shared.u32 	%r661, [%rd71+27904];
	ld.shared.u32 	%r664, [%rd70+28160];
	ld.shared.u32 	%r665, [%rd71+28160];
	ld.shared.u32 	%r666, [%rd70+28416];
	ld.shared.u32 	%r667, [%rd71+28416];
	ld.shared.u32 	%r670, [%rd70+28672];
	ld.shared.u32 	%r671, [%rd71+28672];
	ld.shared.u32 	%r672, [%rd70+28928];
	ld.shared.u32 	%r673, [%rd71+28928];
	ld.shared.u32 	%r676, [%rd70+29184];
	ld.shared.u32 	%r677, [%rd71+29184];
	ld.shared.u32 	%r678, [%rd70+29440];
	ld.shared.u32 	%r679, [%rd71+29440];
	ld.shared.u32 	%r682, [%rd70+29696];
	ld.shared.u32 	%r683, [%rd71+29696];
	ld.shared.u32 	%r684, [%rd70+29952];
	ld.shared.u32 	%r685, [%rd71+29952];
	ld.shared.u32 	%r688, [%rd70+30208];
	ld.shared.u32 	%r689, [%rd71+30208];
	ld.shared.u32 	%r690, [%rd70+30464];
	ld.shared.u32 	%r691, [%rd71+30464];
	ld.shared.u32 	%r694, [%rd70+30720];
	ld.shared.u32 	%r695, [%rd71+30720];
	ld.shared.u32 	%r696, [%rd70+30976];
	ld.shared.u32 	%r697, [%rd71+30976];
	ld.shared.u32 	%r700, [%rd70+31232];
	ld.shared.u32 	%r701, [%rd71+31232];
	ld.shared.u32 	%r702, [%rd70+31488];
	ld.shared.u32 	%r703, [%rd71+31488];
	ld.shared.u32 	%r706, [%rd70+31744];
	ld.shared.u32 	%r707, [%rd71+31744];
	ld.shared.u32 	%r708, [%rd70+32000];
	ld.shared.u32 	%r709, [%rd71+32000];
	ld.shared.u32 	%r712, [%rd70+32256];
	ld.shared.u32 	%r713, [%rd71+32256];
	ld.shared.u32 	%r714, [%rd70+32512];
	ld.shared.u32 	%r715, [%rd71+32512];
	ld.shared.u32 	%r338, [%rd72];
	ld.shared.u32 	%r339, [%rd72+256];
	ld.shared.u32 	%r344, [%rd72+512];
	ld.shared.u32 	%r345, [%rd72+768];
	ld.shared.u32 	%r350, [%rd72+1024];
	ld.shared.u32 	%r351, [%rd72+1280];
	ld.shared.u32 	%r356, [%rd72+1536];
	ld.shared.u32 	%r357, [%rd72+1792];
	ld.shared.u32 	%r362, [%rd72+2048];
	ld.shared.u32 	%r363, [%rd72+2304];
	ld.shared.u32 	%r368, [%rd72+2560];
	ld.shared.u32 	%r369, [%rd72+2816];
	ld.shared.u32 	%r374, [%rd72+3072];
	ld.shared.u32 	%r375, [%rd72+3328];
	ld.shared.u32 	%r380, [%rd72+3584];
	ld.shared.u32 	%r381, [%rd72+3840];
	ld.shared.u32 	%r386, [%rd72+4096];
	ld.shared.u32 	%r387, [%rd72+4352];
	ld.shared.u32 	%r392, [%rd72+4608];
	ld.shared.u32 	%r393, [%rd72+4864];
	ld.shared.u32 	%r398, [%rd72+5120];
	ld.shared.u32 	%r399, [%rd72+5376];
	ld.shared.u32 	%r404, [%rd72+5632];
	ld.shared.u32 	%r405, [%rd72+5888];
	ld.shared.u32 	%r410, [%rd72+6144];
	ld.shared.u32 	%r411, [%rd72+6400];
	ld.shared.u32 	%r416, [%rd72+6656];
	ld.shared.u32 	%r417, [%rd72+6912];
	ld.shared.u32 	%r422, [%rd72+7168];
	ld.shared.u32 	%r423, [%rd72+7424];
	ld.shared.u32 	%r428, [%rd72+7680];
	ld.shared.u32 	%r429, [%rd72+7936];
	ld.shared.u32 	%r434, [%rd72+8192];
	ld.shared.u32 	%r435, [%rd72+8448];
	ld.shared.u32 	%r440, [%rd72+8704];
	ld.shared.u32 	%r441, [%rd72+8960];
	ld.shared.u32 	%r446, [%rd72+9216];
	ld.shared.u32 	%r447, [%rd72+9472];
	ld.shared.u32 	%r452, [%rd72+9728];
	ld.shared.u32 	%r453, [%rd72+9984];
	ld.shared.u32 	%r458, [%rd72+10240];
	ld.shared.u32 	%r459, [%rd72+10496];
	ld.shared.u32 	%r464, [%rd72+10752];
	ld.shared.u32 	%r465, [%rd72+11008];
	ld.shared.u32 	%r470, [%rd72+11264];
	ld.shared.u32 	%r471, [%rd72+11520];
	ld.shared.u32 	%r476, [%rd72+11776];
	ld.shared.u32 	%r477, [%rd72+12032];
	ld.shared.u32 	%r482, [%rd72+12288];
	ld.shared.u32 	%r483, [%rd72+12544];
	ld.shared.u32 	%r488, [%rd72+12800];
	ld.shared.u32 	%r489, [%rd72+13056];
	ld.shared.u32 	%r494, [%rd72+13312];
	ld.shared.u32 	%r495, [%rd72+13568];
	ld.shared.u32 	%r500, [%rd72+13824];
	ld.shared.u32 	%r501, [%rd72+14080];
	ld.shared.u32 	%r506, [%rd72+14336];
	ld.shared.u32 	%r507, [%rd72+14592];
	ld.shared.u32 	%r512, [%rd72+14848];
	ld.shared.u32 	%r513, [%rd72+15104];
	ld.shared.u32 	%r518, [%rd72+15360];
	ld.shared.u32 	%r519, [%rd72+15616];
	ld.shared.u32 	%r524, [%rd72+15872];
	ld.shared.u32 	%r525, [%rd72+16128];
	ld.shared.u32 	%r530, [%rd72+16384];
	ld.shared.u32 	%r531, [%rd72+16640];
	ld.shared.u32 	%r536, [%rd72+16896];
	ld.shared.u32 	%r537, [%rd72+17152];
	ld.shared.u32 	%r542, [%rd72+17408];
	ld.shared.u32 	%r543, [%rd72+17664];
	ld.shared.u32 	%r548, [%rd72+17920];
	ld.shared.u32 	%r549, [%rd72+18176];
	ld.shared.u32 	%r554, [%rd72+18432];
	ld.shared.u32 	%r555, [%rd72+18688];
	ld.shared.u32 	%r560, [%rd72+18944];
	ld.shared.u32 	%r561, [%rd72+19200];
	ld.shared.u32 	%r566, [%rd72+19456];
	ld.shared.u32 	%r567, [%rd72+19712];
	ld.shared.u32 	%r572, [%rd72+19968];
	ld.shared.u32 	%r573, [%rd72+20224];
	ld.shared.u32 	%r578, [%rd72+20480];
	ld.shared.u32 	%r579, [%rd72+20736];
	ld.shared.u32 	%r584, [%rd72+20992];
	ld.shared.u32 	%r585, [%rd72+21248];
	ld.shared.u32 	%r590, [%rd72+21504];
	ld.shared.u32 	%r591, [%rd72+21760];
	ld.shared.u32 	%r596, [%rd72+22016];
	ld.shared.u32 	%r597, [%rd72+22272];
	ld.shared.u32 	%r602, [%rd72+22528];
	ld.shared.u32 	%r603, [%rd72+22784];
	ld.shared.u32 	%r608, [%rd72+23040];
	ld.shared.u32 	%r609, [%rd72+23296];
	ld.shared.u32 	%r614, [%rd72+23552];
	ld.shared.u32 	%r615, [%rd72+23808];
	ld.shared.u32 	%r620, [%rd72+24064];
	ld.shared.u32 	%r621, [%rd72+24320];
	ld.shared.u32 	%r626, [%rd72+24576];
	ld.shared.u32 	%r627, [%rd72+24832];
	ld.shared.u32 	%r632, [%rd72+25088];
	ld.shared.u32 	%r633, [%rd72+25344];
	ld.shared.u32 	%r638, [%rd72+25600];
	ld.shared.u32 	%r639, [%rd72+25856];
	ld.shared.u32 	%r644, [%rd72+26112];
	ld.shared.u32 	%r645, [%rd72+26368];
	ld.shared.u32 	%r650, [%rd72+26624];
	ld.shared.u32 	%r651, [%rd72+26880];
	ld.shared.u32 	%r656, [%rd72+27136];
	ld.shared.u32 	%r657, [%rd72+27392];
	ld.shared.u32 	%r662, [%rd72+27648];
	ld.shared.u32 	%r663, [%rd72+27904];
	ld.shared.u32 	%r668, [%rd72+28160];
	ld.shared.u32 	%r669, [%rd72+28416];
	ld.shared.u32 	%r674, [%rd72+28672];
	ld.shared.u32 	%r675, [%rd72+28928];
	ld.shared.u32 	%r680, [%rd72+29184];
	ld.shared.u32 	%r681, [%rd72+29440];
	ld.shared.u32 	%r686, [%rd72+29696];
	ld.shared.u32 	%r687, [%rd72+29952];
	ld.shared.u32 	%r692, [%rd72+30208];
	ld.shared.u32 	%r693, [%rd72+30464];
	ld.shared.u32 	%r698, [%rd72+30720];
	ld.shared.u32 	%r699, [%rd72+30976];
	ld.shared.u32 	%r704, [%rd72+31232];
	ld.shared.u32 	%r705, [%rd72+31488];
	ld.shared.u32 	%r710, [%rd72+31744];
	ld.shared.u32 	%r711, [%rd72+32000];
	ld.shared.u32 	%r716, [%rd72+32256];
	ld.shared.u32 	%r717, [%rd72+32512];
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r334, %r335, %r336, %r337 }, { %r338, %r339 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r340, %r341, %r342, %r343 }, { %r344, %r345 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r346, %r347, %r348, %r349 }, { %r350, %r351 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r352, %r353, %r354, %r355 }, { %r356, %r357 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r358, %r359, %r360, %r361 }, { %r362, %r363 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r364, %r365, %r366, %r367 }, { %r368, %r369 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r370, %r371, %r372, %r373 }, { %r374, %r375 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r376, %r377, %r378, %r379 }, { %r380, %r381 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r382, %r383, %r384, %r385 }, { %r386, %r387 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r388, %r389, %r390, %r391 }, { %r392, %r393 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r394, %r395, %r396, %r397 }, { %r398, %r399 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r400, %r401, %r402, %r403 }, { %r404, %r405 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r406, %r407, %r408, %r409 }, { %r410, %r411 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r412, %r413, %r414, %r415 }, { %r416, %r417 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r418, %r419, %r420, %r421 }, { %r422, %r423 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r424, %r425, %r426, %r427 }, { %r428, %r429 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r430, %r431, %r432, %r433 }, { %r434, %r435 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r436, %r437, %r438, %r439 }, { %r440, %r441 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r442, %r443, %r444, %r445 }, { %r446, %r447 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r448, %r449, %r450, %r451 }, { %r452, %r453 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r454, %r455, %r456, %r457 }, { %r458, %r459 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r460, %r461, %r462, %r463 }, { %r464, %r465 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r466, %r467, %r468, %r469 }, { %r470, %r471 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r472, %r473, %r474, %r475 }, { %r476, %r477 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r478, %r479, %r480, %r481 }, { %r482, %r483 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r484, %r485, %r486, %r487 }, { %r488, %r489 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r490, %r491, %r492, %r493 }, { %r494, %r495 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r496, %r497, %r498, %r499 }, { %r500, %r501 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r502, %r503, %r504, %r505 }, { %r506, %r507 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r508, %r509, %r510, %r511 }, { %r512, %r513 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r514, %r515, %r516, %r517 }, { %r518, %r519 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r520, %r521, %r522, %r523 }, { %r524, %r525 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r526, %r527, %r528, %r529 }, { %r530, %r531 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r532, %r533, %r534, %r535 }, { %r536, %r537 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r538, %r539, %r540, %r541 }, { %r542, %r543 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r544, %r545, %r546, %r547 }, { %r548, %r549 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r550, %r551, %r552, %r553 }, { %r554, %r555 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r556, %r557, %r558, %r559 }, { %r560, %r561 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r562, %r563, %r564, %r565 }, { %r566, %r567 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r568, %r569, %r570, %r571 }, { %r572, %r573 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r574, %r575, %r576, %r577 }, { %r578, %r579 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r580, %r581, %r582, %r583 }, { %r584, %r585 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r586, %r587, %r588, %r589 }, { %r590, %r591 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r592, %r593, %r594, %r595 }, { %r596, %r597 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r598, %r599, %r600, %r601 }, { %r602, %r603 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r604, %r605, %r606, %r607 }, { %r608, %r609 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r610, %r611, %r612, %r613 }, { %r614, %r615 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r616, %r617, %r618, %r619 }, { %r620, %r621 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r622, %r623, %r624, %r625 }, { %r626, %r627 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r628, %r629, %r630, %r631 }, { %r632, %r633 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r634, %r635, %r636, %r637 }, { %r638, %r639 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r640, %r641, %r642, %r643 }, { %r644, %r645 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r646, %r647, %r648, %r649 }, { %r650, %r651 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r652, %r653, %r654, %r655 }, { %r656, %r657 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r658, %r659, %r660, %r661 }, { %r662, %r663 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r664, %r665, %r666, %r667 }, { %r668, %r669 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r670, %r671, %r672, %r673 }, { %r674, %r675 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r676, %r677, %r678, %r679 }, { %r680, %r681 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r682, %r683, %r684, %r685 }, { %r686, %r687 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r688, %r689, %r690, %r691 }, { %r692, %r693 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r694, %r695, %r696, %r697 }, { %r698, %r699 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r700, %r701, %r702, %r703 }, { %r704, %r705 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r706, %r707, %r708, %r709 }, { %r710, %r711 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r712, %r713, %r714, %r715 }, { %r716, %r717 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	add.s32 	%r730, %r730, 512;
	add.s64 	%rd212, %rd212, 786432;
	add.s64 	%rd211, %rd211, 12288;
	setp.lt.u32 	%p193, %r730, 50688;
	@%p193 bra 	$L__BB299_1;
	mul.lo.s32 	%r720, %r10, 36;
	mul.wide.s32 	%rd199, %r720, 4;
	add.s64 	%rd200, %rd1, %rd199;
	or.b64  	%rd201, %rd2, %rd4;
	mul.lo.s64 	%rd202, %rd201, 24;
	add.s64 	%rd203, %rd200, %rd202;
	shl.b64 	%rd204, %rd5, 2;
	add.s64 	%rd198, %rd203, %rd204;
	max.u64 	%rd205, %rd5, %rd201;
	setp.lt.u64 	%p194, %rd205, 6;
	bar.sync 	0;
	and.b32  	%r721, %r3, 6;
	shl.b32 	%r722, %r5, 3;
	and.b32  	%r723, %r722, 8;
	or.b32  	%r724, %r723, %r721;
	mad.lo.s32 	%r725, %r6, 18, %r724;
	mul.wide.u32 	%rd206, %r725, 4;
	add.s64 	%rd208, %rd88, %rd206;
	st.shared.v2.f32 	[%rd208], {%f529, %f530};
	st.shared.v2.f32 	[%rd208+576], {%f531, %f532};
	bar.sync 	0;
	shr.u32 	%r726, %r2, 3;
	shl.b32 	%r727, %r5, 2;
	or.b32  	%r728, %r727, %r726;
	mad.lo.s32 	%r729, %r728, 18, %r4;
	mul.wide.u32 	%rd209, %r729, 4;
	add.s64 	%rd210, %rd88, %rd209;
	ld.shared.v2.u32 	{%r718, %r719}, [%rd210];
	// begin inline asm
	@%p194 st.global.v2.b32 [ %rd198 + 0 ], { %r718, %r719 };
	// end inline asm
	ret;

}
	// .globl	gemm_fusion_dot_644_1
.visible .entry gemm_fusion_dot_644_1(
	.param .u64 gemm_fusion_dot_644_1_param_0,
	.param .u64 gemm_fusion_dot_644_1_param_1,
	.param .u64 gemm_fusion_dot_644_1_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<195>;
	.reg .b32 	%r<731>;
	.reg .f32 	%f<533>;
	.reg .b64 	%rd<213>;

	ld.param.u64 	%rd80, [gemm_fusion_dot_644_1_param_0];
	ld.param.u64 	%rd81, [gemm_fusion_dot_644_1_param_2];
	cvta.to.global.u64 	%rd1, %rd81;
	ld.param.u64 	%rd82, [gemm_fusion_dot_644_1_param_1];
	cvta.to.global.u64 	%rd83, %rd82;
	cvta.to.global.u64 	%rd84, %rd80;
	// begin inline asm
	mov.u32 %r9, %ctaid.x;
	// end inline asm
	shr.s32 	%r12, %r9, 31;
	shr.u32 	%r13, %r12, 29;
	add.s32 	%r14, %r9, %r13;
	and.b32  	%r15, %r14, -8;
	mov.b32 	%r16, 1;
	sub.s32 	%r17, %r16, %r15;
	min.s32 	%r18, %r17, 8;
	rem.s32 	%r19, %r9, %r18;
	add.s32 	%r20, %r15, %r19;
	sub.s32 	%r21, %r9, %r15;
	div.s32 	%r22, %r21, %r18;
	shl.b32 	%r23, %r20, 4;
	// begin inline asm
	mov.u32 %r10, %ctaid.y;
	// end inline asm
	mul.lo.s32 	%r24, %r10, 307200;
	cvt.s64.s32 	%rd2, %r23;
	shl.b32 	%r25, %r22, 4;
	mul.lo.s32 	%r26, %r10, 6;
	cvt.s64.s32 	%rd85, %r25;
	mov.u32 	%r27, %tid.x;
	and.b32  	%r2, %r27, 31;
	shl.b32 	%r3, %r27, 1;
	and.b32  	%r4, %r3, 14;
	cvt.u64.u32 	%rd86, %r4;
	or.b64  	%rd3, %rd2, %rd86;
	shr.u32 	%r5, %r27, 5;
	shr.u32 	%r28, %r27, 3;
	cvt.u64.u32 	%rd4, %r28;
	or.b64  	%rd5, %rd85, %rd86;
	shr.u32 	%r29, %r27, 1;
	and.b32  	%r30, %r29, 8;
	xor.b32  	%r31, %r4, %r30;
	shl.b32 	%r32, %r28, 4;
	or.b32  	%r33, %r31, %r32;
	mul.wide.u32 	%rd87, %r33, 4;
	mov.u64 	%rd88, global_smem;
	add.s64 	%rd6, %rd88, %rd87;
	or.b32  	%r34, %r33, 256;
	mul.wide.u32 	%rd89, %r34, 4;
	add.s64 	%rd7, %rd88, %rd89;
	or.b32  	%r35, %r33, 512;
	mul.wide.u32 	%rd90, %r35, 4;
	add.s64 	%rd8, %rd88, %rd90;
	or.b32  	%r36, %r33, 768;
	mul.wide.u32 	%rd91, %r36, 4;
	add.s64 	%rd9, %rd88, %rd91;
	or.b32  	%r37, %r33, 1024;
	mul.wide.u32 	%rd92, %r37, 4;
	add.s64 	%rd10, %rd88, %rd92;
	or.b32  	%r38, %r33, 1280;
	mul.wide.u32 	%rd93, %r38, 4;
	add.s64 	%rd11, %rd88, %rd93;
	or.b32  	%r39, %r33, 1536;
	mul.wide.u32 	%rd94, %r39, 4;
	add.s64 	%rd12, %rd88, %rd94;
	or.b32  	%r40, %r33, 1792;
	mul.wide.u32 	%rd95, %r40, 4;
	add.s64 	%rd13, %rd88, %rd95;
	or.b32  	%r41, %r33, 2048;
	mul.wide.u32 	%rd96, %r41, 4;
	add.s64 	%rd14, %rd88, %rd96;
	or.b32  	%r42, %r33, 2304;
	mul.wide.u32 	%rd97, %r42, 4;
	add.s64 	%rd15, %rd88, %rd97;
	or.b32  	%r43, %r33, 2560;
	mul.wide.u32 	%rd98, %r43, 4;
	add.s64 	%rd16, %rd88, %rd98;
	or.b32  	%r44, %r33, 2816;
	mul.wide.u32 	%rd99, %r44, 4;
	add.s64 	%rd17, %rd88, %rd99;
	or.b32  	%r45, %r33, 3072;
	mul.wide.u32 	%rd100, %r45, 4;
	add.s64 	%rd18, %rd88, %rd100;
	or.b32  	%r46, %r33, 3328;
	mul.wide.u32 	%rd101, %r46, 4;
	add.s64 	%rd19, %rd88, %rd101;
	or.b32  	%r47, %r33, 3584;
	mul.wide.u32 	%rd102, %r47, 4;
	add.s64 	%rd20, %rd88, %rd102;
	or.b32  	%r48, %r33, 3840;
	mul.wide.u32 	%rd103, %r48, 4;
	add.s64 	%rd21, %rd88, %rd103;
	or.b32  	%r49, %r33, 4096;
	mul.wide.u32 	%rd104, %r49, 4;
	add.s64 	%rd22, %rd88, %rd104;
	or.b32  	%r50, %r33, 4352;
	mul.wide.u32 	%rd105, %r50, 4;
	add.s64 	%rd23, %rd88, %rd105;
	or.b32  	%r51, %r33, 4608;
	mul.wide.u32 	%rd106, %r51, 4;
	add.s64 	%rd24, %rd88, %rd106;
	or.b32  	%r52, %r33, 4864;
	mul.wide.u32 	%rd107, %r52, 4;
	add.s64 	%rd25, %rd88, %rd107;
	or.b32  	%r53, %r33, 5120;
	mul.wide.u32 	%rd108, %r53, 4;
	add.s64 	%rd26, %rd88, %rd108;
	or.b32  	%r54, %r33, 5376;
	mul.wide.u32 	%rd109, %r54, 4;
	add.s64 	%rd27, %rd88, %rd109;
	or.b32  	%r55, %r33, 5632;
	mul.wide.u32 	%rd110, %r55, 4;
	add.s64 	%rd28, %rd88, %rd110;
	or.b32  	%r56, %r33, 5888;
	mul.wide.u32 	%rd111, %r56, 4;
	add.s64 	%rd29, %rd88, %rd111;
	or.b32  	%r57, %r33, 6144;
	mul.wide.u32 	%rd112, %r57, 4;
	add.s64 	%rd30, %rd88, %rd112;
	or.b32  	%r58, %r33, 6400;
	mul.wide.u32 	%rd113, %r58, 4;
	add.s64 	%rd31, %rd88, %rd113;
	or.b32  	%r59, %r33, 6656;
	mul.wide.u32 	%rd114, %r59, 4;
	add.s64 	%rd32, %rd88, %rd114;
	or.b32  	%r60, %r33, 6912;
	mul.wide.u32 	%rd115, %r60, 4;
	add.s64 	%rd33, %rd88, %rd115;
	or.b32  	%r61, %r33, 7168;
	mul.wide.u32 	%rd116, %r61, 4;
	add.s64 	%rd34, %rd88, %rd116;
	or.b32  	%r62, %r33, 7424;
	mul.wide.u32 	%rd117, %r62, 4;
	add.s64 	%rd35, %rd88, %rd117;
	or.b32  	%r63, %r33, 7680;
	mul.wide.u32 	%rd118, %r63, 4;
	add.s64 	%rd36, %rd88, %rd118;
	or.b32  	%r64, %r33, 7936;
	mul.wide.u32 	%rd119, %r64, 4;
	add.s64 	%rd37, %rd88, %rd119;
	add.s64 	%rd120, %rd88, 32768;
	add.s64 	%rd38, %rd120, %rd87;
	add.s64 	%rd39, %rd120, %rd89;
	add.s64 	%rd40, %rd120, %rd90;
	add.s64 	%rd41, %rd120, %rd91;
	add.s64 	%rd42, %rd120, %rd92;
	add.s64 	%rd43, %rd120, %rd93;
	add.s64 	%rd44, %rd120, %rd94;
	add.s64 	%rd45, %rd120, %rd95;
	add.s64 	%rd46, %rd120, %rd96;
	add.s64 	%rd47, %rd120, %rd97;
	add.s64 	%rd48, %rd120, %rd98;
	add.s64 	%rd49, %rd120, %rd99;
	add.s64 	%rd50, %rd120, %rd100;
	add.s64 	%rd51, %rd120, %rd101;
	add.s64 	%rd52, %rd120, %rd102;
	add.s64 	%rd53, %rd120, %rd103;
	add.s64 	%rd54, %rd120, %rd104;
	add.s64 	%rd55, %rd120, %rd105;
	add.s64 	%rd56, %rd120, %rd106;
	add.s64 	%rd57, %rd120, %rd107;
	add.s64 	%rd58, %rd120, %rd108;
	add.s64 	%rd59, %rd120, %rd109;
	add.s64 	%rd60, %rd120, %rd110;
	add.s64 	%rd61, %rd120, %rd111;
	add.s64 	%rd62, %rd120, %rd112;
	add.s64 	%rd63, %rd120, %rd113;
	add.s64 	%rd64, %rd120, %rd114;
	add.s64 	%rd65, %rd120, %rd115;
	add.s64 	%rd66, %rd120, %rd116;
	add.s64 	%rd67, %rd120, %rd117;
	add.s64 	%rd68, %rd120, %rd118;
	add.s64 	%rd69, %rd120, %rd119;
	bfe.u32 	%r6, %r27, 2, 3;
	and.b32  	%r65, %r27, 3;
	bfe.u32 	%r66, %r27, 1, 1;
	shl.b32 	%r67, %r66, 3;
	or.b32  	%r68, %r67, %r6;
	shl.b32 	%r69, %r65, 4;
	or.b32  	%r70, %r68, %r69;
	xor.b32  	%r71, %r70, 8;
	mul.wide.u32 	%rd121, %r70, 4;
	add.s64 	%rd70, %rd88, %rd121;
	mul.wide.u32 	%rd122, %r71, 4;
	add.s64 	%rd71, %rd88, %rd122;
	bfe.u32 	%r72, %r27, 5, 1;
	xor.b32  	%r73, %r72, %r66;
	shl.b32 	%r74, %r73, 3;
	or.b32  	%r75, %r74, %r6;
	or.b32  	%r76, %r75, %r69;
	mul.wide.u32 	%rd123, %r76, 4;
	add.s64 	%rd72, %rd120, %rd123;
	and.b32  	%r77, %r27, 7;
	mul.wide.u32 	%rd73, %r77, 8;
	mul.wide.u32 	%rd124, %r28, 1536;
	mul.wide.s32 	%rd125, %r25, 4;
	add.s64 	%rd126, %rd124, %rd125;
	mul.wide.s32 	%rd127, %r26, 4;
	add.s64 	%rd128, %rd126, %rd127;
	add.s64 	%rd212, %rd83, %rd128;
	mul.wide.u32 	%rd129, %r28, 24;
	mul.wide.s32 	%rd130, %r24, 4;
	or.b64  	%rd131, %rd129, %rd130;
	mul.wide.s32 	%rd132, %r23, 4;
	add.s64 	%rd133, %rd131, %rd132;
	add.s64 	%rd211, %rd84, %rd133;
	mov.f32 	%f529, 0f00000000;
	mov.b32 	%r730, -512;
	setp.lt.u64 	%p97, %rd5, 6;
	setp.lt.u64 	%p1, %rd3, 6;
	mov.f32 	%f530, %f529;
	mov.f32 	%f531, %f529;
	mov.f32 	%f532, %f529;
$L__BB300_1:
	add.s64 	%rd134, %rd211, %rd73;
	add.s64 	%rd135, %rd134, 384;
	add.s64 	%rd136, %rd134, 768;
	add.s64 	%rd137, %rd134, 1152;
	add.s64 	%rd138, %rd134, 1536;
	add.s64 	%rd139, %rd134, 1920;
	add.s64 	%rd140, %rd134, 2304;
	add.s64 	%rd141, %rd134, 2688;
	add.s64 	%rd142, %rd134, 3072;
	add.s64 	%rd143, %rd134, 3456;
	add.s64 	%rd144, %rd134, 3840;
	add.s64 	%rd145, %rd134, 4224;
	add.s64 	%rd146, %rd134, 4608;
	add.s64 	%rd147, %rd134, 4992;
	add.s64 	%rd148, %rd134, 5376;
	add.s64 	%rd149, %rd134, 5760;
	add.s64 	%rd150, %rd134, 6144;
	add.s64 	%rd151, %rd134, 6528;
	add.s64 	%rd152, %rd134, 6912;
	add.s64 	%rd153, %rd134, 7296;
	add.s64 	%rd154, %rd134, 7680;
	add.s64 	%rd155, %rd134, 8064;
	add.s64 	%rd156, %rd134, 8448;
	add.s64 	%rd157, %rd134, 8832;
	add.s64 	%rd158, %rd134, 9216;
	add.s64 	%rd159, %rd134, 9600;
	add.s64 	%rd160, %rd134, 9984;
	add.s64 	%rd161, %rd134, 10368;
	add.s64 	%rd162, %rd134, 10752;
	add.s64 	%rd163, %rd134, 11136;
	add.s64 	%rd164, %rd134, 11520;
	add.s64 	%rd165, %rd134, 11904;
	mov.b32 	%r80, 0;
	// begin inline asm
	mov.u32 %r78, 0x0;
	mov.u32 %r79, 0x0;
	@%p1 ld.global.v2.b32 { %r78, %r79 }, [ %rd134 + 0 ];
	@!%p1 mov.u32 %r78, %r80;
	@!%p1 mov.u32 %r79, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r82, 0x0;
	mov.u32 %r83, 0x0;
	@%p1 ld.global.v2.b32 { %r82, %r83 }, [ %rd135 + 0 ];
	@!%p1 mov.u32 %r82, %r80;
	@!%p1 mov.u32 %r83, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r86, 0x0;
	mov.u32 %r87, 0x0;
	@%p1 ld.global.v2.b32 { %r86, %r87 }, [ %rd136 + 0 ];
	@!%p1 mov.u32 %r86, %r80;
	@!%p1 mov.u32 %r87, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r90, 0x0;
	mov.u32 %r91, 0x0;
	@%p1 ld.global.v2.b32 { %r90, %r91 }, [ %rd137 + 0 ];
	@!%p1 mov.u32 %r90, %r80;
	@!%p1 mov.u32 %r91, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r94, 0x0;
	mov.u32 %r95, 0x0;
	@%p1 ld.global.v2.b32 { %r94, %r95 }, [ %rd138 + 0 ];
	@!%p1 mov.u32 %r94, %r80;
	@!%p1 mov.u32 %r95, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r98, 0x0;
	mov.u32 %r99, 0x0;
	@%p1 ld.global.v2.b32 { %r98, %r99 }, [ %rd139 + 0 ];
	@!%p1 mov.u32 %r98, %r80;
	@!%p1 mov.u32 %r99, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r102, 0x0;
	mov.u32 %r103, 0x0;
	@%p1 ld.global.v2.b32 { %r102, %r103 }, [ %rd140 + 0 ];
	@!%p1 mov.u32 %r102, %r80;
	@!%p1 mov.u32 %r103, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r106, 0x0;
	mov.u32 %r107, 0x0;
	@%p1 ld.global.v2.b32 { %r106, %r107 }, [ %rd141 + 0 ];
	@!%p1 mov.u32 %r106, %r80;
	@!%p1 mov.u32 %r107, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r110, 0x0;
	mov.u32 %r111, 0x0;
	@%p1 ld.global.v2.b32 { %r110, %r111 }, [ %rd142 + 0 ];
	@!%p1 mov.u32 %r110, %r80;
	@!%p1 mov.u32 %r111, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r114, 0x0;
	mov.u32 %r115, 0x0;
	@%p1 ld.global.v2.b32 { %r114, %r115 }, [ %rd143 + 0 ];
	@!%p1 mov.u32 %r114, %r80;
	@!%p1 mov.u32 %r115, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r118, 0x0;
	mov.u32 %r119, 0x0;
	@%p1 ld.global.v2.b32 { %r118, %r119 }, [ %rd144 + 0 ];
	@!%p1 mov.u32 %r118, %r80;
	@!%p1 mov.u32 %r119, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r122, 0x0;
	mov.u32 %r123, 0x0;
	@%p1 ld.global.v2.b32 { %r122, %r123 }, [ %rd145 + 0 ];
	@!%p1 mov.u32 %r122, %r80;
	@!%p1 mov.u32 %r123, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r126, 0x0;
	mov.u32 %r127, 0x0;
	@%p1 ld.global.v2.b32 { %r126, %r127 }, [ %rd146 + 0 ];
	@!%p1 mov.u32 %r126, %r80;
	@!%p1 mov.u32 %r127, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r130, 0x0;
	mov.u32 %r131, 0x0;
	@%p1 ld.global.v2.b32 { %r130, %r131 }, [ %rd147 + 0 ];
	@!%p1 mov.u32 %r130, %r80;
	@!%p1 mov.u32 %r131, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r134, 0x0;
	mov.u32 %r135, 0x0;
	@%p1 ld.global.v2.b32 { %r134, %r135 }, [ %rd148 + 0 ];
	@!%p1 mov.u32 %r134, %r80;
	@!%p1 mov.u32 %r135, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r138, 0x0;
	mov.u32 %r139, 0x0;
	@%p1 ld.global.v2.b32 { %r138, %r139 }, [ %rd149 + 0 ];
	@!%p1 mov.u32 %r138, %r80;
	@!%p1 mov.u32 %r139, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r142, 0x0;
	mov.u32 %r143, 0x0;
	@%p1 ld.global.v2.b32 { %r142, %r143 }, [ %rd150 + 0 ];
	@!%p1 mov.u32 %r142, %r80;
	@!%p1 mov.u32 %r143, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r146, 0x0;
	mov.u32 %r147, 0x0;
	@%p1 ld.global.v2.b32 { %r146, %r147 }, [ %rd151 + 0 ];
	@!%p1 mov.u32 %r146, %r80;
	@!%p1 mov.u32 %r147, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r150, 0x0;
	mov.u32 %r151, 0x0;
	@%p1 ld.global.v2.b32 { %r150, %r151 }, [ %rd152 + 0 ];
	@!%p1 mov.u32 %r150, %r80;
	@!%p1 mov.u32 %r151, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r154, 0x0;
	mov.u32 %r155, 0x0;
	@%p1 ld.global.v2.b32 { %r154, %r155 }, [ %rd153 + 0 ];
	@!%p1 mov.u32 %r154, %r80;
	@!%p1 mov.u32 %r155, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r158, 0x0;
	mov.u32 %r159, 0x0;
	@%p1 ld.global.v2.b32 { %r158, %r159 }, [ %rd154 + 0 ];
	@!%p1 mov.u32 %r158, %r80;
	@!%p1 mov.u32 %r159, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r162, 0x0;
	mov.u32 %r163, 0x0;
	@%p1 ld.global.v2.b32 { %r162, %r163 }, [ %rd155 + 0 ];
	@!%p1 mov.u32 %r162, %r80;
	@!%p1 mov.u32 %r163, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r166, 0x0;
	mov.u32 %r167, 0x0;
	@%p1 ld.global.v2.b32 { %r166, %r167 }, [ %rd156 + 0 ];
	@!%p1 mov.u32 %r166, %r80;
	@!%p1 mov.u32 %r167, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r170, 0x0;
	mov.u32 %r171, 0x0;
	@%p1 ld.global.v2.b32 { %r170, %r171 }, [ %rd157 + 0 ];
	@!%p1 mov.u32 %r170, %r80;
	@!%p1 mov.u32 %r171, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r174, 0x0;
	mov.u32 %r175, 0x0;
	@%p1 ld.global.v2.b32 { %r174, %r175 }, [ %rd158 + 0 ];
	@!%p1 mov.u32 %r174, %r80;
	@!%p1 mov.u32 %r175, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r178, 0x0;
	mov.u32 %r179, 0x0;
	@%p1 ld.global.v2.b32 { %r178, %r179 }, [ %rd159 + 0 ];
	@!%p1 mov.u32 %r178, %r80;
	@!%p1 mov.u32 %r179, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r182, 0x0;
	mov.u32 %r183, 0x0;
	@%p1 ld.global.v2.b32 { %r182, %r183 }, [ %rd160 + 0 ];
	@!%p1 mov.u32 %r182, %r80;
	@!%p1 mov.u32 %r183, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r186, 0x0;
	mov.u32 %r187, 0x0;
	@%p1 ld.global.v2.b32 { %r186, %r187 }, [ %rd161 + 0 ];
	@!%p1 mov.u32 %r186, %r80;
	@!%p1 mov.u32 %r187, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r190, 0x0;
	mov.u32 %r191, 0x0;
	@%p1 ld.global.v2.b32 { %r190, %r191 }, [ %rd162 + 0 ];
	@!%p1 mov.u32 %r190, %r80;
	@!%p1 mov.u32 %r191, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r194, 0x0;
	mov.u32 %r195, 0x0;
	@%p1 ld.global.v2.b32 { %r194, %r195 }, [ %rd163 + 0 ];
	@!%p1 mov.u32 %r194, %r80;
	@!%p1 mov.u32 %r195, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r198, 0x0;
	mov.u32 %r199, 0x0;
	@%p1 ld.global.v2.b32 { %r198, %r199 }, [ %rd164 + 0 ];
	@!%p1 mov.u32 %r198, %r80;
	@!%p1 mov.u32 %r199, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r202, 0x0;
	mov.u32 %r203, 0x0;
	@%p1 ld.global.v2.b32 { %r202, %r203 }, [ %rd165 + 0 ];
	@!%p1 mov.u32 %r202, %r80;
	@!%p1 mov.u32 %r203, %r80;
	// end inline asm
	bar.sync 	0;
	st.shared.v2.u32 	[%rd6], {%r78, %r79};
	st.shared.v2.u32 	[%rd7], {%r82, %r83};
	st.shared.v2.u32 	[%rd8], {%r86, %r87};
	st.shared.v2.u32 	[%rd9], {%r90, %r91};
	st.shared.v2.u32 	[%rd10], {%r94, %r95};
	st.shared.v2.u32 	[%rd11], {%r98, %r99};
	st.shared.v2.u32 	[%rd12], {%r102, %r103};
	st.shared.v2.u32 	[%rd13], {%r106, %r107};
	st.shared.v2.u32 	[%rd14], {%r110, %r111};
	st.shared.v2.u32 	[%rd15], {%r114, %r115};
	st.shared.v2.u32 	[%rd16], {%r118, %r119};
	st.shared.v2.u32 	[%rd17], {%r122, %r123};
	st.shared.v2.u32 	[%rd18], {%r126, %r127};
	st.shared.v2.u32 	[%rd19], {%r130, %r131};
	st.shared.v2.u32 	[%rd20], {%r134, %r135};
	st.shared.v2.u32 	[%rd21], {%r138, %r139};
	st.shared.v2.u32 	[%rd22], {%r142, %r143};
	st.shared.v2.u32 	[%rd23], {%r146, %r147};
	st.shared.v2.u32 	[%rd24], {%r150, %r151};
	st.shared.v2.u32 	[%rd25], {%r154, %r155};
	st.shared.v2.u32 	[%rd26], {%r158, %r159};
	st.shared.v2.u32 	[%rd27], {%r162, %r163};
	st.shared.v2.u32 	[%rd28], {%r166, %r167};
	st.shared.v2.u32 	[%rd29], {%r170, %r171};
	st.shared.v2.u32 	[%rd30], {%r174, %r175};
	st.shared.v2.u32 	[%rd31], {%r178, %r179};
	st.shared.v2.u32 	[%rd32], {%r182, %r183};
	st.shared.v2.u32 	[%rd33], {%r186, %r187};
	st.shared.v2.u32 	[%rd34], {%r190, %r191};
	st.shared.v2.u32 	[%rd35], {%r194, %r195};
	st.shared.v2.u32 	[%rd36], {%r198, %r199};
	st.shared.v2.u32 	[%rd37], {%r202, %r203};
	add.s64 	%rd166, %rd212, %rd73;
	add.s64 	%rd167, %rd166, 24576;
	add.s64 	%rd168, %rd166, 49152;
	add.s64 	%rd169, %rd166, 73728;
	add.s64 	%rd170, %rd166, 98304;
	add.s64 	%rd171, %rd166, 122880;
	add.s64 	%rd172, %rd166, 147456;
	add.s64 	%rd173, %rd166, 172032;
	add.s64 	%rd174, %rd166, 196608;
	add.s64 	%rd175, %rd166, 221184;
	add.s64 	%rd176, %rd166, 245760;
	add.s64 	%rd177, %rd166, 270336;
	add.s64 	%rd178, %rd166, 294912;
	add.s64 	%rd179, %rd166, 319488;
	add.s64 	%rd180, %rd166, 344064;
	add.s64 	%rd181, %rd166, 368640;
	add.s64 	%rd182, %rd166, 393216;
	add.s64 	%rd183, %rd166, 417792;
	add.s64 	%rd184, %rd166, 442368;
	add.s64 	%rd185, %rd166, 466944;
	add.s64 	%rd186, %rd166, 491520;
	add.s64 	%rd187, %rd166, 516096;
	add.s64 	%rd188, %rd166, 540672;
	add.s64 	%rd189, %rd166, 565248;
	add.s64 	%rd190, %rd166, 589824;
	add.s64 	%rd191, %rd166, 614400;
	add.s64 	%rd192, %rd166, 638976;
	add.s64 	%rd193, %rd166, 663552;
	add.s64 	%rd194, %rd166, 688128;
	add.s64 	%rd195, %rd166, 712704;
	add.s64 	%rd196, %rd166, 737280;
	add.s64 	%rd197, %rd166, 761856;
	// begin inline asm
	mov.u32 %r206, 0x0;
	mov.u32 %r207, 0x0;
	@%p97 ld.global.v2.b32 { %r206, %r207 }, [ %rd166 + 0 ];
	@!%p97 mov.u32 %r206, %r80;
	@!%p97 mov.u32 %r207, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r210, 0x0;
	mov.u32 %r211, 0x0;
	@%p97 ld.global.v2.b32 { %r210, %r211 }, [ %rd167 + 0 ];
	@!%p97 mov.u32 %r210, %r80;
	@!%p97 mov.u32 %r211, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r214, 0x0;
	mov.u32 %r215, 0x0;
	@%p97 ld.global.v2.b32 { %r214, %r215 }, [ %rd168 + 0 ];
	@!%p97 mov.u32 %r214, %r80;
	@!%p97 mov.u32 %r215, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r218, 0x0;
	mov.u32 %r219, 0x0;
	@%p97 ld.global.v2.b32 { %r218, %r219 }, [ %rd169 + 0 ];
	@!%p97 mov.u32 %r218, %r80;
	@!%p97 mov.u32 %r219, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r222, 0x0;
	mov.u32 %r223, 0x0;
	@%p97 ld.global.v2.b32 { %r222, %r223 }, [ %rd170 + 0 ];
	@!%p97 mov.u32 %r222, %r80;
	@!%p97 mov.u32 %r223, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r226, 0x0;
	mov.u32 %r227, 0x0;
	@%p97 ld.global.v2.b32 { %r226, %r227 }, [ %rd171 + 0 ];
	@!%p97 mov.u32 %r226, %r80;
	@!%p97 mov.u32 %r227, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r230, 0x0;
	mov.u32 %r231, 0x0;
	@%p97 ld.global.v2.b32 { %r230, %r231 }, [ %rd172 + 0 ];
	@!%p97 mov.u32 %r230, %r80;
	@!%p97 mov.u32 %r231, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r234, 0x0;
	mov.u32 %r235, 0x0;
	@%p97 ld.global.v2.b32 { %r234, %r235 }, [ %rd173 + 0 ];
	@!%p97 mov.u32 %r234, %r80;
	@!%p97 mov.u32 %r235, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r238, 0x0;
	mov.u32 %r239, 0x0;
	@%p97 ld.global.v2.b32 { %r238, %r239 }, [ %rd174 + 0 ];
	@!%p97 mov.u32 %r238, %r80;
	@!%p97 mov.u32 %r239, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r242, 0x0;
	mov.u32 %r243, 0x0;
	@%p97 ld.global.v2.b32 { %r242, %r243 }, [ %rd175 + 0 ];
	@!%p97 mov.u32 %r242, %r80;
	@!%p97 mov.u32 %r243, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r246, 0x0;
	mov.u32 %r247, 0x0;
	@%p97 ld.global.v2.b32 { %r246, %r247 }, [ %rd176 + 0 ];
	@!%p97 mov.u32 %r246, %r80;
	@!%p97 mov.u32 %r247, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r250, 0x0;
	mov.u32 %r251, 0x0;
	@%p97 ld.global.v2.b32 { %r250, %r251 }, [ %rd177 + 0 ];
	@!%p97 mov.u32 %r250, %r80;
	@!%p97 mov.u32 %r251, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r254, 0x0;
	mov.u32 %r255, 0x0;
	@%p97 ld.global.v2.b32 { %r254, %r255 }, [ %rd178 + 0 ];
	@!%p97 mov.u32 %r254, %r80;
	@!%p97 mov.u32 %r255, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r258, 0x0;
	mov.u32 %r259, 0x0;
	@%p97 ld.global.v2.b32 { %r258, %r259 }, [ %rd179 + 0 ];
	@!%p97 mov.u32 %r258, %r80;
	@!%p97 mov.u32 %r259, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r262, 0x0;
	mov.u32 %r263, 0x0;
	@%p97 ld.global.v2.b32 { %r262, %r263 }, [ %rd180 + 0 ];
	@!%p97 mov.u32 %r262, %r80;
	@!%p97 mov.u32 %r263, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r266, 0x0;
	mov.u32 %r267, 0x0;
	@%p97 ld.global.v2.b32 { %r266, %r267 }, [ %rd181 + 0 ];
	@!%p97 mov.u32 %r266, %r80;
	@!%p97 mov.u32 %r267, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r270, 0x0;
	mov.u32 %r271, 0x0;
	@%p97 ld.global.v2.b32 { %r270, %r271 }, [ %rd182 + 0 ];
	@!%p97 mov.u32 %r270, %r80;
	@!%p97 mov.u32 %r271, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r274, 0x0;
	mov.u32 %r275, 0x0;
	@%p97 ld.global.v2.b32 { %r274, %r275 }, [ %rd183 + 0 ];
	@!%p97 mov.u32 %r274, %r80;
	@!%p97 mov.u32 %r275, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r278, 0x0;
	mov.u32 %r279, 0x0;
	@%p97 ld.global.v2.b32 { %r278, %r279 }, [ %rd184 + 0 ];
	@!%p97 mov.u32 %r278, %r80;
	@!%p97 mov.u32 %r279, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r282, 0x0;
	mov.u32 %r283, 0x0;
	@%p97 ld.global.v2.b32 { %r282, %r283 }, [ %rd185 + 0 ];
	@!%p97 mov.u32 %r282, %r80;
	@!%p97 mov.u32 %r283, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r286, 0x0;
	mov.u32 %r287, 0x0;
	@%p97 ld.global.v2.b32 { %r286, %r287 }, [ %rd186 + 0 ];
	@!%p97 mov.u32 %r286, %r80;
	@!%p97 mov.u32 %r287, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r290, 0x0;
	mov.u32 %r291, 0x0;
	@%p97 ld.global.v2.b32 { %r290, %r291 }, [ %rd187 + 0 ];
	@!%p97 mov.u32 %r290, %r80;
	@!%p97 mov.u32 %r291, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r294, 0x0;
	mov.u32 %r295, 0x0;
	@%p97 ld.global.v2.b32 { %r294, %r295 }, [ %rd188 + 0 ];
	@!%p97 mov.u32 %r294, %r80;
	@!%p97 mov.u32 %r295, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r298, 0x0;
	mov.u32 %r299, 0x0;
	@%p97 ld.global.v2.b32 { %r298, %r299 }, [ %rd189 + 0 ];
	@!%p97 mov.u32 %r298, %r80;
	@!%p97 mov.u32 %r299, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r302, 0x0;
	mov.u32 %r303, 0x0;
	@%p97 ld.global.v2.b32 { %r302, %r303 }, [ %rd190 + 0 ];
	@!%p97 mov.u32 %r302, %r80;
	@!%p97 mov.u32 %r303, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r306, 0x0;
	mov.u32 %r307, 0x0;
	@%p97 ld.global.v2.b32 { %r306, %r307 }, [ %rd191 + 0 ];
	@!%p97 mov.u32 %r306, %r80;
	@!%p97 mov.u32 %r307, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r310, 0x0;
	mov.u32 %r311, 0x0;
	@%p97 ld.global.v2.b32 { %r310, %r311 }, [ %rd192 + 0 ];
	@!%p97 mov.u32 %r310, %r80;
	@!%p97 mov.u32 %r311, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r314, 0x0;
	mov.u32 %r315, 0x0;
	@%p97 ld.global.v2.b32 { %r314, %r315 }, [ %rd193 + 0 ];
	@!%p97 mov.u32 %r314, %r80;
	@!%p97 mov.u32 %r315, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r318, 0x0;
	mov.u32 %r319, 0x0;
	@%p97 ld.global.v2.b32 { %r318, %r319 }, [ %rd194 + 0 ];
	@!%p97 mov.u32 %r318, %r80;
	@!%p97 mov.u32 %r319, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r322, 0x0;
	mov.u32 %r323, 0x0;
	@%p97 ld.global.v2.b32 { %r322, %r323 }, [ %rd195 + 0 ];
	@!%p97 mov.u32 %r322, %r80;
	@!%p97 mov.u32 %r323, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r326, 0x0;
	mov.u32 %r327, 0x0;
	@%p97 ld.global.v2.b32 { %r326, %r327 }, [ %rd196 + 0 ];
	@!%p97 mov.u32 %r326, %r80;
	@!%p97 mov.u32 %r327, %r80;
	// end inline asm
	// begin inline asm
	mov.u32 %r330, 0x0;
	mov.u32 %r331, 0x0;
	@%p97 ld.global.v2.b32 { %r330, %r331 }, [ %rd197 + 0 ];
	@!%p97 mov.u32 %r330, %r80;
	@!%p97 mov.u32 %r331, %r80;
	// end inline asm
	st.shared.v2.u32 	[%rd38], {%r206, %r207};
	st.shared.v2.u32 	[%rd39], {%r210, %r211};
	st.shared.v2.u32 	[%rd40], {%r214, %r215};
	st.shared.v2.u32 	[%rd41], {%r218, %r219};
	st.shared.v2.u32 	[%rd42], {%r222, %r223};
	st.shared.v2.u32 	[%rd43], {%r226, %r227};
	st.shared.v2.u32 	[%rd44], {%r230, %r231};
	st.shared.v2.u32 	[%rd45], {%r234, %r235};
	st.shared.v2.u32 	[%rd46], {%r238, %r239};
	st.shared.v2.u32 	[%rd47], {%r242, %r243};
	st.shared.v2.u32 	[%rd48], {%r246, %r247};
	st.shared.v2.u32 	[%rd49], {%r250, %r251};
	st.shared.v2.u32 	[%rd50], {%r254, %r255};
	st.shared.v2.u32 	[%rd51], {%r258, %r259};
	st.shared.v2.u32 	[%rd52], {%r262, %r263};
	st.shared.v2.u32 	[%rd53], {%r266, %r267};
	st.shared.v2.u32 	[%rd54], {%r270, %r271};
	st.shared.v2.u32 	[%rd55], {%r274, %r275};
	st.shared.v2.u32 	[%rd56], {%r278, %r279};
	st.shared.v2.u32 	[%rd57], {%r282, %r283};
	st.shared.v2.u32 	[%rd58], {%r286, %r287};
	st.shared.v2.u32 	[%rd59], {%r290, %r291};
	st.shared.v2.u32 	[%rd60], {%r294, %r295};
	st.shared.v2.u32 	[%rd61], {%r298, %r299};
	st.shared.v2.u32 	[%rd62], {%r302, %r303};
	st.shared.v2.u32 	[%rd63], {%r306, %r307};
	st.shared.v2.u32 	[%rd64], {%r310, %r311};
	st.shared.v2.u32 	[%rd65], {%r314, %r315};
	st.shared.v2.u32 	[%rd66], {%r318, %r319};
	st.shared.v2.u32 	[%rd67], {%r322, %r323};
	st.shared.v2.u32 	[%rd68], {%r326, %r327};
	st.shared.v2.u32 	[%rd69], {%r330, %r331};
	bar.sync 	0;
	ld.shared.u32 	%r334, [%rd70];
	ld.shared.u32 	%r335, [%rd71];
	ld.shared.u32 	%r336, [%rd70+256];
	ld.shared.u32 	%r337, [%rd71+256];
	ld.shared.u32 	%r340, [%rd70+512];
	ld.shared.u32 	%r341, [%rd71+512];
	ld.shared.u32 	%r342, [%rd70+768];
	ld.shared.u32 	%r343, [%rd71+768];
	ld.shared.u32 	%r346, [%rd70+1024];
	ld.shared.u32 	%r347, [%rd71+1024];
	ld.shared.u32 	%r348, [%rd70+1280];
	ld.shared.u32 	%r349, [%rd71+1280];
	ld.shared.u32 	%r352, [%rd70+1536];
	ld.shared.u32 	%r353, [%rd71+1536];
	ld.shared.u32 	%r354, [%rd70+1792];
	ld.shared.u32 	%r355, [%rd71+1792];
	ld.shared.u32 	%r358, [%rd70+2048];
	ld.shared.u32 	%r359, [%rd71+2048];
	ld.shared.u32 	%r360, [%rd70+2304];
	ld.shared.u32 	%r361, [%rd71+2304];
	ld.shared.u32 	%r364, [%rd70+2560];
	ld.shared.u32 	%r365, [%rd71+2560];
	ld.shared.u32 	%r366, [%rd70+2816];
	ld.shared.u32 	%r367, [%rd71+2816];
	ld.shared.u32 	%r370, [%rd70+3072];
	ld.shared.u32 	%r371, [%rd71+3072];
	ld.shared.u32 	%r372, [%rd70+3328];
	ld.shared.u32 	%r373, [%rd71+3328];
	ld.shared.u32 	%r376, [%rd70+3584];
	ld.shared.u32 	%r377, [%rd71+3584];
	ld.shared.u32 	%r378, [%rd70+3840];
	ld.shared.u32 	%r379, [%rd71+3840];
	ld.shared.u32 	%r382, [%rd70+4096];
	ld.shared.u32 	%r383, [%rd71+4096];
	ld.shared.u32 	%r384, [%rd70+4352];
	ld.shared.u32 	%r385, [%rd71+4352];
	ld.shared.u32 	%r388, [%rd70+4608];
	ld.shared.u32 	%r389, [%rd71+4608];
	ld.shared.u32 	%r390, [%rd70+4864];
	ld.shared.u32 	%r391, [%rd71+4864];
	ld.shared.u32 	%r394, [%rd70+5120];
	ld.shared.u32 	%r395, [%rd71+5120];
	ld.shared.u32 	%r396, [%rd70+5376];
	ld.shared.u32 	%r397, [%rd71+5376];
	ld.shared.u32 	%r400, [%rd70+5632];
	ld.shared.u32 	%r401, [%rd71+5632];
	ld.shared.u32 	%r402, [%rd70+5888];
	ld.shared.u32 	%r403, [%rd71+5888];
	ld.shared.u32 	%r406, [%rd70+6144];
	ld.shared.u32 	%r407, [%rd71+6144];
	ld.shared.u32 	%r408, [%rd70+6400];
	ld.shared.u32 	%r409, [%rd71+6400];
	ld.shared.u32 	%r412, [%rd70+6656];
	ld.shared.u32 	%r413, [%rd71+6656];
	ld.shared.u32 	%r414, [%rd70+6912];
	ld.shared.u32 	%r415, [%rd71+6912];
	ld.shared.u32 	%r418, [%rd70+7168];
	ld.shared.u32 	%r419, [%rd71+7168];
	ld.shared.u32 	%r420, [%rd70+7424];
	ld.shared.u32 	%r421, [%rd71+7424];
	ld.shared.u32 	%r424, [%rd70+7680];
	ld.shared.u32 	%r425, [%rd71+7680];
	ld.shared.u32 	%r426, [%rd70+7936];
	ld.shared.u32 	%r427, [%rd71+7936];
	ld.shared.u32 	%r430, [%rd70+8192];
	ld.shared.u32 	%r431, [%rd71+8192];
	ld.shared.u32 	%r432, [%rd70+8448];
	ld.shared.u32 	%r433, [%rd71+8448];
	ld.shared.u32 	%r436, [%rd70+8704];
	ld.shared.u32 	%r437, [%rd71+8704];
	ld.shared.u32 	%r438, [%rd70+8960];
	ld.shared.u32 	%r439, [%rd71+8960];
	ld.shared.u32 	%r442, [%rd70+9216];
	ld.shared.u32 	%r443, [%rd71+9216];
	ld.shared.u32 	%r444, [%rd70+9472];
	ld.shared.u32 	%r445, [%rd71+9472];
	ld.shared.u32 	%r448, [%rd70+9728];
	ld.shared.u32 	%r449, [%rd71+9728];
	ld.shared.u32 	%r450, [%rd70+9984];
	ld.shared.u32 	%r451, [%rd71+9984];
	ld.shared.u32 	%r454, [%rd70+10240];
	ld.shared.u32 	%r455, [%rd71+10240];
	ld.shared.u32 	%r456, [%rd70+10496];
	ld.shared.u32 	%r457, [%rd71+10496];
	ld.shared.u32 	%r460, [%rd70+10752];
	ld.shared.u32 	%r461, [%rd71+10752];
	ld.shared.u32 	%r462, [%rd70+11008];
	ld.shared.u32 	%r463, [%rd71+11008];
	ld.shared.u32 	%r466, [%rd70+11264];
	ld.shared.u32 	%r467, [%rd71+11264];
	ld.shared.u32 	%r468, [%rd70+11520];
	ld.shared.u32 	%r469, [%rd71+11520];
	ld.shared.u32 	%r472, [%rd70+11776];
	ld.shared.u32 	%r473, [%rd71+11776];
	ld.shared.u32 	%r474, [%rd70+12032];
	ld.shared.u32 	%r475, [%rd71+12032];
	ld.shared.u32 	%r478, [%rd70+12288];
	ld.shared.u32 	%r479, [%rd71+12288];
	ld.shared.u32 	%r480, [%rd70+12544];
	ld.shared.u32 	%r481, [%rd71+12544];
	ld.shared.u32 	%r484, [%rd70+12800];
	ld.shared.u32 	%r485, [%rd71+12800];
	ld.shared.u32 	%r486, [%rd70+13056];
	ld.shared.u32 	%r487, [%rd71+13056];
	ld.shared.u32 	%r490, [%rd70+13312];
	ld.shared.u32 	%r491, [%rd71+13312];
	ld.shared.u32 	%r492, [%rd70+13568];
	ld.shared.u32 	%r493, [%rd71+13568];
	ld.shared.u32 	%r496, [%rd70+13824];
	ld.shared.u32 	%r497, [%rd71+13824];
	ld.shared.u32 	%r498, [%rd70+14080];
	ld.shared.u32 	%r499, [%rd71+14080];
	ld.shared.u32 	%r502, [%rd70+14336];
	ld.shared.u32 	%r503, [%rd71+14336];
	ld.shared.u32 	%r504, [%rd70+14592];
	ld.shared.u32 	%r505, [%rd71+14592];
	ld.shared.u32 	%r508, [%rd70+14848];
	ld.shared.u32 	%r509, [%rd71+14848];
	ld.shared.u32 	%r510, [%rd70+15104];
	ld.shared.u32 	%r511, [%rd71+15104];
	ld.shared.u32 	%r514, [%rd70+15360];
	ld.shared.u32 	%r515, [%rd71+15360];
	ld.shared.u32 	%r516, [%rd70+15616];
	ld.shared.u32 	%r517, [%rd71+15616];
	ld.shared.u32 	%r520, [%rd70+15872];
	ld.shared.u32 	%r521, [%rd71+15872];
	ld.shared.u32 	%r522, [%rd70+16128];
	ld.shared.u32 	%r523, [%rd71+16128];
	ld.shared.u32 	%r526, [%rd70+16384];
	ld.shared.u32 	%r527, [%rd71+16384];
	ld.shared.u32 	%r528, [%rd70+16640];
	ld.shared.u32 	%r529, [%rd71+16640];
	ld.shared.u32 	%r532, [%rd70+16896];
	ld.shared.u32 	%r533, [%rd71+16896];
	ld.shared.u32 	%r534, [%rd70+17152];
	ld.shared.u32 	%r535, [%rd71+17152];
	ld.shared.u32 	%r538, [%rd70+17408];
	ld.shared.u32 	%r539, [%rd71+17408];
	ld.shared.u32 	%r540, [%rd70+17664];
	ld.shared.u32 	%r541, [%rd71+17664];
	ld.shared.u32 	%r544, [%rd70+17920];
	ld.shared.u32 	%r545, [%rd71+17920];
	ld.shared.u32 	%r546, [%rd70+18176];
	ld.shared.u32 	%r547, [%rd71+18176];
	ld.shared.u32 	%r550, [%rd70+18432];
	ld.shared.u32 	%r551, [%rd71+18432];
	ld.shared.u32 	%r552, [%rd70+18688];
	ld.shared.u32 	%r553, [%rd71+18688];
	ld.shared.u32 	%r556, [%rd70+18944];
	ld.shared.u32 	%r557, [%rd71+18944];
	ld.shared.u32 	%r558, [%rd70+19200];
	ld.shared.u32 	%r559, [%rd71+19200];
	ld.shared.u32 	%r562, [%rd70+19456];
	ld.shared.u32 	%r563, [%rd71+19456];
	ld.shared.u32 	%r564, [%rd70+19712];
	ld.shared.u32 	%r565, [%rd71+19712];
	ld.shared.u32 	%r568, [%rd70+19968];
	ld.shared.u32 	%r569, [%rd71+19968];
	ld.shared.u32 	%r570, [%rd70+20224];
	ld.shared.u32 	%r571, [%rd71+20224];
	ld.shared.u32 	%r574, [%rd70+20480];
	ld.shared.u32 	%r575, [%rd71+20480];
	ld.shared.u32 	%r576, [%rd70+20736];
	ld.shared.u32 	%r577, [%rd71+20736];
	ld.shared.u32 	%r580, [%rd70+20992];
	ld.shared.u32 	%r581, [%rd71+20992];
	ld.shared.u32 	%r582, [%rd70+21248];
	ld.shared.u32 	%r583, [%rd71+21248];
	ld.shared.u32 	%r586, [%rd70+21504];
	ld.shared.u32 	%r587, [%rd71+21504];
	ld.shared.u32 	%r588, [%rd70+21760];
	ld.shared.u32 	%r589, [%rd71+21760];
	ld.shared.u32 	%r592, [%rd70+22016];
	ld.shared.u32 	%r593, [%rd71+22016];
	ld.shared.u32 	%r594, [%rd70+22272];
	ld.shared.u32 	%r595, [%rd71+22272];
	ld.shared.u32 	%r598, [%rd70+22528];
	ld.shared.u32 	%r599, [%rd71+22528];
	ld.shared.u32 	%r600, [%rd70+22784];
	ld.shared.u32 	%r601, [%rd71+22784];
	ld.shared.u32 	%r604, [%rd70+23040];
	ld.shared.u32 	%r605, [%rd71+23040];
	ld.shared.u32 	%r606, [%rd70+23296];
	ld.shared.u32 	%r607, [%rd71+23296];
	ld.shared.u32 	%r610, [%rd70+23552];
	ld.shared.u32 	%r611, [%rd71+23552];
	ld.shared.u32 	%r612, [%rd70+23808];
	ld.shared.u32 	%r613, [%rd71+23808];
	ld.shared.u32 	%r616, [%rd70+24064];
	ld.shared.u32 	%r617, [%rd71+24064];
	ld.shared.u32 	%r618, [%rd70+24320];
	ld.shared.u32 	%r619, [%rd71+24320];
	ld.shared.u32 	%r622, [%rd70+24576];
	ld.shared.u32 	%r623, [%rd71+24576];
	ld.shared.u32 	%r624, [%rd70+24832];
	ld.shared.u32 	%r625, [%rd71+24832];
	ld.shared.u32 	%r628, [%rd70+25088];
	ld.shared.u32 	%r629, [%rd71+25088];
	ld.shared.u32 	%r630, [%rd70+25344];
	ld.shared.u32 	%r631, [%rd71+25344];
	ld.shared.u32 	%r634, [%rd70+25600];
	ld.shared.u32 	%r635, [%rd71+25600];
	ld.shared.u32 	%r636, [%rd70+25856];
	ld.shared.u32 	%r637, [%rd71+25856];
	ld.shared.u32 	%r640, [%rd70+26112];
	ld.shared.u32 	%r641, [%rd71+26112];
	ld.shared.u32 	%r642, [%rd70+26368];
	ld.shared.u32 	%r643, [%rd71+26368];
	ld.shared.u32 	%r646, [%rd70+26624];
	ld.shared.u32 	%r647, [%rd71+26624];
	ld.shared.u32 	%r648, [%rd70+26880];
	ld.shared.u32 	%r649, [%rd71+26880];
	ld.shared.u32 	%r652, [%rd70+27136];
	ld.shared.u32 	%r653, [%rd71+27136];
	ld.shared.u32 	%r654, [%rd70+27392];
	ld.shared.u32 	%r655, [%rd71+27392];
	ld.shared.u32 	%r658, [%rd70+27648];
	ld.shared.u32 	%r659, [%rd71+27648];
	ld.shared.u32 	%r660, [%rd70+27904];
	ld.shared.u32 	%r661, [%rd71+27904];
	ld.shared.u32 	%r664, [%rd70+28160];
	ld.shared.u32 	%r665, [%rd71+28160];
	ld.shared.u32 	%r666, [%rd70+28416];
	ld.shared.u32 	%r667, [%rd71+28416];
	ld.shared.u32 	%r670, [%rd70+28672];
	ld.shared.u32 	%r671, [%rd71+28672];
	ld.shared.u32 	%r672, [%rd70+28928];
	ld.shared.u32 	%r673, [%rd71+28928];
	ld.shared.u32 	%r676, [%rd70+29184];
	ld.shared.u32 	%r677, [%rd71+29184];
	ld.shared.u32 	%r678, [%rd70+29440];
	ld.shared.u32 	%r679, [%rd71+29440];
	ld.shared.u32 	%r682, [%rd70+29696];
	ld.shared.u32 	%r683, [%rd71+29696];
	ld.shared.u32 	%r684, [%rd70+29952];
	ld.shared.u32 	%r685, [%rd71+29952];
	ld.shared.u32 	%r688, [%rd70+30208];
	ld.shared.u32 	%r689, [%rd71+30208];
	ld.shared.u32 	%r690, [%rd70+30464];
	ld.shared.u32 	%r691, [%rd71+30464];
	ld.shared.u32 	%r694, [%rd70+30720];
	ld.shared.u32 	%r695, [%rd71+30720];
	ld.shared.u32 	%r696, [%rd70+30976];
	ld.shared.u32 	%r697, [%rd71+30976];
	ld.shared.u32 	%r700, [%rd70+31232];
	ld.shared.u32 	%r701, [%rd71+31232];
	ld.shared.u32 	%r702, [%rd70+31488];
	ld.shared.u32 	%r703, [%rd71+31488];
	ld.shared.u32 	%r706, [%rd70+31744];
	ld.shared.u32 	%r707, [%rd71+31744];
	ld.shared.u32 	%r708, [%rd70+32000];
	ld.shared.u32 	%r709, [%rd71+32000];
	ld.shared.u32 	%r712, [%rd70+32256];
	ld.shared.u32 	%r713, [%rd71+32256];
	ld.shared.u32 	%r714, [%rd70+32512];
	ld.shared.u32 	%r715, [%rd71+32512];
	ld.shared.u32 	%r338, [%rd72];
	ld.shared.u32 	%r339, [%rd72+256];
	ld.shared.u32 	%r344, [%rd72+512];
	ld.shared.u32 	%r345, [%rd72+768];
	ld.shared.u32 	%r350, [%rd72+1024];
	ld.shared.u32 	%r351, [%rd72+1280];
	ld.shared.u32 	%r356, [%rd72+1536];
	ld.shared.u32 	%r357, [%rd72+1792];
	ld.shared.u32 	%r362, [%rd72+2048];
	ld.shared.u32 	%r363, [%rd72+2304];
	ld.shared.u32 	%r368, [%rd72+2560];
	ld.shared.u32 	%r369, [%rd72+2816];
	ld.shared.u32 	%r374, [%rd72+3072];
	ld.shared.u32 	%r375, [%rd72+3328];
	ld.shared.u32 	%r380, [%rd72+3584];
	ld.shared.u32 	%r381, [%rd72+3840];
	ld.shared.u32 	%r386, [%rd72+4096];
	ld.shared.u32 	%r387, [%rd72+4352];
	ld.shared.u32 	%r392, [%rd72+4608];
	ld.shared.u32 	%r393, [%rd72+4864];
	ld.shared.u32 	%r398, [%rd72+5120];
	ld.shared.u32 	%r399, [%rd72+5376];
	ld.shared.u32 	%r404, [%rd72+5632];
	ld.shared.u32 	%r405, [%rd72+5888];
	ld.shared.u32 	%r410, [%rd72+6144];
	ld.shared.u32 	%r411, [%rd72+6400];
	ld.shared.u32 	%r416, [%rd72+6656];
	ld.shared.u32 	%r417, [%rd72+6912];
	ld.shared.u32 	%r422, [%rd72+7168];
	ld.shared.u32 	%r423, [%rd72+7424];
	ld.shared.u32 	%r428, [%rd72+7680];
	ld.shared.u32 	%r429, [%rd72+7936];
	ld.shared.u32 	%r434, [%rd72+8192];
	ld.shared.u32 	%r435, [%rd72+8448];
	ld.shared.u32 	%r440, [%rd72+8704];
	ld.shared.u32 	%r441, [%rd72+8960];
	ld.shared.u32 	%r446, [%rd72+9216];
	ld.shared.u32 	%r447, [%rd72+9472];
	ld.shared.u32 	%r452, [%rd72+9728];
	ld.shared.u32 	%r453, [%rd72+9984];
	ld.shared.u32 	%r458, [%rd72+10240];
	ld.shared.u32 	%r459, [%rd72+10496];
	ld.shared.u32 	%r464, [%rd72+10752];
	ld.shared.u32 	%r465, [%rd72+11008];
	ld.shared.u32 	%r470, [%rd72+11264];
	ld.shared.u32 	%r471, [%rd72+11520];
	ld.shared.u32 	%r476, [%rd72+11776];
	ld.shared.u32 	%r477, [%rd72+12032];
	ld.shared.u32 	%r482, [%rd72+12288];
	ld.shared.u32 	%r483, [%rd72+12544];
	ld.shared.u32 	%r488, [%rd72+12800];
	ld.shared.u32 	%r489, [%rd72+13056];
	ld.shared.u32 	%r494, [%rd72+13312];
	ld.shared.u32 	%r495, [%rd72+13568];
	ld.shared.u32 	%r500, [%rd72+13824];
	ld.shared.u32 	%r501, [%rd72+14080];
	ld.shared.u32 	%r506, [%rd72+14336];
	ld.shared.u32 	%r507, [%rd72+14592];
	ld.shared.u32 	%r512, [%rd72+14848];
	ld.shared.u32 	%r513, [%rd72+15104];
	ld.shared.u32 	%r518, [%rd72+15360];
	ld.shared.u32 	%r519, [%rd72+15616];
	ld.shared.u32 	%r524, [%rd72+15872];
	ld.shared.u32 	%r525, [%rd72+16128];
	ld.shared.u32 	%r530, [%rd72+16384];
	ld.shared.u32 	%r531, [%rd72+16640];
	ld.shared.u32 	%r536, [%rd72+16896];
	ld.shared.u32 	%r537, [%rd72+17152];
	ld.shared.u32 	%r542, [%rd72+17408];
	ld.shared.u32 	%r543, [%rd72+17664];
	ld.shared.u32 	%r548, [%rd72+17920];
	ld.shared.u32 	%r549, [%rd72+18176];
	ld.shared.u32 	%r554, [%rd72+18432];
	ld.shared.u32 	%r555, [%rd72+18688];
	ld.shared.u32 	%r560, [%rd72+18944];
	ld.shared.u32 	%r561, [%rd72+19200];
	ld.shared.u32 	%r566, [%rd72+19456];
	ld.shared.u32 	%r567, [%rd72+19712];
	ld.shared.u32 	%r572, [%rd72+19968];
	ld.shared.u32 	%r573, [%rd72+20224];
	ld.shared.u32 	%r578, [%rd72+20480];
	ld.shared.u32 	%r579, [%rd72+20736];
	ld.shared.u32 	%r584, [%rd72+20992];
	ld.shared.u32 	%r585, [%rd72+21248];
	ld.shared.u32 	%r590, [%rd72+21504];
	ld.shared.u32 	%r591, [%rd72+21760];
	ld.shared.u32 	%r596, [%rd72+22016];
	ld.shared.u32 	%r597, [%rd72+22272];
	ld.shared.u32 	%r602, [%rd72+22528];
	ld.shared.u32 	%r603, [%rd72+22784];
	ld.shared.u32 	%r608, [%rd72+23040];
	ld.shared.u32 	%r609, [%rd72+23296];
	ld.shared.u32 	%r614, [%rd72+23552];
	ld.shared.u32 	%r615, [%rd72+23808];
	ld.shared.u32 	%r620, [%rd72+24064];
	ld.shared.u32 	%r621, [%rd72+24320];
	ld.shared.u32 	%r626, [%rd72+24576];
	ld.shared.u32 	%r627, [%rd72+24832];
	ld.shared.u32 	%r632, [%rd72+25088];
	ld.shared.u32 	%r633, [%rd72+25344];
	ld.shared.u32 	%r638, [%rd72+25600];
	ld.shared.u32 	%r639, [%rd72+25856];
	ld.shared.u32 	%r644, [%rd72+26112];
	ld.shared.u32 	%r645, [%rd72+26368];
	ld.shared.u32 	%r650, [%rd72+26624];
	ld.shared.u32 	%r651, [%rd72+26880];
	ld.shared.u32 	%r656, [%rd72+27136];
	ld.shared.u32 	%r657, [%rd72+27392];
	ld.shared.u32 	%r662, [%rd72+27648];
	ld.shared.u32 	%r663, [%rd72+27904];
	ld.shared.u32 	%r668, [%rd72+28160];
	ld.shared.u32 	%r669, [%rd72+28416];
	ld.shared.u32 	%r674, [%rd72+28672];
	ld.shared.u32 	%r675, [%rd72+28928];
	ld.shared.u32 	%r680, [%rd72+29184];
	ld.shared.u32 	%r681, [%rd72+29440];
	ld.shared.u32 	%r686, [%rd72+29696];
	ld.shared.u32 	%r687, [%rd72+29952];
	ld.shared.u32 	%r692, [%rd72+30208];
	ld.shared.u32 	%r693, [%rd72+30464];
	ld.shared.u32 	%r698, [%rd72+30720];
	ld.shared.u32 	%r699, [%rd72+30976];
	ld.shared.u32 	%r704, [%rd72+31232];
	ld.shared.u32 	%r705, [%rd72+31488];
	ld.shared.u32 	%r710, [%rd72+31744];
	ld.shared.u32 	%r711, [%rd72+32000];
	ld.shared.u32 	%r716, [%rd72+32256];
	ld.shared.u32 	%r717, [%rd72+32512];
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r334, %r335, %r336, %r337 }, { %r338, %r339 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r340, %r341, %r342, %r343 }, { %r344, %r345 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r346, %r347, %r348, %r349 }, { %r350, %r351 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r352, %r353, %r354, %r355 }, { %r356, %r357 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r358, %r359, %r360, %r361 }, { %r362, %r363 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r364, %r365, %r366, %r367 }, { %r368, %r369 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r370, %r371, %r372, %r373 }, { %r374, %r375 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r376, %r377, %r378, %r379 }, { %r380, %r381 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r382, %r383, %r384, %r385 }, { %r386, %r387 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r388, %r389, %r390, %r391 }, { %r392, %r393 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r394, %r395, %r396, %r397 }, { %r398, %r399 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r400, %r401, %r402, %r403 }, { %r404, %r405 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r406, %r407, %r408, %r409 }, { %r410, %r411 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r412, %r413, %r414, %r415 }, { %r416, %r417 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r418, %r419, %r420, %r421 }, { %r422, %r423 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r424, %r425, %r426, %r427 }, { %r428, %r429 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r430, %r431, %r432, %r433 }, { %r434, %r435 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r436, %r437, %r438, %r439 }, { %r440, %r441 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r442, %r443, %r444, %r445 }, { %r446, %r447 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r448, %r449, %r450, %r451 }, { %r452, %r453 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r454, %r455, %r456, %r457 }, { %r458, %r459 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r460, %r461, %r462, %r463 }, { %r464, %r465 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r466, %r467, %r468, %r469 }, { %r470, %r471 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r472, %r473, %r474, %r475 }, { %r476, %r477 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r478, %r479, %r480, %r481 }, { %r482, %r483 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r484, %r485, %r486, %r487 }, { %r488, %r489 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r490, %r491, %r492, %r493 }, { %r494, %r495 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r496, %r497, %r498, %r499 }, { %r500, %r501 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r502, %r503, %r504, %r505 }, { %r506, %r507 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r508, %r509, %r510, %r511 }, { %r512, %r513 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r514, %r515, %r516, %r517 }, { %r518, %r519 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r520, %r521, %r522, %r523 }, { %r524, %r525 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r526, %r527, %r528, %r529 }, { %r530, %r531 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r532, %r533, %r534, %r535 }, { %r536, %r537 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r538, %r539, %r540, %r541 }, { %r542, %r543 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r544, %r545, %r546, %r547 }, { %r548, %r549 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r550, %r551, %r552, %r553 }, { %r554, %r555 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r556, %r557, %r558, %r559 }, { %r560, %r561 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r562, %r563, %r564, %r565 }, { %r566, %r567 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r568, %r569, %r570, %r571 }, { %r572, %r573 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r574, %r575, %r576, %r577 }, { %r578, %r579 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r580, %r581, %r582, %r583 }, { %r584, %r585 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r586, %r587, %r588, %r589 }, { %r590, %r591 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r592, %r593, %r594, %r595 }, { %r596, %r597 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r598, %r599, %r600, %r601 }, { %r602, %r603 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r604, %r605, %r606, %r607 }, { %r608, %r609 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r610, %r611, %r612, %r613 }, { %r614, %r615 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r616, %r617, %r618, %r619 }, { %r620, %r621 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r622, %r623, %r624, %r625 }, { %r626, %r627 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r628, %r629, %r630, %r631 }, { %r632, %r633 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r634, %r635, %r636, %r637 }, { %r638, %r639 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r640, %r641, %r642, %r643 }, { %r644, %r645 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r646, %r647, %r648, %r649 }, { %r650, %r651 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r652, %r653, %r654, %r655 }, { %r656, %r657 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r658, %r659, %r660, %r661 }, { %r662, %r663 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r664, %r665, %r666, %r667 }, { %r668, %r669 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r670, %r671, %r672, %r673 }, { %r674, %r675 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r676, %r677, %r678, %r679 }, { %r680, %r681 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r682, %r683, %r684, %r685 }, { %r686, %r687 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r688, %r689, %r690, %r691 }, { %r692, %r693 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r694, %r695, %r696, %r697 }, { %r698, %r699 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r700, %r701, %r702, %r703 }, { %r704, %r705 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r706, %r707, %r708, %r709 }, { %r710, %r711 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f529, %f530, %f531, %f532 }, { %r712, %r713, %r714, %r715 }, { %r716, %r717 }, { %f529, %f530, %f531, %f532 };
	// end inline asm
	add.s32 	%r730, %r730, 512;
	add.s64 	%rd212, %rd212, 786432;
	add.s64 	%rd211, %rd211, 12288;
	setp.lt.u32 	%p193, %r730, 50688;
	@%p193 bra 	$L__BB300_1;
	mul.lo.s32 	%r720, %r10, 36;
	mul.wide.s32 	%rd199, %r720, 4;
	add.s64 	%rd200, %rd1, %rd199;
	or.b64  	%rd201, %rd2, %rd4;
	mul.lo.s64 	%rd202, %rd201, 24;
	add.s64 	%rd203, %rd200, %rd202;
	shl.b64 	%rd204, %rd5, 2;
	add.s64 	%rd198, %rd203, %rd204;
	max.u64 	%rd205, %rd5, %rd201;
	setp.lt.u64 	%p194, %rd205, 6;
	bar.sync 	0;
	and.b32  	%r721, %r3, 6;
	shl.b32 	%r722, %r5, 3;
	and.b32  	%r723, %r722, 8;
	or.b32  	%r724, %r723, %r721;
	mad.lo.s32 	%r725, %r6, 18, %r724;
	mul.wide.u32 	%rd206, %r725, 4;
	add.s64 	%rd208, %rd88, %rd206;
	st.shared.v2.f32 	[%rd208], {%f529, %f530};
	st.shared.v2.f32 	[%rd208+576], {%f531, %f532};
	bar.sync 	0;
	shr.u32 	%r726, %r2, 3;
	shl.b32 	%r727, %r5, 2;
	or.b32  	%r728, %r727, %r726;
	mad.lo.s32 	%r729, %r728, 18, %r4;
	mul.wide.u32 	%rd209, %r729, 4;
	add.s64 	%rd210, %rd88, %rd209;
	ld.shared.v2.u32 	{%r718, %r719}, [%rd210];
	// begin inline asm
	@%p194 st.global.v2.b32 [ %rd198 + 0 ], { %r718, %r719 };
	// end inline asm
	ret;

}
	// .globl	loop_select_transpose_fusion_2
.visible .entry loop_select_transpose_fusion_2(
	.param .u64 loop_select_transpose_fusion_2_param_0,
	.param .u64 loop_select_transpose_fusion_2_param_1,
	.param .u64 loop_select_transpose_fusion_2_param_2,
	.param .u64 loop_select_transpose_fusion_2_param_3,
	.param .u64 loop_select_transpose_fusion_2_param_4,
	.param .u64 loop_select_transpose_fusion_2_param_5,
	.param .u64 loop_select_transpose_fusion_2_param_6,
	.param .u64 loop_select_transpose_fusion_2_param_7,
	.param .u64 loop_select_transpose_fusion_2_param_8,
	.param .u64 loop_select_transpose_fusion_2_param_9,
	.param .u64 loop_select_transpose_fusion_2_param_10,
	.param .u64 loop_select_transpose_fusion_2_param_11,
	.param .u64 loop_select_transpose_fusion_2_param_12,
	.param .u64 loop_select_transpose_fusion_2_param_13,
	.param .u64 loop_select_transpose_fusion_2_param_14,
	.param .u64 loop_select_transpose_fusion_2_param_15,
	.param .u64 loop_select_transpose_fusion_2_param_16,
	.param .u64 loop_select_transpose_fusion_2_param_17,
	.param .u64 loop_select_transpose_fusion_2_param_18,
	.param .u64 loop_select_transpose_fusion_2_param_19,
	.param .u64 loop_select_transpose_fusion_2_param_20,
	.param .u64 loop_select_transpose_fusion_2_param_21,
	.param .u64 loop_select_transpose_fusion_2_param_22,
	.param .u64 loop_select_transpose_fusion_2_param_23
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<15>;
	.reg .f32 	%f<31>;
	.reg .b64 	%rd<98>;

	ld.param.u64 	%rd1, [loop_select_transpose_fusion_2_param_0];
	ld.param.u64 	%rd2, [loop_select_transpose_fusion_2_param_23];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_select_transpose_fusion_2_param_1];
	ld.param.u64 	%rd5, [loop_select_transpose_fusion_2_param_22];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_select_transpose_fusion_2_param_2];
	ld.param.u64 	%rd8, [loop_select_transpose_fusion_2_param_21];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_select_transpose_fusion_2_param_3];
	ld.param.u64 	%rd11, [loop_select_transpose_fusion_2_param_20];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_select_transpose_fusion_2_param_4];
	ld.param.u64 	%rd14, [loop_select_transpose_fusion_2_param_19];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_select_transpose_fusion_2_param_5];
	ld.param.u64 	%rd17, [loop_select_transpose_fusion_2_param_18];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_select_transpose_fusion_2_param_6];
	ld.param.u64 	%rd20, [loop_select_transpose_fusion_2_param_17];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_select_transpose_fusion_2_param_7];
	ld.param.u64 	%rd23, [loop_select_transpose_fusion_2_param_16];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_select_transpose_fusion_2_param_8];
	ld.param.u64 	%rd26, [loop_select_transpose_fusion_2_param_15];
	cvta.to.global.u64 	%rd27, %rd26;
	ld.param.u64 	%rd28, [loop_select_transpose_fusion_2_param_9];
	ld.param.u64 	%rd29, [loop_select_transpose_fusion_2_param_14];
	cvta.to.global.u64 	%rd30, %rd29;
	ld.param.u64 	%rd31, [loop_select_transpose_fusion_2_param_10];
	ld.param.u64 	%rd32, [loop_select_transpose_fusion_2_param_13];
	cvta.to.global.u64 	%rd33, %rd32;
	ld.param.u64 	%rd34, [loop_select_transpose_fusion_2_param_11];
	ld.param.u64 	%rd35, [loop_select_transpose_fusion_2_param_12];
	cvta.to.global.u64 	%rd36, %rd35;
	cvta.to.global.u64 	%rd37, %rd34;
	cvta.to.global.u64 	%rd38, %rd31;
	cvta.to.global.u64 	%rd39, %rd28;
	cvta.to.global.u64 	%rd40, %rd25;
	cvta.to.global.u64 	%rd41, %rd22;
	cvta.to.global.u64 	%rd42, %rd19;
	cvta.to.global.u64 	%rd43, %rd16;
	cvta.to.global.u64 	%rd44, %rd13;
	cvta.to.global.u64 	%rd45, %rd10;
	cvta.to.global.u64 	%rd46, %rd7;
	cvta.to.global.u64 	%rd47, %rd4;
	cvta.to.global.u64 	%rd48, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r5, %rs3;
	mul.wide.u32 	%rd49, %r5, 4;
	add.s64 	%rd50, %rd45, %rd49;
	ld.global.nc.f32 	%f1, [%rd50];
	setp.gt.f32 	%p1, %f1, 0f41800000;
	selp.u32 	%r6, 1, 0, %p1;
	add.s64 	%rd51, %rd46, %rd49;
	ld.global.nc.u32 	%r7, [%rd51];
	setp.eq.s32 	%p2, %r7, %r6;
	cvt.u32.u16 	%r8, %rs8;
	mul.wide.u32 	%rd52, %r8, 24;
	mul.wide.u32 	%rd53, %r5, 144;
	add.s64 	%rd54, %rd48, %rd53;
	add.s64 	%rd55, %rd54, %rd52;
	cvt.u32.u16 	%r9, %rs10;
	mul.wide.u32 	%rd56, %r9, 4;
	add.s64 	%rd57, %rd55, %rd56;
	ld.global.nc.f32 	%f2, [%rd57];
	add.s64 	%rd58, %rd47, %rd53;
	add.s64 	%rd59, %rd58, %rd52;
	add.s64 	%rd60, %rd59, %rd56;
	ld.global.nc.f32 	%f3, [%rd60];
	add.rn.f32 	%f4, %f2, %f3;
	selp.f32 	%f5, %f4, 0f00000000, %p2;
	add.s64 	%rd61, %rd42, %rd49;
	ld.global.nc.f32 	%f6, [%rd61];
	setp.gt.f32 	%p3, %f6, 0f41800000;
	selp.u32 	%r10, 1, 0, %p3;
	setp.eq.s32 	%p4, %r7, %r10;
	add.s64 	%rd62, %rd44, %rd53;
	add.s64 	%rd63, %rd62, %rd52;
	add.s64 	%rd64, %rd63, %rd56;
	ld.global.nc.f32 	%f7, [%rd64];
	add.s64 	%rd65, %rd43, %rd53;
	add.s64 	%rd66, %rd65, %rd52;
	add.s64 	%rd67, %rd66, %rd56;
	ld.global.nc.f32 	%f8, [%rd67];
	add.rn.f32 	%f9, %f7, %f8;
	selp.f32 	%f10, %f9, 0f00000000, %p4;
	add.s64 	%rd68, %rd39, %rd49;
	ld.global.nc.f32 	%f11, [%rd68];
	setp.gt.f32 	%p5, %f11, 0f41800000;
	selp.u32 	%r11, 1, 0, %p5;
	setp.eq.s32 	%p6, %r7, %r11;
	add.s64 	%rd69, %rd41, %rd53;
	add.s64 	%rd70, %rd69, %rd52;
	add.s64 	%rd71, %rd70, %rd56;
	ld.global.nc.f32 	%f12, [%rd71];
	add.s64 	%rd72, %rd40, %rd53;
	add.s64 	%rd73, %rd72, %rd52;
	add.s64 	%rd74, %rd73, %rd56;
	ld.global.nc.f32 	%f13, [%rd74];
	add.rn.f32 	%f14, %f12, %f13;
	selp.f32 	%f15, %f14, 0f00000000, %p6;
	add.s64 	%rd75, %rd36, %rd49;
	ld.global.nc.f32 	%f16, [%rd75];
	setp.gt.f32 	%p7, %f16, 0f41800000;
	selp.u32 	%r12, 1, 0, %p7;
	setp.eq.s32 	%p8, %r7, %r12;
	add.s64 	%rd76, %rd38, %rd53;
	add.s64 	%rd77, %rd76, %rd52;
	add.s64 	%rd78, %rd77, %rd56;
	ld.global.nc.f32 	%f17, [%rd78];
	add.s64 	%rd79, %rd37, %rd53;
	add.s64 	%rd80, %rd79, %rd52;
	add.s64 	%rd81, %rd80, %rd56;
	ld.global.nc.f32 	%f18, [%rd81];
	add.rn.f32 	%f19, %f17, %f18;
	selp.f32 	%f20, %f19, 0f00000000, %p8;
	add.s64 	%rd82, %rd27, %rd49;
	ld.global.nc.f32 	%f21, [%rd82];
	setp.gt.f32 	%p9, %f21, 0f41800000;
	selp.u32 	%r13, 1, 0, %p9;
	setp.eq.s32 	%p10, %r7, %r13;
	add.s64 	%rd83, %rd33, %rd53;
	add.s64 	%rd84, %rd83, %rd52;
	add.s64 	%rd85, %rd84, %rd56;
	ld.global.nc.f32 	%f22, [%rd85];
	add.s64 	%rd86, %rd30, %rd53;
	add.s64 	%rd87, %rd86, %rd52;
	add.s64 	%rd88, %rd87, %rd56;
	ld.global.nc.f32 	%f23, [%rd88];
	add.rn.f32 	%f24, %f22, %f23;
	selp.f32 	%f25, %f24, 0f00000000, %p10;
	add.s64 	%rd89, %rd18, %rd49;
	ld.global.nc.f32 	%f26, [%rd89];
	setp.gt.f32 	%p11, %f26, 0f41800000;
	selp.u32 	%r14, 1, 0, %p11;
	setp.eq.s32 	%p12, %r7, %r14;
	mul.wide.u32 	%rd90, %r4, 4;
	add.s64 	%rd91, %rd24, %rd90;
	ld.global.f32 	%f27, [%rd91];
	add.s64 	%rd92, %rd21, %rd90;
	ld.global.nc.f32 	%f28, [%rd92];
	add.rn.f32 	%f29, %f27, %f28;
	selp.f32 	%f30, %f29, 0f00000000, %p12;
	add.s64 	%rd93, %rd15, %rd90;
	st.global.f32 	[%rd93], %f5;
	add.s64 	%rd94, %rd12, %rd90;
	st.global.f32 	[%rd94], %f10;
	add.s64 	%rd95, %rd9, %rd90;
	st.global.f32 	[%rd95], %f15;
	add.s64 	%rd96, %rd6, %rd90;
	st.global.f32 	[%rd96], %f20;
	add.s64 	%rd97, %rd3, %rd90;
	st.global.f32 	[%rd97], %f25;
	st.global.f32 	[%rd91], %f30;
	ret;

}
	// .globl	loop_select_fusion_46
.visible .entry loop_select_fusion_46(
	.param .u64 loop_select_fusion_46_param_0,
	.param .u64 loop_select_fusion_46_param_1,
	.param .u64 loop_select_fusion_46_param_2,
	.param .u64 loop_select_fusion_46_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<20>;

	ld.param.u64 	%rd1, [loop_select_fusion_46_param_0];
	ld.param.u64 	%rd2, [loop_select_fusion_46_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_select_fusion_46_param_1];
	ld.param.u64 	%rd5, [loop_select_fusion_46_param_2];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	ld.global.nc.u32 	%r5, [%rd6];
	mov.b32 	%r6, 15;
	sub.s32 	%r7, %r6, %r5;
	setp.lt.s32 	%p1, %r7, 0;
	mov.b32 	%r8, 31;
	sub.s32 	%r9, %r8, %r5;
	selp.b32 	%r10, %r9, %r7, %p1;
	max.s32 	%r11, %r10, 0;
	min.s32 	%r12, %r11, 15;
	mul.wide.u32 	%rd9, %r12, 9216;
	add.s64 	%rd10, %rd7, %rd9;
	cvt.u32.u16 	%r13, %rs3;
	mul.wide.u32 	%rd11, %r13, 144;
	add.s64 	%rd12, %rd10, %rd11;
	cvt.u32.u16 	%r14, %rs8;
	mul.wide.u32 	%rd13, %r14, 24;
	add.s64 	%rd14, %rd12, %rd13;
	cvt.u32.u16 	%r15, %rs10;
	mul.wide.u32 	%rd15, %r15, 4;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.nc.u32 	%r16, [%rd16];
	setp.eq.s32 	%p2, %r16, 1;
	mul.wide.u32 	%rd17, %r4, 4;
	add.s64 	%rd18, %rd8, %rd17;
	ld.global.nc.f32 	%f1, [%rd18];
	selp.f32 	%f2, %f1, 0f00000000, %p2;
	add.s64 	%rd19, %rd3, %rd17;
	st.global.f32 	[%rd19], %f2;
	ret;

}
	// .globl	loop_dynamic_slice_fusion_6
.visible .entry loop_dynamic_slice_fusion_6(
	.param .u64 loop_dynamic_slice_fusion_6_param_0,
	.param .u64 loop_dynamic_slice_fusion_6_param_1,
	.param .u64 loop_dynamic_slice_fusion_6_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<16>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<17>;

	ld.param.u64 	%rd1, [loop_dynamic_slice_fusion_6_param_0];
	ld.param.u64 	%rd2, [loop_dynamic_slice_fusion_6_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_dynamic_slice_fusion_6_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	and.b16  	%rs4, %rs3, 63;
	mul.hi.u16 	%rs5, %rs1, -21845;
	shr.u16 	%rs6, %rs5, 2;
	mul.hi.u16 	%rs7, %rs6, 10923;
	mul.lo.s16 	%rs8, %rs7, 6;
	sub.s16 	%rs9, %rs6, %rs8;
	mul.lo.s16 	%rs10, %rs6, 6;
	sub.s16 	%rs11, %rs1, %rs10;
	ld.global.nc.u32 	%r5, [%rd5];
	mov.b32 	%r6, 15;
	sub.s32 	%r7, %r6, %r5;
	setp.lt.s32 	%p1, %r7, 0;
	mov.b32 	%r8, 31;
	sub.s32 	%r9, %r8, %r5;
	selp.b32 	%r10, %r9, %r7, %p1;
	max.s32 	%r11, %r10, 0;
	min.s32 	%r12, %r11, 15;
	mul.wide.u32 	%rd7, %r12, 9216;
	add.s64 	%rd8, %rd6, %rd7;
	cvt.u32.u16 	%r13, %rs4;
	mul.wide.u32 	%rd9, %r13, 144;
	add.s64 	%rd10, %rd8, %rd9;
	cvt.u32.u16 	%r14, %rs9;
	mul.wide.u32 	%rd11, %r14, 24;
	add.s64 	%rd12, %rd10, %rd11;
	cvt.u32.u16 	%r15, %rs11;
	mul.wide.u32 	%rd13, %r15, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.nc.f32 	%f1, [%rd14];
	mul.wide.u32 	%rd15, %r4, 4;
	add.s64 	%rd16, %rd3, %rd15;
	st.global.f32 	[%rd16], %f1;
	ret;

}
	// .globl	wrapped_dot_173
.visible .entry wrapped_dot_173(
	.param .u64 wrapped_dot_173_param_0,
	.param .u64 wrapped_dot_173_param_1,
	.param .u64 wrapped_dot_173_param_2
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<25>;
	.reg .b64 	%rd<16>;

	ld.param.u64 	%rd1, [wrapped_dot_173_param_0];
	ld.param.u64 	%rd2, [wrapped_dot_173_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [wrapped_dot_173_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs8;
	mul.wide.u32 	%rd7, %r5, 4;
	cvt.u32.u16 	%r6, %rs10;
	mul.wide.u32 	%rd8, %r6, 144;
	add.s64 	%rd9, %rd6, %rd8;
	add.s64 	%rd10, %rd9, %rd7;
	ld.global.nc.f32 	%f1, [%rd10];
	cvt.u32.u16 	%r7, %rs5;
	mul.wide.u32 	%rd11, %r7, 4;
	add.s64 	%rd12, %rd5, %rd8;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.nc.f32 	%f2, [%rd13];
	mul.rn.f32 	%f3, %f1, %f2;
	add.rn.f32 	%f4, %f3, 0f00000000;
	ld.global.nc.f32 	%f5, [%rd10+24];
	ld.global.nc.f32 	%f6, [%rd13+24];
	mul.rn.f32 	%f7, %f5, %f6;
	add.rn.f32 	%f8, %f4, %f7;
	ld.global.nc.f32 	%f9, [%rd10+48];
	ld.global.nc.f32 	%f10, [%rd13+48];
	mul.rn.f32 	%f11, %f9, %f10;
	add.rn.f32 	%f12, %f8, %f11;
	ld.global.nc.f32 	%f13, [%rd10+72];
	ld.global.nc.f32 	%f14, [%rd13+72];
	mul.rn.f32 	%f15, %f13, %f14;
	add.rn.f32 	%f16, %f12, %f15;
	ld.global.nc.f32 	%f17, [%rd10+96];
	ld.global.nc.f32 	%f18, [%rd13+96];
	mul.rn.f32 	%f19, %f17, %f18;
	add.rn.f32 	%f20, %f16, %f19;
	ld.global.nc.f32 	%f21, [%rd10+120];
	ld.global.nc.f32 	%f22, [%rd13+120];
	mul.rn.f32 	%f23, %f21, %f22;
	add.rn.f32 	%f24, %f20, %f23;
	mul.wide.u32 	%rd14, %r4, 4;
	add.s64 	%rd15, %rd3, %rd14;
	st.global.f32 	[%rd15], %f24;
	ret;

}
	// .globl	wrapped_dot_174
.visible .entry wrapped_dot_174(
	.param .u64 wrapped_dot_174_param_0,
	.param .u64 wrapped_dot_174_param_1,
	.param .u64 wrapped_dot_174_param_2
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<25>;
	.reg .b64 	%rd<16>;

	ld.param.u64 	%rd1, [wrapped_dot_174_param_0];
	ld.param.u64 	%rd2, [wrapped_dot_174_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [wrapped_dot_174_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs8;
	mul.wide.u32 	%rd7, %r5, 24;
	cvt.u32.u16 	%r6, %rs10;
	mul.wide.u32 	%rd8, %r6, 144;
	add.s64 	%rd9, %rd6, %rd8;
	add.s64 	%rd10, %rd9, %rd7;
	ld.global.nc.v2.f32 	{%f1, %f2}, [%rd10];
	cvt.u32.u16 	%r7, %rs5;
	mul.wide.u32 	%rd11, %r7, 24;
	add.s64 	%rd12, %rd5, %rd8;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.nc.v2.f32 	{%f3, %f4}, [%rd13];
	mul.rn.f32 	%f5, %f1, %f3;
	add.rn.f32 	%f6, %f5, 0f00000000;
	mul.rn.f32 	%f7, %f2, %f4;
	add.rn.f32 	%f8, %f6, %f7;
	ld.global.nc.v2.f32 	{%f9, %f10}, [%rd10+8];
	ld.global.nc.v2.f32 	{%f11, %f12}, [%rd13+8];
	mul.rn.f32 	%f13, %f9, %f11;
	add.rn.f32 	%f14, %f8, %f13;
	mul.rn.f32 	%f15, %f10, %f12;
	add.rn.f32 	%f16, %f14, %f15;
	ld.global.nc.v2.f32 	{%f17, %f18}, [%rd10+16];
	ld.global.nc.v2.f32 	{%f19, %f20}, [%rd13+16];
	mul.rn.f32 	%f21, %f17, %f19;
	add.rn.f32 	%f22, %f16, %f21;
	mul.rn.f32 	%f23, %f18, %f20;
	add.rn.f32 	%f24, %f22, %f23;
	mul.wide.u32 	%rd14, %r4, 4;
	add.s64 	%rd15, %rd3, %rd14;
	st.global.f32 	[%rd15], %f24;
	ret;

}
	// .globl	loop_add_fusion_521
.visible .entry loop_add_fusion_521(
	.param .u64 loop_add_fusion_521_param_0,
	.param .u64 loop_add_fusion_521_param_1,
	.param .u64 loop_add_fusion_521_param_2,
	.param .u64 loop_add_fusion_521_param_3,
	.param .u64 loop_add_fusion_521_param_4,
	.param .u64 loop_add_fusion_521_param_5,
	.param .u64 loop_add_fusion_521_param_6
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<17>;
	.reg .b32 	%r<17>;
	.reg .f32 	%f<9>;
	.reg .b64 	%rd<39>;

	ld.param.u64 	%rd1, [loop_add_fusion_521_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_521_param_6];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_521_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_521_param_5];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_521_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_521_param_4];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_521_param_3];
	cvta.to.global.u64 	%rd11, %rd10;
	cvta.to.global.u64 	%rd12, %rd7;
	cvta.to.global.u64 	%rd13, %rd4;
	cvta.to.global.u64 	%rd14, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	ld.global.nc.u32 	%r5, [%rd3];
	mov.b32 	%r6, 15;
	sub.s32 	%r7, %r6, %r5;
	setp.lt.s32 	%p1, %r7, 0;
	mov.b32 	%r8, 31;
	sub.s32 	%r9, %r8, %r5;
	selp.b32 	%r10, %r9, %r7, %p1;
	max.s32 	%r11, %r10, 0;
	min.s32 	%r12, %r11, 15;
	cvt.u64.u16 	%rd15, %rs10;
	mul.wide.u32 	%rd16, %r12, 2304;
	add.s64 	%rd17, %rd6, %rd16;
	cvt.u32.u16 	%r13, %rs3;
	mul.wide.u32 	%rd18, %r13, 36;
	add.s64 	%rd19, %rd17, %rd18;
	cvt.u32.u16 	%r14, %rs8;
	mul.wide.u32 	%rd20, %r14, 6;
	add.s64 	%rd21, %rd19, %rd20;
	add.s64 	%rd22, %rd21, %rd15;
	ld.global.nc.u8 	%rs11, [%rd22];
	cvt.u16.u8 	%rs12, %rs11;
	mul.wide.u32 	%rd23, %r4, 4;
	add.s64 	%rd24, %rd14, %rd23;
	ld.global.nc.f32 	%f1, [%rd24];
	add.s64 	%rd25, %rd13, %rd23;
	ld.global.nc.f32 	%f2, [%rd25];
	add.rn.f32 	%f3, %f1, %f2;
	and.b16  	%rs13, %rs12, 1;
	setp.eq.b16 	%p2, %rs13, 1;
	selp.f32 	%f4, %f3, 0f00000000, %p2;
	add.s64 	%rd26, %rd9, %rd16;
	add.s64 	%rd27, %rd26, %rd18;
	add.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd15;
	ld.global.nc.u8 	%rs14, [%rd29];
	cvt.u16.u8 	%rs15, %rs14;
	mul.wide.u32 	%rd30, %r12, 9216;
	add.s64 	%rd31, %rd11, %rd30;
	mul.wide.u32 	%rd32, %r13, 144;
	add.s64 	%rd33, %rd31, %rd32;
	mul.wide.u32 	%rd34, %r14, 24;
	add.s64 	%rd35, %rd33, %rd34;
	cvt.u32.u16 	%r15, %rs10;
	mul.wide.u32 	%rd36, %r15, 4;
	add.s64 	%rd37, %rd35, %rd36;
	ld.global.nc.u32 	%r16, [%rd37];
	setp.eq.s32 	%p3, %r16, 0;
	add.s64 	%rd38, %rd12, %rd23;
	ld.global.f32 	%f5, [%rd38];
	and.b16  	%rs16, %rs15, 1;
	setp.eq.b16 	%p4, %rs16, 1;
	selp.f32 	%f6, %f5, 0f00000000, %p3;
	selp.f32 	%f7, %f6, 0f00000000, %p4;
	add.rn.f32 	%f8, %f4, %f7;
	st.global.f32 	[%rd38], %f8;
	ret;

}
	// .globl	wrapped_transpose_233
.visible .entry wrapped_transpose_233(
	.param .u64 wrapped_transpose_233_param_0,
	.param .u64 wrapped_transpose_233_param_1
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<13>;

	ld.param.u64 	%rd1, [wrapped_transpose_233_param_0];
	ld.param.u64 	%rd2, [wrapped_transpose_233_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd5, %r5, 24;
	cvt.u32.u16 	%r6, %rs3;
	mul.wide.u32 	%rd6, %r6, 144;
	add.s64 	%rd7, %rd4, %rd6;
	add.s64 	%rd8, %rd7, %rd5;
	cvt.u32.u16 	%r7, %rs8;
	mul.wide.u32 	%rd9, %r7, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd3, %rd11;
	st.global.f32 	[%rd12], %f1;
	ret;

}
	// .globl	wrapped_iota_13
.visible .entry wrapped_iota_13(
	.param .u64 wrapped_iota_13_param_0
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [wrapped_iota_13_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	cvt.u32.u16 	%r5, %rs5;
	mul.wide.u32 	%rd3, %r4, 4;
	add.s64 	%rd4, %rd2, %rd3;
	st.global.u32 	[%rd4], %r5;
	ret;

}
	// .globl	sort_35_1
.visible .entry sort_35_1(
	.param .u64 sort_35_1_param_0,
	.param .u64 sort_35_1_param_1,
	.param .u64 sort_35_1_param_2
)
.reqntid 4, 1, 1
{
	.reg .pred 	%p<39>;
	.reg .b32 	%r<83>;
	.reg .b64 	%rd<141>;
	// demoted variable
	.shared .align 4 .b8 sort_$_35_$_1_tile_param_0[256];
	// demoted variable
	.shared .align 4 .b8 sort_$_35_$_1_tile_param_1[256];
	// demoted variable
	.shared .align 4 .b8 sort_$_35_$_1_tile_param_2[256];
	ld.param.u64 	%rd38, [sort_35_1_param_0];
	ld.param.u64 	%rd39, [sort_35_1_param_2];
	cvta.to.global.u64 	%rd1, %rd39;
	ld.param.u64 	%rd40, [sort_35_1_param_1];
	cvta.to.global.u64 	%rd2, %rd40;
	cvta.to.global.u64 	%rd3, %rd38;
	mov.u32 	%r31, %ctaid.x;
	mov.u32 	%r32, %tid.x;
	shl.b32 	%r33, %r31, 2;
	or.b32  	%r34, %r33, %r32;
	cvt.u64.u32 	%rd41, %r34;
	shr.u64 	%rd4, %rd41, 2;
	mul.wide.u32 	%rd42, %r34, 2;
	and.b64  	%rd6, %rd42, 6;
	setp.eq.s64 	%p1, %rd6, 6;
	mul.wide.u32 	%rd7, %r32, 2;
	shl.b64 	%rd134, %rd7, 2;
	mov.u64 	%rd135, sort_$_35_$_1_tile_param_0;
	mul.lo.s64 	%rd136, %rd4, 24;
	shl.b64 	%rd137, %rd6, 2;
	or.b64  	%rd138, %rd6, 1;
	mov.u64 	%rd139, sort_$_35_$_1_tile_param_2;
	@%p1 bra 	$L__BB309_1;
	add.s64 	%rd44, %rd3, %rd136;
	add.s64 	%rd12, %rd44, %rd137;
	ld.global.u32 	%r35, [%rd12];
	add.s64 	%rd13, %rd135, %rd134;
	st.shared.u32 	[%rd13], %r35;
	setp.gt.u64 	%p2, %rd138, 5;
	mov.u64 	%rd133, sort_$_35_$_1_tile_param_1;
	@%p2 bra 	$L__BB309_11;
	ld.global.u32 	%r36, [%rd12+4];
	st.shared.u32 	[%rd13+4], %r36;
	add.s64 	%rd53, %rd2, %rd136;
	add.s64 	%rd55, %rd53, %rd137;
	ld.global.v2.u32 	{%r81, %r37}, [%rd55];
	add.s64 	%rd58, %rd133, %rd134;
	st.shared.u32 	[%rd58+4], %r37;
	bra.uni 	$L__BB309_12;
$L__BB309_11:
	add.s64 	%rd49, %rd2, %rd136;
	add.s64 	%rd51, %rd49, %rd137;
	ld.global.u32 	%r81, [%rd51];
$L__BB309_12:
	add.s64 	%rd61, %rd133, %rd134;
	st.shared.u32 	[%rd61], %r81;
	add.s64 	%rd63, %rd1, %rd136;
	add.s64 	%rd15, %rd63, %rd137;
	ld.global.u32 	%r38, [%rd15];
	add.s64 	%rd16, %rd139, %rd134;
	st.shared.u32 	[%rd16], %r38;
	@%p2 bra 	$L__BB309_1;
	ld.global.u32 	%r39, [%rd15+4];
	st.shared.u32 	[%rd16+4], %r39;
$L__BB309_1:
	cvt.u64.u32 	%rd5, %r32;
	bar.sync 	0;
	or.b64  	%rd8, %rd7, 1;
	setp.lt.u64 	%p4, %rd8, 6;
	@%p4 bra 	$L__BB309_14;
	bra.uni 	$L__BB309_2;
$L__BB309_14:
	add.s64 	%rd17, %rd135, %rd134;
	add.s64 	%rd18, %rd139, %rd134;
	ld.shared.u32 	%r4, [%rd17+4];
	ld.shared.u32 	%r5, [%rd17];
	ld.shared.u32 	%r6, [%rd18+4];
	ld.shared.u32 	%r7, [%rd18];
	setp.ge.s32 	%p5, %r4, %r5;
	setp.eq.s32 	%p6, %r5, %r4;
	setp.ge.s32 	%p7, %r6, %r7;
	selp.u32 	%r40, -1, 0, %p5;
	selp.u32 	%r41, -1, 0, %p7;
	selp.b32 	%r42, %r41, %r40, %p6;
	and.b32  	%r43, %r42, 1;
	setp.eq.b32 	%p8, %r43, 1;
	@%p8 bra 	$L__BB309_2;
	mov.u64 	%rd70, sort_$_35_$_1_tile_param_1;
	add.s64 	%rd71, %rd70, %rd134;
	st.shared.v2.u32 	[%rd17], {%r4, %r5};
	ld.shared.u32 	%r44, [%rd71+4];
	ld.shared.u32 	%r45, [%rd71];
	st.shared.v2.u32 	[%rd71], {%r44, %r45};
	st.shared.v2.u32 	[%rd18], {%r6, %r7};
$L__BB309_2:
	bar.sync 	0;
	and.b64  	%rd72, %rd5, 1;
	and.b64  	%rd73, %rd7, 4;
	or.b64  	%rd9, %rd73, %rd72;
	xor.b64  	%rd10, %rd9, 3;
	setp.lt.u64 	%p9, %rd9, %rd10;
	setp.lt.u64 	%p10, %rd10, 6;
	and.pred  	%p11, %p9, %p10;
	shl.b64 	%rd140, %rd9, 2;
	@%p11 bra 	$L__BB309_16;
	bra.uni 	$L__BB309_3;
$L__BB309_16:
	shl.b64 	%rd74, %rd10, 2;
	add.s64 	%rd19, %rd135, %rd74;
	add.s64 	%rd20, %rd135, %rd140;
	add.s64 	%rd21, %rd139, %rd74;
	add.s64 	%rd22, %rd139, %rd140;
	ld.shared.u32 	%r8, [%rd19];
	ld.shared.u32 	%r9, [%rd20];
	ld.shared.u32 	%r10, [%rd21];
	ld.shared.u32 	%r11, [%rd22];
	setp.ge.s32 	%p12, %r8, %r9;
	setp.eq.s32 	%p13, %r9, %r8;
	setp.ge.s32 	%p14, %r10, %r11;
	selp.u32 	%r46, -1, 0, %p12;
	selp.u32 	%r47, -1, 0, %p14;
	selp.b32 	%r48, %r47, %r46, %p13;
	and.b32  	%r49, %r48, 1;
	setp.eq.b32 	%p15, %r49, 1;
	@%p15 bra 	$L__BB309_3;
	mov.u64 	%rd79, sort_$_35_$_1_tile_param_1;
	add.s64 	%rd80, %rd79, %rd140;
	add.s64 	%rd82, %rd79, %rd74;
	st.shared.u32 	[%rd20], %r8;
	st.shared.u32 	[%rd19], %r9;
	ld.shared.u32 	%r50, [%rd82];
	ld.shared.u32 	%r51, [%rd80];
	st.shared.u32 	[%rd80], %r50;
	st.shared.u32 	[%rd82], %r51;
	st.shared.u32 	[%rd22], %r10;
	st.shared.u32 	[%rd21], %r11;
$L__BB309_3:
	bar.sync 	0;
	@%p4 bra 	$L__BB309_18;
	bra.uni 	$L__BB309_4;
$L__BB309_18:
	add.s64 	%rd23, %rd135, %rd134;
	add.s64 	%rd24, %rd139, %rd134;
	ld.shared.u32 	%r12, [%rd23+4];
	ld.shared.u32 	%r13, [%rd23];
	ld.shared.u32 	%r14, [%rd24+4];
	ld.shared.u32 	%r15, [%rd24];
	setp.ge.s32 	%p17, %r12, %r13;
	setp.eq.s32 	%p18, %r13, %r12;
	setp.ge.s32 	%p19, %r14, %r15;
	selp.u32 	%r52, -1, 0, %p17;
	selp.u32 	%r53, -1, 0, %p19;
	selp.b32 	%r54, %r53, %r52, %p18;
	and.b32  	%r55, %r54, 1;
	setp.eq.b32 	%p20, %r55, 1;
	@%p20 bra 	$L__BB309_4;
	mov.u64 	%rd87, sort_$_35_$_1_tile_param_1;
	add.s64 	%rd88, %rd87, %rd134;
	st.shared.v2.u32 	[%rd23], {%r12, %r13};
	ld.shared.u32 	%r56, [%rd88+4];
	ld.shared.u32 	%r57, [%rd88];
	st.shared.v2.u32 	[%rd88], {%r56, %r57};
	st.shared.v2.u32 	[%rd24], {%r14, %r15};
$L__BB309_4:
	bar.sync 	0;
	xor.b64  	%rd11, %rd5, 7;
	setp.lt.u64 	%p21, %rd11, 6;
	@%p21 bra 	$L__BB309_20;
	bra.uni 	$L__BB309_5;
$L__BB309_20:
	shl.b64 	%rd89, %rd11, 2;
	add.s64 	%rd25, %rd135, %rd89;
	shl.b64 	%rd91, %rd5, 2;
	add.s64 	%rd26, %rd135, %rd91;
	add.s64 	%rd27, %rd139, %rd89;
	add.s64 	%rd28, %rd139, %rd91;
	ld.shared.u32 	%r16, [%rd25];
	ld.shared.u32 	%r17, [%rd26];
	ld.shared.u32 	%r18, [%rd27];
	ld.shared.u32 	%r19, [%rd28];
	setp.ge.s32 	%p22, %r16, %r17;
	setp.eq.s32 	%p23, %r17, %r16;
	setp.ge.s32 	%p24, %r18, %r19;
	selp.u32 	%r58, -1, 0, %p22;
	selp.u32 	%r59, -1, 0, %p24;
	selp.b32 	%r60, %r59, %r58, %p23;
	and.b32  	%r61, %r60, 1;
	setp.eq.b32 	%p25, %r61, 1;
	@%p25 bra 	$L__BB309_5;
	mov.u64 	%rd94, sort_$_35_$_1_tile_param_1;
	add.s64 	%rd95, %rd94, %rd91;
	add.s64 	%rd97, %rd94, %rd89;
	st.shared.u32 	[%rd26], %r16;
	st.shared.u32 	[%rd25], %r17;
	ld.shared.u32 	%r62, [%rd97];
	ld.shared.u32 	%r63, [%rd95];
	st.shared.u32 	[%rd95], %r62;
	st.shared.u32 	[%rd97], %r63;
	st.shared.u32 	[%rd28], %r18;
	st.shared.u32 	[%rd27], %r19;
$L__BB309_5:
	bar.sync 	0;
	or.b64  	%rd98, %rd9, 2;
	setp.lt.u64 	%p26, %rd98, 6;
	@%p26 bra 	$L__BB309_22;
	bra.uni 	$L__BB309_6;
$L__BB309_22:
	add.s64 	%rd29, %rd135, %rd140;
	add.s64 	%rd30, %rd139, %rd140;
	ld.shared.u32 	%r20, [%rd29+8];
	ld.shared.u32 	%r21, [%rd29];
	ld.shared.u32 	%r22, [%rd30+8];
	ld.shared.u32 	%r23, [%rd30];
	setp.ge.s32 	%p27, %r20, %r21;
	setp.eq.s32 	%p28, %r21, %r20;
	setp.ge.s32 	%p29, %r22, %r23;
	selp.u32 	%r64, -1, 0, %p27;
	selp.u32 	%r65, -1, 0, %p29;
	selp.b32 	%r66, %r65, %r64, %p28;
	and.b32  	%r67, %r66, 1;
	setp.eq.b32 	%p30, %r67, 1;
	@%p30 bra 	$L__BB309_6;
	mov.u64 	%rd103, sort_$_35_$_1_tile_param_1;
	add.s64 	%rd104, %rd103, %rd140;
	st.shared.u32 	[%rd29], %r20;
	st.shared.u32 	[%rd29+8], %r21;
	ld.shared.u32 	%r68, [%rd104+8];
	ld.shared.u32 	%r69, [%rd104];
	st.shared.u32 	[%rd104], %r68;
	st.shared.u32 	[%rd104+8], %r69;
	st.shared.u32 	[%rd30], %r22;
	st.shared.u32 	[%rd30+8], %r23;
$L__BB309_6:
	bar.sync 	0;
	@%p4 bra 	$L__BB309_24;
	bra.uni 	$L__BB309_7;
$L__BB309_24:
	add.s64 	%rd31, %rd135, %rd134;
	add.s64 	%rd32, %rd139, %rd134;
	ld.shared.u32 	%r24, [%rd31+4];
	ld.shared.u32 	%r25, [%rd31];
	ld.shared.u32 	%r26, [%rd32+4];
	ld.shared.u32 	%r27, [%rd32];
	setp.ge.s32 	%p32, %r24, %r25;
	setp.eq.s32 	%p33, %r25, %r24;
	setp.ge.s32 	%p34, %r26, %r27;
	selp.u32 	%r70, -1, 0, %p32;
	selp.u32 	%r71, -1, 0, %p34;
	selp.b32 	%r72, %r71, %r70, %p33;
	and.b32  	%r73, %r72, 1;
	setp.eq.b32 	%p35, %r73, 1;
	@%p35 bra 	$L__BB309_7;
	mov.u64 	%rd109, sort_$_35_$_1_tile_param_1;
	add.s64 	%rd110, %rd109, %rd134;
	st.shared.v2.u32 	[%rd31], {%r24, %r25};
	ld.shared.u32 	%r74, [%rd110+4];
	ld.shared.u32 	%r75, [%rd110];
	st.shared.v2.u32 	[%rd110], {%r74, %r75};
	st.shared.v2.u32 	[%rd32], {%r26, %r27};
$L__BB309_7:
	bar.sync 	0;
	@%p1 bra 	$L__BB309_8;
	add.s64 	%rd33, %rd135, %rd134;
	ld.shared.u32 	%r76, [%rd33];
	add.s64 	%rd114, %rd3, %rd136;
	add.s64 	%rd34, %rd114, %rd137;
	st.global.u32 	[%rd34], %r76;
	setp.gt.u64 	%p37, %rd138, 5;
	@%p37 bra 	$L__BB309_28;
	ld.shared.u32 	%r77, [%rd33+4];
	st.global.u32 	[%rd34+4], %r77;
	mov.u64 	%rd120, sort_$_35_$_1_tile_param_1;
	add.s64 	%rd121, %rd120, %rd134;
	ld.shared.v2.u32 	{%r82, %r78}, [%rd121];
	add.s64 	%rd123, %rd2, %rd136;
	add.s64 	%rd125, %rd123, %rd137;
	st.global.u32 	[%rd125+4], %r78;
	bra.uni 	$L__BB309_29;
$L__BB309_28:
	mov.u64 	%rd117, sort_$_35_$_1_tile_param_1;
	add.s64 	%rd118, %rd117, %rd134;
	ld.shared.u32 	%r82, [%rd118];
$L__BB309_29:
	add.s64 	%rd127, %rd2, %rd136;
	add.s64 	%rd129, %rd127, %rd137;
	st.global.u32 	[%rd129], %r82;
	add.s64 	%rd36, %rd139, %rd134;
	ld.shared.u32 	%r79, [%rd36];
	add.s64 	%rd132, %rd1, %rd136;
	add.s64 	%rd37, %rd132, %rd137;
	st.global.u32 	[%rd37], %r79;
	@%p37 bra 	$L__BB309_8;
	ld.shared.u32 	%r80, [%rd36+4];
	st.global.u32 	[%rd37+4], %r80;
$L__BB309_8:
	ret;

}
	// .globl	loop_transpose_fusion_192
.visible .entry loop_transpose_fusion_192(
	.param .u64 loop_transpose_fusion_192_param_0,
	.param .u64 loop_transpose_fusion_192_param_1,
	.param .u64 loop_transpose_fusion_192_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<20>;
	.reg .b32 	%r<14>;
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<19>;

	ld.param.u64 	%rd1, [loop_transpose_fusion_192_param_0];
	ld.param.u64 	%rd2, [loop_transpose_fusion_192_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_transpose_fusion_192_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	and.b16  	%rs4, %rs3, 63;
	mul.hi.u16 	%rs5, %rs1, -21845;
	shr.u16 	%rs6, %rs5, 2;
	mul.hi.u16 	%rs7, %rs6, 10923;
	mul.lo.s16 	%rs8, %rs7, 6;
	sub.s16 	%rs9, %rs6, %rs8;
	mul.lo.s16 	%rs10, %rs6, 6;
	sub.s16 	%rs11, %rs1, %rs10;
	mul.lo.s16 	%rs12, %rs4, 6;
	add.s16 	%rs13, %rs12, %rs11;
	mul.hi.u16 	%rs15, %rs13, -21845;
	shr.u16 	%rs16, %rs15, 2;
	setp.gt.u16 	%p1, %rs13, 377;
	selp.b16 	%rs17, 63, %rs16, %p1;
	mul.lo.s16 	%rs18, %rs16, 6;
	sub.s16 	%rs19, %rs13, %rs18;
	cvt.u32.u16 	%r5, %rs19;
	mul.wide.u32 	%rd7, %r5, 4;
	cvt.u32.u16 	%r6, %rs16;
	mul.wide.u32 	%rd8, %r6, 24;
	add.s64 	%rd9, %rd6, %rd8;
	add.s64 	%rd10, %rd9, %rd7;
	ld.global.nc.u32 	%r7, [%rd10];
	setp.lt.s32 	%p2, %r7, 0;
	add.s32 	%r8, %r7, 6;
	selp.b32 	%r9, %r8, %r7, %p2;
	max.s32 	%r10, %r9, 0;
	min.s32 	%r11, %r10, 5;
	mul.wide.u32 	%rd11, %r11, 4;
	cvt.u32.u16 	%r12, %rs17;
	mul.wide.u32 	%rd12, %r12, 144;
	add.s64 	%rd13, %rd5, %rd12;
	cvt.u32.u16 	%r13, %rs9;
	mul.wide.u32 	%rd14, %r13, 24;
	add.s64 	%rd15, %rd13, %rd14;
	add.s64 	%rd16, %rd15, %rd11;
	ld.global.nc.f32 	%f1, [%rd16];
	neg.f32 	%f2, %f1;
	mul.wide.u32 	%rd17, %r4, 4;
	add.s64 	%rd18, %rd3, %rd17;
	st.global.f32 	[%rd18], %f2;
	ret;

}
	// .globl	sort_34_1
.visible .entry sort_34_1(
	.param .u64 sort_34_1_param_0,
	.param .u64 sort_34_1_param_1,
	.param .u64 sort_34_1_param_2
)
.reqntid 4, 1, 1
{
	.reg .pred 	%p<39>;
	.reg .b32 	%r<83>;
	.reg .b64 	%rd<141>;
	// demoted variable
	.shared .align 4 .b8 sort_$_34_$_1_tile_param_0[256];
	// demoted variable
	.shared .align 4 .b8 sort_$_34_$_1_tile_param_1[256];
	// demoted variable
	.shared .align 4 .b8 sort_$_34_$_1_tile_param_2[256];
	ld.param.u64 	%rd38, [sort_34_1_param_0];
	ld.param.u64 	%rd39, [sort_34_1_param_2];
	cvta.to.global.u64 	%rd1, %rd39;
	ld.param.u64 	%rd40, [sort_34_1_param_1];
	cvta.to.global.u64 	%rd2, %rd40;
	cvta.to.global.u64 	%rd3, %rd38;
	mov.u32 	%r31, %ctaid.x;
	mov.u32 	%r32, %tid.x;
	shl.b32 	%r33, %r31, 2;
	or.b32  	%r34, %r33, %r32;
	cvt.u64.u32 	%rd41, %r34;
	shr.u64 	%rd4, %rd41, 2;
	mul.wide.u32 	%rd42, %r34, 2;
	and.b64  	%rd6, %rd42, 6;
	setp.eq.s64 	%p1, %rd6, 6;
	mul.wide.u32 	%rd7, %r32, 2;
	shl.b64 	%rd134, %rd7, 2;
	mov.u64 	%rd135, sort_$_34_$_1_tile_param_0;
	mul.lo.s64 	%rd136, %rd4, 24;
	shl.b64 	%rd137, %rd6, 2;
	or.b64  	%rd138, %rd6, 1;
	mov.u64 	%rd139, sort_$_34_$_1_tile_param_2;
	@%p1 bra 	$L__BB311_1;
	add.s64 	%rd44, %rd3, %rd136;
	add.s64 	%rd12, %rd44, %rd137;
	ld.global.u32 	%r35, [%rd12];
	add.s64 	%rd13, %rd135, %rd134;
	st.shared.u32 	[%rd13], %r35;
	setp.gt.u64 	%p2, %rd138, 5;
	mov.u64 	%rd133, sort_$_34_$_1_tile_param_1;
	@%p2 bra 	$L__BB311_11;
	ld.global.u32 	%r36, [%rd12+4];
	st.shared.u32 	[%rd13+4], %r36;
	add.s64 	%rd53, %rd2, %rd136;
	add.s64 	%rd55, %rd53, %rd137;
	ld.global.v2.u32 	{%r81, %r37}, [%rd55];
	add.s64 	%rd58, %rd133, %rd134;
	st.shared.u32 	[%rd58+4], %r37;
	bra.uni 	$L__BB311_12;
$L__BB311_11:
	add.s64 	%rd49, %rd2, %rd136;
	add.s64 	%rd51, %rd49, %rd137;
	ld.global.u32 	%r81, [%rd51];
$L__BB311_12:
	add.s64 	%rd61, %rd133, %rd134;
	st.shared.u32 	[%rd61], %r81;
	add.s64 	%rd63, %rd1, %rd136;
	add.s64 	%rd15, %rd63, %rd137;
	ld.global.u32 	%r38, [%rd15];
	add.s64 	%rd16, %rd139, %rd134;
	st.shared.u32 	[%rd16], %r38;
	@%p2 bra 	$L__BB311_1;
	ld.global.u32 	%r39, [%rd15+4];
	st.shared.u32 	[%rd16+4], %r39;
$L__BB311_1:
	cvt.u64.u32 	%rd5, %r32;
	bar.sync 	0;
	or.b64  	%rd8, %rd7, 1;
	setp.lt.u64 	%p4, %rd8, 6;
	@%p4 bra 	$L__BB311_14;
	bra.uni 	$L__BB311_2;
$L__BB311_14:
	add.s64 	%rd17, %rd135, %rd134;
	add.s64 	%rd18, %rd139, %rd134;
	ld.shared.u32 	%r4, [%rd17+4];
	ld.shared.u32 	%r5, [%rd17];
	ld.shared.u32 	%r6, [%rd18+4];
	ld.shared.u32 	%r7, [%rd18];
	setp.ge.s32 	%p5, %r4, %r5;
	setp.eq.s32 	%p6, %r5, %r4;
	setp.ge.s32 	%p7, %r6, %r7;
	selp.u32 	%r40, -1, 0, %p5;
	selp.u32 	%r41, -1, 0, %p7;
	selp.b32 	%r42, %r41, %r40, %p6;
	and.b32  	%r43, %r42, 1;
	setp.eq.b32 	%p8, %r43, 1;
	@%p8 bra 	$L__BB311_2;
	mov.u64 	%rd70, sort_$_34_$_1_tile_param_1;
	add.s64 	%rd71, %rd70, %rd134;
	st.shared.v2.u32 	[%rd17], {%r4, %r5};
	ld.shared.u32 	%r44, [%rd71+4];
	ld.shared.u32 	%r45, [%rd71];
	st.shared.v2.u32 	[%rd71], {%r44, %r45};
	st.shared.v2.u32 	[%rd18], {%r6, %r7};
$L__BB311_2:
	bar.sync 	0;
	and.b64  	%rd72, %rd5, 1;
	and.b64  	%rd73, %rd7, 4;
	or.b64  	%rd9, %rd73, %rd72;
	xor.b64  	%rd10, %rd9, 3;
	setp.lt.u64 	%p9, %rd9, %rd10;
	setp.lt.u64 	%p10, %rd10, 6;
	and.pred  	%p11, %p9, %p10;
	shl.b64 	%rd140, %rd9, 2;
	@%p11 bra 	$L__BB311_16;
	bra.uni 	$L__BB311_3;
$L__BB311_16:
	shl.b64 	%rd74, %rd10, 2;
	add.s64 	%rd19, %rd135, %rd74;
	add.s64 	%rd20, %rd135, %rd140;
	add.s64 	%rd21, %rd139, %rd74;
	add.s64 	%rd22, %rd139, %rd140;
	ld.shared.u32 	%r8, [%rd19];
	ld.shared.u32 	%r9, [%rd20];
	ld.shared.u32 	%r10, [%rd21];
	ld.shared.u32 	%r11, [%rd22];
	setp.ge.s32 	%p12, %r8, %r9;
	setp.eq.s32 	%p13, %r9, %r8;
	setp.ge.s32 	%p14, %r10, %r11;
	selp.u32 	%r46, -1, 0, %p12;
	selp.u32 	%r47, -1, 0, %p14;
	selp.b32 	%r48, %r47, %r46, %p13;
	and.b32  	%r49, %r48, 1;
	setp.eq.b32 	%p15, %r49, 1;
	@%p15 bra 	$L__BB311_3;
	mov.u64 	%rd79, sort_$_34_$_1_tile_param_1;
	add.s64 	%rd80, %rd79, %rd140;
	add.s64 	%rd82, %rd79, %rd74;
	st.shared.u32 	[%rd20], %r8;
	st.shared.u32 	[%rd19], %r9;
	ld.shared.u32 	%r50, [%rd82];
	ld.shared.u32 	%r51, [%rd80];
	st.shared.u32 	[%rd80], %r50;
	st.shared.u32 	[%rd82], %r51;
	st.shared.u32 	[%rd22], %r10;
	st.shared.u32 	[%rd21], %r11;
$L__BB311_3:
	bar.sync 	0;
	@%p4 bra 	$L__BB311_18;
	bra.uni 	$L__BB311_4;
$L__BB311_18:
	add.s64 	%rd23, %rd135, %rd134;
	add.s64 	%rd24, %rd139, %rd134;
	ld.shared.u32 	%r12, [%rd23+4];
	ld.shared.u32 	%r13, [%rd23];
	ld.shared.u32 	%r14, [%rd24+4];
	ld.shared.u32 	%r15, [%rd24];
	setp.ge.s32 	%p17, %r12, %r13;
	setp.eq.s32 	%p18, %r13, %r12;
	setp.ge.s32 	%p19, %r14, %r15;
	selp.u32 	%r52, -1, 0, %p17;
	selp.u32 	%r53, -1, 0, %p19;
	selp.b32 	%r54, %r53, %r52, %p18;
	and.b32  	%r55, %r54, 1;
	setp.eq.b32 	%p20, %r55, 1;
	@%p20 bra 	$L__BB311_4;
	mov.u64 	%rd87, sort_$_34_$_1_tile_param_1;
	add.s64 	%rd88, %rd87, %rd134;
	st.shared.v2.u32 	[%rd23], {%r12, %r13};
	ld.shared.u32 	%r56, [%rd88+4];
	ld.shared.u32 	%r57, [%rd88];
	st.shared.v2.u32 	[%rd88], {%r56, %r57};
	st.shared.v2.u32 	[%rd24], {%r14, %r15};
$L__BB311_4:
	bar.sync 	0;
	xor.b64  	%rd11, %rd5, 7;
	setp.lt.u64 	%p21, %rd11, 6;
	@%p21 bra 	$L__BB311_20;
	bra.uni 	$L__BB311_5;
$L__BB311_20:
	shl.b64 	%rd89, %rd11, 2;
	add.s64 	%rd25, %rd135, %rd89;
	shl.b64 	%rd91, %rd5, 2;
	add.s64 	%rd26, %rd135, %rd91;
	add.s64 	%rd27, %rd139, %rd89;
	add.s64 	%rd28, %rd139, %rd91;
	ld.shared.u32 	%r16, [%rd25];
	ld.shared.u32 	%r17, [%rd26];
	ld.shared.u32 	%r18, [%rd27];
	ld.shared.u32 	%r19, [%rd28];
	setp.ge.s32 	%p22, %r16, %r17;
	setp.eq.s32 	%p23, %r17, %r16;
	setp.ge.s32 	%p24, %r18, %r19;
	selp.u32 	%r58, -1, 0, %p22;
	selp.u32 	%r59, -1, 0, %p24;
	selp.b32 	%r60, %r59, %r58, %p23;
	and.b32  	%r61, %r60, 1;
	setp.eq.b32 	%p25, %r61, 1;
	@%p25 bra 	$L__BB311_5;
	mov.u64 	%rd94, sort_$_34_$_1_tile_param_1;
	add.s64 	%rd95, %rd94, %rd91;
	add.s64 	%rd97, %rd94, %rd89;
	st.shared.u32 	[%rd26], %r16;
	st.shared.u32 	[%rd25], %r17;
	ld.shared.u32 	%r62, [%rd97];
	ld.shared.u32 	%r63, [%rd95];
	st.shared.u32 	[%rd95], %r62;
	st.shared.u32 	[%rd97], %r63;
	st.shared.u32 	[%rd28], %r18;
	st.shared.u32 	[%rd27], %r19;
$L__BB311_5:
	bar.sync 	0;
	or.b64  	%rd98, %rd9, 2;
	setp.lt.u64 	%p26, %rd98, 6;
	@%p26 bra 	$L__BB311_22;
	bra.uni 	$L__BB311_6;
$L__BB311_22:
	add.s64 	%rd29, %rd135, %rd140;
	add.s64 	%rd30, %rd139, %rd140;
	ld.shared.u32 	%r20, [%rd29+8];
	ld.shared.u32 	%r21, [%rd29];
	ld.shared.u32 	%r22, [%rd30+8];
	ld.shared.u32 	%r23, [%rd30];
	setp.ge.s32 	%p27, %r20, %r21;
	setp.eq.s32 	%p28, %r21, %r20;
	setp.ge.s32 	%p29, %r22, %r23;
	selp.u32 	%r64, -1, 0, %p27;
	selp.u32 	%r65, -1, 0, %p29;
	selp.b32 	%r66, %r65, %r64, %p28;
	and.b32  	%r67, %r66, 1;
	setp.eq.b32 	%p30, %r67, 1;
	@%p30 bra 	$L__BB311_6;
	mov.u64 	%rd103, sort_$_34_$_1_tile_param_1;
	add.s64 	%rd104, %rd103, %rd140;
	st.shared.u32 	[%rd29], %r20;
	st.shared.u32 	[%rd29+8], %r21;
	ld.shared.u32 	%r68, [%rd104+8];
	ld.shared.u32 	%r69, [%rd104];
	st.shared.u32 	[%rd104], %r68;
	st.shared.u32 	[%rd104+8], %r69;
	st.shared.u32 	[%rd30], %r22;
	st.shared.u32 	[%rd30+8], %r23;
$L__BB311_6:
	bar.sync 	0;
	@%p4 bra 	$L__BB311_24;
	bra.uni 	$L__BB311_7;
$L__BB311_24:
	add.s64 	%rd31, %rd135, %rd134;
	add.s64 	%rd32, %rd139, %rd134;
	ld.shared.u32 	%r24, [%rd31+4];
	ld.shared.u32 	%r25, [%rd31];
	ld.shared.u32 	%r26, [%rd32+4];
	ld.shared.u32 	%r27, [%rd32];
	setp.ge.s32 	%p32, %r24, %r25;
	setp.eq.s32 	%p33, %r25, %r24;
	setp.ge.s32 	%p34, %r26, %r27;
	selp.u32 	%r70, -1, 0, %p32;
	selp.u32 	%r71, -1, 0, %p34;
	selp.b32 	%r72, %r71, %r70, %p33;
	and.b32  	%r73, %r72, 1;
	setp.eq.b32 	%p35, %r73, 1;
	@%p35 bra 	$L__BB311_7;
	mov.u64 	%rd109, sort_$_34_$_1_tile_param_1;
	add.s64 	%rd110, %rd109, %rd134;
	st.shared.v2.u32 	[%rd31], {%r24, %r25};
	ld.shared.u32 	%r74, [%rd110+4];
	ld.shared.u32 	%r75, [%rd110];
	st.shared.v2.u32 	[%rd110], {%r74, %r75};
	st.shared.v2.u32 	[%rd32], {%r26, %r27};
$L__BB311_7:
	bar.sync 	0;
	@%p1 bra 	$L__BB311_8;
	add.s64 	%rd33, %rd135, %rd134;
	ld.shared.u32 	%r76, [%rd33];
	add.s64 	%rd114, %rd3, %rd136;
	add.s64 	%rd34, %rd114, %rd137;
	st.global.u32 	[%rd34], %r76;
	setp.gt.u64 	%p37, %rd138, 5;
	@%p37 bra 	$L__BB311_28;
	ld.shared.u32 	%r77, [%rd33+4];
	st.global.u32 	[%rd34+4], %r77;
	mov.u64 	%rd120, sort_$_34_$_1_tile_param_1;
	add.s64 	%rd121, %rd120, %rd134;
	ld.shared.v2.u32 	{%r82, %r78}, [%rd121];
	add.s64 	%rd123, %rd2, %rd136;
	add.s64 	%rd125, %rd123, %rd137;
	st.global.u32 	[%rd125+4], %r78;
	bra.uni 	$L__BB311_29;
$L__BB311_28:
	mov.u64 	%rd117, sort_$_34_$_1_tile_param_1;
	add.s64 	%rd118, %rd117, %rd134;
	ld.shared.u32 	%r82, [%rd118];
$L__BB311_29:
	add.s64 	%rd127, %rd2, %rd136;
	add.s64 	%rd129, %rd127, %rd137;
	st.global.u32 	[%rd129], %r82;
	add.s64 	%rd36, %rd139, %rd134;
	ld.shared.u32 	%r79, [%rd36];
	add.s64 	%rd132, %rd1, %rd136;
	add.s64 	%rd37, %rd132, %rd137;
	st.global.u32 	[%rd37], %r79;
	@%p37 bra 	$L__BB311_8;
	ld.shared.u32 	%r80, [%rd36+4];
	st.global.u32 	[%rd37+4], %r80;
$L__BB311_8:
	ret;

}
	// .globl	sort_33_1
.visible .entry sort_33_1(
	.param .u64 sort_33_1_param_0,
	.param .u64 sort_33_1_param_1,
	.param .u64 sort_33_1_param_2
)
.reqntid 4, 1, 1
{
	.reg .pred 	%p<39>;
	.reg .b32 	%r<83>;
	.reg .b64 	%rd<141>;
	// demoted variable
	.shared .align 4 .b8 sort_$_33_$_1_tile_param_0[256];
	// demoted variable
	.shared .align 4 .b8 sort_$_33_$_1_tile_param_1[256];
	// demoted variable
	.shared .align 4 .b8 sort_$_33_$_1_tile_param_2[256];
	ld.param.u64 	%rd38, [sort_33_1_param_0];
	ld.param.u64 	%rd39, [sort_33_1_param_2];
	cvta.to.global.u64 	%rd1, %rd39;
	ld.param.u64 	%rd40, [sort_33_1_param_1];
	cvta.to.global.u64 	%rd2, %rd40;
	cvta.to.global.u64 	%rd3, %rd38;
	mov.u32 	%r31, %ctaid.x;
	mov.u32 	%r32, %tid.x;
	shl.b32 	%r33, %r31, 2;
	or.b32  	%r34, %r33, %r32;
	cvt.u64.u32 	%rd41, %r34;
	shr.u64 	%rd4, %rd41, 2;
	mul.wide.u32 	%rd42, %r34, 2;
	and.b64  	%rd6, %rd42, 6;
	setp.eq.s64 	%p1, %rd6, 6;
	mul.wide.u32 	%rd7, %r32, 2;
	shl.b64 	%rd134, %rd7, 2;
	mov.u64 	%rd135, sort_$_33_$_1_tile_param_0;
	mul.lo.s64 	%rd136, %rd4, 24;
	shl.b64 	%rd137, %rd6, 2;
	or.b64  	%rd138, %rd6, 1;
	mov.u64 	%rd139, sort_$_33_$_1_tile_param_2;
	@%p1 bra 	$L__BB312_1;
	add.s64 	%rd44, %rd3, %rd136;
	add.s64 	%rd12, %rd44, %rd137;
	ld.global.u32 	%r35, [%rd12];
	add.s64 	%rd13, %rd135, %rd134;
	st.shared.u32 	[%rd13], %r35;
	setp.gt.u64 	%p2, %rd138, 5;
	mov.u64 	%rd133, sort_$_33_$_1_tile_param_1;
	@%p2 bra 	$L__BB312_11;
	ld.global.u32 	%r36, [%rd12+4];
	st.shared.u32 	[%rd13+4], %r36;
	add.s64 	%rd53, %rd2, %rd136;
	add.s64 	%rd55, %rd53, %rd137;
	ld.global.v2.u32 	{%r81, %r37}, [%rd55];
	add.s64 	%rd58, %rd133, %rd134;
	st.shared.u32 	[%rd58+4], %r37;
	bra.uni 	$L__BB312_12;
$L__BB312_11:
	add.s64 	%rd49, %rd2, %rd136;
	add.s64 	%rd51, %rd49, %rd137;
	ld.global.u32 	%r81, [%rd51];
$L__BB312_12:
	add.s64 	%rd61, %rd133, %rd134;
	st.shared.u32 	[%rd61], %r81;
	add.s64 	%rd63, %rd1, %rd136;
	add.s64 	%rd15, %rd63, %rd137;
	ld.global.u32 	%r38, [%rd15];
	add.s64 	%rd16, %rd139, %rd134;
	st.shared.u32 	[%rd16], %r38;
	@%p2 bra 	$L__BB312_1;
	ld.global.u32 	%r39, [%rd15+4];
	st.shared.u32 	[%rd16+4], %r39;
$L__BB312_1:
	cvt.u64.u32 	%rd5, %r32;
	bar.sync 	0;
	or.b64  	%rd8, %rd7, 1;
	setp.lt.u64 	%p4, %rd8, 6;
	@%p4 bra 	$L__BB312_14;
	bra.uni 	$L__BB312_2;
$L__BB312_14:
	add.s64 	%rd17, %rd135, %rd134;
	add.s64 	%rd18, %rd139, %rd134;
	ld.shared.u32 	%r4, [%rd17+4];
	ld.shared.u32 	%r5, [%rd17];
	ld.shared.u32 	%r6, [%rd18+4];
	ld.shared.u32 	%r7, [%rd18];
	setp.ge.s32 	%p5, %r4, %r5;
	setp.eq.s32 	%p6, %r5, %r4;
	setp.ge.s32 	%p7, %r6, %r7;
	selp.u32 	%r40, -1, 0, %p5;
	selp.u32 	%r41, -1, 0, %p7;
	selp.b32 	%r42, %r41, %r40, %p6;
	and.b32  	%r43, %r42, 1;
	setp.eq.b32 	%p8, %r43, 1;
	@%p8 bra 	$L__BB312_2;
	mov.u64 	%rd70, sort_$_33_$_1_tile_param_1;
	add.s64 	%rd71, %rd70, %rd134;
	st.shared.v2.u32 	[%rd17], {%r4, %r5};
	ld.shared.u32 	%r44, [%rd71+4];
	ld.shared.u32 	%r45, [%rd71];
	st.shared.v2.u32 	[%rd71], {%r44, %r45};
	st.shared.v2.u32 	[%rd18], {%r6, %r7};
$L__BB312_2:
	bar.sync 	0;
	and.b64  	%rd72, %rd5, 1;
	and.b64  	%rd73, %rd7, 4;
	or.b64  	%rd9, %rd73, %rd72;
	xor.b64  	%rd10, %rd9, 3;
	setp.lt.u64 	%p9, %rd9, %rd10;
	setp.lt.u64 	%p10, %rd10, 6;
	and.pred  	%p11, %p9, %p10;
	shl.b64 	%rd140, %rd9, 2;
	@%p11 bra 	$L__BB312_16;
	bra.uni 	$L__BB312_3;
$L__BB312_16:
	shl.b64 	%rd74, %rd10, 2;
	add.s64 	%rd19, %rd135, %rd74;
	add.s64 	%rd20, %rd135, %rd140;
	add.s64 	%rd21, %rd139, %rd74;
	add.s64 	%rd22, %rd139, %rd140;
	ld.shared.u32 	%r8, [%rd19];
	ld.shared.u32 	%r9, [%rd20];
	ld.shared.u32 	%r10, [%rd21];
	ld.shared.u32 	%r11, [%rd22];
	setp.ge.s32 	%p12, %r8, %r9;
	setp.eq.s32 	%p13, %r9, %r8;
	setp.ge.s32 	%p14, %r10, %r11;
	selp.u32 	%r46, -1, 0, %p12;
	selp.u32 	%r47, -1, 0, %p14;
	selp.b32 	%r48, %r47, %r46, %p13;
	and.b32  	%r49, %r48, 1;
	setp.eq.b32 	%p15, %r49, 1;
	@%p15 bra 	$L__BB312_3;
	mov.u64 	%rd79, sort_$_33_$_1_tile_param_1;
	add.s64 	%rd80, %rd79, %rd140;
	add.s64 	%rd82, %rd79, %rd74;
	st.shared.u32 	[%rd20], %r8;
	st.shared.u32 	[%rd19], %r9;
	ld.shared.u32 	%r50, [%rd82];
	ld.shared.u32 	%r51, [%rd80];
	st.shared.u32 	[%rd80], %r50;
	st.shared.u32 	[%rd82], %r51;
	st.shared.u32 	[%rd22], %r10;
	st.shared.u32 	[%rd21], %r11;
$L__BB312_3:
	bar.sync 	0;
	@%p4 bra 	$L__BB312_18;
	bra.uni 	$L__BB312_4;
$L__BB312_18:
	add.s64 	%rd23, %rd135, %rd134;
	add.s64 	%rd24, %rd139, %rd134;
	ld.shared.u32 	%r12, [%rd23+4];
	ld.shared.u32 	%r13, [%rd23];
	ld.shared.u32 	%r14, [%rd24+4];
	ld.shared.u32 	%r15, [%rd24];
	setp.ge.s32 	%p17, %r12, %r13;
	setp.eq.s32 	%p18, %r13, %r12;
	setp.ge.s32 	%p19, %r14, %r15;
	selp.u32 	%r52, -1, 0, %p17;
	selp.u32 	%r53, -1, 0, %p19;
	selp.b32 	%r54, %r53, %r52, %p18;
	and.b32  	%r55, %r54, 1;
	setp.eq.b32 	%p20, %r55, 1;
	@%p20 bra 	$L__BB312_4;
	mov.u64 	%rd87, sort_$_33_$_1_tile_param_1;
	add.s64 	%rd88, %rd87, %rd134;
	st.shared.v2.u32 	[%rd23], {%r12, %r13};
	ld.shared.u32 	%r56, [%rd88+4];
	ld.shared.u32 	%r57, [%rd88];
	st.shared.v2.u32 	[%rd88], {%r56, %r57};
	st.shared.v2.u32 	[%rd24], {%r14, %r15};
$L__BB312_4:
	bar.sync 	0;
	xor.b64  	%rd11, %rd5, 7;
	setp.lt.u64 	%p21, %rd11, 6;
	@%p21 bra 	$L__BB312_20;
	bra.uni 	$L__BB312_5;
$L__BB312_20:
	shl.b64 	%rd89, %rd11, 2;
	add.s64 	%rd25, %rd135, %rd89;
	shl.b64 	%rd91, %rd5, 2;
	add.s64 	%rd26, %rd135, %rd91;
	add.s64 	%rd27, %rd139, %rd89;
	add.s64 	%rd28, %rd139, %rd91;
	ld.shared.u32 	%r16, [%rd25];
	ld.shared.u32 	%r17, [%rd26];
	ld.shared.u32 	%r18, [%rd27];
	ld.shared.u32 	%r19, [%rd28];
	setp.ge.s32 	%p22, %r16, %r17;
	setp.eq.s32 	%p23, %r17, %r16;
	setp.ge.s32 	%p24, %r18, %r19;
	selp.u32 	%r58, -1, 0, %p22;
	selp.u32 	%r59, -1, 0, %p24;
	selp.b32 	%r60, %r59, %r58, %p23;
	and.b32  	%r61, %r60, 1;
	setp.eq.b32 	%p25, %r61, 1;
	@%p25 bra 	$L__BB312_5;
	mov.u64 	%rd94, sort_$_33_$_1_tile_param_1;
	add.s64 	%rd95, %rd94, %rd91;
	add.s64 	%rd97, %rd94, %rd89;
	st.shared.u32 	[%rd26], %r16;
	st.shared.u32 	[%rd25], %r17;
	ld.shared.u32 	%r62, [%rd97];
	ld.shared.u32 	%r63, [%rd95];
	st.shared.u32 	[%rd95], %r62;
	st.shared.u32 	[%rd97], %r63;
	st.shared.u32 	[%rd28], %r18;
	st.shared.u32 	[%rd27], %r19;
$L__BB312_5:
	bar.sync 	0;
	or.b64  	%rd98, %rd9, 2;
	setp.lt.u64 	%p26, %rd98, 6;
	@%p26 bra 	$L__BB312_22;
	bra.uni 	$L__BB312_6;
$L__BB312_22:
	add.s64 	%rd29, %rd135, %rd140;
	add.s64 	%rd30, %rd139, %rd140;
	ld.shared.u32 	%r20, [%rd29+8];
	ld.shared.u32 	%r21, [%rd29];
	ld.shared.u32 	%r22, [%rd30+8];
	ld.shared.u32 	%r23, [%rd30];
	setp.ge.s32 	%p27, %r20, %r21;
	setp.eq.s32 	%p28, %r21, %r20;
	setp.ge.s32 	%p29, %r22, %r23;
	selp.u32 	%r64, -1, 0, %p27;
	selp.u32 	%r65, -1, 0, %p29;
	selp.b32 	%r66, %r65, %r64, %p28;
	and.b32  	%r67, %r66, 1;
	setp.eq.b32 	%p30, %r67, 1;
	@%p30 bra 	$L__BB312_6;
	mov.u64 	%rd103, sort_$_33_$_1_tile_param_1;
	add.s64 	%rd104, %rd103, %rd140;
	st.shared.u32 	[%rd29], %r20;
	st.shared.u32 	[%rd29+8], %r21;
	ld.shared.u32 	%r68, [%rd104+8];
	ld.shared.u32 	%r69, [%rd104];
	st.shared.u32 	[%rd104], %r68;
	st.shared.u32 	[%rd104+8], %r69;
	st.shared.u32 	[%rd30], %r22;
	st.shared.u32 	[%rd30+8], %r23;
$L__BB312_6:
	bar.sync 	0;
	@%p4 bra 	$L__BB312_24;
	bra.uni 	$L__BB312_7;
$L__BB312_24:
	add.s64 	%rd31, %rd135, %rd134;
	add.s64 	%rd32, %rd139, %rd134;
	ld.shared.u32 	%r24, [%rd31+4];
	ld.shared.u32 	%r25, [%rd31];
	ld.shared.u32 	%r26, [%rd32+4];
	ld.shared.u32 	%r27, [%rd32];
	setp.ge.s32 	%p32, %r24, %r25;
	setp.eq.s32 	%p33, %r25, %r24;
	setp.ge.s32 	%p34, %r26, %r27;
	selp.u32 	%r70, -1, 0, %p32;
	selp.u32 	%r71, -1, 0, %p34;
	selp.b32 	%r72, %r71, %r70, %p33;
	and.b32  	%r73, %r72, 1;
	setp.eq.b32 	%p35, %r73, 1;
	@%p35 bra 	$L__BB312_7;
	mov.u64 	%rd109, sort_$_33_$_1_tile_param_1;
	add.s64 	%rd110, %rd109, %rd134;
	st.shared.v2.u32 	[%rd31], {%r24, %r25};
	ld.shared.u32 	%r74, [%rd110+4];
	ld.shared.u32 	%r75, [%rd110];
	st.shared.v2.u32 	[%rd110], {%r74, %r75};
	st.shared.v2.u32 	[%rd32], {%r26, %r27};
$L__BB312_7:
	bar.sync 	0;
	@%p1 bra 	$L__BB312_8;
	add.s64 	%rd33, %rd135, %rd134;
	ld.shared.u32 	%r76, [%rd33];
	add.s64 	%rd114, %rd3, %rd136;
	add.s64 	%rd34, %rd114, %rd137;
	st.global.u32 	[%rd34], %r76;
	setp.gt.u64 	%p37, %rd138, 5;
	@%p37 bra 	$L__BB312_28;
	ld.shared.u32 	%r77, [%rd33+4];
	st.global.u32 	[%rd34+4], %r77;
	mov.u64 	%rd120, sort_$_33_$_1_tile_param_1;
	add.s64 	%rd121, %rd120, %rd134;
	ld.shared.v2.u32 	{%r82, %r78}, [%rd121];
	add.s64 	%rd123, %rd2, %rd136;
	add.s64 	%rd125, %rd123, %rd137;
	st.global.u32 	[%rd125+4], %r78;
	bra.uni 	$L__BB312_29;
$L__BB312_28:
	mov.u64 	%rd117, sort_$_33_$_1_tile_param_1;
	add.s64 	%rd118, %rd117, %rd134;
	ld.shared.u32 	%r82, [%rd118];
$L__BB312_29:
	add.s64 	%rd127, %rd2, %rd136;
	add.s64 	%rd129, %rd127, %rd137;
	st.global.u32 	[%rd129], %r82;
	add.s64 	%rd36, %rd139, %rd134;
	ld.shared.u32 	%r79, [%rd36];
	add.s64 	%rd132, %rd1, %rd136;
	add.s64 	%rd37, %rd132, %rd137;
	st.global.u32 	[%rd37], %r79;
	@%p37 bra 	$L__BB312_8;
	ld.shared.u32 	%r80, [%rd36+4];
	st.global.u32 	[%rd37+4], %r80;
$L__BB312_8:
	ret;

}
	// .globl	sort_32_1
.visible .entry sort_32_1(
	.param .u64 sort_32_1_param_0,
	.param .u64 sort_32_1_param_1,
	.param .u64 sort_32_1_param_2
)
.reqntid 4, 1, 1
{
	.reg .pred 	%p<39>;
	.reg .b32 	%r<83>;
	.reg .b64 	%rd<141>;
	// demoted variable
	.shared .align 4 .b8 sort_$_32_$_1_tile_param_0[256];
	// demoted variable
	.shared .align 4 .b8 sort_$_32_$_1_tile_param_1[256];
	// demoted variable
	.shared .align 4 .b8 sort_$_32_$_1_tile_param_2[256];
	ld.param.u64 	%rd38, [sort_32_1_param_0];
	ld.param.u64 	%rd39, [sort_32_1_param_2];
	cvta.to.global.u64 	%rd1, %rd39;
	ld.param.u64 	%rd40, [sort_32_1_param_1];
	cvta.to.global.u64 	%rd2, %rd40;
	cvta.to.global.u64 	%rd3, %rd38;
	mov.u32 	%r31, %ctaid.x;
	mov.u32 	%r32, %tid.x;
	shl.b32 	%r33, %r31, 2;
	or.b32  	%r34, %r33, %r32;
	cvt.u64.u32 	%rd41, %r34;
	shr.u64 	%rd4, %rd41, 2;
	mul.wide.u32 	%rd42, %r34, 2;
	and.b64  	%rd6, %rd42, 6;
	setp.eq.s64 	%p1, %rd6, 6;
	mul.wide.u32 	%rd7, %r32, 2;
	shl.b64 	%rd134, %rd7, 2;
	mov.u64 	%rd135, sort_$_32_$_1_tile_param_0;
	mul.lo.s64 	%rd136, %rd4, 24;
	shl.b64 	%rd137, %rd6, 2;
	or.b64  	%rd138, %rd6, 1;
	mov.u64 	%rd139, sort_$_32_$_1_tile_param_2;
	@%p1 bra 	$L__BB313_1;
	add.s64 	%rd44, %rd3, %rd136;
	add.s64 	%rd12, %rd44, %rd137;
	ld.global.u32 	%r35, [%rd12];
	add.s64 	%rd13, %rd135, %rd134;
	st.shared.u32 	[%rd13], %r35;
	setp.gt.u64 	%p2, %rd138, 5;
	mov.u64 	%rd133, sort_$_32_$_1_tile_param_1;
	@%p2 bra 	$L__BB313_11;
	ld.global.u32 	%r36, [%rd12+4];
	st.shared.u32 	[%rd13+4], %r36;
	add.s64 	%rd53, %rd2, %rd136;
	add.s64 	%rd55, %rd53, %rd137;
	ld.global.v2.u32 	{%r81, %r37}, [%rd55];
	add.s64 	%rd58, %rd133, %rd134;
	st.shared.u32 	[%rd58+4], %r37;
	bra.uni 	$L__BB313_12;
$L__BB313_11:
	add.s64 	%rd49, %rd2, %rd136;
	add.s64 	%rd51, %rd49, %rd137;
	ld.global.u32 	%r81, [%rd51];
$L__BB313_12:
	add.s64 	%rd61, %rd133, %rd134;
	st.shared.u32 	[%rd61], %r81;
	add.s64 	%rd63, %rd1, %rd136;
	add.s64 	%rd15, %rd63, %rd137;
	ld.global.u32 	%r38, [%rd15];
	add.s64 	%rd16, %rd139, %rd134;
	st.shared.u32 	[%rd16], %r38;
	@%p2 bra 	$L__BB313_1;
	ld.global.u32 	%r39, [%rd15+4];
	st.shared.u32 	[%rd16+4], %r39;
$L__BB313_1:
	cvt.u64.u32 	%rd5, %r32;
	bar.sync 	0;
	or.b64  	%rd8, %rd7, 1;
	setp.lt.u64 	%p4, %rd8, 6;
	@%p4 bra 	$L__BB313_14;
	bra.uni 	$L__BB313_2;
$L__BB313_14:
	add.s64 	%rd17, %rd135, %rd134;
	add.s64 	%rd18, %rd139, %rd134;
	ld.shared.u32 	%r4, [%rd17+4];
	ld.shared.u32 	%r5, [%rd17];
	ld.shared.u32 	%r6, [%rd18+4];
	ld.shared.u32 	%r7, [%rd18];
	setp.ge.s32 	%p5, %r4, %r5;
	setp.eq.s32 	%p6, %r5, %r4;
	setp.ge.s32 	%p7, %r6, %r7;
	selp.u32 	%r40, -1, 0, %p5;
	selp.u32 	%r41, -1, 0, %p7;
	selp.b32 	%r42, %r41, %r40, %p6;
	and.b32  	%r43, %r42, 1;
	setp.eq.b32 	%p8, %r43, 1;
	@%p8 bra 	$L__BB313_2;
	mov.u64 	%rd70, sort_$_32_$_1_tile_param_1;
	add.s64 	%rd71, %rd70, %rd134;
	st.shared.v2.u32 	[%rd17], {%r4, %r5};
	ld.shared.u32 	%r44, [%rd71+4];
	ld.shared.u32 	%r45, [%rd71];
	st.shared.v2.u32 	[%rd71], {%r44, %r45};
	st.shared.v2.u32 	[%rd18], {%r6, %r7};
$L__BB313_2:
	bar.sync 	0;
	and.b64  	%rd72, %rd5, 1;
	and.b64  	%rd73, %rd7, 4;
	or.b64  	%rd9, %rd73, %rd72;
	xor.b64  	%rd10, %rd9, 3;
	setp.lt.u64 	%p9, %rd9, %rd10;
	setp.lt.u64 	%p10, %rd10, 6;
	and.pred  	%p11, %p9, %p10;
	shl.b64 	%rd140, %rd9, 2;
	@%p11 bra 	$L__BB313_16;
	bra.uni 	$L__BB313_3;
$L__BB313_16:
	shl.b64 	%rd74, %rd10, 2;
	add.s64 	%rd19, %rd135, %rd74;
	add.s64 	%rd20, %rd135, %rd140;
	add.s64 	%rd21, %rd139, %rd74;
	add.s64 	%rd22, %rd139, %rd140;
	ld.shared.u32 	%r8, [%rd19];
	ld.shared.u32 	%r9, [%rd20];
	ld.shared.u32 	%r10, [%rd21];
	ld.shared.u32 	%r11, [%rd22];
	setp.ge.s32 	%p12, %r8, %r9;
	setp.eq.s32 	%p13, %r9, %r8;
	setp.ge.s32 	%p14, %r10, %r11;
	selp.u32 	%r46, -1, 0, %p12;
	selp.u32 	%r47, -1, 0, %p14;
	selp.b32 	%r48, %r47, %r46, %p13;
	and.b32  	%r49, %r48, 1;
	setp.eq.b32 	%p15, %r49, 1;
	@%p15 bra 	$L__BB313_3;
	mov.u64 	%rd79, sort_$_32_$_1_tile_param_1;
	add.s64 	%rd80, %rd79, %rd140;
	add.s64 	%rd82, %rd79, %rd74;
	st.shared.u32 	[%rd20], %r8;
	st.shared.u32 	[%rd19], %r9;
	ld.shared.u32 	%r50, [%rd82];
	ld.shared.u32 	%r51, [%rd80];
	st.shared.u32 	[%rd80], %r50;
	st.shared.u32 	[%rd82], %r51;
	st.shared.u32 	[%rd22], %r10;
	st.shared.u32 	[%rd21], %r11;
$L__BB313_3:
	bar.sync 	0;
	@%p4 bra 	$L__BB313_18;
	bra.uni 	$L__BB313_4;
$L__BB313_18:
	add.s64 	%rd23, %rd135, %rd134;
	add.s64 	%rd24, %rd139, %rd134;
	ld.shared.u32 	%r12, [%rd23+4];
	ld.shared.u32 	%r13, [%rd23];
	ld.shared.u32 	%r14, [%rd24+4];
	ld.shared.u32 	%r15, [%rd24];
	setp.ge.s32 	%p17, %r12, %r13;
	setp.eq.s32 	%p18, %r13, %r12;
	setp.ge.s32 	%p19, %r14, %r15;
	selp.u32 	%r52, -1, 0, %p17;
	selp.u32 	%r53, -1, 0, %p19;
	selp.b32 	%r54, %r53, %r52, %p18;
	and.b32  	%r55, %r54, 1;
	setp.eq.b32 	%p20, %r55, 1;
	@%p20 bra 	$L__BB313_4;
	mov.u64 	%rd87, sort_$_32_$_1_tile_param_1;
	add.s64 	%rd88, %rd87, %rd134;
	st.shared.v2.u32 	[%rd23], {%r12, %r13};
	ld.shared.u32 	%r56, [%rd88+4];
	ld.shared.u32 	%r57, [%rd88];
	st.shared.v2.u32 	[%rd88], {%r56, %r57};
	st.shared.v2.u32 	[%rd24], {%r14, %r15};
$L__BB313_4:
	bar.sync 	0;
	xor.b64  	%rd11, %rd5, 7;
	setp.lt.u64 	%p21, %rd11, 6;
	@%p21 bra 	$L__BB313_20;
	bra.uni 	$L__BB313_5;
$L__BB313_20:
	shl.b64 	%rd89, %rd11, 2;
	add.s64 	%rd25, %rd135, %rd89;
	shl.b64 	%rd91, %rd5, 2;
	add.s64 	%rd26, %rd135, %rd91;
	add.s64 	%rd27, %rd139, %rd89;
	add.s64 	%rd28, %rd139, %rd91;
	ld.shared.u32 	%r16, [%rd25];
	ld.shared.u32 	%r17, [%rd26];
	ld.shared.u32 	%r18, [%rd27];
	ld.shared.u32 	%r19, [%rd28];
	setp.ge.s32 	%p22, %r16, %r17;
	setp.eq.s32 	%p23, %r17, %r16;
	setp.ge.s32 	%p24, %r18, %r19;
	selp.u32 	%r58, -1, 0, %p22;
	selp.u32 	%r59, -1, 0, %p24;
	selp.b32 	%r60, %r59, %r58, %p23;
	and.b32  	%r61, %r60, 1;
	setp.eq.b32 	%p25, %r61, 1;
	@%p25 bra 	$L__BB313_5;
	mov.u64 	%rd94, sort_$_32_$_1_tile_param_1;
	add.s64 	%rd95, %rd94, %rd91;
	add.s64 	%rd97, %rd94, %rd89;
	st.shared.u32 	[%rd26], %r16;
	st.shared.u32 	[%rd25], %r17;
	ld.shared.u32 	%r62, [%rd97];
	ld.shared.u32 	%r63, [%rd95];
	st.shared.u32 	[%rd95], %r62;
	st.shared.u32 	[%rd97], %r63;
	st.shared.u32 	[%rd28], %r18;
	st.shared.u32 	[%rd27], %r19;
$L__BB313_5:
	bar.sync 	0;
	or.b64  	%rd98, %rd9, 2;
	setp.lt.u64 	%p26, %rd98, 6;
	@%p26 bra 	$L__BB313_22;
	bra.uni 	$L__BB313_6;
$L__BB313_22:
	add.s64 	%rd29, %rd135, %rd140;
	add.s64 	%rd30, %rd139, %rd140;
	ld.shared.u32 	%r20, [%rd29+8];
	ld.shared.u32 	%r21, [%rd29];
	ld.shared.u32 	%r22, [%rd30+8];
	ld.shared.u32 	%r23, [%rd30];
	setp.ge.s32 	%p27, %r20, %r21;
	setp.eq.s32 	%p28, %r21, %r20;
	setp.ge.s32 	%p29, %r22, %r23;
	selp.u32 	%r64, -1, 0, %p27;
	selp.u32 	%r65, -1, 0, %p29;
	selp.b32 	%r66, %r65, %r64, %p28;
	and.b32  	%r67, %r66, 1;
	setp.eq.b32 	%p30, %r67, 1;
	@%p30 bra 	$L__BB313_6;
	mov.u64 	%rd103, sort_$_32_$_1_tile_param_1;
	add.s64 	%rd104, %rd103, %rd140;
	st.shared.u32 	[%rd29], %r20;
	st.shared.u32 	[%rd29+8], %r21;
	ld.shared.u32 	%r68, [%rd104+8];
	ld.shared.u32 	%r69, [%rd104];
	st.shared.u32 	[%rd104], %r68;
	st.shared.u32 	[%rd104+8], %r69;
	st.shared.u32 	[%rd30], %r22;
	st.shared.u32 	[%rd30+8], %r23;
$L__BB313_6:
	bar.sync 	0;
	@%p4 bra 	$L__BB313_24;
	bra.uni 	$L__BB313_7;
$L__BB313_24:
	add.s64 	%rd31, %rd135, %rd134;
	add.s64 	%rd32, %rd139, %rd134;
	ld.shared.u32 	%r24, [%rd31+4];
	ld.shared.u32 	%r25, [%rd31];
	ld.shared.u32 	%r26, [%rd32+4];
	ld.shared.u32 	%r27, [%rd32];
	setp.ge.s32 	%p32, %r24, %r25;
	setp.eq.s32 	%p33, %r25, %r24;
	setp.ge.s32 	%p34, %r26, %r27;
	selp.u32 	%r70, -1, 0, %p32;
	selp.u32 	%r71, -1, 0, %p34;
	selp.b32 	%r72, %r71, %r70, %p33;
	and.b32  	%r73, %r72, 1;
	setp.eq.b32 	%p35, %r73, 1;
	@%p35 bra 	$L__BB313_7;
	mov.u64 	%rd109, sort_$_32_$_1_tile_param_1;
	add.s64 	%rd110, %rd109, %rd134;
	st.shared.v2.u32 	[%rd31], {%r24, %r25};
	ld.shared.u32 	%r74, [%rd110+4];
	ld.shared.u32 	%r75, [%rd110];
	st.shared.v2.u32 	[%rd110], {%r74, %r75};
	st.shared.v2.u32 	[%rd32], {%r26, %r27};
$L__BB313_7:
	bar.sync 	0;
	@%p1 bra 	$L__BB313_8;
	add.s64 	%rd33, %rd135, %rd134;
	ld.shared.u32 	%r76, [%rd33];
	add.s64 	%rd114, %rd3, %rd136;
	add.s64 	%rd34, %rd114, %rd137;
	st.global.u32 	[%rd34], %r76;
	setp.gt.u64 	%p37, %rd138, 5;
	@%p37 bra 	$L__BB313_28;
	ld.shared.u32 	%r77, [%rd33+4];
	st.global.u32 	[%rd34+4], %r77;
	mov.u64 	%rd120, sort_$_32_$_1_tile_param_1;
	add.s64 	%rd121, %rd120, %rd134;
	ld.shared.v2.u32 	{%r82, %r78}, [%rd121];
	add.s64 	%rd123, %rd2, %rd136;
	add.s64 	%rd125, %rd123, %rd137;
	st.global.u32 	[%rd125+4], %r78;
	bra.uni 	$L__BB313_29;
$L__BB313_28:
	mov.u64 	%rd117, sort_$_32_$_1_tile_param_1;
	add.s64 	%rd118, %rd117, %rd134;
	ld.shared.u32 	%r82, [%rd118];
$L__BB313_29:
	add.s64 	%rd127, %rd2, %rd136;
	add.s64 	%rd129, %rd127, %rd137;
	st.global.u32 	[%rd129], %r82;
	add.s64 	%rd36, %rd139, %rd134;
	ld.shared.u32 	%r79, [%rd36];
	add.s64 	%rd132, %rd1, %rd136;
	add.s64 	%rd37, %rd132, %rd137;
	st.global.u32 	[%rd37], %r79;
	@%p37 bra 	$L__BB313_8;
	ld.shared.u32 	%r80, [%rd36+4];
	st.global.u32 	[%rd37+4], %r80;
$L__BB313_8:
	ret;

}
	// .globl	sort_31_0
.visible .entry sort_31_0(
	.param .u64 sort_31_0_param_0,
	.param .u64 sort_31_0_param_1,
	.param .u64 sort_31_0_param_2
)
.reqntid 4, 1, 1
{
	.reg .pred 	%p<39>;
	.reg .b32 	%r<83>;
	.reg .b64 	%rd<141>;
	// demoted variable
	.shared .align 4 .b8 sort_$_31_$_0_tile_param_0[256];
	// demoted variable
	.shared .align 4 .b8 sort_$_31_$_0_tile_param_1[256];
	// demoted variable
	.shared .align 4 .b8 sort_$_31_$_0_tile_param_2[256];
	ld.param.u64 	%rd38, [sort_31_0_param_0];
	ld.param.u64 	%rd39, [sort_31_0_param_2];
	cvta.to.global.u64 	%rd1, %rd39;
	ld.param.u64 	%rd40, [sort_31_0_param_1];
	cvta.to.global.u64 	%rd2, %rd40;
	cvta.to.global.u64 	%rd3, %rd38;
	mov.u32 	%r31, %ctaid.x;
	mov.u32 	%r32, %tid.x;
	shl.b32 	%r33, %r31, 2;
	or.b32  	%r34, %r33, %r32;
	cvt.u64.u32 	%rd41, %r34;
	shr.u64 	%rd4, %rd41, 2;
	mul.wide.u32 	%rd42, %r34, 2;
	and.b64  	%rd6, %rd42, 6;
	setp.eq.s64 	%p1, %rd6, 6;
	mul.wide.u32 	%rd7, %r32, 2;
	shl.b64 	%rd134, %rd7, 2;
	mov.u64 	%rd135, sort_$_31_$_0_tile_param_0;
	mul.lo.s64 	%rd136, %rd4, 24;
	shl.b64 	%rd137, %rd6, 2;
	or.b64  	%rd138, %rd6, 1;
	mov.u64 	%rd139, sort_$_31_$_0_tile_param_2;
	@%p1 bra 	$L__BB314_1;
	add.s64 	%rd44, %rd3, %rd136;
	add.s64 	%rd12, %rd44, %rd137;
	ld.global.u32 	%r35, [%rd12];
	add.s64 	%rd13, %rd135, %rd134;
	st.shared.u32 	[%rd13], %r35;
	setp.gt.u64 	%p2, %rd138, 5;
	mov.u64 	%rd133, sort_$_31_$_0_tile_param_1;
	@%p2 bra 	$L__BB314_11;
	ld.global.u32 	%r36, [%rd12+4];
	st.shared.u32 	[%rd13+4], %r36;
	add.s64 	%rd53, %rd2, %rd136;
	add.s64 	%rd55, %rd53, %rd137;
	ld.global.v2.u32 	{%r81, %r37}, [%rd55];
	add.s64 	%rd58, %rd133, %rd134;
	st.shared.u32 	[%rd58+4], %r37;
	bra.uni 	$L__BB314_12;
$L__BB314_11:
	add.s64 	%rd49, %rd2, %rd136;
	add.s64 	%rd51, %rd49, %rd137;
	ld.global.u32 	%r81, [%rd51];
$L__BB314_12:
	add.s64 	%rd61, %rd133, %rd134;
	st.shared.u32 	[%rd61], %r81;
	add.s64 	%rd63, %rd1, %rd136;
	add.s64 	%rd15, %rd63, %rd137;
	ld.global.u32 	%r38, [%rd15];
	add.s64 	%rd16, %rd139, %rd134;
	st.shared.u32 	[%rd16], %r38;
	@%p2 bra 	$L__BB314_1;
	ld.global.u32 	%r39, [%rd15+4];
	st.shared.u32 	[%rd16+4], %r39;
$L__BB314_1:
	cvt.u64.u32 	%rd5, %r32;
	bar.sync 	0;
	or.b64  	%rd8, %rd7, 1;
	setp.lt.u64 	%p4, %rd8, 6;
	@%p4 bra 	$L__BB314_14;
	bra.uni 	$L__BB314_2;
$L__BB314_14:
	add.s64 	%rd17, %rd135, %rd134;
	add.s64 	%rd18, %rd139, %rd134;
	ld.shared.u32 	%r4, [%rd17+4];
	ld.shared.u32 	%r5, [%rd17];
	ld.shared.u32 	%r6, [%rd18+4];
	ld.shared.u32 	%r7, [%rd18];
	setp.ge.s32 	%p5, %r4, %r5;
	setp.eq.s32 	%p6, %r5, %r4;
	setp.ge.s32 	%p7, %r6, %r7;
	selp.u32 	%r40, -1, 0, %p5;
	selp.u32 	%r41, -1, 0, %p7;
	selp.b32 	%r42, %r41, %r40, %p6;
	and.b32  	%r43, %r42, 1;
	setp.eq.b32 	%p8, %r43, 1;
	@%p8 bra 	$L__BB314_2;
	mov.u64 	%rd70, sort_$_31_$_0_tile_param_1;
	add.s64 	%rd71, %rd70, %rd134;
	st.shared.v2.u32 	[%rd17], {%r4, %r5};
	ld.shared.u32 	%r44, [%rd71+4];
	ld.shared.u32 	%r45, [%rd71];
	st.shared.v2.u32 	[%rd71], {%r44, %r45};
	st.shared.v2.u32 	[%rd18], {%r6, %r7};
$L__BB314_2:
	bar.sync 	0;
	and.b64  	%rd72, %rd5, 1;
	and.b64  	%rd73, %rd7, 4;
	or.b64  	%rd9, %rd73, %rd72;
	xor.b64  	%rd10, %rd9, 3;
	setp.lt.u64 	%p9, %rd9, %rd10;
	setp.lt.u64 	%p10, %rd10, 6;
	and.pred  	%p11, %p9, %p10;
	shl.b64 	%rd140, %rd9, 2;
	@%p11 bra 	$L__BB314_16;
	bra.uni 	$L__BB314_3;
$L__BB314_16:
	shl.b64 	%rd74, %rd10, 2;
	add.s64 	%rd19, %rd135, %rd74;
	add.s64 	%rd20, %rd135, %rd140;
	add.s64 	%rd21, %rd139, %rd74;
	add.s64 	%rd22, %rd139, %rd140;
	ld.shared.u32 	%r8, [%rd19];
	ld.shared.u32 	%r9, [%rd20];
	ld.shared.u32 	%r10, [%rd21];
	ld.shared.u32 	%r11, [%rd22];
	setp.ge.s32 	%p12, %r8, %r9;
	setp.eq.s32 	%p13, %r9, %r8;
	setp.ge.s32 	%p14, %r10, %r11;
	selp.u32 	%r46, -1, 0, %p12;
	selp.u32 	%r47, -1, 0, %p14;
	selp.b32 	%r48, %r47, %r46, %p13;
	and.b32  	%r49, %r48, 1;
	setp.eq.b32 	%p15, %r49, 1;
	@%p15 bra 	$L__BB314_3;
	mov.u64 	%rd79, sort_$_31_$_0_tile_param_1;
	add.s64 	%rd80, %rd79, %rd140;
	add.s64 	%rd82, %rd79, %rd74;
	st.shared.u32 	[%rd20], %r8;
	st.shared.u32 	[%rd19], %r9;
	ld.shared.u32 	%r50, [%rd82];
	ld.shared.u32 	%r51, [%rd80];
	st.shared.u32 	[%rd80], %r50;
	st.shared.u32 	[%rd82], %r51;
	st.shared.u32 	[%rd22], %r10;
	st.shared.u32 	[%rd21], %r11;
$L__BB314_3:
	bar.sync 	0;
	@%p4 bra 	$L__BB314_18;
	bra.uni 	$L__BB314_4;
$L__BB314_18:
	add.s64 	%rd23, %rd135, %rd134;
	add.s64 	%rd24, %rd139, %rd134;
	ld.shared.u32 	%r12, [%rd23+4];
	ld.shared.u32 	%r13, [%rd23];
	ld.shared.u32 	%r14, [%rd24+4];
	ld.shared.u32 	%r15, [%rd24];
	setp.ge.s32 	%p17, %r12, %r13;
	setp.eq.s32 	%p18, %r13, %r12;
	setp.ge.s32 	%p19, %r14, %r15;
	selp.u32 	%r52, -1, 0, %p17;
	selp.u32 	%r53, -1, 0, %p19;
	selp.b32 	%r54, %r53, %r52, %p18;
	and.b32  	%r55, %r54, 1;
	setp.eq.b32 	%p20, %r55, 1;
	@%p20 bra 	$L__BB314_4;
	mov.u64 	%rd87, sort_$_31_$_0_tile_param_1;
	add.s64 	%rd88, %rd87, %rd134;
	st.shared.v2.u32 	[%rd23], {%r12, %r13};
	ld.shared.u32 	%r56, [%rd88+4];
	ld.shared.u32 	%r57, [%rd88];
	st.shared.v2.u32 	[%rd88], {%r56, %r57};
	st.shared.v2.u32 	[%rd24], {%r14, %r15};
$L__BB314_4:
	bar.sync 	0;
	xor.b64  	%rd11, %rd5, 7;
	setp.lt.u64 	%p21, %rd11, 6;
	@%p21 bra 	$L__BB314_20;
	bra.uni 	$L__BB314_5;
$L__BB314_20:
	shl.b64 	%rd89, %rd11, 2;
	add.s64 	%rd25, %rd135, %rd89;
	shl.b64 	%rd91, %rd5, 2;
	add.s64 	%rd26, %rd135, %rd91;
	add.s64 	%rd27, %rd139, %rd89;
	add.s64 	%rd28, %rd139, %rd91;
	ld.shared.u32 	%r16, [%rd25];
	ld.shared.u32 	%r17, [%rd26];
	ld.shared.u32 	%r18, [%rd27];
	ld.shared.u32 	%r19, [%rd28];
	setp.ge.s32 	%p22, %r16, %r17;
	setp.eq.s32 	%p23, %r17, %r16;
	setp.ge.s32 	%p24, %r18, %r19;
	selp.u32 	%r58, -1, 0, %p22;
	selp.u32 	%r59, -1, 0, %p24;
	selp.b32 	%r60, %r59, %r58, %p23;
	and.b32  	%r61, %r60, 1;
	setp.eq.b32 	%p25, %r61, 1;
	@%p25 bra 	$L__BB314_5;
	mov.u64 	%rd94, sort_$_31_$_0_tile_param_1;
	add.s64 	%rd95, %rd94, %rd91;
	add.s64 	%rd97, %rd94, %rd89;
	st.shared.u32 	[%rd26], %r16;
	st.shared.u32 	[%rd25], %r17;
	ld.shared.u32 	%r62, [%rd97];
	ld.shared.u32 	%r63, [%rd95];
	st.shared.u32 	[%rd95], %r62;
	st.shared.u32 	[%rd97], %r63;
	st.shared.u32 	[%rd28], %r18;
	st.shared.u32 	[%rd27], %r19;
$L__BB314_5:
	bar.sync 	0;
	or.b64  	%rd98, %rd9, 2;
	setp.lt.u64 	%p26, %rd98, 6;
	@%p26 bra 	$L__BB314_22;
	bra.uni 	$L__BB314_6;
$L__BB314_22:
	add.s64 	%rd29, %rd135, %rd140;
	add.s64 	%rd30, %rd139, %rd140;
	ld.shared.u32 	%r20, [%rd29+8];
	ld.shared.u32 	%r21, [%rd29];
	ld.shared.u32 	%r22, [%rd30+8];
	ld.shared.u32 	%r23, [%rd30];
	setp.ge.s32 	%p27, %r20, %r21;
	setp.eq.s32 	%p28, %r21, %r20;
	setp.ge.s32 	%p29, %r22, %r23;
	selp.u32 	%r64, -1, 0, %p27;
	selp.u32 	%r65, -1, 0, %p29;
	selp.b32 	%r66, %r65, %r64, %p28;
	and.b32  	%r67, %r66, 1;
	setp.eq.b32 	%p30, %r67, 1;
	@%p30 bra 	$L__BB314_6;
	mov.u64 	%rd103, sort_$_31_$_0_tile_param_1;
	add.s64 	%rd104, %rd103, %rd140;
	st.shared.u32 	[%rd29], %r20;
	st.shared.u32 	[%rd29+8], %r21;
	ld.shared.u32 	%r68, [%rd104+8];
	ld.shared.u32 	%r69, [%rd104];
	st.shared.u32 	[%rd104], %r68;
	st.shared.u32 	[%rd104+8], %r69;
	st.shared.u32 	[%rd30], %r22;
	st.shared.u32 	[%rd30+8], %r23;
$L__BB314_6:
	bar.sync 	0;
	@%p4 bra 	$L__BB314_24;
	bra.uni 	$L__BB314_7;
$L__BB314_24:
	add.s64 	%rd31, %rd135, %rd134;
	add.s64 	%rd32, %rd139, %rd134;
	ld.shared.u32 	%r24, [%rd31+4];
	ld.shared.u32 	%r25, [%rd31];
	ld.shared.u32 	%r26, [%rd32+4];
	ld.shared.u32 	%r27, [%rd32];
	setp.ge.s32 	%p32, %r24, %r25;
	setp.eq.s32 	%p33, %r25, %r24;
	setp.ge.s32 	%p34, %r26, %r27;
	selp.u32 	%r70, -1, 0, %p32;
	selp.u32 	%r71, -1, 0, %p34;
	selp.b32 	%r72, %r71, %r70, %p33;
	and.b32  	%r73, %r72, 1;
	setp.eq.b32 	%p35, %r73, 1;
	@%p35 bra 	$L__BB314_7;
	mov.u64 	%rd109, sort_$_31_$_0_tile_param_1;
	add.s64 	%rd110, %rd109, %rd134;
	st.shared.v2.u32 	[%rd31], {%r24, %r25};
	ld.shared.u32 	%r74, [%rd110+4];
	ld.shared.u32 	%r75, [%rd110];
	st.shared.v2.u32 	[%rd110], {%r74, %r75};
	st.shared.v2.u32 	[%rd32], {%r26, %r27};
$L__BB314_7:
	bar.sync 	0;
	@%p1 bra 	$L__BB314_8;
	add.s64 	%rd33, %rd135, %rd134;
	ld.shared.u32 	%r76, [%rd33];
	add.s64 	%rd114, %rd3, %rd136;
	add.s64 	%rd34, %rd114, %rd137;
	st.global.u32 	[%rd34], %r76;
	setp.gt.u64 	%p37, %rd138, 5;
	@%p37 bra 	$L__BB314_28;
	ld.shared.u32 	%r77, [%rd33+4];
	st.global.u32 	[%rd34+4], %r77;
	mov.u64 	%rd120, sort_$_31_$_0_tile_param_1;
	add.s64 	%rd121, %rd120, %rd134;
	ld.shared.v2.u32 	{%r82, %r78}, [%rd121];
	add.s64 	%rd123, %rd2, %rd136;
	add.s64 	%rd125, %rd123, %rd137;
	st.global.u32 	[%rd125+4], %r78;
	bra.uni 	$L__BB314_29;
$L__BB314_28:
	mov.u64 	%rd117, sort_$_31_$_0_tile_param_1;
	add.s64 	%rd118, %rd117, %rd134;
	ld.shared.u32 	%r82, [%rd118];
$L__BB314_29:
	add.s64 	%rd127, %rd2, %rd136;
	add.s64 	%rd129, %rd127, %rd137;
	st.global.u32 	[%rd129], %r82;
	add.s64 	%rd36, %rd139, %rd134;
	ld.shared.u32 	%r79, [%rd36];
	add.s64 	%rd132, %rd1, %rd136;
	add.s64 	%rd37, %rd132, %rd137;
	st.global.u32 	[%rd37], %r79;
	@%p37 bra 	$L__BB314_8;
	ld.shared.u32 	%r80, [%rd36+4];
	st.global.u32 	[%rd37+4], %r80;
$L__BB314_8:
	ret;

}
	// .globl	sort_30_1
.visible .entry sort_30_1(
	.param .u64 sort_30_1_param_0,
	.param .u64 sort_30_1_param_1,
	.param .u64 sort_30_1_param_2
)
.reqntid 4, 1, 1
{
	.reg .pred 	%p<39>;
	.reg .b32 	%r<83>;
	.reg .b64 	%rd<141>;
	// demoted variable
	.shared .align 4 .b8 sort_$_30_$_1_tile_param_0[256];
	// demoted variable
	.shared .align 4 .b8 sort_$_30_$_1_tile_param_1[256];
	// demoted variable
	.shared .align 4 .b8 sort_$_30_$_1_tile_param_2[256];
	ld.param.u64 	%rd38, [sort_30_1_param_0];
	ld.param.u64 	%rd39, [sort_30_1_param_2];
	cvta.to.global.u64 	%rd1, %rd39;
	ld.param.u64 	%rd40, [sort_30_1_param_1];
	cvta.to.global.u64 	%rd2, %rd40;
	cvta.to.global.u64 	%rd3, %rd38;
	mov.u32 	%r31, %ctaid.x;
	mov.u32 	%r32, %tid.x;
	shl.b32 	%r33, %r31, 2;
	or.b32  	%r34, %r33, %r32;
	cvt.u64.u32 	%rd41, %r34;
	shr.u64 	%rd4, %rd41, 2;
	mul.wide.u32 	%rd42, %r34, 2;
	and.b64  	%rd6, %rd42, 6;
	setp.eq.s64 	%p1, %rd6, 6;
	mul.wide.u32 	%rd7, %r32, 2;
	shl.b64 	%rd134, %rd7, 2;
	mov.u64 	%rd135, sort_$_30_$_1_tile_param_0;
	mul.lo.s64 	%rd136, %rd4, 24;
	shl.b64 	%rd137, %rd6, 2;
	or.b64  	%rd138, %rd6, 1;
	mov.u64 	%rd139, sort_$_30_$_1_tile_param_2;
	@%p1 bra 	$L__BB315_1;
	add.s64 	%rd44, %rd3, %rd136;
	add.s64 	%rd12, %rd44, %rd137;
	ld.global.u32 	%r35, [%rd12];
	add.s64 	%rd13, %rd135, %rd134;
	st.shared.u32 	[%rd13], %r35;
	setp.gt.u64 	%p2, %rd138, 5;
	mov.u64 	%rd133, sort_$_30_$_1_tile_param_1;
	@%p2 bra 	$L__BB315_11;
	ld.global.u32 	%r36, [%rd12+4];
	st.shared.u32 	[%rd13+4], %r36;
	add.s64 	%rd53, %rd2, %rd136;
	add.s64 	%rd55, %rd53, %rd137;
	ld.global.v2.u32 	{%r81, %r37}, [%rd55];
	add.s64 	%rd58, %rd133, %rd134;
	st.shared.u32 	[%rd58+4], %r37;
	bra.uni 	$L__BB315_12;
$L__BB315_11:
	add.s64 	%rd49, %rd2, %rd136;
	add.s64 	%rd51, %rd49, %rd137;
	ld.global.u32 	%r81, [%rd51];
$L__BB315_12:
	add.s64 	%rd61, %rd133, %rd134;
	st.shared.u32 	[%rd61], %r81;
	add.s64 	%rd63, %rd1, %rd136;
	add.s64 	%rd15, %rd63, %rd137;
	ld.global.u32 	%r38, [%rd15];
	add.s64 	%rd16, %rd139, %rd134;
	st.shared.u32 	[%rd16], %r38;
	@%p2 bra 	$L__BB315_1;
	ld.global.u32 	%r39, [%rd15+4];
	st.shared.u32 	[%rd16+4], %r39;
$L__BB315_1:
	cvt.u64.u32 	%rd5, %r32;
	bar.sync 	0;
	or.b64  	%rd8, %rd7, 1;
	setp.lt.u64 	%p4, %rd8, 6;
	@%p4 bra 	$L__BB315_14;
	bra.uni 	$L__BB315_2;
$L__BB315_14:
	add.s64 	%rd17, %rd135, %rd134;
	add.s64 	%rd18, %rd139, %rd134;
	ld.shared.u32 	%r4, [%rd17+4];
	ld.shared.u32 	%r5, [%rd17];
	ld.shared.u32 	%r6, [%rd18+4];
	ld.shared.u32 	%r7, [%rd18];
	setp.ge.s32 	%p5, %r4, %r5;
	setp.eq.s32 	%p6, %r5, %r4;
	setp.ge.s32 	%p7, %r6, %r7;
	selp.u32 	%r40, -1, 0, %p5;
	selp.u32 	%r41, -1, 0, %p7;
	selp.b32 	%r42, %r41, %r40, %p6;
	and.b32  	%r43, %r42, 1;
	setp.eq.b32 	%p8, %r43, 1;
	@%p8 bra 	$L__BB315_2;
	mov.u64 	%rd70, sort_$_30_$_1_tile_param_1;
	add.s64 	%rd71, %rd70, %rd134;
	st.shared.v2.u32 	[%rd17], {%r4, %r5};
	ld.shared.u32 	%r44, [%rd71+4];
	ld.shared.u32 	%r45, [%rd71];
	st.shared.v2.u32 	[%rd71], {%r44, %r45};
	st.shared.v2.u32 	[%rd18], {%r6, %r7};
$L__BB315_2:
	bar.sync 	0;
	and.b64  	%rd72, %rd5, 1;
	and.b64  	%rd73, %rd7, 4;
	or.b64  	%rd9, %rd73, %rd72;
	xor.b64  	%rd10, %rd9, 3;
	setp.lt.u64 	%p9, %rd9, %rd10;
	setp.lt.u64 	%p10, %rd10, 6;
	and.pred  	%p11, %p9, %p10;
	shl.b64 	%rd140, %rd9, 2;
	@%p11 bra 	$L__BB315_16;
	bra.uni 	$L__BB315_3;
$L__BB315_16:
	shl.b64 	%rd74, %rd10, 2;
	add.s64 	%rd19, %rd135, %rd74;
	add.s64 	%rd20, %rd135, %rd140;
	add.s64 	%rd21, %rd139, %rd74;
	add.s64 	%rd22, %rd139, %rd140;
	ld.shared.u32 	%r8, [%rd19];
	ld.shared.u32 	%r9, [%rd20];
	ld.shared.u32 	%r10, [%rd21];
	ld.shared.u32 	%r11, [%rd22];
	setp.ge.s32 	%p12, %r8, %r9;
	setp.eq.s32 	%p13, %r9, %r8;
	setp.ge.s32 	%p14, %r10, %r11;
	selp.u32 	%r46, -1, 0, %p12;
	selp.u32 	%r47, -1, 0, %p14;
	selp.b32 	%r48, %r47, %r46, %p13;
	and.b32  	%r49, %r48, 1;
	setp.eq.b32 	%p15, %r49, 1;
	@%p15 bra 	$L__BB315_3;
	mov.u64 	%rd79, sort_$_30_$_1_tile_param_1;
	add.s64 	%rd80, %rd79, %rd140;
	add.s64 	%rd82, %rd79, %rd74;
	st.shared.u32 	[%rd20], %r8;
	st.shared.u32 	[%rd19], %r9;
	ld.shared.u32 	%r50, [%rd82];
	ld.shared.u32 	%r51, [%rd80];
	st.shared.u32 	[%rd80], %r50;
	st.shared.u32 	[%rd82], %r51;
	st.shared.u32 	[%rd22], %r10;
	st.shared.u32 	[%rd21], %r11;
$L__BB315_3:
	bar.sync 	0;
	@%p4 bra 	$L__BB315_18;
	bra.uni 	$L__BB315_4;
$L__BB315_18:
	add.s64 	%rd23, %rd135, %rd134;
	add.s64 	%rd24, %rd139, %rd134;
	ld.shared.u32 	%r12, [%rd23+4];
	ld.shared.u32 	%r13, [%rd23];
	ld.shared.u32 	%r14, [%rd24+4];
	ld.shared.u32 	%r15, [%rd24];
	setp.ge.s32 	%p17, %r12, %r13;
	setp.eq.s32 	%p18, %r13, %r12;
	setp.ge.s32 	%p19, %r14, %r15;
	selp.u32 	%r52, -1, 0, %p17;
	selp.u32 	%r53, -1, 0, %p19;
	selp.b32 	%r54, %r53, %r52, %p18;
	and.b32  	%r55, %r54, 1;
	setp.eq.b32 	%p20, %r55, 1;
	@%p20 bra 	$L__BB315_4;
	mov.u64 	%rd87, sort_$_30_$_1_tile_param_1;
	add.s64 	%rd88, %rd87, %rd134;
	st.shared.v2.u32 	[%rd23], {%r12, %r13};
	ld.shared.u32 	%r56, [%rd88+4];
	ld.shared.u32 	%r57, [%rd88];
	st.shared.v2.u32 	[%rd88], {%r56, %r57};
	st.shared.v2.u32 	[%rd24], {%r14, %r15};
$L__BB315_4:
	bar.sync 	0;
	xor.b64  	%rd11, %rd5, 7;
	setp.lt.u64 	%p21, %rd11, 6;
	@%p21 bra 	$L__BB315_20;
	bra.uni 	$L__BB315_5;
$L__BB315_20:
	shl.b64 	%rd89, %rd11, 2;
	add.s64 	%rd25, %rd135, %rd89;
	shl.b64 	%rd91, %rd5, 2;
	add.s64 	%rd26, %rd135, %rd91;
	add.s64 	%rd27, %rd139, %rd89;
	add.s64 	%rd28, %rd139, %rd91;
	ld.shared.u32 	%r16, [%rd25];
	ld.shared.u32 	%r17, [%rd26];
	ld.shared.u32 	%r18, [%rd27];
	ld.shared.u32 	%r19, [%rd28];
	setp.ge.s32 	%p22, %r16, %r17;
	setp.eq.s32 	%p23, %r17, %r16;
	setp.ge.s32 	%p24, %r18, %r19;
	selp.u32 	%r58, -1, 0, %p22;
	selp.u32 	%r59, -1, 0, %p24;
	selp.b32 	%r60, %r59, %r58, %p23;
	and.b32  	%r61, %r60, 1;
	setp.eq.b32 	%p25, %r61, 1;
	@%p25 bra 	$L__BB315_5;
	mov.u64 	%rd94, sort_$_30_$_1_tile_param_1;
	add.s64 	%rd95, %rd94, %rd91;
	add.s64 	%rd97, %rd94, %rd89;
	st.shared.u32 	[%rd26], %r16;
	st.shared.u32 	[%rd25], %r17;
	ld.shared.u32 	%r62, [%rd97];
	ld.shared.u32 	%r63, [%rd95];
	st.shared.u32 	[%rd95], %r62;
	st.shared.u32 	[%rd97], %r63;
	st.shared.u32 	[%rd28], %r18;
	st.shared.u32 	[%rd27], %r19;
$L__BB315_5:
	bar.sync 	0;
	or.b64  	%rd98, %rd9, 2;
	setp.lt.u64 	%p26, %rd98, 6;
	@%p26 bra 	$L__BB315_22;
	bra.uni 	$L__BB315_6;
$L__BB315_22:
	add.s64 	%rd29, %rd135, %rd140;
	add.s64 	%rd30, %rd139, %rd140;
	ld.shared.u32 	%r20, [%rd29+8];
	ld.shared.u32 	%r21, [%rd29];
	ld.shared.u32 	%r22, [%rd30+8];
	ld.shared.u32 	%r23, [%rd30];
	setp.ge.s32 	%p27, %r20, %r21;
	setp.eq.s32 	%p28, %r21, %r20;
	setp.ge.s32 	%p29, %r22, %r23;
	selp.u32 	%r64, -1, 0, %p27;
	selp.u32 	%r65, -1, 0, %p29;
	selp.b32 	%r66, %r65, %r64, %p28;
	and.b32  	%r67, %r66, 1;
	setp.eq.b32 	%p30, %r67, 1;
	@%p30 bra 	$L__BB315_6;
	mov.u64 	%rd103, sort_$_30_$_1_tile_param_1;
	add.s64 	%rd104, %rd103, %rd140;
	st.shared.u32 	[%rd29], %r20;
	st.shared.u32 	[%rd29+8], %r21;
	ld.shared.u32 	%r68, [%rd104+8];
	ld.shared.u32 	%r69, [%rd104];
	st.shared.u32 	[%rd104], %r68;
	st.shared.u32 	[%rd104+8], %r69;
	st.shared.u32 	[%rd30], %r22;
	st.shared.u32 	[%rd30+8], %r23;
$L__BB315_6:
	bar.sync 	0;
	@%p4 bra 	$L__BB315_24;
	bra.uni 	$L__BB315_7;
$L__BB315_24:
	add.s64 	%rd31, %rd135, %rd134;
	add.s64 	%rd32, %rd139, %rd134;
	ld.shared.u32 	%r24, [%rd31+4];
	ld.shared.u32 	%r25, [%rd31];
	ld.shared.u32 	%r26, [%rd32+4];
	ld.shared.u32 	%r27, [%rd32];
	setp.ge.s32 	%p32, %r24, %r25;
	setp.eq.s32 	%p33, %r25, %r24;
	setp.ge.s32 	%p34, %r26, %r27;
	selp.u32 	%r70, -1, 0, %p32;
	selp.u32 	%r71, -1, 0, %p34;
	selp.b32 	%r72, %r71, %r70, %p33;
	and.b32  	%r73, %r72, 1;
	setp.eq.b32 	%p35, %r73, 1;
	@%p35 bra 	$L__BB315_7;
	mov.u64 	%rd109, sort_$_30_$_1_tile_param_1;
	add.s64 	%rd110, %rd109, %rd134;
	st.shared.v2.u32 	[%rd31], {%r24, %r25};
	ld.shared.u32 	%r74, [%rd110+4];
	ld.shared.u32 	%r75, [%rd110];
	st.shared.v2.u32 	[%rd110], {%r74, %r75};
	st.shared.v2.u32 	[%rd32], {%r26, %r27};
$L__BB315_7:
	bar.sync 	0;
	@%p1 bra 	$L__BB315_8;
	add.s64 	%rd33, %rd135, %rd134;
	ld.shared.u32 	%r76, [%rd33];
	add.s64 	%rd114, %rd3, %rd136;
	add.s64 	%rd34, %rd114, %rd137;
	st.global.u32 	[%rd34], %r76;
	setp.gt.u64 	%p37, %rd138, 5;
	@%p37 bra 	$L__BB315_28;
	ld.shared.u32 	%r77, [%rd33+4];
	st.global.u32 	[%rd34+4], %r77;
	mov.u64 	%rd120, sort_$_30_$_1_tile_param_1;
	add.s64 	%rd121, %rd120, %rd134;
	ld.shared.v2.u32 	{%r82, %r78}, [%rd121];
	add.s64 	%rd123, %rd2, %rd136;
	add.s64 	%rd125, %rd123, %rd137;
	st.global.u32 	[%rd125+4], %r78;
	bra.uni 	$L__BB315_29;
$L__BB315_28:
	mov.u64 	%rd117, sort_$_30_$_1_tile_param_1;
	add.s64 	%rd118, %rd117, %rd134;
	ld.shared.u32 	%r82, [%rd118];
$L__BB315_29:
	add.s64 	%rd127, %rd2, %rd136;
	add.s64 	%rd129, %rd127, %rd137;
	st.global.u32 	[%rd129], %r82;
	add.s64 	%rd36, %rd139, %rd134;
	ld.shared.u32 	%r79, [%rd36];
	add.s64 	%rd132, %rd1, %rd136;
	add.s64 	%rd37, %rd132, %rd137;
	st.global.u32 	[%rd37], %r79;
	@%p37 bra 	$L__BB315_8;
	ld.shared.u32 	%r80, [%rd36+4];
	st.global.u32 	[%rd37+4], %r80;
$L__BB315_8:
	ret;

}
	// .globl	loop_select_fusion_38
.visible .entry loop_select_fusion_38(
	.param .u64 loop_select_fusion_38_param_0,
	.param .u64 loop_select_fusion_38_param_1,
	.param .u64 loop_select_fusion_38_param_2,
	.param .u64 loop_select_fusion_38_param_3,
	.param .u64 loop_select_fusion_38_param_4,
	.param .u64 loop_select_fusion_38_param_5,
	.param .u64 loop_select_fusion_38_param_6,
	.param .u64 loop_select_fusion_38_param_7,
	.param .u64 loop_select_fusion_38_param_8,
	.param .u64 loop_select_fusion_38_param_9,
	.param .u64 loop_select_fusion_38_param_10,
	.param .u64 loop_select_fusion_38_param_11,
	.param .u64 loop_select_fusion_38_param_12,
	.param .u64 loop_select_fusion_38_param_13,
	.param .u64 loop_select_fusion_38_param_14,
	.param .u64 loop_select_fusion_38_param_15,
	.param .u64 loop_select_fusion_38_param_16,
	.param .u64 loop_select_fusion_38_param_17,
	.param .u64 loop_select_fusion_38_param_18,
	.param .u64 loop_select_fusion_38_param_19,
	.param .u64 loop_select_fusion_38_param_20,
	.param .u64 loop_select_fusion_38_param_21,
	.param .u64 loop_select_fusion_38_param_22,
	.param .u64 loop_select_fusion_38_param_23,
	.param .u64 loop_select_fusion_38_param_24,
	.param .u64 loop_select_fusion_38_param_25,
	.param .u64 loop_select_fusion_38_param_26,
	.param .u64 loop_select_fusion_38_param_27,
	.param .u64 loop_select_fusion_38_param_28,
	.param .u64 loop_select_fusion_38_param_29,
	.param .u64 loop_select_fusion_38_param_30,
	.param .u64 loop_select_fusion_38_param_31,
	.param .u64 loop_select_fusion_38_param_32,
	.param .u64 loop_select_fusion_38_param_33,
	.param .u64 loop_select_fusion_38_param_34,
	.param .u64 loop_select_fusion_38_param_35,
	.param .u64 loop_select_fusion_38_param_36,
	.param .u64 loop_select_fusion_38_param_37,
	.param .u64 loop_select_fusion_38_param_38,
	.param .u64 loop_select_fusion_38_param_39,
	.param .u64 loop_select_fusion_38_param_40,
	.param .u64 loop_select_fusion_38_param_41,
	.param .u64 loop_select_fusion_38_param_42,
	.param .u64 loop_select_fusion_38_param_43,
	.param .u64 loop_select_fusion_38_param_44,
	.param .u64 loop_select_fusion_38_param_45,
	.param .u64 loop_select_fusion_38_param_46,
	.param .u64 loop_select_fusion_38_param_47,
	.param .u64 loop_select_fusion_38_param_48,
	.param .u64 loop_select_fusion_38_param_49
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<51>;
	.reg .b16 	%rs<26>;
	.reg .b32 	%r<78>;
	.reg .f32 	%f<61>;
	.reg .b64 	%rd<195>;

	ld.param.u64 	%rd1, [loop_select_fusion_38_param_0];
	ld.param.u64 	%rd2, [loop_select_fusion_38_param_49];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_select_fusion_38_param_1];
	ld.param.u64 	%rd5, [loop_select_fusion_38_param_48];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_select_fusion_38_param_2];
	ld.param.u64 	%rd8, [loop_select_fusion_38_param_47];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_select_fusion_38_param_3];
	ld.param.u64 	%rd11, [loop_select_fusion_38_param_46];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_select_fusion_38_param_4];
	ld.param.u64 	%rd14, [loop_select_fusion_38_param_45];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_select_fusion_38_param_5];
	ld.param.u64 	%rd17, [loop_select_fusion_38_param_44];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_select_fusion_38_param_6];
	ld.param.u64 	%rd20, [loop_select_fusion_38_param_43];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_select_fusion_38_param_7];
	ld.param.u64 	%rd23, [loop_select_fusion_38_param_42];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_select_fusion_38_param_8];
	ld.param.u64 	%rd26, [loop_select_fusion_38_param_41];
	cvta.to.global.u64 	%rd27, %rd26;
	ld.param.u64 	%rd28, [loop_select_fusion_38_param_9];
	ld.param.u64 	%rd29, [loop_select_fusion_38_param_40];
	cvta.to.global.u64 	%rd30, %rd29;
	ld.param.u64 	%rd31, [loop_select_fusion_38_param_10];
	ld.param.u64 	%rd32, [loop_select_fusion_38_param_39];
	cvta.to.global.u64 	%rd33, %rd32;
	ld.param.u64 	%rd34, [loop_select_fusion_38_param_11];
	ld.param.u64 	%rd35, [loop_select_fusion_38_param_38];
	cvta.to.global.u64 	%rd36, %rd35;
	ld.param.u64 	%rd37, [loop_select_fusion_38_param_12];
	ld.param.u64 	%rd38, [loop_select_fusion_38_param_37];
	cvta.to.global.u64 	%rd39, %rd38;
	ld.param.u64 	%rd40, [loop_select_fusion_38_param_13];
	ld.param.u64 	%rd41, [loop_select_fusion_38_param_36];
	cvta.to.global.u64 	%rd42, %rd41;
	ld.param.u64 	%rd43, [loop_select_fusion_38_param_14];
	ld.param.u64 	%rd44, [loop_select_fusion_38_param_35];
	cvta.to.global.u64 	%rd45, %rd44;
	ld.param.u64 	%rd46, [loop_select_fusion_38_param_15];
	ld.param.u64 	%rd47, [loop_select_fusion_38_param_34];
	cvta.to.global.u64 	%rd48, %rd47;
	ld.param.u64 	%rd49, [loop_select_fusion_38_param_16];
	ld.param.u64 	%rd50, [loop_select_fusion_38_param_33];
	cvta.to.global.u64 	%rd51, %rd50;
	ld.param.u64 	%rd52, [loop_select_fusion_38_param_17];
	ld.param.u64 	%rd53, [loop_select_fusion_38_param_32];
	cvta.to.global.u64 	%rd54, %rd53;
	ld.param.u64 	%rd55, [loop_select_fusion_38_param_18];
	ld.param.u64 	%rd56, [loop_select_fusion_38_param_31];
	cvta.to.global.u64 	%rd57, %rd56;
	ld.param.u64 	%rd58, [loop_select_fusion_38_param_19];
	ld.param.u64 	%rd59, [loop_select_fusion_38_param_30];
	cvta.to.global.u64 	%rd60, %rd59;
	ld.param.u64 	%rd61, [loop_select_fusion_38_param_20];
	ld.param.u64 	%rd62, [loop_select_fusion_38_param_29];
	cvta.to.global.u64 	%rd63, %rd62;
	ld.param.u64 	%rd64, [loop_select_fusion_38_param_21];
	ld.param.u64 	%rd65, [loop_select_fusion_38_param_28];
	cvta.to.global.u64 	%rd66, %rd65;
	ld.param.u64 	%rd67, [loop_select_fusion_38_param_22];
	ld.param.u64 	%rd68, [loop_select_fusion_38_param_27];
	cvta.to.global.u64 	%rd69, %rd68;
	ld.param.u64 	%rd70, [loop_select_fusion_38_param_23];
	ld.param.u64 	%rd71, [loop_select_fusion_38_param_26];
	cvta.to.global.u64 	%rd72, %rd71;
	ld.param.u64 	%rd73, [loop_select_fusion_38_param_24];
	ld.param.u64 	%rd74, [loop_select_fusion_38_param_25];
	cvta.to.global.u64 	%rd75, %rd74;
	cvta.to.global.u64 	%rd76, %rd73;
	cvta.to.global.u64 	%rd77, %rd70;
	cvta.to.global.u64 	%rd78, %rd67;
	cvta.to.global.u64 	%rd79, %rd64;
	cvta.to.global.u64 	%rd80, %rd61;
	cvta.to.global.u64 	%rd81, %rd58;
	cvta.to.global.u64 	%rd82, %rd55;
	cvta.to.global.u64 	%rd83, %rd52;
	cvta.to.global.u64 	%rd84, %rd49;
	cvta.to.global.u64 	%rd85, %rd46;
	cvta.to.global.u64 	%rd86, %rd43;
	cvta.to.global.u64 	%rd87, %rd40;
	cvta.to.global.u64 	%rd88, %rd37;
	cvta.to.global.u64 	%rd89, %rd34;
	cvta.to.global.u64 	%rd90, %rd31;
	cvta.to.global.u64 	%rd91, %rd28;
	cvta.to.global.u64 	%rd92, %rd25;
	cvta.to.global.u64 	%rd93, %rd22;
	cvta.to.global.u64 	%rd94, %rd19;
	cvta.to.global.u64 	%rd95, %rd16;
	cvta.to.global.u64 	%rd96, %rd13;
	cvta.to.global.u64 	%rd97, %rd10;
	cvta.to.global.u64 	%rd98, %rd7;
	cvta.to.global.u64 	%rd99, %rd4;
	cvta.to.global.u64 	%rd100, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r5, %rs3;
	mul.wide.u32 	%rd101, %r5, 4;
	add.s64 	%rd102, %rd99, %rd101;
	ld.global.nc.u32 	%r6, [%rd102];
	add.s64 	%rd103, %rd98, %rd101;
	ld.global.nc.u32 	%r7, [%rd103];
	add.s64 	%rd104, %rd97, %rd101;
	ld.global.nc.u32 	%r8, [%rd104];
	max.s32 	%r9, %r6, %r7;
	setp.gt.s32 	%p1, %r8, %r9;
	min.s32 	%r10, %r8, %r9;
	setp.eq.s32 	%p2, %r10, %r6;
	add.s64 	%rd105, %rd96, %rd101;
	ld.global.nc.f32 	%f1, [%rd105];
	setp.gt.f32 	%p3, %f1, 0f41800000;
	selp.u32 	%r11, 1, 0, %p3;
	setp.eq.s32 	%p4, %r6, %r11;
	mul.wide.u32 	%rd106, %r4, 4;
	add.s64 	%rd107, %rd100, %rd106;
	ld.global.nc.f32 	%f2, [%rd107];
	selp.f32 	%f3, %f2, 0f00000000, %p4;
	mul.lo.s16 	%rs11, %rs3, 6;
	add.s16 	%rs12, %rs11, %rs10;
	mul.hi.u16 	%rs14, %rs12, -21845;
	shr.u16 	%rs15, %rs14, 2;
	cvt.u32.u16 	%r12, %rs15;
	mul.wide.u32 	%rd108, %r12, 4;
	add.s64 	%rd109, %rd96, %rd108;
	ld.global.nc.f32 	%f4, [%rd109];
	setp.gt.f32 	%p5, %f4, 0f41800000;
	selp.u32 	%r13, 1, 0, %p5;
	add.s64 	%rd110, %rd99, %rd108;
	ld.global.nc.u32 	%r14, [%rd110];
	setp.eq.s32 	%p6, %r14, %r13;
	setp.gt.u16 	%p7, %rs12, 377;
	selp.b16 	%rs16, 63, %rs15, %p7;
	mul.lo.s16 	%rs17, %rs15, 6;
	sub.s16 	%rs18, %rs12, %rs17;
	cvt.u32.u16 	%r15, %rs18;
	mul.wide.u32 	%rd111, %r15, 4;
	mul.wide.u32 	%rd112, %r12, 24;
	add.s64 	%rd113, %rd95, %rd112;
	add.s64 	%rd114, %rd113, %rd111;
	ld.global.nc.u32 	%r16, [%rd114];
	setp.lt.s32 	%p8, %r16, 0;
	add.s32 	%r17, %r16, 6;
	selp.b32 	%r18, %r17, %r16, %p8;
	max.s32 	%r19, %r18, 0;
	min.s32 	%r20, %r19, 5;
	mul.wide.u32 	%rd115, %r20, 4;
	cvt.u32.u16 	%r21, %rs16;
	mul.wide.u32 	%rd116, %r21, 144;
	add.s64 	%rd117, %rd94, %rd116;
	cvt.u32.u16 	%r22, %rs8;
	mul.wide.u32 	%rd118, %r22, 24;
	add.s64 	%rd119, %rd117, %rd118;
	add.s64 	%rd120, %rd119, %rd115;
	ld.global.nc.f32 	%f5, [%rd120];
	selp.f32 	%f6, %f5, 0f00000000, %p6;
	sub.rn.f32 	%f7, %f6, %f3;
	selp.f32 	%f8, %f7, 0f00000000, %p2;
	setp.eq.s32 	%p9, %r10, 1;
	selp.f32 	%f9, %f7, 0f00000000, %p9;
	selp.f32 	%f10, 0f00000000, %f7, %p1;
	add.s64 	%rd121, %rd89, %rd101;
	ld.global.nc.u32 	%r23, [%rd121];
	max.s32 	%r24, %r6, %r23;
	setp.gt.s32 	%p10, %r8, %r24;
	min.s32 	%r25, %r8, %r24;
	add.s64 	%rd122, %rd90, %rd101;
	ld.global.nc.f32 	%f11, [%rd122];
	setp.gt.f32 	%p11, %f11, 0f41800000;
	selp.u32 	%r26, 1, 0, %p11;
	setp.eq.s32 	%p12, %r6, %r26;
	add.s64 	%rd123, %rd91, %rd106;
	ld.global.nc.f32 	%f12, [%rd123];
	selp.f32 	%f13, %f12, 0f00000000, %p12;
	add.s64 	%rd124, %rd90, %rd108;
	ld.global.nc.f32 	%f14, [%rd124];
	setp.gt.f32 	%p13, %f14, 0f41800000;
	selp.u32 	%r27, 1, 0, %p13;
	setp.eq.s32 	%p14, %r14, %r27;
	add.s64 	%rd125, %rd93, %rd112;
	add.s64 	%rd126, %rd125, %rd111;
	ld.global.nc.u32 	%r28, [%rd126];
	setp.lt.s32 	%p15, %r28, 0;
	add.s32 	%r29, %r28, 6;
	selp.b32 	%r30, %r29, %r28, %p15;
	max.s32 	%r31, %r30, 0;
	min.s32 	%r32, %r31, 5;
	mul.wide.u32 	%rd127, %r32, 4;
	add.s64 	%rd128, %rd92, %rd116;
	add.s64 	%rd129, %rd128, %rd118;
	add.s64 	%rd130, %rd129, %rd127;
	ld.global.nc.f32 	%f15, [%rd130];
	selp.f32 	%f16, %f15, 0f00000000, %p14;
	sub.rn.f32 	%f17, %f16, %f13;
	selp.f32 	%f18, 0f00000000, %f17, %p10;
	setp.eq.s32 	%p16, %r25, 1;
	selp.f32 	%f19, %f17, 0f00000000, %p16;
	setp.eq.s32 	%p17, %r25, %r6;
	selp.f32 	%f20, %f17, 0f00000000, %p17;
	add.s64 	%rd131, %rd84, %rd101;
	ld.global.nc.u32 	%r33, [%rd131];
	max.s32 	%r34, %r6, %r33;
	setp.gt.s32 	%p18, %r8, %r34;
	min.s32 	%r35, %r8, %r34;
	add.s64 	%rd132, %rd85, %rd101;
	ld.global.nc.f32 	%f21, [%rd132];
	setp.gt.f32 	%p19, %f21, 0f41800000;
	selp.u32 	%r36, 1, 0, %p19;
	setp.eq.s32 	%p20, %r6, %r36;
	add.s64 	%rd133, %rd86, %rd106;
	ld.global.nc.f32 	%f22, [%rd133];
	selp.f32 	%f23, %f22, 0f00000000, %p20;
	add.s64 	%rd134, %rd85, %rd108;
	ld.global.nc.f32 	%f24, [%rd134];
	setp.gt.f32 	%p21, %f24, 0f41800000;
	selp.u32 	%r37, 1, 0, %p21;
	setp.eq.s32 	%p22, %r14, %r37;
	add.s64 	%rd135, %rd88, %rd112;
	add.s64 	%rd136, %rd135, %rd111;
	ld.global.nc.u32 	%r38, [%rd136];
	setp.lt.s32 	%p23, %r38, 0;
	add.s32 	%r39, %r38, 6;
	selp.b32 	%r40, %r39, %r38, %p23;
	max.s32 	%r41, %r40, 0;
	min.s32 	%r42, %r41, 5;
	mul.wide.u32 	%rd137, %r42, 4;
	add.s64 	%rd138, %rd87, %rd116;
	add.s64 	%rd139, %rd138, %rd118;
	add.s64 	%rd140, %rd139, %rd137;
	ld.global.nc.f32 	%f25, [%rd140];
	selp.f32 	%f26, %f25, 0f00000000, %p22;
	sub.rn.f32 	%f27, %f26, %f23;
	selp.f32 	%f28, 0f00000000, %f27, %p18;
	setp.eq.s32 	%p24, %r35, 1;
	selp.f32 	%f29, %f27, 0f00000000, %p24;
	setp.eq.s32 	%p25, %r35, %r6;
	selp.f32 	%f30, %f27, 0f00000000, %p25;
	add.s64 	%rd141, %rd79, %rd101;
	ld.global.nc.u32 	%r43, [%rd141];
	max.s32 	%r44, %r6, %r43;
	setp.gt.s32 	%p26, %r8, %r44;
	min.s32 	%r45, %r8, %r44;
	add.s64 	%rd142, %rd80, %rd101;
	ld.global.nc.f32 	%f31, [%rd142];
	setp.gt.f32 	%p27, %f31, 0f41800000;
	selp.u32 	%r46, 1, 0, %p27;
	setp.eq.s32 	%p28, %r6, %r46;
	add.s64 	%rd143, %rd81, %rd106;
	ld.global.nc.f32 	%f32, [%rd143];
	selp.f32 	%f33, %f32, 0f00000000, %p28;
	add.s64 	%rd144, %rd80, %rd108;
	ld.global.nc.f32 	%f34, [%rd144];
	setp.gt.f32 	%p29, %f34, 0f41800000;
	selp.u32 	%r47, 1, 0, %p29;
	setp.eq.s32 	%p30, %r14, %r47;
	add.s64 	%rd145, %rd83, %rd112;
	add.s64 	%rd146, %rd145, %rd111;
	ld.global.nc.u32 	%r48, [%rd146];
	setp.lt.s32 	%p31, %r48, 0;
	add.s32 	%r49, %r48, 6;
	selp.b32 	%r50, %r49, %r48, %p31;
	max.s32 	%r51, %r50, 0;
	min.s32 	%r52, %r51, 5;
	mul.wide.u32 	%rd147, %r52, 4;
	add.s64 	%rd148, %rd82, %rd116;
	add.s64 	%rd149, %rd148, %rd118;
	add.s64 	%rd150, %rd149, %rd147;
	ld.global.nc.f32 	%f35, [%rd150];
	selp.f32 	%f36, %f35, 0f00000000, %p30;
	sub.rn.f32 	%f37, %f36, %f33;
	selp.f32 	%f38, 0f00000000, %f37, %p26;
	setp.eq.s32 	%p32, %r45, 1;
	selp.f32 	%f39, %f37, 0f00000000, %p32;
	setp.eq.s32 	%p33, %r45, %r6;
	selp.f32 	%f40, %f37, 0f00000000, %p33;
	add.s64 	%rd151, %rd72, %rd101;
	ld.global.nc.u32 	%r53, [%rd151];
	max.s32 	%r54, %r6, %r53;
	setp.gt.s32 	%p34, %r8, %r54;
	min.s32 	%r55, %r8, %r54;
	add.s64 	%rd152, %rd75, %rd101;
	ld.global.nc.f32 	%f41, [%rd152];
	setp.gt.f32 	%p35, %f41, 0f41800000;
	selp.u32 	%r56, 1, 0, %p35;
	setp.eq.s32 	%p36, %r6, %r56;
	add.s64 	%rd153, %rd76, %rd106;
	ld.global.nc.f32 	%f42, [%rd153];
	selp.f32 	%f43, %f42, 0f00000000, %p36;
	add.s64 	%rd154, %rd75, %rd108;
	ld.global.nc.f32 	%f44, [%rd154];
	setp.gt.f32 	%p37, %f44, 0f41800000;
	selp.u32 	%r57, 1, 0, %p37;
	setp.eq.s32 	%p38, %r14, %r57;
	add.s64 	%rd155, %rd78, %rd112;
	add.s64 	%rd156, %rd155, %rd111;
	ld.global.nc.u32 	%r58, [%rd156];
	setp.lt.s32 	%p39, %r58, 0;
	add.s32 	%r59, %r58, 6;
	selp.b32 	%r60, %r59, %r58, %p39;
	max.s32 	%r61, %r60, 0;
	min.s32 	%r62, %r61, 5;
	mul.wide.u32 	%rd157, %r62, 4;
	add.s64 	%rd158, %rd77, %rd116;
	add.s64 	%rd159, %rd158, %rd118;
	add.s64 	%rd160, %rd159, %rd157;
	ld.global.nc.f32 	%f45, [%rd160];
	selp.f32 	%f46, %f45, 0f00000000, %p38;
	sub.rn.f32 	%f47, %f46, %f43;
	selp.f32 	%f48, 0f00000000, %f47, %p34;
	setp.eq.s32 	%p40, %r55, 1;
	selp.f32 	%f49, %f47, 0f00000000, %p40;
	setp.eq.s32 	%p41, %r55, %r6;
	selp.f32 	%f50, %f47, 0f00000000, %p41;
	add.s64 	%rd161, %rd57, %rd101;
	ld.global.nc.u32 	%r63, [%rd161];
	max.s32 	%r64, %r6, %r63;
	setp.gt.s32 	%p42, %r8, %r64;
	min.s32 	%r65, %r8, %r64;
	add.s64 	%rd162, %rd60, %rd101;
	ld.global.nc.f32 	%f51, [%rd162];
	setp.gt.f32 	%p43, %f51, 0f41800000;
	selp.u32 	%r66, 1, 0, %p43;
	setp.eq.s32 	%p44, %r6, %r66;
	add.s64 	%rd163, %rd63, %rd106;
	ld.global.nc.f32 	%f52, [%rd163];
	selp.f32 	%f53, %f52, 0f00000000, %p44;
	add.s16 	%rs19, %rs8, %rs11;
	mul.hi.u16 	%rs21, %rs19, -21845;
	shr.u16 	%rs22, %rs21, 2;
	cvt.u32.u16 	%r67, %rs22;
	mul.wide.u32 	%rd164, %r67, 4;
	add.s64 	%rd165, %rd60, %rd164;
	ld.global.nc.f32 	%f54, [%rd165];
	setp.gt.f32 	%p45, %f54, 0f41800000;
	selp.u32 	%r68, 1, 0, %p45;
	add.s64 	%rd166, %rd99, %rd164;
	ld.global.nc.u32 	%r69, [%rd166];
	setp.eq.s32 	%p46, %r69, %r68;
	setp.gt.u16 	%p47, %rs19, 377;
	selp.b16 	%rs23, 63, %rs22, %p47;
	mul.lo.s16 	%rs24, %rs22, 6;
	sub.s16 	%rs25, %rs19, %rs24;
	cvt.u32.u16 	%r70, %rs25;
	mul.wide.u32 	%rd167, %r70, 4;
	mul.wide.u32 	%rd168, %r67, 24;
	add.s64 	%rd169, %rd69, %rd168;
	add.s64 	%rd170, %rd169, %rd167;
	ld.global.nc.u32 	%r71, [%rd170];
	setp.lt.s32 	%p48, %r71, 0;
	add.s32 	%r72, %r71, 6;
	selp.b32 	%r73, %r72, %r71, %p48;
	max.s32 	%r74, %r73, 0;
	min.s32 	%r75, %r74, 5;
	mul.wide.u32 	%rd171, %r75, 4;
	cvt.u32.u16 	%r76, %rs23;
	mul.wide.u32 	%rd172, %r76, 144;
	add.s64 	%rd173, %rd66, %rd172;
	cvt.u32.u16 	%r77, %rs10;
	mul.wide.u32 	%rd174, %r77, 24;
	add.s64 	%rd175, %rd173, %rd174;
	add.s64 	%rd176, %rd175, %rd171;
	ld.global.nc.f32 	%f55, [%rd176];
	selp.f32 	%f56, %f55, 0f00000000, %p46;
	sub.rn.f32 	%f57, %f56, %f53;
	selp.f32 	%f58, 0f00000000, %f57, %p42;
	setp.eq.s32 	%p49, %r65, 1;
	selp.f32 	%f59, %f57, 0f00000000, %p49;
	setp.eq.s32 	%p50, %r65, %r6;
	selp.f32 	%f60, %f57, 0f00000000, %p50;
	add.s64 	%rd177, %rd54, %rd106;
	st.global.f32 	[%rd177], %f8;
	add.s64 	%rd178, %rd51, %rd106;
	st.global.f32 	[%rd178], %f9;
	add.s64 	%rd179, %rd48, %rd106;
	st.global.f32 	[%rd179], %f10;
	add.s64 	%rd180, %rd45, %rd106;
	st.global.f32 	[%rd180], %f18;
	add.s64 	%rd181, %rd42, %rd106;
	st.global.f32 	[%rd181], %f19;
	add.s64 	%rd182, %rd39, %rd106;
	st.global.f32 	[%rd182], %f20;
	add.s64 	%rd183, %rd36, %rd106;
	st.global.f32 	[%rd183], %f28;
	add.s64 	%rd184, %rd33, %rd106;
	st.global.f32 	[%rd184], %f29;
	add.s64 	%rd185, %rd30, %rd106;
	st.global.f32 	[%rd185], %f30;
	add.s64 	%rd186, %rd27, %rd106;
	st.global.f32 	[%rd186], %f38;
	add.s64 	%rd187, %rd24, %rd106;
	st.global.f32 	[%rd187], %f39;
	add.s64 	%rd188, %rd21, %rd106;
	st.global.f32 	[%rd188], %f40;
	add.s64 	%rd189, %rd18, %rd106;
	st.global.f32 	[%rd189], %f48;
	add.s64 	%rd190, %rd15, %rd106;
	st.global.f32 	[%rd190], %f49;
	add.s64 	%rd191, %rd12, %rd106;
	st.global.f32 	[%rd191], %f50;
	add.s64 	%rd192, %rd9, %rd106;
	st.global.f32 	[%rd192], %f58;
	add.s64 	%rd193, %rd6, %rd106;
	st.global.f32 	[%rd193], %f59;
	add.s64 	%rd194, %rd3, %rd106;
	st.global.f32 	[%rd194], %f60;
	ret;

}
	// .globl	loop_add_fusion_411
.visible .entry loop_add_fusion_411(
	.param .u64 loop_add_fusion_411_param_0,
	.param .u64 loop_add_fusion_411_param_1,
	.param .u64 loop_add_fusion_411_param_2,
	.param .u64 loop_add_fusion_411_param_3,
	.param .u64 loop_add_fusion_411_param_4,
	.param .u64 loop_add_fusion_411_param_5,
	.param .u64 loop_add_fusion_411_param_6,
	.param .u64 loop_add_fusion_411_param_7,
	.param .u64 loop_add_fusion_411_param_8,
	.param .u64 loop_add_fusion_411_param_9,
	.param .u64 loop_add_fusion_411_param_10,
	.param .u64 loop_add_fusion_411_param_11,
	.param .u64 loop_add_fusion_411_param_12,
	.param .u64 loop_add_fusion_411_param_13,
	.param .u64 loop_add_fusion_411_param_14,
	.param .u64 loop_add_fusion_411_param_15,
	.param .u64 loop_add_fusion_411_param_16,
	.param .u64 loop_add_fusion_411_param_17,
	.param .u64 loop_add_fusion_411_param_18,
	.param .u64 loop_add_fusion_411_param_19,
	.param .u64 loop_add_fusion_411_param_20,
	.param .u64 loop_add_fusion_411_param_21,
	.param .u64 loop_add_fusion_411_param_22,
	.param .u64 loop_add_fusion_411_param_23,
	.param .u64 loop_add_fusion_411_param_24,
	.param .u64 loop_add_fusion_411_param_25,
	.param .u64 loop_add_fusion_411_param_26,
	.param .u64 loop_add_fusion_411_param_27,
	.param .u64 loop_add_fusion_411_param_28,
	.param .u64 loop_add_fusion_411_param_29,
	.param .u64 loop_add_fusion_411_param_30,
	.param .u64 loop_add_fusion_411_param_31,
	.param .u64 loop_add_fusion_411_param_32,
	.param .u64 loop_add_fusion_411_param_33,
	.param .u64 loop_add_fusion_411_param_34,
	.param .u64 loop_add_fusion_411_param_35,
	.param .u64 loop_add_fusion_411_param_36
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<33>;
	.reg .b16 	%rs<26>;
	.reg .b32 	%r<63>;
	.reg .f32 	%f<56>;
	.reg .b64 	%rd<169>;

	ld.param.u64 	%rd1, [loop_add_fusion_411_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_411_param_36];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_411_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_411_param_35];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_411_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_411_param_34];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_411_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_411_param_33];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_411_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_411_param_32];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_411_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_411_param_31];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_411_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_411_param_30];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_411_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_411_param_29];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_add_fusion_411_param_8];
	ld.param.u64 	%rd26, [loop_add_fusion_411_param_28];
	cvta.to.global.u64 	%rd27, %rd26;
	ld.param.u64 	%rd28, [loop_add_fusion_411_param_9];
	ld.param.u64 	%rd29, [loop_add_fusion_411_param_27];
	cvta.to.global.u64 	%rd30, %rd29;
	ld.param.u64 	%rd31, [loop_add_fusion_411_param_10];
	ld.param.u64 	%rd32, [loop_add_fusion_411_param_26];
	cvta.to.global.u64 	%rd33, %rd32;
	ld.param.u64 	%rd34, [loop_add_fusion_411_param_11];
	ld.param.u64 	%rd35, [loop_add_fusion_411_param_25];
	cvta.to.global.u64 	%rd36, %rd35;
	ld.param.u64 	%rd37, [loop_add_fusion_411_param_12];
	ld.param.u64 	%rd38, [loop_add_fusion_411_param_24];
	cvta.to.global.u64 	%rd39, %rd38;
	ld.param.u64 	%rd40, [loop_add_fusion_411_param_13];
	ld.param.u64 	%rd41, [loop_add_fusion_411_param_23];
	cvta.to.global.u64 	%rd42, %rd41;
	ld.param.u64 	%rd43, [loop_add_fusion_411_param_14];
	ld.param.u64 	%rd44, [loop_add_fusion_411_param_22];
	cvta.to.global.u64 	%rd45, %rd44;
	ld.param.u64 	%rd46, [loop_add_fusion_411_param_15];
	ld.param.u64 	%rd47, [loop_add_fusion_411_param_21];
	cvta.to.global.u64 	%rd48, %rd47;
	ld.param.u64 	%rd49, [loop_add_fusion_411_param_16];
	ld.param.u64 	%rd50, [loop_add_fusion_411_param_20];
	cvta.to.global.u64 	%rd51, %rd50;
	ld.param.u64 	%rd52, [loop_add_fusion_411_param_17];
	ld.param.u64 	%rd53, [loop_add_fusion_411_param_19];
	cvta.to.global.u64 	%rd54, %rd53;
	ld.param.u64 	%rd55, [loop_add_fusion_411_param_18];
	cvta.to.global.u64 	%rd56, %rd55;
	cvta.to.global.u64 	%rd57, %rd52;
	cvta.to.global.u64 	%rd58, %rd49;
	cvta.to.global.u64 	%rd59, %rd46;
	cvta.to.global.u64 	%rd60, %rd43;
	cvta.to.global.u64 	%rd61, %rd40;
	cvta.to.global.u64 	%rd62, %rd37;
	cvta.to.global.u64 	%rd63, %rd34;
	cvta.to.global.u64 	%rd64, %rd31;
	cvta.to.global.u64 	%rd65, %rd28;
	cvta.to.global.u64 	%rd66, %rd25;
	cvta.to.global.u64 	%rd67, %rd22;
	cvta.to.global.u64 	%rd68, %rd19;
	cvta.to.global.u64 	%rd69, %rd16;
	cvta.to.global.u64 	%rd70, %rd13;
	cvta.to.global.u64 	%rd71, %rd10;
	cvta.to.global.u64 	%rd72, %rd7;
	cvta.to.global.u64 	%rd73, %rd4;
	cvta.to.global.u64 	%rd74, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r5, %rs3;
	mul.wide.u32 	%rd75, %r5, 4;
	add.s64 	%rd76, %rd72, %rd75;
	ld.global.nc.u32 	%r6, [%rd76];
	add.s64 	%rd77, %rd69, %rd75;
	ld.global.nc.u32 	%r7, [%rd77];
	add.s64 	%rd78, %rd70, %rd75;
	ld.global.nc.u32 	%r8, [%rd78];
	max.s32 	%r9, %r6, %r7;
	setp.gt.s32 	%p1, %r8, %r9;
	add.s64 	%rd79, %rd71, %rd75;
	ld.global.nc.f32 	%f1, [%rd79];
	setp.gt.f32 	%p2, %f1, 0f41800000;
	selp.u32 	%r10, 1, 0, %p2;
	setp.eq.s32 	%p3, %r6, %r10;
	cvt.u32.u16 	%r11, %rs10;
	mul.wide.u32 	%rd80, %r11, 24;
	mul.wide.u32 	%rd81, %r5, 144;
	add.s64 	%rd82, %rd73, %rd81;
	add.s64 	%rd83, %rd82, %rd80;
	cvt.u32.u16 	%r12, %rs8;
	mul.wide.u32 	%rd84, %r12, 4;
	add.s64 	%rd85, %rd83, %rd84;
	ld.global.nc.f32 	%f2, [%rd85];
	selp.f32 	%f3, %f2, 0f00000000, %p3;
	mul.lo.s16 	%rs11, %rs3, 6;
	add.s16 	%rs12, %rs8, %rs11;
	mul.hi.u16 	%rs14, %rs12, -21845;
	shr.u16 	%rs15, %rs14, 2;
	cvt.u32.u16 	%r13, %rs15;
	mul.wide.u32 	%rd86, %r13, 4;
	add.s64 	%rd87, %rd71, %rd86;
	ld.global.nc.f32 	%f4, [%rd87];
	setp.gt.f32 	%p4, %f4, 0f41800000;
	selp.u32 	%r14, 1, 0, %p4;
	add.s64 	%rd88, %rd72, %rd86;
	ld.global.nc.u32 	%r15, [%rd88];
	setp.eq.s32 	%p5, %r15, %r14;
	setp.gt.u16 	%p6, %rs12, 377;
	selp.b16 	%rs16, 63, %rs15, %p6;
	mul.lo.s16 	%rs17, %rs15, 6;
	sub.s16 	%rs18, %rs12, %rs17;
	cvt.u32.u16 	%r16, %rs18;
	mul.wide.u32 	%rd89, %r16, 4;
	mul.wide.u32 	%rd90, %r13, 24;
	add.s64 	%rd91, %rd68, %rd90;
	add.s64 	%rd92, %rd91, %rd89;
	ld.global.nc.u32 	%r17, [%rd92];
	setp.lt.s32 	%p7, %r17, 0;
	add.s32 	%r18, %r17, 6;
	selp.b32 	%r19, %r18, %r17, %p7;
	max.s32 	%r20, %r19, 0;
	min.s32 	%r21, %r20, 5;
	mul.wide.u32 	%rd93, %r21, 4;
	cvt.u32.u16 	%r22, %rs16;
	mul.wide.u32 	%rd94, %r22, 144;
	add.s64 	%rd95, %rd67, %rd94;
	add.s64 	%rd96, %rd95, %rd80;
	add.s64 	%rd97, %rd96, %rd93;
	ld.global.nc.f32 	%f5, [%rd97];
	selp.f32 	%f6, %f5, 0f00000000, %p5;
	add.rn.f32 	%f7, %f3, %f6;
	mul.rn.f32 	%f8, %f7, 0f42600000;
	selp.f32 	%f9, 0f00000000, %f8, %p1;
	mul.wide.u32 	%rd98, %r12, 72;
	mul.wide.u32 	%rd99, %r5, 432;
	add.s64 	%rd100, %rd74, %rd99;
	add.s64 	%rd101, %rd100, %rd98;
	mul.wide.u32 	%rd102, %r11, 4;
	add.s64 	%rd103, %rd101, %rd102;
	ld.global.nc.f32 	%f10, [%rd103];
	add.rn.f32 	%f11, %f10, %f9;
	add.s64 	%rd104, %rd61, %rd75;
	ld.global.nc.u32 	%r23, [%rd104];
	max.s32 	%r24, %r6, %r23;
	setp.gt.s32 	%p8, %r8, %r24;
	add.s64 	%rd105, %rd62, %rd75;
	ld.global.nc.f32 	%f12, [%rd105];
	setp.gt.f32 	%p9, %f12, 0f41800000;
	selp.u32 	%r25, 1, 0, %p9;
	setp.eq.s32 	%p10, %r6, %r25;
	mul.wide.u32 	%rd106, %r4, 4;
	add.s64 	%rd107, %rd63, %rd106;
	ld.global.nc.f32 	%f13, [%rd107];
	selp.f32 	%f14, %f13, 0f00000000, %p10;
	add.s16 	%rs19, %rs11, %rs10;
	mul.hi.u16 	%rs21, %rs19, -21845;
	shr.u16 	%rs22, %rs21, 2;
	cvt.u32.u16 	%r26, %rs22;
	mul.wide.u32 	%rd108, %r26, 4;
	add.s64 	%rd109, %rd62, %rd108;
	ld.global.nc.f32 	%f15, [%rd109];
	setp.gt.f32 	%p11, %f15, 0f41800000;
	selp.u32 	%r27, 1, 0, %p11;
	add.s64 	%rd110, %rd72, %rd108;
	ld.global.nc.u32 	%r28, [%rd110];
	setp.eq.s32 	%p12, %r28, %r27;
	setp.gt.u16 	%p13, %rs19, 377;
	selp.b16 	%rs23, 63, %rs22, %p13;
	mul.lo.s16 	%rs24, %rs22, 6;
	sub.s16 	%rs25, %rs19, %rs24;
	cvt.u32.u16 	%r29, %rs25;
	mul.wide.u32 	%rd111, %r29, 4;
	mul.wide.u32 	%rd112, %r26, 24;
	add.s64 	%rd113, %rd65, %rd112;
	add.s64 	%rd114, %rd113, %rd111;
	ld.global.nc.u32 	%r30, [%rd114];
	setp.lt.s32 	%p14, %r30, 0;
	add.s32 	%r31, %r30, 6;
	selp.b32 	%r32, %r31, %r30, %p14;
	max.s32 	%r33, %r32, 0;
	min.s32 	%r34, %r33, 5;
	mul.wide.u32 	%rd115, %r34, 4;
	cvt.u32.u16 	%r35, %rs23;
	mul.wide.u32 	%rd116, %r35, 144;
	add.s64 	%rd117, %rd64, %rd116;
	mul.wide.u32 	%rd118, %r12, 24;
	add.s64 	%rd119, %rd117, %rd118;
	add.s64 	%rd120, %rd119, %rd115;
	ld.global.nc.f32 	%f16, [%rd120];
	selp.f32 	%f17, %f16, 0f00000000, %p12;
	add.rn.f32 	%f18, %f14, %f17;
	mul.rn.f32 	%f19, %f18, 0f42600000;
	selp.f32 	%f20, 0f00000000, %f19, %p8;
	mul.wide.u32 	%rd121, %r11, 72;
	add.s64 	%rd122, %rd66, %rd99;
	add.s64 	%rd123, %rd122, %rd121;
	add.s64 	%rd124, %rd123, %rd84;
	ld.global.nc.f32 	%f21, [%rd124];
	add.rn.f32 	%f22, %f21, %f20;
	add.s64 	%rd125, %rd54, %rd75;
	ld.global.nc.u32 	%r36, [%rd125];
	max.s32 	%r37, %r6, %r36;
	setp.gt.s32 	%p15, %r8, %r37;
	add.s64 	%rd126, %rd56, %rd75;
	ld.global.nc.f32 	%f23, [%rd126];
	setp.gt.f32 	%p16, %f23, 0f41800000;
	selp.u32 	%r38, 1, 0, %p16;
	setp.eq.s32 	%p17, %r6, %r38;
	add.s64 	%rd127, %rd57, %rd106;
	ld.global.nc.f32 	%f24, [%rd127];
	selp.f32 	%f25, %f24, 0f00000000, %p17;
	add.s64 	%rd128, %rd56, %rd108;
	ld.global.nc.f32 	%f26, [%rd128];
	setp.gt.f32 	%p18, %f26, 0f41800000;
	selp.u32 	%r39, 1, 0, %p18;
	setp.eq.s32 	%p19, %r28, %r39;
	add.s64 	%rd129, %rd59, %rd112;
	add.s64 	%rd130, %rd129, %rd111;
	ld.global.nc.u32 	%r40, [%rd130];
	setp.lt.s32 	%p20, %r40, 0;
	add.s32 	%r41, %r40, 6;
	selp.b32 	%r42, %r41, %r40, %p20;
	max.s32 	%r43, %r42, 0;
	min.s32 	%r44, %r43, 5;
	mul.wide.u32 	%rd131, %r44, 4;
	add.s64 	%rd132, %rd58, %rd116;
	add.s64 	%rd133, %rd132, %rd118;
	add.s64 	%rd134, %rd133, %rd131;
	ld.global.nc.f32 	%f27, [%rd134];
	selp.f32 	%f28, %f27, 0f00000000, %p19;
	add.rn.f32 	%f29, %f25, %f28;
	mul.rn.f32 	%f30, %f29, 0f42600000;
	selp.f32 	%f31, 0f00000000, %f30, %p15;
	add.s64 	%rd135, %rd60, %rd99;
	add.s64 	%rd136, %rd135, %rd121;
	add.s64 	%rd137, %rd136, %rd84;
	ld.global.nc.f32 	%f32, [%rd137];
	add.rn.f32 	%f33, %f32, %f31;
	add.s64 	%rd138, %rd36, %rd75;
	ld.global.nc.u32 	%r45, [%rd138];
	max.s32 	%r46, %r6, %r45;
	setp.gt.s32 	%p21, %r8, %r46;
	add.s64 	%rd139, %rd39, %rd75;
	ld.global.nc.f32 	%f34, [%rd139];
	setp.gt.f32 	%p22, %f34, 0f41800000;
	selp.u32 	%r47, 1, 0, %p22;
	setp.eq.s32 	%p23, %r6, %r47;
	add.s64 	%rd140, %rd42, %rd106;
	ld.global.nc.f32 	%f35, [%rd140];
	selp.f32 	%f36, %f35, 0f00000000, %p23;
	add.s64 	%rd141, %rd39, %rd108;
	ld.global.nc.f32 	%f37, [%rd141];
	setp.gt.f32 	%p24, %f37, 0f41800000;
	selp.u32 	%r48, 1, 0, %p24;
	setp.eq.s32 	%p25, %r28, %r48;
	add.s64 	%rd142, %rd48, %rd112;
	add.s64 	%rd143, %rd142, %rd111;
	ld.global.nc.u32 	%r49, [%rd143];
	setp.lt.s32 	%p26, %r49, 0;
	add.s32 	%r50, %r49, 6;
	selp.b32 	%r51, %r50, %r49, %p26;
	max.s32 	%r52, %r51, 0;
	min.s32 	%r53, %r52, 5;
	mul.wide.u32 	%rd144, %r53, 4;
	add.s64 	%rd145, %rd45, %rd116;
	add.s64 	%rd146, %rd145, %rd118;
	add.s64 	%rd147, %rd146, %rd144;
	ld.global.nc.f32 	%f38, [%rd147];
	selp.f32 	%f39, %f38, 0f00000000, %p25;
	add.rn.f32 	%f40, %f36, %f39;
	mul.rn.f32 	%f41, %f40, 0f42600000;
	selp.f32 	%f42, 0f00000000, %f41, %p21;
	add.s64 	%rd148, %rd51, %rd99;
	add.s64 	%rd149, %rd148, %rd121;
	add.s64 	%rd150, %rd149, %rd84;
	ld.global.nc.f32 	%f43, [%rd150];
	add.rn.f32 	%f44, %f43, %f42;
	add.s64 	%rd151, %rd18, %rd75;
	ld.global.nc.u32 	%r54, [%rd151];
	max.s32 	%r55, %r6, %r54;
	setp.gt.s32 	%p27, %r8, %r55;
	add.s64 	%rd152, %rd21, %rd75;
	ld.global.nc.f32 	%f45, [%rd152];
	setp.gt.f32 	%p28, %f45, 0f41800000;
	selp.u32 	%r56, 1, 0, %p28;
	setp.eq.s32 	%p29, %r6, %r56;
	add.s64 	%rd153, %rd24, %rd106;
	ld.global.nc.f32 	%f46, [%rd153];
	selp.f32 	%f47, %f46, 0f00000000, %p29;
	add.s64 	%rd154, %rd21, %rd108;
	ld.global.nc.f32 	%f48, [%rd154];
	setp.gt.f32 	%p30, %f48, 0f41800000;
	selp.u32 	%r57, 1, 0, %p30;
	setp.eq.s32 	%p31, %r28, %r57;
	add.s64 	%rd155, %rd30, %rd112;
	add.s64 	%rd156, %rd155, %rd111;
	ld.global.nc.u32 	%r58, [%rd156];
	setp.lt.s32 	%p32, %r58, 0;
	add.s32 	%r59, %r58, 6;
	selp.b32 	%r60, %r59, %r58, %p32;
	max.s32 	%r61, %r60, 0;
	min.s32 	%r62, %r61, 5;
	mul.wide.u32 	%rd157, %r62, 4;
	add.s64 	%rd158, %rd27, %rd116;
	add.s64 	%rd159, %rd158, %rd118;
	add.s64 	%rd160, %rd159, %rd157;
	ld.global.nc.f32 	%f49, [%rd160];
	selp.f32 	%f50, %f49, 0f00000000, %p31;
	add.rn.f32 	%f51, %f47, %f50;
	mul.rn.f32 	%f52, %f51, 0f42600000;
	selp.f32 	%f53, 0f00000000, %f52, %p27;
	add.s64 	%rd161, %rd33, %rd99;
	add.s64 	%rd162, %rd161, %rd121;
	add.s64 	%rd163, %rd162, %rd84;
	ld.global.nc.f32 	%f54, [%rd163];
	add.rn.f32 	%f55, %f54, %f53;
	add.s64 	%rd164, %rd15, %rd106;
	st.global.f32 	[%rd164], %f11;
	add.s64 	%rd165, %rd12, %rd106;
	st.global.f32 	[%rd165], %f22;
	add.s64 	%rd166, %rd9, %rd106;
	st.global.f32 	[%rd166], %f33;
	add.s64 	%rd167, %rd6, %rd106;
	st.global.f32 	[%rd167], %f44;
	add.s64 	%rd168, %rd3, %rd106;
	st.global.f32 	[%rd168], %f55;
	ret;

}
	// .globl	wrapped_concatenate_35
.visible .entry wrapped_concatenate_35(
	.param .u64 wrapped_concatenate_35_param_0,
	.param .u64 wrapped_concatenate_35_param_1,
	.param .u64 wrapped_concatenate_35_param_2,
	.param .u64 wrapped_concatenate_35_param_3
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<4>;
	.reg .b64 	%rd<19>;

	ld.param.u64 	%rd1, [wrapped_concatenate_35_param_0];
	ld.param.u64 	%rd2, [wrapped_concatenate_35_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [wrapped_concatenate_35_param_1];
	ld.param.u64 	%rd5, [wrapped_concatenate_35_param_2];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	mul.wide.u32 	%rd9, %r4, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	cvt.u32.u16 	%r5, %rs8;
	mul.wide.u32 	%rd11, %r5, 72;
	cvt.u32.u16 	%r6, %rs10;
	mul.wide.u32 	%rd12, %r6, 432;
	add.s64 	%rd13, %rd3, %rd12;
	add.s64 	%rd14, %rd13, %rd11;
	cvt.u32.u16 	%r7, %rs5;
	mul.wide.u32 	%rd15, %r7, 4;
	add.s64 	%rd16, %rd14, %rd15;
	st.global.f32 	[%rd16], %f1;
	add.s64 	%rd17, %rd7, %rd9;
	ld.global.nc.f32 	%f2, [%rd17];
	st.global.f32 	[%rd16+24], %f2;
	add.s64 	%rd18, %rd6, %rd9;
	ld.global.nc.f32 	%f3, [%rd18];
	st.global.f32 	[%rd16+48], %f3;
	ret;

}
	// .globl	wrapped_dot_122
.visible .entry wrapped_dot_122(
	.param .u64 wrapped_dot_122_param_0,
	.param .u64 wrapped_dot_122_param_1,
	.param .u64 wrapped_dot_122_param_2
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<25>;
	.reg .b64 	%rd<16>;

	ld.param.u64 	%rd1, [wrapped_dot_122_param_0];
	ld.param.u64 	%rd2, [wrapped_dot_122_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [wrapped_dot_122_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs8;
	mul.wide.u32 	%rd7, %r5, 4;
	cvt.u32.u16 	%r6, %rs10;
	mul.wide.u32 	%rd8, %r6, 144;
	add.s64 	%rd9, %rd6, %rd8;
	add.s64 	%rd10, %rd9, %rd7;
	ld.global.nc.f32 	%f1, [%rd10];
	cvt.u32.u16 	%r7, %rs5;
	mul.wide.u32 	%rd11, %r7, 24;
	add.s64 	%rd12, %rd5, %rd8;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.nc.v2.f32 	{%f2, %f3}, [%rd13];
	mul.rn.f32 	%f4, %f1, %f2;
	add.rn.f32 	%f5, %f4, 0f00000000;
	ld.global.nc.f32 	%f6, [%rd10+24];
	mul.rn.f32 	%f7, %f6, %f3;
	add.rn.f32 	%f8, %f5, %f7;
	ld.global.nc.f32 	%f9, [%rd10+48];
	ld.global.nc.v2.f32 	{%f10, %f11}, [%rd13+8];
	mul.rn.f32 	%f12, %f9, %f10;
	add.rn.f32 	%f13, %f8, %f12;
	ld.global.nc.f32 	%f14, [%rd10+72];
	mul.rn.f32 	%f15, %f14, %f11;
	add.rn.f32 	%f16, %f13, %f15;
	ld.global.nc.f32 	%f17, [%rd10+96];
	ld.global.nc.v2.f32 	{%f18, %f19}, [%rd13+16];
	mul.rn.f32 	%f20, %f17, %f18;
	add.rn.f32 	%f21, %f16, %f20;
	ld.global.nc.f32 	%f22, [%rd10+120];
	mul.rn.f32 	%f23, %f22, %f19;
	add.rn.f32 	%f24, %f21, %f23;
	mul.wide.u32 	%rd14, %r4, 4;
	add.s64 	%rd15, %rd3, %rd14;
	st.global.f32 	[%rd15], %f24;
	ret;

}
	// .globl	loop_add_fusion_412
.visible .entry loop_add_fusion_412(
	.param .u64 loop_add_fusion_412_param_0,
	.param .u64 loop_add_fusion_412_param_1,
	.param .u64 loop_add_fusion_412_param_2,
	.param .u64 loop_add_fusion_412_param_3,
	.param .u64 loop_add_fusion_412_param_4,
	.param .u64 loop_add_fusion_412_param_5,
	.param .u64 loop_add_fusion_412_param_6,
	.param .u64 loop_add_fusion_412_param_7,
	.param .u64 loop_add_fusion_412_param_8,
	.param .u64 loop_add_fusion_412_param_9,
	.param .u64 loop_add_fusion_412_param_10,
	.param .u64 loop_add_fusion_412_param_11,
	.param .u64 loop_add_fusion_412_param_12,
	.param .u64 loop_add_fusion_412_param_13,
	.param .u64 loop_add_fusion_412_param_14,
	.param .u64 loop_add_fusion_412_param_15,
	.param .u64 loop_add_fusion_412_param_16,
	.param .u64 loop_add_fusion_412_param_17,
	.param .u64 loop_add_fusion_412_param_18,
	.param .u64 loop_add_fusion_412_param_19,
	.param .u64 loop_add_fusion_412_param_20,
	.param .u64 loop_add_fusion_412_param_21,
	.param .u64 loop_add_fusion_412_param_22,
	.param .u64 loop_add_fusion_412_param_23,
	.param .u64 loop_add_fusion_412_param_24,
	.param .u64 loop_add_fusion_412_param_25,
	.param .u64 loop_add_fusion_412_param_26,
	.param .u64 loop_add_fusion_412_param_27,
	.param .u64 loop_add_fusion_412_param_28,
	.param .u64 loop_add_fusion_412_param_29,
	.param .u64 loop_add_fusion_412_param_30,
	.param .u64 loop_add_fusion_412_param_31,
	.param .u64 loop_add_fusion_412_param_32,
	.param .u64 loop_add_fusion_412_param_33,
	.param .u64 loop_add_fusion_412_param_34,
	.param .u64 loop_add_fusion_412_param_35,
	.param .u64 loop_add_fusion_412_param_36,
	.param .u64 loop_add_fusion_412_param_37,
	.param .u64 loop_add_fusion_412_param_38,
	.param .u64 loop_add_fusion_412_param_39,
	.param .u64 loop_add_fusion_412_param_40,
	.param .u64 loop_add_fusion_412_param_41,
	.param .u64 loop_add_fusion_412_param_42,
	.param .u64 loop_add_fusion_412_param_43,
	.param .u64 loop_add_fusion_412_param_44,
	.param .u64 loop_add_fusion_412_param_45,
	.param .u64 loop_add_fusion_412_param_46,
	.param .u64 loop_add_fusion_412_param_47,
	.param .u64 loop_add_fusion_412_param_48,
	.param .u64 loop_add_fusion_412_param_49,
	.param .u64 loop_add_fusion_412_param_50,
	.param .u64 loop_add_fusion_412_param_51,
	.param .u64 loop_add_fusion_412_param_52
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<45>;
	.reg .b16 	%rs<22>;
	.reg .b32 	%r<81>;
	.reg .f32 	%f<106>;
	.reg .b64 	%rd<230>;

	ld.param.u64 	%rd1, [loop_add_fusion_412_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_412_param_52];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_412_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_412_param_51];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_412_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_412_param_50];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_412_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_412_param_49];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_412_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_412_param_48];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_412_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_412_param_47];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_412_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_412_param_46];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_412_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_412_param_45];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_add_fusion_412_param_8];
	ld.param.u64 	%rd26, [loop_add_fusion_412_param_44];
	cvta.to.global.u64 	%rd27, %rd26;
	ld.param.u64 	%rd28, [loop_add_fusion_412_param_9];
	ld.param.u64 	%rd29, [loop_add_fusion_412_param_43];
	cvta.to.global.u64 	%rd30, %rd29;
	ld.param.u64 	%rd31, [loop_add_fusion_412_param_10];
	ld.param.u64 	%rd32, [loop_add_fusion_412_param_42];
	cvta.to.global.u64 	%rd33, %rd32;
	ld.param.u64 	%rd34, [loop_add_fusion_412_param_11];
	ld.param.u64 	%rd35, [loop_add_fusion_412_param_41];
	cvta.to.global.u64 	%rd36, %rd35;
	ld.param.u64 	%rd37, [loop_add_fusion_412_param_12];
	ld.param.u64 	%rd38, [loop_add_fusion_412_param_40];
	cvta.to.global.u64 	%rd39, %rd38;
	ld.param.u64 	%rd40, [loop_add_fusion_412_param_13];
	ld.param.u64 	%rd41, [loop_add_fusion_412_param_39];
	cvta.to.global.u64 	%rd42, %rd41;
	ld.param.u64 	%rd43, [loop_add_fusion_412_param_14];
	ld.param.u64 	%rd44, [loop_add_fusion_412_param_38];
	cvta.to.global.u64 	%rd45, %rd44;
	ld.param.u64 	%rd46, [loop_add_fusion_412_param_15];
	ld.param.u64 	%rd47, [loop_add_fusion_412_param_37];
	cvta.to.global.u64 	%rd48, %rd47;
	ld.param.u64 	%rd49, [loop_add_fusion_412_param_16];
	ld.param.u64 	%rd50, [loop_add_fusion_412_param_36];
	cvta.to.global.u64 	%rd51, %rd50;
	ld.param.u64 	%rd52, [loop_add_fusion_412_param_17];
	ld.param.u64 	%rd53, [loop_add_fusion_412_param_35];
	cvta.to.global.u64 	%rd54, %rd53;
	ld.param.u64 	%rd55, [loop_add_fusion_412_param_18];
	ld.param.u64 	%rd56, [loop_add_fusion_412_param_34];
	cvta.to.global.u64 	%rd57, %rd56;
	ld.param.u64 	%rd58, [loop_add_fusion_412_param_19];
	ld.param.u64 	%rd59, [loop_add_fusion_412_param_33];
	cvta.to.global.u64 	%rd60, %rd59;
	ld.param.u64 	%rd61, [loop_add_fusion_412_param_20];
	ld.param.u64 	%rd62, [loop_add_fusion_412_param_32];
	cvta.to.global.u64 	%rd63, %rd62;
	ld.param.u64 	%rd64, [loop_add_fusion_412_param_21];
	ld.param.u64 	%rd65, [loop_add_fusion_412_param_31];
	cvta.to.global.u64 	%rd66, %rd65;
	ld.param.u64 	%rd67, [loop_add_fusion_412_param_22];
	ld.param.u64 	%rd68, [loop_add_fusion_412_param_30];
	cvta.to.global.u64 	%rd69, %rd68;
	ld.param.u64 	%rd70, [loop_add_fusion_412_param_23];
	ld.param.u64 	%rd71, [loop_add_fusion_412_param_29];
	cvta.to.global.u64 	%rd72, %rd71;
	ld.param.u64 	%rd73, [loop_add_fusion_412_param_24];
	ld.param.u64 	%rd74, [loop_add_fusion_412_param_28];
	cvta.to.global.u64 	%rd75, %rd74;
	ld.param.u64 	%rd76, [loop_add_fusion_412_param_25];
	ld.param.u64 	%rd77, [loop_add_fusion_412_param_27];
	cvta.to.global.u64 	%rd78, %rd77;
	ld.param.u64 	%rd79, [loop_add_fusion_412_param_26];
	cvta.to.global.u64 	%rd80, %rd79;
	cvta.to.global.u64 	%rd81, %rd76;
	cvta.to.global.u64 	%rd82, %rd73;
	cvta.to.global.u64 	%rd83, %rd70;
	cvta.to.global.u64 	%rd84, %rd67;
	cvta.to.global.u64 	%rd85, %rd64;
	cvta.to.global.u64 	%rd86, %rd61;
	cvta.to.global.u64 	%rd87, %rd58;
	cvta.to.global.u64 	%rd88, %rd55;
	cvta.to.global.u64 	%rd89, %rd52;
	cvta.to.global.u64 	%rd90, %rd49;
	cvta.to.global.u64 	%rd91, %rd46;
	cvta.to.global.u64 	%rd92, %rd43;
	cvta.to.global.u64 	%rd93, %rd40;
	cvta.to.global.u64 	%rd94, %rd37;
	cvta.to.global.u64 	%rd95, %rd34;
	cvta.to.global.u64 	%rd96, %rd31;
	cvta.to.global.u64 	%rd97, %rd28;
	cvta.to.global.u64 	%rd98, %rd25;
	cvta.to.global.u64 	%rd99, %rd22;
	cvta.to.global.u64 	%rd100, %rd19;
	cvta.to.global.u64 	%rd101, %rd16;
	cvta.to.global.u64 	%rd102, %rd13;
	cvta.to.global.u64 	%rd103, %rd10;
	cvta.to.global.u64 	%rd104, %rd7;
	cvta.to.global.u64 	%rd105, %rd4;
	cvta.to.global.u64 	%rd106, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	cvt.u32.u16 	%r5, %rs8;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r6, %rs10;
	cvt.u32.u16 	%r7, %rs3;
	mul.wide.u32 	%rd107, %r7, 4;
	add.s64 	%rd108, %rd103, %rd107;
	ld.global.nc.u32 	%r8, [%rd108];
	add.s64 	%rd109, %rd102, %rd107;
	ld.global.nc.u32 	%r9, [%rd109];
	add.s64 	%rd110, %rd104, %rd107;
	ld.global.nc.u32 	%r10, [%rd110];
	max.s32 	%r11, %r8, %r9;
	setp.gt.s32 	%p1, %r10, %r11;
	min.s32 	%r12, %r10, %r11;
	add.s64 	%rd111, %rd100, %rd107;
	ld.global.nc.f32 	%f1, [%rd111];
	setp.gt.f32 	%p2, %f1, 0f41800000;
	selp.u32 	%r13, 1, 0, %p2;
	setp.eq.s32 	%p3, %r8, %r13;
	mul.wide.u32 	%rd112, %r4, 4;
	add.s64 	%rd113, %rd101, %rd112;
	ld.global.nc.f32 	%f2, [%rd113];
	selp.f32 	%f3, %f2, 0f00000000, %p3;
	mul.lo.s16 	%rs11, %rs3, 6;
	cvt.u32.u16 	%r14, %rs11;
	add.s32 	%r15, %r14, %r6;
	cvt.u16.u32 	%rs12, %r15;
	mul.hi.u16 	%rs13, %rs12, -21845;
	shr.u16 	%rs14, %rs13, 2;
	cvt.u64.u16 	%rd114, %rs14;
	cvt.u32.u16 	%r17, %rs14;
	mul.wide.u32 	%rd115, %r17, 4;
	add.s64 	%rd116, %rd100, %rd115;
	ld.global.nc.f32 	%f4, [%rd116];
	setp.gt.f32 	%p4, %f4, 0f41800000;
	selp.u32 	%r18, 1, 0, %p4;
	add.s64 	%rd117, %rd103, %rd115;
	ld.global.nc.u32 	%r19, [%rd117];
	setp.eq.s32 	%p5, %r19, %r18;
	setp.gt.u32 	%p6, %r15, 377;
	selp.b64 	%rd118, 63, %rd114, %p6;
	mul.lo.s16 	%rs15, %rs14, 6;
	sub.s16 	%rs16, %rs12, %rs15;
	cvt.u32.u16 	%r20, %rs16;
	mul.wide.u32 	%rd119, %r20, 4;
	mul.wide.u32 	%rd120, %r17, 24;
	add.s64 	%rd121, %rd99, %rd120;
	add.s64 	%rd122, %rd121, %rd119;
	ld.global.nc.u32 	%r21, [%rd122];
	setp.lt.s32 	%p7, %r21, 0;
	add.s32 	%r22, %r21, 6;
	selp.b32 	%r23, %r22, %r21, %p7;
	max.s32 	%r24, %r23, 0;
	min.s32 	%r25, %r24, 5;
	mul.wide.u32 	%rd123, %r25, 4;
	mul.lo.s64 	%rd124, %rd118, 144;
	add.s64 	%rd125, %rd98, %rd124;
	mul.wide.u32 	%rd126, %r5, 24;
	add.s64 	%rd127, %rd125, %rd126;
	add.s64 	%rd128, %rd127, %rd123;
	ld.global.nc.f32 	%f5, [%rd128];
	selp.f32 	%f6, %f5, 0f00000000, %p5;
	add.rn.f32 	%f7, %f3, %f6;
	mul.rn.f32 	%f8, %f7, 0f46C4E000;
	selp.f32 	%f9, 0f00000000, %f8, %p1;
	mul.wide.u32 	%rd129, %r6, 72;
	mul.wide.u32 	%rd130, %r7, 432;
	add.s64 	%rd131, %rd105, %rd130;
	add.s64 	%rd132, %rd131, %rd129;
	mul.wide.u32 	%rd133, %r5, 4;
	add.s64 	%rd134, %rd132, %rd133;
	ld.global.nc.f32 	%f10, [%rd134];
	mul.rn.f32 	%f11, %f10, 0f44BD0000;
	add.rn.f32 	%f12, %f11, %f9;
	add.s64 	%rd135, %rd106, %rd112;
	ld.global.nc.f32 	%f13, [%rd135];
	add.rn.f32 	%f14, %f13, %f12;
	setp.eq.s32 	%p8, %r12, 1;
	mul.rn.f32 	%f15, %f7, 0f41F00000;
	selp.f32 	%f16, %f15, 0f00000000, %p8;
	ld.global.nc.f32 	%f17, [%rd134+24];
	add.rn.f32 	%f18, %f17, %f16;
	add.s64 	%rd136, %rd91, %rd107;
	ld.global.nc.u32 	%r26, [%rd136];
	max.s32 	%r27, %r8, %r26;
	setp.gt.s32 	%p9, %r10, %r27;
	min.s32 	%r28, %r10, %r27;
	add.s64 	%rd137, %rd92, %rd107;
	ld.global.nc.f32 	%f19, [%rd137];
	setp.gt.f32 	%p10, %f19, 0f41800000;
	selp.u32 	%r29, 1, 0, %p10;
	setp.eq.s32 	%p11, %r8, %r29;
	mul.wide.u32 	%rd138, %r6, 24;
	mul.wide.u32 	%rd139, %r7, 144;
	add.s64 	%rd140, %rd93, %rd139;
	add.s64 	%rd141, %rd140, %rd138;
	add.s64 	%rd142, %rd141, %rd133;
	ld.global.nc.f32 	%f20, [%rd142];
	selp.f32 	%f21, %f20, 0f00000000, %p11;
	add.s32 	%r30, %r5, %r14;
	cvt.u16.u32 	%rs17, %r30;
	mul.hi.u16 	%rs18, %rs17, -21845;
	shr.u16 	%rs19, %rs18, 2;
	cvt.u64.u16 	%rd143, %rs19;
	cvt.u32.u16 	%r32, %rs19;
	mul.wide.u32 	%rd144, %r32, 4;
	add.s64 	%rd145, %rd92, %rd144;
	ld.global.nc.f32 	%f22, [%rd145];
	setp.gt.f32 	%p12, %f22, 0f41800000;
	selp.u32 	%r33, 1, 0, %p12;
	add.s64 	%rd146, %rd103, %rd144;
	ld.global.nc.u32 	%r34, [%rd146];
	setp.eq.s32 	%p13, %r34, %r33;
	setp.gt.u32 	%p14, %r30, 377;
	selp.b64 	%rd147, 63, %rd143, %p14;
	mul.lo.s16 	%rs20, %rs19, 6;
	sub.s16 	%rs21, %rs17, %rs20;
	cvt.u32.u16 	%r35, %rs21;
	mul.wide.u32 	%rd148, %r35, 4;
	mul.wide.u32 	%rd149, %r32, 24;
	add.s64 	%rd150, %rd95, %rd149;
	add.s64 	%rd151, %rd150, %rd148;
	ld.global.nc.u32 	%r36, [%rd151];
	setp.lt.s32 	%p15, %r36, 0;
	add.s32 	%r37, %r36, 6;
	selp.b32 	%r38, %r37, %r36, %p15;
	max.s32 	%r39, %r38, 0;
	min.s32 	%r40, %r39, 5;
	mul.wide.u32 	%rd152, %r40, 4;
	mul.lo.s64 	%rd153, %rd147, 144;
	add.s64 	%rd154, %rd94, %rd153;
	add.s64 	%rd155, %rd154, %rd138;
	add.s64 	%rd156, %rd155, %rd152;
	ld.global.nc.f32 	%f23, [%rd156];
	selp.f32 	%f24, %f23, 0f00000000, %p13;
	add.rn.f32 	%f25, %f21, %f24;
	mul.rn.f32 	%f26, %f25, 0f46C4E000;
	selp.f32 	%f27, 0f00000000, %f26, %p9;
	mul.wide.u32 	%rd157, %r5, 72;
	add.s64 	%rd158, %rd96, %rd130;
	add.s64 	%rd159, %rd158, %rd157;
	mul.wide.u32 	%rd160, %r6, 4;
	add.s64 	%rd161, %rd159, %rd160;
	ld.global.nc.f32 	%f28, [%rd161];
	mul.rn.f32 	%f29, %f28, 0f44BD0000;
	add.rn.f32 	%f30, %f29, %f27;
	add.s64 	%rd162, %rd97, %rd112;
	ld.global.f32 	%f31, [%rd162];
	add.rn.f32 	%f32, %f31, %f30;
	setp.eq.s32 	%p16, %r28, 1;
	mul.rn.f32 	%f33, %f25, 0f41F00000;
	selp.f32 	%f34, %f33, 0f00000000, %p16;
	ld.global.nc.f32 	%f35, [%rd161+24];
	add.rn.f32 	%f36, %f35, %f34;
	add.s64 	%rd163, %rd85, %rd107;
	ld.global.nc.u32 	%r41, [%rd163];
	max.s32 	%r42, %r8, %r41;
	setp.gt.s32 	%p17, %r10, %r42;
	min.s32 	%r43, %r10, %r42;
	setp.eq.s32 	%p18, %r43, 1;
	add.s64 	%rd164, %rd86, %rd107;
	ld.global.nc.f32 	%f37, [%rd164];
	setp.gt.f32 	%p19, %f37, 0f41800000;
	selp.u32 	%r44, 1, 0, %p19;
	setp.eq.s32 	%p20, %r8, %r44;
	add.s64 	%rd165, %rd87, %rd112;
	ld.global.nc.f32 	%f38, [%rd165];
	selp.f32 	%f39, %f38, 0f00000000, %p20;
	add.s64 	%rd166, %rd86, %rd144;
	ld.global.nc.f32 	%f40, [%rd166];
	setp.gt.f32 	%p21, %f40, 0f41800000;
	selp.u32 	%r45, 1, 0, %p21;
	setp.eq.s32 	%p22, %r34, %r45;
	add.s64 	%rd167, %rd89, %rd149;
	add.s64 	%rd168, %rd167, %rd148;
	ld.global.nc.u32 	%r46, [%rd168];
	setp.lt.s32 	%p23, %r46, 0;
	add.s32 	%r47, %r46, 6;
	selp.b32 	%r48, %r47, %r46, %p23;
	max.s32 	%r49, %r48, 0;
	min.s32 	%r50, %r49, 5;
	mul.wide.u32 	%rd169, %r50, 4;
	add.s64 	%rd170, %rd88, %rd153;
	add.s64 	%rd171, %rd170, %rd138;
	add.s64 	%rd172, %rd171, %rd169;
	ld.global.nc.f32 	%f41, [%rd172];
	selp.f32 	%f42, %f41, 0f00000000, %p22;
	add.rn.f32 	%f43, %f39, %f42;
	mul.rn.f32 	%f44, %f43, 0f41F00000;
	selp.f32 	%f45, %f44, 0f00000000, %p18;
	add.s64 	%rd173, %rd90, %rd130;
	add.s64 	%rd174, %rd173, %rd157;
	add.s64 	%rd175, %rd174, %rd160;
	ld.global.nc.f32 	%f46, [%rd175+24];
	add.rn.f32 	%f47, %f46, %f45;
	mul.rn.f32 	%f48, %f43, 0f42600000;
	selp.f32 	%f49, 0f00000000, %f48, %p17;
	ld.global.nc.f32 	%f50, [%rd175];
	add.rn.f32 	%f51, %f50, %f49;
	add.s64 	%rd176, %rd78, %rd107;
	ld.global.nc.u32 	%r51, [%rd176];
	max.s32 	%r52, %r8, %r51;
	setp.gt.s32 	%p24, %r10, %r52;
	min.s32 	%r53, %r10, %r52;
	setp.eq.s32 	%p25, %r53, 1;
	add.s64 	%rd177, %rd80, %rd107;
	ld.global.nc.f32 	%f52, [%rd177];
	setp.gt.f32 	%p26, %f52, 0f41800000;
	selp.u32 	%r54, 1, 0, %p26;
	setp.eq.s32 	%p27, %r8, %r54;
	add.s64 	%rd178, %rd81, %rd139;
	add.s64 	%rd179, %rd178, %rd138;
	add.s64 	%rd180, %rd179, %rd133;
	ld.global.nc.f32 	%f53, [%rd180];
	selp.f32 	%f54, %f53, 0f00000000, %p27;
	add.s64 	%rd181, %rd80, %rd144;
	ld.global.nc.f32 	%f55, [%rd181];
	setp.gt.f32 	%p28, %f55, 0f41800000;
	selp.u32 	%r55, 1, 0, %p28;
	setp.eq.s32 	%p29, %r34, %r55;
	add.s64 	%rd182, %rd83, %rd149;
	add.s64 	%rd183, %rd182, %rd148;
	ld.global.nc.u32 	%r56, [%rd183];
	setp.lt.s32 	%p30, %r56, 0;
	add.s32 	%r57, %r56, 6;
	selp.b32 	%r58, %r57, %r56, %p30;
	max.s32 	%r59, %r58, 0;
	min.s32 	%r60, %r59, 5;
	mul.wide.u32 	%rd184, %r60, 4;
	add.s64 	%rd185, %rd82, %rd153;
	add.s64 	%rd186, %rd185, %rd138;
	add.s64 	%rd187, %rd186, %rd184;
	ld.global.nc.f32 	%f56, [%rd187];
	selp.f32 	%f57, %f56, 0f00000000, %p29;
	add.rn.f32 	%f58, %f54, %f57;
	mul.rn.f32 	%f59, %f58, 0f41F00000;
	selp.f32 	%f60, %f59, 0f00000000, %p25;
	add.s64 	%rd188, %rd84, %rd130;
	add.s64 	%rd189, %rd188, %rd157;
	add.s64 	%rd190, %rd189, %rd160;
	ld.global.nc.f32 	%f61, [%rd190+24];
	add.rn.f32 	%f62, %f61, %f60;
	mul.rn.f32 	%f63, %f58, 0f46C4E000;
	selp.f32 	%f64, 0f00000000, %f63, %p24;
	ld.global.nc.f32 	%f65, [%rd190];
	mul.rn.f32 	%f66, %f65, 0f44BD0000;
	add.rn.f32 	%f67, %f66, %f64;
	add.s64 	%rd191, %rd75, %rd112;
	ld.global.f32 	%f68, [%rd191];
	add.rn.f32 	%f69, %f68, %f67;
	add.s64 	%rd192, %rd57, %rd107;
	ld.global.nc.u32 	%r61, [%rd192];
	max.s32 	%r62, %r8, %r61;
	setp.gt.s32 	%p31, %r10, %r62;
	min.s32 	%r63, %r10, %r62;
	setp.eq.s32 	%p32, %r63, 1;
	add.s64 	%rd193, %rd60, %rd107;
	ld.global.nc.f32 	%f70, [%rd193];
	setp.gt.f32 	%p33, %f70, 0f41800000;
	selp.u32 	%r64, 1, 0, %p33;
	setp.eq.s32 	%p34, %r8, %r64;
	add.s64 	%rd194, %rd63, %rd112;
	ld.global.nc.f32 	%f71, [%rd194];
	selp.f32 	%f72, %f71, 0f00000000, %p34;
	add.s64 	%rd195, %rd60, %rd115;
	ld.global.nc.f32 	%f73, [%rd195];
	setp.gt.f32 	%p35, %f73, 0f41800000;
	selp.u32 	%r65, 1, 0, %p35;
	setp.eq.s32 	%p36, %r19, %r65;
	add.s64 	%rd196, %rd69, %rd120;
	add.s64 	%rd197, %rd196, %rd119;
	ld.global.nc.u32 	%r66, [%rd197];
	setp.lt.s32 	%p37, %r66, 0;
	add.s32 	%r67, %r66, 6;
	selp.b32 	%r68, %r67, %r66, %p37;
	max.s32 	%r69, %r68, 0;
	min.s32 	%r70, %r69, 5;
	mul.wide.u32 	%rd198, %r70, 4;
	add.s64 	%rd199, %rd66, %rd124;
	add.s64 	%rd200, %rd199, %rd126;
	add.s64 	%rd201, %rd200, %rd198;
	ld.global.nc.f32 	%f74, [%rd201];
	selp.f32 	%f75, %f74, 0f00000000, %p36;
	add.rn.f32 	%f76, %f72, %f75;
	mul.rn.f32 	%f77, %f76, 0f41F00000;
	selp.f32 	%f78, %f77, 0f00000000, %p32;
	add.s64 	%rd202, %rd72, %rd130;
	add.s64 	%rd203, %rd202, %rd129;
	add.s64 	%rd204, %rd203, %rd133;
	ld.global.nc.f32 	%f79, [%rd204+24];
	add.rn.f32 	%f80, %f79, %f78;
	mul.rn.f32 	%f81, %f76, 0f46C4E000;
	selp.f32 	%f82, 0f00000000, %f81, %p31;
	ld.global.nc.f32 	%f83, [%rd204];
	mul.rn.f32 	%f84, %f83, 0f44BD0000;
	add.rn.f32 	%f85, %f84, %f82;
	add.s64 	%rd205, %rd54, %rd112;
	ld.global.nc.f32 	%f86, [%rd205];
	add.rn.f32 	%f87, %f86, %f85;
	add.s64 	%rd206, %rd36, %rd107;
	ld.global.nc.u32 	%r71, [%rd206];
	max.s32 	%r72, %r8, %r71;
	setp.gt.s32 	%p38, %r10, %r72;
	min.s32 	%r73, %r10, %r72;
	setp.eq.s32 	%p39, %r73, 1;
	add.s64 	%rd207, %rd39, %rd107;
	ld.global.nc.f32 	%f88, [%rd207];
	setp.gt.f32 	%p40, %f88, 0f41800000;
	selp.u32 	%r74, 1, 0, %p40;
	setp.eq.s32 	%p41, %r8, %r74;
	add.s64 	%rd208, %rd42, %rd112;
	ld.global.nc.f32 	%f89, [%rd208];
	selp.f32 	%f90, %f89, 0f00000000, %p41;
	add.s64 	%rd209, %rd39, %rd115;
	ld.global.nc.f32 	%f91, [%rd209];
	setp.gt.f32 	%p42, %f91, 0f41800000;
	selp.u32 	%r75, 1, 0, %p42;
	setp.eq.s32 	%p43, %r19, %r75;
	add.s64 	%rd210, %rd48, %rd120;
	add.s64 	%rd211, %rd210, %rd119;
	ld.global.nc.u32 	%r76, [%rd211];
	setp.lt.s32 	%p44, %r76, 0;
	add.s32 	%r77, %r76, 6;
	selp.b32 	%r78, %r77, %r76, %p44;
	max.s32 	%r79, %r78, 0;
	min.s32 	%r80, %r79, 5;
	mul.wide.u32 	%rd212, %r80, 4;
	add.s64 	%rd213, %rd45, %rd124;
	add.s64 	%rd214, %rd213, %rd126;
	add.s64 	%rd215, %rd214, %rd212;
	ld.global.nc.f32 	%f92, [%rd215];
	selp.f32 	%f93, %f92, 0f00000000, %p43;
	add.rn.f32 	%f94, %f90, %f93;
	mul.rn.f32 	%f95, %f94, 0f41F00000;
	selp.f32 	%f96, %f95, 0f00000000, %p39;
	add.s64 	%rd216, %rd51, %rd130;
	add.s64 	%rd217, %rd216, %rd129;
	add.s64 	%rd218, %rd217, %rd133;
	ld.global.nc.f32 	%f97, [%rd218+24];
	add.rn.f32 	%f98, %f97, %f96;
	mul.rn.f32 	%f99, %f94, 0f46C4E000;
	selp.f32 	%f100, 0f00000000, %f99, %p38;
	ld.global.nc.f32 	%f101, [%rd218];
	mul.rn.f32 	%f102, %f101, 0f44BD0000;
	add.rn.f32 	%f103, %f102, %f100;
	add.s64 	%rd219, %rd33, %rd112;
	ld.global.nc.f32 	%f104, [%rd219];
	add.rn.f32 	%f105, %f104, %f103;
	add.s64 	%rd220, %rd30, %rd112;
	st.global.f32 	[%rd220], %f14;
	add.s64 	%rd221, %rd27, %rd112;
	st.global.f32 	[%rd221], %f18;
	st.global.f32 	[%rd162], %f32;
	add.s64 	%rd222, %rd24, %rd112;
	st.global.f32 	[%rd222], %f36;
	add.s64 	%rd223, %rd21, %rd112;
	st.global.f32 	[%rd223], %f47;
	add.s64 	%rd224, %rd18, %rd112;
	st.global.f32 	[%rd224], %f51;
	add.s64 	%rd225, %rd15, %rd112;
	st.global.f32 	[%rd225], %f62;
	st.global.f32 	[%rd191], %f69;
	add.s64 	%rd226, %rd12, %rd112;
	st.global.f32 	[%rd226], %f80;
	add.s64 	%rd227, %rd9, %rd112;
	st.global.f32 	[%rd227], %f87;
	add.s64 	%rd228, %rd6, %rd112;
	st.global.f32 	[%rd228], %f98;
	add.s64 	%rd229, %rd3, %rd112;
	st.global.f32 	[%rd229], %f105;
	ret;

}
	// .globl	input_concatenate_fusion_328
.visible .entry input_concatenate_fusion_328(
	.param .u64 input_concatenate_fusion_328_param_0,
	.param .u64 input_concatenate_fusion_328_param_1,
	.param .u64 input_concatenate_fusion_328_param_2,
	.param .u64 input_concatenate_fusion_328_param_3,
	.param .u64 input_concatenate_fusion_328_param_4,
	.param .u64 input_concatenate_fusion_328_param_5,
	.param .u64 input_concatenate_fusion_328_param_6,
	.param .u64 input_concatenate_fusion_328_param_7,
	.param .u64 input_concatenate_fusion_328_param_8,
	.param .u64 input_concatenate_fusion_328_param_9,
	.param .u64 input_concatenate_fusion_328_param_10,
	.param .u64 input_concatenate_fusion_328_param_11,
	.param .u64 input_concatenate_fusion_328_param_12,
	.param .u64 input_concatenate_fusion_328_param_13
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<67>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_328_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_328_param_13];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [input_concatenate_fusion_328_param_1];
	ld.param.u64 	%rd5, [input_concatenate_fusion_328_param_12];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [input_concatenate_fusion_328_param_2];
	ld.param.u64 	%rd8, [input_concatenate_fusion_328_param_11];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [input_concatenate_fusion_328_param_3];
	ld.param.u64 	%rd11, [input_concatenate_fusion_328_param_10];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [input_concatenate_fusion_328_param_4];
	ld.param.u64 	%rd14, [input_concatenate_fusion_328_param_9];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [input_concatenate_fusion_328_param_5];
	ld.param.u64 	%rd17, [input_concatenate_fusion_328_param_8];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [input_concatenate_fusion_328_param_6];
	ld.param.u64 	%rd20, [input_concatenate_fusion_328_param_7];
	cvta.to.global.u64 	%rd21, %rd20;
	cvta.to.global.u64 	%rd22, %rd19;
	cvta.to.global.u64 	%rd23, %rd16;
	cvta.to.global.u64 	%rd24, %rd13;
	cvta.to.global.u64 	%rd25, %rd10;
	cvta.to.global.u64 	%rd26, %rd7;
	cvta.to.global.u64 	%rd27, %rd4;
	cvta.to.global.u64 	%rd28, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd29, %r5, 4;
	add.s64 	%rd30, %rd22, %rd29;
	ld.global.nc.u32 	%r6, [%rd30];
	add.s64 	%rd31, %rd21, %rd29;
	ld.global.nc.u32 	%r7, [%rd31];
	add.s64 	%rd32, %rd18, %rd29;
	ld.global.nc.u32 	%r8, [%rd32];
	max.s32 	%r9, %r6, %r7;
	setp.gt.s32 	%p1, %r8, %r9;
	add.s64 	%rd33, %rd12, %rd29;
	ld.global.nc.f32 	%f1, [%rd33];
	setp.gt.f32 	%p2, %f1, 0f41800000;
	selp.u32 	%r10, 1, 0, %p2;
	setp.eq.s32 	%p3, %r6, %r10;
	cvt.u32.u16 	%r11, %rs5;
	mul.wide.u32 	%rd34, %r11, 24;
	mul.wide.u32 	%rd35, %r5, 144;
	add.s64 	%rd36, %rd15, %rd35;
	add.s64 	%rd37, %rd36, %rd34;
	cvt.u32.u16 	%r12, %rs8;
	mul.wide.u32 	%rd38, %r12, 4;
	add.s64 	%rd39, %rd37, %rd38;
	ld.global.nc.f32 	%f2, [%rd39];
	selp.f32 	%f3, %f2, 0f00000000, %p3;
	mul.lo.s16 	%rs11, %rs10, 6;
	add.s16 	%rs12, %rs8, %rs11;
	mul.hi.u16 	%rs14, %rs12, -21845;
	shr.u16 	%rs15, %rs14, 2;
	cvt.u32.u16 	%r13, %rs15;
	mul.wide.u32 	%rd40, %r13, 4;
	add.s64 	%rd41, %rd12, %rd40;
	ld.global.nc.f32 	%f4, [%rd41];
	setp.gt.f32 	%p4, %f4, 0f41800000;
	selp.u32 	%r14, 1, 0, %p4;
	add.s64 	%rd42, %rd22, %rd40;
	ld.global.nc.u32 	%r15, [%rd42];
	setp.eq.s32 	%p5, %r15, %r14;
	setp.gt.u16 	%p6, %rs12, 377;
	selp.b16 	%rs16, 63, %rs15, %p6;
	mul.lo.s16 	%rs17, %rs15, 6;
	sub.s16 	%rs18, %rs12, %rs17;
	cvt.u32.u16 	%r16, %rs18;
	mul.wide.u32 	%rd43, %r16, 4;
	mul.wide.u32 	%rd44, %r13, 24;
	add.s64 	%rd45, %rd9, %rd44;
	add.s64 	%rd46, %rd45, %rd43;
	ld.global.nc.u32 	%r17, [%rd46];
	setp.lt.s32 	%p7, %r17, 0;
	add.s32 	%r18, %r17, 6;
	selp.b32 	%r19, %r18, %r17, %p7;
	max.s32 	%r20, %r19, 0;
	min.s32 	%r21, %r20, 5;
	mul.wide.u32 	%rd47, %r21, 4;
	cvt.u32.u16 	%r22, %rs16;
	mul.wide.u32 	%rd48, %r22, 144;
	add.s64 	%rd49, %rd6, %rd48;
	add.s64 	%rd50, %rd49, %rd34;
	add.s64 	%rd51, %rd50, %rd47;
	ld.global.nc.f32 	%f5, [%rd51];
	selp.f32 	%f6, %f5, 0f00000000, %p5;
	add.rn.f32 	%f7, %f3, %f6;
	mul.rn.f32 	%f8, %f7, 0f49F3A200;
	selp.f32 	%f9, 0f00000000, %f8, %p1;
	mul.wide.u32 	%rd52, %r12, 72;
	mul.wide.u32 	%rd53, %r5, 432;
	add.s64 	%rd54, %rd23, %rd53;
	add.s64 	%rd55, %rd54, %rd52;
	mul.wide.u32 	%rd56, %r11, 4;
	add.s64 	%rd57, %rd55, %rd56;
	ld.global.nc.f32 	%f10, [%rd57];
	mul.rn.f32 	%f11, %f10, 0f48875A00;
	add.rn.f32 	%f12, %f11, %f9;
	mul.wide.u32 	%rd58, %r4, 4;
	add.s64 	%rd59, %rd24, %rd58;
	ld.global.nc.f32 	%f13, [%rd59];
	add.rn.f32 	%f14, %f13, %f12;
	add.s64 	%rd60, %rd25, %rd58;
	ld.global.nc.f32 	%f15, [%rd60];
	add.rn.f32 	%f16, %f15, %f14;
	add.s64 	%rd61, %rd26, %rd58;
	ld.global.nc.f32 	%f17, [%rd61];
	add.rn.f32 	%f18, %f17, %f16;
	add.s64 	%rd62, %rd3, %rd53;
	add.s64 	%rd63, %rd62, %rd52;
	add.s64 	%rd64, %rd63, %rd56;
	st.global.f32 	[%rd64], %f18;
	min.s32 	%r23, %r8, %r9;
	setp.eq.s32 	%p8, %r23, 1;
	mul.rn.f32 	%f19, %f7, 0f45520000;
	selp.f32 	%f20, %f19, 0f00000000, %p8;
	ld.global.nc.f32 	%f21, [%rd57+24];
	mul.rn.f32 	%f22, %f21, 0f43D20000;
	add.rn.f32 	%f23, %f20, %f22;
	add.s64 	%rd65, %rd27, %rd58;
	ld.global.nc.f32 	%f24, [%rd65];
	add.rn.f32 	%f25, %f24, %f23;
	add.s64 	%rd66, %rd28, %rd58;
	ld.global.nc.f32 	%f26, [%rd66];
	add.rn.f32 	%f27, %f26, %f25;
	st.global.f32 	[%rd64+24], %f27;
	setp.eq.s32 	%p9, %r23, %r6;
	mul.rn.f32 	%f28, %f7, 0f41400000;
	selp.f32 	%f29, %f28, 0f00000000, %p9;
	ld.global.nc.f32 	%f30, [%rd57+48];
	add.rn.f32 	%f31, %f29, %f30;
	st.global.f32 	[%rd64+48], %f31;
	ret;

}
	// .globl	input_concatenate_fusion_329
.visible .entry input_concatenate_fusion_329(
	.param .u64 input_concatenate_fusion_329_param_0,
	.param .u64 input_concatenate_fusion_329_param_1,
	.param .u64 input_concatenate_fusion_329_param_2,
	.param .u64 input_concatenate_fusion_329_param_3,
	.param .u64 input_concatenate_fusion_329_param_4,
	.param .u64 input_concatenate_fusion_329_param_5,
	.param .u64 input_concatenate_fusion_329_param_6,
	.param .u64 input_concatenate_fusion_329_param_7,
	.param .u64 input_concatenate_fusion_329_param_8,
	.param .u64 input_concatenate_fusion_329_param_9,
	.param .u64 input_concatenate_fusion_329_param_10,
	.param .u64 input_concatenate_fusion_329_param_11,
	.param .u64 input_concatenate_fusion_329_param_12,
	.param .u64 input_concatenate_fusion_329_param_13
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<68>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_329_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_329_param_13];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [input_concatenate_fusion_329_param_1];
	ld.param.u64 	%rd5, [input_concatenate_fusion_329_param_12];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [input_concatenate_fusion_329_param_2];
	ld.param.u64 	%rd8, [input_concatenate_fusion_329_param_11];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [input_concatenate_fusion_329_param_3];
	ld.param.u64 	%rd11, [input_concatenate_fusion_329_param_10];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [input_concatenate_fusion_329_param_4];
	ld.param.u64 	%rd14, [input_concatenate_fusion_329_param_9];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [input_concatenate_fusion_329_param_5];
	ld.param.u64 	%rd17, [input_concatenate_fusion_329_param_8];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [input_concatenate_fusion_329_param_6];
	ld.param.u64 	%rd20, [input_concatenate_fusion_329_param_7];
	cvta.to.global.u64 	%rd21, %rd20;
	cvta.to.global.u64 	%rd22, %rd19;
	cvta.to.global.u64 	%rd23, %rd16;
	cvta.to.global.u64 	%rd24, %rd13;
	cvta.to.global.u64 	%rd25, %rd10;
	cvta.to.global.u64 	%rd26, %rd7;
	cvta.to.global.u64 	%rd27, %rd4;
	cvta.to.global.u64 	%rd28, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd29, %r5, 4;
	add.s64 	%rd30, %rd22, %rd29;
	ld.global.nc.u32 	%r6, [%rd30];
	add.s64 	%rd31, %rd21, %rd29;
	ld.global.nc.u32 	%r7, [%rd31];
	add.s64 	%rd32, %rd18, %rd29;
	ld.global.nc.u32 	%r8, [%rd32];
	max.s32 	%r9, %r6, %r7;
	setp.gt.s32 	%p1, %r8, %r9;
	add.s64 	%rd33, %rd12, %rd29;
	ld.global.nc.f32 	%f1, [%rd33];
	setp.gt.f32 	%p2, %f1, 0f41800000;
	selp.u32 	%r10, 1, 0, %p2;
	setp.eq.s32 	%p3, %r6, %r10;
	cvt.u32.u16 	%r11, %rs5;
	mul.wide.u32 	%rd34, %r11, 24;
	mul.wide.u32 	%rd35, %r5, 144;
	add.s64 	%rd36, %rd15, %rd35;
	add.s64 	%rd37, %rd36, %rd34;
	cvt.u32.u16 	%r12, %rs8;
	mul.wide.u32 	%rd38, %r12, 4;
	add.s64 	%rd39, %rd37, %rd38;
	ld.global.nc.f32 	%f2, [%rd39];
	selp.f32 	%f3, %f2, 0f00000000, %p3;
	mul.lo.s16 	%rs11, %rs10, 6;
	add.s16 	%rs12, %rs8, %rs11;
	mul.hi.u16 	%rs14, %rs12, -21845;
	shr.u16 	%rs15, %rs14, 2;
	cvt.u32.u16 	%r13, %rs15;
	mul.wide.u32 	%rd40, %r13, 4;
	add.s64 	%rd41, %rd12, %rd40;
	ld.global.nc.f32 	%f4, [%rd41];
	setp.gt.f32 	%p4, %f4, 0f41800000;
	selp.u32 	%r14, 1, 0, %p4;
	add.s64 	%rd42, %rd22, %rd40;
	ld.global.nc.u32 	%r15, [%rd42];
	setp.eq.s32 	%p5, %r15, %r14;
	setp.gt.u16 	%p6, %rs12, 377;
	selp.b16 	%rs16, 63, %rs15, %p6;
	mul.lo.s16 	%rs17, %rs15, 6;
	sub.s16 	%rs18, %rs12, %rs17;
	cvt.u32.u16 	%r16, %rs18;
	mul.wide.u32 	%rd43, %r16, 4;
	mul.wide.u32 	%rd44, %r13, 24;
	add.s64 	%rd45, %rd9, %rd44;
	add.s64 	%rd46, %rd45, %rd43;
	ld.global.nc.u32 	%r17, [%rd46];
	setp.lt.s32 	%p7, %r17, 0;
	add.s32 	%r18, %r17, 6;
	selp.b32 	%r19, %r18, %r17, %p7;
	max.s32 	%r20, %r19, 0;
	min.s32 	%r21, %r20, 5;
	mul.wide.u32 	%rd47, %r21, 4;
	cvt.u32.u16 	%r22, %rs16;
	mul.wide.u32 	%rd48, %r22, 144;
	add.s64 	%rd49, %rd6, %rd48;
	add.s64 	%rd50, %rd49, %rd34;
	add.s64 	%rd51, %rd50, %rd47;
	ld.global.nc.f32 	%f5, [%rd51];
	selp.f32 	%f6, %f5, 0f00000000, %p5;
	add.rn.f32 	%f7, %f3, %f6;
	mul.rn.f32 	%f8, %f7, 0f49F3A200;
	selp.f32 	%f9, 0f00000000, %f8, %p1;
	mul.wide.u32 	%rd52, %r12, 72;
	mul.wide.u32 	%rd53, %r5, 432;
	add.s64 	%rd54, %rd23, %rd53;
	add.s64 	%rd55, %rd54, %rd52;
	mul.wide.u32 	%rd56, %r11, 4;
	add.s64 	%rd57, %rd55, %rd56;
	ld.global.nc.f32 	%f10, [%rd57];
	mul.rn.f32 	%f11, %f10, 0f48875A00;
	add.rn.f32 	%f12, %f11, %f9;
	mul.wide.u32 	%rd58, %r4, 4;
	add.s64 	%rd59, %rd24, %rd58;
	ld.global.nc.f32 	%f13, [%rd59];
	add.rn.f32 	%f14, %f13, %f12;
	add.s64 	%rd60, %rd25, %rd58;
	ld.global.nc.f32 	%f15, [%rd60];
	add.rn.f32 	%f16, %f15, %f14;
	add.s64 	%rd61, %rd26, %rd58;
	ld.global.nc.f32 	%f17, [%rd61];
	add.rn.f32 	%f18, %f17, %f16;
	mul.wide.u32 	%rd62, %r12, 24;
	add.s64 	%rd63, %rd3, %rd53;
	add.s64 	%rd64, %rd63, %rd62;
	add.s64 	%rd65, %rd64, %rd56;
	st.global.f32 	[%rd65], %f18;
	min.s32 	%r23, %r8, %r9;
	setp.eq.s32 	%p8, %r23, 1;
	mul.rn.f32 	%f19, %f7, 0f45520000;
	selp.f32 	%f20, %f19, 0f00000000, %p8;
	ld.global.nc.f32 	%f21, [%rd57+24];
	mul.rn.f32 	%f22, %f21, 0f43D20000;
	add.rn.f32 	%f23, %f20, %f22;
	add.s64 	%rd66, %rd27, %rd58;
	ld.global.nc.f32 	%f24, [%rd66];
	add.rn.f32 	%f25, %f24, %f23;
	add.s64 	%rd67, %rd28, %rd58;
	ld.global.nc.f32 	%f26, [%rd67];
	add.rn.f32 	%f27, %f26, %f25;
	st.global.f32 	[%rd65+144], %f27;
	setp.eq.s32 	%p9, %r23, %r6;
	mul.rn.f32 	%f28, %f7, 0f41400000;
	selp.f32 	%f29, %f28, 0f00000000, %p9;
	ld.global.nc.f32 	%f30, [%rd57+48];
	add.rn.f32 	%f31, %f29, %f30;
	st.global.f32 	[%rd65+288], %f31;
	ret;

}
	// .globl	input_concatenate_fusion_330
.visible .entry input_concatenate_fusion_330(
	.param .u64 input_concatenate_fusion_330_param_0,
	.param .u64 input_concatenate_fusion_330_param_1,
	.param .u64 input_concatenate_fusion_330_param_2,
	.param .u64 input_concatenate_fusion_330_param_3,
	.param .u64 input_concatenate_fusion_330_param_4,
	.param .u64 input_concatenate_fusion_330_param_5,
	.param .u64 input_concatenate_fusion_330_param_6,
	.param .u64 input_concatenate_fusion_330_param_7,
	.param .u64 input_concatenate_fusion_330_param_8,
	.param .u64 input_concatenate_fusion_330_param_9,
	.param .u64 input_concatenate_fusion_330_param_10,
	.param .u64 input_concatenate_fusion_330_param_11,
	.param .u64 input_concatenate_fusion_330_param_12,
	.param .u64 input_concatenate_fusion_330_param_13
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<67>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_330_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_330_param_13];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [input_concatenate_fusion_330_param_1];
	ld.param.u64 	%rd5, [input_concatenate_fusion_330_param_12];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [input_concatenate_fusion_330_param_2];
	ld.param.u64 	%rd8, [input_concatenate_fusion_330_param_11];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [input_concatenate_fusion_330_param_3];
	ld.param.u64 	%rd11, [input_concatenate_fusion_330_param_10];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [input_concatenate_fusion_330_param_4];
	ld.param.u64 	%rd14, [input_concatenate_fusion_330_param_9];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [input_concatenate_fusion_330_param_5];
	ld.param.u64 	%rd17, [input_concatenate_fusion_330_param_8];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [input_concatenate_fusion_330_param_6];
	ld.param.u64 	%rd20, [input_concatenate_fusion_330_param_7];
	cvta.to.global.u64 	%rd21, %rd20;
	cvta.to.global.u64 	%rd22, %rd19;
	cvta.to.global.u64 	%rd23, %rd16;
	cvta.to.global.u64 	%rd24, %rd13;
	cvta.to.global.u64 	%rd25, %rd10;
	cvta.to.global.u64 	%rd26, %rd7;
	cvta.to.global.u64 	%rd27, %rd4;
	cvta.to.global.u64 	%rd28, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd29, %r5, 4;
	add.s64 	%rd30, %rd22, %rd29;
	ld.global.nc.u32 	%r6, [%rd30];
	add.s64 	%rd31, %rd21, %rd29;
	ld.global.nc.u32 	%r7, [%rd31];
	add.s64 	%rd32, %rd18, %rd29;
	ld.global.nc.u32 	%r8, [%rd32];
	max.s32 	%r9, %r6, %r7;
	setp.gt.s32 	%p1, %r8, %r9;
	add.s64 	%rd33, %rd12, %rd29;
	ld.global.nc.f32 	%f1, [%rd33];
	setp.gt.f32 	%p2, %f1, 0f41800000;
	selp.u32 	%r10, 1, 0, %p2;
	setp.eq.s32 	%p3, %r6, %r10;
	cvt.u32.u16 	%r11, %rs5;
	mul.wide.u32 	%rd34, %r11, 24;
	mul.wide.u32 	%rd35, %r5, 144;
	add.s64 	%rd36, %rd15, %rd35;
	add.s64 	%rd37, %rd36, %rd34;
	cvt.u32.u16 	%r12, %rs8;
	mul.wide.u32 	%rd38, %r12, 4;
	add.s64 	%rd39, %rd37, %rd38;
	ld.global.nc.f32 	%f2, [%rd39];
	selp.f32 	%f3, %f2, 0f00000000, %p3;
	mul.lo.s16 	%rs11, %rs10, 6;
	add.s16 	%rs12, %rs8, %rs11;
	mul.hi.u16 	%rs14, %rs12, -21845;
	shr.u16 	%rs15, %rs14, 2;
	cvt.u32.u16 	%r13, %rs15;
	mul.wide.u32 	%rd40, %r13, 4;
	add.s64 	%rd41, %rd12, %rd40;
	ld.global.nc.f32 	%f4, [%rd41];
	setp.gt.f32 	%p4, %f4, 0f41800000;
	selp.u32 	%r14, 1, 0, %p4;
	add.s64 	%rd42, %rd22, %rd40;
	ld.global.nc.u32 	%r15, [%rd42];
	setp.eq.s32 	%p5, %r15, %r14;
	setp.gt.u16 	%p6, %rs12, 377;
	selp.b16 	%rs16, 63, %rs15, %p6;
	mul.lo.s16 	%rs17, %rs15, 6;
	sub.s16 	%rs18, %rs12, %rs17;
	cvt.u32.u16 	%r16, %rs18;
	mul.wide.u32 	%rd43, %r16, 4;
	mul.wide.u32 	%rd44, %r13, 24;
	add.s64 	%rd45, %rd9, %rd44;
	add.s64 	%rd46, %rd45, %rd43;
	ld.global.nc.u32 	%r17, [%rd46];
	setp.lt.s32 	%p7, %r17, 0;
	add.s32 	%r18, %r17, 6;
	selp.b32 	%r19, %r18, %r17, %p7;
	max.s32 	%r20, %r19, 0;
	min.s32 	%r21, %r20, 5;
	mul.wide.u32 	%rd47, %r21, 4;
	cvt.u32.u16 	%r22, %rs16;
	mul.wide.u32 	%rd48, %r22, 144;
	add.s64 	%rd49, %rd6, %rd48;
	add.s64 	%rd50, %rd49, %rd34;
	add.s64 	%rd51, %rd50, %rd47;
	ld.global.nc.f32 	%f5, [%rd51];
	selp.f32 	%f6, %f5, 0f00000000, %p5;
	add.rn.f32 	%f7, %f3, %f6;
	mul.rn.f32 	%f8, %f7, 0f49F3A200;
	selp.f32 	%f9, 0f00000000, %f8, %p1;
	mul.wide.u32 	%rd52, %r12, 72;
	mul.wide.u32 	%rd53, %r5, 432;
	add.s64 	%rd54, %rd23, %rd53;
	add.s64 	%rd55, %rd54, %rd52;
	mul.wide.u32 	%rd56, %r11, 4;
	add.s64 	%rd57, %rd55, %rd56;
	ld.global.nc.f32 	%f10, [%rd57];
	mul.rn.f32 	%f11, %f10, 0f48875A00;
	add.rn.f32 	%f12, %f11, %f9;
	mul.wide.u32 	%rd58, %r4, 4;
	add.s64 	%rd59, %rd24, %rd58;
	ld.global.nc.f32 	%f13, [%rd59];
	add.rn.f32 	%f14, %f13, %f12;
	add.s64 	%rd60, %rd25, %rd58;
	ld.global.nc.f32 	%f15, [%rd60];
	add.rn.f32 	%f16, %f15, %f14;
	add.s64 	%rd61, %rd26, %rd58;
	ld.global.nc.f32 	%f17, [%rd61];
	add.rn.f32 	%f18, %f17, %f16;
	add.s64 	%rd62, %rd3, %rd53;
	add.s64 	%rd63, %rd62, %rd52;
	add.s64 	%rd64, %rd63, %rd56;
	st.global.f32 	[%rd64], %f18;
	min.s32 	%r23, %r8, %r9;
	setp.eq.s32 	%p8, %r23, 1;
	mul.rn.f32 	%f19, %f7, 0f45520000;
	selp.f32 	%f20, %f19, 0f00000000, %p8;
	ld.global.nc.f32 	%f21, [%rd57+24];
	mul.rn.f32 	%f22, %f21, 0f43D20000;
	add.rn.f32 	%f23, %f20, %f22;
	add.s64 	%rd65, %rd27, %rd58;
	ld.global.nc.f32 	%f24, [%rd65];
	add.rn.f32 	%f25, %f24, %f23;
	add.s64 	%rd66, %rd28, %rd58;
	ld.global.nc.f32 	%f26, [%rd66];
	add.rn.f32 	%f27, %f26, %f25;
	st.global.f32 	[%rd64+24], %f27;
	setp.eq.s32 	%p9, %r23, %r6;
	mul.rn.f32 	%f28, %f7, 0f41400000;
	selp.f32 	%f29, %f28, 0f00000000, %p9;
	ld.global.nc.f32 	%f30, [%rd57+48];
	add.rn.f32 	%f31, %f29, %f30;
	st.global.f32 	[%rd64+48], %f31;
	ret;

}
	// .globl	input_concatenate_fusion_331
.visible .entry input_concatenate_fusion_331(
	.param .u64 input_concatenate_fusion_331_param_0,
	.param .u64 input_concatenate_fusion_331_param_1,
	.param .u64 input_concatenate_fusion_331_param_2,
	.param .u64 input_concatenate_fusion_331_param_3,
	.param .u64 input_concatenate_fusion_331_param_4,
	.param .u64 input_concatenate_fusion_331_param_5,
	.param .u64 input_concatenate_fusion_331_param_6,
	.param .u64 input_concatenate_fusion_331_param_7,
	.param .u64 input_concatenate_fusion_331_param_8,
	.param .u64 input_concatenate_fusion_331_param_9,
	.param .u64 input_concatenate_fusion_331_param_10,
	.param .u64 input_concatenate_fusion_331_param_11,
	.param .u64 input_concatenate_fusion_331_param_12,
	.param .u64 input_concatenate_fusion_331_param_13
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<68>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_331_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_331_param_13];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [input_concatenate_fusion_331_param_1];
	ld.param.u64 	%rd5, [input_concatenate_fusion_331_param_12];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [input_concatenate_fusion_331_param_2];
	ld.param.u64 	%rd8, [input_concatenate_fusion_331_param_11];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [input_concatenate_fusion_331_param_3];
	ld.param.u64 	%rd11, [input_concatenate_fusion_331_param_10];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [input_concatenate_fusion_331_param_4];
	ld.param.u64 	%rd14, [input_concatenate_fusion_331_param_9];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [input_concatenate_fusion_331_param_5];
	ld.param.u64 	%rd17, [input_concatenate_fusion_331_param_8];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [input_concatenate_fusion_331_param_6];
	ld.param.u64 	%rd20, [input_concatenate_fusion_331_param_7];
	cvta.to.global.u64 	%rd21, %rd20;
	cvta.to.global.u64 	%rd22, %rd19;
	cvta.to.global.u64 	%rd23, %rd16;
	cvta.to.global.u64 	%rd24, %rd13;
	cvta.to.global.u64 	%rd25, %rd10;
	cvta.to.global.u64 	%rd26, %rd7;
	cvta.to.global.u64 	%rd27, %rd4;
	cvta.to.global.u64 	%rd28, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd29, %r5, 4;
	add.s64 	%rd30, %rd22, %rd29;
	ld.global.nc.u32 	%r6, [%rd30];
	add.s64 	%rd31, %rd21, %rd29;
	ld.global.nc.u32 	%r7, [%rd31];
	add.s64 	%rd32, %rd18, %rd29;
	ld.global.nc.u32 	%r8, [%rd32];
	max.s32 	%r9, %r6, %r7;
	setp.gt.s32 	%p1, %r8, %r9;
	add.s64 	%rd33, %rd12, %rd29;
	ld.global.nc.f32 	%f1, [%rd33];
	setp.gt.f32 	%p2, %f1, 0f41800000;
	selp.u32 	%r10, 1, 0, %p2;
	setp.eq.s32 	%p3, %r6, %r10;
	cvt.u32.u16 	%r11, %rs5;
	mul.wide.u32 	%rd34, %r11, 24;
	mul.wide.u32 	%rd35, %r5, 144;
	add.s64 	%rd36, %rd15, %rd35;
	add.s64 	%rd37, %rd36, %rd34;
	cvt.u32.u16 	%r12, %rs8;
	mul.wide.u32 	%rd38, %r12, 4;
	add.s64 	%rd39, %rd37, %rd38;
	ld.global.nc.f32 	%f2, [%rd39];
	selp.f32 	%f3, %f2, 0f00000000, %p3;
	mul.lo.s16 	%rs11, %rs10, 6;
	add.s16 	%rs12, %rs8, %rs11;
	mul.hi.u16 	%rs14, %rs12, -21845;
	shr.u16 	%rs15, %rs14, 2;
	cvt.u32.u16 	%r13, %rs15;
	mul.wide.u32 	%rd40, %r13, 4;
	add.s64 	%rd41, %rd12, %rd40;
	ld.global.nc.f32 	%f4, [%rd41];
	setp.gt.f32 	%p4, %f4, 0f41800000;
	selp.u32 	%r14, 1, 0, %p4;
	add.s64 	%rd42, %rd22, %rd40;
	ld.global.nc.u32 	%r15, [%rd42];
	setp.eq.s32 	%p5, %r15, %r14;
	setp.gt.u16 	%p6, %rs12, 377;
	selp.b16 	%rs16, 63, %rs15, %p6;
	mul.lo.s16 	%rs17, %rs15, 6;
	sub.s16 	%rs18, %rs12, %rs17;
	cvt.u32.u16 	%r16, %rs18;
	mul.wide.u32 	%rd43, %r16, 4;
	mul.wide.u32 	%rd44, %r13, 24;
	add.s64 	%rd45, %rd9, %rd44;
	add.s64 	%rd46, %rd45, %rd43;
	ld.global.nc.u32 	%r17, [%rd46];
	setp.lt.s32 	%p7, %r17, 0;
	add.s32 	%r18, %r17, 6;
	selp.b32 	%r19, %r18, %r17, %p7;
	max.s32 	%r20, %r19, 0;
	min.s32 	%r21, %r20, 5;
	mul.wide.u32 	%rd47, %r21, 4;
	cvt.u32.u16 	%r22, %rs16;
	mul.wide.u32 	%rd48, %r22, 144;
	add.s64 	%rd49, %rd6, %rd48;
	add.s64 	%rd50, %rd49, %rd34;
	add.s64 	%rd51, %rd50, %rd47;
	ld.global.nc.f32 	%f5, [%rd51];
	selp.f32 	%f6, %f5, 0f00000000, %p5;
	add.rn.f32 	%f7, %f3, %f6;
	mul.rn.f32 	%f8, %f7, 0f49F3A200;
	selp.f32 	%f9, 0f00000000, %f8, %p1;
	mul.wide.u32 	%rd52, %r12, 72;
	mul.wide.u32 	%rd53, %r5, 432;
	add.s64 	%rd54, %rd23, %rd53;
	add.s64 	%rd55, %rd54, %rd52;
	mul.wide.u32 	%rd56, %r11, 4;
	add.s64 	%rd57, %rd55, %rd56;
	ld.global.nc.f32 	%f10, [%rd57];
	mul.rn.f32 	%f11, %f10, 0f48875A00;
	add.rn.f32 	%f12, %f11, %f9;
	mul.wide.u32 	%rd58, %r4, 4;
	add.s64 	%rd59, %rd24, %rd58;
	ld.global.nc.f32 	%f13, [%rd59];
	add.rn.f32 	%f14, %f13, %f12;
	add.s64 	%rd60, %rd25, %rd58;
	ld.global.nc.f32 	%f15, [%rd60];
	add.rn.f32 	%f16, %f15, %f14;
	add.s64 	%rd61, %rd26, %rd58;
	ld.global.nc.f32 	%f17, [%rd61];
	add.rn.f32 	%f18, %f17, %f16;
	mul.wide.u32 	%rd62, %r12, 24;
	add.s64 	%rd63, %rd3, %rd53;
	add.s64 	%rd64, %rd63, %rd62;
	add.s64 	%rd65, %rd64, %rd56;
	st.global.f32 	[%rd65], %f18;
	min.s32 	%r23, %r8, %r9;
	setp.eq.s32 	%p8, %r23, 1;
	mul.rn.f32 	%f19, %f7, 0f45520000;
	selp.f32 	%f20, %f19, 0f00000000, %p8;
	ld.global.nc.f32 	%f21, [%rd57+24];
	mul.rn.f32 	%f22, %f21, 0f43D20000;
	add.rn.f32 	%f23, %f20, %f22;
	add.s64 	%rd66, %rd27, %rd58;
	ld.global.nc.f32 	%f24, [%rd66];
	add.rn.f32 	%f25, %f24, %f23;
	add.s64 	%rd67, %rd28, %rd58;
	ld.global.nc.f32 	%f26, [%rd67];
	add.rn.f32 	%f27, %f26, %f25;
	st.global.f32 	[%rd65+144], %f27;
	setp.eq.s32 	%p9, %r23, %r6;
	mul.rn.f32 	%f28, %f7, 0f41400000;
	selp.f32 	%f29, %f28, 0f00000000, %p9;
	ld.global.nc.f32 	%f30, [%rd57+48];
	add.rn.f32 	%f31, %f29, %f30;
	st.global.f32 	[%rd65+288], %f31;
	ret;

}
	// .globl	input_concatenate_fusion_332
.visible .entry input_concatenate_fusion_332(
	.param .u64 input_concatenate_fusion_332_param_0,
	.param .u64 input_concatenate_fusion_332_param_1,
	.param .u64 input_concatenate_fusion_332_param_2,
	.param .u64 input_concatenate_fusion_332_param_3,
	.param .u64 input_concatenate_fusion_332_param_4,
	.param .u64 input_concatenate_fusion_332_param_5,
	.param .u64 input_concatenate_fusion_332_param_6,
	.param .u64 input_concatenate_fusion_332_param_7,
	.param .u64 input_concatenate_fusion_332_param_8,
	.param .u64 input_concatenate_fusion_332_param_9,
	.param .u64 input_concatenate_fusion_332_param_10,
	.param .u64 input_concatenate_fusion_332_param_11,
	.param .u64 input_concatenate_fusion_332_param_12,
	.param .u64 input_concatenate_fusion_332_param_13
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<64>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_332_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_332_param_13];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [input_concatenate_fusion_332_param_1];
	ld.param.u64 	%rd5, [input_concatenate_fusion_332_param_12];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [input_concatenate_fusion_332_param_2];
	ld.param.u64 	%rd8, [input_concatenate_fusion_332_param_11];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [input_concatenate_fusion_332_param_3];
	ld.param.u64 	%rd11, [input_concatenate_fusion_332_param_10];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [input_concatenate_fusion_332_param_4];
	ld.param.u64 	%rd14, [input_concatenate_fusion_332_param_9];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [input_concatenate_fusion_332_param_5];
	ld.param.u64 	%rd17, [input_concatenate_fusion_332_param_8];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [input_concatenate_fusion_332_param_6];
	ld.param.u64 	%rd20, [input_concatenate_fusion_332_param_7];
	cvta.to.global.u64 	%rd21, %rd20;
	cvta.to.global.u64 	%rd22, %rd19;
	cvta.to.global.u64 	%rd23, %rd16;
	cvta.to.global.u64 	%rd24, %rd13;
	cvta.to.global.u64 	%rd25, %rd10;
	cvta.to.global.u64 	%rd26, %rd7;
	cvta.to.global.u64 	%rd27, %rd4;
	cvta.to.global.u64 	%rd28, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd29, %r5, 4;
	add.s64 	%rd30, %rd22, %rd29;
	ld.global.nc.u32 	%r6, [%rd30];
	add.s64 	%rd31, %rd21, %rd29;
	ld.global.nc.u32 	%r7, [%rd31];
	add.s64 	%rd32, %rd18, %rd29;
	ld.global.nc.u32 	%r8, [%rd32];
	max.s32 	%r9, %r6, %r7;
	setp.gt.s32 	%p1, %r8, %r9;
	add.s64 	%rd33, %rd12, %rd29;
	ld.global.nc.f32 	%f1, [%rd33];
	setp.gt.f32 	%p2, %f1, 0f41800000;
	selp.u32 	%r10, 1, 0, %p2;
	setp.eq.s32 	%p3, %r6, %r10;
	mul.wide.u32 	%rd34, %r4, 4;
	add.s64 	%rd35, %rd15, %rd34;
	ld.global.nc.f32 	%f2, [%rd35];
	selp.f32 	%f3, %f2, 0f00000000, %p3;
	mul.lo.s16 	%rs11, %rs10, 6;
	add.s16 	%rs12, %rs11, %rs5;
	mul.hi.u16 	%rs14, %rs12, -21845;
	shr.u16 	%rs15, %rs14, 2;
	cvt.u32.u16 	%r11, %rs15;
	mul.wide.u32 	%rd36, %r11, 4;
	add.s64 	%rd37, %rd12, %rd36;
	ld.global.nc.f32 	%f4, [%rd37];
	setp.gt.f32 	%p4, %f4, 0f41800000;
	selp.u32 	%r12, 1, 0, %p4;
	add.s64 	%rd38, %rd22, %rd36;
	ld.global.nc.u32 	%r13, [%rd38];
	setp.eq.s32 	%p5, %r13, %r12;
	setp.gt.u16 	%p6, %rs12, 377;
	selp.b16 	%rs16, 63, %rs15, %p6;
	mul.lo.s16 	%rs17, %rs15, 6;
	sub.s16 	%rs18, %rs12, %rs17;
	cvt.u32.u16 	%r14, %rs18;
	mul.wide.u32 	%rd39, %r14, 4;
	mul.wide.u32 	%rd40, %r11, 24;
	add.s64 	%rd41, %rd9, %rd40;
	add.s64 	%rd42, %rd41, %rd39;
	ld.global.nc.u32 	%r15, [%rd42];
	setp.lt.s32 	%p7, %r15, 0;
	add.s32 	%r16, %r15, 6;
	selp.b32 	%r17, %r16, %r15, %p7;
	max.s32 	%r18, %r17, 0;
	min.s32 	%r19, %r18, 5;
	mul.wide.u32 	%rd43, %r19, 4;
	cvt.u32.u16 	%r20, %rs16;
	mul.wide.u32 	%rd44, %r20, 144;
	add.s64 	%rd45, %rd6, %rd44;
	cvt.u32.u16 	%r21, %rs8;
	mul.wide.u32 	%rd46, %r21, 24;
	add.s64 	%rd47, %rd45, %rd46;
	add.s64 	%rd48, %rd47, %rd43;
	ld.global.nc.f32 	%f5, [%rd48];
	selp.f32 	%f6, %f5, 0f00000000, %p5;
	add.rn.f32 	%f7, %f3, %f6;
	mul.rn.f32 	%f8, %f7, 0f49F3A200;
	selp.f32 	%f9, 0f00000000, %f8, %p1;
	cvt.u32.u16 	%r22, %rs5;
	mul.wide.u32 	%rd49, %r22, 72;
	mul.wide.u32 	%rd50, %r5, 432;
	add.s64 	%rd51, %rd23, %rd50;
	add.s64 	%rd52, %rd51, %rd49;
	mul.wide.u32 	%rd53, %r21, 4;
	add.s64 	%rd54, %rd52, %rd53;
	ld.global.nc.f32 	%f10, [%rd54];
	mul.rn.f32 	%f11, %f10, 0f48875A00;
	add.rn.f32 	%f12, %f11, %f9;
	add.s64 	%rd55, %rd24, %rd34;
	ld.global.nc.f32 	%f13, [%rd55];
	add.rn.f32 	%f14, %f13, %f12;
	add.s64 	%rd56, %rd25, %rd34;
	ld.global.nc.f32 	%f15, [%rd56];
	add.rn.f32 	%f16, %f15, %f14;
	add.s64 	%rd57, %rd26, %rd34;
	ld.global.nc.f32 	%f17, [%rd57];
	add.rn.f32 	%f18, %f17, %f16;
	add.s64 	%rd58, %rd3, %rd50;
	add.s64 	%rd59, %rd58, %rd46;
	mul.wide.u32 	%rd60, %r22, 4;
	add.s64 	%rd61, %rd59, %rd60;
	st.global.f32 	[%rd61], %f18;
	min.s32 	%r23, %r8, %r9;
	setp.eq.s32 	%p8, %r23, 1;
	mul.rn.f32 	%f19, %f7, 0f45520000;
	selp.f32 	%f20, %f19, 0f00000000, %p8;
	ld.global.nc.f32 	%f21, [%rd54+24];
	mul.rn.f32 	%f22, %f21, 0f43D20000;
	add.rn.f32 	%f23, %f20, %f22;
	add.s64 	%rd62, %rd27, %rd34;
	ld.global.nc.f32 	%f24, [%rd62];
	add.rn.f32 	%f25, %f24, %f23;
	add.s64 	%rd63, %rd28, %rd34;
	ld.global.nc.f32 	%f26, [%rd63];
	add.rn.f32 	%f27, %f26, %f25;
	st.global.f32 	[%rd61+144], %f27;
	setp.eq.s32 	%p9, %r23, %r6;
	mul.rn.f32 	%f28, %f7, 0f41400000;
	selp.f32 	%f29, %f28, 0f00000000, %p9;
	ld.global.nc.f32 	%f30, [%rd54+48];
	add.rn.f32 	%f31, %f29, %f30;
	st.global.f32 	[%rd61+288], %f31;
	ret;

}
	// .globl	input_concatenate_fusion_333
.visible .entry input_concatenate_fusion_333(
	.param .u64 input_concatenate_fusion_333_param_0,
	.param .u64 input_concatenate_fusion_333_param_1,
	.param .u64 input_concatenate_fusion_333_param_2,
	.param .u64 input_concatenate_fusion_333_param_3,
	.param .u64 input_concatenate_fusion_333_param_4,
	.param .u64 input_concatenate_fusion_333_param_5,
	.param .u64 input_concatenate_fusion_333_param_6,
	.param .u64 input_concatenate_fusion_333_param_7,
	.param .u64 input_concatenate_fusion_333_param_8,
	.param .u64 input_concatenate_fusion_333_param_9,
	.param .u64 input_concatenate_fusion_333_param_10,
	.param .u64 input_concatenate_fusion_333_param_11,
	.param .u64 input_concatenate_fusion_333_param_12,
	.param .u64 input_concatenate_fusion_333_param_13
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<65>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_333_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_333_param_13];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [input_concatenate_fusion_333_param_1];
	ld.param.u64 	%rd5, [input_concatenate_fusion_333_param_12];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [input_concatenate_fusion_333_param_2];
	ld.param.u64 	%rd8, [input_concatenate_fusion_333_param_11];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [input_concatenate_fusion_333_param_3];
	ld.param.u64 	%rd11, [input_concatenate_fusion_333_param_10];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [input_concatenate_fusion_333_param_4];
	ld.param.u64 	%rd14, [input_concatenate_fusion_333_param_9];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [input_concatenate_fusion_333_param_5];
	ld.param.u64 	%rd17, [input_concatenate_fusion_333_param_8];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [input_concatenate_fusion_333_param_6];
	ld.param.u64 	%rd20, [input_concatenate_fusion_333_param_7];
	cvta.to.global.u64 	%rd21, %rd20;
	cvta.to.global.u64 	%rd22, %rd19;
	cvta.to.global.u64 	%rd23, %rd16;
	cvta.to.global.u64 	%rd24, %rd13;
	cvta.to.global.u64 	%rd25, %rd10;
	cvta.to.global.u64 	%rd26, %rd7;
	cvta.to.global.u64 	%rd27, %rd4;
	cvta.to.global.u64 	%rd28, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd29, %r5, 4;
	add.s64 	%rd30, %rd22, %rd29;
	ld.global.nc.u32 	%r6, [%rd30];
	add.s64 	%rd31, %rd21, %rd29;
	ld.global.nc.u32 	%r7, [%rd31];
	add.s64 	%rd32, %rd18, %rd29;
	ld.global.nc.u32 	%r8, [%rd32];
	max.s32 	%r9, %r6, %r7;
	setp.gt.s32 	%p1, %r8, %r9;
	add.s64 	%rd33, %rd12, %rd29;
	ld.global.nc.f32 	%f1, [%rd33];
	setp.gt.f32 	%p2, %f1, 0f41800000;
	selp.u32 	%r10, 1, 0, %p2;
	setp.eq.s32 	%p3, %r6, %r10;
	mul.wide.u32 	%rd34, %r4, 4;
	add.s64 	%rd35, %rd15, %rd34;
	ld.global.nc.f32 	%f2, [%rd35];
	selp.f32 	%f3, %f2, 0f00000000, %p3;
	mul.lo.s16 	%rs11, %rs10, 6;
	add.s16 	%rs12, %rs11, %rs5;
	mul.hi.u16 	%rs14, %rs12, -21845;
	shr.u16 	%rs15, %rs14, 2;
	cvt.u32.u16 	%r11, %rs15;
	mul.wide.u32 	%rd36, %r11, 4;
	add.s64 	%rd37, %rd12, %rd36;
	ld.global.nc.f32 	%f4, [%rd37];
	setp.gt.f32 	%p4, %f4, 0f41800000;
	selp.u32 	%r12, 1, 0, %p4;
	add.s64 	%rd38, %rd22, %rd36;
	ld.global.nc.u32 	%r13, [%rd38];
	setp.eq.s32 	%p5, %r13, %r12;
	setp.gt.u16 	%p6, %rs12, 377;
	selp.b16 	%rs16, 63, %rs15, %p6;
	mul.lo.s16 	%rs17, %rs15, 6;
	sub.s16 	%rs18, %rs12, %rs17;
	cvt.u32.u16 	%r14, %rs18;
	mul.wide.u32 	%rd39, %r14, 4;
	mul.wide.u32 	%rd40, %r11, 24;
	add.s64 	%rd41, %rd9, %rd40;
	add.s64 	%rd42, %rd41, %rd39;
	ld.global.nc.u32 	%r15, [%rd42];
	setp.lt.s32 	%p7, %r15, 0;
	add.s32 	%r16, %r15, 6;
	selp.b32 	%r17, %r16, %r15, %p7;
	max.s32 	%r18, %r17, 0;
	min.s32 	%r19, %r18, 5;
	mul.wide.u32 	%rd43, %r19, 4;
	cvt.u32.u16 	%r20, %rs16;
	mul.wide.u32 	%rd44, %r20, 144;
	add.s64 	%rd45, %rd6, %rd44;
	cvt.u32.u16 	%r21, %rs8;
	mul.wide.u32 	%rd46, %r21, 24;
	add.s64 	%rd47, %rd45, %rd46;
	add.s64 	%rd48, %rd47, %rd43;
	ld.global.nc.f32 	%f5, [%rd48];
	selp.f32 	%f6, %f5, 0f00000000, %p5;
	add.rn.f32 	%f7, %f3, %f6;
	mul.rn.f32 	%f8, %f7, 0f49F3A200;
	selp.f32 	%f9, 0f00000000, %f8, %p1;
	cvt.u32.u16 	%r22, %rs5;
	mul.wide.u32 	%rd49, %r22, 72;
	mul.wide.u32 	%rd50, %r5, 432;
	add.s64 	%rd51, %rd23, %rd50;
	add.s64 	%rd52, %rd51, %rd49;
	mul.wide.u32 	%rd53, %r21, 4;
	add.s64 	%rd54, %rd52, %rd53;
	ld.global.nc.f32 	%f10, [%rd54];
	mul.rn.f32 	%f11, %f10, 0f48875A00;
	add.rn.f32 	%f12, %f11, %f9;
	add.s64 	%rd55, %rd24, %rd34;
	ld.global.nc.f32 	%f13, [%rd55];
	add.rn.f32 	%f14, %f13, %f12;
	add.s64 	%rd56, %rd25, %rd34;
	ld.global.nc.f32 	%f15, [%rd56];
	add.rn.f32 	%f16, %f15, %f14;
	add.s64 	%rd57, %rd26, %rd34;
	ld.global.nc.f32 	%f17, [%rd57];
	add.rn.f32 	%f18, %f17, %f16;
	mul.wide.u32 	%rd58, %r21, 72;
	add.s64 	%rd59, %rd3, %rd50;
	add.s64 	%rd60, %rd59, %rd58;
	mul.wide.u32 	%rd61, %r22, 4;
	add.s64 	%rd62, %rd60, %rd61;
	st.global.f32 	[%rd62], %f18;
	min.s32 	%r23, %r8, %r9;
	setp.eq.s32 	%p8, %r23, 1;
	mul.rn.f32 	%f19, %f7, 0f45520000;
	selp.f32 	%f20, %f19, 0f00000000, %p8;
	ld.global.nc.f32 	%f21, [%rd54+24];
	mul.rn.f32 	%f22, %f21, 0f43D20000;
	add.rn.f32 	%f23, %f20, %f22;
	add.s64 	%rd63, %rd27, %rd34;
	ld.global.nc.f32 	%f24, [%rd63];
	add.rn.f32 	%f25, %f24, %f23;
	add.s64 	%rd64, %rd28, %rd34;
	ld.global.nc.f32 	%f26, [%rd64];
	add.rn.f32 	%f27, %f26, %f25;
	st.global.f32 	[%rd62+24], %f27;
	setp.eq.s32 	%p9, %r23, %r6;
	mul.rn.f32 	%f28, %f7, 0f41400000;
	selp.f32 	%f29, %f28, 0f00000000, %p9;
	ld.global.nc.f32 	%f30, [%rd54+48];
	add.rn.f32 	%f31, %f29, %f30;
	st.global.f32 	[%rd62+48], %f31;
	ret;

}
	// .globl	loop_add_fusion_413
.visible .entry loop_add_fusion_413(
	.param .u64 loop_add_fusion_413_param_0,
	.param .u64 loop_add_fusion_413_param_1,
	.param .u64 loop_add_fusion_413_param_2,
	.param .u64 loop_add_fusion_413_param_3,
	.param .u64 loop_add_fusion_413_param_4,
	.param .u64 loop_add_fusion_413_param_5,
	.param .u64 loop_add_fusion_413_param_6,
	.param .u64 loop_add_fusion_413_param_7,
	.param .u64 loop_add_fusion_413_param_8
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<8>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<23>;
	.reg .f32 	%f<15>;
	.reg .b64 	%rd<46>;

	ld.param.u64 	%rd1, [loop_add_fusion_413_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_413_param_8];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_413_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_413_param_7];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_413_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_413_param_6];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_413_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_413_param_5];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_413_param_4];
	cvta.to.global.u64 	%rd14, %rd13;
	cvta.to.global.u64 	%rd15, %rd10;
	cvta.to.global.u64 	%rd16, %rd7;
	cvta.to.global.u64 	%rd17, %rd4;
	cvta.to.global.u64 	%rd18, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	cvt.u32.u16 	%r5, %rs3;
	mul.wide.u32 	%rd19, %r5, 4;
	add.s64 	%rd20, %rd15, %rd19;
	ld.global.nc.u32 	%r6, [%rd20];
	add.s64 	%rd21, %rd14, %rd19;
	ld.global.nc.u32 	%r7, [%rd21];
	add.s64 	%rd22, %rd16, %rd19;
	ld.global.nc.u32 	%r8, [%rd22];
	max.s32 	%r9, %r6, %r7;
	setp.gt.s32 	%p1, %r8, %r9;
	add.s64 	%rd23, %rd3, %rd19;
	ld.global.nc.f32 	%f1, [%rd23];
	setp.gt.f32 	%p2, %f1, 0f41800000;
	selp.u32 	%r10, 1, 0, %p2;
	setp.eq.s32 	%p3, %r6, %r10;
	mul.wide.u32 	%rd24, %r4, 4;
	add.s64 	%rd25, %rd6, %rd24;
	ld.global.nc.f32 	%f2, [%rd25];
	selp.f32 	%f3, %f2, 0f00000000, %p3;
	mul.lo.s16 	%rs11, %rs3, 6;
	add.s16 	%rs12, %rs8, %rs11;
	mul.hi.u16 	%rs14, %rs12, -21845;
	shr.u16 	%rs15, %rs14, 2;
	cvt.u32.u16 	%r11, %rs15;
	mul.wide.u32 	%rd26, %r11, 4;
	add.s64 	%rd27, %rd3, %rd26;
	ld.global.nc.f32 	%f4, [%rd27];
	setp.gt.f32 	%p4, %f4, 0f41800000;
	selp.u32 	%r12, 1, 0, %p4;
	add.s64 	%rd28, %rd15, %rd26;
	ld.global.nc.u32 	%r13, [%rd28];
	setp.eq.s32 	%p5, %r13, %r12;
	setp.gt.u16 	%p6, %rs12, 377;
	selp.b16 	%rs16, 63, %rs15, %p6;
	mul.lo.s16 	%rs17, %rs15, 6;
	sub.s16 	%rs18, %rs12, %rs17;
	cvt.u32.u16 	%r14, %rs18;
	mul.wide.u32 	%rd29, %r14, 4;
	mul.wide.u32 	%rd30, %r11, 24;
	add.s64 	%rd31, %rd12, %rd30;
	add.s64 	%rd32, %rd31, %rd29;
	ld.global.nc.u32 	%r15, [%rd32];
	setp.lt.s32 	%p7, %r15, 0;
	add.s32 	%r16, %r15, 6;
	selp.b32 	%r17, %r16, %r15, %p7;
	max.s32 	%r18, %r17, 0;
	min.s32 	%r19, %r18, 5;
	mul.wide.u32 	%rd33, %r19, 4;
	cvt.u32.u16 	%r20, %rs16;
	mul.wide.u32 	%rd34, %r20, 144;
	add.s64 	%rd35, %rd9, %rd34;
	cvt.u32.u16 	%r21, %rs10;
	mul.wide.u32 	%rd36, %r21, 24;
	add.s64 	%rd37, %rd35, %rd36;
	add.s64 	%rd38, %rd37, %rd33;
	ld.global.nc.f32 	%f5, [%rd38];
	selp.f32 	%f6, %f5, 0f00000000, %p5;
	add.rn.f32 	%f7, %f3, %f6;
	mul.rn.f32 	%f8, %f7, 0f46C4E000;
	selp.f32 	%f9, 0f00000000, %f8, %p1;
	cvt.u32.u16 	%r22, %rs8;
	mul.wide.u32 	%rd39, %r22, 72;
	mul.wide.u32 	%rd40, %r5, 432;
	add.s64 	%rd41, %rd17, %rd40;
	add.s64 	%rd42, %rd41, %rd39;
	mul.wide.u32 	%rd43, %r21, 4;
	add.s64 	%rd44, %rd42, %rd43;
	ld.global.nc.f32 	%f10, [%rd44];
	mul.rn.f32 	%f11, %f10, 0f44BD0000;
	add.rn.f32 	%f12, %f11, %f9;
	add.s64 	%rd45, %rd18, %rd24;
	ld.global.f32 	%f13, [%rd45];
	add.rn.f32 	%f14, %f13, %f12;
	st.global.f32 	[%rd45], %f14;
	ret;

}
	// .globl	input_concatenate_fusion_338
.visible .entry input_concatenate_fusion_338(
	.param .u64 input_concatenate_fusion_338_param_0,
	.param .u64 input_concatenate_fusion_338_param_1,
	.param .u64 input_concatenate_fusion_338_param_2,
	.param .u64 input_concatenate_fusion_338_param_3,
	.param .u64 input_concatenate_fusion_338_param_4,
	.param .u64 input_concatenate_fusion_338_param_5,
	.param .u64 input_concatenate_fusion_338_param_6,
	.param .u64 input_concatenate_fusion_338_param_7,
	.param .u64 input_concatenate_fusion_338_param_8,
	.param .u64 input_concatenate_fusion_338_param_9,
	.param .u64 input_concatenate_fusion_338_param_10,
	.param .u64 input_concatenate_fusion_338_param_11,
	.param .u64 input_concatenate_fusion_338_param_12,
	.param .u64 input_concatenate_fusion_338_param_13
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<35>;
	.reg .b64 	%rd<68>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_338_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_338_param_13];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [input_concatenate_fusion_338_param_1];
	ld.param.u64 	%rd5, [input_concatenate_fusion_338_param_12];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [input_concatenate_fusion_338_param_2];
	ld.param.u64 	%rd8, [input_concatenate_fusion_338_param_11];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [input_concatenate_fusion_338_param_3];
	ld.param.u64 	%rd11, [input_concatenate_fusion_338_param_10];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [input_concatenate_fusion_338_param_4];
	ld.param.u64 	%rd14, [input_concatenate_fusion_338_param_9];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [input_concatenate_fusion_338_param_5];
	ld.param.u64 	%rd17, [input_concatenate_fusion_338_param_8];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [input_concatenate_fusion_338_param_6];
	ld.param.u64 	%rd20, [input_concatenate_fusion_338_param_7];
	cvta.to.global.u64 	%rd21, %rd20;
	cvta.to.global.u64 	%rd22, %rd19;
	cvta.to.global.u64 	%rd23, %rd16;
	cvta.to.global.u64 	%rd24, %rd13;
	cvta.to.global.u64 	%rd25, %rd10;
	cvta.to.global.u64 	%rd26, %rd7;
	cvta.to.global.u64 	%rd27, %rd4;
	cvta.to.global.u64 	%rd28, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd29, %r5, 4;
	add.s64 	%rd30, %rd22, %rd29;
	ld.global.nc.u32 	%r6, [%rd30];
	add.s64 	%rd31, %rd21, %rd29;
	ld.global.nc.u32 	%r7, [%rd31];
	add.s64 	%rd32, %rd18, %rd29;
	ld.global.nc.u32 	%r8, [%rd32];
	max.s32 	%r9, %r6, %r7;
	setp.gt.s32 	%p1, %r8, %r9;
	add.s64 	%rd33, %rd6, %rd29;
	ld.global.nc.f32 	%f1, [%rd33];
	setp.gt.f32 	%p2, %f1, 0f41800000;
	selp.u32 	%r10, 1, 0, %p2;
	setp.eq.s32 	%p3, %r6, %r10;
	cvt.u32.u16 	%r11, %rs8;
	mul.wide.u32 	%rd34, %r11, 24;
	mul.wide.u32 	%rd35, %r5, 144;
	add.s64 	%rd36, %rd9, %rd35;
	add.s64 	%rd37, %rd36, %rd34;
	cvt.u32.u16 	%r12, %rs5;
	mul.wide.u32 	%rd38, %r12, 4;
	add.s64 	%rd39, %rd37, %rd38;
	ld.global.nc.f32 	%f2, [%rd39];
	selp.f32 	%f3, %f2, 0f00000000, %p3;
	mul.lo.s16 	%rs11, %rs10, 6;
	add.s16 	%rs12, %rs8, %rs11;
	mul.hi.u16 	%rs14, %rs12, -21845;
	shr.u16 	%rs15, %rs14, 2;
	cvt.u32.u16 	%r13, %rs15;
	mul.wide.u32 	%rd40, %r13, 4;
	add.s64 	%rd41, %rd6, %rd40;
	ld.global.nc.f32 	%f4, [%rd41];
	setp.gt.f32 	%p4, %f4, 0f41800000;
	selp.u32 	%r14, 1, 0, %p4;
	add.s64 	%rd42, %rd22, %rd40;
	ld.global.nc.u32 	%r15, [%rd42];
	setp.eq.s32 	%p5, %r15, %r14;
	setp.gt.u16 	%p6, %rs12, 377;
	selp.b16 	%rs16, 63, %rs15, %p6;
	mul.lo.s16 	%rs17, %rs15, 6;
	sub.s16 	%rs18, %rs12, %rs17;
	cvt.u32.u16 	%r16, %rs18;
	mul.wide.u32 	%rd43, %r16, 4;
	mul.wide.u32 	%rd44, %r13, 24;
	add.s64 	%rd45, %rd15, %rd44;
	add.s64 	%rd46, %rd45, %rd43;
	ld.global.nc.u32 	%r17, [%rd46];
	setp.lt.s32 	%p7, %r17, 0;
	add.s32 	%r18, %r17, 6;
	selp.b32 	%r19, %r18, %r17, %p7;
	max.s32 	%r20, %r19, 0;
	min.s32 	%r21, %r20, 5;
	mul.wide.u32 	%rd47, %r21, 4;
	cvt.u32.u16 	%r22, %rs16;
	mul.wide.u32 	%rd48, %r22, 144;
	add.s64 	%rd49, %rd12, %rd48;
	mul.wide.u32 	%rd50, %r12, 24;
	add.s64 	%rd51, %rd49, %rd50;
	add.s64 	%rd52, %rd51, %rd47;
	ld.global.nc.f32 	%f5, [%rd52];
	selp.f32 	%f6, %f5, 0f00000000, %p5;
	add.rn.f32 	%f7, %f3, %f6;
	mul.rn.f32 	%f8, %f7, 0f49F3A200;
	selp.f32 	%f9, 0f00000000, %f8, %p1;
	mul.wide.u32 	%rd53, %r11, 72;
	mul.wide.u32 	%rd54, %r5, 432;
	add.s64 	%rd55, %rd23, %rd54;
	add.s64 	%rd56, %rd55, %rd53;
	add.s64 	%rd57, %rd56, %rd38;
	ld.global.nc.f32 	%f10, [%rd57];
	mul.rn.f32 	%f11, %f10, 0f48875A00;
	add.rn.f32 	%f12, %f11, %f9;
	mul.wide.u32 	%rd58, %r4, 4;
	add.s64 	%rd59, %rd24, %rd58;
	ld.global.nc.f32 	%f13, [%rd59];
	add.rn.f32 	%f14, %f13, %f12;
	add.s64 	%rd60, %rd25, %rd58;
	ld.global.nc.f32 	%f15, [%rd60];
	add.rn.f32 	%f16, %f15, %f14;
	add.s64 	%rd61, %rd26, %rd58;
	ld.global.nc.f32 	%f17, [%rd61];
	add.rn.f32 	%f18, %f17, %f16;
	add.s64 	%rd62, %rd3, %rd54;
	add.s64 	%rd63, %rd62, %rd53;
	add.s64 	%rd64, %rd63, %rd38;
	st.global.f32 	[%rd64], %f18;
	min.s32 	%r23, %r8, %r9;
	setp.eq.s32 	%p8, %r23, 1;
	add.s64 	%rd65, %rd9, %rd58;
	ld.global.nc.f32 	%f19, [%rd65];
	selp.f32 	%f20, %f19, 0f00000000, %p3;
	add.rn.f32 	%f21, %f6, %f20;
	mul.rn.f32 	%f22, %f21, 0f45520000;
	selp.f32 	%f23, %f22, 0f00000000, %p8;
	ld.global.nc.f32 	%f24, [%rd57+24];
	mul.rn.f32 	%f25, %f24, 0f43D20000;
	add.rn.f32 	%f26, %f25, %f23;
	add.s64 	%rd66, %rd27, %rd58;
	ld.global.nc.f32 	%f27, [%rd66];
	add.rn.f32 	%f28, %f27, %f26;
	add.s64 	%rd67, %rd28, %rd58;
	ld.global.nc.f32 	%f29, [%rd67];
	add.rn.f32 	%f30, %f29, %f28;
	st.global.f32 	[%rd64+24], %f30;
	setp.eq.s32 	%p9, %r23, %r6;
	mul.rn.f32 	%f31, %f21, 0f41400000;
	selp.f32 	%f32, %f31, 0f00000000, %p9;
	ld.global.nc.f32 	%f33, [%rd57+48];
	add.rn.f32 	%f34, %f32, %f33;
	st.global.f32 	[%rd64+48], %f34;
	ret;

}
	// .globl	input_concatenate_fusion_339
.visible .entry input_concatenate_fusion_339(
	.param .u64 input_concatenate_fusion_339_param_0,
	.param .u64 input_concatenate_fusion_339_param_1,
	.param .u64 input_concatenate_fusion_339_param_2,
	.param .u64 input_concatenate_fusion_339_param_3,
	.param .u64 input_concatenate_fusion_339_param_4,
	.param .u64 input_concatenate_fusion_339_param_5,
	.param .u64 input_concatenate_fusion_339_param_6,
	.param .u64 input_concatenate_fusion_339_param_7,
	.param .u64 input_concatenate_fusion_339_param_8,
	.param .u64 input_concatenate_fusion_339_param_9,
	.param .u64 input_concatenate_fusion_339_param_10,
	.param .u64 input_concatenate_fusion_339_param_11,
	.param .u64 input_concatenate_fusion_339_param_12,
	.param .u64 input_concatenate_fusion_339_param_13
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<19>;
	.reg .b32 	%r<24>;
	.reg .f32 	%f<35>;
	.reg .b64 	%rd<68>;

	ld.param.u64 	%rd1, [input_concatenate_fusion_339_param_0];
	ld.param.u64 	%rd2, [input_concatenate_fusion_339_param_13];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [input_concatenate_fusion_339_param_1];
	ld.param.u64 	%rd5, [input_concatenate_fusion_339_param_12];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [input_concatenate_fusion_339_param_2];
	ld.param.u64 	%rd8, [input_concatenate_fusion_339_param_11];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [input_concatenate_fusion_339_param_3];
	ld.param.u64 	%rd11, [input_concatenate_fusion_339_param_10];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [input_concatenate_fusion_339_param_4];
	ld.param.u64 	%rd14, [input_concatenate_fusion_339_param_9];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [input_concatenate_fusion_339_param_5];
	ld.param.u64 	%rd17, [input_concatenate_fusion_339_param_8];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [input_concatenate_fusion_339_param_6];
	ld.param.u64 	%rd20, [input_concatenate_fusion_339_param_7];
	cvta.to.global.u64 	%rd21, %rd20;
	cvta.to.global.u64 	%rd22, %rd19;
	cvta.to.global.u64 	%rd23, %rd16;
	cvta.to.global.u64 	%rd24, %rd13;
	cvta.to.global.u64 	%rd25, %rd10;
	cvta.to.global.u64 	%rd26, %rd7;
	cvta.to.global.u64 	%rd27, %rd4;
	cvta.to.global.u64 	%rd28, %rd1;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r3, %r1, 7;
	or.b32  	%r4, %r3, %r2;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	cvt.u32.u16 	%r5, %rs10;
	mul.wide.u32 	%rd29, %r5, 4;
	add.s64 	%rd30, %rd22, %rd29;
	ld.global.nc.u32 	%r6, [%rd30];
	add.s64 	%rd31, %rd21, %rd29;
	ld.global.nc.u32 	%r7, [%rd31];
	add.s64 	%rd32, %rd18, %rd29;
	ld.global.nc.u32 	%r8, [%rd32];
	max.s32 	%r9, %r6, %r7;
	setp.gt.s32 	%p1, %r8, %r9;
	add.s64 	%rd33, %rd6, %rd29;
	ld.global.nc.f32 	%f1, [%rd33];
	setp.gt.f32 	%p2, %f1, 0f41800000;
	selp.u32 	%r10, 1, 0, %p2;
	setp.eq.s32 	%p3, %r6, %r10;
	cvt.u32.u16 	%r11, %rs8;
	mul.wide.u32 	%rd34, %r11, 24;
	mul.wide.u32 	%rd35, %r5, 144;
	add.s64 	%rd36, %rd9, %rd35;
	add.s64 	%rd37, %rd36, %rd34;
	cvt.u32.u16 	%r12, %rs5;
	mul.wide.u32 	%rd38, %r12, 4;
	add.s64 	%rd39, %rd37, %rd38;
	ld.global.nc.f32 	%f2, [%rd39];
	selp.f32 	%f3, %f2, 0f00000000, %p3;
	mul.lo.s16 	%rs11, %rs10, 6;
	add.s16 	%rs12, %rs8, %rs11;
	mul.hi.u16 	%rs14, %rs12, -21845;
	shr.u16 	%rs15, %rs14, 2;
	cvt.u32.u16 	%r13, %rs15;
	mul.wide.u32 	%rd40, %r13, 4;
	add.s64 	%rd41, %rd6, %rd40;
	ld.global.nc.f32 	%f4, [%rd41];
	setp.gt.f32 	%p4, %f4, 0f41800000;
	selp.u32 	%r14, 1, 0, %p4;
	add.s64 	%rd42, %rd22, %rd40;
	ld.global.nc.u32 	%r15, [%rd42];
	setp.eq.s32 	%p5, %r15, %r14;
	setp.gt.u16 	%p6, %rs12, 377;
	selp.b16 	%rs16, 63, %rs15, %p6;
	mul.lo.s16 	%rs17, %rs15, 6;
	sub.s16 	%rs18, %rs12, %rs17;
	cvt.u32.u16 	%r16, %rs18;
	mul.wide.u32 	%rd43, %r16, 4;
	mul.wide.u32 	%rd44, %r13, 24;
	add.s64 	%rd45, %rd15, %rd44;
	add.s64 	%rd46, %rd45, %rd43;
	ld.global.nc.u32 	%r17, [%rd46];
	setp.lt.s32 	%p7, %r17, 0;
	add.s32 	%r18, %r17, 6;
	selp.b32 	%r19, %r18, %r17, %p7;
	max.s32 	%r20, %r19, 0;
	min.s32 	%r21, %r20, 5;
	mul.wide.u32 	%rd47, %r21, 4;
	cvt.u32.u16 	%r22, %rs16;
	mul.wide.u32 	%rd48, %r22, 144;
	add.s64 	%rd49, %rd12, %rd48;
	mul.wide.u32 	%rd50, %r12, 24;
	add.s64 	%rd51, %rd49, %rd50;
	add.s64 	%rd52, %rd51, %rd47;
	ld.global.nc.f32 	%f5, [%rd52];
	selp.f32 	%f6, %f5, 0f00000000, %p5;
	add.rn.f32 	%f7, %f3, %f6;
	mul.rn.f32 	%f8, %f7, 0f49F3A200;
	selp.f32 	%f9, 0f00000000, %f8, %p1;
	mul.wide.u32 	%rd53, %r11, 72;
	mul.wide.u32 	%rd54, %r5, 432;
	add.s64 	%rd55, %rd23, %rd54;
	add.s64 	%rd56, %rd55, %rd53;
	add.s64 	%rd57, %rd56, %rd38;
	ld.global.nc.f32 	%f10, [%rd57];
	mul.rn.f32 	%f11, %f10, 0f48875A00;
	add.rn.f32 	%f12, %f11, %f9;
	mul.wide.u32 	%rd58, %r4, 4;
	add.s64 	%rd59, %rd24, %rd58;
	ld.global.nc.f32 	%f13, [%rd59];
	add.rn.f32 	%f14, %f13, %f12;
	add.s64 	%rd60, %rd25, %rd58;
	ld.global.nc.f32 	%f15, [%rd60];
	add.rn.f32 	%f16, %f15, %f14;
	add.s64 	%rd61, %rd26, %rd58;
	ld.global.nc.f32 	%f17, [%rd61];
	add.rn.f32 	%f18, %f17, %f16;
	add.s64 	%rd62, %rd3, %rd54;
	add.s64 	%rd63, %rd62, %rd34;
	add.s64 	%rd64, %rd63, %rd38;
	st.global.f32 	[%rd64], %f18;
	min.s32 	%r23, %r8, %r9;
	setp.eq.s32 	%p8, %r23, 1;
	add.s64 	%rd65, %rd9, %rd58;
	ld.global.nc.f32 	%f19, [%rd65];
	selp.f32 	%f20, %f19, 0f00000000, %p3;
	add.rn.f32 	%f21, %f6, %f20;
	mul.rn.f32 	%f22, %f21, 0f45520000;
	selp.f32 	%f23, %f22, 0f00000000, %p8;
	ld.global.nc.f32 	%f24, [%rd57+24];
	mul.rn.f32 	%f25, %f24, 0f43D20000;
	add.rn.f32 	%f26, %f25, %f23;
	add.s64 	%rd66, %rd27, %rd58;
	ld.global.nc.f32 	%f27, [%rd66];
	add.rn.f32 	%f28, %f27, %f26;
	add.s64 	%rd67, %rd28, %rd58;
	ld.global.nc.f32 	%f29, [%rd67];
	add.rn.f32 	%f30, %f29, %f28;
	st.global.f32 	[%rd64+144], %f30;
	setp.eq.s32 	%p9, %r23, %r6;
	mul.rn.f32 	%f31, %f21, 0f41400000;
	selp.f32 	%f32, %f31, 0f00000000, %p9;
	ld.global.nc.f32 	%f33, [%rd57+48];
	add.rn.f32 	%f34, %f32, %f33;
	st.global.f32 	[%rd64+288], %f34;
	ret;

}
	// .globl	loop_add_divide_fusion_1
.visible .entry loop_add_divide_fusion_1(
	.param .u64 loop_add_divide_fusion_1_param_0,
	.param .u64 loop_add_divide_fusion_1_param_1,
	.param .u64 loop_add_divide_fusion_1_param_2,
	.param .u64 loop_add_divide_fusion_1_param_3,
	.param .u64 loop_add_divide_fusion_1_param_4,
	.param .u64 loop_add_divide_fusion_1_param_5,
	.param .u64 loop_add_divide_fusion_1_param_6,
	.param .u64 loop_add_divide_fusion_1_param_7,
	.param .u64 loop_add_divide_fusion_1_param_8,
	.param .u64 loop_add_divide_fusion_1_param_9,
	.param .u64 loop_add_divide_fusion_1_param_10,
	.param .u64 loop_add_divide_fusion_1_param_11,
	.param .u64 loop_add_divide_fusion_1_param_12,
	.param .u64 loop_add_divide_fusion_1_param_13,
	.param .u64 loop_add_divide_fusion_1_param_14,
	.param .u64 loop_add_divide_fusion_1_param_15,
	.param .u64 loop_add_divide_fusion_1_param_16,
	.param .u64 loop_add_divide_fusion_1_param_17,
	.param .u64 loop_add_divide_fusion_1_param_18,
	.param .u64 loop_add_divide_fusion_1_param_19,
	.param .u64 loop_add_divide_fusion_1_param_20,
	.param .u64 loop_add_divide_fusion_1_param_21,
	.param .u64 loop_add_divide_fusion_1_param_22,
	.param .u64 loop_add_divide_fusion_1_param_23,
	.param .u64 loop_add_divide_fusion_1_param_24,
	.param .u64 loop_add_divide_fusion_1_param_25,
	.param .u64 loop_add_divide_fusion_1_param_26,
	.param .u64 loop_add_divide_fusion_1_param_27,
	.param .u64 loop_add_divide_fusion_1_param_28,
	.param .u64 loop_add_divide_fusion_1_param_29,
	.param .u64 loop_add_divide_fusion_1_param_30,
	.param .u64 loop_add_divide_fusion_1_param_31,
	.param .u64 loop_add_divide_fusion_1_param_32,
	.param .u64 loop_add_divide_fusion_1_param_33,
	.param .u64 loop_add_divide_fusion_1_param_34,
	.param .u64 loop_add_divide_fusion_1_param_35,
	.param .u64 loop_add_divide_fusion_1_param_36,
	.param .u64 loop_add_divide_fusion_1_param_37,
	.param .u64 loop_add_divide_fusion_1_param_38,
	.param .u64 loop_add_divide_fusion_1_param_39,
	.param .u64 loop_add_divide_fusion_1_param_40,
	.param .u64 loop_add_divide_fusion_1_param_41,
	.param .u64 loop_add_divide_fusion_1_param_42,
	.param .u64 loop_add_divide_fusion_1_param_43,
	.param .u64 loop_add_divide_fusion_1_param_44,
	.param .u64 loop_add_divide_fusion_1_param_45,
	.param .u64 loop_add_divide_fusion_1_param_46,
	.param .u64 loop_add_divide_fusion_1_param_47,
	.param .u64 loop_add_divide_fusion_1_param_48,
	.param .u64 loop_add_divide_fusion_1_param_49,
	.param .u64 loop_add_divide_fusion_1_param_50,
	.param .u64 loop_add_divide_fusion_1_param_51,
	.param .u64 loop_add_divide_fusion_1_param_52,
	.param .u64 loop_add_divide_fusion_1_param_53
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<38>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<42>;
	.reg .f32 	%f<254>;
	.reg .b64 	%rd<247>;

	ld.param.u64 	%rd19, [loop_add_divide_fusion_1_param_0];
	ld.param.u64 	%rd20, [loop_add_divide_fusion_1_param_53];
	ld.param.u64 	%rd21, [loop_add_divide_fusion_1_param_1];
	ld.param.u64 	%rd22, [loop_add_divide_fusion_1_param_52];
	ld.param.u64 	%rd23, [loop_add_divide_fusion_1_param_2];
	ld.param.u64 	%rd24, [loop_add_divide_fusion_1_param_51];
	ld.param.u64 	%rd25, [loop_add_divide_fusion_1_param_3];
	ld.param.u64 	%rd26, [loop_add_divide_fusion_1_param_50];
	ld.param.u64 	%rd27, [loop_add_divide_fusion_1_param_4];
	ld.param.u64 	%rd28, [loop_add_divide_fusion_1_param_49];
	ld.param.u64 	%rd29, [loop_add_divide_fusion_1_param_5];
	ld.param.u64 	%rd30, [loop_add_divide_fusion_1_param_48];
	ld.param.u64 	%rd31, [loop_add_divide_fusion_1_param_6];
	ld.param.u64 	%rd32, [loop_add_divide_fusion_1_param_47];
	ld.param.u64 	%rd33, [loop_add_divide_fusion_1_param_7];
	ld.param.u64 	%rd34, [loop_add_divide_fusion_1_param_46];
	cvta.to.global.u64 	%rd8, %rd34;
	ld.param.u64 	%rd35, [loop_add_divide_fusion_1_param_8];
	ld.param.u64 	%rd36, [loop_add_divide_fusion_1_param_45];
	cvta.to.global.u64 	%rd9, %rd36;
	ld.param.u64 	%rd37, [loop_add_divide_fusion_1_param_9];
	ld.param.u64 	%rd38, [loop_add_divide_fusion_1_param_44];
	cvta.to.global.u64 	%rd10, %rd38;
	ld.param.u64 	%rd39, [loop_add_divide_fusion_1_param_10];
	ld.param.u64 	%rd40, [loop_add_divide_fusion_1_param_43];
	cvta.to.global.u64 	%rd11, %rd40;
	ld.param.u64 	%rd41, [loop_add_divide_fusion_1_param_11];
	ld.param.u64 	%rd42, [loop_add_divide_fusion_1_param_42];
	cvta.to.global.u64 	%rd12, %rd42;
	ld.param.u64 	%rd43, [loop_add_divide_fusion_1_param_12];
	ld.param.u64 	%rd44, [loop_add_divide_fusion_1_param_41];
	cvta.to.global.u64 	%rd13, %rd44;
	ld.param.u64 	%rd45, [loop_add_divide_fusion_1_param_13];
	ld.param.u64 	%rd46, [loop_add_divide_fusion_1_param_40];
	cvta.to.global.u64 	%rd14, %rd46;
	ld.param.u64 	%rd47, [loop_add_divide_fusion_1_param_14];
	ld.param.u64 	%rd48, [loop_add_divide_fusion_1_param_39];
	cvta.to.global.u64 	%rd49, %rd48;
	ld.param.u64 	%rd50, [loop_add_divide_fusion_1_param_15];
	ld.param.u64 	%rd51, [loop_add_divide_fusion_1_param_38];
	cvta.to.global.u64 	%rd52, %rd51;
	ld.param.u64 	%rd53, [loop_add_divide_fusion_1_param_16];
	ld.param.u64 	%rd54, [loop_add_divide_fusion_1_param_37];
	cvta.to.global.u64 	%rd55, %rd54;
	ld.param.u64 	%rd56, [loop_add_divide_fusion_1_param_17];
	ld.param.u64 	%rd57, [loop_add_divide_fusion_1_param_36];
	cvta.to.global.u64 	%rd58, %rd57;
	ld.param.u64 	%rd59, [loop_add_divide_fusion_1_param_18];
	ld.param.u64 	%rd60, [loop_add_divide_fusion_1_param_35];
	cvta.to.global.u64 	%rd61, %rd60;
	ld.param.u64 	%rd62, [loop_add_divide_fusion_1_param_19];
	ld.param.u64 	%rd63, [loop_add_divide_fusion_1_param_34];
	cvta.to.global.u64 	%rd64, %rd63;
	ld.param.u64 	%rd65, [loop_add_divide_fusion_1_param_20];
	ld.param.u64 	%rd66, [loop_add_divide_fusion_1_param_33];
	cvta.to.global.u64 	%rd67, %rd66;
	ld.param.u64 	%rd68, [loop_add_divide_fusion_1_param_21];
	ld.param.u64 	%rd69, [loop_add_divide_fusion_1_param_32];
	cvta.to.global.u64 	%rd70, %rd69;
	ld.param.u64 	%rd71, [loop_add_divide_fusion_1_param_22];
	ld.param.u64 	%rd72, [loop_add_divide_fusion_1_param_31];
	cvta.to.global.u64 	%rd73, %rd72;
	ld.param.u64 	%rd74, [loop_add_divide_fusion_1_param_23];
	ld.param.u64 	%rd75, [loop_add_divide_fusion_1_param_30];
	cvta.to.global.u64 	%rd76, %rd75;
	ld.param.u64 	%rd77, [loop_add_divide_fusion_1_param_24];
	ld.param.u64 	%rd78, [loop_add_divide_fusion_1_param_29];
	cvta.to.global.u64 	%rd79, %rd78;
	ld.param.u64 	%rd80, [loop_add_divide_fusion_1_param_25];
	ld.param.u64 	%rd81, [loop_add_divide_fusion_1_param_28];
	cvta.to.global.u64 	%rd82, %rd81;
	ld.param.u64 	%rd83, [loop_add_divide_fusion_1_param_26];
	ld.param.u64 	%rd84, [loop_add_divide_fusion_1_param_27];
	cvta.to.global.u64 	%rd85, %rd84;
	cvta.to.global.u64 	%rd86, %rd83;
	cvta.to.global.u64 	%rd87, %rd80;
	cvta.to.global.u64 	%rd88, %rd77;
	cvta.to.global.u64 	%rd89, %rd74;
	cvta.to.global.u64 	%rd90, %rd71;
	cvta.to.global.u64 	%rd91, %rd68;
	cvta.to.global.u64 	%rd92, %rd65;
	cvta.to.global.u64 	%rd93, %rd62;
	cvta.to.global.u64 	%rd94, %rd59;
	cvta.to.global.u64 	%rd95, %rd56;
	cvta.to.global.u64 	%rd96, %rd53;
	cvta.to.global.u64 	%rd97, %rd50;
	cvta.to.global.u64 	%rd98, %rd47;
	cvta.to.global.u64 	%rd99, %rd45;
	cvta.to.global.u64 	%rd100, %rd43;
	cvta.to.global.u64 	%rd101, %rd41;
	cvta.to.global.u64 	%rd102, %rd39;
	cvta.to.global.u64 	%rd103, %rd37;
	cvta.to.global.u64 	%rd104, %rd35;
	cvta.to.global.u64 	%rd105, %rd33;
	cvta.to.global.u64 	%rd106, %rd31;
	cvta.to.global.u64 	%rd107, %rd29;
	cvta.to.global.u64 	%rd108, %rd27;
	cvta.to.global.u64 	%rd109, %rd25;
	cvta.to.global.u64 	%rd110, %rd23;
	cvta.to.global.u64 	%rd111, %rd21;
	cvta.to.global.u64 	%rd112, %rd19;
	mov.u32 	%r9, %ctaid.x;
	mov.u32 	%r10, %tid.x;
	shl.b32 	%r11, %r9, 7;
	or.b32  	%r12, %r11, %r10;
	cvt.u16.u32 	%rs1, %r12;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	ld.global.nc.f32 	%f1, [%rd109];
	cvt.u64.u16 	%rd15, %rs10;
	cvt.u32.u16 	%r13, %rs10;
	mul.wide.u32 	%rd113, %r13, 4;
	add.s64 	%rd114, %rd102, %rd113;
	ld.global.nc.u32 	%r1, [%rd114];
	add.s64 	%rd115, %rd98, %rd113;
	ld.global.nc.u32 	%r2, [%rd115];
	add.s64 	%rd116, %rd99, %rd113;
	ld.global.nc.u32 	%r3, [%rd116];
	cvt.u64.u16 	%rd16, %rs8;
	cvt.u64.u16 	%rd17, %rs5;
	cvt.u32.u16 	%r14, %rs8;
	mul.wide.u32 	%rd117, %r14, 72;
	mul.wide.u32 	%rd118, %r13, 432;
	add.s64 	%rd119, %rd103, %rd118;
	add.s64 	%rd120, %rd119, %rd117;
	cvt.u32.u16 	%r15, %rs5;
	mul.wide.u32 	%rd121, %r15, 4;
	add.s64 	%rd122, %rd120, %rd121;
	ld.global.nc.f32 	%f2, [%rd122];
	mul.wide.u32 	%rd123, %r14, 24;
	add.s64 	%rd124, %rd104, %rd118;
	add.s64 	%rd125, %rd124, %rd123;
	add.s64 	%rd126, %rd125, %rd121;
	ld.global.nc.f32 	%f3, [%rd126];
	mul.wide.u32 	%rd127, %r12, 4;
	add.s64 	%rd128, %rd100, %rd127;
	ld.global.nc.f32 	%f4, [%rd128];
	ld.global.nc.f32 	%f5, [%rd122+24];
	ld.global.nc.f32 	%f6, [%rd126+144];
	add.s64 	%rd129, %rd101, %rd127;
	ld.global.nc.f32 	%f7, [%rd129];
	ld.global.nc.f32 	%f8, [%rd122+48];
	ld.global.nc.f32 	%f9, [%rd126+288];
	add.s64 	%rd130, %rd105, %rd127;
	ld.global.nc.f32 	%f10, [%rd130];
	add.s64 	%rd131, %rd110, %rd113;
	ld.global.nc.f32 	%f11, [%rd131];
	mul.wide.u32 	%rd132, %r15, 72;
	add.s64 	%rd133, %rd119, %rd132;
	mul.wide.u32 	%rd134, %r14, 4;
	add.s64 	%rd135, %rd133, %rd134;
	ld.global.nc.f32 	%f12, [%rd135];
	mul.wide.u32 	%rd136, %r15, 24;
	add.s64 	%rd137, %rd124, %rd136;
	add.s64 	%rd138, %rd137, %rd134;
	ld.global.nc.f32 	%f13, [%rd138];
	mul.wide.u32 	%rd139, %r13, 144;
	add.s64 	%rd140, %rd100, %rd139;
	add.s64 	%rd141, %rd140, %rd136;
	add.s64 	%rd142, %rd141, %rd134;
	ld.global.nc.f32 	%f14, [%rd142];
	ld.global.nc.f32 	%f15, [%rd135+24];
	ld.global.nc.f32 	%f16, [%rd138+144];
	add.s64 	%rd143, %rd101, %rd139;
	add.s64 	%rd144, %rd143, %rd136;
	add.s64 	%rd145, %rd144, %rd134;
	ld.global.nc.f32 	%f17, [%rd145];
	ld.global.nc.f32 	%f18, [%rd135+48];
	ld.global.nc.f32 	%f19, [%rd138+288];
	add.s64 	%rd146, %rd105, %rd139;
	add.s64 	%rd147, %rd146, %rd136;
	add.s64 	%rd148, %rd147, %rd134;
	ld.global.nc.f32 	%f20, [%rd148];
	ld.global.nc.f32 	%f21, [%rd111];
	add.s64 	%rd149, %rd112, %rd127;
	ld.global.nc.f32 	%f22, [%rd149];
	ld.global.nc.f32 	%f23, [%rd106];
	ld.global.nc.f32 	%f24, [%rd107];
	add.s64 	%rd150, %rd108, %rd127;
	ld.global.nc.f32 	%f25, [%rd150];
	add.s64 	%rd151, %rd92, %rd113;
	ld.global.nc.u32 	%r4, [%rd151];
	add.s64 	%rd152, %rd95, %rd118;
	add.s64 	%rd153, %rd152, %rd132;
	add.s64 	%rd154, %rd153, %rd134;
	ld.global.nc.f32 	%f26, [%rd154];
	add.s64 	%rd155, %rd96, %rd118;
	add.s64 	%rd156, %rd155, %rd136;
	add.s64 	%rd157, %rd156, %rd134;
	ld.global.nc.f32 	%f27, [%rd157];
	add.s64 	%rd158, %rd93, %rd139;
	add.s64 	%rd159, %rd158, %rd136;
	add.s64 	%rd160, %rd159, %rd134;
	ld.global.nc.f32 	%f28, [%rd160];
	ld.global.nc.f32 	%f29, [%rd154+24];
	ld.global.nc.f32 	%f30, [%rd157+144];
	add.s64 	%rd161, %rd94, %rd139;
	add.s64 	%rd162, %rd161, %rd136;
	add.s64 	%rd163, %rd162, %rd134;
	ld.global.nc.f32 	%f31, [%rd163];
	ld.global.nc.f32 	%f32, [%rd154+48];
	ld.global.nc.f32 	%f33, [%rd157+288];
	add.s64 	%rd164, %rd97, %rd139;
	add.s64 	%rd165, %rd164, %rd136;
	add.s64 	%rd166, %rd165, %rd134;
	ld.global.nc.f32 	%f34, [%rd166];
	add.s64 	%rd167, %rd86, %rd113;
	ld.global.nc.u32 	%r5, [%rd167];
	add.s64 	%rd168, %rd89, %rd118;
	add.s64 	%rd169, %rd168, %rd132;
	add.s64 	%rd170, %rd169, %rd134;
	ld.global.nc.f32 	%f35, [%rd170];
	add.s64 	%rd171, %rd90, %rd118;
	add.s64 	%rd172, %rd171, %rd136;
	add.s64 	%rd173, %rd172, %rd134;
	ld.global.nc.f32 	%f36, [%rd173];
	add.s64 	%rd174, %rd87, %rd139;
	add.s64 	%rd175, %rd174, %rd136;
	add.s64 	%rd176, %rd175, %rd134;
	ld.global.nc.f32 	%f37, [%rd176];
	ld.global.nc.f32 	%f38, [%rd170+24];
	ld.global.nc.f32 	%f39, [%rd173+144];
	add.s64 	%rd177, %rd88, %rd139;
	add.s64 	%rd178, %rd177, %rd136;
	add.s64 	%rd179, %rd178, %rd134;
	ld.global.nc.f32 	%f40, [%rd179];
	ld.global.nc.f32 	%f41, [%rd170+48];
	ld.global.nc.f32 	%f42, [%rd173+288];
	add.s64 	%rd180, %rd91, %rd139;
	add.s64 	%rd181, %rd180, %rd136;
	add.s64 	%rd182, %rd181, %rd134;
	ld.global.nc.f32 	%f43, [%rd182];
	add.s64 	%rd183, %rd70, %rd113;
	ld.global.nc.u32 	%r6, [%rd183];
	add.s64 	%rd184, %rd79, %rd118;
	add.s64 	%rd185, %rd184, %rd132;
	add.s64 	%rd186, %rd185, %rd134;
	ld.global.nc.f32 	%f44, [%rd186];
	add.s64 	%rd187, %rd82, %rd118;
	add.s64 	%rd188, %rd187, %rd136;
	add.s64 	%rd189, %rd188, %rd134;
	ld.global.nc.f32 	%f45, [%rd189];
	add.s64 	%rd190, %rd73, %rd139;
	add.s64 	%rd191, %rd190, %rd136;
	add.s64 	%rd192, %rd191, %rd134;
	ld.global.nc.f32 	%f46, [%rd192];
	ld.global.nc.f32 	%f47, [%rd186+24];
	ld.global.nc.f32 	%f48, [%rd189+144];
	add.s64 	%rd193, %rd76, %rd139;
	add.s64 	%rd194, %rd193, %rd136;
	add.s64 	%rd195, %rd194, %rd134;
	ld.global.nc.f32 	%f49, [%rd195];
	ld.global.nc.f32 	%f50, [%rd186+48];
	ld.global.nc.f32 	%f51, [%rd189+288];
	add.s64 	%rd196, %rd85, %rd139;
	add.s64 	%rd197, %rd196, %rd136;
	add.s64 	%rd198, %rd197, %rd134;
	ld.global.nc.f32 	%f52, [%rd198];
	add.s64 	%rd199, %rd49, %rd113;
	ld.global.nc.u32 	%r7, [%rd199];
	add.s64 	%rd200, %rd58, %rd118;
	add.s64 	%rd201, %rd200, %rd132;
	add.s64 	%rd202, %rd201, %rd134;
	ld.global.nc.f32 	%f53, [%rd202];
	add.s64 	%rd203, %rd61, %rd118;
	add.s64 	%rd204, %rd203, %rd136;
	add.s64 	%rd205, %rd204, %rd134;
	ld.global.nc.f32 	%f54, [%rd205];
	add.s64 	%rd206, %rd52, %rd139;
	add.s64 	%rd207, %rd206, %rd136;
	add.s64 	%rd208, %rd207, %rd134;
	ld.global.nc.f32 	%f55, [%rd208];
	ld.global.nc.f32 	%f56, [%rd202+24];
	ld.global.nc.f32 	%f57, [%rd205+144];
	add.s64 	%rd209, %rd55, %rd139;
	add.s64 	%rd210, %rd209, %rd136;
	add.s64 	%rd211, %rd210, %rd134;
	ld.global.nc.f32 	%f58, [%rd211];
	ld.global.nc.f32 	%f59, [%rd202+48];
	ld.global.nc.f32 	%f60, [%rd205+288];
	add.s64 	%rd212, %rd64, %rd139;
	add.s64 	%rd213, %rd212, %rd136;
	add.s64 	%rd214, %rd213, %rd134;
	ld.global.nc.f32 	%f61, [%rd214];
	add.s64 	%rd215, %rd67, %rd113;
	ld.global.nc.f32 	%f62, [%rd215];
	mov.f32 	%f87, 0f40000000;
	abs.f32 	%f63, %f87;
	setp.lt.f32 	%p1, %f63, 0f00800000;
	mul.rn.f32 	%f88, %f63, 0f4B800000;
	selp.f32 	%f89, %f88, %f63, %p1;
	selp.f32 	%f90, 0fC1C00000, 0f00000000, %p1;
	mov.b32 	%r16, %f89;
	add.s32 	%r17, %r16, -1060439283;
	and.b32  	%r18, %r17, -8388608;
	sub.s32 	%r19, %r16, %r18;
	mov.b32 	%f91, %r19;
	cvt.rn.f32.s32 	%f92, %r18;
	fma.rn.f32 	%f93, %f92, 0f34000000, %f90;
	add.rn.f32 	%f94, %f91, 0fBF800000;
	add.rn.f32 	%f85, %f91, 0f3F800000;
	// begin inline asm
	rcp.approx.ftz.f32 %f84,%f85;
	// end inline asm
	add.rn.f32 	%f95, %f94, %f94;
	mul.rn.f32 	%f96, %f95, %f84;
	mul.rn.f32 	%f97, %f96, %f96;
	sub.rn.f32 	%f98, %f94, %f96;
	add.rn.f32 	%f99, %f98, %f98;
	neg.f32 	%f100, %f96;
	fma.rn.f32 	%f101, %f100, %f94, %f99;
	mul.rn.f32 	%f102, %f84, %f101;
	fma.rn.f32 	%f103, %f97, 0f3A2C32E4, 0f3B52E7DB;
	fma.rn.f32 	%f104, %f103, %f97, 0f3C93BB73;
	fma.rn.f32 	%f105, %f104, %f97, 0f3DF6384F;
	mul.rn.f32 	%f106, %f105, %f97;
	fma.rn.f32 	%f107, %f96, 0f3FB8AA3B, %f93;
	sub.rn.f32 	%f108, %f93, %f107;
	fma.rn.f32 	%f109, %f96, 0f3FB8AA3B, %f108;
	fma.rn.f32 	%f110, %f102, 0f3FB8AA3B, %f109;
	fma.rn.f32 	%f111, %f96, 0f32A55E34, %f110;
	mul.rn.f32 	%f112, %f106, 0f40400000;
	fma.rn.f32 	%f113, %f112, %f102, %f111;
	fma.rn.f32 	%f114, %f106, %f96, %f113;
	add.rn.f32 	%f64, %f107, %f114;
	neg.f32 	%f115, %f107;
	add.rn.f32 	%f116, %f64, %f115;
	neg.f32 	%f117, %f116;
	add.rn.f32 	%f65, %f114, %f117;
	setp.eq.f32 	%p5, %f62, 0f00000000;
	mov.f32 	%f253, 0f3F800000;
	mov.f32 	%f252, %f253;
	@%p5 bra 	$L__BB330_4;
	setp.nan.f32 	%p6, %f63, %f63;
	abs.f32 	%f137, %f62;
	setp.nan.f32 	%p7, %f137, %f137;
	or.pred  	%p8, %p6, %p7;
	@!%p8 bra 	$L__BB330_3;
	bra.uni 	$L__BB330_2;
$L__BB330_2:
	add.rn.f32 	%f252, %f87, %f62;
	bra.uni 	$L__BB330_4;
$L__BB330_3:
	mul.rn.f32 	%f118, %f64, %f62;
	neg.f32 	%f119, %f118;
	fma.rn.f32 	%f120, %f64, %f62, %f119;
	fma.rn.f32 	%f121, %f65, %f62, %f120;
	cvt.rni.f32.f32 	%f122, %f118;
	sub.rn.f32 	%f123, %f118, %f122;
	add.rn.f32 	%f124, %f123, %f121;
	fma.rn.f32 	%f125, %f124, 0f391FCB8E, 0f3AAF85ED;
	fma.rn.f32 	%f126, %f125, %f124, 0f3C1D9856;
	fma.rn.f32 	%f127, %f126, %f124, 0f3D6357BB;
	fma.rn.f32 	%f128, %f127, %f124, 0f3E75FDEC;
	fma.rn.f32 	%f129, %f128, %f124, 0f3F317218;
	fma.rn.f32 	%f130, %f129, %f124, 0f3F800000;
	cvt.rzi.s32.f32 	%r20, %f122;
	setp.gt.f32 	%p2, %f122, 0f00000000;
	selp.b32 	%r21, 0, -2097152000, %p2;
	add.s32 	%r22, %r21, 2130706432;
	mov.b32 	%f131, %r22;
	mul.rn.f32 	%f132, %f130, %f131;
	shl.b32 	%r23, %r20, 23;
	sub.s32 	%r24, %r23, %r21;
	mov.b32 	%f133, %r24;
	mul.rn.f32 	%f134, %f132, %f133;
	abs.f32 	%f135, %f118;
	setp.gt.f32 	%p3, %f135, 0f43180000;
	setp.lt.f32 	%p4, %f118, 0f00000000;
	selp.f32 	%f136, 0f00000000, 0f7F800000, %p4;
	selp.f32 	%f66, %f136, %f134, %p3;
	setp.eq.f32 	%p9, %f63, 0f7F800000;
	setp.lt.f32 	%p10, %f62, 0f00000000;
	selp.f32 	%f138, 0f3F000000, 0f40800000, %p10;
	selp.f32 	%f252, %f138, %f66, %p9;
$L__BB330_4:
	cvta.to.global.u64 	%rd1, %rd20;
	cvta.to.global.u64 	%rd2, %rd22;
	cvta.to.global.u64 	%rd3, %rd24;
	cvta.to.global.u64 	%rd4, %rd26;
	cvta.to.global.u64 	%rd5, %rd28;
	cvta.to.global.u64 	%rd6, %rd30;
	cvta.to.global.u64 	%rd7, %rd32;
	cvt.u64.u32 	%rd18, %r12;
	shl.b64 	%rd216, %rd15, 2;
	add.s64 	%rd217, %rd8, %rd216;
	ld.global.nc.u32 	%r8, [%rd217];
	mul.lo.s64 	%rd218, %rd15, 432;
	add.s64 	%rd219, %rd11, %rd218;
	mul.lo.s64 	%rd220, %rd17, 72;
	add.s64 	%rd221, %rd219, %rd220;
	shl.b64 	%rd222, %rd16, 2;
	add.s64 	%rd223, %rd221, %rd222;
	ld.global.nc.f32 	%f70, [%rd223];
	add.s64 	%rd224, %rd12, %rd218;
	mul.lo.s64 	%rd225, %rd17, 24;
	add.s64 	%rd226, %rd224, %rd225;
	add.s64 	%rd227, %rd226, %rd222;
	ld.global.nc.f32 	%f71, [%rd227];
	mul.lo.s64 	%rd228, %rd15, 144;
	add.s64 	%rd229, %rd9, %rd228;
	add.s64 	%rd230, %rd229, %rd225;
	add.s64 	%rd231, %rd230, %rd222;
	ld.global.nc.f32 	%f72, [%rd231];
	ld.global.nc.f32 	%f73, [%rd223+24];
	ld.global.nc.f32 	%f74, [%rd227+144];
	add.s64 	%rd232, %rd10, %rd228;
	add.s64 	%rd233, %rd232, %rd225;
	add.s64 	%rd234, %rd233, %rd222;
	ld.global.nc.f32 	%f75, [%rd234];
	ld.global.nc.f32 	%f76, [%rd223+48];
	ld.global.nc.f32 	%f77, [%rd227+288];
	add.s64 	%rd235, %rd13, %rd228;
	add.s64 	%rd236, %rd235, %rd225;
	add.s64 	%rd237, %rd236, %rd222;
	ld.global.nc.f32 	%f78, [%rd237];
	add.s64 	%rd238, %rd14, %rd216;
	ld.global.nc.f32 	%f79, [%rd238];
	setp.eq.f32 	%p14, %f79, 0f00000000;
	@%p14 bra 	$L__BB330_8;
	setp.nan.f32 	%p15, %f63, %f63;
	abs.f32 	%f160, %f79;
	setp.nan.f32 	%p16, %f160, %f160;
	or.pred  	%p17, %p15, %p16;
	@!%p17 bra 	$L__BB330_7;
	bra.uni 	$L__BB330_6;
$L__BB330_6:
	add.rn.f32 	%f253, %f87, %f79;
	bra.uni 	$L__BB330_8;
$L__BB330_7:
	mul.rn.f32 	%f141, %f64, %f79;
	neg.f32 	%f142, %f141;
	fma.rn.f32 	%f143, %f64, %f79, %f142;
	fma.rn.f32 	%f144, %f65, %f79, %f143;
	cvt.rni.f32.f32 	%f145, %f141;
	sub.rn.f32 	%f146, %f141, %f145;
	add.rn.f32 	%f147, %f146, %f144;
	fma.rn.f32 	%f148, %f147, 0f391FCB8E, 0f3AAF85ED;
	fma.rn.f32 	%f149, %f148, %f147, 0f3C1D9856;
	fma.rn.f32 	%f150, %f149, %f147, 0f3D6357BB;
	fma.rn.f32 	%f151, %f150, %f147, 0f3E75FDEC;
	fma.rn.f32 	%f152, %f151, %f147, 0f3F317218;
	fma.rn.f32 	%f153, %f152, %f147, 0f3F800000;
	cvt.rzi.s32.f32 	%r25, %f145;
	setp.gt.f32 	%p11, %f145, 0f00000000;
	selp.b32 	%r26, 0, -2097152000, %p11;
	add.s32 	%r27, %r26, 2130706432;
	mov.b32 	%f154, %r27;
	mul.rn.f32 	%f155, %f153, %f154;
	shl.b32 	%r28, %r25, 23;
	sub.s32 	%r29, %r28, %r26;
	mov.b32 	%f156, %r29;
	mul.rn.f32 	%f157, %f155, %f156;
	abs.f32 	%f158, %f141;
	setp.gt.f32 	%p12, %f158, 0f43180000;
	setp.lt.f32 	%p13, %f141, 0f00000000;
	selp.f32 	%f159, 0f00000000, 0f7F800000, %p13;
	selp.f32 	%f80, %f159, %f157, %p12;
	setp.eq.f32 	%p18, %f63, 0f7F800000;
	setp.lt.f32 	%p19, %f79, 0f00000000;
	selp.f32 	%f161, 0f3F000000, 0f40800000, %p19;
	selp.f32 	%f253, %f161, %f80, %p18;
$L__BB330_8:
	max.s32 	%r30, %r1, %r8;
	setp.gt.s32 	%p20, %r3, %r30;
	add.rn.f32 	%f163, %f70, %f71;
	add.rn.f32 	%f164, %f163, %f72;
	selp.f32 	%f165, 0f00000000, %f164, %p20;
	min.s32 	%r31, %r3, %r30;
	setp.eq.s32 	%p21, %r31, 1;
	add.rn.f32 	%f166, %f73, %f74;
	add.rn.f32 	%f167, %f166, %f75;
	selp.f32 	%f168, %f167, 0f00000000, %p21;
	add.rn.f32 	%f169, %f165, %f168;
	setp.eq.s32 	%p22, %r31, %r1;
	add.rn.f32 	%f170, %f76, %f77;
	add.rn.f32 	%f171, %f170, %f78;
	selp.f32 	%f172, %f171, 0f00000000, %p22;
	add.rn.f32 	%f173, %f169, %f172;
	max.s32 	%r32, %r1, %r7;
	setp.gt.s32 	%p23, %r3, %r32;
	add.rn.f32 	%f174, %f53, %f54;
	add.rn.f32 	%f175, %f174, %f55;
	selp.f32 	%f176, 0f00000000, %f175, %p23;
	min.s32 	%r33, %r3, %r32;
	setp.eq.s32 	%p24, %r33, 1;
	add.rn.f32 	%f177, %f56, %f57;
	add.rn.f32 	%f178, %f177, %f58;
	selp.f32 	%f179, %f178, 0f00000000, %p24;
	add.rn.f32 	%f180, %f176, %f179;
	setp.eq.s32 	%p25, %r33, %r1;
	add.rn.f32 	%f181, %f59, %f60;
	add.rn.f32 	%f182, %f181, %f61;
	selp.f32 	%f183, %f182, 0f00000000, %p25;
	add.rn.f32 	%f184, %f180, %f183;
	div.full.f32 	%f185, %f184, %f252;
	max.s32 	%r34, %r1, %r6;
	setp.gt.s32 	%p26, %r3, %r34;
	add.rn.f32 	%f186, %f44, %f45;
	add.rn.f32 	%f187, %f186, %f46;
	selp.f32 	%f188, 0f00000000, %f187, %p26;
	min.s32 	%r35, %r3, %r34;
	setp.eq.s32 	%p27, %r35, 1;
	add.rn.f32 	%f189, %f47, %f48;
	add.rn.f32 	%f190, %f189, %f49;
	selp.f32 	%f191, %f190, 0f00000000, %p27;
	add.rn.f32 	%f192, %f188, %f191;
	setp.eq.s32 	%p28, %r35, %r1;
	add.rn.f32 	%f193, %f50, %f51;
	add.rn.f32 	%f194, %f193, %f52;
	selp.f32 	%f195, %f194, 0f00000000, %p28;
	add.rn.f32 	%f196, %f192, %f195;
	max.s32 	%r36, %r1, %r5;
	setp.gt.s32 	%p29, %r3, %r36;
	add.rn.f32 	%f197, %f35, %f36;
	add.rn.f32 	%f198, %f197, %f37;
	selp.f32 	%f199, 0f00000000, %f198, %p29;
	min.s32 	%r37, %r3, %r36;
	setp.eq.s32 	%p30, %r37, 1;
	add.rn.f32 	%f200, %f38, %f39;
	add.rn.f32 	%f201, %f200, %f40;
	selp.f32 	%f202, %f201, 0f00000000, %p30;
	add.rn.f32 	%f203, %f199, %f202;
	setp.eq.s32 	%p31, %r37, %r1;
	add.rn.f32 	%f204, %f41, %f42;
	add.rn.f32 	%f205, %f204, %f43;
	selp.f32 	%f206, %f205, 0f00000000, %p31;
	add.rn.f32 	%f207, %f203, %f206;
	max.s32 	%r38, %r1, %r4;
	setp.gt.s32 	%p32, %r3, %r38;
	add.rn.f32 	%f208, %f26, %f27;
	add.rn.f32 	%f209, %f208, %f28;
	selp.f32 	%f210, 0f00000000, %f209, %p32;
	min.s32 	%r39, %r3, %r38;
	setp.eq.s32 	%p33, %r39, 1;
	add.rn.f32 	%f211, %f29, %f30;
	add.rn.f32 	%f212, %f211, %f31;
	selp.f32 	%f213, %f212, 0f00000000, %p33;
	add.rn.f32 	%f214, %f210, %f213;
	setp.eq.s32 	%p34, %r39, %r1;
	add.rn.f32 	%f215, %f32, %f33;
	add.rn.f32 	%f216, %f215, %f34;
	selp.f32 	%f217, %f216, 0f00000000, %p34;
	add.rn.f32 	%f218, %f214, %f217;
	max.s32 	%r40, %r1, %r2;
	setp.gt.s32 	%p35, %r3, %r40;
	add.rn.f32 	%f219, %f2, %f3;
	add.rn.f32 	%f220, %f219, %f4;
	selp.f32 	%f221, 0f00000000, %f220, %p35;
	min.s32 	%r41, %r3, %r40;
	setp.eq.s32 	%p36, %r41, 1;
	add.rn.f32 	%f222, %f5, %f6;
	add.rn.f32 	%f223, %f222, %f7;
	selp.f32 	%f224, %f223, 0f00000000, %p36;
	add.rn.f32 	%f225, %f221, %f224;
	setp.eq.s32 	%p37, %r41, %r1;
	add.rn.f32 	%f226, %f8, %f9;
	add.rn.f32 	%f227, %f226, %f10;
	selp.f32 	%f228, %f227, 0f00000000, %p37;
	add.rn.f32 	%f229, %f225, %f228;
	div.full.f32 	%f230, %f229, %f11;
	add.rn.f32 	%f231, %f12, %f13;
	add.rn.f32 	%f232, %f231, %f14;
	selp.f32 	%f233, 0f00000000, %f232, %p35;
	add.rn.f32 	%f234, %f15, %f16;
	add.rn.f32 	%f235, %f234, %f17;
	selp.f32 	%f236, %f235, 0f00000000, %p36;
	add.rn.f32 	%f237, %f233, %f236;
	add.rn.f32 	%f238, %f18, %f19;
	add.rn.f32 	%f239, %f238, %f20;
	selp.f32 	%f240, %f239, 0f00000000, %p37;
	add.rn.f32 	%f241, %f237, %f240;
	div.full.f32 	%f242, %f241, %f11;
	sub.rn.f32 	%f243, %f230, %f242;
	mul.rn.f32 	%f244, %f243, %f243;
	mul.rn.f32 	%f245, %f23, %f244;
	mul.rn.f32 	%f246, %f24, %f25;
	add.rn.f32 	%f247, %f246, %f245;
	mul.rn.f32 	%f248, %f1, %f243;
	mul.rn.f32 	%f249, %f21, %f22;
	add.rn.f32 	%f250, %f249, %f248;
	div.full.f32 	%f251, %f173, %f253;
	shl.b64 	%rd239, %rd18, 2;
	add.s64 	%rd240, %rd7, %rd239;
	st.global.f32 	[%rd240], %f250;
	add.s64 	%rd241, %rd6, %rd239;
	st.global.f32 	[%rd241], %f247;
	add.s64 	%rd242, %rd5, %rd239;
	st.global.f32 	[%rd242], %f218;
	add.s64 	%rd243, %rd4, %rd239;
	st.global.f32 	[%rd243], %f207;
	add.s64 	%rd244, %rd3, %rd239;
	st.global.f32 	[%rd244], %f196;
	add.s64 	%rd245, %rd2, %rd239;
	st.global.f32 	[%rd245], %f185;
	add.s64 	%rd246, %rd1, %rd239;
	st.global.f32 	[%rd246], %f251;
	ret;

}
	// .globl	loop_add_fusion_414
.visible .entry loop_add_fusion_414(
	.param .u64 loop_add_fusion_414_param_0,
	.param .u64 loop_add_fusion_414_param_1,
	.param .u64 loop_add_fusion_414_param_2,
	.param .u64 loop_add_fusion_414_param_3,
	.param .u64 loop_add_fusion_414_param_4,
	.param .u64 loop_add_fusion_414_param_5,
	.param .u64 loop_add_fusion_414_param_6,
	.param .u64 loop_add_fusion_414_param_7,
	.param .u64 loop_add_fusion_414_param_8,
	.param .u64 loop_add_fusion_414_param_9
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<5>;
	.reg .f32 	%f<20>;
	.reg .b64 	%rd<26>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 10;
	or.b32  	%r1, %r4, %r3;
	setp.lt.u32 	%p1, %r1, 2304;
	@%p1 bra 	$L__BB331_2;
	bra.uni 	$L__BB331_1;
$L__BB331_2:
	ld.param.u64 	%rd11, [loop_add_fusion_414_param_0];
	ld.param.u64 	%rd12, [loop_add_fusion_414_param_9];
	cvta.to.global.u64 	%rd1, %rd12;
	ld.param.u64 	%rd13, [loop_add_fusion_414_param_1];
	ld.param.u64 	%rd14, [loop_add_fusion_414_param_8];
	cvta.to.global.u64 	%rd2, %rd14;
	ld.param.u64 	%rd15, [loop_add_fusion_414_param_2];
	ld.param.u64 	%rd16, [loop_add_fusion_414_param_7];
	cvta.to.global.u64 	%rd3, %rd16;
	ld.param.u64 	%rd17, [loop_add_fusion_414_param_3];
	ld.param.u64 	%rd18, [loop_add_fusion_414_param_6];
	cvta.to.global.u64 	%rd4, %rd18;
	ld.param.u64 	%rd19, [loop_add_fusion_414_param_4];
	ld.param.u64 	%rd20, [loop_add_fusion_414_param_5];
	cvta.to.global.u64 	%rd5, %rd20;
	cvta.to.global.u64 	%rd6, %rd19;
	cvta.to.global.u64 	%rd7, %rd17;
	cvta.to.global.u64 	%rd8, %rd15;
	cvta.to.global.u64 	%rd9, %rd13;
	cvta.to.global.u64 	%rd10, %rd11;
	mul.wide.u32 	%rd21, %r1, 4;
	add.s64 	%rd22, %rd10, %rd21;
	ld.global.nc.f32 	%f1, [%rd22];
	ld.global.nc.f32 	%f2, [%rd2];
	add.s64 	%rd23, %rd9, %rd21;
	ld.global.nc.f32 	%f3, [%rd23];
	ld.global.nc.f32 	%f4, [%rd3];
	add.s64 	%rd24, %rd8, %rd21;
	ld.global.nc.f32 	%f5, [%rd24];
	ld.global.nc.f32 	%f6, [%rd4];
	div.full.f32 	%f7, %f5, %f6;
	ld.global.nc.f32 	%f8, [%rd5];
	add.rn.f32 	%f9, %f7, %f8;
	sqrt.approx.f32 	%f10, %f9;
	ld.global.nc.f32 	%f11, [%rd6];
	add.rn.f32 	%f12, %f10, %f11;
	mul.rn.f32 	%f13, %f4, %f12;
	div.full.f32 	%f14, %f3, %f13;
	ld.global.nc.f32 	%f15, [%rd7];
	mul.rn.f32 	%f16, %f1, %f15;
	add.rn.f32 	%f17, %f16, %f14;
	mul.rn.f32 	%f18, %f2, %f17;
	add.rn.f32 	%f19, %f1, %f18;
	add.s64 	%rd25, %rd1, %rd21;
	st.global.f32 	[%rd25], %f19;
$L__BB331_1:
	ret;

}
	// .globl	loop_select_fusion_39
.visible .entry loop_select_fusion_39(
	.param .u64 loop_select_fusion_39_param_0,
	.param .u64 loop_select_fusion_39_param_1,
	.param .u64 loop_select_fusion_39_param_2,
	.param .u64 loop_select_fusion_39_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<16>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd1, [loop_select_fusion_39_param_0];
	ld.param.u64 	%rd2, [loop_select_fusion_39_param_3];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_select_fusion_39_param_1];
	ld.param.u64 	%rd5, [loop_select_fusion_39_param_2];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -7281;
	shr.u16 	%rs3, %rs2, 5;
	mul.hi.u16 	%rs4, %rs1, -21845;
	shr.u16 	%rs5, %rs4, 2;
	mul.hi.u16 	%rs6, %rs5, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs5, %rs7;
	mul.lo.s16 	%rs9, %rs5, 6;
	sub.s16 	%rs10, %rs1, %rs9;
	setp.eq.s16 	%p1, %rs8, %rs10;
	cvt.u32.u16 	%r5, %rs3;
	mul.wide.u32 	%rd9, %r5, 4;
	add.s64 	%rd10, %rd6, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	add.s64 	%rd11, %rd8, %rd9;
	ld.global.nc.f32 	%f2, [%rd11];
	mov.f32 	%f3, 0f3F800000;
	sub.rn.f32 	%f4, %f3, %f2;
	add.s64 	%rd12, %rd7, %rd9;
	ld.global.nc.f32 	%f5, [%rd12];
	div.full.f32 	%f6, %f4, %f5;
	sqrt.approx.f32 	%f7, %f6;
	mov.f32 	%f8, 0fBF000000;
	div.full.f32 	%f9, %f8, %f7;
	mul.rn.f32 	%f10, %f5, %f5;
	rcp.approx.f32 	%f11, %f10;
	mul.rn.f32 	%f12, %f9, %f1;
	mul.rn.f32 	%f13, %f11, %f12;
	mul.rn.f32 	%f14, %f4, %f13;
	selp.f32 	%f15, %f14, 0f00000000, %p1;
	mul.wide.u32 	%rd13, %r4, 4;
	add.s64 	%rd14, %rd3, %rd13;
	st.global.f32 	[%rd14], %f15;
	ret;

}
	// .globl	loop_add_fusion_415
.visible .entry loop_add_fusion_415(
	.param .u64 loop_add_fusion_415_param_0,
	.param .u64 loop_add_fusion_415_param_1,
	.param .u64 loop_add_fusion_415_param_2,
	.param .u64 loop_add_fusion_415_param_3,
	.param .u64 loop_add_fusion_415_param_4,
	.param .u64 loop_add_fusion_415_param_5,
	.param .u64 loop_add_fusion_415_param_6,
	.param .u64 loop_add_fusion_415_param_7,
	.param .u64 loop_add_fusion_415_param_8,
	.param .u64 loop_add_fusion_415_param_9,
	.param .u64 loop_add_fusion_415_param_10,
	.param .u64 loop_add_fusion_415_param_11,
	.param .u64 loop_add_fusion_415_param_12,
	.param .u64 loop_add_fusion_415_param_13,
	.param .u64 loop_add_fusion_415_param_14,
	.param .u64 loop_add_fusion_415_param_15,
	.param .u64 loop_add_fusion_415_param_16,
	.param .u64 loop_add_fusion_415_param_17
)
.reqntid 128, 1, 1
{
	.reg .b32 	%r<5>;
	.reg .f32 	%f<34>;
	.reg .b64 	%rd<46>;

	ld.param.u64 	%rd1, [loop_add_fusion_415_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_415_param_17];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_415_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_415_param_16];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_415_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_415_param_15];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_415_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_415_param_14];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_415_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_415_param_13];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_415_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_415_param_12];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_415_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_415_param_11];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_415_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_415_param_10];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_add_fusion_415_param_8];
	ld.param.u64 	%rd26, [loop_add_fusion_415_param_9];
	cvta.to.global.u64 	%rd27, %rd26;
	cvta.to.global.u64 	%rd28, %rd25;
	cvta.to.global.u64 	%rd29, %rd22;
	cvta.to.global.u64 	%rd30, %rd19;
	cvta.to.global.u64 	%rd31, %rd16;
	cvta.to.global.u64 	%rd32, %rd13;
	cvta.to.global.u64 	%rd33, %rd10;
	cvta.to.global.u64 	%rd34, %rd7;
	cvta.to.global.u64 	%rd35, %rd4;
	cvta.to.global.u64 	%rd36, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.wide.u32 	%rd37, %r4, 4;
	add.s64 	%rd38, %rd36, %rd37;
	ld.global.nc.f32 	%f1, [%rd38];
	ld.global.nc.f32 	%f2, [%rd35];
	ld.global.nc.f32 	%f3, [%rd12];
	add.s64 	%rd39, %rd27, %rd37;
	ld.global.nc.f32 	%f4, [%rd39];
	add.s64 	%rd40, %rd24, %rd37;
	ld.global.nc.f32 	%f5, [%rd40];
	add.rn.f32 	%f6, %f4, %f5;
	mul.rn.f32 	%f7, %f3, %f6;
	ld.global.nc.f32 	%f8, [%rd15];
	add.s64 	%rd41, %rd18, %rd37;
	ld.global.nc.f32 	%f9, [%rd41];
	mul.rn.f32 	%f10, %f8, %f9;
	add.rn.f32 	%f11, %f7, %f10;
	ld.global.nc.f32 	%f12, [%rd34];
	ld.global.nc.f32 	%f13, [%rd21];
	mul.rn.f32 	%f14, %f6, %f6;
	mul.rn.f32 	%f15, %f14, %f13;
	ld.global.nc.f32 	%f16, [%rd28];
	add.s64 	%rd42, %rd29, %rd37;
	ld.global.nc.f32 	%f17, [%rd42];
	mul.rn.f32 	%f18, %f16, %f17;
	add.rn.f32 	%f19, %f15, %f18;
	ld.global.nc.f32 	%f20, [%rd30];
	div.full.f32 	%f21, %f19, %f20;
	ld.global.nc.f32 	%f22, [%rd31];
	add.rn.f32 	%f23, %f22, %f21;
	sqrt.approx.f32 	%f24, %f23;
	ld.global.nc.f32 	%f25, [%rd32];
	add.rn.f32 	%f26, %f24, %f25;
	mul.rn.f32 	%f27, %f12, %f26;
	div.full.f32 	%f28, %f11, %f27;
	ld.global.nc.f32 	%f29, [%rd33];
	mul.rn.f32 	%f30, %f1, %f29;
	add.rn.f32 	%f31, %f30, %f28;
	mul.rn.f32 	%f32, %f2, %f31;
	add.rn.f32 	%f33, %f1, %f32;
	add.s64 	%rd43, %rd9, %rd37;
	st.global.f32 	[%rd43], %f33;
	add.s64 	%rd44, %rd6, %rd37;
	st.global.f32 	[%rd44], %f19;
	add.s64 	%rd45, %rd3, %rd37;
	st.global.f32 	[%rd45], %f11;
	ret;

}
	// .globl	loop_multiply_fusion_107
.visible .entry loop_multiply_fusion_107(
	.param .u64 loop_multiply_fusion_107_param_0,
	.param .u64 loop_multiply_fusion_107_param_1,
	.param .u64 loop_multiply_fusion_107_param_2,
	.param .u64 loop_multiply_fusion_107_param_3,
	.param .u64 loop_multiply_fusion_107_param_4,
	.param .u64 loop_multiply_fusion_107_param_5,
	.param .u64 loop_multiply_fusion_107_param_6,
	.param .u64 loop_multiply_fusion_107_param_7,
	.param .u64 loop_multiply_fusion_107_param_8
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot334[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<20>;
	.reg .b16 	%rs<18>;
	.reg .b32 	%r<120>;
	.reg .f32 	%f<99>;
	.reg .b64 	%rd<84>;
	.reg .f64 	%fd<5>;

	mov.u64 	%SPL, __local_depot334;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd24, [loop_multiply_fusion_107_param_2];
	ld.param.u64 	%rd26, [loop_multiply_fusion_107_param_3];
	ld.param.u64 	%rd27, [loop_multiply_fusion_107_param_5];
	cvta.to.global.u64 	%rd29, %rd26;
	cvta.to.global.u64 	%rd30, %rd24;
	mov.u32 	%r34, %ctaid.x;
	mov.u32 	%r35, %tid.x;
	shl.b32 	%r36, %r34, 7;
	or.b32  	%r1, %r36, %r35;
	cvt.u16.u32 	%rs2, %r1;
	mul.hi.u16 	%rs3, %rs2, -21845;
	shr.u16 	%rs4, %rs3, 2;
	mul.lo.s16 	%rs5, %rs4, 6;
	sub.s16 	%rs1, %rs2, %rs5;
	mul.hi.u16 	%rs6, %rs4, 21846;
	mul.lo.s16 	%rs7, %rs6, 3;
	sub.s16 	%rs8, %rs4, %rs7;
	cvt.u32.u16 	%r37, %rs8;
	mul.hi.u16 	%rs9, %rs2, -7281;
	shr.u16 	%rs10, %rs9, 4;
	mul.hi.u16 	%rs11, %rs10, 1311;
	mul.lo.s16 	%rs12, %rs11, 50;
	sub.s16 	%rs13, %rs10, %rs12;
	mul.hi.u16 	%rs14, %rs2, -28253;
	shr.u16 	%rs15, %rs14, 9;
	and.b16  	%rs16, %rs15, 63;
	cvt.u32.u16 	%r38, %rs16;
	mul.wide.u32 	%rd34, %r38, 4;
	add.s64 	%rd35, %rd29, %rd34;
	ld.global.nc.f32 	%f1, [%rd35];
	cvt.u32.u16 	%r39, %rs13;
	mul.wide.u32 	%rd36, %r39, 96;
	mul.wide.u32 	%rd37, %r38, 4800;
	add.s64 	%rd38, %rd30, %rd37;
	add.s64 	%rd39, %rd38, %rd36;
	mul.wide.u32 	%rd40, %r37, 24;
	add.s64 	%rd41, %rd39, %rd40;
	cvt.u32.u16 	%r40, %rs1;
	mul.wide.u32 	%rd42, %r40, 4;
	add.s64 	%rd43, %rd41, %rd42;
	ld.global.nc.f32 	%f2, [%rd43+24];
	and.b32  	%r2, %r37, 1;
	setp.eq.s32 	%p1, %r2, 0;
	mov.f32 	%f96, 0f00000000;
	mov.f32 	%f95, %f96;
	@%p1 bra 	$L__BB334_19;
	bra.uni 	$L__BB334_1;
$L__BB334_19:
	ld.param.u64 	%rd22, [loop_multiply_fusion_107_param_1];
	cvta.to.global.u64 	%rd31, %rd22;
	shr.u32 	%r41, %r37, 1;
	mul.wide.u32 	%rd44, %r39, 48;
	mul.wide.u32 	%rd45, %r38, 2400;
	add.s64 	%rd46, %rd31, %rd45;
	add.s64 	%rd47, %rd46, %rd44;
	mul.wide.u32 	%rd48, %r41, 24;
	add.s64 	%rd49, %rd47, %rd48;
	add.s64 	%rd12, %rd49, %rd42;
	ld.global.nc.f32 	%f95, [%rd12];
$L__BB334_1:
	add.u64 	%rd32, %SP, 0;
	cvt.u64.u16 	%rd9, %rs16;
	cvta.to.global.u64 	%rd4, %rd27;
	setp.ne.s32 	%p2, %r2, 0;
	@%p2 bra 	$L__BB334_20;
	bra.uni 	$L__BB334_2;
$L__BB334_20:
	ld.param.u64 	%rd20, [loop_multiply_fusion_107_param_0];
	cvta.to.global.u64 	%rd6, %rd20;
	cvt.u64.u16 	%rd10, %rs13;
	cvt.u64.u16 	%rd11, %rs1;
	mul.lo.s64 	%rd50, %rd9, 2400;
	add.s64 	%rd51, %rd6, %rd50;
	mul.lo.s64 	%rd52, %rd10, 48;
	add.s64 	%rd53, %rd51, %rd52;
	shl.b64 	%rd54, %rd11, 2;
	add.s64 	%rd13, %rd53, %rd54;
	ld.global.nc.f32 	%f96, [%rd13];
$L__BB334_2:
	ld.param.u64 	%rd21, [loop_multiply_fusion_107_param_8];
	ld.param.u64 	%rd23, [loop_multiply_fusion_107_param_7];
	ld.param.u64 	%rd25, [loop_multiply_fusion_107_param_6];
	ld.param.u64 	%rd28, [loop_multiply_fusion_107_param_4];
	cvta.to.local.u64 	%rd7, %rd32;
	shr.u16 	%rs17, %rs1, 1;
	mul.lo.s64 	%rd55, %rd9, 12;
	add.s64 	%rd56, %rd4, %rd55;
	cvt.u32.u16 	%r42, %rs17;
	mul.wide.u32 	%rd57, %r42, 4;
	add.s64 	%rd58, %rd56, %rd57;
	ld.global.nc.f32 	%f18, [%rd58];
	add.rn.f32 	%f19, %f18, %f18;
	add.rn.f32 	%f20, %f19, %f19;
	add.rn.f32 	%f5, %f20, %f20;
	mul.rn.f32 	%f21, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r119, %f21;
	cvt.rn.f32.s32 	%f22, %r119;
	fma.rn.f32 	%f23, %f22, 0fBFC90FDA, %f5;
	fma.rn.f32 	%f24, %f22, 0fB3A22168, %f23;
	fma.rn.f32 	%f98, %f22, 0fA7C234C5, %f24;
	abs.f32 	%f7, %f5;
	setp.ltu.f32 	%p3, %f7, 0f47CE4780;
	setp.neu.f32 	%p19, %f7, 0f7F800000;
	mov.u32 	%r115, %r119;
	mov.f32 	%f97, %f98;
	@%p3 bra 	$L__BB334_10;
	@%p19 bra 	$L__BB334_5;
	mov.f32 	%f27, 0f00000000;
	mul.rn.f32 	%f97, %f5, %f27;
	mov.b32 	%r115, 0;
	bra.uni 	$L__BB334_10;
$L__BB334_5:
	mov.b32 	%r4, %f5;
	shr.u32 	%r5, %r4, 23;
	and.b32  	%r44, %r5, 224;
	add.s32 	%r45, %r44, -128;
	shl.b32 	%r46, %r4, 8;
	or.b32  	%r50, %r46, -2147483648;
	shr.u32 	%r7, %r45, 5;
	mov.b32 	%r112, 0;
	mov.u64 	%rd82, 0;
	mov.u64 	%rd60, __cudart_i2opi_f;
$L__BB334_6:
	.pragma "nounroll";
	add.s64 	%rd61, %rd60, %rd82;
	ld.global.nc.u32 	%r49, [%rd61];
	// begin inline asm
	{
	mad.lo.cc.u32   %r47, %r49, %r50, %r112;
	madc.hi.u32     %r112, %r49, %r50,  0;
	}
	// end inline asm
	add.s64 	%rd62, %rd7, %rd82;
	st.local.u32 	[%rd62], %r47;
	add.s64 	%rd82, %rd82, 4;
	cvt.u32.u64 	%r52, %rd82;
	setp.ne.s32 	%p5, %r52, 24;
	@%p5 bra 	$L__BB334_6;
	st.local.u32 	[%rd7+24], %r112;
	and.b32  	%r10, %r5, 31;
	mul.wide.u32 	%rd63, %r7, 4;
	sub.s64 	%rd16, %rd7, %rd63;
	ld.local.u32 	%r113, [%rd16+24];
	ld.local.u32 	%r114, [%rd16+20];
	setp.eq.s32 	%p6, %r10, 0;
	@%p6 bra 	$L__BB334_9;
	shl.b32 	%r53, %r114, %r10;
	shl.b32 	%r54, %r113, %r10;
	mov.b32 	%r55, 32;
	sub.s32 	%r56, %r55, %r10;
	shr.u32 	%r57, %r114, %r56;
	add.s32 	%r113, %r57, %r54;
	ld.local.u32 	%r58, [%rd16+16];
	shr.u32 	%r59, %r58, %r56;
	add.s32 	%r114, %r59, %r53;
$L__BB334_9:
	shr.u32 	%r60, %r113, 30;
	shr.u32 	%r61, %r114, 30;
	shl.b32 	%r62, %r113, 2;
	or.b32  	%r63, %r62, %r61;
	shl.b32 	%r64, %r114, 2;
	bfe.u32 	%r65, %r113, 29, 1;
	add.s32 	%r66, %r65, %r60;
	neg.s32 	%r67, %r66;
	setp.lt.s32 	%p7, %r4, 0;
	selp.b32 	%r115, %r67, %r66, %p7;
	xor.b32  	%r68, %r63, %r4;
	bfe.s32 	%r69, %r113, 29, 1;
	xor.b32  	%r70, %r69, %r63;
	xor.b32  	%r71, %r69, %r64;
	cvt.u64.u32 	%rd64, %r70;
	shl.b64 	%rd65, %rd64, 32;
	cvt.u64.u32 	%rd66, %r71;
	or.b64  	%rd67, %rd65, %rd66;
	cvt.rn.f64.s64 	%fd1, %rd67;
	mul.rn.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f25, %fd2;
	neg.f32 	%f26, %f25;
	setp.lt.s32 	%p8, %r68, 0;
	selp.f32 	%f97, %f26, %f25, %p8;
$L__BB334_10:
	cvta.to.global.u64 	%rd1, %rd21;
	cvta.to.global.u64 	%rd2, %rd23;
	cvta.to.global.u64 	%rd3, %rd25;
	cvta.to.global.u64 	%rd5, %rd28;
	@%p3 bra 	$L__BB334_18;
	@%p19 bra 	$L__BB334_13;
	mov.f32 	%f30, 0f00000000;
	mul.rn.f32 	%f98, %f5, %f30;
	mov.b32 	%r119, 0;
	bra.uni 	$L__BB334_18;
$L__BB334_13:
	mov.b32 	%r19, %f5;
	shr.u32 	%r20, %r19, 23;
	and.b32  	%r74, %r20, 224;
	add.s32 	%r75, %r74, -128;
	shl.b32 	%r76, %r19, 8;
	or.b32  	%r80, %r76, -2147483648;
	shr.u32 	%r22, %r75, 5;
	mov.b32 	%r116, 0;
	mov.u64 	%rd83, 0;
	mov.u64 	%rd69, __cudart_i2opi_f;
$L__BB334_14:
	.pragma "nounroll";
	add.s64 	%rd70, %rd69, %rd83;
	ld.global.nc.u32 	%r79, [%rd70];
	// begin inline asm
	{
	mad.lo.cc.u32   %r77, %r79, %r80, %r116;
	madc.hi.u32     %r116, %r79, %r80,  0;
	}
	// end inline asm
	add.s64 	%rd71, %rd7, %rd83;
	st.local.u32 	[%rd71], %r77;
	add.s64 	%rd83, %rd83, 4;
	cvt.u32.u64 	%r82, %rd83;
	setp.ne.s32 	%p11, %r82, 24;
	@%p11 bra 	$L__BB334_14;
	st.local.u32 	[%rd7+24], %r116;
	and.b32  	%r25, %r20, 31;
	mul.wide.u32 	%rd72, %r22, 4;
	sub.s64 	%rd19, %rd7, %rd72;
	ld.local.u32 	%r117, [%rd19+24];
	ld.local.u32 	%r118, [%rd19+20];
	setp.eq.s32 	%p12, %r25, 0;
	@%p12 bra 	$L__BB334_17;
	shl.b32 	%r83, %r118, %r25;
	shl.b32 	%r84, %r117, %r25;
	mov.b32 	%r85, 32;
	sub.s32 	%r86, %r85, %r25;
	shr.u32 	%r87, %r118, %r86;
	add.s32 	%r117, %r87, %r84;
	ld.local.u32 	%r88, [%rd19+16];
	shr.u32 	%r89, %r88, %r86;
	add.s32 	%r118, %r89, %r83;
$L__BB334_17:
	shr.u32 	%r90, %r117, 30;
	shr.u32 	%r91, %r118, 30;
	shl.b32 	%r92, %r117, 2;
	or.b32  	%r93, %r92, %r91;
	shl.b32 	%r94, %r118, 2;
	bfe.u32 	%r95, %r117, 29, 1;
	add.s32 	%r96, %r95, %r90;
	neg.s32 	%r97, %r96;
	setp.lt.s32 	%p13, %r19, 0;
	selp.b32 	%r119, %r97, %r96, %p13;
	xor.b32  	%r98, %r93, %r19;
	bfe.s32 	%r99, %r117, 29, 1;
	xor.b32  	%r100, %r99, %r93;
	xor.b32  	%r101, %r99, %r94;
	cvt.u64.u32 	%rd73, %r100;
	shl.b64 	%rd74, %rd73, 32;
	cvt.u64.u32 	%rd75, %r101;
	or.b64  	%rd76, %rd74, %rd75;
	cvt.rn.f64.s64 	%fd3, %rd76;
	mul.rn.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f28, %fd4;
	neg.f32 	%f29, %f28;
	setp.lt.s32 	%p14, %r98, 0;
	selp.f32 	%f98, %f29, %f28, %p14;
$L__BB334_18:
	add.s32 	%r103, %r115, 1;
	and.b32  	%r104, %r103, 2;
	setp.eq.s32 	%p15, %r104, 0;
	and.b32  	%r105, %r115, 1;
	setp.eq.b32 	%p16, %r105, 1;
	mul.rn.f32 	%f31, %f97, %f97;
	fma.rn.f32 	%f32, %f31, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f33, 0fB94D4153, %f32, %p16;
	selp.f32 	%f34, 0f3C0885E4, 0f3D2AAABB, %p16;
	fma.rn.f32 	%f35, %f33, %f31, %f34;
	selp.f32 	%f36, 0fBE2AAAA8, 0fBEFFFFFF, %p16;
	fma.rn.f32 	%f37, %f35, %f31, %f36;
	selp.f32 	%f38, %f97, 0f3F800000, %p16;
	fma.rn.f32 	%f39, %f31, %f38, 0f00000000;
	fma.rn.f32 	%f40, %f37, %f39, %f38;
	mov.f32 	%f41, 0f00000000;
	sub.rn.f32 	%f42, %f41, %f40;
	selp.f32 	%f43, %f40, %f42, %p15;
	add.rn.f32 	%f44, %f95, %f96;
	mul.rn.f32 	%f45, %f44, %f43;
	fma.rn.f32 	%f46, %f1, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f47, %f46;
	mov.f32 	%f48, 0f4B400001;
	mov.f32 	%f49, 0f437C0000;
	fma.rm.f32 	%f50, %f47, %f49, %f48;
	add.rn.f32 	%f51, %f50, 0fCB40007F;
	neg.f32 	%f52, %f51;
	fma.rn.f32 	%f53, %f1, 0f3FB8AA3B, %f52;
	fma.rn.f32 	%f54, %f1, 0f32A57060, %f53;
	ex2.approx.ftz.f32 	%f55, %f54;
	mov.b32 	%r106, %f50;
	shl.b32 	%r107, %r106, 23;
	mov.b32 	%f56, %r107;
	mul.rn.f32 	%f57, %f55, %f56;
	neg.f32 	%f58, %f57;
	sub.rn.f32 	%f59, %f58, %f57;
	add.rn.f32 	%f60, %f59, %f59;
	add.rn.f32 	%f61, %f60, %f60;
	add.rn.f32 	%f62, %f61, %f61;
	add.rn.f32 	%f63, %f62, %f62;
	add.rn.f32 	%f64, %f63, %f63;
	add.rn.f32 	%f65, %f64, %f64;
	fma.rn.f32 	%f66, %f65, 0f3BBB989D, 0f3F000000;
	cvt.sat.f32.f32 	%f67, %f66;
	fma.rm.f32 	%f68, %f67, %f49, %f48;
	add.rn.f32 	%f69, %f68, 0fCB40007F;
	neg.f32 	%f70, %f69;
	fma.rn.f32 	%f71, %f65, 0f3FB8AA3B, %f70;
	fma.rn.f32 	%f72, %f65, 0f32A57060, %f71;
	ex2.approx.ftz.f32 	%f73, %f72;
	mov.b32 	%r108, %f68;
	shl.b32 	%r109, %r108, 23;
	mov.b32 	%f74, %r109;
	mul.rn.f32 	%f75, %f73, %f74;
	mul.rn.f32 	%f76, %f2, %f75;
	mul.rn.f32 	%f77, %f44, %f76;
	mul.rn.f32 	%f78, %f98, %f98;
	and.b32  	%r110, %r119, 1;
	setp.eq.b32 	%p17, %r110, 1;
	selp.f32 	%f79, 0f3F800000, %f98, %p17;
	fma.rn.f32 	%f80, %f78, %f79, 0f00000000;
	fma.rn.f32 	%f81, %f78, 0f37CBAC00, 0fBAB607ED;
	selp.f32 	%f82, %f81, 0fB94D4153, %p17;
	selp.f32 	%f83, 0f3D2AAABB, 0f3C0885E4, %p17;
	fma.rn.f32 	%f84, %f82, %f78, %f83;
	selp.f32 	%f85, 0fBEFFFFFF, 0fBE2AAAA8, %p17;
	fma.rn.f32 	%f86, %f84, %f78, %f85;
	fma.rn.f32 	%f87, %f86, %f80, %f79;
	and.b32  	%r111, %r119, 2;
	setp.eq.s32 	%p18, %r111, 0;
	sub.rn.f32 	%f88, %f41, %f87;
	selp.f32 	%f89, %f87, %f88, %p18;
	mul.wide.u32 	%rd77, %r1, 4;
	add.s64 	%rd78, %rd5, %rd77;
	ld.global.nc.f32 	%f90, [%rd78];
	mul.rn.f32 	%f91, %f90, %f89;
	add.rn.f32 	%f92, %f45, %f91;
	mul.rn.f32 	%f93, %f2, %f92;
	mul.rn.f32 	%f94, %f90, %f76;
	add.s64 	%rd79, %rd3, %rd77;
	st.global.f32 	[%rd79], %f77;
	add.s64 	%rd80, %rd2, %rd77;
	st.global.f32 	[%rd80], %f93;
	add.s64 	%rd81, %rd1, %rd77;
	st.global.f32 	[%rd81], %f94;
	ret;

}
	// .globl	loop_add_fusion_427
.visible .entry loop_add_fusion_427(
	.param .u64 loop_add_fusion_427_param_0,
	.param .u64 loop_add_fusion_427_param_1,
	.param .u64 loop_add_fusion_427_param_2,
	.param .u64 loop_add_fusion_427_param_3,
	.param .u64 loop_add_fusion_427_param_4,
	.param .u64 loop_add_fusion_427_param_5,
	.param .u64 loop_add_fusion_427_param_6,
	.param .u64 loop_add_fusion_427_param_7,
	.param .u64 loop_add_fusion_427_param_8
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<17>;
	.reg .b64 	%rd<31>;

	ld.param.u64 	%rd1, [loop_add_fusion_427_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_427_param_8];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_427_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_427_param_7];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_427_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_427_param_6];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_427_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_427_param_5];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_427_param_4];
	cvta.to.global.u64 	%rd14, %rd13;
	cvta.to.global.u64 	%rd15, %rd10;
	cvta.to.global.u64 	%rd16, %rd7;
	cvta.to.global.u64 	%rd17, %rd4;
	cvta.to.global.u64 	%rd18, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	ld.global.nc.f32 	%f1, [%rd15];
	cvt.u32.u16 	%r5, %rs5;
	mul.wide.u32 	%rd19, %r5, 24;
	cvt.u32.u16 	%r6, %rs10;
	mul.wide.u32 	%rd20, %r6, 144;
	add.s64 	%rd21, %rd17, %rd20;
	add.s64 	%rd22, %rd21, %rd19;
	cvt.u32.u16 	%r7, %rs8;
	mul.wide.u32 	%rd23, %r7, 4;
	add.s64 	%rd24, %rd22, %rd23;
	ld.global.nc.f32 	%f2, [%rd24];
	mul.wide.u32 	%rd25, %r4, 4;
	add.s64 	%rd26, %rd17, %rd25;
	ld.global.nc.f32 	%f3, [%rd26];
	sub.rn.f32 	%f4, %f2, %f3;
	mul.rn.f32 	%f5, %f4, %f4;
	mul.rn.f32 	%f6, %f1, %f5;
	ld.global.nc.f32 	%f7, [%rd16];
	add.s64 	%rd27, %rd18, %rd25;
	ld.global.nc.f32 	%f8, [%rd27];
	mul.rn.f32 	%f9, %f7, %f8;
	add.rn.f32 	%f10, %f6, %f9;
	ld.global.nc.f32 	%f11, [%rd9];
	mul.rn.f32 	%f12, %f4, %f11;
	ld.global.nc.f32 	%f13, [%rd12];
	add.s64 	%rd28, %rd14, %rd25;
	ld.global.nc.f32 	%f14, [%rd28];
	mul.rn.f32 	%f15, %f13, %f14;
	add.rn.f32 	%f16, %f12, %f15;
	add.s64 	%rd29, %rd6, %rd25;
	st.global.f32 	[%rd29], %f10;
	add.s64 	%rd30, %rd3, %rd25;
	st.global.f32 	[%rd30], %f16;
	ret;

}
	// .globl	loop_add_fusion_455
.visible .entry loop_add_fusion_455(
	.param .u64 loop_add_fusion_455_param_0,
	.param .u64 loop_add_fusion_455_param_1,
	.param .u64 loop_add_fusion_455_param_2,
	.param .u64 loop_add_fusion_455_param_3,
	.param .u64 loop_add_fusion_455_param_4,
	.param .u64 loop_add_fusion_455_param_5,
	.param .u64 loop_add_fusion_455_param_6,
	.param .u64 loop_add_fusion_455_param_7,
	.param .u64 loop_add_fusion_455_param_8,
	.param .u64 loop_add_fusion_455_param_9
)
.reqntid 128, 1, 1
{
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<8>;
	.reg .f32 	%f<20>;
	.reg .b64 	%rd<38>;

	ld.param.u64 	%rd1, [loop_add_fusion_455_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_455_param_9];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_455_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_455_param_8];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_455_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_455_param_7];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_455_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_455_param_6];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_455_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_455_param_5];
	cvta.to.global.u64 	%rd15, %rd14;
	cvta.to.global.u64 	%rd16, %rd13;
	cvta.to.global.u64 	%rd17, %rd10;
	cvta.to.global.u64 	%rd18, %rd7;
	cvta.to.global.u64 	%rd19, %rd4;
	cvta.to.global.u64 	%rd20, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	cvt.u16.u32 	%rs1, %r4;
	mul.hi.u16 	%rs2, %rs1, -21845;
	shr.u16 	%rs3, %rs2, 2;
	mul.lo.s16 	%rs4, %rs3, 6;
	sub.s16 	%rs5, %rs1, %rs4;
	mul.hi.u16 	%rs6, %rs3, 10923;
	mul.lo.s16 	%rs7, %rs6, 6;
	sub.s16 	%rs8, %rs3, %rs7;
	mul.hi.u16 	%rs9, %rs1, -7281;
	shr.u16 	%rs10, %rs9, 5;
	ld.global.nc.f32 	%f1, [%rd16];
	cvt.u32.u16 	%r5, %rs5;
	mul.wide.u32 	%rd21, %r5, 24;
	cvt.u32.u16 	%r6, %rs10;
	mul.wide.u32 	%rd22, %r6, 144;
	add.s64 	%rd23, %rd18, %rd22;
	add.s64 	%rd24, %rd23, %rd21;
	cvt.u32.u16 	%r7, %rs8;
	mul.wide.u32 	%rd25, %r7, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.f32 	%f2, [%rd26];
	mul.wide.u32 	%rd27, %r6, 4;
	add.s64 	%rd28, %rd17, %rd27;
	ld.global.nc.f32 	%f3, [%rd28];
	div.full.f32 	%f4, %f2, %f3;
	mul.wide.u32 	%rd29, %r7, 24;
	add.s64 	%rd30, %rd23, %rd29;
	mul.wide.u32 	%rd31, %r5, 4;
	add.s64 	%rd32, %rd30, %rd31;
	ld.global.nc.f32 	%f5, [%rd32];
	div.full.f32 	%f6, %f5, %f3;
	sub.rn.f32 	%f7, %f4, %f6;
	mul.rn.f32 	%f8, %f1, %f7;
	ld.global.nc.f32 	%f9, [%rd19];
	mul.wide.u32 	%rd33, %r4, 4;
	add.s64 	%rd34, %rd20, %rd33;
	ld.global.nc.f32 	%f10, [%rd34];
	mul.rn.f32 	%f11, %f9, %f10;
	add.rn.f32 	%f12, %f8, %f11;
	ld.global.nc.f32 	%f13, [%rd9];
	mul.rn.f32 	%f14, %f7, %f7;
	mul.rn.f32 	%f15, %f13, %f14;
	ld.global.nc.f32 	%f16, [%rd12];
	add.s64 	%rd35, %rd15, %rd33;
	ld.global.nc.f32 	%f17, [%rd35];
	mul.rn.f32 	%f18, %f16, %f17;
	add.rn.f32 	%f19, %f15, %f18;
	add.s64 	%rd36, %rd6, %rd33;
	st.global.f32 	[%rd36], %f12;
	add.s64 	%rd37, %rd3, %rd33;
	st.global.f32 	[%rd37], %f19;
	ret;

}
	// .globl	loop_add_fusion_484
.visible .entry loop_add_fusion_484(
	.param .u64 loop_add_fusion_484_param_0,
	.param .u64 loop_add_fusion_484_param_1,
	.param .u64 loop_add_fusion_484_param_2,
	.param .u64 loop_add_fusion_484_param_3,
	.param .u64 loop_add_fusion_484_param_4,
	.param .u64 loop_add_fusion_484_param_5,
	.param .u64 loop_add_fusion_484_param_6,
	.param .u64 loop_add_fusion_484_param_7,
	.param .u64 loop_add_fusion_484_param_8,
	.param .u64 loop_add_fusion_484_param_9
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<5>;
	.reg .f32 	%f<20>;
	.reg .b64 	%rd<26>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 10;
	or.b32  	%r1, %r4, %r3;
	setp.lt.u32 	%p1, %r1, 2304;
	@%p1 bra 	$L__BB337_2;
	bra.uni 	$L__BB337_1;
$L__BB337_2:
	ld.param.u64 	%rd11, [loop_add_fusion_484_param_0];
	ld.param.u64 	%rd12, [loop_add_fusion_484_param_9];
	cvta.to.global.u64 	%rd1, %rd12;
	ld.param.u64 	%rd13, [loop_add_fusion_484_param_1];
	ld.param.u64 	%rd14, [loop_add_fusion_484_param_8];
	cvta.to.global.u64 	%rd2, %rd14;
	ld.param.u64 	%rd15, [loop_add_fusion_484_param_2];
	ld.param.u64 	%rd16, [loop_add_fusion_484_param_7];
	cvta.to.global.u64 	%rd3, %rd16;
	ld.param.u64 	%rd17, [loop_add_fusion_484_param_3];
	ld.param.u64 	%rd18, [loop_add_fusion_484_param_6];
	cvta.to.global.u64 	%rd4, %rd18;
	ld.param.u64 	%rd19, [loop_add_fusion_484_param_4];
	ld.param.u64 	%rd20, [loop_add_fusion_484_param_5];
	cvta.to.global.u64 	%rd5, %rd20;
	cvta.to.global.u64 	%rd6, %rd19;
	cvta.to.global.u64 	%rd7, %rd17;
	cvta.to.global.u64 	%rd8, %rd15;
	cvta.to.global.u64 	%rd9, %rd13;
	cvta.to.global.u64 	%rd10, %rd11;
	mul.wide.u32 	%rd21, %r1, 4;
	add.s64 	%rd22, %rd10, %rd21;
	ld.global.nc.f32 	%f1, [%rd22];
	ld.global.nc.f32 	%f2, [%rd2];
	add.s64 	%rd23, %rd8, %rd21;
	ld.global.nc.f32 	%f3, [%rd23];
	ld.global.nc.f32 	%f4, [%rd3];
	add.s64 	%rd24, %rd5, %rd21;
	ld.global.nc.f32 	%f5, [%rd24];
	ld.global.nc.f32 	%f6, [%rd4];
	div.full.f32 	%f7, %f5, %f6;
	ld.global.nc.f32 	%f8, [%rd6];
	add.rn.f32 	%f9, %f7, %f8;
	sqrt.approx.f32 	%f10, %f9;
	ld.global.nc.f32 	%f11, [%rd7];
	add.rn.f32 	%f12, %f10, %f11;
	mul.rn.f32 	%f13, %f4, %f12;
	div.full.f32 	%f14, %f3, %f13;
	ld.global.nc.f32 	%f15, [%rd9];
	mul.rn.f32 	%f16, %f1, %f15;
	add.rn.f32 	%f17, %f16, %f14;
	mul.rn.f32 	%f18, %f2, %f17;
	add.rn.f32 	%f19, %f1, %f18;
	add.s64 	%rd25, %rd1, %rd21;
	st.global.f32 	[%rd25], %f19;
$L__BB337_1:
	ret;

}
	// .globl	input_reduce_fusion_557
.visible .entry input_reduce_fusion_557(
	.param .u64 input_reduce_fusion_557_param_0,
	.param .u64 input_reduce_fusion_557_param_1,
	.param .u64 input_reduce_fusion_557_param_2,
	.param .u64 input_reduce_fusion_557_param_3,
	.param .u64 input_reduce_fusion_557_param_4,
	.param .u64 input_reduce_fusion_557_param_5,
	.param .u64 input_reduce_fusion_557_param_6,
	.param .u64 input_reduce_fusion_557_param_7
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<5>;
	.reg .b32 	%r<42>;
	.reg .f32 	%f<86>;
	.reg .b64 	%rd<102>;
	// demoted variable
	.shared .align 4 .b8 shared_cache63[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache64[4224];
	ld.param.u64 	%rd27, [input_reduce_fusion_557_param_0];
	ld.param.u64 	%rd28, [input_reduce_fusion_557_param_7];
	ld.param.u64 	%rd29, [input_reduce_fusion_557_param_1];
	ld.param.u64 	%rd30, [input_reduce_fusion_557_param_6];
	ld.param.u64 	%rd31, [input_reduce_fusion_557_param_2];
	ld.param.u64 	%rd32, [input_reduce_fusion_557_param_5];
	cvta.to.global.u64 	%rd33, %rd32;
	ld.param.u64 	%rd34, [input_reduce_fusion_557_param_3];
	ld.param.u64 	%rd35, [input_reduce_fusion_557_param_4];
	cvta.to.global.u64 	%rd36, %rd35;
	cvta.to.global.u64 	%rd3, %rd34;
	cvta.to.global.u64 	%rd37, %rd31;
	cvta.to.global.u64 	%rd38, %rd29;
	cvta.to.global.u64 	%rd4, %rd27;
	mov.u32 	%r15, %tid.x;
	mov.u32 	%r1, %ctaid.x;
	shr.u32 	%r2, %r15, 5;
	and.b32  	%r3, %r15, 31;
	shr.u32 	%r4, %r1, 4;
	shl.b32 	%r16, %r1, 5;
	and.b32  	%r5, %r16, 480;
	or.b32  	%r17, %r5, %r3;
	mul.lo.s32 	%r6, %r4, 400;
	cvt.u64.u32 	%rd5, %r17;
	mul.wide.u32 	%rd39, %r17, 4;
	add.s64 	%rd40, %rd37, %rd39;
	ld.global.nc.f32 	%f1, [%rd40];
	add.s64 	%rd41, %rd38, %rd39;
	ld.global.nc.f32 	%f2, [%rd41];
	add.s64 	%rd42, %rd36, %rd39;
	ld.global.nc.f32 	%f3, [%rd42];
	add.s64 	%rd43, %rd33, %rd39;
	ld.global.nc.f32 	%f4, [%rd43];
	mov.b32 	%r18, 399;
	sub.s32 	%r19, %r18, %r2;
	shr.u32 	%r20, %r19, 5;
	add.s32 	%r21, %r20, 1;
	and.b32  	%r38, %r21, 3;
	setp.ne.s32 	%p1, %r38, 0;
	@%p1 bra 	$L__BB338_2;
	bra.uni 	$L__BB338_1;
$L__BB338_2:
	add.s32 	%r22, %r2, %r6;
	cvt.u64.u32 	%rd97, %r22;
	mul.wide.u32 	%rd44, %r22, 2048;
	shl.b64 	%rd100, %rd5, 2;
	or.b64  	%rd45, %rd44, %rd100;
	add.s64 	%rd99, %rd4, %rd45;
	cvt.u16.u32 	%rs1, %r4;
	mul.lo.s16 	%rs2, %rs1, 400;
	cvt.u16.u32 	%rs3, %r2;
	add.s16 	%rs4, %rs2, %rs3;
	cvt.u32.u16 	%r23, %rs4;
	and.b32  	%r24, %r23, 1023;
	mul.wide.u32 	%rd46, %r24, 4;
	add.s64 	%rd98, %rd3, %rd46;
	mov.f32 	%f82, 0f00000000;
	mov.u32 	%r40, %r2;
	mov.f32 	%f83, %f82;
$L__BB338_3:
	.pragma "nounroll";
	add.s32 	%r40, %r40, 32;
	shl.b64 	%rd47, %rd97, 2;
	and.b64  	%rd48, %rd47, -4096;
	add.s64 	%rd49, %rd98, %rd48;
	ld.global.nc.f32 	%f18, [%rd49];
	mul.rn.f32 	%f19, %f18, %f1;
	add.rn.f32 	%f20, %f19, %f2;
	sub.rn.f32 	%f21, %f20, %f3;
	ld.global.nc.f32 	%f22, [%rd99];
	mul.rn.f32 	%f23, %f21, %f22;
	add.rn.f32 	%f83, %f83, %f23;
	mul.rn.f32 	%f24, %f22, %f4;
	add.rn.f32 	%f82, %f82, %f24;
	add.s64 	%rd99, %rd99, 65536;
	add.s64 	%rd98, %rd98, 128;
	add.s64 	%rd97, %rd97, 32;
	add.s32 	%r38, %r38, -1;
	setp.ne.s32 	%p2, %r38, 0;
	@%p2 bra 	$L__BB338_3;
	bra.uni 	$L__BB338_4;
$L__BB338_1:
	shl.b64 	%rd100, %rd5, 2;
	mov.f32 	%f82, 0f00000000;
	mov.u32 	%r40, %r2;
	mov.f32 	%f83, %f82;
$L__BB338_4:
	cvta.to.global.u64 	%rd1, %rd28;
	cvta.to.global.u64 	%rd2, %rd30;
	cvt.u64.u32 	%rd50, %r1;
	shr.u64 	%rd51, %rd50, 4;
	mul.lo.s64 	%rd52, %rd51, 819200;
	mul.wide.u32 	%rd53, %r40, 2048;
	add.s64 	%rd54, %rd52, %rd53;
	or.b64  	%rd55, %rd54, %rd100;
	add.s64 	%rd56, %rd55, %rd4;
	add.s64 	%rd101, %rd56, 131072;
$L__BB338_5:
	add.s32 	%r25, %r6, %r40;
	and.b32  	%r26, %r25, 1023;
	shr.u32 	%r27, %r25, 10;
	mul.wide.u32 	%rd57, %r27, 4096;
	add.s64 	%rd58, %rd3, %rd57;
	mul.wide.u32 	%rd59, %r26, 4;
	add.s64 	%rd60, %rd58, %rd59;
	ld.global.nc.f32 	%f26, [%rd60];
	mul.rn.f32 	%f27, %f26, %f1;
	add.rn.f32 	%f28, %f27, %f2;
	sub.rn.f32 	%f29, %f28, %f3;
	ld.global.nc.f32 	%f30, [%rd101+-131072];
	mul.rn.f32 	%f31, %f29, %f30;
	add.rn.f32 	%f32, %f83, %f31;
	mul.rn.f32 	%f33, %f30, %f4;
	add.rn.f32 	%f34, %f82, %f33;
	add.s32 	%r28, %r25, 32;
	and.b32  	%r29, %r28, 1023;
	shr.u32 	%r30, %r28, 10;
	mul.wide.u32 	%rd61, %r30, 4096;
	add.s64 	%rd62, %rd3, %rd61;
	mul.wide.u32 	%rd63, %r29, 4;
	add.s64 	%rd64, %rd62, %rd63;
	ld.global.nc.f32 	%f35, [%rd64];
	mul.rn.f32 	%f36, %f35, %f1;
	add.rn.f32 	%f37, %f36, %f2;
	sub.rn.f32 	%f38, %f37, %f3;
	ld.global.nc.f32 	%f39, [%rd101+-65536];
	mul.rn.f32 	%f40, %f38, %f39;
	add.rn.f32 	%f41, %f32, %f40;
	mul.rn.f32 	%f42, %f39, %f4;
	add.rn.f32 	%f43, %f34, %f42;
	add.s32 	%r31, %r25, 64;
	and.b32  	%r32, %r31, 1023;
	shr.u32 	%r33, %r31, 10;
	mul.wide.u32 	%rd65, %r33, 4096;
	add.s64 	%rd66, %rd3, %rd65;
	mul.wide.u32 	%rd67, %r32, 4;
	add.s64 	%rd68, %rd66, %rd67;
	ld.global.nc.f32 	%f44, [%rd68];
	mul.rn.f32 	%f45, %f44, %f1;
	add.rn.f32 	%f46, %f45, %f2;
	sub.rn.f32 	%f47, %f46, %f3;
	ld.global.nc.f32 	%f48, [%rd101];
	mul.rn.f32 	%f49, %f47, %f48;
	add.rn.f32 	%f50, %f41, %f49;
	mul.rn.f32 	%f51, %f48, %f4;
	add.rn.f32 	%f52, %f43, %f51;
	add.s32 	%r14, %r40, 128;
	add.s32 	%r34, %r25, 96;
	and.b32  	%r35, %r34, 1023;
	shr.u32 	%r36, %r34, 10;
	mul.wide.u32 	%rd69, %r36, 4096;
	add.s64 	%rd70, %rd3, %rd69;
	mul.wide.u32 	%rd71, %r35, 4;
	add.s64 	%rd72, %rd70, %rd71;
	ld.global.nc.f32 	%f53, [%rd72];
	mul.rn.f32 	%f54, %f53, %f1;
	add.rn.f32 	%f55, %f54, %f2;
	sub.rn.f32 	%f56, %f55, %f3;
	ld.global.nc.f32 	%f57, [%rd101+65536];
	mul.rn.f32 	%f58, %f56, %f57;
	add.rn.f32 	%f83, %f50, %f58;
	mul.rn.f32 	%f59, %f57, %f4;
	add.rn.f32 	%f82, %f52, %f59;
	add.s64 	%rd101, %rd101, 262144;
	setp.lt.u32 	%p3, %r40, 272;
	mov.u32 	%r40, %r14;
	@%p3 bra 	$L__BB338_5;
	cvt.u64.u32 	%rd21, %r3;
	cvt.u64.u32 	%rd22, %r2;
	mul.wide.u32 	%rd73, %r3, 132;
	mov.u64 	%rd74, shared_cache63;
	add.s64 	%rd75, %rd74, %rd73;
	mul.wide.u32 	%rd76, %r2, 4;
	add.s64 	%rd77, %rd75, %rd76;
	st.shared.f32 	[%rd77], %f83;
	bar.sync 	0;
	mul.wide.u32 	%rd78, %r2, 132;
	add.s64 	%rd79, %rd74, %rd78;
	mul.wide.u32 	%rd80, %r3, 4;
	add.s64 	%rd81, %rd79, %rd80;
	ld.shared.f32 	%f60, [%rd81];
	shfl.sync.down.b32	%f61, %f60, 16, 31, -1;
	add.rn.f32 	%f62, %f60, %f61;
	shfl.sync.down.b32	%f63, %f62, 8, 31, -1;
	add.rn.f32 	%f64, %f62, %f63;
	shfl.sync.down.b32	%f65, %f64, 4, 31, -1;
	add.rn.f32 	%f66, %f64, %f65;
	shfl.sync.down.b32	%f67, %f66, 2, 31, -1;
	add.rn.f32 	%f68, %f66, %f67;
	shfl.sync.down.b32	%f69, %f68, 1, 31, -1;
	add.rn.f32 	%f15, %f68, %f69;
	st.shared.f32 	[%rd81], %f15;
	setp.eq.s32 	%p4, %r3, 0;
	or.b32  	%r37, %r5, %r2;
	@%p4 bra 	$L__BB338_9;
	bra.uni 	$L__BB338_7;
$L__BB338_9:
	mul.wide.u32 	%rd82, %r4, 2048;
	add.s64 	%rd83, %rd2, %rd82;
	mul.wide.u32 	%rd84, %r37, 4;
	add.s64 	%rd25, %rd83, %rd84;
	st.global.f32 	[%rd25], %f15;
$L__BB338_7:
	mul.lo.s64 	%rd85, %rd21, 132;
	mov.u64 	%rd86, shared_cache64;
	add.s64 	%rd87, %rd86, %rd85;
	shl.b64 	%rd88, %rd22, 2;
	add.s64 	%rd89, %rd87, %rd88;
	st.shared.f32 	[%rd89], %f82;
	bar.sync 	0;
	mul.lo.s64 	%rd90, %rd22, 132;
	add.s64 	%rd91, %rd86, %rd90;
	shl.b64 	%rd92, %rd21, 2;
	add.s64 	%rd93, %rd91, %rd92;
	ld.shared.f32 	%f70, [%rd93];
	shfl.sync.down.b32	%f71, %f70, 16, 31, -1;
	add.rn.f32 	%f72, %f70, %f71;
	shfl.sync.down.b32	%f73, %f72, 8, 31, -1;
	add.rn.f32 	%f74, %f72, %f73;
	shfl.sync.down.b32	%f75, %f74, 4, 31, -1;
	add.rn.f32 	%f76, %f74, %f75;
	shfl.sync.down.b32	%f77, %f76, 2, 31, -1;
	add.rn.f32 	%f78, %f76, %f77;
	shfl.sync.down.b32	%f79, %f78, 1, 31, -1;
	add.rn.f32 	%f16, %f78, %f79;
	st.shared.f32 	[%rd93], %f16;
	@%p4 bra 	$L__BB338_10;
	bra.uni 	$L__BB338_8;
$L__BB338_10:
	cvt.u64.u32 	%rd23, %r4;
	cvt.u64.u32 	%rd24, %r37;
	shl.b64 	%rd94, %rd23, 11;
	add.s64 	%rd95, %rd1, %rd94;
	shl.b64 	%rd96, %rd24, 2;
	add.s64 	%rd26, %rd95, %rd96;
	st.global.f32 	[%rd26], %f16;
$L__BB338_8:
	ret;

}
	// .globl	input_add_reduce_fusion_75
.visible .entry input_add_reduce_fusion_75(
	.param .u64 input_add_reduce_fusion_75_param_0,
	.param .u64 input_add_reduce_fusion_75_param_1,
	.param .u64 input_add_reduce_fusion_75_param_2,
	.param .u64 input_add_reduce_fusion_75_param_3,
	.param .u64 input_add_reduce_fusion_75_param_4,
	.param .u64 input_add_reduce_fusion_75_param_5,
	.param .u64 input_add_reduce_fusion_75_param_6,
	.param .u64 input_add_reduce_fusion_75_param_7,
	.param .u64 input_add_reduce_fusion_75_param_8,
	.param .u64 input_add_reduce_fusion_75_param_9,
	.param .u64 input_add_reduce_fusion_75_param_10
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<29>;
	.reg .f32 	%f<73>;
	.reg .b64 	%rd<114>;
	// demoted variable
	.shared .align 4 .b8 shared_cache65[4224];
	// demoted variable
	.shared .align 4 .b8 shared_cache66[4224];
	ld.param.u64 	%rd17, [input_add_reduce_fusion_75_param_0];
	ld.param.u64 	%rd18, [input_add_reduce_fusion_75_param_10];
	ld.param.u64 	%rd19, [input_add_reduce_fusion_75_param_1];
	ld.param.u64 	%rd20, [input_add_reduce_fusion_75_param_9];
	cvta.to.global.u64 	%rd2, %rd20;
	ld.param.u64 	%rd21, [input_add_reduce_fusion_75_param_2];
	ld.param.u64 	%rd22, [input_add_reduce_fusion_75_param_8];
	ld.param.u64 	%rd23, [input_add_reduce_fusion_75_param_3];
	ld.param.u64 	%rd24, [input_add_reduce_fusion_75_param_7];
	cvta.to.global.u64 	%rd4, %rd24;
	ld.param.u64 	%rd25, [input_add_reduce_fusion_75_param_4];
	ld.param.u64 	%rd26, [input_add_reduce_fusion_75_param_6];
	cvta.to.global.u64 	%rd27, %rd26;
	ld.param.u64 	%rd28, [input_add_reduce_fusion_75_param_5];
	cvta.to.global.u64 	%rd5, %rd28;
	cvta.to.global.u64 	%rd6, %rd25;
	cvta.to.global.u64 	%rd29, %rd23;
	cvta.to.global.u64 	%rd30, %rd21;
	cvta.to.global.u64 	%rd31, %rd19;
	cvta.to.global.u64 	%rd32, %rd17;
	mov.u32 	%r11, %tid.x;
	mov.u32 	%r1, %ctaid.x;
	shr.u32 	%r2, %r11, 5;
	and.b32  	%r3, %r11, 31;
	shr.u32 	%r4, %r1, 4;
	shl.b32 	%r12, %r1, 5;
	and.b32  	%r5, %r12, 480;
	or.b32  	%r13, %r5, %r3;
	mul.lo.s32 	%r6, %r4, 400;
	cvt.u64.u32 	%rd7, %r13;
	mul.wide.u32 	%rd33, %r13, 4;
	add.s64 	%rd34, %rd27, %rd33;
	ld.global.nc.f32 	%f1, [%rd34];
	add.s64 	%rd35, %rd29, %rd33;
	ld.global.nc.f32 	%f2, [%rd35];
	add.s64 	%rd36, %rd30, %rd33;
	ld.global.nc.f32 	%f3, [%rd36];
	add.s64 	%rd37, %rd31, %rd33;
	ld.global.nc.f32 	%f4, [%rd37];
	add.s64 	%rd38, %rd32, %rd33;
	ld.global.nc.f32 	%f5, [%rd38];
	mov.b32 	%r14, 15;
	sub.s32 	%r15, %r14, %r2;
	and.b32  	%r16, %r15, 32;
	setp.ne.s32 	%p1, %r16, 0;
	mov.f32 	%f71, 0f00000000;
	shl.b64 	%rd112, %rd7, 2;
	mov.u32 	%r28, %r2;
	mov.f32 	%f72, %f71;
	@%p1 bra 	$L__BB339_2;
	or.b32  	%r28, %r2, 32;
	add.s32 	%r17, %r2, %r6;
	and.b32  	%r18, %r17, 1023;
	shr.u32 	%r19, %r17, 10;
	mul.wide.u32 	%rd39, %r19, 2097152;
	add.s64 	%rd40, %rd5, %rd39;
	mul.wide.u32 	%rd41, %r18, 2048;
	add.s64 	%rd42, %rd40, %rd41;
	add.s64 	%rd44, %rd42, %rd112;
	ld.global.nc.f32 	%f17, [%rd44];
	mul.wide.u32 	%rd45, %r17, 2048;
	add.s64 	%rd46, %rd4, %rd45;
	add.s64 	%rd47, %rd46, %rd112;
	ld.global.nc.f32 	%f18, [%rd47];
	mul.rn.f32 	%f19, %f18, %f1;
	add.rn.f32 	%f20, %f17, %f19;
	mul.wide.u32 	%rd48, %r19, 4096;
	add.s64 	%rd49, %rd6, %rd48;
	mul.wide.u32 	%rd50, %r18, 4;
	add.s64 	%rd51, %rd49, %rd50;
	ld.global.nc.f32 	%f21, [%rd51];
	mul.rn.f32 	%f22, %f21, %f2;
	add.rn.f32 	%f23, %f22, %f3;
	mul.rn.f32 	%f24, %f23, %f4;
	add.rn.f32 	%f25, %f20, %f24;
	add.rn.f32 	%f26, %f5, %f25;
	add.rn.f32 	%f72, %f26, 0f00000000;
	add.rn.f32 	%f71, %f18, 0f00000000;
	add.s64 	%rd52, %rd2, %rd39;
	add.s64 	%rd53, %rd52, %rd41;
	add.s64 	%rd54, %rd53, %rd112;
	st.global.f32 	[%rd54], %f26;
$L__BB339_2:
	cvta.to.global.u64 	%rd1, %rd18;
	cvta.to.global.u64 	%rd3, %rd22;
	cvt.u64.u32 	%rd55, %r1;
	shr.u64 	%rd56, %rd55, 4;
	mul.lo.s64 	%rd57, %rd56, 819200;
	mul.wide.u32 	%rd58, %r28, 2048;
	add.s64 	%rd59, %rd57, %rd58;
	or.b64  	%rd61, %rd59, %rd112;
	add.s64 	%rd62, %rd61, %rd4;
	add.s64 	%rd113, %rd62, 65536;
$L__BB339_3:
	add.s32 	%r20, %r6, %r28;
	and.b32  	%r21, %r20, 1023;
	shr.u32 	%r22, %r20, 10;
	mul.wide.u32 	%rd63, %r22, 2097152;
	add.s64 	%rd64, %rd5, %rd63;
	mul.wide.u32 	%rd65, %r21, 2048;
	add.s64 	%rd66, %rd64, %rd65;
	add.s64 	%rd68, %rd66, %rd112;
	ld.global.nc.f32 	%f27, [%rd68];
	ld.global.nc.f32 	%f28, [%rd113+-65536];
	mul.rn.f32 	%f29, %f28, %f1;
	add.rn.f32 	%f30, %f27, %f29;
	mul.wide.u32 	%rd69, %r22, 4096;
	add.s64 	%rd70, %rd6, %rd69;
	mul.wide.u32 	%rd71, %r21, 4;
	add.s64 	%rd72, %rd70, %rd71;
	ld.global.nc.f32 	%f31, [%rd72];
	mul.rn.f32 	%f32, %f31, %f2;
	add.rn.f32 	%f33, %f32, %f3;
	mul.rn.f32 	%f34, %f33, %f4;
	add.rn.f32 	%f35, %f30, %f34;
	add.rn.f32 	%f36, %f5, %f35;
	add.rn.f32 	%f37, %f72, %f36;
	add.rn.f32 	%f38, %f71, %f28;
	add.s64 	%rd73, %rd2, %rd63;
	add.s64 	%rd74, %rd73, %rd65;
	add.s64 	%rd75, %rd74, %rd112;
	st.global.f32 	[%rd75], %f36;
	add.s32 	%r10, %r28, 64;
	add.s32 	%r23, %r20, 32;
	and.b32  	%r24, %r23, 1023;
	shr.u32 	%r25, %r23, 10;
	mul.wide.u32 	%rd76, %r25, 2097152;
	add.s64 	%rd77, %rd5, %rd76;
	mul.wide.u32 	%rd78, %r24, 2048;
	add.s64 	%rd79, %rd77, %rd78;
	add.s64 	%rd80, %rd79, %rd112;
	ld.global.nc.f32 	%f39, [%rd80];
	ld.global.nc.f32 	%f40, [%rd113];
	mul.rn.f32 	%f41, %f40, %f1;
	add.rn.f32 	%f42, %f39, %f41;
	mul.wide.u32 	%rd81, %r25, 4096;
	add.s64 	%rd82, %rd6, %rd81;
	mul.wide.u32 	%rd83, %r24, 4;
	add.s64 	%rd84, %rd82, %rd83;
	ld.global.nc.f32 	%f43, [%rd84];
	mul.rn.f32 	%f44, %f43, %f2;
	add.rn.f32 	%f45, %f44, %f3;
	mul.rn.f32 	%f46, %f45, %f4;
	add.rn.f32 	%f47, %f42, %f46;
	add.rn.f32 	%f48, %f5, %f47;
	add.rn.f32 	%f72, %f37, %f48;
	add.rn.f32 	%f71, %f38, %f40;
	add.s64 	%rd85, %rd2, %rd76;
	add.s64 	%rd86, %rd85, %rd78;
	add.s64 	%rd87, %rd86, %rd112;
	st.global.f32 	[%rd87], %f48;
	add.s64 	%rd113, %rd113, 131072;
	setp.lt.u32 	%p2, %r28, 336;
	mov.u32 	%r28, %r10;
	@%p2 bra 	$L__BB339_3;
	cvt.u64.u32 	%rd11, %r3;
	cvt.u64.u32 	%rd12, %r2;
	mul.wide.u32 	%rd88, %r3, 132;
	mov.u64 	%rd89, shared_cache65;
	add.s64 	%rd90, %rd89, %rd88;
	mul.wide.u32 	%rd91, %r2, 4;
	add.s64 	%rd92, %rd90, %rd91;
	st.shared.f32 	[%rd92], %f72;
	bar.sync 	0;
	mul.wide.u32 	%rd93, %r2, 132;
	add.s64 	%rd94, %rd89, %rd93;
	mul.wide.u32 	%rd95, %r3, 4;
	add.s64 	%rd96, %rd94, %rd95;
	ld.shared.f32 	%f49, [%rd96];
	shfl.sync.down.b32	%f50, %f49, 16, 31, -1;
	add.rn.f32 	%f51, %f49, %f50;
	shfl.sync.down.b32	%f52, %f51, 8, 31, -1;
	add.rn.f32 	%f53, %f51, %f52;
	shfl.sync.down.b32	%f54, %f53, 4, 31, -1;
	add.rn.f32 	%f55, %f53, %f54;
	shfl.sync.down.b32	%f56, %f55, 2, 31, -1;
	add.rn.f32 	%f57, %f55, %f56;
	shfl.sync.down.b32	%f58, %f57, 1, 31, -1;
	add.rn.f32 	%f14, %f57, %f58;
	st.shared.f32 	[%rd96], %f14;
	setp.eq.s32 	%p3, %r3, 0;
	or.b32  	%r26, %r5, %r2;
	@%p3 bra 	$L__BB339_7;
	bra.uni 	$L__BB339_5;
$L__BB339_7:
	mul.wide.u32 	%rd97, %r4, 2048;
	add.s64 	%rd98, %rd3, %rd97;
	mul.wide.u32 	%rd99, %r26, 4;
	add.s64 	%rd15, %rd98, %rd99;
	st.global.f32 	[%rd15], %f14;
$L__BB339_5:
	mul.lo.s64 	%rd100, %rd11, 132;
	mov.u64 	%rd101, shared_cache66;
	add.s64 	%rd102, %rd101, %rd100;
	shl.b64 	%rd103, %rd12, 2;
	add.s64 	%rd104, %rd102, %rd103;
	st.shared.f32 	[%rd104], %f71;
	bar.sync 	0;
	mul.lo.s64 	%rd105, %rd12, 132;
	add.s64 	%rd106, %rd101, %rd105;
	shl.b64 	%rd107, %rd11, 2;
	add.s64 	%rd108, %rd106, %rd107;
	ld.shared.f32 	%f59, [%rd108];
	shfl.sync.down.b32	%f60, %f59, 16, 31, -1;
	add.rn.f32 	%f61, %f59, %f60;
	shfl.sync.down.b32	%f62, %f61, 8, 31, -1;
	add.rn.f32 	%f63, %f61, %f62;
	shfl.sync.down.b32	%f64, %f63, 4, 31, -1;
	add.rn.f32 	%f65, %f63, %f64;
	shfl.sync.down.b32	%f66, %f65, 2, 31, -1;
	add.rn.f32 	%f67, %f65, %f66;
	shfl.sync.down.b32	%f68, %f67, 1, 31, -1;
	add.rn.f32 	%f15, %f67, %f68;
	st.shared.f32 	[%rd108], %f15;
	@%p3 bra 	$L__BB339_8;
	bra.uni 	$L__BB339_6;
$L__BB339_8:
	cvt.u64.u32 	%rd13, %r4;
	cvt.u64.u32 	%rd14, %r26;
	shl.b64 	%rd109, %rd13, 11;
	add.s64 	%rd110, %rd1, %rd109;
	shl.b64 	%rd111, %rd14, 2;
	add.s64 	%rd16, %rd110, %rd111;
	st.global.f32 	[%rd16], %f15;
$L__BB339_6:
	ret;

}
	// .globl	loop_add_fusion_486
.visible .entry loop_add_fusion_486(
	.param .u64 loop_add_fusion_486_param_0,
	.param .u64 loop_add_fusion_486_param_1,
	.param .u64 loop_add_fusion_486_param_2,
	.param .u64 loop_add_fusion_486_param_3,
	.param .u64 loop_add_fusion_486_param_4,
	.param .u64 loop_add_fusion_486_param_5,
	.param .u64 loop_add_fusion_486_param_6,
	.param .u64 loop_add_fusion_486_param_7,
	.param .u64 loop_add_fusion_486_param_8,
	.param .u64 loop_add_fusion_486_param_9,
	.param .u64 loop_add_fusion_486_param_10,
	.param .u64 loop_add_fusion_486_param_11,
	.param .u64 loop_add_fusion_486_param_12,
	.param .u64 loop_add_fusion_486_param_13,
	.param .u64 loop_add_fusion_486_param_14,
	.param .u64 loop_add_fusion_486_param_15,
	.param .u64 loop_add_fusion_486_param_16
)
.reqntid 128, 1, 1
{
	.reg .b32 	%r<5>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<43>;

	ld.param.u64 	%rd1, [loop_add_fusion_486_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_486_param_16];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_486_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_486_param_15];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_486_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_486_param_14];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_486_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_486_param_13];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_486_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_486_param_12];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_486_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_486_param_11];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_486_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_486_param_10];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_486_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_486_param_9];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_add_fusion_486_param_8];
	cvta.to.global.u64 	%rd26, %rd25;
	cvta.to.global.u64 	%rd27, %rd22;
	cvta.to.global.u64 	%rd28, %rd19;
	cvta.to.global.u64 	%rd29, %rd16;
	cvta.to.global.u64 	%rd30, %rd13;
	cvta.to.global.u64 	%rd31, %rd10;
	cvta.to.global.u64 	%rd32, %rd7;
	cvta.to.global.u64 	%rd33, %rd4;
	cvta.to.global.u64 	%rd34, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.wide.u32 	%rd35, %r4, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.nc.f32 	%f1, [%rd36];
	ld.global.nc.f32 	%f2, [%rd28];
	ld.global.nc.f32 	%f3, [%rd12];
	add.s64 	%rd37, %rd24, %rd35;
	ld.global.nc.f32 	%f4, [%rd37];
	mul.rn.f32 	%f5, %f3, %f4;
	ld.global.nc.f32 	%f6, [%rd15];
	add.s64 	%rd38, %rd18, %rd35;
	ld.global.nc.f32 	%f7, [%rd38];
	mul.rn.f32 	%f8, %f6, %f7;
	add.rn.f32 	%f9, %f5, %f8;
	ld.global.nc.f32 	%f10, [%rd29];
	ld.global.nc.f32 	%f11, [%rd21];
	mul.rn.f32 	%f12, %f4, %f4;
	mul.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.f32 	%f14, [%rd26];
	add.s64 	%rd39, %rd27, %rd35;
	ld.global.nc.f32 	%f15, [%rd39];
	mul.rn.f32 	%f16, %f14, %f15;
	add.rn.f32 	%f17, %f13, %f16;
	ld.global.nc.f32 	%f18, [%rd30];
	div.full.f32 	%f19, %f17, %f18;
	ld.global.nc.f32 	%f20, [%rd31];
	add.rn.f32 	%f21, %f20, %f19;
	sqrt.approx.f32 	%f22, %f21;
	ld.global.nc.f32 	%f23, [%rd32];
	add.rn.f32 	%f24, %f22, %f23;
	mul.rn.f32 	%f25, %f10, %f24;
	div.full.f32 	%f26, %f9, %f25;
	ld.global.nc.f32 	%f27, [%rd33];
	mul.rn.f32 	%f28, %f1, %f27;
	add.rn.f32 	%f29, %f28, %f26;
	mul.rn.f32 	%f30, %f2, %f29;
	add.rn.f32 	%f31, %f1, %f30;
	add.s64 	%rd40, %rd9, %rd35;
	st.global.f32 	[%rd40], %f31;
	add.s64 	%rd41, %rd6, %rd35;
	st.global.f32 	[%rd41], %f17;
	add.s64 	%rd42, %rd3, %rd35;
	st.global.f32 	[%rd42], %f9;
	ret;

}
	// .globl	input_reduce_fusion_559
.visible .entry input_reduce_fusion_559(
	.param .u64 input_reduce_fusion_559_param_0,
	.param .u64 input_reduce_fusion_559_param_1
)
.reqntid 1024, 1, 1
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<12>;
	.reg .f32 	%f<17>;
	.reg .b64 	%rd<25>;
	// demoted variable
	.shared .align 4 .b8 shared_cache67[4224];
	ld.param.u64 	%rd6, [input_reduce_fusion_559_param_0];
	ld.param.u64 	%rd7, [input_reduce_fusion_559_param_1];
	cvta.to.global.u64 	%rd1, %rd7;
	cvta.to.global.u64 	%rd8, %rd6;
	mov.u32 	%r7, %tid.x;
	mov.u32 	%r8, %ctaid.x;
	shr.u32 	%r1, %r7, 5;
	and.b32  	%r2, %r7, 31;
	shl.b32 	%r3, %r8, 5;
	or.b32  	%r9, %r3, %r2;
	add.s32 	%r11, %r1, -32;
	cvt.u64.u32 	%rd9, %r7;
	shl.b64 	%rd10, %rd9, 6;
	and.b64  	%rd11, %rd10, 274877904896;
	mul.wide.u32 	%rd12, %r9, 4;
	add.s64 	%rd13, %rd11, %rd12;
	add.s64 	%rd24, %rd8, %rd13;
	mov.f32 	%f16, 0f00000000;
$L__BB341_1:
	ld.global.nc.f32 	%f5, [%rd24];
	add.rn.f32 	%f16, %f16, %f5;
	add.s32 	%r11, %r11, 32;
	add.s64 	%rd24, %rd24, 65536;
	setp.lt.u32 	%p1, %r11, 96;
	@%p1 bra 	$L__BB341_1;
	mul.wide.u32 	%rd14, %r2, 132;
	mov.u64 	%rd15, shared_cache67;
	add.s64 	%rd16, %rd15, %rd14;
	mul.wide.u32 	%rd17, %r1, 4;
	add.s64 	%rd18, %rd16, %rd17;
	st.shared.f32 	[%rd18], %f16;
	bar.sync 	0;
	mul.wide.u32 	%rd19, %r1, 132;
	add.s64 	%rd20, %rd15, %rd19;
	mul.wide.u32 	%rd21, %r2, 4;
	add.s64 	%rd22, %rd20, %rd21;
	ld.shared.f32 	%f6, [%rd22];
	shfl.sync.down.b32	%f7, %f6, 16, 31, -1;
	add.rn.f32 	%f8, %f6, %f7;
	shfl.sync.down.b32	%f9, %f8, 8, 31, -1;
	add.rn.f32 	%f10, %f8, %f9;
	shfl.sync.down.b32	%f11, %f10, 4, 31, -1;
	add.rn.f32 	%f12, %f10, %f11;
	shfl.sync.down.b32	%f13, %f12, 2, 31, -1;
	add.rn.f32 	%f14, %f12, %f13;
	shfl.sync.down.b32	%f15, %f14, 1, 31, -1;
	add.rn.f32 	%f3, %f14, %f15;
	st.shared.f32 	[%rd22], %f3;
	setp.ne.s32 	%p2, %r2, 0;
	@%p2 bra 	$L__BB341_4;
	or.b32  	%r10, %r3, %r1;
	mul.wide.u32 	%rd23, %r10, 4;
	add.s64 	%rd5, %rd1, %rd23;
	st.global.f32 	[%rd5], %f3;
$L__BB341_4:
	ret;

}
	// .globl	loop_add_fusion_487
.visible .entry loop_add_fusion_487(
	.param .u64 loop_add_fusion_487_param_0,
	.param .u64 loop_add_fusion_487_param_1,
	.param .u64 loop_add_fusion_487_param_2,
	.param .u64 loop_add_fusion_487_param_3,
	.param .u64 loop_add_fusion_487_param_4,
	.param .u64 loop_add_fusion_487_param_5,
	.param .u64 loop_add_fusion_487_param_6,
	.param .u64 loop_add_fusion_487_param_7,
	.param .u64 loop_add_fusion_487_param_8,
	.param .u64 loop_add_fusion_487_param_9,
	.param .u64 loop_add_fusion_487_param_10,
	.param .u64 loop_add_fusion_487_param_11,
	.param .u64 loop_add_fusion_487_param_12,
	.param .u64 loop_add_fusion_487_param_13,
	.param .u64 loop_add_fusion_487_param_14,
	.param .u64 loop_add_fusion_487_param_15,
	.param .u64 loop_add_fusion_487_param_16
)
.reqntid 512, 1, 1
{
	.reg .b32 	%r<2>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<43>;

	ld.param.u64 	%rd1, [loop_add_fusion_487_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_487_param_16];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_487_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_487_param_15];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_487_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_487_param_14];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_487_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_487_param_13];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_487_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_487_param_12];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_487_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_487_param_11];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_487_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_487_param_10];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_487_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_487_param_9];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_add_fusion_487_param_8];
	cvta.to.global.u64 	%rd26, %rd25;
	cvta.to.global.u64 	%rd27, %rd22;
	cvta.to.global.u64 	%rd28, %rd19;
	cvta.to.global.u64 	%rd29, %rd16;
	cvta.to.global.u64 	%rd30, %rd13;
	cvta.to.global.u64 	%rd31, %rd10;
	cvta.to.global.u64 	%rd32, %rd7;
	cvta.to.global.u64 	%rd33, %rd4;
	cvta.to.global.u64 	%rd34, %rd1;
	mov.u32 	%r1, %tid.x;
	mul.wide.u32 	%rd35, %r1, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.nc.f32 	%f1, [%rd36];
	ld.global.nc.f32 	%f2, [%rd33];
	ld.global.nc.f32 	%f3, [%rd12];
	add.s64 	%rd37, %rd24, %rd35;
	ld.global.nc.f32 	%f4, [%rd37];
	mul.rn.f32 	%f5, %f3, %f4;
	ld.global.nc.f32 	%f6, [%rd15];
	add.s64 	%rd38, %rd18, %rd35;
	ld.global.nc.f32 	%f7, [%rd38];
	mul.rn.f32 	%f8, %f6, %f7;
	add.rn.f32 	%f9, %f5, %f8;
	ld.global.nc.f32 	%f10, [%rd32];
	ld.global.nc.f32 	%f11, [%rd21];
	mul.rn.f32 	%f12, %f4, %f4;
	mul.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.f32 	%f14, [%rd26];
	add.s64 	%rd39, %rd27, %rd35;
	ld.global.nc.f32 	%f15, [%rd39];
	mul.rn.f32 	%f16, %f14, %f15;
	add.rn.f32 	%f17, %f13, %f16;
	ld.global.nc.f32 	%f18, [%rd28];
	div.full.f32 	%f19, %f17, %f18;
	ld.global.nc.f32 	%f20, [%rd29];
	add.rn.f32 	%f21, %f20, %f19;
	sqrt.approx.f32 	%f22, %f21;
	ld.global.nc.f32 	%f23, [%rd30];
	add.rn.f32 	%f24, %f22, %f23;
	mul.rn.f32 	%f25, %f10, %f24;
	div.full.f32 	%f26, %f9, %f25;
	ld.global.nc.f32 	%f27, [%rd31];
	mul.rn.f32 	%f28, %f1, %f27;
	add.rn.f32 	%f29, %f28, %f26;
	mul.rn.f32 	%f30, %f2, %f29;
	add.rn.f32 	%f31, %f1, %f30;
	add.s64 	%rd40, %rd9, %rd35;
	st.global.f32 	[%rd40], %f31;
	add.s64 	%rd41, %rd6, %rd35;
	st.global.f32 	[%rd41], %f17;
	add.s64 	%rd42, %rd3, %rd35;
	st.global.f32 	[%rd42], %f9;
	ret;

}
	// .globl	loop_add_fusion_489
.visible .entry loop_add_fusion_489(
	.param .u64 loop_add_fusion_489_param_0,
	.param .u64 loop_add_fusion_489_param_1,
	.param .u64 loop_add_fusion_489_param_2,
	.param .u64 loop_add_fusion_489_param_3,
	.param .u64 loop_add_fusion_489_param_4,
	.param .u64 loop_add_fusion_489_param_5,
	.param .u64 loop_add_fusion_489_param_6,
	.param .u64 loop_add_fusion_489_param_7,
	.param .u64 loop_add_fusion_489_param_8,
	.param .u64 loop_add_fusion_489_param_9,
	.param .u64 loop_add_fusion_489_param_10,
	.param .u64 loop_add_fusion_489_param_11,
	.param .u64 loop_add_fusion_489_param_12,
	.param .u64 loop_add_fusion_489_param_13,
	.param .u64 loop_add_fusion_489_param_14,
	.param .u64 loop_add_fusion_489_param_15,
	.param .u64 loop_add_fusion_489_param_16
)
.reqntid 256, 1, 1
{
	.reg .b32 	%r<6>;
	.reg .f32 	%f<95>;
	.reg .b64 	%rd<43>;

	ld.param.u64 	%rd1, [loop_add_fusion_489_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_489_param_16];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_489_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_489_param_15];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_489_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_489_param_14];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_489_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_489_param_13];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_489_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_489_param_12];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_489_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_489_param_11];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_489_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_489_param_10];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_489_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_489_param_9];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_add_fusion_489_param_8];
	cvta.to.global.u64 	%rd26, %rd25;
	cvta.to.global.u64 	%rd27, %rd22;
	cvta.to.global.u64 	%rd28, %rd19;
	cvta.to.global.u64 	%rd29, %rd16;
	cvta.to.global.u64 	%rd30, %rd13;
	cvta.to.global.u64 	%rd31, %rd10;
	cvta.to.global.u64 	%rd32, %rd7;
	cvta.to.global.u64 	%rd33, %rd4;
	cvta.to.global.u64 	%rd34, %rd1;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	shl.b32 	%r3, %r2, 10;
	shl.b32 	%r4, %r1, 2;
	or.b32  	%r5, %r3, %r4;
	mul.wide.u32 	%rd35, %r5, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd36];
	ld.global.nc.f32 	%f5, [%rd33];
	ld.global.nc.f32 	%f6, [%rd12];
	add.s64 	%rd37, %rd24, %rd35;
	ld.global.nc.v4.f32 	{%f7, %f8, %f9, %f10}, [%rd37];
	mul.rn.f32 	%f11, %f6, %f7;
	ld.global.nc.f32 	%f12, [%rd15];
	add.s64 	%rd38, %rd18, %rd35;
	ld.global.nc.v4.f32 	{%f13, %f14, %f15, %f16}, [%rd38];
	mul.rn.f32 	%f17, %f12, %f13;
	add.rn.f32 	%f18, %f11, %f17;
	ld.global.nc.f32 	%f19, [%rd32];
	ld.global.nc.f32 	%f20, [%rd21];
	mul.rn.f32 	%f21, %f7, %f7;
	mul.rn.f32 	%f22, %f21, %f20;
	ld.global.nc.f32 	%f23, [%rd26];
	add.s64 	%rd39, %rd27, %rd35;
	ld.global.nc.v4.f32 	{%f24, %f25, %f26, %f27}, [%rd39];
	mul.rn.f32 	%f28, %f23, %f24;
	add.rn.f32 	%f29, %f22, %f28;
	ld.global.nc.f32 	%f30, [%rd28];
	div.full.f32 	%f31, %f29, %f30;
	ld.global.nc.f32 	%f32, [%rd29];
	add.rn.f32 	%f33, %f32, %f31;
	sqrt.approx.f32 	%f34, %f33;
	ld.global.nc.f32 	%f35, [%rd30];
	add.rn.f32 	%f36, %f34, %f35;
	mul.rn.f32 	%f37, %f19, %f36;
	div.full.f32 	%f38, %f18, %f37;
	ld.global.nc.f32 	%f39, [%rd31];
	mul.rn.f32 	%f40, %f1, %f39;
	add.rn.f32 	%f41, %f40, %f38;
	mul.rn.f32 	%f42, %f5, %f41;
	add.rn.f32 	%f43, %f1, %f42;
	add.s64 	%rd40, %rd9, %rd35;
	add.s64 	%rd41, %rd6, %rd35;
	add.s64 	%rd42, %rd3, %rd35;
	mul.rn.f32 	%f44, %f6, %f8;
	mul.rn.f32 	%f45, %f12, %f14;
	add.rn.f32 	%f46, %f44, %f45;
	mul.rn.f32 	%f47, %f8, %f8;
	mul.rn.f32 	%f48, %f20, %f47;
	mul.rn.f32 	%f49, %f23, %f25;
	add.rn.f32 	%f50, %f48, %f49;
	div.full.f32 	%f51, %f50, %f30;
	add.rn.f32 	%f52, %f32, %f51;
	sqrt.approx.f32 	%f53, %f52;
	add.rn.f32 	%f54, %f35, %f53;
	mul.rn.f32 	%f55, %f19, %f54;
	div.full.f32 	%f56, %f46, %f55;
	mul.rn.f32 	%f57, %f39, %f2;
	add.rn.f32 	%f58, %f57, %f56;
	mul.rn.f32 	%f59, %f5, %f58;
	add.rn.f32 	%f60, %f2, %f59;
	mul.rn.f32 	%f61, %f6, %f9;
	mul.rn.f32 	%f62, %f12, %f15;
	add.rn.f32 	%f63, %f61, %f62;
	mul.rn.f32 	%f64, %f9, %f9;
	mul.rn.f32 	%f65, %f20, %f64;
	mul.rn.f32 	%f66, %f23, %f26;
	add.rn.f32 	%f67, %f65, %f66;
	div.full.f32 	%f68, %f67, %f30;
	add.rn.f32 	%f69, %f32, %f68;
	sqrt.approx.f32 	%f70, %f69;
	add.rn.f32 	%f71, %f35, %f70;
	mul.rn.f32 	%f72, %f19, %f71;
	div.full.f32 	%f73, %f63, %f72;
	mul.rn.f32 	%f74, %f39, %f3;
	add.rn.f32 	%f75, %f74, %f73;
	mul.rn.f32 	%f76, %f5, %f75;
	add.rn.f32 	%f77, %f3, %f76;
	mul.rn.f32 	%f78, %f6, %f10;
	mul.rn.f32 	%f79, %f12, %f16;
	add.rn.f32 	%f80, %f78, %f79;
	mul.rn.f32 	%f81, %f10, %f10;
	mul.rn.f32 	%f82, %f20, %f81;
	mul.rn.f32 	%f83, %f23, %f27;
	add.rn.f32 	%f84, %f82, %f83;
	div.full.f32 	%f85, %f84, %f30;
	add.rn.f32 	%f86, %f32, %f85;
	sqrt.approx.f32 	%f87, %f86;
	add.rn.f32 	%f88, %f35, %f87;
	mul.rn.f32 	%f89, %f19, %f88;
	div.full.f32 	%f90, %f80, %f89;
	mul.rn.f32 	%f91, %f39, %f4;
	add.rn.f32 	%f92, %f91, %f90;
	mul.rn.f32 	%f93, %f5, %f92;
	add.rn.f32 	%f94, %f4, %f93;
	st.global.v4.f32 	[%rd40], {%f43, %f60, %f77, %f94};
	st.global.v4.f32 	[%rd41], {%f29, %f50, %f67, %f84};
	st.global.v4.f32 	[%rd42], {%f18, %f46, %f63, %f80};
	ret;

}
	// .globl	loop_add_fusion_490
.visible .entry loop_add_fusion_490(
	.param .u64 loop_add_fusion_490_param_0,
	.param .u64 loop_add_fusion_490_param_1,
	.param .u64 loop_add_fusion_490_param_2,
	.param .u64 loop_add_fusion_490_param_3,
	.param .u64 loop_add_fusion_490_param_4,
	.param .u64 loop_add_fusion_490_param_5,
	.param .u64 loop_add_fusion_490_param_6,
	.param .u64 loop_add_fusion_490_param_7,
	.param .u64 loop_add_fusion_490_param_8,
	.param .u64 loop_add_fusion_490_param_9,
	.param .u64 loop_add_fusion_490_param_10,
	.param .u64 loop_add_fusion_490_param_11,
	.param .u64 loop_add_fusion_490_param_12,
	.param .u64 loop_add_fusion_490_param_13,
	.param .u64 loop_add_fusion_490_param_14,
	.param .u64 loop_add_fusion_490_param_15,
	.param .u64 loop_add_fusion_490_param_16
)
.reqntid 1024, 1, 1
{
	.reg .b32 	%r<5>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<43>;

	ld.param.u64 	%rd1, [loop_add_fusion_490_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_490_param_16];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_490_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_490_param_15];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_490_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_490_param_14];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_490_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_490_param_13];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_490_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_490_param_12];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_490_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_490_param_11];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_490_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_490_param_10];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_490_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_490_param_9];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_add_fusion_490_param_8];
	cvta.to.global.u64 	%rd26, %rd25;
	cvta.to.global.u64 	%rd27, %rd22;
	cvta.to.global.u64 	%rd28, %rd19;
	cvta.to.global.u64 	%rd29, %rd16;
	cvta.to.global.u64 	%rd30, %rd13;
	cvta.to.global.u64 	%rd31, %rd10;
	cvta.to.global.u64 	%rd32, %rd7;
	cvta.to.global.u64 	%rd33, %rd4;
	cvta.to.global.u64 	%rd34, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 10;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.wide.u32 	%rd35, %r4, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.nc.f32 	%f1, [%rd36];
	ld.global.nc.f32 	%f2, [%rd33];
	ld.global.nc.f32 	%f3, [%rd12];
	add.s64 	%rd37, %rd24, %rd35;
	ld.global.nc.f32 	%f4, [%rd37];
	mul.rn.f32 	%f5, %f3, %f4;
	ld.global.nc.f32 	%f6, [%rd15];
	add.s64 	%rd38, %rd18, %rd35;
	ld.global.nc.f32 	%f7, [%rd38];
	mul.rn.f32 	%f8, %f6, %f7;
	add.rn.f32 	%f9, %f5, %f8;
	ld.global.nc.f32 	%f10, [%rd32];
	ld.global.nc.f32 	%f11, [%rd21];
	mul.rn.f32 	%f12, %f4, %f4;
	mul.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.f32 	%f14, [%rd26];
	add.s64 	%rd39, %rd27, %rd35;
	ld.global.nc.f32 	%f15, [%rd39];
	mul.rn.f32 	%f16, %f14, %f15;
	add.rn.f32 	%f17, %f13, %f16;
	ld.global.nc.f32 	%f18, [%rd28];
	div.full.f32 	%f19, %f17, %f18;
	ld.global.nc.f32 	%f20, [%rd29];
	add.rn.f32 	%f21, %f20, %f19;
	sqrt.approx.f32 	%f22, %f21;
	ld.global.nc.f32 	%f23, [%rd30];
	add.rn.f32 	%f24, %f22, %f23;
	mul.rn.f32 	%f25, %f10, %f24;
	div.full.f32 	%f26, %f9, %f25;
	ld.global.nc.f32 	%f27, [%rd31];
	mul.rn.f32 	%f28, %f1, %f27;
	add.rn.f32 	%f29, %f28, %f26;
	mul.rn.f32 	%f30, %f2, %f29;
	add.rn.f32 	%f31, %f1, %f30;
	add.s64 	%rd40, %rd9, %rd35;
	st.global.f32 	[%rd40], %f31;
	add.s64 	%rd41, %rd6, %rd35;
	st.global.f32 	[%rd41], %f17;
	add.s64 	%rd42, %rd3, %rd35;
	st.global.f32 	[%rd42], %f9;
	ret;

}
	// .globl	loop_add_fusion_491
.visible .entry loop_add_fusion_491(
	.param .u64 loop_add_fusion_491_param_0,
	.param .u64 loop_add_fusion_491_param_1,
	.param .u64 loop_add_fusion_491_param_2,
	.param .u64 loop_add_fusion_491_param_3,
	.param .u64 loop_add_fusion_491_param_4,
	.param .u64 loop_add_fusion_491_param_5,
	.param .u64 loop_add_fusion_491_param_6,
	.param .u64 loop_add_fusion_491_param_7,
	.param .u64 loop_add_fusion_491_param_8,
	.param .u64 loop_add_fusion_491_param_9,
	.param .u64 loop_add_fusion_491_param_10,
	.param .u64 loop_add_fusion_491_param_11,
	.param .u64 loop_add_fusion_491_param_12,
	.param .u64 loop_add_fusion_491_param_13,
	.param .u64 loop_add_fusion_491_param_14,
	.param .u64 loop_add_fusion_491_param_15,
	.param .u64 loop_add_fusion_491_param_16
)
.reqntid 128, 1, 1
{
	.reg .b32 	%r<5>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<43>;

	ld.param.u64 	%rd1, [loop_add_fusion_491_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_491_param_16];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_491_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_491_param_15];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_491_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_491_param_14];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_491_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_491_param_13];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_491_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_491_param_12];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_491_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_491_param_11];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_491_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_491_param_10];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_491_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_491_param_9];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_add_fusion_491_param_8];
	cvta.to.global.u64 	%rd26, %rd25;
	cvta.to.global.u64 	%rd27, %rd22;
	cvta.to.global.u64 	%rd28, %rd19;
	cvta.to.global.u64 	%rd29, %rd16;
	cvta.to.global.u64 	%rd30, %rd13;
	cvta.to.global.u64 	%rd31, %rd10;
	cvta.to.global.u64 	%rd32, %rd7;
	cvta.to.global.u64 	%rd33, %rd4;
	cvta.to.global.u64 	%rd34, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.wide.u32 	%rd35, %r4, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.nc.f32 	%f1, [%rd36];
	ld.global.nc.f32 	%f2, [%rd33];
	ld.global.nc.f32 	%f3, [%rd12];
	add.s64 	%rd37, %rd24, %rd35;
	ld.global.nc.f32 	%f4, [%rd37];
	mul.rn.f32 	%f5, %f3, %f4;
	ld.global.nc.f32 	%f6, [%rd15];
	add.s64 	%rd38, %rd18, %rd35;
	ld.global.nc.f32 	%f7, [%rd38];
	mul.rn.f32 	%f8, %f6, %f7;
	add.rn.f32 	%f9, %f5, %f8;
	ld.global.nc.f32 	%f10, [%rd32];
	ld.global.nc.f32 	%f11, [%rd21];
	mul.rn.f32 	%f12, %f4, %f4;
	mul.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.f32 	%f14, [%rd26];
	add.s64 	%rd39, %rd27, %rd35;
	ld.global.nc.f32 	%f15, [%rd39];
	mul.rn.f32 	%f16, %f14, %f15;
	add.rn.f32 	%f17, %f13, %f16;
	ld.global.nc.f32 	%f18, [%rd28];
	div.full.f32 	%f19, %f17, %f18;
	ld.global.nc.f32 	%f20, [%rd29];
	add.rn.f32 	%f21, %f20, %f19;
	sqrt.approx.f32 	%f22, %f21;
	ld.global.nc.f32 	%f23, [%rd30];
	add.rn.f32 	%f24, %f22, %f23;
	mul.rn.f32 	%f25, %f10, %f24;
	div.full.f32 	%f26, %f9, %f25;
	ld.global.nc.f32 	%f27, [%rd31];
	mul.rn.f32 	%f28, %f1, %f27;
	add.rn.f32 	%f29, %f28, %f26;
	mul.rn.f32 	%f30, %f2, %f29;
	add.rn.f32 	%f31, %f1, %f30;
	add.s64 	%rd40, %rd9, %rd35;
	st.global.f32 	[%rd40], %f31;
	add.s64 	%rd41, %rd6, %rd35;
	st.global.f32 	[%rd41], %f17;
	add.s64 	%rd42, %rd3, %rd35;
	st.global.f32 	[%rd42], %f9;
	ret;

}
	// .globl	loop_add_fusion_508
.visible .entry loop_add_fusion_508(
	.param .u64 loop_add_fusion_508_param_0,
	.param .u64 loop_add_fusion_508_param_1,
	.param .u64 loop_add_fusion_508_param_2,
	.param .u64 loop_add_fusion_508_param_3,
	.param .u64 loop_add_fusion_508_param_4,
	.param .u64 loop_add_fusion_508_param_5,
	.param .u64 loop_add_fusion_508_param_6,
	.param .u64 loop_add_fusion_508_param_7,
	.param .u64 loop_add_fusion_508_param_8,
	.param .u64 loop_add_fusion_508_param_9,
	.param .u64 loop_add_fusion_508_param_10,
	.param .u64 loop_add_fusion_508_param_11,
	.param .u64 loop_add_fusion_508_param_12,
	.param .u64 loop_add_fusion_508_param_13,
	.param .u64 loop_add_fusion_508_param_14,
	.param .u64 loop_add_fusion_508_param_15
)
.reqntid 256, 1, 1
{
	.reg .b32 	%r<6>;
	.reg .f32 	%f<95>;
	.reg .b64 	%rd<40>;

	ld.param.u64 	%rd1, [loop_add_fusion_508_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_508_param_15];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_508_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_508_param_14];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_508_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_508_param_13];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_508_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_508_param_12];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_508_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_508_param_11];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_508_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_508_param_10];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_508_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_508_param_9];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_508_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_508_param_8];
	cvta.to.global.u64 	%rd24, %rd23;
	cvta.to.global.u64 	%rd25, %rd22;
	cvta.to.global.u64 	%rd26, %rd19;
	cvta.to.global.u64 	%rd27, %rd16;
	cvta.to.global.u64 	%rd28, %rd13;
	cvta.to.global.u64 	%rd29, %rd10;
	cvta.to.global.u64 	%rd30, %rd7;
	cvta.to.global.u64 	%rd31, %rd4;
	cvta.to.global.u64 	%rd32, %rd1;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	shl.b32 	%r3, %r2, 10;
	shl.b32 	%r4, %r1, 2;
	or.b32  	%r5, %r3, %r4;
	mul.wide.u32 	%rd33, %r5, 4;
	add.s64 	%rd34, %rd32, %rd33;
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd34];
	ld.global.nc.f32 	%f5, [%rd31];
	ld.global.nc.f32 	%f6, [%rd9];
	add.s64 	%rd35, %rd21, %rd33;
	ld.global.v4.f32 	{%f7, %f8, %f9, %f10}, [%rd35];
	mul.rn.f32 	%f11, %f6, %f7;
	ld.global.nc.f32 	%f12, [%rd12];
	add.s64 	%rd36, %rd15, %rd33;
	ld.global.nc.v4.f32 	{%f13, %f14, %f15, %f16}, [%rd36];
	mul.rn.f32 	%f17, %f12, %f13;
	add.rn.f32 	%f18, %f11, %f17;
	ld.global.nc.f32 	%f19, [%rd30];
	ld.global.nc.f32 	%f20, [%rd18];
	mul.rn.f32 	%f21, %f7, %f7;
	mul.rn.f32 	%f22, %f21, %f20;
	ld.global.nc.f32 	%f23, [%rd24];
	add.s64 	%rd37, %rd25, %rd33;
	ld.global.nc.v4.f32 	{%f24, %f25, %f26, %f27}, [%rd37];
	mul.rn.f32 	%f28, %f23, %f24;
	add.rn.f32 	%f29, %f22, %f28;
	ld.global.nc.f32 	%f30, [%rd26];
	div.full.f32 	%f31, %f29, %f30;
	ld.global.nc.f32 	%f32, [%rd27];
	add.rn.f32 	%f33, %f32, %f31;
	sqrt.approx.f32 	%f34, %f33;
	ld.global.nc.f32 	%f35, [%rd28];
	add.rn.f32 	%f36, %f34, %f35;
	mul.rn.f32 	%f37, %f19, %f36;
	div.full.f32 	%f38, %f18, %f37;
	ld.global.nc.f32 	%f39, [%rd29];
	mul.rn.f32 	%f40, %f1, %f39;
	add.rn.f32 	%f41, %f40, %f38;
	mul.rn.f32 	%f42, %f5, %f41;
	add.rn.f32 	%f43, %f1, %f42;
	add.s64 	%rd38, %rd6, %rd33;
	add.s64 	%rd39, %rd3, %rd33;
	mul.rn.f32 	%f44, %f6, %f8;
	mul.rn.f32 	%f45, %f12, %f14;
	add.rn.f32 	%f46, %f44, %f45;
	mul.rn.f32 	%f47, %f8, %f8;
	mul.rn.f32 	%f48, %f20, %f47;
	mul.rn.f32 	%f49, %f23, %f25;
	add.rn.f32 	%f50, %f48, %f49;
	div.full.f32 	%f51, %f50, %f30;
	add.rn.f32 	%f52, %f32, %f51;
	sqrt.approx.f32 	%f53, %f52;
	add.rn.f32 	%f54, %f35, %f53;
	mul.rn.f32 	%f55, %f19, %f54;
	div.full.f32 	%f56, %f46, %f55;
	mul.rn.f32 	%f57, %f39, %f2;
	add.rn.f32 	%f58, %f57, %f56;
	mul.rn.f32 	%f59, %f5, %f58;
	add.rn.f32 	%f60, %f2, %f59;
	mul.rn.f32 	%f61, %f6, %f9;
	mul.rn.f32 	%f62, %f12, %f15;
	add.rn.f32 	%f63, %f61, %f62;
	mul.rn.f32 	%f64, %f9, %f9;
	mul.rn.f32 	%f65, %f20, %f64;
	mul.rn.f32 	%f66, %f23, %f26;
	add.rn.f32 	%f67, %f65, %f66;
	div.full.f32 	%f68, %f67, %f30;
	add.rn.f32 	%f69, %f32, %f68;
	sqrt.approx.f32 	%f70, %f69;
	add.rn.f32 	%f71, %f35, %f70;
	mul.rn.f32 	%f72, %f19, %f71;
	div.full.f32 	%f73, %f63, %f72;
	mul.rn.f32 	%f74, %f39, %f3;
	add.rn.f32 	%f75, %f74, %f73;
	mul.rn.f32 	%f76, %f5, %f75;
	add.rn.f32 	%f77, %f3, %f76;
	mul.rn.f32 	%f78, %f6, %f10;
	mul.rn.f32 	%f79, %f12, %f16;
	add.rn.f32 	%f80, %f78, %f79;
	mul.rn.f32 	%f81, %f10, %f10;
	mul.rn.f32 	%f82, %f20, %f81;
	mul.rn.f32 	%f83, %f23, %f27;
	add.rn.f32 	%f84, %f82, %f83;
	div.full.f32 	%f85, %f84, %f30;
	add.rn.f32 	%f86, %f32, %f85;
	sqrt.approx.f32 	%f87, %f86;
	add.rn.f32 	%f88, %f35, %f87;
	mul.rn.f32 	%f89, %f19, %f88;
	div.full.f32 	%f90, %f80, %f89;
	mul.rn.f32 	%f91, %f39, %f4;
	add.rn.f32 	%f92, %f91, %f90;
	mul.rn.f32 	%f93, %f5, %f92;
	add.rn.f32 	%f94, %f4, %f93;
	st.global.v4.f32 	[%rd38], {%f43, %f60, %f77, %f94};
	st.global.v4.f32 	[%rd39], {%f29, %f50, %f67, %f84};
	st.global.v4.f32 	[%rd35], {%f18, %f46, %f63, %f80};
	ret;

}
	// .globl	loop_add_fusion_510
.visible .entry loop_add_fusion_510(
	.param .u64 loop_add_fusion_510_param_0,
	.param .u64 loop_add_fusion_510_param_1,
	.param .u64 loop_add_fusion_510_param_2,
	.param .u64 loop_add_fusion_510_param_3,
	.param .u64 loop_add_fusion_510_param_4,
	.param .u64 loop_add_fusion_510_param_5,
	.param .u64 loop_add_fusion_510_param_6,
	.param .u64 loop_add_fusion_510_param_7,
	.param .u64 loop_add_fusion_510_param_8,
	.param .u64 loop_add_fusion_510_param_9,
	.param .u64 loop_add_fusion_510_param_10,
	.param .u64 loop_add_fusion_510_param_11,
	.param .u64 loop_add_fusion_510_param_12,
	.param .u64 loop_add_fusion_510_param_13,
	.param .u64 loop_add_fusion_510_param_14,
	.param .u64 loop_add_fusion_510_param_15
)
.reqntid 1024, 1, 1
{
	.reg .b32 	%r<5>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<40>;

	ld.param.u64 	%rd1, [loop_add_fusion_510_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_510_param_15];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_510_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_510_param_14];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_510_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_510_param_13];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_510_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_510_param_12];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_510_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_510_param_11];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_510_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_510_param_10];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_510_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_510_param_9];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_510_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_510_param_8];
	cvta.to.global.u64 	%rd24, %rd23;
	cvta.to.global.u64 	%rd25, %rd22;
	cvta.to.global.u64 	%rd26, %rd19;
	cvta.to.global.u64 	%rd27, %rd16;
	cvta.to.global.u64 	%rd28, %rd13;
	cvta.to.global.u64 	%rd29, %rd10;
	cvta.to.global.u64 	%rd30, %rd7;
	cvta.to.global.u64 	%rd31, %rd4;
	cvta.to.global.u64 	%rd32, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 10;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.wide.u32 	%rd33, %r4, 4;
	add.s64 	%rd34, %rd32, %rd33;
	ld.global.nc.f32 	%f1, [%rd34];
	ld.global.nc.f32 	%f2, [%rd31];
	ld.global.nc.f32 	%f3, [%rd9];
	add.s64 	%rd35, %rd21, %rd33;
	ld.global.f32 	%f4, [%rd35];
	mul.rn.f32 	%f5, %f3, %f4;
	ld.global.nc.f32 	%f6, [%rd12];
	add.s64 	%rd36, %rd15, %rd33;
	ld.global.nc.f32 	%f7, [%rd36];
	mul.rn.f32 	%f8, %f6, %f7;
	add.rn.f32 	%f9, %f5, %f8;
	ld.global.nc.f32 	%f10, [%rd30];
	ld.global.nc.f32 	%f11, [%rd18];
	mul.rn.f32 	%f12, %f4, %f4;
	mul.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.f32 	%f14, [%rd24];
	add.s64 	%rd37, %rd25, %rd33;
	ld.global.nc.f32 	%f15, [%rd37];
	mul.rn.f32 	%f16, %f14, %f15;
	add.rn.f32 	%f17, %f13, %f16;
	ld.global.nc.f32 	%f18, [%rd26];
	div.full.f32 	%f19, %f17, %f18;
	ld.global.nc.f32 	%f20, [%rd27];
	add.rn.f32 	%f21, %f20, %f19;
	sqrt.approx.f32 	%f22, %f21;
	ld.global.nc.f32 	%f23, [%rd28];
	add.rn.f32 	%f24, %f22, %f23;
	mul.rn.f32 	%f25, %f10, %f24;
	div.full.f32 	%f26, %f9, %f25;
	ld.global.nc.f32 	%f27, [%rd29];
	mul.rn.f32 	%f28, %f1, %f27;
	add.rn.f32 	%f29, %f28, %f26;
	mul.rn.f32 	%f30, %f2, %f29;
	add.rn.f32 	%f31, %f1, %f30;
	add.s64 	%rd38, %rd6, %rd33;
	st.global.f32 	[%rd38], %f31;
	add.s64 	%rd39, %rd3, %rd33;
	st.global.f32 	[%rd39], %f17;
	st.global.f32 	[%rd35], %f9;
	ret;

}
	// .globl	loop_add_fusion_516
.visible .entry loop_add_fusion_516(
	.param .u64 loop_add_fusion_516_param_0,
	.param .u64 loop_add_fusion_516_param_1,
	.param .u64 loop_add_fusion_516_param_2,
	.param .u64 loop_add_fusion_516_param_3,
	.param .u64 loop_add_fusion_516_param_4,
	.param .u64 loop_add_fusion_516_param_5,
	.param .u64 loop_add_fusion_516_param_6,
	.param .u64 loop_add_fusion_516_param_7,
	.param .u64 loop_add_fusion_516_param_8,
	.param .u64 loop_add_fusion_516_param_9,
	.param .u64 loop_add_fusion_516_param_10,
	.param .u64 loop_add_fusion_516_param_11,
	.param .u64 loop_add_fusion_516_param_12,
	.param .u64 loop_add_fusion_516_param_13,
	.param .u64 loop_add_fusion_516_param_14,
	.param .u64 loop_add_fusion_516_param_15
)
.reqntid 128, 1, 1
{
	.reg .b32 	%r<5>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<40>;

	ld.param.u64 	%rd1, [loop_add_fusion_516_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_516_param_15];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_516_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_516_param_14];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_516_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_516_param_13];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_516_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_516_param_12];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_516_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_516_param_11];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_516_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_516_param_10];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_516_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_516_param_9];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_516_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_516_param_8];
	cvta.to.global.u64 	%rd24, %rd23;
	cvta.to.global.u64 	%rd25, %rd22;
	cvta.to.global.u64 	%rd26, %rd19;
	cvta.to.global.u64 	%rd27, %rd16;
	cvta.to.global.u64 	%rd28, %rd13;
	cvta.to.global.u64 	%rd29, %rd10;
	cvta.to.global.u64 	%rd30, %rd7;
	cvta.to.global.u64 	%rd31, %rd4;
	cvta.to.global.u64 	%rd32, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 7;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.wide.u32 	%rd33, %r4, 4;
	add.s64 	%rd34, %rd32, %rd33;
	ld.global.nc.f32 	%f1, [%rd34];
	ld.global.nc.f32 	%f2, [%rd31];
	ld.global.nc.f32 	%f3, [%rd9];
	add.s64 	%rd35, %rd21, %rd33;
	ld.global.f32 	%f4, [%rd35];
	mul.rn.f32 	%f5, %f3, %f4;
	ld.global.nc.f32 	%f6, [%rd12];
	add.s64 	%rd36, %rd15, %rd33;
	ld.global.nc.f32 	%f7, [%rd36];
	mul.rn.f32 	%f8, %f6, %f7;
	add.rn.f32 	%f9, %f5, %f8;
	ld.global.nc.f32 	%f10, [%rd30];
	ld.global.nc.f32 	%f11, [%rd18];
	mul.rn.f32 	%f12, %f4, %f4;
	mul.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.f32 	%f14, [%rd24];
	add.s64 	%rd37, %rd25, %rd33;
	ld.global.nc.f32 	%f15, [%rd37];
	mul.rn.f32 	%f16, %f14, %f15;
	add.rn.f32 	%f17, %f13, %f16;
	ld.global.nc.f32 	%f18, [%rd26];
	div.full.f32 	%f19, %f17, %f18;
	ld.global.nc.f32 	%f20, [%rd27];
	add.rn.f32 	%f21, %f20, %f19;
	sqrt.approx.f32 	%f22, %f21;
	ld.global.nc.f32 	%f23, [%rd28];
	add.rn.f32 	%f24, %f22, %f23;
	mul.rn.f32 	%f25, %f10, %f24;
	div.full.f32 	%f26, %f9, %f25;
	ld.global.nc.f32 	%f27, [%rd29];
	mul.rn.f32 	%f28, %f1, %f27;
	add.rn.f32 	%f29, %f28, %f26;
	mul.rn.f32 	%f30, %f2, %f29;
	add.rn.f32 	%f31, %f1, %f30;
	add.s64 	%rd38, %rd6, %rd33;
	st.global.f32 	[%rd38], %f31;
	add.s64 	%rd39, %rd3, %rd33;
	st.global.f32 	[%rd39], %f17;
	st.global.f32 	[%rd35], %f9;
	ret;

}
	// .globl	loop_add_fusion_517
.visible .entry loop_add_fusion_517(
	.param .u64 loop_add_fusion_517_param_0,
	.param .u64 loop_add_fusion_517_param_1,
	.param .u64 loop_add_fusion_517_param_2,
	.param .u64 loop_add_fusion_517_param_3,
	.param .u64 loop_add_fusion_517_param_4,
	.param .u64 loop_add_fusion_517_param_5,
	.param .u64 loop_add_fusion_517_param_6,
	.param .u64 loop_add_fusion_517_param_7,
	.param .u64 loop_add_fusion_517_param_8,
	.param .u64 loop_add_fusion_517_param_9,
	.param .u64 loop_add_fusion_517_param_10,
	.param .u64 loop_add_fusion_517_param_11,
	.param .u64 loop_add_fusion_517_param_12,
	.param .u64 loop_add_fusion_517_param_13,
	.param .u64 loop_add_fusion_517_param_14,
	.param .u64 loop_add_fusion_517_param_15
)
.reqntid 512, 1, 1
{
	.reg .b32 	%r<2>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<40>;

	ld.param.u64 	%rd1, [loop_add_fusion_517_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_517_param_15];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_517_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_517_param_14];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_517_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_517_param_13];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_517_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_517_param_12];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_517_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_517_param_11];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_517_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_517_param_10];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_517_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_517_param_9];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_517_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_517_param_8];
	cvta.to.global.u64 	%rd24, %rd23;
	cvta.to.global.u64 	%rd25, %rd22;
	cvta.to.global.u64 	%rd26, %rd19;
	cvta.to.global.u64 	%rd27, %rd16;
	cvta.to.global.u64 	%rd28, %rd13;
	cvta.to.global.u64 	%rd29, %rd10;
	cvta.to.global.u64 	%rd30, %rd7;
	cvta.to.global.u64 	%rd31, %rd4;
	cvta.to.global.u64 	%rd32, %rd1;
	mov.u32 	%r1, %tid.x;
	mul.wide.u32 	%rd33, %r1, 4;
	add.s64 	%rd34, %rd32, %rd33;
	ld.global.nc.f32 	%f1, [%rd34];
	ld.global.nc.f32 	%f2, [%rd31];
	ld.global.nc.f32 	%f3, [%rd9];
	add.s64 	%rd35, %rd21, %rd33;
	ld.global.f32 	%f4, [%rd35];
	mul.rn.f32 	%f5, %f3, %f4;
	ld.global.nc.f32 	%f6, [%rd12];
	add.s64 	%rd36, %rd15, %rd33;
	ld.global.nc.f32 	%f7, [%rd36];
	mul.rn.f32 	%f8, %f6, %f7;
	add.rn.f32 	%f9, %f5, %f8;
	ld.global.nc.f32 	%f10, [%rd30];
	ld.global.nc.f32 	%f11, [%rd18];
	mul.rn.f32 	%f12, %f4, %f4;
	mul.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.f32 	%f14, [%rd24];
	add.s64 	%rd37, %rd25, %rd33;
	ld.global.nc.f32 	%f15, [%rd37];
	mul.rn.f32 	%f16, %f14, %f15;
	add.rn.f32 	%f17, %f13, %f16;
	ld.global.nc.f32 	%f18, [%rd26];
	div.full.f32 	%f19, %f17, %f18;
	ld.global.nc.f32 	%f20, [%rd27];
	add.rn.f32 	%f21, %f20, %f19;
	sqrt.approx.f32 	%f22, %f21;
	ld.global.nc.f32 	%f23, [%rd28];
	add.rn.f32 	%f24, %f22, %f23;
	mul.rn.f32 	%f25, %f10, %f24;
	div.full.f32 	%f26, %f9, %f25;
	ld.global.nc.f32 	%f27, [%rd29];
	mul.rn.f32 	%f28, %f1, %f27;
	add.rn.f32 	%f29, %f28, %f26;
	mul.rn.f32 	%f30, %f2, %f29;
	add.rn.f32 	%f31, %f1, %f30;
	add.s64 	%rd38, %rd6, %rd33;
	st.global.f32 	[%rd38], %f31;
	add.s64 	%rd39, %rd3, %rd33;
	st.global.f32 	[%rd39], %f17;
	st.global.f32 	[%rd35], %f9;
	ret;

}
	// .globl	gemm_fusion_dot_642_1
.visible .entry gemm_fusion_dot_642_1(
	.param .u64 gemm_fusion_dot_642_1_param_0,
	.param .u64 gemm_fusion_dot_642_1_param_1,
	.param .u64 gemm_fusion_dot_642_1_param_2
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<25>;
	.reg .b32 	%r<150>;
	.reg .f32 	%f<89>;
	.reg .b64 	%rd<62>;

	ld.param.u64 	%rd8, [gemm_fusion_dot_642_1_param_0];
	ld.param.u64 	%rd9, [gemm_fusion_dot_642_1_param_2];
	cvta.to.global.u64 	%rd10, %rd9;
	ld.param.u64 	%rd11, [gemm_fusion_dot_642_1_param_1];
	cvta.to.global.u64 	%rd12, %rd11;
	cvta.to.global.u64 	%rd13, %rd8;
	// begin inline asm
	mov.u32 %r1, %ctaid.x;
	// end inline asm
	shr.s32 	%r84, %r1, 31;
	shr.u32 	%r85, %r84, 29;
	add.s32 	%r86, %r1, %r85;
	and.b32  	%r87, %r86, -8;
	mov.b32 	%r88, 32;
	sub.s32 	%r89, %r88, %r87;
	min.s32 	%r90, %r89, 8;
	rem.s32 	%r91, %r1, %r90;
	add.s32 	%r92, %r87, %r91;
	sub.s32 	%r93, %r1, %r87;
	div.s32 	%r94, %r93, %r90;
	shl.b32 	%r95, %r92, 4;
	cvt.s64.s32 	%rd14, %r95;
	shl.b32 	%r96, %r94, 4;
	cvt.s64.s32 	%rd15, %r96;
	mov.u32 	%r97, %tid.x;
	shl.b32 	%r98, %r97, 2;
	and.b32  	%r99, %r98, 12;
	shr.u32 	%r100, %r97, 5;
	and.b32  	%r101, %r97, 8;
	shr.u32 	%r102, %r97, 3;
	shl.b32 	%r103, %r97, 1;
	and.b32  	%r104, %r103, 14;
	cvt.u64.u32 	%rd16, %r99;
	cvt.u64.u32 	%rd17, %r102;
	cvt.u64.u32 	%rd18, %r104;
	or.b64  	%rd19, %rd14, %rd16;
	or.b64  	%rd20, %rd14, %rd17;
	shr.u32 	%r105, %r97, 2;
	or.b32  	%r106, %r105, 32;
	or.b32  	%r107, %r102, 16;
	or.b32  	%r108, %r102, 48;
	shl.b32 	%r109, %r105, 9;
	shl.b32 	%r110, %r106, 9;
	shl.b64 	%rd21, %rd19, 2;
	add.s64 	%rd22, %rd13, %rd21;
	mul.wide.u32 	%rd23, %r109, 4;
	add.s64 	%rd1, %rd22, %rd23;
	mul.wide.u32 	%rd24, %r110, 4;
	add.s64 	%rd2, %rd22, %rd24;
	setp.lt.u32 	%p6, %r106, 50;
	mov.b32 	%r6, 0;
	mov.pred 	%p1, -1;
	// begin inline asm
	mov.u32 %r2, 0x0;
	mov.u32 %r3, 0x0;
	mov.u32 %r4, 0x0;
	mov.u32 %r5, 0x0;
	@%p1 ld.global.v4.b32 { %r2, %r3, %r4, %r5 }, [ %rd1 + 0 ];
	@!%p1 mov.u32 %r2, %r6;
	@!%p1 mov.u32 %r3, %r6;
	@!%p1 mov.u32 %r4, %r6;
	@!%p1 mov.u32 %r5, %r6;
	// end inline asm
	// begin inline asm
	mov.u32 %r10, 0x0;
	mov.u32 %r11, 0x0;
	mov.u32 %r12, 0x0;
	mov.u32 %r13, 0x0;
	@%p6 ld.global.v4.b32 { %r10, %r11, %r12, %r13 }, [ %rd2 + 0 ];
	@!%p6 mov.u32 %r10, %r6;
	@!%p6 mov.u32 %r11, %r6;
	@!%p6 mov.u32 %r12, %r6;
	@!%p6 mov.u32 %r13, %r6;
	// end inline asm
	mul.lo.s32 	%r111, %r107, 10;
	add.s32 	%r112, %r111, 320;
	or.b64  	%rd25, %rd15, %rd18;
	mul.wide.u32 	%rd26, %r102, 40;
	shl.b64 	%rd27, %rd25, 2;
	add.s64 	%rd28, %rd12, %rd27;
	add.s64 	%rd3, %rd28, %rd26;
	mul.wide.u32 	%rd29, %r111, 4;
	add.s64 	%rd4, %rd28, %rd29;
	add.s64 	%rd5, %rd4, 640;
	mul.wide.u32 	%rd30, %r112, 4;
	add.s64 	%rd6, %rd28, %rd30;
	setp.lt.u32 	%p24, %r108, 50;
	setp.lt.u64 	%p11, %rd25, 10;
	and.pred  	%p20, %p24, %p11;
	// begin inline asm
	mov.u32 %r18, 0x0;
	mov.u32 %r19, 0x0;
	@%p11 ld.global.v2.b32 { %r18, %r19 }, [ %rd3 + 0 ];
	@!%p11 mov.u32 %r18, %r6;
	@!%p11 mov.u32 %r19, %r6;
	// end inline asm
	// begin inline asm
	mov.u32 %r22, 0x0;
	mov.u32 %r23, 0x0;
	@%p11 ld.global.v2.b32 { %r22, %r23 }, [ %rd4 + 0 ];
	@!%p11 mov.u32 %r22, %r6;
	@!%p11 mov.u32 %r23, %r6;
	// end inline asm
	// begin inline asm
	mov.u32 %r26, 0x0;
	mov.u32 %r27, 0x0;
	@%p11 ld.global.v2.b32 { %r26, %r27 }, [ %rd5 + 0 ];
	@!%p11 mov.u32 %r26, %r6;
	@!%p11 mov.u32 %r27, %r6;
	// end inline asm
	// begin inline asm
	mov.u32 %r30, 0x0;
	mov.u32 %r31, 0x0;
	@%p20 ld.global.v2.b32 { %r30, %r31 }, [ %rd6 + 0 ];
	@!%p20 mov.u32 %r30, %r6;
	@!%p20 mov.u32 %r31, %r6;
	// end inline asm
	mov.b32 	%f65, %r30;
	mov.b32 	%f66, %r31;
	mov.b32 	%f67, %r2;
	mov.b32 	%f68, %r3;
	mov.b32 	%f69, %r4;
	mov.b32 	%f70, %r5;
	mul.rn.f32 	%f71, %f70, 0f3A800000;
	mul.rn.f32 	%f72, %f69, 0f3A800000;
	mul.rn.f32 	%f73, %f68, 0f3A800000;
	mul.rn.f32 	%f74, %f67, 0f3A800000;
	mov.b32 	%f75, %r13;
	mov.b32 	%f76, %r12;
	mov.b32 	%f77, %r11;
	mov.b32 	%f78, %r10;
	mul.rn.f32 	%f79, %f78, 0f3A800000;
	mul.rn.f32 	%f80, %f77, 0f3A800000;
	mul.rn.f32 	%f81, %f76, 0f3A800000;
	mul.rn.f32 	%f82, %f75, 0f3A800000;
	selp.f32 	%f83, %f82, 0f00000000, %p6;
	selp.f32 	%f84, %f81, 0f00000000, %p6;
	selp.f32 	%f85, %f80, 0f00000000, %p6;
	selp.f32 	%f86, %f79, 0f00000000, %p6;
	xor.b32  	%r113, %r99, %r101;
	shl.b32 	%r114, %r105, 4;
	or.b32  	%r115, %r113, %r114;
	mul.wide.u32 	%rd31, %r115, 4;
	mov.u64 	%rd32, global_smem;
	add.s64 	%rd33, %rd32, %rd31;
	st.shared.v4.f32 	[%rd33], {%f74, %f73, %f72, %f71};
	shl.b32 	%r116, %r106, 4;
	or.b32  	%r117, %r116, %r113;
	mul.wide.u32 	%rd34, %r117, 4;
	add.s64 	%rd35, %rd32, %rd34;
	st.shared.v4.f32 	[%rd35], {%f86, %f85, %f84, %f83};
	selp.f32 	%f87, %f65, 0f00000000, %p24;
	selp.f32 	%f88, %f66, 0f00000000, %p24;
	shr.u32 	%r118, %r97, 1;
	and.b32  	%r119, %r118, 8;
	xor.b32  	%r120, %r104, %r119;
	shl.b32 	%r121, %r102, 4;
	or.b32  	%r122, %r120, %r121;
	mul.wide.u32 	%rd36, %r122, 4;
	add.s64 	%rd37, %rd32, 4096;
	add.s64 	%rd38, %rd37, %rd36;
	st.shared.v2.u32 	[%rd38], {%r18, %r19};
	shl.b32 	%r123, %r107, 4;
	or.b32  	%r124, %r120, %r123;
	mul.wide.u32 	%rd39, %r124, 4;
	add.s64 	%rd40, %rd37, %rd39;
	st.shared.v2.u32 	[%rd40], {%r22, %r23};
	or.b32  	%r125, %r122, 512;
	mul.wide.u32 	%rd41, %r125, 4;
	add.s64 	%rd42, %rd37, %rd41;
	st.shared.v2.u32 	[%rd42], {%r26, %r27};
	shl.b32 	%r126, %r108, 4;
	or.b32  	%r127, %r120, %r126;
	mul.wide.u32 	%rd43, %r127, 4;
	add.s64 	%rd44, %rd37, %rd43;
	st.shared.v2.f32 	[%rd44], {%f87, %f88};
	bar.sync 	0;
	bfe.u32 	%r128, %r97, 2, 3;
	and.b32  	%r129, %r97, 3;
	bfe.u32 	%r130, %r97, 1, 1;
	shl.b32 	%r131, %r130, 3;
	or.b32  	%r132, %r131, %r128;
	shl.b32 	%r133, %r129, 4;
	or.b32  	%r134, %r132, %r133;
	xor.b32  	%r135, %r134, 8;
	mul.wide.u32 	%rd45, %r134, 4;
	add.s64 	%rd46, %rd32, %rd45;
	mul.wide.u32 	%rd47, %r135, 4;
	add.s64 	%rd48, %rd32, %rd47;
	ld.shared.u32 	%r34, [%rd46];
	ld.shared.u32 	%r35, [%rd48];
	ld.shared.u32 	%r36, [%rd46+256];
	ld.shared.u32 	%r37, [%rd48+256];
	ld.shared.u32 	%r40, [%rd46+512];
	ld.shared.u32 	%r41, [%rd48+512];
	ld.shared.u32 	%r42, [%rd46+768];
	ld.shared.u32 	%r43, [%rd48+768];
	ld.shared.u32 	%r46, [%rd46+1024];
	ld.shared.u32 	%r47, [%rd48+1024];
	ld.shared.u32 	%r48, [%rd46+1280];
	ld.shared.u32 	%r49, [%rd48+1280];
	ld.shared.u32 	%r52, [%rd46+1536];
	ld.shared.u32 	%r53, [%rd48+1536];
	ld.shared.u32 	%r54, [%rd46+1792];
	ld.shared.u32 	%r55, [%rd48+1792];
	ld.shared.u32 	%r58, [%rd46+2048];
	ld.shared.u32 	%r59, [%rd48+2048];
	ld.shared.u32 	%r60, [%rd46+2304];
	ld.shared.u32 	%r61, [%rd48+2304];
	ld.shared.u32 	%r64, [%rd46+2560];
	ld.shared.u32 	%r65, [%rd48+2560];
	ld.shared.u32 	%r66, [%rd46+2816];
	ld.shared.u32 	%r67, [%rd48+2816];
	ld.shared.u32 	%r70, [%rd46+3072];
	ld.shared.u32 	%r71, [%rd48+3072];
	ld.shared.u32 	%r72, [%rd46+3328];
	ld.shared.u32 	%r73, [%rd48+3328];
	ld.shared.u32 	%r76, [%rd46+3584];
	ld.shared.u32 	%r77, [%rd48+3584];
	ld.shared.u32 	%r78, [%rd46+3840];
	ld.shared.u32 	%r79, [%rd48+3840];
	bfe.u32 	%r136, %r97, 5, 1;
	xor.b32  	%r137, %r136, %r130;
	shl.b32 	%r138, %r137, 3;
	or.b32  	%r139, %r138, %r128;
	or.b32  	%r140, %r139, %r133;
	mul.wide.u32 	%rd49, %r140, 4;
	add.s64 	%rd50, %rd37, %rd49;
	ld.shared.u32 	%r38, [%rd50];
	ld.shared.u32 	%r39, [%rd50+256];
	ld.shared.u32 	%r44, [%rd50+512];
	ld.shared.u32 	%r45, [%rd50+768];
	ld.shared.u32 	%r50, [%rd50+1024];
	ld.shared.u32 	%r51, [%rd50+1280];
	ld.shared.u32 	%r56, [%rd50+1536];
	ld.shared.u32 	%r57, [%rd50+1792];
	ld.shared.u32 	%r62, [%rd50+2048];
	ld.shared.u32 	%r63, [%rd50+2304];
	ld.shared.u32 	%r68, [%rd50+2560];
	ld.shared.u32 	%r69, [%rd50+2816];
	ld.shared.u32 	%r74, [%rd50+3072];
	ld.shared.u32 	%r75, [%rd50+3328];
	ld.shared.u32 	%r80, [%rd50+3584];
	ld.shared.u32 	%r81, [%rd50+3840];
	mov.f32 	%f12, 0f00000000;
	mov.f32 	%f9, %f12;
	mov.f32 	%f10, %f12;
	mov.f32 	%f11, %f12;
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r34, %r35, %r36, %r37 }, { %r38, %r39 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r40, %r41, %r42, %r43 }, { %r44, %r45 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r46, %r47, %r48, %r49 }, { %r50, %r51 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r52, %r53, %r54, %r55 }, { %r56, %r57 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r58, %r59, %r60, %r61 }, { %r62, %r63 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r64, %r65, %r66, %r67 }, { %r68, %r69 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r70, %r71, %r72, %r73 }, { %r74, %r75 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f9, %f10, %f11, %f12 }, { %r76, %r77, %r78, %r79 }, { %r80, %r81 }, { %f9, %f10, %f11, %f12 };
	// end inline asm
	mul.lo.s64 	%rd51, %rd20, 40;
	add.s64 	%rd52, %rd10, %rd51;
	add.s64 	%rd7, %rd52, %rd27;
	bar.sync 	0;
	shl.b32 	%r141, %r129, 1;
	shl.b32 	%r142, %r136, 3;
	or.b32  	%r143, %r142, %r141;
	mul.lo.s32 	%r144, %r128, 18;
	add.s32 	%r145, %r143, %r144;
	mul.wide.u32 	%rd53, %r145, 4;
	add.s64 	%rd54, %rd32, %rd53;
	st.shared.v2.f32 	[%rd54], {%f9, %f10};
	cvt.u64.u32 	%rd55, %r143;
	cvt.u64.u32 	%rd56, %r144;
	add.s64 	%rd57, %rd56, %rd55;
	shl.b64 	%rd58, %rd57, 2;
	add.s64 	%rd59, %rd32, %rd58;
	st.shared.v2.f32 	[%rd59+576], {%f11, %f12};
	bar.sync 	0;
	bfe.u32 	%r146, %r97, 3, 2;
	shl.b32 	%r147, %r100, 2;
	or.b32  	%r148, %r147, %r146;
	mad.lo.s32 	%r149, %r148, 18, %r104;
	mul.wide.u32 	%rd60, %r149, 4;
	add.s64 	%rd61, %rd32, %rd60;
	ld.shared.v2.u32 	{%r82, %r83}, [%rd61];
	// begin inline asm
	@%p11 st.global.v2.b32 [ %rd7 + 0 ], { %r82, %r83 };
	// end inline asm
	ret;

}
	// .globl	loop_add_fusion_518
.visible .entry loop_add_fusion_518(
	.param .u64 loop_add_fusion_518_param_0,
	.param .u64 loop_add_fusion_518_param_1,
	.param .u64 loop_add_fusion_518_param_2,
	.param .u64 loop_add_fusion_518_param_3,
	.param .u64 loop_add_fusion_518_param_4,
	.param .u64 loop_add_fusion_518_param_5,
	.param .u64 loop_add_fusion_518_param_6,
	.param .u64 loop_add_fusion_518_param_7,
	.param .u64 loop_add_fusion_518_param_8,
	.param .u64 loop_add_fusion_518_param_9,
	.param .u64 loop_add_fusion_518_param_10,
	.param .u64 loop_add_fusion_518_param_11,
	.param .u64 loop_add_fusion_518_param_12,
	.param .u64 loop_add_fusion_518_param_13,
	.param .u64 loop_add_fusion_518_param_14,
	.param .u64 loop_add_fusion_518_param_15
)
.reqntid 1024, 1, 1
{
	.reg .b32 	%r<5>;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<40>;

	ld.param.u64 	%rd1, [loop_add_fusion_518_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_518_param_15];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_518_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_518_param_14];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_518_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_518_param_13];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_518_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_518_param_12];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_518_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_518_param_11];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_518_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_518_param_10];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_518_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_518_param_9];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_518_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_518_param_8];
	cvta.to.global.u64 	%rd24, %rd23;
	cvta.to.global.u64 	%rd25, %rd22;
	cvta.to.global.u64 	%rd26, %rd19;
	cvta.to.global.u64 	%rd27, %rd16;
	cvta.to.global.u64 	%rd28, %rd13;
	cvta.to.global.u64 	%rd29, %rd10;
	cvta.to.global.u64 	%rd30, %rd7;
	cvta.to.global.u64 	%rd31, %rd4;
	cvta.to.global.u64 	%rd32, %rd1;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 10;
	mov.u32 	%r3, %tid.x;
	or.b32  	%r4, %r2, %r3;
	mul.wide.u32 	%rd33, %r4, 4;
	add.s64 	%rd34, %rd32, %rd33;
	ld.global.nc.f32 	%f1, [%rd34];
	ld.global.nc.f32 	%f2, [%rd26];
	ld.global.nc.f32 	%f3, [%rd9];
	add.s64 	%rd35, %rd21, %rd33;
	ld.global.f32 	%f4, [%rd35];
	mul.rn.f32 	%f5, %f3, %f4;
	ld.global.nc.f32 	%f6, [%rd12];
	add.s64 	%rd36, %rd15, %rd33;
	ld.global.nc.f32 	%f7, [%rd36];
	mul.rn.f32 	%f8, %f6, %f7;
	add.rn.f32 	%f9, %f5, %f8;
	ld.global.nc.f32 	%f10, [%rd27];
	ld.global.nc.f32 	%f11, [%rd18];
	mul.rn.f32 	%f12, %f4, %f4;
	mul.rn.f32 	%f13, %f12, %f11;
	ld.global.nc.f32 	%f14, [%rd24];
	add.s64 	%rd37, %rd25, %rd33;
	ld.global.nc.f32 	%f15, [%rd37];
	mul.rn.f32 	%f16, %f14, %f15;
	add.rn.f32 	%f17, %f13, %f16;
	ld.global.nc.f32 	%f18, [%rd28];
	div.full.f32 	%f19, %f17, %f18;
	ld.global.nc.f32 	%f20, [%rd29];
	add.rn.f32 	%f21, %f20, %f19;
	sqrt.approx.f32 	%f22, %f21;
	ld.global.nc.f32 	%f23, [%rd30];
	add.rn.f32 	%f24, %f22, %f23;
	mul.rn.f32 	%f25, %f10, %f24;
	div.full.f32 	%f26, %f9, %f25;
	ld.global.nc.f32 	%f27, [%rd31];
	mul.rn.f32 	%f28, %f1, %f27;
	add.rn.f32 	%f29, %f28, %f26;
	mul.rn.f32 	%f30, %f2, %f29;
	add.rn.f32 	%f31, %f1, %f30;
	add.s64 	%rd38, %rd6, %rd33;
	st.global.f32 	[%rd38], %f31;
	add.s64 	%rd39, %rd3, %rd33;
	st.global.f32 	[%rd39], %f17;
	st.global.f32 	[%rd35], %f9;
	ret;

}
	// .globl	loop_add_fusion_519
.visible .entry loop_add_fusion_519(
	.param .u64 loop_add_fusion_519_param_0,
	.param .u64 loop_add_fusion_519_param_1,
	.param .u64 loop_add_fusion_519_param_2,
	.param .u64 loop_add_fusion_519_param_3,
	.param .u64 loop_add_fusion_519_param_4,
	.param .u64 loop_add_fusion_519_param_5,
	.param .u64 loop_add_fusion_519_param_6,
	.param .u64 loop_add_fusion_519_param_7,
	.param .u64 loop_add_fusion_519_param_8,
	.param .u64 loop_add_fusion_519_param_9,
	.param .u64 loop_add_fusion_519_param_10,
	.param .u64 loop_add_fusion_519_param_11,
	.param .u64 loop_add_fusion_519_param_12,
	.param .u64 loop_add_fusion_519_param_13,
	.param .u64 loop_add_fusion_519_param_14,
	.param .u64 loop_add_fusion_519_param_15,
	.param .u64 loop_add_fusion_519_param_16
)
.reqntid 10, 1, 1
{
	.reg .b32 	%r<2>;
	.reg .f32 	%f<131>;
	.reg .b64 	%rd<43>;

	ld.param.u64 	%rd1, [loop_add_fusion_519_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_519_param_16];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_add_fusion_519_param_1];
	ld.param.u64 	%rd5, [loop_add_fusion_519_param_15];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_add_fusion_519_param_2];
	ld.param.u64 	%rd8, [loop_add_fusion_519_param_14];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_add_fusion_519_param_3];
	ld.param.u64 	%rd11, [loop_add_fusion_519_param_13];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_add_fusion_519_param_4];
	ld.param.u64 	%rd14, [loop_add_fusion_519_param_12];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.param.u64 	%rd16, [loop_add_fusion_519_param_5];
	ld.param.u64 	%rd17, [loop_add_fusion_519_param_11];
	cvta.to.global.u64 	%rd18, %rd17;
	ld.param.u64 	%rd19, [loop_add_fusion_519_param_6];
	ld.param.u64 	%rd20, [loop_add_fusion_519_param_10];
	cvta.to.global.u64 	%rd21, %rd20;
	ld.param.u64 	%rd22, [loop_add_fusion_519_param_7];
	ld.param.u64 	%rd23, [loop_add_fusion_519_param_9];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [loop_add_fusion_519_param_8];
	cvta.to.global.u64 	%rd26, %rd25;
	cvta.to.global.u64 	%rd27, %rd22;
	cvta.to.global.u64 	%rd28, %rd19;
	cvta.to.global.u64 	%rd29, %rd16;
	cvta.to.global.u64 	%rd30, %rd13;
	cvta.to.global.u64 	%rd31, %rd10;
	cvta.to.global.u64 	%rd32, %rd7;
	cvta.to.global.u64 	%rd33, %rd4;
	cvta.to.global.u64 	%rd34, %rd1;
	mov.u32 	%r1, %tid.x;
	mul.wide.u32 	%rd35, %r1, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.nc.f32 	%f1, [%rd36];
	ld.global.nc.f32 	%f2, [%rd33];
	ld.global.nc.f32 	%f3, [%rd12];
	add.s64 	%rd37, %rd24, %rd35;
	ld.global.nc.f32 	%f4, [%rd37];
	add.rn.f32 	%f5, %f4, 0f00000000;
	ld.global.nc.f32 	%f6, [%rd37+40];
	add.rn.f32 	%f7, %f5, %f6;
	ld.global.nc.f32 	%f8, [%rd37+80];
	add.rn.f32 	%f9, %f7, %f8;
	ld.global.nc.f32 	%f10, [%rd37+120];
	add.rn.f32 	%f11, %f9, %f10;
	ld.global.nc.f32 	%f12, [%rd37+160];
	add.rn.f32 	%f13, %f11, %f12;
	ld.global.nc.f32 	%f14, [%rd37+200];
	add.rn.f32 	%f15, %f13, %f14;
	ld.global.nc.f32 	%f16, [%rd37+240];
	add.rn.f32 	%f17, %f15, %f16;
	ld.global.nc.f32 	%f18, [%rd37+280];
	add.rn.f32 	%f19, %f17, %f18;
	ld.global.nc.f32 	%f20, [%rd37+320];
	add.rn.f32 	%f21, %f19, %f20;
	ld.global.nc.f32 	%f22, [%rd37+360];
	add.rn.f32 	%f23, %f21, %f22;
	ld.global.nc.f32 	%f24, [%rd37+400];
	add.rn.f32 	%f25, %f23, %f24;
	ld.global.nc.f32 	%f26, [%rd37+440];
	add.rn.f32 	%f27, %f25, %f26;
	ld.global.nc.f32 	%f28, [%rd37+480];
	add.rn.f32 	%f29, %f27, %f28;
	ld.global.nc.f32 	%f30, [%rd37+520];
	add.rn.f32 	%f31, %f29, %f30;
	ld.global.nc.f32 	%f32, [%rd37+560];
	add.rn.f32 	%f33, %f31, %f32;
	ld.global.nc.f32 	%f34, [%rd37+600];
	add.rn.f32 	%f35, %f33, %f34;
	ld.global.nc.f32 	%f36, [%rd37+640];
	add.rn.f32 	%f37, %f35, %f36;
	ld.global.nc.f32 	%f38, [%rd37+680];
	add.rn.f32 	%f39, %f37, %f38;
	ld.global.nc.f32 	%f40, [%rd37+720];
	add.rn.f32 	%f41, %f39, %f40;
	ld.global.nc.f32 	%f42, [%rd37+760];
	add.rn.f32 	%f43, %f41, %f42;
	ld.global.nc.f32 	%f44, [%rd37+800];
	add.rn.f32 	%f45, %f43, %f44;
	ld.global.nc.f32 	%f46, [%rd37+840];
	add.rn.f32 	%f47, %f45, %f46;
	ld.global.nc.f32 	%f48, [%rd37+880];
	add.rn.f32 	%f49, %f47, %f48;
	ld.global.nc.f32 	%f50, [%rd37+920];
	add.rn.f32 	%f51, %f49, %f50;
	ld.global.nc.f32 	%f52, [%rd37+960];
	add.rn.f32 	%f53, %f51, %f52;
	ld.global.nc.f32 	%f54, [%rd37+1000];
	add.rn.f32 	%f55, %f53, %f54;
	ld.global.nc.f32 	%f56, [%rd37+1040];
	add.rn.f32 	%f57, %f55, %f56;
	ld.global.nc.f32 	%f58, [%rd37+1080];
	add.rn.f32 	%f59, %f57, %f58;
	ld.global.nc.f32 	%f60, [%rd37+1120];
	add.rn.f32 	%f61, %f59, %f60;
	ld.global.nc.f32 	%f62, [%rd37+1160];
	add.rn.f32 	%f63, %f61, %f62;
	ld.global.nc.f32 	%f64, [%rd37+1200];
	add.rn.f32 	%f65, %f63, %f64;
	ld.global.nc.f32 	%f66, [%rd37+1240];
	add.rn.f32 	%f67, %f65, %f66;
	ld.global.nc.f32 	%f68, [%rd37+1280];
	add.rn.f32 	%f69, %f67, %f68;
	ld.global.nc.f32 	%f70, [%rd37+1320];
	add.rn.f32 	%f71, %f69, %f70;
	ld.global.nc.f32 	%f72, [%rd37+1360];
	add.rn.f32 	%f73, %f71, %f72;
	ld.global.nc.f32 	%f74, [%rd37+1400];
	add.rn.f32 	%f75, %f73, %f74;
	ld.global.nc.f32 	%f76, [%rd37+1440];
	add.rn.f32 	%f77, %f75, %f76;
	ld.global.nc.f32 	%f78, [%rd37+1480];
	add.rn.f32 	%f79, %f77, %f78;
	ld.global.nc.f32 	%f80, [%rd37+1520];
	add.rn.f32 	%f81, %f79, %f80;
	ld.global.nc.f32 	%f82, [%rd37+1560];
	add.rn.f32 	%f83, %f81, %f82;
	ld.global.nc.f32 	%f84, [%rd37+1600];
	add.rn.f32 	%f85, %f83, %f84;
	ld.global.nc.f32 	%f86, [%rd37+1640];
	add.rn.f32 	%f87, %f85, %f86;
	ld.global.nc.f32 	%f88, [%rd37+1680];
	add.rn.f32 	%f89, %f87, %f88;
	ld.global.nc.f32 	%f90, [%rd37+1720];
	add.rn.f32 	%f91, %f89, %f90;
	ld.global.nc.f32 	%f92, [%rd37+1760];
	add.rn.f32 	%f93, %f91, %f92;
	ld.global.nc.f32 	%f94, [%rd37+1800];
	add.rn.f32 	%f95, %f93, %f94;
	ld.global.nc.f32 	%f96, [%rd37+1840];
	add.rn.f32 	%f97, %f95, %f96;
	ld.global.nc.f32 	%f98, [%rd37+1880];
	add.rn.f32 	%f99, %f97, %f98;
	ld.global.nc.f32 	%f100, [%rd37+1920];
	add.rn.f32 	%f101, %f99, %f100;
	ld.global.nc.f32 	%f102, [%rd37+1960];
	add.rn.f32 	%f103, %f101, %f102;
	mul.rn.f32 	%f104, %f3, %f103;
	ld.global.nc.f32 	%f105, [%rd15];
	add.s64 	%rd38, %rd18, %rd35;
	ld.global.nc.f32 	%f106, [%rd38];
	mul.rn.f32 	%f107, %f105, %f106;
	add.rn.f32 	%f108, %f104, %f107;
	ld.global.nc.f32 	%f109, [%rd32];
	ld.global.nc.f32 	%f110, [%rd21];
	mul.rn.f32 	%f111, %f103, %f103;
	mul.rn.f32 	%f112, %f111, %f110;
	ld.global.nc.f32 	%f113, [%rd26];
	add.s64 	%rd39, %rd27, %rd35;
	ld.global.nc.f32 	%f114, [%rd39];
	mul.rn.f32 	%f115, %f113, %f114;
	add.rn.f32 	%f116, %f112, %f115;
	ld.global.nc.f32 	%f117, [%rd29];
	div.full.f32 	%f118, %f116, %f117;
	ld.global.nc.f32 	%f119, [%rd30];
	add.rn.f32 	%f120, %f119, %f118;
	sqrt.approx.f32 	%f121, %f120;
	ld.global.nc.f32 	%f122, [%rd31];
	add.rn.f32 	%f123, %f121, %f122;
	mul.rn.f32 	%f124, %f109, %f123;
	div.full.f32 	%f125, %f108, %f124;
	ld.global.nc.f32 	%f126, [%rd28];
	mul.rn.f32 	%f127, %f1, %f126;
	add.rn.f32 	%f128, %f127, %f125;
	mul.rn.f32 	%f129, %f2, %f128;
	add.rn.f32 	%f130, %f1, %f129;
	add.s64 	%rd40, %rd9, %rd35;
	st.global.f32 	[%rd40], %f130;
	add.s64 	%rd41, %rd6, %rd35;
	st.global.f32 	[%rd41], %f116;
	add.s64 	%rd42, %rd3, %rd35;
	st.global.f32 	[%rd42], %f108;
	ret;

}
	// .globl	loop_multiply_fusion_147
.visible .entry loop_multiply_fusion_147(
	.param .u64 loop_multiply_fusion_147_param_0,
	.param .u64 loop_multiply_fusion_147_param_1
)
.reqntid 1, 1, 1
{
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [loop_multiply_fusion_147_param_0];
	ld.param.u64 	%rd2, [loop_multiply_fusion_147_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	ld.global.nc.f32 	%f1, [%rd4];
	mul.rn.f32 	%f2, %f1, 0f3CA3D70A;
	st.global.f32 	[%rd3], %f2;
	ret;

}
	// .globl	loop_select_fusion_45
.visible .entry loop_select_fusion_45(
	.param .u64 loop_select_fusion_45_param_0,
	.param .u64 loop_select_fusion_45_param_1,
	.param .u64 loop_select_fusion_45_param_2,
	.param .u64 loop_select_fusion_45_param_3,
	.param .u64 loop_select_fusion_45_param_4,
	.param .u64 loop_select_fusion_45_param_5,
	.param .u64 loop_select_fusion_45_param_6,
	.param .u64 loop_select_fusion_45_param_7,
	.param .u64 loop_select_fusion_45_param_8,
	.param .u64 loop_select_fusion_45_param_9
)
.reqntid 1, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<21>;

	ld.param.u64 	%rd1, [loop_select_fusion_45_param_0];
	ld.param.u64 	%rd2, [loop_select_fusion_45_param_9];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [loop_select_fusion_45_param_1];
	ld.param.u64 	%rd5, [loop_select_fusion_45_param_8];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u64 	%rd7, [loop_select_fusion_45_param_2];
	ld.param.u64 	%rd8, [loop_select_fusion_45_param_7];
	cvta.to.global.u64 	%rd9, %rd8;
	ld.param.u64 	%rd10, [loop_select_fusion_45_param_3];
	ld.param.u64 	%rd11, [loop_select_fusion_45_param_6];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.param.u64 	%rd13, [loop_select_fusion_45_param_4];
	ld.param.u64 	%rd14, [loop_select_fusion_45_param_5];
	cvta.to.global.u64 	%rd15, %rd14;
	cvta.to.global.u64 	%rd16, %rd13;
	cvta.to.global.u64 	%rd17, %rd10;
	cvta.to.global.u64 	%rd18, %rd7;
	cvta.to.global.u64 	%rd19, %rd4;
	cvta.to.global.u64 	%rd20, %rd1;
	ld.global.nc.u32 	%r1, [%rd20];
	setp.eq.s32 	%p1, %r1, 2147483647;
	add.s32 	%r2, %r1, 1;
	selp.b32 	%r3, 2147483647, %r2, %p1;
	ld.global.nc.u32 	%r4, [%rd19];
	setp.eq.s32 	%p2, %r4, 2147483647;
	add.s32 	%r5, %r4, 1;
	selp.b32 	%r6, 2147483647, %r5, %p2;
	ld.global.nc.u32 	%r7, [%rd18];
	setp.eq.s32 	%p3, %r7, 2147483647;
	add.s32 	%r8, %r7, 1;
	selp.b32 	%r9, 2147483647, %r8, %p3;
	ld.global.nc.u32 	%r10, [%rd17];
	setp.eq.s32 	%p4, %r10, 2147483647;
	add.s32 	%r11, %r10, 1;
	selp.b32 	%r12, 2147483647, %r11, %p4;
	ld.global.nc.u32 	%r13, [%rd16];
	setp.eq.s32 	%p5, %r13, 2147483647;
	add.s32 	%r14, %r13, 1;
	selp.b32 	%r15, 2147483647, %r14, %p5;
	st.global.u32 	[%rd15], %r3;
	st.global.u32 	[%rd12], %r6;
	st.global.u32 	[%rd9], %r9;
	st.global.u32 	[%rd6], %r12;
	st.global.u32 	[%rd3], %r15;
	ret;

}
	// .globl	loop_add_fusion_520
.visible .entry loop_add_fusion_520(
	.param .u64 loop_add_fusion_520_param_0,
	.param .u64 loop_add_fusion_520_param_1
)
.reqntid 1, 1, 1
{
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [loop_add_fusion_520_param_0];
	ld.param.u64 	%rd2, [loop_add_fusion_520_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	ld.global.nc.u32 	%r1, [%rd4];
	add.s32 	%r2, %r1, 1;
	st.global.u32 	[%rd3], %r2;
	ret;

}
